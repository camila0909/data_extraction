Sociedade Brasileira de Matemática - SBM 

Universidade Federal do Acre - UFAC 

Mestrado Profissional em Matemática - PROFMAT 

Ismael Dourado de Assis 

Elementos ortogonais 

Fevereiro  

2019 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Sociedade Brasileira de Matemática - SBM 

Universidade Federal do Acre - UFAC 

Mestrado Profissional em Matemática - PROFMAT 

Elementos Ortogonais 

Trabalho  de  conclusão  de  curso  apresentado  ao 

Mestrado Profissional de Matemática em Rede Nacional 

-  PROFMAT,  na  cidade  de  Rio  Branco,  Acre,  como 

requisito parcial para a obtenção do título de Mestre em 

Matemática. 

Orientador: Prof. Dr. José Ivan da Silva Ramos 

Fevereiro  

2019 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Ficha catalográfica elaborada pela Biblioteca Central da UFAC 

  As76e    Assis, Ismael Dourado de, 1987 - 

Elementos Ortogonais / Ismael Dourado de Assis; orientador: Dr.  José Ivan 

da Silva Ramos. – 2019. 

56 f.: il. ; 30 cm. 

Dissertação  (Mestrado)  –  Universidade  Federal  do  Acre,  Programa  de  Pós-
Graduação  em Mestrado Profissional em Matemática - PROFMAT, Rio Branco, 
2019. 

Inclui referências bibliográficas. 

1. Vetores ortogonais. 2. Conjunto C. 3. Elemento ortogonal. I. Ramos, José 

Ivan da Silva (orientador). II. Título. 

                                                                                       CDD: 510.7                                      

Bibliotecária: Nádia Batista Vieira   CRB-11º/882. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                         
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
          
            
 
                                                               
 
 
 
 
 
 
                                                                                   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
DEDICATÓRIA 

Em especial à minha mãe, Tereza Montefusco Dourado; à 

minha família, aos meus amigos e aos meus professores. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
AGRADECIMENTOS 

À minha família: mãe,  pela dedicação  e ensinamentos, os quais levo comigo, em 

especial o valor pelo trabalho, por tudo(!); aos meus irmãos (sem distinção) e pai, pelo 

apoio, principalmente o financeiro, quando muito precisei.  

Ao meu orientador, professor e amigo, José Ivan da Silva Ramos, pelo apoio e força. 

Pelos conselhos, pela cobrança, não somente nas questões acadêmicas, mas nas questões 

do dia-a-dia e também no tocante à minha presença quando por vezes Eu passo dias sem 

aparecer.  Por  desde  a  graduação,  ser  muito  prestativo  quando  Eu  desanimava  com 

algumas  disciplinas.  Por  ser  um  dos  grandes  responsáveis  pelo  meu  interesse  pela 

matemática pura juntamente com o professor Sérgio Brazil Junior.  

Ao  professor  Sérgio  Brazil  Junior,  por  quem  também  tenho  muita  admiração  e 

respeito, por ter sido meu professor na graduação e no mestrado, colaborando com o meu 

crescimento  acadêmico.  Meu  muito  obrigado  pelo  apoio  e  bom  direcionamento  na 

disciplina de aritmética.  

Ao professor Geirto de Souza, por ter sido meu professor na graduação e também 

no mestrado, com bom direcionamento na disciplina de geometria.  

Ao professor Isaac Dayan Bastos da Silva, por ter sido meu orientador de iniciação 

científica,  ligada  ao  projeto  Integrando  a  Amazônia  (SBM)  e  por  ter  contribuído,  no 

mestrado com a disciplina de cálculo.  

Aos demais professores que compõem o corpo docente do PROFMAT.  

Aos colegas de mestrado, pelos quais sempre estive e estarei a torcer pelo sucesso 

dos mesmos (na qualificação). 

Aos demais amigos, no sentido restrito da palavra, os quais reservo-me no direito 

de não citar para não cometer injustiça, tendo em vista a possibilidade de esquecer algum 

nome. 

 
 
 
 
 
 
 
 
 
 
 
 
 
Resumo  

Vetores  ortogonais  podem  aparecer  formando  as  colunas  de  uma  matriz 

motivando alguns autores a estabelecerem a definição de elemento ortogonal em 𝑀𝑛(ℝ). 
Isso  se  traduz  pela  igualdade  𝐴𝐴𝑡 = 𝐼𝑛.  Examinando  o  caso  𝑛 = 2  mostramos  que  esse 
conceito pode ser estendido para o conjunto ℂ dos números complexos. 

Palavras-chave: Isomorfismos, operadores lineares, matrizes e elementos ortogonais. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Abstract 

Orthogonal vectors may appear to form the columns of a matrix motivating some 

authors to establish the orthogonal element definition in 𝑀𝑛(ℝ). This is translated by the 
equation 𝐴𝐴𝑡 = 𝐼𝑛. Examining the case 𝑛 = 2 we show that this concept can be extended 
to the set  ℂ of the complex numbers. 

Key words: Isomorphisms, linear operators, matrices and orthogonal elements. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    SUMÁRIO 

Introdução ....................................................................................................................................... 10 

Capítulo 1 - Uma representação dos números complexos dentro de um anel de matrizes ....... 13 

1.1 Definições e operações ............................................................................................................. 13 

1.2 O anel das matrizes quadradas de ordem 2 ............................................................................ 20 

1.3 O corpo dos números complexos ............................................................................................. 24 

1.4 Isomorfismos - cópias do corpo dos números complexos ..................................................... 26 

1.5 Espaços vetoriais ...................................................................................................................... 32 

1.6 Transformações lineares .......................................................................................................... 35 

Capítulo 2 - Elementos ortogonais ................................................................................................ 41 

2.1 Os elementos ortogonais de 𝕄2(ℝ) ........................................................................................ 41 
2.2 As 𝜑−1 - imagens dos elementos ortogonais de 𝒞 .................................................................. 42 

2.3 Uma razoável definição para elementos ortogonais em ℂ ..................................................... 44 

2.4 Os elementos ortogonais de ℝ² ............................................................................................... 46 

2.5 Os elementos ortogonais de ℱ(ℝ²) ......................................................................................... 48 

Capítulo 3 - Considerações finais ................................................................................................... 52 

Bibliografia ...................................................................................................................................... 56 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Lista de Símbolos 

<: menor do que,  

>: maior do que 

≤: menor do que ou igual a 

≥: maior do que ou igual a 

≡: identificador por 

≠: diferente 

≃: isomorfo a 

≲: imerso em 

∀: para todo, qualquer que seja 

⇒: então, implica 

⇔: equivalente, se e somente se, se e só se 

∞: infinito (não é um número) 

 / (ou ;): tal que 

∃: existe  

∄ : não existe  

∈: pertence a 

∉: não pertence a 

⊂: está contido,  

⊄: não está contido 

∪: união  

∩: interseção 

𝑋 e 𝑌 : conjuntos abstratos 

#𝑋: número de elementos do conjunto 𝑋 

ℕ: conjunto dos números naturais 

ℤ: conjunto dos números inteiros 

ℚ: conjunto dos números racionais 

ℝ: conjunto dos números reais 

ℂ: conjunto dos números complexos 

𝕄𝑚×𝑛(𝐾): o conjunto das matrizes de ordem 𝑚 × 𝑛 sobre um corpo 𝐾 

 
 
 
 
10 

Introdução 

O Mestrado Profissional 

Embora o mestrado profissional em Matemática - PROTMAT seja na modalidade 

de um mestrado semipresencial e visto com certa desconfiança por alguns da comunidade 

da matemática,  ele é muito bem avaliado pela CAPES e  o diploma que ele  concede aos 

estudantes também é bem valorizado. 

É bastante claro o objetivo do PROFMAT em aprofundar alguns conhecimentos de 

Matemática  básica,  oportunizando  ao  professor  uma  formação  mais  sólida,  que  pode 

obter maior confiança no exercício dessa bela profissão de ensinar.  

Depois  de  conhecer  as  particularidades  do  PROFMAT  e  conversar  com  alguns 

colegas, egressos desse curso ou que ainda estavam estudando, percebi que todos falavam 

positivamente do mestrado e aí eu vi a oportunidade de estar trabalhando e estudando 

perto da família e amigos, participando efetivamente de um programa de estudo que me 

garantirá  boas  oportunidades  profissionais  no  futuro  e  ainda  me  permitirá  ser  um 

professor melhor qualificado. 

No  PROFMAT  pude  reforçar  alguns  conteúdos  que  tive  na  graduação;  já  que  as 

disciplinas:  Números  e  Funções,  Matemática  Discreta,  Geometria  e  Aritmética,  que 

compõe  a  base  da  prova  do  exame  nacional  de  qualificação  (ENQ),  nos  proporcionam 

fazer uma revisão bastante significativa dos conteúdos de Matemática da educação básica. 

Isso me deu mais certeza de que fiz a escolha certa ao optar por essa área do conhecimento 

e  eu  destaco  a  Aritmética  e  a  Álgebra  Linear  como  as  disciplinas  que  guardam  os 

conteúdos que Eu, depois de concluir mais essa etapa de estudos, passarei a dedicar mais 

do meu tempo para fazer novas investigações. 

A escolha do tema  

Com relação ao tema a ser apresentado no Trabalho de Conclusão de Curso - TCC, 

meu orientador e eu vínhamos conversando sobre fazermos algo na Teoria dos Números, 

sobre a reciprocidade quadrática de Gauss, porém, percebemos que além de já existirem 

outras dissertações levaríamos muito tempo para fazer algo diferente e de significação 

sobre esse tema. Então, em meios às longas conversas que tínhamos surgiu uma pergunta 

feita  pelo  meu  colega  de  classe  Leonézio  Ponce:  o  que  motiva  a  definição  de  matrizes 

ortogonais? A discussão girou em torno do fato de que ortogonalidade é uma relação 2 

 
 
 
 
11 

testável em um espaço de vetores, no qual está definido um produto interno. O meu colega 

havia  percebido  um  pequeno  exercício  em  [4];  página  106,  pedindo  para  concluir  que 

matrizes ortogonais possuem determinantes igual a ±1. 

 Com  o  passar  dos  dias  algumas  considerações  foram  sendo  feitas  sem  que 

olhássemos o que, de fato, motivou a denominação de ortogonal: matriz ortogonal é todo 
matriz 𝐴 ∈ 𝕄𝑛(ℝ) tal que 𝐴𝐴𝑡 = 𝐼𝑛. Mais em frente, sabendo que o conjunto dos números 
complexos está imerso no anel de matrizes quadradas de ordem 2, via um isomorfismo, 

pensamos em como definir um elemento ortogonal em  ℂ.  Assim, investigamos como o 

conjunto dos elementos ortogonais de  𝕄2(ℝ) se relacionavam com  as imagens  diretas 

desse isomorfismo, para depois, de volta em  ℂ, tentar estabelecer esse conceito.  

A estrutura deste TCC  

Nosso  primeiro  capítulo,  de  noções  preliminares,  relembra  o  conjunto  das 

matrizes com as suas operações e propriedades usuais, onde fizemos uma breve descrição 

da  estrutura  de  anel  à  qual  o  conjunto  𝕄2(ℝ)  se  encaixa.  Através  de  isomorfismo, 

encerrando essa parte do trabalho, mostramos que podemos encontrar uma cópia de  ℂ 

dentro dessa estrutura algébrica. A parte final deste capítulo, que trata de espaço vetorial, 

mostra que o conceito de elemento ortogonal em 𝕄𝑛(ℝ) realmente é motivado pelo fato 

de que vetores ortogonais podem formar as colunas de uma matriz. Mostra também, e isso 

não é novo, que podemos chamar de ortogonal determinadas funções definidas em ℝ2.  

No capítulo dois estabelecemos o conceito de elemento ortogonal em ℂ, mostrando 

que  esse  conceito  está  diretamente  ligado  ao  conceito  de  conjugado  de  um  número 

complexo e,  portanto, longe do que motivou essa definição em  𝕄𝑛(ℝ); o que pode dar 

certa valorização para a nossa pesquisa. 

No capítulo três fazemos algumas considerações a respeito do nosso trabalho. 

Revisão bibliográfica 

Afim  de  respondermos  a  uma  pergunta  sobre  o  que  tratam  os  assuntos  que 

motivaram  a  definição  de  matrizes  ortogonais,  passamos  a  investigar  alguns  livros  de 

álgebra linear  usados, em geral,  nos cursos de matemática  na graduação.  Rapidamente 

encontramos uma boa resposta para essa pergunta. Por exemplo, no livro de Steinbruch, 

nossa referência [7], ele faz a definição de operador ortogonal, na página143. Seguindo, 
na  página  145,  ele  mostra  que  a  igualdade  𝐴𝐴𝑡 = 𝐼𝑛  aparece  naturalmente,  como  uma 

 
 
 
 
 
12 

propriedade, usando o fato de que o operador ortogonal preserva a norma. Assim, o autor 
chama de matriz ortogonal a toda matriz 𝐴 que satisfaz a igualdade 𝐴𝐴𝑡 = 𝐼𝑛. 

Em nossa referência [2], na página 254, o autor define matriz ortogonal e, usando 

o fato de que matriz ortogonal é composta por linhas ou colunas que são vetores dois a 

dois  ortogonais  e  unitários,  define,  na  página  258,  operador  ortogonal.  Isso  é  feito  da 

mesma maneira, na página 389 de nossa referência [1]. 

Por fim, em [6], na página 286, Seymour define operador ortogonal para os caso 

real  e  complexo.  Em  seguida,  na  página  287,  ele  define  matriz  ortogonal  como 

consequência do teorema 13.10B, a saber: A matriz 𝐴 com entradas reais representa um 

operador 𝑇 (relativo a uma base ortonormal) se, e somente se, 𝐴𝑡 = 𝐴−1.  

Na página  285, existe uma tabela na qual o autor  faz uma interessante  analogia 

entre a aplicação adjunta 𝑇 ⟶ 𝑇∗ e a aplicação de conjugação  𝑧 ⟶ 𝑧̅, em ℂ, conforme a 

tabela 1.  

Tabela 1: Analogia entre aplicação adjunta e a conjugação nos complexos 

Classe 

de 

Números 

Comportamento 

Classe de operadores de A(V) 

Comportamento pela 

Complexos 

pela Conjugação 

aplicação adjunta 

Círculo unitário (|𝑧| = 1) 

Eixo real 

𝑧̅ =

1
𝑧

𝑧̅ = 𝑧 

Operador  ortogonal  (caso  real)  ou 

𝑇∗ = 𝑇−1 

unitário (caso complexo) 

Operador  autoadjunto  (caso  real)  ou 

𝑇∗ = 𝑇 

Eixo imaginário 

𝑧̅ = −𝑧 

Operador  antiadjunto  (caso  real)  ou 

𝑇∗ = −𝑇 

hermitiano (caso complexo) 

Eixo positivo (0, ∞) 

𝑧̅ = 𝑤̅𝑤, 𝑤 ≠ 0 

Operadores positivos 

antihermitiano (caso complexo) 

𝑇 = 𝑆∗𝑆  com  𝑆  não 

singular 

Fonte: [6], página 285 

A tabela mostra o comportamento, pela conjugação, dos números complexos que 

têm módulos iguais a 1. Esses são os mesmos elementos que definimos como ortogonais. 

Reforçamos  que  a  nossa  sugestão  é  definir  números  complexos  ortogonais,  sem  que 

tivéssemos conhecimentos prévio dessa tabela. Isso foi feito olhando para a equação 𝑧𝑧̅ =

1, depois de analisar a imagem inversa de uma matriz ortogonal que também representa 

a imagem direta de um número complexo, através de um isomorfismo. (Ver a definição 

em 2.3.1). 

 
 
 
 
 
 
 
 
 
 
13 

Capítulo  1  -  Uma  representação  dos  números 
complexos dentro de um anel de matrizes 

Este primeiro capítulo, de noções preliminares, será uma base na qual apoiaremos 

discursões breves sobre o conjunto das matrizes, relembrando as definições usuais das 

operações de adição, multiplicação por escalar e multiplicação. 

Também relembraremos a definição de anéis, dando ênfase ao anel das matrizes 

quadradas  de  ordem  2.  Em  seguida,  faremos  uma  breve  descrição  dos  números 

complexos, mostrando que dentro do anel 𝕄2(ℝ) existe uma cópia de ℂ.  

1.1 Definições e operações 

A  presente  seção  será  dedicada  ao  conjunto  das  matrizes.  Começaremos 

relembrando a seguinte 

1.1.1. Definição: Digamos que 𝑚 e 𝑛 sejam dois números naturais não nulos. Definimos, 

assim, matriz  de  ordem 𝑚 por 𝑛  (𝑚 × 𝑛),  a  qualquer  tabela  de  𝑚  linhas  e  𝑛  colunas, 

formada por números, os quais chamamos de entradas da matriz.  

1.1.2. Exemplo: A tabela [5]1×1 é uma matriz de ordem 1 × 1, enquanto que  

[

1 4
]
2 5
3 6

3×2

é uma matriz de ordem 3 × 2, onde as entradas da primeira linha são os números 1 e 4 e 

as entradas da segunda e terceira linhas são, respectivamente, os números 2 e 5 e 3 e 6.  

É usual escrevemos uma matriz 𝐴 de ordem 𝑚 × 𝑛 por 

𝑎11
𝑎21
⋮

𝑎12 ⋯ 𝑎1𝑚
𝑎22 ⋯ 𝑎2𝑚
⋱
⋮

⋮

]

𝐴 = [

𝑎𝑚1 𝑎𝑚2 ⋯ 𝑎𝑚𝑛

𝑚×𝑛

ou, ainda, por 𝐴 = [𝑎𝑖𝑗]

𝑚×𝑛

, onde a entrada 𝑎𝑖𝑗 refere-se ao elemento da linha 𝑖 e coluna 

𝑗. Se a ordem da matriz já estiver subentendida escrevemos apenas 𝐴 = [𝑎𝑖𝑗].  

Vejamos, agora, como são denominadas algumas matrizes quando consideramos 

suas ordens. 

 
 
   
 
 
 
 
14 

1.1.3. Exemplo: A matriz de ordem 3 × 2 do exemplo em 1.1.2 é chamada de retangular. 

Do mesmo modo a matriz,  

[

1 2 3
3 2 1

]

2×3

é  uma matriz retangular.  Isto  é,  toda  matriz  de  ordem  𝑚 × 𝑛,  com  𝑚 ≠ 𝑛,  é  dita  uma 

matriz  retangular.  As  matrizes  retangulares  de  ordens  1 × 𝑛  e  𝑚 × 1,  com  𝑚 ≠ 1,  são 

chamadas de matriz linha e matriz coluna, respectivamente. Por exemplo, as matrizes  

[1 6 3 0]1×4 e [

0
9
]
2
5

4×1

são matrizes linha e coluna de ordens 1 × 4 e 4 × 1.  

Quando ocorrer de a ordem de uma matriz ser 𝑚 × 𝑛 com 𝑚 = 𝑛, diremos que essa 

matriz é uma quadrada de ordem 𝑛 (ou 𝑚). Assim, a matriz  

[

1 1
]
1 1

2×2

é uma matriz quadrada de ordem 2. 

Se uma matriz quadrada 𝐴 = [𝑎𝑖𝑗]

𝑛×𝑛

 todas as entradas 𝑎𝑖𝑗’s iguais a zero, quando 

𝑖 ≠ 𝑗 e 1 ≤ 𝑖, 𝑗 ≤ 𝑛, então será denominada de matriz diagonal. Como exemplo, a matriz  

𝐷 = [

0
2 0
0 7
0
0 0 19

]

. 

3×3

Dentre as matrizes diagonais, podemos destacar 𝐼𝑛 = [𝑎𝑖𝑗]

𝑛×𝑛

; onde 𝑎𝑖𝑗 = 1, se 𝑖 =

𝑗 e 𝑎𝑖𝑗 = 0, se 𝑖 ≠ 𝑗, para todo 𝑖, 𝑗 ∈ {1, 2, … , 𝑛}. Essa matriz é denominada de identidade 

de ordem 𝑛.  

Esse nome para 𝐼𝑛 é sugerido pelo fato de que essa matriz é o elemento neutro da 

multiplicação de matrizes que estabeleceremos na proposição em 1.1.8. Particularmente,   

𝐼2 = [

1 0
]
0 1

2×2

é o elemento neutro da multiplicação em 𝕄2(ℝ). 

Denominamos de matriz triangular superior (inferior), a matriz 𝐴 = [𝑎𝑖𝑗] tal que 

𝑎𝑖𝑗 = 0  se 𝑖 > 𝑗 (𝑎𝑖𝑗 = 0 se 𝑖 < 𝑗). Como exemplo, temos que 

[

1 2 3
0 4 5
0 0 6

]

 e [

3×3

0 0 0 0
1 6 0 0
]
2 3 0 0
4 5 6 1

, 

4×4

são, respectivamente, uma matriz triangular superior e uma matriz triangular inferior. 

 
 
 
 
 
15 

Matriz nula, é definida como sendo uma matriz cujas entradas são todas iguais a 

zero. Ela é o elemento neutro da adição que definiremos em 1.1.5.  

A matriz 

𝑂 = [

0 0 0
0 0 0
0 0 0

]

, 

3×3

é  a  matriz  nula  de  ordem  3.  Também  é  uma  matriz  diagonal,  triangular  inferior  e 

triangular superior. 

Duas  matrizes  são  iguais  se,  e  somente  se,  têm  a  mesma  ordem  e  entradas 

correspondentes iguais. Vejamos no seguinte 

1.1.4. Exemplo: As matrizes  [

1 3
]
5 8

2×2

 e [

1 𝑦
𝑥 8

]

2×2

só ocorrem de serem iguais se tivermos  

𝑥 = 5 e 𝑦 = 3. 

Na definição seguinte mostraremos como a adição de matrizes muito se assemelha 

a adição dos números reais, no que diz respeito às propriedades que essa operação possui. 

1.1.5.  Definição:  Dadas  duas  matrizes  𝐴 = [𝑎𝑖𝑗]

𝑚×𝑛

  e  𝐵 = [𝑏𝑖𝑗]

𝑚×𝑛

  de  mesma  ordem, 

definimos a adição de 𝐴 e 𝐵, representada por 𝐴 + 𝐵, como sendo a matriz 𝐶 = [𝑐𝑖𝑗]

𝑚×𝑛

tal que 𝑐𝑖𝑗 = 𝑎𝑖𝑗 + 𝑏𝑖𝑗 para todo 1 ≤ 𝑖 ≤ 𝑚 e para todo 1 ≤ 𝑗 ≤ 𝑛.  

Decorre dessa definição propriedades que são de imediata verificação.  

1.1.6. Proposição: Suponha que 𝐴, 𝐵 e 𝐶 sejam matrizes de mesma ordem. Então valem: 

𝑨𝟏: 𝐴 + (𝐵 + 𝐶) = (𝐴 + 𝐵) + 𝐶  (Associatividade da adição);  

𝑨𝟐: 𝐴 + 𝐵 = 𝐵 + 𝐴 (Comutatividade da adição);  

𝑨𝟑: 𝐴 + 𝑂 = 𝑂 + 𝐴 = 𝐴 (Existência de elemento neutro, onde 𝑂 é a matriz nula); 
𝑨𝟒: 𝐴 + (−𝐴) = −𝐴 + 𝐴 = 𝑂 (Existência de inverso aditivo). 

Demonstração: Tomemos matrizes quaisquer 𝐴 = [𝑎𝑖𝑗], 𝐵 = [𝑏𝑖𝑗] e 𝐶 = [𝑐𝑖𝑗], de mesma 

ordem.  Então,  temos  que  𝐴 + (𝐵 + 𝐶) = [𝑎𝑖𝑗] + ([𝑏𝑖𝑗] + [𝑐𝑖𝑗]) = [𝑎𝑖𝑗] + [𝑏𝑖𝑗 + 𝑐𝑖𝑗] =

[𝑎𝑖𝑗 + (𝑏𝑖𝑗 + 𝑐𝑖𝑗)] = [(𝑎𝑖𝑗 + 𝑏𝑖𝑗) + 𝑐𝑖𝑗] = [𝑎𝑖𝑗 + 𝑏𝑖𝑗] + [𝑐𝑖𝑗] = ([𝑎𝑖𝑗] + [𝑏𝑖𝑗]) + [𝑐𝑖𝑗] =

(𝐴 + 𝐵) + 𝐶. Portanto, vale 𝐴1. 

 
 
 
 
 
 
 
16 

Agora,  vale  que  𝐴 + 𝐵 = [𝑎𝑖𝑗] + [𝑏𝑖𝑗] = [𝑎𝑖𝑗 + 𝑏𝑖𝑗] = [𝑏𝑖𝑗 + 𝑎𝑖𝑗] = [𝑏𝑖𝑗] + [𝑎𝑖𝑗] =

𝐵 + 𝐴, e assim, vale 𝐴2. 

Omitiremos a demonstração das propriedades  𝐴3 e 𝐴4, que também não é difícil 

perceber, decorrem imediatamente das propriedades dos números reais. 

1.1.7.  Definição:  Sejam  𝛼  um  número  real  e  𝐴 = [𝑎𝑖𝑗]

𝑚×𝑛

  uma  matriz  de  ordem  𝑚 × 𝑛. 

Definimos a multiplicação de 𝐴 pelo escalar 𝛼 à matriz 𝛼𝐴 = [𝛼𝑎𝑖𝑗]

. 

𝑚×𝑛

1.1.8. Proposição: Sejam 𝐴 e 𝐵 matrizes de mesma ordem, 𝛼 e 𝜆 números reais.  Então, 

valem e são de imediata verificação, as seguintes propriedades: 

𝑬𝟏: 𝛼(𝐴 + 𝐵) = 𝛼𝐴 + 𝛼𝐵;      
𝑬𝟐: (𝛼 + 𝜆)𝐴 = 𝛼𝐴 + 𝜆𝐴;  
𝑬𝟑: 𝛼(𝜆𝐴) = (𝛼𝜆)𝐴; 

𝑬𝟒: 1𝐴 = 𝐴.  

Demonstração: Consideremos 𝐴 = [𝑎𝑖𝑗]

𝑚×𝑛

 e 𝐵 = [𝑏𝑖𝑗]

𝑚×𝑛

 matrizes quaisquer de mesma 

ordem  e  𝛼  um  número  real.  Temos  que  𝛼(𝐴 + 𝐵) = 𝛼([𝑎𝑖𝑗] + [𝑏𝑖𝑗]) = 𝛼([𝑎𝑖𝑗 + 𝑏𝑖𝑗]) =

[𝛼(𝑎𝑖𝑗 + 𝑏𝑖𝑗)] = [𝛼𝑎𝑖𝑗 + 𝛼𝑏𝑖𝑗] = [𝛼𝑎𝑖𝑗] + [𝛼𝑏𝑖𝑗] = 𝛼[𝑎𝑖𝑗] + 𝛼[𝑏𝑖𝑗] = 𝛼𝐴 + 𝛼𝐵.  Portanto, 

vale 𝐸1. 

Os  outros  fatos  não  serão  verificados.  Mas,  também  são  decorrentes  das 

propriedades dos números reais. 

1.1.9.  Definição:  Sejam  𝐴 = [𝑎𝑖𝑗]

𝑚×𝑙

  e 

  𝐵 = [𝑏𝑖𝑗]

𝑙×𝑛

  duas  matrizes.  Definimos  a 

multiplicação  de  A  por  𝐵,  nessa  ordem,  a  matriz  𝐶 = [𝑐𝑖𝑗]

𝑚×𝑛

,  como  sendo  de  ordem 

𝑚 × 𝑛, tal que  

𝑙

𝑐𝑖𝑗 = ∑ 𝑎𝑖𝑘𝑏𝑘𝑗 = 𝑎𝑖1𝑏1𝑗 + ⋯ + 𝑎𝑖𝑙𝑏𝑙𝑗

𝑘=1

para todo 1 ≤ 𝑖 ≤ 𝑚 e para todo 1 ≤ 𝑗 ≤ 𝑛.  

1.1.10. Exemplo: Em geral, não vale a igualdade 𝐴𝐵 = 𝐵𝐴. Notemos que 

[

8 8
]
4 1

2×2

= [

2 3
]
1 0

2×2

∙ [

4 1
]
0 2

2×2

≠ [

4 1
0 2

]

2×2

∙ [

2 3
]
1 0

2×2

= [

9 12
]
0
2

, 

2×2

isto é, essa operação não é comutativa. 

 
 
 
 
 
 
 
 
17 

Vejamos as propriedades da multiplicação de matrizes na seguinte 

1.1.11.  Proposição:  Sejam  𝐴, 𝐵  e  𝐶  matrizes  tais  que  os  produtos  indicados  abaixo  são 

possíveis de serem calculados. Então, valem:  

𝑴𝟏: 𝐴(𝐵 + 𝐶) = 𝐴𝐵 + 𝐴𝐶 (Distributiva à esquerda em relação à adição);   
𝑴𝟐: (𝐴 + 𝐵)𝐶 = 𝐴𝐶 + 𝐵𝐶 (Distributiva à direita em relação à adição);  

𝑴𝟑: 𝐴(𝐵𝐶) = (𝐴𝐵)𝐶 (Associatividade da multiplicação); 

𝑴𝟒: Se 𝐴 é uma matriz quadrada de ordem, então 𝐴𝐼𝑛 = 𝐼𝑛𝐴 = 𝐴 (Existência de elemento 

neutro da multiplicação). 

Demonstração: Mostraremos apenas 𝑀1. As outras propriedades decorrem igualmente da 

definição de multiplicação de matrizes. Temos 

𝐴(𝐵 + 𝐶) = [𝑎𝑖𝑘]([𝑏𝑘𝑗] + [𝑐𝑘𝑗]) = [𝑎𝑖𝑘]([𝑏𝑘𝑗 + 𝑐𝑘𝑗]) = [∑

𝑛
𝑘=1

𝑎𝑖𝑘(𝑏𝑘𝑗 + 𝑐𝑘𝑗) 

] =

[∑ (𝑎𝑖𝑘𝑏𝑘𝑗 + 𝑎𝑖𝑘𝑐𝑘𝑗)

𝑙
𝑘=1

] = [∑

𝑙
𝑘=1

𝑎𝑖𝑘𝑏𝑘𝑗

] + [∑

𝑙
𝑘=1

𝑎𝑖𝑘𝑐𝑘𝑗

] = 𝐴𝐵 + 𝐴𝐶,  com  𝑖 = 1, … , 𝑚  e 

𝑗 = 1, … , 𝑛. Portanto, vale 𝑀1. 

1.1.12. Exemplo: Acontece às vezes de o produto entre duas matrizes não nulas resultar 

na matriz nula. Veja,  

[

2 0
]
0 0

2×2

∙ [

0 0
4 0

]

2×2

= [

0 0
]
0 0

. 

2×2

Fazendo uma analogia com o conjunto dos números, onde um produto é nulo se, e 

somente se, um dos fatores é nulo, vemos que em um conjunto de matrizes podem existir 

divisores de zero. 

Mais uma operação que podemos considerar é apresentada na seguinte 

1.1.13. Definição: Dada uma matriz 𝐴 = [𝑎𝑖𝑗]

𝑚×𝑛

, dizemos que a matriz 𝐴𝑡 = [𝑎𝑗𝑖]

 é a 

𝑛×𝑚

transposta da matriz 𝐴.  

Em particular, a matriz 𝐴𝑡 = [

2 5 0
]
0 1 3

2×3

 de ordem 2 × 3 é a transposta da 

matriz 𝐴 = [

2 0
5 1
0 3

]

3×2

 de ordem 3 × 2. 

Se acontecer de 𝐴𝑡 = 𝐴 dizemos que a matriz 𝐴 é uma matriz simétrica. Se tivermos 

que 𝐴𝑡 = −𝐴 dizemos que a matriz 𝐴 é uma matriz antissimétrica. 

 
 
 
 
 
 
1.1.14. Proposição: Para toda matriz 𝐴 = [𝑎𝑖𝑗] e 𝐵 = [𝑏𝑖𝑗] e todo número real 𝛼, desde que 

18 

a multiplicação e a adição possam ser calculadas, vale que:  
𝑻𝟏: (𝐴𝑡)𝑡 = 𝐴;  
𝑻𝟐: (𝐴 + 𝐵)𝑡 = 𝐴𝑡 + 𝐵𝑡;  
𝑻𝟑: (𝐴𝐵)𝑡 = 𝐵𝑡𝐴𝑡;  
𝑻𝟒: (𝛼𝐴)𝑡 = 𝛼𝐴𝑡. 
Demonstração:  Temos 

𝑻𝟏: (𝐴𝑡)𝑡 = ([𝑎𝑖𝑗]

𝑡

𝑡

)

𝑡

= [𝑎𝑗𝑖]

= [𝑎𝑖𝑗] = 𝐴; 

𝑻𝟐: (𝐴 + 𝐵)𝑡 = ([𝑎𝑖𝑗] + [𝑏𝑖𝑗])

𝑡

= ([𝑎𝑖𝑗 + 𝑏𝑖𝑗])

𝑡

= [𝑎𝑗𝑖 + 𝑏𝑗𝑖] = [𝑎𝑗𝑖]

𝑡

𝑡
+ [𝑏𝑗𝑖]

= 𝐴𝑡 + 𝐵𝑡;  

𝑻𝟑: (𝐴𝐵)𝑡 = ([𝑎𝑖𝑗][𝑏𝑖𝑗])

𝑡

= ([∑

𝑛
𝑘=1

𝑎𝑖𝑘𝑏𝑘𝑗

])

𝑡

= [∑

𝑛
𝑘=1

𝑎𝑘𝑖𝑏𝑗𝑘

] = [∑

𝑛
𝑘=1

𝑏𝑗𝑘

𝑎𝑘𝑖] =

[𝑏𝑗𝑖][𝑎𝑗𝑖] = 𝐵𝑡𝐴𝑡;  

𝑻𝟒: (𝛼𝐴)𝑡 = (𝛼[𝑎𝑖𝑗])

𝑡

= ([𝛼𝑎𝑖𝑗])

𝑡

= [𝛼𝑎𝑗𝑖] = 𝛼[𝑎𝑗𝑖] = 𝛼𝐴𝑡.    

1.1.15. Definição: Dada uma matriz quadrada A de ordem  𝑛, dizemos que a matriz 𝐵 é a 

inversa da matriz 𝐴 se tivermos que  

𝐴𝐵 = 𝐵𝐴 = 𝐼𝑛. 

Nesse caso, denotamos por  𝐵 = 𝐴−1 a inversa de  𝐴. Claro que a ordem de  𝐵 é a 

mesma de 𝐴. Além disso, 𝐴 = 𝐵−1. 

Uma matriz é dita inversível quando admite inversa.  

1.1.16. Exemplo: Em particular, as matrizes  

𝐴 = [3 5
]
1 2

2×2

 e 𝐵 = [

2 −5
]
−1    3

2×2

são tais que 𝐴𝐵 = 𝐵𝐴 = [

1 0
]
0 1

2×2

; logo, a matriz 𝐵 é a inversa de 𝐴, e vice-versa.  

1.1.17. Proposição: A inversa de uma matriz, quando existir, é única. 

Demonstração: Suponha que 𝐴 seja uma matriz inversível e que 𝐵 é uma inversa de 𝐴, isto 

é,  𝐴𝐵 = 𝐵𝐴 = 𝐼𝑛.  Se  houver  uma  matriz  𝐶  para  a  qual  também  seja  válida  a  igualdade 

𝐴𝐶 = 𝐶𝐴 = 𝐼𝑛, então afirmarmos que 𝐶 = 𝐵.  

Realmente,  se  𝐴𝐶 = 𝐼𝑛  temos  𝐵𝐴𝐶 = 𝐵𝐼𝑛,  isso  implica  que  𝐶 = 𝐵.  Portanto,  a 

inversa de uma matriz, quando existe, é mesmo única. 

 
 
 
 
 
 
 
19 

Vejamos algumas propriedades ligadas à inversão de matrizes. 

1.1.18. Proposição: Consideremos 𝐴 e 𝐵 matrizes quadradas de ordem 1 ≤ 𝑛 ∈ ℕ. Temos 

que: 

𝑺: Se 𝐴 é inversível, então 𝐴−1 é também inversível e (𝐴−1)−1 = 𝐴; 
𝑺𝟐: Se 𝐴 e 𝐵 são inversíveis, então 𝐴𝐵 também é inversível e (𝐴𝐵)−1 = 𝐵−1𝐴−1;  
𝑺𝟑: Se 𝐴 é inversível, então 𝐴𝑡 também é inversível, e (𝐴𝑡)−1 = (𝐴−1)𝑡;  
Demonstração:  Ora,  𝐴−1  é  inversível  se  podemos  encontrar  uma  matriz  𝑋  para  a  qual 
𝐴−1𝑋 = 𝑋𝐴−1 = 𝐼𝑛. Porém, sendo 𝐴 inversível, temos que 𝐴−1𝐴 = 𝐴𝐴−1 = 𝐼𝑛; ou seja, 𝑋 =
𝐴. Como a inversa é única só resta que (𝐴−1)−1 = 𝐴. Portanto, vale 𝑆1.  

que 

Temos 

e 
(𝐵−1𝐴−1)(𝐴𝐵) = 𝐵−1(𝐴−1𝐴)𝐵 = 𝐵−1𝐼𝑛𝐵 = 𝐵−1𝐵 = 𝐼𝑛.  Isto  é,  𝐴𝐵  é  inversível  e,  como 
possui uma única inversa, concluímos que (𝐴𝐵)−1 = 𝐵−1𝐴−1 e vale 𝑆2. 

(𝐴𝐵)(𝐵−1𝐴−1) = 𝐴(𝐵𝐵−1)𝐴−1 = 𝐴𝐼𝑛𝐴−1 = 𝐴𝐴−1 = 𝐼 

Por  fim,  temos  que  𝐴𝐴−1 = 𝐴−1𝐴 = 𝐼𝑛,  o  que  implica  que  (𝐴𝐴−1)𝑡 = (𝐴−1𝐴)𝑡 =

𝑡 = 𝐼𝑛; isto é, (𝐴−1)𝑡𝐴𝑡 = 𝐴𝑡(𝐴−1)𝑡 = 𝐼𝑛. Portanto, (𝐴𝑡)−1 = (𝐴−1)𝑡 e vale 𝑆3. 
𝐼𝑛

1.1.19.  Definição:  Seja  𝐴  uma  matriz  quadrada  de  ordem  1 ≤ 𝑛 ∈ ℕ  dizemos  que  𝐴  é 

ortogonal se, e somente se, for satisfeita a seguinte condição: 

𝐴𝐴𝑡 = 𝐴𝑡𝐴 = 𝐼𝑛. 

1.1.20. Exemplo: As matrizes  [

𝑐𝑜𝑠𝜃 −𝑠𝑒𝑛𝜃
𝑠𝑒𝑛𝜃    𝑐𝑜𝑠𝜃

]

 e [

2×2

Vale que: 

𝑐𝑜𝑠𝜃 −𝑠𝑒𝑛𝜃 0
𝑠𝑒𝑛𝜃    𝑐𝑜𝑠𝜃 0
1

0

0

]

são ortogonais. 

3×3

𝑐𝑜𝑠𝜃 −𝑠𝑒𝑛𝜃
[
𝑠𝑒𝑛𝜃    𝑐𝑜𝑠𝜃

]
2×2

   𝑐𝑜𝑠𝜃 𝑠𝑒𝑛𝜃
[
−𝑠𝑒𝑛𝜃 𝑐𝑜𝑠𝜃

]
2×2

= [𝑐𝑜𝑠2𝜃 + 𝑠𝑒𝑛2𝜃
0

0
𝑐𝑜𝑠2𝜃 + 𝑠𝑒𝑛2𝜃

]

2×2

= [

1 0
]
0 1
2×2

. 

Na  referência  [6]  de  nossa  bibliografia,  o  autor,  na  página  254,  define  matrizes 

simétricas e matrizes ortogonais. Comenta ainda que as matrizes ortogonais formam um 

conjunto  de  matrizes  que  são  inversíveis  e,  que  a  relação  entre  matrizes  inversíveis, 

simétricas e ortogonais é indicada conforme o diagrama abaixo:   

 
 
 
 
 
 
 
 
 
𝕀𝑛(ℝ) 

𝒪(𝕄𝑛(ℝ)) 

𝕄𝑛(ℝ) 

𝕄𝕊𝑛(ℝ) 

20 

𝕄𝑛(ℝ): Matrizes 
𝕀𝑛(ℝ): Matrizes inversíveis 

𝒪(𝕄𝑛(ℝ)): Matrizes ortogonais 

𝕄𝕊𝑛(ℝ): Matrizes simétricas 

Observamos que a matriz [

3 −1
]
4
−1

2×2

 é simultaneamente simétrica e inversível, 

mas não é ortogonal. Enquanto que, a matriz [ √0,81

√0,9
]
−√0,9 √0,81

 é ortogonal e inversível, 

2×2

mas não é simétrica. 

Observação 1.1.21: O produto de matrizes ortogonais é uma matriz ortogonal.  

Demonstração: De fato, sejam 𝑀1 e 𝑀2 matrizes ortogonais 1 ≤ 𝑛 ∈ ℕ. Como já sabemos 

que 𝑀1𝑀1

𝑡 = 𝐼𝑛. Temos que, 
𝑡 = 𝑀2𝑀2
 (𝑀1 ∙ 𝑀2) ∙ (𝑀1 ∙ 𝑀2)𝑡 = 𝑀1 ∙ (𝑀2 ∙ 𝑀2

𝑡) ∙ 𝑀2 = 𝑀1 ∙ 𝐼 ∙ 𝑀2 = 𝑀1 ∙ 𝑀2 = 𝐼𝑛, 

o que mostra que 𝑀1𝑀2 é uma matriz ortogonal. 

1.2 O anel das matrizes quadradas de ordem 2 

A identificação de um número  complexo com uma matriz quadrada de ordem 2 

será  feita,  por  meio  de  isomorfismo  depois  de  descrevermos  a  estrutura  de  𝕄2(ℝ). 

Começamos com a seguinte 

1.2.1 Definição: Digamos que 𝐴 seja um conjunto não vazio, no qual estão definidas uma 

operação  de  adição  e  uma  operação  de  multiplicação.  Se,  além  disso,  para  quaisquer 

𝑎, 𝑏, 𝑐 ∈ 𝐴, valer que: 

𝑨𝟏: 𝑎 + (𝑏 + 𝑐) = (𝑎 + 𝑏) + 𝑐;  

𝑨𝟐: 𝑎 + 𝑏 = 𝑏 + 𝑎;  

𝑨𝟑: existe 0 ∈ A tal que 0 + 𝑎 = 𝑎 + 0 = 𝑎;  
𝑨𝟒: existe − 𝑎 = (−1)𝑎 ∈ 𝐴 tal que 𝑎 + (−𝑎) = −𝑎 + 𝑎 = 0; 
𝑨𝟓: 𝑎 ∙ (𝑏 ∙ 𝑐) = (𝑎 ∙ 𝑏) ∙ 𝑐;   
𝑨𝟔: 𝑎 ∙ (𝑏 + 𝑐) = 𝑎 ∙ 𝑏 + 𝑎 ∙ 𝑐; (𝑏 + 𝑐) ∙ 𝑎 = 𝑏 ∙ 𝑎 + 𝑐 ∙ 𝑎,    

diremos que (𝐴, +,∙) é um anel. 

 
 
 
 
 
 
 
 
 
 
 
 
21 

1.2.2. Definição: Se (𝐴, +,∙) é um anel e para quaisquer 𝑎, 𝑏 ∈ 𝐴, valer que 𝑎𝑏 = 𝑏𝑎 dizemos 

que (𝐴, +,∙) é um anel comutativo. 

1.2.3. Definição: Se (𝐴, +,∙) é um anel e existir 1 ∈ 𝐴 tal que 1 ∙ 𝑎 = 𝑎 ∙ 1 = 𝑎, dizemos que 

(𝐴, +,∙) é um anel com unidade. 

1.2.4. Definição: Se (𝐴, +,∙) é um anel comutativo com unidade e para quaisquer 𝑎, 𝑏 ∈ 𝐴, 

com 𝑎 ∙ 𝑏 = 0, implicar que 𝑎 = 0 ou 𝑏 = 0, diremos que (𝐴, +,∙) é um domínio (ou anel) 

de integridade, o que significa dizer que não existem divisores de zero no anel (𝐴, +,∙). 

1.2.5.  Definição:  Se (𝐴, +,∙)  é  um  domínio  de  integridade  e  para  todo  𝑎 ≠ 0 ∈ 𝐴,  existir 

𝑎−1 ∈ 𝐴 tal que 𝑎 ∙ 𝑎−1 =  𝑎−1 ∙ 𝑎 = 1, dizemos que (𝐴, +,∙) é um corpo. 

1.2.6. Exemplo: Seja 𝐷 ≠ {0} um domínio de integridade. Então, se a função 

𝛹: 𝐷
                         𝑥

→        𝐷
↦        𝛹(𝑥) = 𝑎𝑥,

para todo 𝑎 ∈ 𝐷\{0}, for sobrejetiva, 𝐷 é um corpo. 

Realmente, para todo elemento 𝑎 ≠ 0 em 𝐷, definindo 𝛹 como acima, o fato dela 

ser sobrejetiva garante que, para a identidade 1 em 𝐷 = 𝐶𝐷(𝛹), existe 𝑏 ∈ 𝐷 = 𝐷(𝛹)  tal 

que 𝛹(𝑏) = 1;  ou  seja,  𝑎 ∙ 𝑏 = 1  e  𝑎 é  inversível.  Portanto,  pela  generalidade  de  𝑎, 

concluímos que 𝐷 é um corpo. 

1.2.7. Exemplos: Consoante às definições vistas nesta unidade, podemos perceber que o 

conjunto das matrizes quadradas de ordem 2, 

𝕄2(ℝ) = {[

𝑎 𝑏
𝑐 𝑑

] : 𝑎, 𝑏, 𝑐, 𝑑 ∈ ℝ} 

é um anel não comutativo, com unidade e que admite divisores de zero. 

De  fato,  [

1    1
]
2 −1

  e  [

1 1
]
1 1

2×2

  são  elementos  em  𝕄2(ℝ)  e  temos  que 

[

1    1
]
2 −1

2×2

∙   [

1 1
]
1 1

2×2

= [

2 2
1 1

]

2×2

= [

1 1
1 1

]

2×2

∙ [

1    1
]
2 −1

. 

2×2

2×2

2×2
3 0
]
3 0

≠ [

A  matriz  𝐼2 = [

1 0
]
0 1

2×2

é  a  unidade  de  𝕄2(ℝ),  pois  para  uma  matriz    𝑀 =

[

𝑎 𝑏
𝑐 𝑑

]

2×2

 qualquer em 𝕄2(ℝ), vale que 𝐼2 ∙ 𝑀 = 𝑀 ∙ 𝐼2 = 𝑀.  

 
 
 
 
 
                       
                       
 
 
Ademais, se 𝑏 e 𝑏′ são dois números reais quaisquer, as matrizes 𝐵 = [

𝐵′ = [

0
0
0  𝑏′

]

2×2

 são tais que 𝐵 ∙ 𝐵′ = [

0 0
0 0

]

. 

2×2

22 

0 0
]
𝑏 0

 e 

2×2

1.2.8. Observação: Se 𝐴 é um anel, para todo 𝑎 ∈ 𝐴, vale que 0 ∙ 𝑎  =  0  =  𝑎 ∙ 0. 

Demonstração: Usando a propriedade  𝐴3 da definição em 1.2.1 e escrevendo 0 = 0 + 0, 

temos 

as 

seguintes 

equivalências: 

𝑎 ∙ 0 = 𝑎 ∙ (0 + 0)

𝐴6
⇔ 𝑎  ∙ 0 = 𝑎 ∙ 0 + 𝑎 ∙ 0

𝐴4
⇔ (−𝑎) ∙ 0 + 𝑎 ∙ 0 = (−𝑎) ∙ 0 + (𝑎 ∙ 0 + 𝑎 ∙ 0)

𝐴1, 𝐴4
⇔    0 = ((−𝑎) ∙ 0 + 𝑎 ∙ 0) + 𝑎 ∙ 0   ⟺ 0 =

0 + 𝑎 ∙ 0. Usando a propriedade 𝐴3, da definição em 1.2.1, concluímos que 𝑎 ∙ 0 = 0. 

1.2.9.  Observação:  Em  um  anel  comutativo  com  unidade,  a  existência  de  inverso 

multiplicativo implica na não existência de divisores de zero. 

Demonstração: Considere 𝐴 um anel comutativo com unidade e 𝑎, 𝑏 ∈ A com 𝑎 ∙ 𝑏  =  0. 

Suponhamos que 𝑎 ≠ 0. Por hipótese, existe 𝑎−1 ∈ 𝐴 tal que 𝑎−1 ∙ 𝑎 = 1. Daí, vemos que 

𝑎 ∙ 𝑏 = 0 ⟺ 𝑎−1(𝑎𝑏) = 𝑎−1 ∙ 0 ⟺ (𝑎−1 ∙ 𝑎)𝑏 = 0 ⟺  1 ∙ 𝑏 = 0 ⟺ 𝑏 = 0. 

Analogamente, suponhamos que 𝑏 ≠ 0. Como, por hipótese, existe 𝑏−1 em 𝐴 tal que 

𝑏−1 ∙ 𝑏 = 1,  vale  que  𝑎𝑏 = 0 ⟺ (𝑎𝑏)𝑏−1 = 0 ∙ 𝑎−1 ⟺ 𝑎(𝑏𝑏−1) = 0 ⟺ 𝑎 ∙ 1 = 0 ⟺ 𝑎 =

0. 

1.2.10. Observação: Em um domínio de integridade, a equação 𝑥2 = 𝑥  tem como únicas 

soluções 0 e 1. 

Demonstração: De fato, 𝑥2 = 𝑥 ⟺ 𝑥2 − 𝑥 = 0 ⟺ 𝑥 ∙ (𝑥  − 1) = 0. Como em um domínio 

de integridade não existem divisores de zero, só nos resta a conclusão de que 𝑥 = 0 ou 

𝑥 − 1 = 0 ⟺ 𝑥 = 1. 

A  próxima  observação  que  faremos  toca  diretamente  na  “regra  dos  sinais”  da 

adição e multiplicação de números inteiros; já que ℤ possui a estrutura de um anel. 

1.2.11. Observação: Sejam 𝐴 um anel com unidade e 𝑥 e, 𝑦 elementos em 𝐴. Então, valem: 

a) (−1) ∙ 𝑥 = −𝑥; 

b) −(−𝑥)   = 𝑥; 

c) (−𝑥) ∙ 𝑦 = 𝑥 ∙ (−𝑦) = −𝑥𝑦; 

 
 
 
 
 
 
23 

d) (−𝑥) ∙ (−𝑦) = 𝑥𝑦. 

Demonstração:  a)  Veja  𝑥 +   (−1) ∙  𝑥 =  1 ∙ 𝑥  +   (−1) ∙ 𝑥  =   [1 + (−1)] ∙ 𝑥  =  0 ∙ 𝑥  =  0 

concluímos que (−1) ∙ 𝑥  =   −𝑥; 

b) Temos que −(−𝑥) é o inverso aditivo do inverso aditivo de 𝑥. Como pelo item a) vale a 

igualdade    𝑥 +   (−𝑥) = 𝑥 + (−1) ∙ 𝑥,  podemos  perceber  que  também  é  verdadeira  a 

igualdade 1 ∙ 𝑥 + (−1) ∙ 𝑥 =   [1 +   (−1)] ∙ 𝑥  =  0 ∙ 𝑥  =  0. Isso mostra que 𝑥 = −(−𝑥); 

c)  Ora,  (−𝑥) ∙ 𝑦 = [(−1) ∙ 𝑥] ∙ 𝑦 = (−1) ∙ (𝑥 ∙ 𝑦).  De  a)  vem  que  (−𝑥) ∙ 𝑦 = −𝑥 ∙ 𝑦.  De 

maneira semelhante, obtemos que 𝑥 ∙ (−𝑦) = −𝑥 ∙ 𝑦; 

d)  Vejamos  que  (−𝑥) ∙ (−𝑦) = [(−1) ∙ 𝑥] ∙ [(−1) ∙ 𝑦] = (−1) ∙ 𝑥 ∙ (−1) ∙ 𝑦.  Assim,  por 

termos da multiplicação ser comutativa, vemos que:  (−𝑥) ∙ (−𝑦) = (−1) ∙ (−1) ∙ 𝑥 ∙ 𝑦 =

(−1) ∙ [(−1) ∙ 𝑥 ∙ 𝑦] = (−1) ∙ [(−1)(𝑥 ∙ 𝑦)]   = (−1) ∙ (−𝑥 ∙ 𝑦) = −(−𝑥 ∙ 𝑦) = 𝑥 ∙ 𝑦. E essas 

últimas igualdades decorrem de a) e b). 

1.2.12. Definição: Sejam 𝐴 um anel e 𝐵 um subconjunto de 𝐴. Dizemos que 𝐵 é um subanel 

de 𝐴 se, e somente se, 𝐵 é um anel com respeito às operações de adição e multiplicação 

definidas em 𝐴. 

1.2.13. Exemplo: O conjunto dos múltiplos de 3, 3ℤ =   {… , −6, −3, 0, 3, 6, … } é um subanel 

de ℤ. Enquanto que ℚ é um subanel de ℝ. 

Claro que  3ℤ não possui  unidade e  ℚ, na  verdade, é mais do que  um anel, é um 

subcorpo de ℝ. 

1.2.14. Observação (Caracterização de um subanel): Seja 𝐴 um anel. Então, 𝐵 é um subanel 

de A se, e somente se, as seguintes condições são verificadas: 

𝑎) 0 ∈ 𝐵 (o elemento neutro de 𝐴 pertence 𝐵); 

𝑏) 𝑥 − 𝑦  ∈ 𝐵, para todo 𝑥, 𝑦 ∈ 𝐵; 

𝑐) 𝑥 ∙ 𝑦  ∈ 𝐵, para todo 𝑥, 𝑦 ∈ 𝐵. 

Demonstração: Ver referência [3]; página 43. 

1.2.15.  Exemplo:  Considere  o  subconjunto  𝒞 =   {[

𝑥
𝑦
−𝑦 𝑥]

2×2

/ 𝑥, 𝑦 ∈ ℝ}  do  anel 

(𝕄2(ℝ), +, ·). 

Temos que 𝑂 = [

0 0
]
0 0

2×2

∈ 𝒞. 

 
 
 
 
 
 
24 

Além  disso,  para  𝑋 = [

𝑎
𝑏
−𝑏 𝑎

]

 e   𝑌 =   [

2×2

𝑑
𝑐
−𝑑 𝑐

]

2×2

 em 𝒞,  vale  que  𝑋 − 𝑌 =

 [

𝑎 − 𝑐

𝑏 − 𝑑
−(𝑏 − 𝑑) 𝑎 − 𝑐

]

2×2

 e 𝑋 ∙ 𝑌 =   [

𝑎𝑐 − 𝑏𝑑

𝑎𝑑 + 𝑏𝑐
−(𝑏𝑐 + 𝑎𝑑) 𝑎𝑐 − 𝑏𝑑

]

2×2

 pertencem a 𝒞. Portanto, 𝒞 é 

um subanel de (𝕄2(ℝ), +,∙). 

Esse  conjunto  𝒞  será  muito  importante  para  as  definições  que  pretendemos 

estabelecer. No final, mostraremos que ele é, na verdade, uma cópia do conjunto  ℂ dos 

números complexos que descrevemos a seguir.  

1.3 O corpo dos números complexos 

Os  números  complexos,  historicamente,  existem  por  duas  razões  principais,  a 

saber:  uma  de  natureza  algébrica  com  a  resolução  da  equação  𝑥2 + 1 = 0,  quando  na 

Europa  discutia-se  as  “soluções  impossíveis”  de  uma  equação  em  torno  dos  números 

negativos e irracionais. Outra, com o desejo de criar um análogo aritmético do conceito de 

vetor, que surgiu dentro da Geometria e da Física, onde os números complexos aparecem 

como candidatos perfeitos para representar e permitir operar com vetores no plano.  

Em ℂ = {𝑧 = 𝑥 + 𝑦𝑖; 𝑥, 𝑦 ∈ ℝ e 𝑖 = √−1, onde 𝑖2 = −1}, estão bem definidas uma 

operação de adição e uma operação de multiplicação. Para todos 𝑧 = 𝑎 + 𝑏𝑖 e ℎ = 𝑐 + 𝑑𝑖; 

definimos: 

(+): 𝑧 + ℎ = (𝑎 + 𝑏𝑖) + (𝑐 + 𝑑𝑖) = (𝑎 + 𝑐) + (𝑏 + 𝑑)𝑖 ∈ ℂ; 

( ∙ ): 𝑧 ∙ ℎ = (𝑎 + 𝑏𝑖) ∙ (𝑐 + 𝑑𝑖) = 𝑎𝑐 − 𝑏𝑑 + (𝑎𝑑 + 𝑏𝑐)𝑖 ∈ ℂ. 

Claro que ℝ ⊂ ℂ, já que para todo 𝑟 ∈ ℝ, podemos escrever 𝑟 = 𝑟 + 0𝑖. 

1.3.1 Observação: Para essas operações de adição e multiplicação definidas em ℂ, valem 

as seguintes propriedades, para todo 𝑧1, 𝑧2, 𝑧3 ∈ ℂ: 
𝑨𝟏: 𝑧1 + (𝑧2 + 𝑧3) = (𝑧1 + 𝑧2) + 𝑧3  (associativa da adição);    

𝑨𝟐: 𝑧1 + 𝑧2 = 𝑧2 + 𝑧1  (comutativa da adição);   

𝑨𝟑: existe 0 = 0 + 0𝑖 ∈ ℂ,  tal que 0 + 𝑧1 = 𝑧1 + 0 = 𝑧1  (existência de elemento neutro da 

adição);   

𝑨𝟒: para 𝑧1 = 𝑎 + 𝑏𝑖, ∃   − 𝑧1 = −𝑎 + (−𝑏)𝑖 ∈ ℂ  em  que 

𝑧1 + (−𝑧1) = −𝑧1 + 𝑧1 = 0 

(existência de inverso aditivo); 

 
 
 
 
 
25 

𝑴𝟏: 𝑧1 ∙ (𝑧2 ∙ 𝑧3) = (𝑧1 ∙ 𝑧2) ∙ 𝑧3  (associativa da multiplicação);   

𝑴𝟐: 𝑧1 ∙ 𝑧2 = 𝑧2 ∙ 𝑧1  (comutativa da multiplicação);   

𝑴𝟑: existe 1 = 1 + 0𝑖 ∈ ℂ,  tal  que  1 ∙ 𝑧1 = 𝑧1 ∙ 1 = 𝑧1  (existência  de  elemento  neutro  da 

multiplicação);    
𝑴𝟒: para todo 𝑧 ∈ ℂ  com  𝑧 ≠ 0, existe 𝑧−1 ∈ ℂ   tal  que  𝑧 ∙ 𝑧−1 = 𝑧−1 ∙ 𝑧 = 1    (existência 
de inverso multiplicativo); 

𝑫: 𝑧1 ∙ (𝑧2 + 𝑧3) = 𝑧1 ∙ 𝑧2 + 𝑧1 ∙ 𝑧3 = 𝑧2 ∙ 𝑧1 + 𝑧3 ∙ 𝑧1 = (𝑧2 + 𝑧3) ∙ 𝑧1  (distributividade  da 

multiplicação em relação à adição); 

𝑪: Se 𝑧1 ∙ 𝑧2 = 0, então 𝑧1 = 0 ou 𝑧2 = 0 (em ℂ não existem divisores de zero).     

Demonstração:  A  propriedade  𝑀4  será  provada  em  frente  na  observação  1.3.3. 

Provaremos, aqui, somente a validade da propriedade 𝐶: admitindo a validade de 𝑀4, se 
−1 ∈ ℂ, tal que 𝑧 ∙ 𝑧−1 = 𝑧−1 ∙ 𝑧 = 1. Daí, temos 𝑧1 ∙

 𝑧1 ∙ 𝑧2 = 0 e 𝑧1 ≠ 0, temos que existe 𝑧1

𝑧2 = 0 ⟺ 𝑧1

−1 ∙ (𝑧1 ∙ 𝑧2) = 𝑧1

−1 ∙ 0

𝑀1
⇔ (𝑧1

−1 ∙ 𝑧1) ∙ 𝑧2 = 0 ⟺ 1 ∙ 𝑧2 = 0 ⟺ 𝑧2 = 0.   

Analogamente, se 𝑧2 ≠ 0, podemos concluir que 𝑧1 = 0, o que completa a prova da 

validade de 𝐶. 

1.3.2. Definição: Sejam 𝑧1 = 𝑎 + 𝑏𝑖 e 𝑧2 = 𝑐 + 𝑑𝑖 elementos em ℂ. Então: 

a) dizemos que o número complexo 𝑖 = 0 + 𝑖 é a unidade imaginária; 

b) os números reais 𝑎 = Re(z1) e  𝑏 = Im(z1) são, respectivamente, a parte real e a parte 

imaginaria  do  número  complexo  𝑧1.  A  parte  imaginária  é  a  que  acompanha  a  unidade 

imaginária 𝑖; 

c) definimos 𝑧1̅ = 𝑎 − 𝑏𝑖 como sendo o conjugado do número complexo 𝑧1; 

d) Diremos que os números complexos 𝑧1 e 𝑧2 são iguais, se e somente se, tivermos que 
Re(𝑧1) = Re(𝑧2) e  Im(𝑧1) = Im(𝑧2). 

1.3.3. Observação: Seja 0 ≠ 𝑧 = 𝑎 + 𝑏𝑖 ∈ ℂ. Então 𝑧−1 = 

𝑧̅
𝑎2+𝑏2 =

𝑎

𝑎2+𝑏2 −

𝑏

𝑎2+𝑏2 𝑖 é o inverso 

multiplicativo de 𝑧. 

Demonstração: Seja 𝑧−1 = 𝑥 + 𝑦𝑖. Então, vale  a condição  𝑧−1 ∙ 𝑧 = 1 = 1 + 0𝑖. Usando a 

definição de multiplicação em ℂ, obtemos 

𝑧−1 ∙ 𝑧 = (𝑥 + 𝑦𝑖) ∙ (𝑎 + 𝑏𝑖) =   (𝑎𝑥 − 𝑏𝑦) + (𝑏𝑥 + 𝑎𝑦)𝑖 = 1 = 1 + 0𝑖. 

 
 
 
26 

Pela igualdade definida no item d) de 1.3.2, vem que {

 é um sistema linear nas 

𝑎𝑥 − 𝑏𝑦 = 1
𝑏𝑥 + 𝑎𝑦 = 0

variáveis 𝑥 e 𝑦. Esse sistema é equivalente ao sistema  {

𝑎2𝑥 − 𝑎𝑏𝑦 = 𝑎
𝑏2𝑥 + 𝑏𝑎𝑦 = 0

. Somando essas 

equações, obtemos (𝑎2 + 𝑏2)𝑥 = 𝑎 ⇔ 𝑥 =

𝑎

𝑎2+𝑏2. Substituindo esse valor na 2ª equação, 

vemos que 

𝑏2𝑎
𝑎2+𝑏2 + 𝑏𝑎𝑦 = 0 ⇔ 𝑦 = −
inverso multiplicativo de 𝑧 = 𝑎 + 𝑏𝑖. 

𝑏2𝑎
𝑎2+𝑏2

1

𝑏𝑎

=

−𝑏

𝑎2+𝑏2. Portanto, vale que, 𝑧−1 = 

𝑎2+𝑏2 é o 

𝑧̅

1.3.4. Exemplo: O inverso do número complexo 𝑤  =  4 − 7𝑖 é igual 𝑤−1 =

4

65

+

7

65

𝑖. 

1.4 Isomorfismos - cópias do corpo dos números complexos  

Nesta  seção  vamos  apresentar  versões  concretas  dos  números  complexos.  Uma 

como um par de números reais, outra como uma matriz de ordem 2. Antes definiremos as 

funções especiais que permitem que façamos essas identificação. 

1.4.1.  Definição:  Uma  função  𝑓 de  𝑋 em  𝑌  é  uma  lei  que  associa  a  cada  elemento  do 

conjunto 𝑋 um elemento do conjunto 𝑌. Comumente, escrevemos 

𝑓: 𝑋
           𝑥

→        𝑌
↦        𝑓(𝑥)

para  denotar  uma  função  de  𝑋  em  𝑌.  Também  é  comum  chamar  uma  função  de 

transformação ou aplicação. 

Na  definição  acima  𝑋  =  𝐷(𝑓)  é  o domínio  e  𝑌  =  𝐶𝐷(𝑓)  é  o contradomínio  da 

função 𝑓. Por 𝐼𝑚(𝑓)   =  𝑓(𝑋)   =   {𝑓(𝑥): 𝑥 ∈ 𝑋} denotamos o conjunto imagem da função 

𝑓, formado pelas transformadas de 𝑓. 

Algumas funções recebem nomes especiais devido a forma como atuam nos seus 

domínios. Vejamos isso na seguinte 

1.4.2. Definição: Seja 𝑓 uma função de 𝑋 em 𝑌. 

a) Dizemos que 𝑓 é sobrejetiva se, e somente se, 𝑓(𝑋)   =  𝐶𝐷(𝑓)   =  𝑌. 

b) Dizemos que 𝑓 é injetiva se, e somente se, 𝑓(𝑥)   ≠  𝑓(𝑦), sempre que 𝑥, 𝑦 ∈ 𝑋 e 𝑥  ≠  𝑦 

se, e somente se, sempre que 𝑓(𝑥)   =  𝑓(𝑦) para 𝑥, 𝑦 ∈  𝑋 temos 𝑥  =  𝑦. 

 
 
 
 
                       
                       
 
    
 
27 

c) Se 𝑔 é uma função de 𝑍 em 𝑊, dizemos que 𝑓 é igual a 𝑔 se, e somente se, temos que 

𝑋  =  𝑍, 𝑌  =  𝑊 e 𝑓(𝑥)   =  𝑔(𝑥), para todo 𝑥 ∈ 𝑋  =  𝑍. 

d) Dizemos que 𝑓 é bijetiva se, e somente se, for injetiva e sobrejetiva.  

e) Se 𝐴 ⊂ 𝑋, a função 

               𝑓/𝐴: 𝐴
                                                   𝑎

→        𝑌
↦        𝑓/𝐴(𝑎) = 𝑓(𝑎),

é denominada de função restrição de 𝑓 ao subconjunto 𝐴 de 𝑋. 

1.4.3. Exemplo: A função 

                                𝑓: ℕ
                                                     𝑛

→        2ℕ
↦        𝑓(𝑛) = 2𝑛,

que associa a cada número natural o seu dobro, é bijetiva.  

1.4.4. Definição: Sejam 𝑋 e 𝑌 conjuntos não vazios. Suponha que ∗ é uma operação bem 

definida em 𝑋 e □ é uma operação bem definida em 𝑌. Uma função 

𝜑: 𝑋
              𝑥

→        𝑌
↦        𝜑(𝑥),

é  dita  um homomorfismo  se,  e  somente  se,  para  todo 𝑎, 𝑏 ∈ 𝑋  ,  valer  que    𝜑(𝑎 ∗ 𝑏) =

𝜑(𝑎)□𝜑(𝑏). 

Um  homomorfismo  injetivo  é  denominado monomorfismo.  Se  for  sobrejetivo  é 

denominado epimorfismo. Se for bijetivo é denominado isomorfismo. 

É fácil ver que, se 𝜑 é um isomorfismo de 𝑋 em 𝑌, então 𝜑−1 é um isomorfismo de 

𝑌 em 𝑋. 

1.4.5. Observação: Se 𝜑 é um isomorfismo de 𝑋 em 𝑌, valem as seguintes propriedades: 

a) Se 𝑒 é o elemento neutro para uma operação ∗ definida em 𝑋, 𝑒’ o elemento neutro para 

uma operação □ definida em 𝑌 e, em 𝑌, valem as leis do cancelamento para essa operação, 

então, 𝜑(𝑒) = 𝑒’. 

b) Se 𝑥−1 é o inverso de um elemento 𝑥 em 𝑋, então 𝜑(𝑥−1) = 𝜑(𝑥)−1. 

Demonstração: Primeiramente, temos que 𝑒  ∗  𝑒  =  𝑒. Daí vale que  

𝑒’□𝜑(𝑒) = 𝜑(𝑒) = 𝜑(𝑒  ∗  𝑒) = 𝜑(𝑒)□𝜑(𝑒); 

já  que  𝜑  é  um  homomorfismo.  Cancelando  𝜑(𝑒)  em  ambos  os  membros  da  igualdade, 

vemos que  𝜑(𝑒) = 𝑒’. 

 
                       
                       
 
 
                       
                       
 
 
                       
                       
 
 
 
28 

Agora,  de  𝑥  ∗   𝑥−1 =  𝑒,  obtemos  𝜑(𝑥 ∗  𝑥−1) = 𝜑(𝑒).  Como  𝜑  é  um 

homomorfismo,  conforme  o  que  provamos  anteriormente,  𝜑(𝑒) = 𝑒’,  vem  que 

𝜑(𝑥)□𝜑(𝑥−1 ) = 𝑒’. Isso mostra que 𝜑(𝑥−1) = 𝜑(𝑥)−1. 

1.4.6.  Definição:  Consideremos  o  conjunto  ℝ2 = ℝ × ℝ =   {(𝑎, 𝑏) /𝑎, 𝑏 ∈ ℝ}.  Podemos 

definir as seguintes operações de adição e multiplicação para todo (𝑎, 𝑏), (𝑐, 𝑑) ∈ ℝ2: 

(+): (𝑎, 𝑏) + (𝑐, 𝑑) = (𝑎 + 𝑐, 𝑏 + 𝑑)  

( ⋅ ): (𝑎, 𝑏) ∙ (𝑐, 𝑑) = (𝑎 ∙ 𝑐 − 𝑏 ∙ 𝑑, 𝑎 ∙ 𝑑 + 𝑏 ∙ 𝑐).     

Valem as mesmas propriedades da  adição e da multiplicação, 𝐴1, 𝐴2, 𝐴3, 𝐴4, 𝑀1, 
𝑀2, 𝑀3, 𝑀4, 𝐷 𝑒 𝐶, exibidas em 1.3.1, com (1, 0) sendo o elemento neutro da multiplicação. 

Além  disso,  podemos  identificar  cada  número  complexo  com  um  único  par 

ordenado de ℝ × ℝ = ℝ2, como mostra a observação seguinte.  

1.4.7. Observação: A aplicação 

𝛿: ℂ
                          𝑧 = 𝑎 + 𝑏𝑖

→                 ℝ2

↦        𝛿(𝑧) = (𝑎, 𝑏),

é um isomorfismo; isto é, ℂ ≅ ℝ2. 

Demonstração: De fato, sejam  𝑧1 = 𝑝 + 𝑞𝑖 e  𝑧2 = 𝑟 + 𝑠𝑖 dois número complexos. Para a 
adição  e  a  multiplicação  definidas  na  observação  em  1.4.6,  temos  que  𝛿(𝑧1 + 𝑧2) =

𝛿((𝑝 + 𝑞𝑖)   +   (𝑟 + 𝑠𝑖))   =  𝛿((𝑝 + 𝑟)   +   (𝑞 + 𝑠)𝑖)   =   (𝑝 + 𝑟, 𝑞 + 𝑠)   =   (𝑝, 𝑞)   +   (𝑟, 𝑠) =

𝛿(𝑧1) + 𝛿(𝑧2) 

e 

𝛿(𝑧1 ∙ 𝑧2)   =  𝛿((𝑝 + 𝑞𝑖) ∙ (𝑟 + 𝑠𝑖))   =  𝛿((𝑝𝑟 − 𝑞𝑠) + (𝑝𝑠 + 𝑞𝑟)𝑖) =

(𝑝𝑟 − 𝑞𝑠, 𝑝𝑠 + 𝑞𝑟) = (𝑝, 𝑞) ∙ (𝑟, 𝑠) = 𝛿(𝑧1) ∙ 𝛿(𝑧2).  Mais  do  que  isso,  vemos  que  a 
igualdade 𝛿(𝑝 + 𝑞𝑖) = 𝛿(𝑟 + 𝑠𝑖) implica em (𝑝, 𝑞) = (𝑟, 𝑠); isto é, 𝑝 = 𝑟 e 𝑞 = 𝑠. Logo, 𝛿 é 

injetiva.  Agora,  para  todo  par  (𝑡, 𝑢) ∈ ℝ2  temos  que  existe  𝑧 = 𝑡 + 𝑢𝑖 ∈ ℂ  tal  que 

𝛿(𝑡 + 𝑢𝑖) = (𝑡, 𝑢),  ou  seja,  𝛿  é  sobrejetiva.  Portanto,  𝛿  é  bijetiva;  logo,  ℂ e ℝ2  são 

isomorfos. 

1.4.8.  Definição:  Sejam  𝑧 = 𝑎 + 𝑏𝑖  um  número  complexo  não  nulo  e  o  par  (𝑎, 𝑏)  que  o 

representa no plano, conforme a correspondência estabelecida em 1.4.7. 

 Usando  o  triângulo  retângulo  da  figura  da  página  a  seguir  temos  as  relações: 

 
 
 
                                                 
                       
 
 
 
 
 
 
 
29 

𝑥 

1) 𝑎 = 𝑟𝑐𝑜𝑠𝜃;  

2) 𝑏 = 𝑟𝑠𝑒𝑛𝜃,                                                                                                    

𝑦 

e de 1 e 2, temos:                                                                                           

a 

3) (𝑎, 𝑏) = (𝑟𝑐𝑜𝑠𝜃, 𝑟𝑠𝑒𝑛𝜃).     

4) 𝑧 = 𝑎 + 𝑏𝑖 = 𝑟𝑐𝑜𝑠𝜃 + 𝑖𝑟𝑠𝑒𝑛𝜃 = 𝑟(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃).                                                       

𝑏 

𝑟 
𝜃 
𝑎 

Nesse  caso, 𝑟 = |𝑧| = √𝑎2 + 𝑏2  significa,  na 

norma euclidiana, a distância do ponto 𝑃 = (𝑎, 𝑏) ao 

ponto  𝑂 = (0, 0),  obtida  através  do  teorema  de 

Pitágoras, e θ é o ângulo que o segmento 𝑂𝑃 faz com 

o  eixo  horizontal  do  plano  cartesiano,  no  sentido 

anti-horário. 

Considerando essas relações, definimos que:  

(1): 𝑧 = |𝑧|(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃) é a representação polar do número complexo 𝑧.  

(2): O ângulo  θ, considerado no intervalo  0 ≤ θ < 2π, é  denominado de argumento do 

número complexo 𝑧, comumente denotado por arg(𝑧).  

Olhando sobre o círculo trigonométrico, vemos que  arg(𝑧) = arg(𝑧) + 2𝑘π, para 

todo 𝑘 ∈ ℤ. 

1.4.9.  Observação:  Sejam  𝑧 = |𝑧|(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃)  e  𝑤 = |𝑤|(𝑐𝑜𝑠𝛾 + 𝑖𝑠𝑒𝑛𝛾)  dois  números 

complexos  na  forma  polar.  Então,  a  representação  polar  do  número  𝑧𝑤  é  dada  pela 

fórmula 𝑧𝑤 = |𝑧||𝑤|(𝑐𝑜𝑠 (𝜃 + 𝛾) + 𝑖𝑠𝑒𝑛(𝜃 + 𝛾)).     

Demonstração:  De  fato,  temos  que  𝑧𝑤  =   (|𝑧|(𝑐𝑜𝑠𝜃  +  𝑖𝑠𝑒𝑛𝜃))(|𝑤|(𝑐𝑜𝑠𝛾 + 𝑖𝑠𝑒𝑛𝛾)) =

|𝑧||𝑤|(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃)(𝑐𝑜𝑠𝛾 + 𝑖𝑠𝑒𝑛𝛾).  Como  esse 

resultado  equivale  a 

igualdade: 

|𝑧||𝑤|(𝑐𝑜𝑠𝜃𝑐𝑜𝑠𝛾  −  𝑠𝑒𝑛𝜃𝑠𝑒𝑛𝛾  +  𝑖(𝑐𝑜𝑠𝜃𝑠𝑒𝑛𝛾  +  𝑠𝑒𝑛𝜃𝑐𝑜𝑠𝛾)),  concluímos  facilmente  que 

|𝑧||𝑤|(cos(𝜃  +  𝛾)   + 𝑖𝑠𝑒𝑛(𝜃 + 𝛾)). 

Mais geral é o conhecido 

1.4.10.  Lema  de  De  Moivre:  Consideremos  o  número  complexo  𝑧 = |𝑧|(𝑐𝑜𝑠 𝜃 + 𝑖𝑠𝑒𝑛 𝜃). 

Então, para todo inteiro positivo 𝑛, vale que  

𝑧𝑛 = |𝑧|𝑛(cos(𝑛𝜃) + 𝑖𝑠𝑒𝑛(𝑛𝜃)) 

Demonstração: Vamos usar indução sobre o inteiro 𝑛. 

 
 
 
 
                  
30 

É claro que se 𝑛  =  0 ou 𝑛  =  1, não há nada a ser mostrado. Se 𝑛  =  2, é o caso 

mostrado na observação em 1.4.9. 

Agora,  vamos  supor  que  𝑧𝑘 = |𝑧|𝑘(𝑐𝑜𝑠 𝑘𝜃 + 𝑖𝑠𝑒𝑛 𝑘𝜃);  para  todo  2  <  𝑘 ∈ ℕ. 

Provaremos com isso que, 𝑧𝑘+1 = |𝑧|𝑘+1(𝑐𝑜𝑠 (𝑘 + 1)𝜃 + 𝑖𝑠𝑒𝑛 (𝑘 + 1)𝜃). 

Realmente, temos que 𝑧𝑘+1 = 𝑧 ∙ 𝑧𝑘 = (|𝑧|(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃))(|𝑧|𝑘(𝑐𝑜𝑠𝑘𝜃 + 𝑖𝑠𝑒𝑛𝑘𝜃)) =

|𝑧||𝑧|𝑘(𝑐𝑜𝑠𝜃 + 𝑖𝑠𝑒𝑛𝜃)(𝑐𝑜𝑠𝑘𝜃 + 𝑖𝑠𝑒𝑛𝑘𝜃).  Por  sua  vez,  essa  igualdade  nos  conduz  a 

|𝑧||𝑧|𝑘(𝑐𝑜𝑠𝜃𝑐𝑜𝑠𝑘𝜃 − 𝑠𝑒𝑛𝜃𝑠𝑒𝑛𝑘𝜃) + 𝑖(𝑐𝑜𝑠𝜃𝑠𝑒𝑛𝑘𝜃 + 𝑠𝑒𝑛𝜃𝑐𝑜𝑠𝑘𝜃),  que  nada  mais  é  do  que 

|𝑧|𝑘+1(𝑐𝑜𝑠(𝜃 + 𝑘𝜃) + 𝑖𝑠𝑒𝑛(𝜃 + 𝑘𝜃) = | 𝑧|𝑘+1(𝑐𝑜𝑠(𝑘 + 1) 𝜃 + 𝑖𝑠𝑒𝑛(𝑘 + 1)𝜃). 

Portanto, 

podemos concluir a veracidade de que 𝑧𝑛 = |𝑧|𝑛(cos(𝑛𝜃) + 𝑖𝑠𝑒𝑛(𝑛𝜃)), para todo 𝑛 ∈ ℕ. 

A fórmula 𝑧𝑛 = |𝑧|𝑛(𝑐𝑜𝑠 𝑛𝜃 + 𝑖𝑠𝑒𝑛 𝑛𝜃), contida no lema acima, é conhecida como 

a fórmula de De Moivre. 

 Esse lema permite calcularmos de maneira prática e precisa as raízes de um dado 

número complexo.  

1.4.11. Observação: Seja 𝑤 = |𝑤|(𝑐𝑜𝑠 𝛼 + 𝑖𝑠𝑒𝑛 𝛼) um número complexo não nulo. Então, 

as enésimas raízes de 𝑤 são dadas pela fórmula 

𝑤𝑘 = √𝑟𝑛

[𝑐𝑜𝑠  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

) + 𝑖𝑠𝑒𝑛  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

)] , 𝑘 = 0, … , 𝑛 − 1. 

Demonstração: Ver [5], página 190. 

O  isomorfismo  que  apresentaremos  a  seguir  mostra  que  o  conjunto  ℂ  pode  ser 

identificado como um subconjunto do conjunto das matrizes quadradas de ordem 2. 

1.4.12. Observação:    Seja  𝜑  a  função  que  associa  a  cada  número  complexo  uma  matriz 

quadrada de ordem 2, definida por 

𝜑: ℂ

→                 𝒞 ⊂ 𝕄2(ℝ)
𝑥
𝑦
−𝑦 𝑥]

↦        𝜑(𝑧) = [

                        𝑧 = 𝑥 + 𝑦𝑖

;

2×2

onde  𝒞 =   {[

𝑦
𝑥
−𝑦 𝑥]

2×2

isomorfismo. 

/ 𝑥, 𝑦 ∈ ℝ}  é  o  conjunto  do  exemplo  em  1.2.15.  Então,  𝜑  é  um 

Demonstração: Realmente; sejam 𝑧1 = 𝑎 + 𝑏𝑖 e 𝑧2 = 𝑐 + 𝑑𝑖 dois elementos quaisquer em 

ℂ. Então valem: 

 
 
 
 
 
                                                 
                       
 
i)  para  𝑧1 + 𝑧2 = (𝑎 + 𝑐) + (𝑏 + 𝑑)𝑖, 

temos  𝜑(𝑧1 + 𝑧2) = [

𝑎 + 𝑐

𝑏 + 𝑑
−(𝑏 + 𝑑) 𝑎 + 𝑐

]

=

2×2

31 

[

𝑏 + 𝑑
𝑎 + 𝑐
−𝑏 − 𝑑 𝑎 + 𝑐

]

2×2

= [

𝑏
𝑎
−𝑏 𝑎

]

2×2

+ [

𝑑
𝑐
−𝑑 𝑐

]

2×2

= 𝜑(𝑧1) + 𝜑(𝑧2). 

ii) 

para 

𝑧1 ∙ 𝑧2 = (𝑎𝑐 − 𝑏𝑑) + (𝑎𝑑 + 𝑏𝑐)𝑖, 

temos 

[

𝑎𝑐 − 𝑏𝑑

𝑎𝑑 + 𝑏𝑐
−(𝑎𝑑 + 𝑏𝑐) 𝑎𝑐 − 𝑏𝑑

]

  =   [

𝑎𝑑 + 𝑏𝑐
𝑎𝑐 − 𝑏𝑑
−𝑎𝑑 − 𝑏𝑐 𝑎𝑐 − 𝑏𝑑

]

  =    [

𝑏
𝑎
−𝑏 𝑎

]

2×2

∙ [

2×2

2×2

𝜑(𝑧1) ∙ 𝜑(𝑧2) 

Além disso,  

𝜑(𝑧1 ∙ 𝑧2) =
𝑑
𝑐
−𝑑 𝑐

=

2×2

]

iii)  𝜑  é  injetiva,  pois  vemos  que  valem  as  seguintes  implicações:  𝜑(𝑧1) = 𝜑(𝑧2) ⟹

[

𝑏
𝑎
−𝑏 𝑎

]

2×2

= [

𝑑
𝑐
−𝑑 𝑐

]

2×2

⟺  𝑎 = 𝑐 e 𝑏 = 𝑑 ⟺ 𝑧1 = 𝑧2. 

iv) 𝜑 é sobrejetiva, pois para toda matriz 𝑀 = [

𝑥
𝑦
−𝑦 𝑥]

2×2

∈ 𝒞 existe 𝑧 = 𝑥 + 𝑦𝑖 ∈ ℂ tal 

que 𝜑(𝑧) = 𝑀. 

O conjunto 𝒞 acima é uma cópia de ℂ dentro do anel das matrizes quadradas de 

ordem 2. Portanto, tem a mesma estrutura de ℂ; é um corpo dentro de 𝕄2(ℝ).  

Usando o item b) de 1.4.5, podemos determinar a inversa de uma matriz quadrada 

de ordem 2 de uma maneira diferente. 

1.4.13. Exemplo: Podemos calcular a inversa da matriz  𝐸 = [

1 −4
]
4    1

2×2

 sem recorrer aos 

determinantes  ou outro método comumente  empregado. Basta fazer o seguinte:  temos 

que  𝐸 = 𝜑(𝑧 = 1 − 4𝑖). Agora, como visivelmente  𝑧−1 =

1

17

+

4

17

𝑖 é o inverso de  𝑧. Pelo 

item b) de 1.4.5, concluímos que  

𝜑(𝑧−1) = 𝜑(𝑧)−1 = 𝐸−1 = [

1
17
4
17

−

4
17
1
17

]

. 

2×2

Claramente, temos  

𝜑(𝑧) ∙ 𝜑(𝑧−1) = [

1 −4
]
4    1

2×2

1
17
4
17

[
−

4
17
1
17

]

= 𝐼2 = 𝐸 ∙ 𝐸−1. 

2×2

 
 
 
   
 
   
 
32 

1.5 Espaços vetoriais 

Apresentaremos  nesta  seção  alguns  conceitos  e  propriedades  referentes  a 

estrutura algébrica dos espaços vetoriais. 

1.5.1.  Definição:  Seja  𝑉  um  conjunto  não  vazio  em  que  está  definida  uma  operação  de 

adição tal que ∀ 𝑢, 𝑣 ∈ 𝑉, tem-se 𝑢 + 𝑣 ∈ 𝑉, e uma operação de multiplicação por escalar 

onde ∀ 𝜆 ∈ 𝐾 e ∀ 𝑣 ∈ 𝑉, tem-se 𝜆 𝑣 ∈ 𝑉. 

Suponhamos  que  para  quaisquer  𝑢, 𝑣, 𝑤  elementos  em  𝑉  e  quaisquer  𝛼, 𝜆 

elementos num corpo 𝐾, valem:  

𝑨𝟏: 𝑢 + (𝑣 + 𝑤) = (𝑢 + 𝑣) + 𝑤 (Associatividade da adição);  

𝑨𝟐: 𝑢 + 𝑣 = 𝑣 + 𝑢 (Comutatividade da adição);  

𝑨𝟑: existe 0 ∈ 𝑉 tal que 𝑢 + 0 = 0 + 𝑢 (Existência de elemento neutro da adição); 
𝑨𝟒: existe  − 𝑥 ∈ 𝑉 tal que 𝑥 + (−𝑥) = −𝑥 + 𝑥 = 0 (Existência de inverso aditivo);  
𝑴𝟏: (𝛼𝜆)𝑢 = 𝛼(𝜆𝑢);  
𝑴𝟐: (𝛼 + 𝜆)𝑢 = 𝛼𝑢 + 𝜆𝑢;  
𝑴𝟑: 𝛼(𝑢 + 𝑣) = 𝛼𝑢 + 𝛼𝑣;  

𝑴𝟒: 1 ∙ 𝑢 = 𝑢.  

Nessas  condições  dizemos  que  𝑉  é  um  espaço  vetorial  sobre  o  corpo  𝐾,  que 

denotamos por 𝑉(𝐾).   

1.5.2. Observação: Se V é um espaço vetorial sobre um corpo 𝐾, valem 

i) 𝜆0 = 0, ∀𝜆 ∈ 𝐾; 

ii) (−1)𝑣 = −𝑣, ∀𝑣 ∈ 𝑉.  

Demonstração: Para i), temos que 𝜆0 = 𝜆(0 + 0) = 𝜆0 + 𝜆0, o que implica que 0 = 𝜆0, ou 

seja, 𝜆0 = 0. Agora, para ii), temos que 0 = 0𝑣 = (1 + (−1))𝑣 = 1𝑣 + (−1)𝑣 = 𝑣 + (−1)𝑣; 

o que implica que (−1)𝑣 = −𝑣. 

1.5.3.  Exemplo:  O  conjunto  ℱ(ℝ) = {𝑓: ℝ ⟶ ℝ; 𝑓 é função}  de  todas  as  funções  reais, 

munido  das  operações  de  adição  e  da  multiplicação  por  escalar  definidas  da  seguinte 

forma: ∀ 𝑓, 𝑔 ∈ ℱ(ℝ) e ∀ 𝛼, 𝜆 ∈ ℝ, temos 

(+): 𝑓 + 𝑔: ℝ
                      𝑥

→        ℝ 
↦        (𝑓 + 𝑔)(𝑥) = 𝑓(𝑥) + 𝑔(𝑥); 

 
 
 
 
 
 
                       
                       
 
33 

( ∙ ): 𝜆𝑓: ℝ
                 𝑥
é um espaço vetorial sobre ℝ.  

→        ℝ 
↦        (𝜆𝑓)(𝑥) = 𝜆𝑓(𝑥), 

Como a operação de adição em ℝ é associativa vale que: (𝑓(𝑥) + 𝑔(𝑥)) + ℎ(𝑥) =

𝑓(𝑥) + (𝑔(𝑥) + ℎ(𝑥)) para cada 𝑥, logo (𝑓 + 𝑔) + ℎ = 𝑓 + (𝑔 + ℎ) e vale 𝐴1.  

Como a adição em ℝ é comutativa; vale que 𝑓(𝑥) + 𝑔(𝑥) = 𝑔(𝑥) + 𝑓(𝑥) para cada 

𝑥, logo 𝑓 + 𝑔 = 𝑔 + 𝑓 e vale 𝐴2. 

O “vetor” nulo é a função  

𝑜: ℝ
                    𝑥

→        ℝ
↦        𝑜(𝑥) = 0.

A função 

−𝑓: ℝ
                                        𝑥

→        ℝ
↦        (−𝑓)(𝑥) = −𝑓(𝑥)

é o inverso aditivo de 𝑓.  

Temos também que [(𝛼𝜆)𝑓](𝑥) = (𝛼𝜆)𝑓(𝑥) = 𝛼[𝜆𝑓(𝑥)] = 𝛼(𝜆𝑓)(𝑥), ou seja, que 

vale  𝑀1.  Que  [(𝛼  +  𝜆)𝑓](𝑥)   =   (𝛼  +  𝜆)𝑓(𝑥) = 𝛼𝑓(𝑥)   +  𝜆𝑓(𝑥) = (𝛼𝑓)(𝑥) + (𝜆𝑓)(𝑥) =
(𝛼𝑓 + 𝜆𝑓)(𝑥) e, vale  𝑀2. Mais ainda,  [𝜆(𝑓  +  𝑔)](𝑥) = 𝜆[(𝑓  +  𝑔)(𝑥)] = 𝜆[𝑓(𝑥) + 𝑔(𝑥)] =

𝜆𝑓(𝑥) + 𝜆𝑔(𝑥) = (𝜆𝑓)(𝑥) + (𝜆𝑔)(𝑥) = (𝜆𝑓 + 𝜆) e, vale 𝑀3. 

Por fim, a função  

1𝑓: ℝ
                                                      𝑥

→        ℝ
↦        (1𝑓)(𝑥) = 1𝑓(𝑥) = 𝑓(𝑥);

mostra que, 1𝑓 = 𝑓 e, vale 𝑀4.  

Essas  verificações  dependem  do  conceito  de  igualdade  de  funções  e  das 

propriedades da adição e multiplicação de números. 

1.5.4. Definição: Um vetor 𝑣 é dito uma combinação linear dos vetores 𝑣1, … , 𝑣𝑛 em 𝑉 se 

existem escalares 𝜆1, … , 𝜆𝑛 em 𝐾 tais que  

𝑛

𝑣 = 𝜆1𝑣1 + ⋯ + 𝜆𝑛𝑣𝑛 = ∑ 𝜆𝑖𝑣𝑖

𝑖=1

1.5.5. Definição: Dizemos que o conjunto 𝛽 = {𝑣1, … , 𝑣𝑛} gera um espaço vetorial 𝑉 se todo 

vetor em 𝑉 puder ser escrito como combinação linear dos vetores de 𝛽. 

 
                       
                       
                                                
                       
                       
 
 
                       
                       
 
 
 
 
                       
                       
 
 
 
 
 
 
34 

1.5.6.  Definição:  Sejam  𝑉  um  espaço  vetorial  e  𝛽 = {𝑣1, … , 𝑣𝑛}  um  subconjunto  de  𝑉. 

Dizemos que 𝛽 é linearmente independente (LI), ou que os vetores 𝑣1, … , 𝑣𝑛 são LI, se a 

equação  

𝜆1𝑣1 + ⋯ + 𝜆𝑛𝑣𝑛 = 0 

implicar 𝜆1 = ⋯ = 𝜆𝑛 = 0. No caso em que existe algum 𝜆𝑖 ≠ 0 para 𝑖 = 1,2, … , 𝑛, dizemos 

que 𝛽 é linearmente dependente (LD), ou que os vetores 𝑣1, … , 𝑣𝑛 são LD. 

1.5.7. Observação: Sejam 𝑣1, … 𝑣𝑛 vetores em  𝑉. Se 𝑣1, … 𝑣𝑛 são LI’s então a combinação 

linear 𝑣 = 𝜆1𝑣1 + ⋯ + 𝜆𝑛𝑣𝑛 é unicamente determinada pelos escalares reis 𝜆1, … , 𝜆𝑛. 

Demonstração: De fato, considere que exista outra combinação linear com 𝛼1, … , 𝛼𝑛 ∈ 𝐾 

tal que 

Então vale que  

𝑣 = 𝛼1𝑣1 + ⋯ + 𝛼𝑛𝑣𝑛 = 𝜆1𝑣1 + ⋯ + 𝜆𝑛𝑣𝑛. 

Como 𝑣1, … , 𝑣𝑛 são LI’s, resta que 𝑎1 = 𝜆1, … , 𝛼𝑛 = 𝜆𝑛. 

(𝛼1 − 𝜆1)𝑣1 + ⋯ + (𝛼𝑛 − 𝜆𝑛)𝑣𝑛 = 0. 

1.5.8. Definição: Seja 𝑛 um número natural. Dizemos que um subconjunto 𝛽 = {𝑣1, … , 𝑣𝑛} 

de um espaço vetorial 𝑉 é uma base desse espaço se, e somente se: 

i) 𝛽 gera 𝑉;  

ii) 𝛽 é um conjunto LI. 

1.5.9. Proposição: Se 𝛽 = {𝑣1, … , 𝑣𝑛} é uma base ordenada do espaço vetorial 𝑉, cada vetor 

em 𝑉 pode ser expresso de maneira única como combinação linear dos vetores de 𝛽.  

Demonstração: Sabemos que 𝛽 gera 𝑉, logo um vetor arbitrário 𝑣 em 𝑉 pode ser expresso 

como combinação linear dos vetores de 𝛽. Suponhamos que  

𝑣 = 𝛼1𝑣1 + ⋯ + 𝛼𝑛𝑣𝑛 e 𝑣 = 𝜆1𝑣1 + ⋯ + 𝜆𝑛𝑣𝑛 

com 𝛼1, … , 𝛼𝑛, 𝜆1, … , 𝜆𝑛 ∈ ℝ. Daí, obtemos  

0 = 𝑣 − 𝑣 = (𝛼1 − 𝜆1)𝑣1 + ⋯ + (𝛼𝑛 − 𝜆𝑛)𝑣𝑛. 

Como 𝑣1, … , 𝑣𝑛 são LI’s concluímos que 𝛼1 = 𝜆1, … , 𝛼𝑛 = 𝜆𝑛. 

1.5.10. Definição: Seja 𝑛 um número natural. Se 𝛽 = {𝑣1, … , 𝑣𝑛} for uma base de um espaço 

vetorial  𝑉, dizemos que  𝑉 tem dimensão finita  𝑛 (ou que 𝑉 é 𝑛-dimensional). O espaço 

constituído do vetor nulo tem dimensão zero. Indicaremos por dim(𝑉) a dimensão de 𝑉. 

 
 
 
 
 
35 

Muitos  resultados  à  respeito  de  um  espaço  vetorial  podem  ser  vistos  nas 

referências  [1],  [2],  [3],  [4]  e  [5].  Os  que  incluímos  aqui  é  para  dar  significado  aos 

conjuntos  que  investigaremos.  Facilmente,  podemos  reconhecer  que  ℂ  e  𝕄2(ℝ)  são 

também  espaços  vetoriais  sobre  o  corpo  ℝ.  O  conjunto  𝛽 = {1, 𝑖}  é  uma  base  de  ℂ  e  o 

conjunto 𝛾 = {[

1 0
0 0

]

2×2

, [

0 1
]
0 0

2×2

, [

0 0
]
1 0

2×2

, [

0 0
]
0 1

2×2

} é uma base de 𝕄2(ℝ); isto é, 

dim(ℂ) = 2 e dim(𝕄2(ℝ)) = 4 .  

O  conjunto  𝒞  é  dois  gerado;  já  que  𝜉 = {[

1 0
]
0 1

2×2

, [

   0 1
]
−1 0

2×2

}  é  uma  de  suas 

bases. Além disso, vale que dim(𝒞) = 2, o que não pode ser uma novidade, pois por 1.4.12, 

vale que ℂ ≅ 𝒞. 

1.6 Transformações lineares 

Nesta seção relacionaremos alguns resultados sobre transformações lineares, que 

são funções especiais cujo domínio e contradomínio são espaços vetoriais sobre um corpo 

𝐾.  O  objetivo  principal  é  estabelecer  que  essas  funções  podem  ser  representadas  por 

matrizes.  

1.6.1.  Definição:  Sejam  𝑉  e  𝑊espaços  vetoriais  sobre  um  corpo  𝐾.  Diremos  que  uma 

transformação 𝑇 de 𝑉 em 𝑊 é linear se, e somente se, 

i) 𝑇(𝑢 + 𝑣) = 𝑇(𝑢) + 𝑇(𝑣); 

ii) 𝑇(𝜆𝑢) = 𝜆𝑇(𝑢),  

onde 𝑢 e 𝑣 são vetores arbitrários em 𝑉 e 𝜆 é um escalar arbitrário em 𝐾. 

1.6.2. Exemplo:  Se 𝑉  é  um  espaço  vetorial,  a  transformação  identidade  𝐼𝑉,  definida  por 
𝐼𝑉(𝑢) = 𝑢, para todo 𝑢 ∈ 𝑉, é linear. Do mesmo modo a transformação nula, definida por 
𝑂(𝑢) = 0, para todo 𝑢 ∈ 𝑉. 

Note que se 𝜆 = 0 em ii), por 1.5.2, temos que 𝑇(0) = 0; isto é, toda transformação 

linear leva vetor nulo em vetor nulo. Observemos que o contrário não vale, isto é, se 𝑇 é 

uma transformação linear, temos que 𝑇(0) = 0 não implica que 𝑇 é linear, pois 𝑇(𝑥) = |𝑥| 

não é linear. 

 
 
 
 
 
 
 
 
 
 
36 

1.6.3. Proposição: Uma transformação 𝑇: 𝑉 ⟶ 𝑊 é linear se, e somente se, ∀𝑢, 𝑣 ∈ 𝑉(𝐾) e 

∀ 𝜆 ∈ 𝐾 tivermos que 𝑇(𝜆𝑢 + 𝑣) = 𝜆𝑇(𝑢) + 𝑇(𝑣). 

Demonstração: Se 𝑇 é linear, temos 𝑇(𝜆𝑢 + 𝑣) = 𝑇(𝜆𝑢) + 𝑇(𝑣) = 𝜆𝑇(𝑢) + 𝑇(𝑣). 

Equivalentemente,  pondo  𝜆 = 1, temos  𝑇(𝑢 + 𝑣) = 𝑇(1𝑢 + 𝑣) = 𝑇(1𝑢) + 𝑇(𝑣) =

1𝑇(𝑢) + 𝑇(𝑣) = 𝑇(𝑢) + 𝑇(𝑣) 

E, usando que 𝑇(0) = 0, temos 𝑇(𝜆𝑢) = 𝑇(𝜆𝑢 + 0) = 𝑇(𝜆𝑢) + 𝑇(0) = 𝜆𝑇(𝑢) + 0 =

𝜆𝑇(𝑢). 

1.6.4.  Exemplo:  Seja  𝐴  é  uma  matriz  de  ordem  𝑚 × 𝑛  sobre  o  corpo  ℝ.  A  matriz  𝐴 
determina a “transformação matricial” 𝑇𝐴: ℝ𝑛 ⟶ ℝ𝑚 definida por 𝑇𝐴(𝑋) = 𝐴𝑋, para todo 
𝑋  em  ℝ𝑛.  (Aqui  os  vetores  de  ℝ𝑛  e  ℝ𝑚  são  escritos  como  matrizes  coluna).  Essa 
transformação  é  linear,  pois  para  qualquer  𝑋1, 𝑋2 ∈ ℝ𝑛  e  todo  𝜆 ∈ ℝ,  temos  que 
𝑇𝐴(𝜆𝑋1 + 𝑋2) = 𝐴(𝜆𝑋1 + 𝑋2) = 𝐴(𝜆𝑋1) + 𝐴(𝑋2) = 𝜆𝐴𝑋1 + 𝐴𝑋2 = 𝜆𝑇𝐴(𝑋1) + 𝑇𝐴(𝑋2). 

1.6.5. Proposição: Sejam 𝑉 e 𝑊 espaços vetoriais de dimensão finita. Se 𝛽 = {𝑣1, … , 𝑣𝑛} for 
uma base ordenada de 𝑉 e 𝛽′ = {𝑤1, … , 𝑤𝑛} um conjunto de vetores, não necessariamente 
distintos, em 𝑊, existe uma única transformação linear 𝑇: 𝑉 ⟶ 𝑊 tal que 𝑇(𝑣𝑖) = 𝑤𝑖, para 

todo 𝑖 = 1, … , 𝑛.  

Demonstração: Ver [6]; página 135. 

1.6.6. Proposição: Sejam 𝑉 e 𝑊 espaços vetoriais sobre um corpo 𝐾 e as aplicações lineares 

𝑇: 𝑉 ⟶ 𝑊 e 𝑇′: 𝑉  ⟶ 𝑊. Então 𝑇 + 𝑇′ e 𝜆𝑇 definidas por: 

(𝑇 + 𝑇′)(𝑣) = 𝑇(𝑣) + 𝑇′(𝑣) e (𝜆𝑇)(𝑣) = 𝜆𝑇(𝑣) 

são transformações lineares de 𝑉 em 𝑊.   

Demonstração: Ver [5]; página 128. 

1.6.7.  Proposição:  Sejam  𝑉,  𝑊  e  𝑍  espaços  vetoriais  sobre  um  corpo  𝐾,  𝑇: 𝑉 ⟶ 𝑊  e 

𝑇′: 𝑊  ⟶ 𝑍  transformações  lineares.  Então,  a  composta  𝑇′ ∘ 𝑇: 𝑉 ⟶ 𝑍,  definida  por  

(𝑇′ ∘ 𝑇)(𝑣) = 𝑇′(𝑇(𝑣)) é uma transformação linear. 

Demonstração: Ver [4], página 124.  

 
 
 
 
 
 
 
 
 
1.6.8. Exemplo: Vemos que 

𝑇: ℝ2
    (𝑥, 𝑦)

→          ℂ                                                        𝐿: ℂ

→                 𝒞 

↦        (1𝑓)(𝑥) = 1𝑓(𝑥) = 𝑓(𝑥)       e        𝑧 = 𝑥 + 𝑦𝑖

↦        𝐿(𝑧) = [

37 

   𝑥 𝑦
−𝑦 𝑥]

2×2

são aplicações lineares, e  

→          𝒞 

𝐿 ∘ 𝑇: ℝ2
           (𝑥, 𝑦)

↦        (𝐿 ∘ 𝑇)((𝑥, 𝑦)) = 𝐿 (𝑇((𝑥, 𝑦))) = 𝐿(𝑥 + 𝑦𝑖) = [

   𝑥 𝑦
−𝑦 𝑥]

. 

2×2

1.6.9. Definição: Sejam 𝑉 e 𝑊 espaços vetoriais de dimensão finita sobre um corpo 𝐾 com 
bases 𝛽 = {𝑣1, … , 𝑣𝑛} e 𝛽′ = {𝑤1, … , 𝑤𝑚} fixadas, respectivamente, e seja 𝑇: 𝑉 ⟶ 𝑊 uma 
𝛽 , é a 
𝛽′

transformação linear. A matriz de  𝑇 em relação às bases  𝛽 e 𝛽′, indicada por  [𝑇]

única matriz cuja  𝑗-ésima coluna é a matriz coordenada do vetor  𝑇(𝑣𝑗) = ∑ 𝑎𝑖𝑗𝑣𝑗

𝑛
𝑖=1

 na 

base 𝛽′. Então,  

[𝑇]

𝛽 = [
𝛽′

𝑎11
𝑎21
⋮

𝑎12 ⋯ 𝑎1𝑛
𝑎22 ⋯ 𝑎2𝑛
⋮
⋮ ⋯
𝑎𝑚1 𝑎𝑚2 ⋯ 𝑎𝑚𝑛

]

, 

𝑚×𝑛

é a matriz que representa a transformação 𝑇, a qual notamos ser a matriz transposta da 

matriz dos coeficientes de  

(∗) {

𝑇(𝑣1) = 𝑎11𝑤1 + 𝑎21𝑤2 + ⋯ + 𝑎𝑚1𝑤𝑚
𝑇(𝑣2) = 𝑎12𝑤1 + 𝑎22𝑤2 + ⋯ + 𝑎𝑚2𝑤𝑚
… … … … … … … … … … … … … … … … … …
𝑇(𝑣𝑛) = 𝑎1𝑛𝑤2 + 𝑎2𝑛𝑤2 + ⋯ + 𝑎𝑚𝑛𝑤𝑚

, 

que obtemos escrevendo as imagens dos vetores da base 𝛽 como combinação linear dos 

vetores da base 𝛽′. 

Note que a unicidade da matriz [𝑇]

𝛽  é garantida pela proposição em 1.5.7. 
𝛽′

1.6.10. Exemplo: Seja 𝐿 a aplicação do exemplo em 1.6.8. Temos que  

  𝐿(1) = [

  𝐿(𝑖) = [

]

1 0
0 1
   0 1
−1 0

= 1 [

1 0
]
0 1

2×2

2×2

+ 0 [

= 0 [

]

2×2

1 0
]
0 1

2×2

1 [

   0 1
]
−1 0
   0 1
−1 0

]

2×2

.

2×2

Então, temos que [𝐿]𝛾

𝛽 =   [

1 0
0 1

]

. 

2×2

1.6.11. Definição: Seja 𝑉 um espaço vetorial sobre um corpo 𝐾. Uma aplicação linear de 𝑉 

em 𝑉 será denominado de operador linear. 

 
                             
                                                
                       
                       
                                                                                 
                              
                       
 
 
 
 
 
 
38 

Em se tratando da representação matricial de um operador linear 𝑇: 𝑉 ⟶ 𝑉, é mais 
𝛽 ≡ [𝑇]𝛽  será 

conveniente  usarmos  a  mesma  base  ordenada  de  𝑉.  Nesse  caso  [𝑇]𝛽

denominada simplesmente de matriz de 𝑇 em relação a base ordenada 𝛽. 

1.6.12. Exemplo: Consideremos o operador linear  𝑇: ℝ2 ⟶ ℝ2 definido  por  𝑇((𝑥, 𝑦)) =

(𝑥 + 𝑘𝑦, 𝑦). Para 𝑘 ∈ ℝ e 𝛽 = {(1, 0), (0, 1)} uma base ordenada de ℝ2, vamos determinar 

[𝑇]𝛽. Temos  

então, [𝑇]𝛽 = [

1 𝑘
0 1

]

. 

2×2

𝑇((1, 0)) = (1, 0) = 1(1, 0) + 0(0, 1)
 𝑇((0, 1)) = (𝑘, 1) = 𝑘(1, 0) + 1(0, 1),

Notemos  que,  se  𝛽 ≠ {(1, 0), (0, 1)}  então,  [𝑇]𝛽 ≠ [

1 𝑘
0 1

]

2×2

;  ou  seja,  para  cada 

base ordenada 𝛽 há uma única matriz [𝑇]𝛽 que representa o operador linear 𝑇. 

Seja  𝑉  um  espaço  vetorial  de  dimensão  finita  1 ≤ 𝑛 ∈ ℕ  sobre  um  corpo  𝐾. 

Conforme o exemplo em 1.5.4 e a observação em 1.6.6, podemos considerar o conjunto 

ℱ(𝑉) = {𝑓: 𝑉 ⟶ 𝑉/𝑓 é uma função}. Dentro desse conjunto, um espaço vetorial sobre o 

corpo  𝐾,  é  o  conjunto  ℒ(𝑉) = {𝑇: 𝑉 ⟶ 𝑉/𝑇 é uma aplicação linear}  dos  operadores 

lineares de 𝑉 em 𝑉. Cada elemento de ℒ(𝑉), fixada uma base 𝛽, pode ser representado por 

uma matriz de 𝕄𝑛(𝐾). 

1.6.13. Proposição: Se 𝑉 é um espaço vetorial 𝑛-dimensional sobre o corpo  ℝ com uma 

base  ordenada  𝛽 = {𝑣1, … , 𝑣𝑛}  fixada,  existe  uma  bijeção  entre  o  conjunto  ℒ(𝑉)  dos 

operadores lineares 𝑇 de 𝑉 em 𝑉 e o conjunto 𝕄𝑛(ℝ) das matrizes de ordem 𝑛 × 𝑛 sobre 

o corpo ℝ.  

Demonstração:  Consideremos a função 𝔉 que associa a cada operador linear 𝑇 em ℒ(𝑉) 

uma matriz quadrada em 𝕄𝑛(ℝ) definida por  

                        𝔉: ℒ(𝑉)

𝑇

→        𝕄𝑛(ℝ) 
↦         𝔉(𝑇) = [𝑇]𝛽: 𝕄𝑛×1(ℝ)

↦         𝕄𝑛×1(ℝ) 

                                                                                    𝑋

↦         [𝑇]𝛽𝑋 

Ora,  já  sabemos,  pela  definição  em  1.6.9,  que  a  cada  transformação  linear,  está 

associada a uma matriz e, em particular, ao operador linear 𝑇 está associada uma matriz 

de ordem 𝑛 × 𝑛 fixada uma base 𝛽 = {𝑣1, … , 𝑣𝑛} de seu domínio. Isto é, se [𝑇1]𝛽 e [𝑇2]𝛽 são 

 
 
 
 
 
                       
                        
                        
                        
39 

matrizes  de  𝕄𝑛(ℝ),  que  representam  os  operadores  lineares  𝑇1  e  𝑇2  em  ℒ(𝑉), 
respectivamente, e se [𝑇1] = [𝑇2]; então ocorre que 𝑇1 = 𝑇2.  Logo, 𝔉 é injetiva. Já para toda 

matriz 

𝑎11 𝑎12 ⋯ 𝑎1𝑛
𝑎21 𝑎22 ⋯ 𝑎2𝑛
⋮ ⋯ ⋮
⋮

]

[𝑇]𝛽 = [

𝑎𝑛1 𝑎𝑛2 ⋯ 𝑎𝑛𝑛

𝑛×𝑛

∈ 𝕄𝑛(ℝ), 

existe um operador linear 𝑇 ∈ ℒ(𝑉) tal que 𝔉(𝑇) = [𝑇]𝛽, o que mostra que 𝔉 é sobrejetiva. 

Portanto, 𝔉 é uma bijeção de ℒ(𝑉) em 𝕄𝑛(ℝ). 

1.6.14. Proposição:  Sejam  𝑣  um  elemento  do  espaço  vetorial  𝑉  e  𝑇  um  operador  linear 

sobre 𝑉. Se [𝑣]𝛽 e [𝑇(𝑣)]𝛽 indicam, respectivamente, as matrizes coordenadas de 𝑣 e 𝑇(𝑣) 

numa base 𝛽 = {𝑣1, … , 𝑣𝑛} de 𝑉, então  

Demonstração:  Se 𝑣 = ∑

𝑛
𝑗=1

𝑐𝑗𝑣𝑗

 é um elemento de 𝑉, 

[𝑇(𝑣)]𝛽 = [𝑇]𝛽[𝑣]𝛽. 

então  

𝑛

𝑛

𝑇(𝑣) = 𝑇 (∑ 𝑐𝑗𝑣𝑗

) = ∑ 𝑐𝑗𝑇(𝑣𝑗)

. 

𝑗=1

𝑗=1

Como as imagens dos vetores da base pertencem a 𝑉, podemos escrever  

𝑛

𝑇(𝑣𝑗) = ∑ 𝑐𝑘𝑗𝑣𝑘

para todo 𝑗 = 1, … , 𝑛. 

𝑘=1

Daí,  

𝑛

𝑛

𝑇(𝑣) = 𝑇 (∑ 𝑐𝑗𝑣𝑗

) = ∑ 𝑐𝑗𝑇(𝑣𝑗)

𝑗=1

𝑗=1

𝑛
= ∑ 𝑐𝑗
𝑗=1

𝑛

𝑛

𝑛

(∑ 𝑐𝑘𝑗𝑣𝑘

) = ∑ (∑ 𝑐𝑘𝑗𝑐𝑗

) 𝑣𝑘

. 

𝑘=1

𝑘=1

𝑗=1

Consequentemente, a matriz coordenada de 𝑇(𝑣) na base 𝛽 é 
𝑎11𝑐1 + 𝑎12𝑐2 + ⋯ + 𝑎1𝑛𝑐𝑛
𝑎21𝑐1 + 𝑎22𝑐2 + ⋯ + 𝑎2𝑛𝑐𝑛
]
… … … … … … … … … … … … …
𝑎𝑛1𝑐1 + 𝑎𝑛2𝑐2 + ⋯ + 𝑎𝑛𝑛𝑐𝑛

𝑎11 𝑎12 ⋯ 𝑎1𝑛
𝑎21 𝑎22 ⋯ 𝑎2𝑛
⋮
⋮ ⋯ ⋮
𝑎𝑛1 𝑎𝑛2 ⋯ 𝑎𝑛𝑛

[𝑇(𝑣)]𝛽 = [

= [

𝑛×1

𝑐1
𝑐2
⋮
𝑐𝑛

[

]

𝑛×𝑛

]

.  

𝑛×1

Isto é,  

[𝑇(𝑣)] = [𝑇]𝛽[𝑣]𝛽. 

 
 
 
40 

1.6.15. Exemplo: Se [𝑇]𝛽 = [

1 𝑘
0 1

]

2×2

 é a matriz da transformação do exemplo em 1.6.11 

e [𝑣]𝛽 = [

𝑥
𝑦]

2×1

 a matriz coordenada de um vetor 𝑣 qualquer do espaço vetorial ℝ2, então 

[𝑇]𝛽[𝑣]𝛽 = [

1 𝑘
0 1

]

2×2

𝑥
𝑦]

[

2×1

= [

𝑥 + 𝑘𝑦
𝑦

]

2×1

𝑇((𝑥, 𝑦)) = (𝑥 + 𝑘𝑦, 𝑦).  

  é  a  matriz  coordenada  da  imagem  de 

1.6.16. Proposição: Sejam 𝑉 um espaço vetorial sobre o corpo ℝ e 𝛽 = {𝑣1, … , 𝑣𝑛} uma base 
ordenada de 𝑉. Sejam 𝑇 e 𝑇′ operadores lineares sobre 𝑉. Se [𝑇]𝛽 = 𝐴 e [𝑇′]𝛽 = 𝐵, então 
[𝑇 ∘ 𝑇′]𝛽 = 𝐴𝐵 (nessa ordem). 
Demonstração: Seja 𝐶 = [𝑇 ∘ 𝑇′]𝛽 e sejam 𝐴 = [𝑇]𝛽 e 𝐵 = [𝑇′]𝛽. É fácil ver que 𝐶 = 𝐴𝐵, 

pois  se  𝑣  é  um  vetor  qualquer  de  𝑉,  temos  [𝑇(𝑣)]𝛽 = 𝐴[𝑣]𝛽 𝑒 [𝑇(𝑇′(𝑣))]
𝛽

= 𝐴[𝑇′(𝑣)], 

então  [(𝑇 ∘ 𝑇′)(𝑣)]𝛽 = 𝐴𝐵[𝑣]𝛽.  Logo,  por  definição  e  pela  unicidade  da  matriz  que 

representa um operador linear fixada uma base 𝛽, temos necessariamente que 𝐶 = 𝐴𝐵. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
41 

Capítulo 2 - Elementos ortogonais 

Neste capítulo, depois de definirmos o conjunto das matrizes ortogonais de ordem 

2,  faremos  a  intersecção  com  o  conjunto  𝒞  do  exemplo  em  1.2.15,  mostrando  que  o 

conjunto 𝒪(𝒞), dos elementos ortogonais de 𝒞, está contido propriamente nesse conjunto. 

Por isomorfismo, constataremos que 𝒪(𝒞) tem uma pré imagem em ℂ, que coincide com 

𝒵 = {𝑧 ∈ ℂ / 𝑧 ∙ 𝑧̅ = 1}.  Esse  conjunto  𝒵 = 𝒪(ℂ)  será  denominado  de  conjunto  dos 

elementos ortogonais de ℂ. 

2.1 Os elementos ortogonais de 𝕄𝟐(ℝ) 

É  comum,  que  a  partir  de  conjuntos  conhecidos  e  de  conjuntos  que  possuem 

elementos de mesma natureza, construamos o conjunto intersecção, o conjunto união, o 

conjunto soma ou produto cartesiano. Assim, foi que, olhando, simultaneamente, em 𝒞 e 

no conjunto de todas as matrizes ortogonais de 𝕄2(ℝ) pudemos chegar aos elementos 

ortogonais de ℂ. 

Primeiramente, note que, se 𝑀 = [

∈ 𝕄2(ℝ), a igualdade  

𝑚 𝑛
𝑞]
𝑝
2×2
𝑚 𝑝
𝑞]
𝑛

∙ [

2×2

2×2

= [

1 0
]
0 1

2×2

𝑀 ∙ 𝑀𝑡 = [

𝑚 𝑛
𝑞]
𝑝

impõe  as  seguintes  relações:  𝑚2 + 𝑛2 = 𝑝2 + 𝑞2 = 1  e  𝑚𝑝 + 𝑛𝑞 = 0.  Portanto,  vamos 

definir  por  𝒪(𝕄2(ℝ)) = {𝐴 ∈ 𝕄2(ℝ); 𝑎11

2 + 𝑎12

2 = 𝑎21

2 + 𝑎22

2 = 1 𝑒 𝑎11𝑎21 + 𝑎12𝑎22 = 0} =

{𝑀 ∈ 𝕄2(ℝ);  𝑀 ∙ 𝑀𝑡 = 𝐼2} o conjunto das matrizes ortogonais de 𝕄2(ℝ).  

Obviamente, 𝒞 não coincide com  𝒪(𝕄2(ℝ)). Isso fica claro se observamos que a 

matriz 𝑀 = [

1
√2
1
√2

1
√2
1
−
√2

]

2×2

é um elemento de  𝒪(𝕄2(ℝ)); pois 𝑀 ∙ 𝑀𝑡 = 𝐼2. Porém, sendo 

𝑚11 ≠ 𝑚22, temos que 𝑀 ∉ 𝒞 e isso mostra que 𝒪(𝕄2(ℝ)) ⊄ 𝒞.  

Por  outro  lado,  é  claro  que  a  matriz  𝑁 = [

1
2
]
−1 2

2×2

  está  em  𝒞  e  não  está  em 

𝒪(𝕄2(ℝ)); já que [

2
1
−1 2

]

2×2

∙ [

2 −1
]
2
1

2×2

= [

5 0
]
0 5

2×2

≠ [

1 0
]
0 1

2×2

; o que mostra que 

𝑁 ∉ 𝒪(𝕄2(ℝ)) e, assim, 𝒞 ⊄ 𝒪(𝕄2(ℝ)). 

 
 
   
 
 
 
 
𝑥
𝑦
−𝑦 𝑥]
𝑥
𝑦
−𝑦 𝑥]

∙ [

2×2

2×2
𝑥 −𝑦
𝑦    𝑥 ]

=

2×2

Agora,  pelo  fato  de  que  𝒪(𝕄2(ℝ)) ∩ 𝒞 ≠ ∅;  já  que  esse  conjunto  contém  𝐼2,  faz 

sentido  investigarmos  os  elementos  dessa  intersecção  que,  na  verdade,  são  formas 

concretas de números complexos, via isomorfismo.  

42 

A  análise  é  a  seguinte:  um  elemento  de  𝒞,  digamos  𝑀 = [

,  está  em 

𝒪(𝕄2(ℝ)) 

se, 

e 

somente 

se, 

tivermos  𝑀 ∙ 𝑀𝑡 = [

[

𝑥2 + 𝑦2
𝑥𝑦 − 𝑥𝑦
𝑥𝑦 − 𝑥𝑦 𝑥2 + 𝑦2]

= [

𝑥2 + 𝑦2
0

0
𝑥2 + 𝑦2]

= [

1 0
0 1

]

2×2

2×2

2×2

;  de  onde  obtemos  a 

igualdade 𝑥2 + 𝑦2 = 1, que por sua vez, fornece 𝑦 = 𝑥 ± √1 − 𝑥2, com −1 ≤ 𝑥 ≤ 1. Isso 

mostra que as matrizes ortogonais de 𝕄2(ℝ) dentro de 𝒞 formam o conjunto  

𝒪(𝒞) = {[

𝑥

(±√1 − 𝑥2)

− (±√1 − 𝑥2)

𝑥

]

;  𝑥 ∈ ℝ e  − 1 ≤ 𝑥 ≤ 1 } = 𝒪(𝕄2(ℝ)) ∩ 𝒞. 

2×2

Assim, como na página 20, vemos que existe estreita relação entre o conjunto das 

matrizes, das matrizes inversíveis, das matrizes ortogonais e ordem 2 e as matrizes de 𝒞. 

Veja o seguinte diagrama: 

𝕀2(ℝ) 

𝕄2(ℝ) 

𝒪(𝕄2(ℝ)) 

𝒞 

𝕄2(ℝ): Matrizes 
𝕀2(ℝ): Matrizes inversíveis 

𝒪(𝕄2(ℝ)): Matrizes ortogonais 

𝒞: Matrizes de ℂ 

2.2 As 𝝋−𝟏 - imagens dos elementos ortogonais de 𝓒 

Na observação em 1.4.12 vimos que a função 𝜑 é bijetiva. Evidentemente, podemos 

definir a função 𝜑−1, bijetiva, inversa de 𝜑, que associa a cada elemento em 𝒞, um único 

elemento em ℂ. Investigaremos como se comportam as imagens dos elementos de  𝒪(𝒞) 

no conjunto dos números complexos.  

Veremos que tais investigações,  nos levam a um interessante subconjunto de  ℂ, 

que  assim  como  o  conjunto  das  matrizes  ortogonais,  cujos  elementos  inversos  se 

destacam por serem as matrizes transpostas, tal conjunto de números complexos  pode 

também  ser  destacado  a  partir  uma  particular  característica  relacionada  aos  seus 

inversos. 

 
 
 
 
 
 
 
 
 
 
 
43 

2.2.1. Definição: Definimos por  

𝜑−1: 𝒞
                     𝑀

→        ℂ
↦         𝜑−1(𝑀)

a função  que associa  a  cada  matriz  em  𝒞  um  único  número  complexo. Assim,  a  função 
𝜑−1/𝒪(𝒞), restrição da função 𝜑−1 ao conjunto 𝒪(𝒞), fornece, através desse isomorfismo 

inverso, o subconjunto de números complexos 

𝒵 = {𝑥 ± √1 − 𝑥2𝑖; 𝑖 = √−1, com 𝑖2 = −1 e 𝑥 ∈ ℝ com − 1 ≤ 𝑥 ≤ 1}. 

2.2.2.  Observação:  Seja  𝒵 = {𝑥 ± √1 − 𝑥2𝑖; 𝑖 = √−1, com 𝑖2 = −1 e 𝑥 ∈ ℝ com − 1 ≤ 𝑥 ≤ 1}. 

Então, valem:  

i) Todo elemento de 𝒵 tem módulo igual a 1, ou seja, no plano complexo, todo elemento 

de 𝒵 está sobre uma circunferência de raio 1 e centro na origem; 

ii) 𝑤 ∙ 𝑤̅ = 1, para todo 𝑤 ∈ 𝒵; 

iii) Se 𝑤−1 = 𝑤̅; vale que 𝜑(𝑤−1) = (𝜑(𝑤))

−1

= (𝜑(𝑤))

𝑡

, para todo 𝑤 ∈ 𝒵. 

Demonstração:  Seja  𝑤 = 𝑥 ± √1 − 𝑥2𝑖  um  elemento  de  𝒵.  Temos,  então,  que  |𝑤| =

√𝑥2 + (±√1 − 𝑥2)

2

= √𝑥2 + (1 − 𝑥2) =   √1 = 1. Portanto, vale i). 

Temos, ainda, que  

𝑤 ∙ 𝑤̅   =   (𝑥  +   √1  −  𝑥2𝑖) ∙ (𝑥  −   √1  −   𝑥2𝑖)   =   (𝑥  −   √1  −   𝑥2𝑖) ∙ (𝑥  +  √1  −   𝑥2𝑖)   =

𝑥2 − (1 − 𝑥2)𝑖2 = 𝑥2 + (1 − 𝑥2) = 1, o que mostra a validade de ii).  

Por  fim,  se  𝑤 = 𝑥 + √1 − 𝑥2𝑖,  sabendo  que  𝜑(𝑤) = [

    𝑥
−√1 − 𝑥2

√1 − 𝑥2
 𝑥

]

, 

2×2

vemos  que  𝜑(𝑤−1) = [

𝑥
√1 − 𝑥2

−√1 − 𝑥2
𝑥

]

2×2

= (𝜑(𝑤))

𝑡

  ou,  se  𝑤 = 𝑥 − √1 − 𝑥2𝑖  e, 

sabendo que  𝜑(𝑤) = [

 𝑥
√1 − 𝑥2

−√1 − 𝑥2
    𝑥

]

2×2

, percebemos que se verifica a igualdade 

𝜑(𝑤−1) = [

    𝑥
−√1 − 𝑥2

√1 − 𝑥2
 𝑥

]

2×2

= (𝜑(𝑤))

𝑡

 , o que mostra que vale iii). 

 
                                                
                        
                        
 
 
 
 
44 

2.2.3.  Exemplo:  Veja  que  para  𝑤 = 0,4 + √0,84𝑖  e  𝑤̅ = 0,4 − √0,84𝑖,  temos  a  seguinte 

igualdade  𝜑(𝑤) = [

0,4
−√0,84

√0,84
0,4

]

2×2

  é  verificada  e,  portanto,  concluímos  que 

𝜑(𝑤−1) = [

0,4
√0,84

−√0,84
]
0,4

2×2

= (𝜑(𝑤))

𝑡

.  

2.3 Uma razoável definição para elementos ortogonais em ℂ  

Da equação da circunferência  𝑥2 + 𝑦2 = 1 de raio 1 centrada  na origem, vemos, 

claramente, que essa pode ser reescrita como segue abaixa:  

𝑥2 + 𝑦2 = 𝑥2 − (−𝑦2) = 𝑥2 − 𝑖2𝑦2 = 𝑥2 − 𝑥𝑦𝑖 + 𝑥𝑦𝑖 − 𝑦2𝑖2 = (𝑥 + 𝑦𝑖)(𝑥 − 𝑦𝑖) = 1. 

Percebemos, assim, que a igualdade 𝑥2 + 𝑦2 = 1 ocorre em ℂ quando um número 

complexo 𝑧 = 𝑥 + 𝑦𝑖 é multiplicado pelo seu conjugado 𝑧̅ = 𝑥 − 𝑦𝑖. Isto é, o conjunto 𝒵 é 

conjunto  dos  números  complexos  que  tem  a  característica  do  seu  conjugado  ser  o  seu 

inverso multiplicativo. 

2.3.1.  Definição:  Dizemos  que  um  número  complexo  𝑧  é  ortogonal  se,  e  somente,  se  a 

igualdade  𝑧 ∙ 𝑧̅ = 1  ocorrer.  Por  𝒪(ℂ) = {𝑧 ∈ ℂ; 𝑧 ∙ 𝑧̅ = 1}  denotaremos  o  conjunto  dos 

números complexos ortogonais.  Ressaltamos,  e  é  fácil  perceber  que  o  conjunto  𝒪(ℂ)  é 

exatamente 𝒵 = {𝑥 ± √1 − 𝑥2𝑖; 𝑖 = √−1 com 𝑖2 = −1 e 𝑥 ∈ ℝ com −1 ≤ 𝑥 ≤ 1}. 

2.3.2. Exemplo: O número complexo 𝑧 = 0,6 + 0,8𝑖 é ortogonal, pois  

𝑧 ∙ 𝑧̅ = (0,6 + 0,8𝑖) ∙ (0,6 − 0,8𝑖) = 0,36 + 0,64 = 1. 

Ademais,  sendo  𝜑  o  isomorfismo  em  1.4.12,  a  matriz  𝜑(𝑧) = 𝑀 = [

0,8
0,6
]
−0,8 0,6

é 

2×2

ortogonal, já que  𝑀 ∙ 𝑀𝑡 = [

0,8
0,6
]
−0,8 0,6

∙ [

0,6 −0,8
]
0,6
0,8

= [

1 0
]
0 1

. 

2×2

2×2

2×2

É  claro  que  para  encontrar  um  número  complexo  ortogonal  𝑧 = 𝑥 + 𝑦𝑖  bastar 

encontrar dois números reais 𝑥 e 𝑦 satisfazendo a igualdade 𝑥2 + 𝑦2 = 1 e pertencentes 

ao intervalo [−1,1].  

Fazendo um parelelo a observação em 1.1.21 temos o seguinte fechamento para a 

multiplicação em 𝒪(ℂ). 

 
 
 
 
 
 
 
 
 
45 

2.3.3. Observação: O produto de dois números complexos ortogonais é ainda ortogonal.  

Demonstração:  Realmente, sejam 𝑧1 e 𝑧2 dois números complexos ortogonais, temos 

(𝑧1 ∙ 𝑧2) ∙ (𝑧1 ∙ 𝑧2) = 𝑧1 ∙ 𝑧2 ∙ (𝑧1) ∙ (𝑧2) = 𝑧1 ∙ (𝑧1) ∙ 𝑧2 ∙ (𝑧2) = 1 ∙ 1 = 1. 

2.3.4.  Observação:  O  produto  entre  números  complexos  ortogonais  permanece  na 

circunferência unitária centrada na origem.  

Demonstração: De fato, sejam  𝑧1 e 𝑧2 dois números 

𝑦 

complexos ortogonais. Digamos que 𝜃1 e 𝜃2 sejam os 

argumentos  de  𝑧1  e  𝑧2,  respectivamente.  Como  o 

módulo de 𝑧1 e 𝑧2 são ambos iguais a 1, temos  
𝑧1 ∙ 𝑧2 = cos(𝜃1 + 𝜃2) + 𝑖𝑠𝑒𝑛(𝜃1 + 𝜃2), 

de onde obtemos 

|𝑧1 ∙ 𝑧2| = |cos(𝜃1 + 𝜃2) + 𝑖𝑠𝑒𝑛(𝜃1 + 𝜃2)| = 1. 

𝑏 

1 

𝑎 

𝑥 

2.3.5.  Observação:  A  potência  de  um  número 

complexo ortogonal permanece sobre a circunferência unitária centrada na origem.  

Demonstração: Pela formula de De Moivre, temos  

𝑧𝑛 = (𝑐𝑜𝑠 𝑛𝜃 + 𝑖𝑠𝑒𝑛 𝑛𝜃), 

pois o módulo de 𝑧 é igual a 1. Como |𝑐𝑜𝑠 𝑛𝜃 + 𝑖𝑠𝑒𝑛 𝑛𝜃| = √(𝑐𝑜𝑠 𝑛𝜃)2 + (𝑠𝑒𝑛 𝑛𝜃)2 = 1, 

vemos que a potência de um número complexo ortogonal realmente permanece sobre a 

circunferência de raio 1.  

2.3.6. Observação: A 𝑛-ésima raiz de um número complexo ortogonal permanece sobre a 

circunferência de raio 1.  

Demonstração: De fato, temos que o módulo de um número complexo é igual a 1. Assim,  

𝑤𝑘 = √𝑟𝑛

[𝑐𝑜𝑠  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

) + 𝑖𝑠𝑒𝑛  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

)] , 𝑘 = 0, … , 𝑛 − 1, 

equivale a  

Como  

𝑤𝑘 = [𝑐𝑜𝑠  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

) + 𝑖𝑠𝑒𝑛  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

)] , 𝑘 = 0, … , 𝑛 − 1. 

|𝑐𝑜𝑠  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

) + 𝑖𝑠𝑒𝑛  (

𝛼
𝑛

+

2𝜋𝑘
𝑛

)| = 1 

verificamos esse fato. 

 
 
 
 
46 

2.3.7. Observação: O número complexo 𝑖 é ortogonal.  

Demonstração: Realmente, (0 + 𝑖) ∙ (0 − 𝑖) = −𝑖2 = −(−1) = 1. 

Podemos  ter  uma  visão  geral  do  comportamento  dos  números  complexos,  dos 

números complexos inversíveis e dos números complexos ortogonais no diagrama  logo 

abaixo.  

ℂ 

𝐼(ℂ) 

𝒪(ℂ) 

ℂ: Números complexos 

𝐼(ℂ): Números complexos não nulos 

𝒪(ℂ): Números complexos ortogonais 

2.4 Os elementos ortogonais de ℝ𝟐   

Nesta seção, brevemente, consideraremos o conjunto dos pares ordenados de ℝ2, 

que são imagens dos elementos de 𝒪(ℂ) pela função 𝛿, definida em 1.4.7. 

Temos 

                            𝛿/𝒪(ℂ): 𝒪(ℂ)
                                                𝑧 = 𝑥 ± √1 − 𝑥2𝑖

→                       ℝ2 

↦        𝛿/𝒪(𝒞)(𝑧) = 𝛿(𝑧) = (𝑥, ±√1 − 𝑥2), 

restrição da função 𝛿  e, conforme a definição de 𝒪(ℂ), vale que −1 ≤ 𝑥 ≤ 1.  

Verifiquemos  o  comportamento  dessas  imagens  com  respeito  à  multiplicação 

definida  em  1.4.6:  ∀ (𝑎, 𝑏), (𝑐, 𝑑) ∈ ℝ2,  (𝑎, 𝑏) ∙ (𝑐, 𝑑) = (𝑎 ∙ 𝑐 − 𝑏 ∙ 𝑑, 𝑎 ∙ 𝑑 + 𝑏 ∙ 𝑐).  Antes, 

vejamos,  primeiramente,  que  𝐼𝑚(𝛿/𝒪(ℂ)),  o  conjunto  imagem  da  função  𝛿/𝒪(ℂ),  é 

exatamente o conjunto ℨ = {(𝑥, ±√1 − 𝑥2) ∈ ℝ2/𝑥 ∈ ℝ com −1 ≤ 𝑥 ≤ 1}.  

Para  𝑥 = 1,  temos  que  (1, 0) ∈ ℨ.  Além  disso,  se  (𝑥, ±√1 − 𝑥2) ∈ ℨ,  usando  o 

isomorfismo 𝛿 e o fato de que, em ℂ, o inverso de 𝛿−1 ((𝑥, ±√1 − 𝑥2)) = 𝑥  ±  √1  −  𝑥2𝑖, 

é o número complexo (𝑥  ±   √1  −  𝑥2𝑖)

−1

= 𝑥 − (±√1 − 𝑥2)𝑖, de volta em ℨ, temos que 

𝛿 ((𝑥  ±   √1  −  𝑥2𝑖)

−1

) = 𝛿(𝑥 − (±√1 − 𝑥2)𝑖) = (𝑥, −(±√1 − 𝑥2)) = (𝑥, ± √1  −  𝑥2)

−1

∈ ℨ. 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
                                                                 
                      
 
 
47 

É 

natural 

definirmos  𝒪(ℝ2) = {(𝑎, 𝑏) ∈ ℝ2/(𝑎, 𝑏)(𝑎, −𝑏) = (1,0)}, 

pelo 

isomorfismo 𝛿, como sendo o conjunto dos elementos ortogonais de ℝ2. Esse conjunto 

coincide com 𝐼𝑚(𝛿/𝒪(ℂ)) = ℨ = {(𝑥, ±√1 − 𝑥2) ∈ ℝ2/𝑥 ∈ ℝ com −1 ≤ 𝑥 ≤ 1}. 

Os elemento de 𝒪(ℝ2) = {(𝑥, ±√1 − 𝑥2) ∈ ℝ2/𝑥 ∈ ℝ com −1 ≤ 𝑥 ≤ 1} são todos 

inversíveis, no entanto,  ℑ(ℝ2), o conjunto dos elementos inversíveis de  ℝ2, é maior  do 

que 𝒪(ℝ2).  Por  exemplo,  (2, 0) ∈ ℑ(ℝ2)  mas,  (2, 0) ∉ ℨ.  Já  o  par  ordenado  (

6

10

,

8

10

)  é 

ortogonal, pois conforme a definição acima, temos que (

6

10

,

8

10

) (

6

10

, −

8

10

) = (1,0).  

2.4.1.  Observação:  Todo  elemento  de  ℨ  pode  ser  representado  como  um  ponto  na 

circunferência unitária. 

Demonstração:  Como  o  número  complexo  𝑧 = 𝑥 ± √1 − 𝑥2𝑖  está  na  circunferência 

unitária, pelo item i) da observação em 2.2.2, e como cada número complexo representa 

um par ordenado, conforme a função 𝛿 definida em 1.4.7, temos que (𝑥, ±√1 − 𝑥2) está 

na circunferência unitária.  

2.4.2. Observação: O produto de dois pares ordenados ortogonais é ortogonal.  

Demonstração:  Sejam  (𝑎, ±√1 − 𝑎2)  e  (𝑏, ±√1 − 𝑏2)  dois  elementos  de  𝒪(ℝ2).  Temos 

(𝑎, ±√1 − 𝑎2)(𝑏, ±√1 − 𝑏2) = (𝑎𝑏 − (±√(1 − 𝑎2)(1 − 𝑏2)) , 𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2)).    E, 

o produto desse elemento por (𝑎𝑏 − (±√(1 − 𝑎2)(1 − 𝑏2)) , − (𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2))) 

2
fornece ((𝑎𝑏 − (±√(1 − 𝑎2)(1 − 𝑏2)))

− ( 𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2)) (− (𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2))) , 0) 

= ((𝑎𝑏 − (±√(1 − 𝑎2)(1 − 𝑏2)))

2

+ ( 𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2)) (𝑎(±√1 − 𝑏2) + 𝑏(±√1 − 𝑎2)) , 0) 

= ((𝑎𝑏  −   (±√(1 − 𝑎2)(1 − 𝑏2)))

+   (𝑎(±√1 − 𝑏2))

2

2

2
  +  2𝑎𝑏 (±√(1 − 𝑎2)(1 − 𝑏2))  +  (𝑏(±√1 − 𝑎2))

, 0) 

=(𝑎2𝑏2 − 2𝑎𝑏 (±√(1 − 𝑎2)(1 − 𝑏2)) + (1 − 𝑎2)(1 − 𝑏2) + 𝑎2(1 − 𝑏2) + 2𝑎𝑏 (±√(1 − 𝑎2)(1 − 𝑏2)) + 𝑏2(1 − 𝑎2), 0) 

=(𝑎2𝑏2 + (1 − 𝑎2)(1 − 𝑏2) + 𝑎2(1 − 𝑏2) + 𝑏2(1 − 𝑎2), 0) = (𝑎2𝑏2 + 1 − 𝑏2 − 𝑎2 + 𝑎2𝑏2 + 𝑎2 − 𝑎2𝑏2 + 𝑏2 − 𝑎2𝑏2, 0) 
=(1,0). Isso mostra que (𝑎, ±√1 − 𝑎2)(𝑏, ±√1 − 𝑏2) ∈ 𝒪(ℝ2). 

 
 
 
 
 
 
 
 
48 

2.4.3. Observação: Seja 𝒪(ℝ2) o conjunto dos elementos ortogonais de ℝ2. Então: 

i) se 𝑧 ∈ 𝒪(ℂ), vale que 𝛿(𝑧−1) = (𝛿(𝑧))

−1

∈ 𝒪(ℝ2) 

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
ii) para um qualquer elemento (𝑥, ±√1 − 𝑥2) em 𝒪(ℝ2), vale que 𝛿−1 ((𝑥, ±√1 − 𝑥2))

=

(𝛿−1 ((𝑥, ±√1 − 𝑥2)))

−1

.   

Demonstração:  i)  Para  𝑧 = 𝑥 ± √1 − 𝑥2𝑖,  vale  que  𝛿(𝑧) = (𝑥, ±√1 − 𝑥2).  Daí,  temos 

𝛿(𝑧−1) = 𝛿(𝑧̅) = (𝑥, −(±√1 − 𝑥2)) = (𝑥, ±√1 − 𝑥2)

−1

= (𝛿(𝑧))

−1

.  

ii)  Considere  𝛿−1,  a  função  inversa  de  𝛿  da  observação  em  1.4.7.  Então,  temos  que 

𝛿−1 ((𝑥, ±√1 − 𝑥2)) ∈ 𝒪(ℂ). 

Como, 

pela 

definição 

em 

2.3.1, 

vale 

que 

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
𝛿−1 ((𝑥, ±√1 − 𝑥2)) ∈ 𝒪(ℂ) ⇔ 𝛿−1 ((𝑥, ±√1 − 𝑥2)) 𝛿−1 ((𝑥, ±√1 − 𝑥2))

= 1, 

temos, 

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
portanto, que 𝛿−1 ((𝑥, ±√1 − 𝑥2))

= (𝛿−1 ((𝑥, ±√1 − 𝑥2)))

−1

. 

Podemos  ver  o  comportamento  dos  pares  ordenados  de  ℝ2,  ℑ(ℝ2)  e  𝒪(ℝ2) 

conforme o seguinte diagrama.  

ℝ2  ℑ(ℝ2)  𝒪(ℝ2) 

ℝ2: Pares ordenados 

ℑ(ℝ2): Pares ordenados inversíveis 

𝒪(ℝ2): Pares ordenados ortogonais 

2.5 Os elementos ortogonais de 𝓕(ℝ𝟐) 

Conforme a observação em 1.6.13, dentro das funções que agem de  ℝ2 para ℝ2, 

podemos considerar o conjunto  ℒ(ℝ2) = {𝑇: ℝ2 ⟶ ℝ2 / 𝑇 é uma aplicação linear}. Mais 
ainda,  existe  uma  bijeção  entre  ℒ(ℝ2)  e  o  conjunto  𝕄2(ℝ)  das  matrizes  quadradas  de 
ordem 2 com entradas em ℝ. 

Dentro de ℒ(ℝ2) vamos considerar o conjunto  

ƻ = {𝑇 ∈ ℒ(ℝ2)/ 𝑇((𝑥, 𝑦)) = (𝑚𝑥 + 𝑛𝑦, 𝑝𝑥 + 𝑞𝑦); com 𝑚2 + 𝑛2 = 𝑝2 + 𝑞2 = 1 𝑒 𝑚𝑝 + 𝑛𝑞 = 0}. 

Isso permite que formulemos o seguinte resultado.  

 
 
 
 
 
 
 
 
 
 
 
 
 
2.5.1. Observação: Seja 𝜓 a aplicação que associa a cada matriz ortogonal um operador 

linear definida como abaixo  

49 

           𝜓: 𝒪(𝕄2(ℝ))
                                𝑀
                                                                               (𝑥, 𝑦)

→        ƻ ⊂ ℒ(ℝ2) 
↦         𝔉𝜓(𝑀) = 𝑇: ℝ2

↦         ℝ2 

↦      ((𝑥, 𝑦)) = (𝑚𝑥 + 𝑛𝑦, 𝑝𝑥 + 𝑞𝑦), 

com 𝑚2 + 𝑛2 = 𝑝2 + 𝑞2 = 1 e 𝑚𝑝 + 𝑛𝑞 = 0, então 𝜓 é um isomorfismo. 

Demonstração: Já sabemos que o produto de duas matrizes ortogonal é  ortogonal. (Ver 
1.1.21). Assim, sejam 𝑇1: ℝ2 ⟶ ℝ2 e 𝑇2: ℝ2 ⟶ ℝ2 operadores lineares em ℒ(ℝ2), temos 
que 𝜓(𝑀1 ∙ 𝑀2) = 𝑇1 ∙ 𝑇2 = 𝑇1 ∘ 𝑇2 = 𝜓(𝑀1) ∘ 𝜓(𝑀2). (Ver 1.6.16).  

Agora, como pela proposição em 1.6.12 a função 𝔉: ℒ(ℝ𝑛) ⟶ 𝕄𝑛(ℝ) é uma bijeção 
e em particular, ℒ(ℝ2) ⊂ ℒ(ℝ𝑛) e 𝒪(𝕄2(ℝ)) ⊂ 𝕄𝑛(ℝ), temos que 𝜓 como definida acima 
também é uma bijeção e, portanto, um isomorfismo. 

O isomorfismo definido na observação acima induz à seguinte definição.  

2.5.2. Definição: Uma aplicação linear 𝑇 ∈ ℒ(ℝ2) é ortogonal se, e somente se, fixada uma 
base 𝛽 de ℝ2, a matriz de 𝕄2(ℝ) que representa 𝑇 é ortogonal, ou seja, a matriz [𝑇]𝛽 =
𝑚 𝑛
𝑞]
𝑝

; onde 𝑚2 + 𝑛2 = 𝑝2 + 𝑞2 = 1 e 𝑚𝑝 + 𝑛𝑞 = 0. 

[

2×2

2.5.3. Exemplo: O operador 𝑇: ℝ2 ⟶ ℝ2 definido por  

𝑇((𝑥, 𝑦)) = (𝑥𝑐𝑜𝑠𝜃 + 𝑦𝑠𝑒𝑛𝜃, −𝑥𝑠𝑒𝑛𝜃 + 𝑦𝑐𝑜𝑠𝜃) 

é um operador ortogonal.  

De fato, consideremos 𝛽 = {(1, 0), (0, 1)} uma base de ℝ2. Temos que  

   𝑇((1, 0)) = (𝑐𝑜𝑠𝜃, −𝑠𝑒𝑛𝜃) = 𝑐𝑜𝑠𝜃(1, 0) − 𝑠𝑒𝑛𝜃(0, 1)
𝑇((0, 1)) = (𝑠𝑒𝑛𝜃, 𝑐𝑜𝑠𝜃) = 𝑠𝑒𝑛𝜃(1, 0) + 𝑐𝑜𝑠𝜃(0, 1),

o  que  implica  que  [𝑇]𝛽 = [

   𝑐𝑜𝑠𝜃 𝑠𝑒𝑛𝜃
−𝑠𝑒𝑛𝜃 𝑐𝑜𝑠𝜃

]

2×2

.  Ademais,  são  satisfeitas  as  condições 

(𝑐𝑜𝑠𝜃)2 + (𝑠𝑒𝑛𝜃)2 = (𝑐𝑜𝑠𝜃)2 + (−𝑠𝑒𝑛𝜃)2 = 1 e (𝑐𝑜𝑠𝜃 ∙ (−𝑠𝑒𝑛𝜃)) + (𝑠𝑒𝑛𝜃 ∙ 𝑐𝑜𝑠𝜃) = 0. 

Obviamente,  conforme  a  definição  acima,  o  conjunto  de  todos  os  operados 

ortogonais 𝒪(ℒ(ℝ2)) de ℒ2(ℝ2) é o conjunto ƻ, isto é:  

𝒪(ℒ(ℝ2)) = {𝑇 ∈ ℒ(ℝ2) / 𝑇((𝑥, 𝑦)) = (𝑚𝑥 + 𝑛𝑦, 𝑝𝑥 + 𝑞𝑦)};  com  a  condição  de  que  se 

verifiquem as igualdades 𝑚2 + 𝑛2 = 𝑝2 + 𝑞2 = 1 e 𝑚𝑝 + 𝑛𝑞 = 0.  

 
                       
                        
                        
                 
 
 
 
 
 
 
 
50 

Podemos verificar a relação entre as aplicações lineares, os operadores lineares, os 

operadores inversíveis e os operados ortogonais em ℝ2, no seguinte diagrama: 

ℱ2(ℝ)  ℒ2(ℝ) 

ℐ2(ℝ2) 

𝒪(ℒ(ℝ2)) 

ℱ2(ℝ2): Operadores 
ℒ2(ℝ2): Operadores lineares 
ℐ2(ℝ2): Operadores inversíveis 
𝒪(ℒ(ℝ2)): Operadores ortogonais 

2.5.4. Observação: Sejam 𝑇1 e 𝑇2 elementos de  𝒪(ℒ(ℝ2)). Então, vale que  𝑇1𝑇2 ≡ 𝑇1 ∘ 𝑇2 

também é um elemento de 𝒪(ℒ(ℝ2)). 

Demonstração:  Pela  definição  em  2.4.2,  vemos  que  cada  operador  ortogonal  está 
representado por uma matriz ortogonal. Assim, fixada uma base  𝛽 de ℝ2, sejam [𝑇1]𝛽 e 

[𝑇2]𝛽  as  matrizes  que  representam  os  operadores  𝑇1  e  𝑇2,  respectivamente.  Pela 

observação  em  1.1.21,  temos  que  [𝑇1]𝛽[𝑇2]𝛽  é  ortogonal.  Pela  observação  em  1.6.16, 

temos que [𝑇1]𝛽[𝑇2]𝛽 representa o operador 𝑇1 ∘ 𝑇2. Então, pela definição em 2.2.2, vemos 

que 𝑇1 ∘ 𝑇2 ∈ 𝒪(ℒ(ℝ2)) 

2.5.5. Observação: Sejam ℒ(ℝ2) ⊂ ℱ(ℝ2) o conjunto dos operadores lineares de ℝ2 em ℝ2 

e 𝛽 uma base fixa de ℝ2. Então, são equivalentes:  

i) 𝑇 ∈ 𝒪(ℒ(ℝ2)); 

ii) [𝑇]𝛽 ∈ 𝒪(𝕄2(ℝ)).  

Demonstração: Pela definição em 2.4.2, 𝑇 ∈ 𝒪(ℒ(ℝ2)) se, e somente se, [𝑇]𝛽 ∈ 𝒪(𝕄2(ℝ)).  

2.5.6. Observação: Sejam 𝑇 ∈ 𝒪(ℒ(ℝ2)) e [𝑇]𝛽 a matriz que representa 𝑇 em relação a uma 
base 𝛽 de ℝ2. Então, são equivalentes:  

i) [𝑇]𝛽 ∈ 𝒪(𝒞) = 𝒪(𝕄2(ℝ)) ∩ 𝒞 ⊂ 𝜑(ℂ);  

ii) 𝜑−1([𝑇]𝛽)

̅̅̅̅̅̅̅̅̅̅̅̅̅̅ = (𝜑−1([𝑇]𝛽))

−1

, onde 𝜑 é o isomorfismo da observação em 1.4.12. 

Demonstração:  Consideremos  i).  Vemos  que  𝜑−1([𝑇]𝛽) ∈ 𝒪(ℂ).  Então,  pelo  item  ii)  da 

observação  em  2.2.2,  só  podemos  acreditar  que  𝜑−1([𝑇]𝛽)

̅̅̅̅̅̅̅̅̅̅̅̅̅̅ = (𝜑−1([𝑇]𝛽))

−1

,  pois 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
51 

𝜑−1([𝑇]𝛽)𝜑−1([𝑇]𝛽)

̅̅̅̅̅̅̅̅̅̅̅̅̅̅ = 1. Agora, se considerarmos ii), temos pelo item iii) da observação 

em 2.2.2, que 𝜑 ((𝜑−1([𝑇]𝛽))

−1

) = (𝜑 (𝜑−1([𝑇]𝛽)))

−1

= [𝑇]𝛽

−1 = [𝑇]𝛽

𝑡 e, [𝑇]𝛽 ∈ 𝒪(𝒞). 

Considerando  o  isomorfismo  𝜑−1,  inversa  de  𝜑,  definida  em  1.4.12,  temos  a 

seguinte demonstração alternativa: a função restrição 

                            𝜑−1/𝒪(𝒞): 𝒪(𝒞)
                                                                   𝑋

→        𝒵 ⊂ ℂ 
↦        𝜑−1/𝒪(𝒞)(𝑋) = 𝜑−1(𝑋) 

é  um  isomorfismo.  Consequentemente,  temos  que:  [𝑇]𝛽 ∈ 𝒪(𝒞)  se,  somente  se,  

𝜑−1/𝒪(𝒞)([𝑇]𝛽) = 𝜑−1([𝑇]𝛽) ∈ 𝒪(ℂ) se, e somente se, (𝜑−1([𝑇]𝛽))

−1

̅̅̅̅̅̅̅̅̅̅̅̅̅̅.  
= 𝜑−1([𝑇]𝛽)

 
 
 
                       
                       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
52 

Capítulo 3 - Considerações finais 

A respeito de um grupo 𝑮 

Nossas  discussões  permeiam  algumas  estruturas  algébricas,  pois  os  conjuntos 

abordados se encaixam em algumas delas.  

3.1 Definição: Um grupo multiplicativo (𝐺,

∙) é um conjunto não vazio, no qual está defina 

uma  operação  “∙”  de  multiplicação  que  possui  as  seguintes  propriedades:  ∀ 𝑥, 𝑦, 𝑧  ∈ 𝐺, 

vale que,  

G1:   𝑥(𝑦𝑧) = (𝑥𝑦)𝑧; 

G2: ∃ 𝑒 ∈ 𝐺 tal que 𝑥𝑒 = 𝑒𝑥 = 𝑥; 
G3: ∃ 𝑥−1 ∈ 𝐺 tal que 𝑥−1𝑥 = 𝑥𝑥−1 = 𝑒; 

Se, além dessas propriedades, tivermos  

G4:   𝑥𝑦 = 𝑦𝑥; 

dizemos que 𝐺 é um grupo abeliano. 

O leitor deve perceber que os conjuntos ℂ, 𝒞 e ℝ2, munidos de suas particulares 

multiplicações,  são 

todos  grupos  multiplicativos  abelianos.  Reduzindo  nossas 

considerações aos conjuntos 𝒪(ℂ), 𝒪(𝒞) e 𝒪(ℝ2),  todos isomorfos entre si. Também, que 

𝕄2(ℝ) e ℒ(ℝ2) (ver 1.6.6) são espaços vetoriais sobre o corpo ℝ e 𝒪(𝕄2(ℝ)) e 𝒪(ℒ(ℝ2)) 

são isomorfos.  

Uma generalização do conceito de ortogonalidade, longe daquele que provém de 

um produto interno, definido em um espaço vetorial, conhecidamente uma propriedade 

dois testável, pode ser dado como a seguir. 

3.2 Definição: Seja (𝐺,

∙) um grupo multiplicativo. Então, se existe um isomorfismo 𝜉 de ℂ 

(ou 𝒞 ou ℝ2 ou ℒ(ℝ2)) para 𝐺 , diremos que em 𝐺 existem elementos ortogonais. Mais 

especificamente, diremos que 𝜉(𝑧) = 𝑔 é um elemento ortogonal de 𝐺 se, e somente se 

i)  𝑔−1,  o  inverso  multiplicativo  de  𝑔,  é  a  imagem  direta  do  conjugado  de  um  número 

complexo 𝑧 tal que 𝑧̅ = 𝑧−1; ou  

ii) 𝑔−1,  o  inverso  multiplicativo  de  𝑔,  é  a  imagem  direta  da  transposta  de  uma  matriz 

ortogonal,  que  é  imagem  direta,  pelo  isomorfismo  𝜑,  do  conjugado  de  um  número 

complexo 𝑧 tal que 𝑧̅ = 𝑧−1; ou 

 
 
 
 
 
 
 
53 

iii) 𝑔−1, o inverso multiplicativo de 𝑔, é a imagem direta, pelo isomorfismo 𝛿, do conjugado 

de um número complexo 𝑧 tal que 𝑧̅ = 𝑧−1; ou 

iv) 𝑔−1, o inverso multiplicativo de  𝑔, é a imagem direta de um operador linear,  que é 

imagem direta, pelo isomorfismo 𝜓, da transposta de uma matriz ortogonal, que é imagem 

direta, pelo isomorfismo 𝜑, do conjugado de um número complexo 𝑧 tal que 𝑧̅ = 𝑧−1. 

Note que a sequência que apresentamos os itens i), ii), iii) e iv) pode ser alterada 

para ii), iv), i) e iii), olhando primeiramente para o produto  interno de cada par de vetores 

coluna de uma matriz quadrada, seus comprimentos, reduzindo esse entendimento para 

matrizes quadradas de ordem 2 que, por construção representam operadores lineares. 

Depois, olhando para a natural representação “concreta” de um número complexo como 

um vetor de ℝ2. 

Estabelecida a representação matricial de um operador linear 𝑇, agindo sobre um 

espaço  vetorial  𝑉  de  dimensão  finita  1 ≤ 𝑛 ∈ ℕ,  sobre  um  corpo  𝐾,  a  definição  de 

operador ortogonal está ligada ao fato das colunas dessa matriz serem duas a duas vetores 

ortogonais. Se considerarmos o caso 𝑛 = 2, os elementos de ℒ(𝑉), definido no parágrafo 

1.6, seriam representados por matrizes quadradas de ordem 2. Se o espaço vetorial 𝑉 for 

definido sobre um corpo 𝐾, cada elemento de ℒ(𝑉) pode ser reconhecido com uma matriz 

de 𝕄2(𝐾). Isso pode induzir uma generalização do estudo que fizemos no parágrafo 2.5 e, 
nesse  caso,  poderíamos  estabelecer  que  os  elementos  ortogonais  de  ℒ(𝑉)  seriam 

determinados pela representação matricial em 𝕄2(𝐾), onde essas matrizes deveriam ter 

pares de colunas como vetores ortogonais.  

No  entanto,  reconhecer  os  elementos  ortogonais  de  ℒ(ℝ2)  como  matrizes 

quadradas  de  ordem  2,  cujas  inversas  são  suas  transpostas  é  tecnicamente  visível  e 

possibilita, ainda, que relacionemos esses operadores com os elementos ortogonais de ℂ 

ou de ℝ2.    

Substituir em ℒ(ℝ2), o conjunto ℝ2 por 𝐷2(ℝ), o conjunto das matrizes diagonais 

de ordem 2 ou por 𝑃1(𝑡), o conjunto dos polinômio de grau no máximo 1, juntamente com 

o  polinômio  identicamente  nulo  nos  levaria  a  definir  os  elementos  ortogonais  de 

ℒ(𝐷2(ℝ)) ou  ℒ(𝑃1(𝑡)) como em 2.5.2. Consequentemente, resultados análogos aos das 

observações em 2.5.1, 2.5.3, 2.5.4, 2.5.5 e 2.5.6 seriam obtidos.  

 
 
 
 
 
 
54 

A respeito dos nossos estudos 

Neste  TCC,  no  capítulo  1,  desenvolvemos  alguns  tópicos  da  matemática  básica, 

como  o  estudo  das  matrizes  e,  em  particular  o  estudo  da  estrutura  do  conjunto  das 

matrizes quadradas e ordem 2 e o conjunto dos números complexos.  

Destacamos ainda os isomorfismos 𝛿 e 𝜑 definidos nas observações 1.4.7 e 1.4.12, 

respectivamente.  Tais  funções  merecem  destaque  porque  permitem  estender  os 

conceitos  que  elaboramos,  de  uma  matriz  quadrada  de  ordem  2  para  um  número 

complexo, e desse, para um par ordenado em ℝ2.  

Não  menos  importante,  foi  o  estudo  das  transformações  lineares,  das  quais 

destacamos os operadores lineares na definição em 1.6.11, e a proposição em 1.6.13, que 

faz associar a cada operador linear de ℒ(𝑉), onde 𝑉 é um espaço vetorial 𝑛-dimensional 

sobre o corpo ℝ, uma única matriz quadrada em 𝕄𝑛(ℝ). 

O capítulo 2 é o capítulo que julgamos mais relevante de nosso trabalho, pois é nele 

que definimos os elementos ortogonais de ℂ, ℝ2 e ℱ(ℝ2). Em primeiro lugar, ao encontro 

da definição em 1.1.19, explicitamos o conjunto dos elementos ortogonais de 𝕄2(ℝ), que 

denotamos  por  𝒪(𝕄2(ℝ)).  Em  seguida,  intersectamos  𝒪(𝕄2(ℝ))  com  o  conjunto  das 

imagens  de  ℂ  pela  função  𝜑,  que  denotamos  por  𝒞,  e  obtivemos  o  conjunto  𝒪(𝒞).  O 
conjunto  𝒪(𝒞),  mandamos  de  volta  para  ℂ  pela  função  restrição  𝜑−1/𝒪(𝒞) ,  obtendo  o 

conjunto 𝒪(ℂ) dos números complexos ortogonais.  

Dentro  de  𝒪(ℂ)  vimos  que  existe  o  fechamento  para  a  multiplicação,  fato  que 

comprovamos na observação em 2.3.3. Mais ainda, na observação em 2.3.4, confirmamos 

que a multiplicação de quaisquer dois números complexos ortogonais sempre permanece 

na circunferência unitária e, do mesmo modo a potência e a raiz, pelas observações 2.3.5 

e 2.3.6, respectivamente.  

Em relação a ℝ2, definimos par ordenado ortogonal em 2.4.1 e o conjunto desses 

elementos denotamos por 𝒪(ℝ2), que por sua vez, são as imagens dos elementos de 𝒪(ℂ) 

pela função restrição 𝛿/𝒪(ℂ). Destacamos as observação 2.4.3 e 2.4.4, como consequência 

da  definição  de  número  complexo  ortogonal  em  2.3.1,  cujas  demonstrações  revelam  o 

poder do isomorfismo 𝛿. 

Finalizamos  o  capítulo  2,  explorando  o  conjunto  𝒪(ℒ(ℝ2))  dos  operados 

ortogonais, definidos em 2.5.2. Vale ressaltar que, a definição em 2.5.2, não tem o caráter 

da  definição  de  operadores  ortogonais  que  encontramos,  por  exemplo,  em  nossa 

referência [2], página 143, já que aqui não consideramos o produto interno entre vetores, 

 
 
 
 
 
 
55 

mas a definição dada em 1.1.19, como mostram a abordagem que fizemos nas observações 

em 2.5.4 e 2.5.5.  

Embora  o  tema  tratado  aqui  não  seja  difícil  de  acessar,  acreditamos  que  as 

definições e relações que estabelecemos mereçam alguma atenção de quem se dedicar ao 

estudo dos vetores de ℝ2 e da Álgebra das Matrizes.   

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
56 

Bibliografia 

[1] ANTON, Howard. Álgebra linear com aplicações. 10.ed. Bookman. Porto Alegre, 2012. 

[2] BOLDRINI, José Luiz. Álgebra linear. 3ed. Harbra & Row do Brasil. SãoPaulo, 1980. 

[3] GONÇALVES, Adilson. Introdução à Álgebra. 5 ed., Rio de Janeiro-RJ; IMPA (2008) 

[4] GONÇALVEZ, Adilson e SOUZA, Rita M.L de. Introdução à Álgebra linear. Ed. Bücher 

LTDA, São Paulo, 1977. 

[5] HEFEZ, Abramo. Curso de Álgebra; vol. 1. 2 ed. Rio de Janeiro; IMPA (1993). 

[6] LIPSCHUTZ, Seymour. Álgebra linear. McGraw-Hill, 1968. 

[7] STEINBRUCH, Alfredo. Álgebra linear. 3ed. McGraw-Hill, São Paulo, 1990. 

 
 
 
 

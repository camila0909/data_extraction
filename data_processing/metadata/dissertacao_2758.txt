0 

UNIVERSIDADE DO ESTADO DE MATO GROSSO 

CAMPUS UNIVERSITÁRIO DE SINOP 

FACULDADE DE CIÊNCIAS EXATAS E TECNOLÓGICAS 

MESTRADO PROFISSIONAL EM MATEMÁTICA EM REDE  

NACIONAL PROFMAT 

LUANA KÁTIA HERBER QUEVEDO 

ÍNDICES ESPECTRAIS APLICADOS AO SENSORIAMENTO REMOTO 

Sinop – MT 

2017 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
LUANA KÁTIA HERBER QUEVEDO 

1 

ÍNDICES ESPECTRAIS APLICADOS AO SENSORIAMENTO REMOTO 

apresentada 

Dissertação 
ao 
Programa  de  Mestrado  Profissional 
em Matemática em Rede Nacional – 
PROFMAT,  da  Universidade  do 
Estado de Mato Grosso – UNEMAT, 
como requisito parcial para obtenção 
do grau de Mestre em Matemática. 

Prof. Dr. Rodrigo Bruno Zanin 
Orientador 

Prof. Ms. Erico Fernando de Oliveira 
Martins 
Coorientador 

Sinop – MT 

2017 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
2 

CIP – CATALOGAÇÃO NA PUBLICAÇÃO 

Ficha catalográfica elaborada pelo bibliotecário Luiz Kenji Umeno Alencar – CRB1 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
3 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4 

Dedico  este  trabalho  à  minha  mãe,  Etajana  (in 

memoriam) mesmo antes de que eu tivesse concluído 

a faculdade, acreditava que eu seria mestre. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
5 

AGRADECIMENTOS 

A Deus por tudo que tem me dado. 

A todos da minha família, meu pai Luiz, meus irmãos Michelly e Diego, 

aos meus sobrinhos Pedro e Lucas, ao meu marido Deive, minha sogra Maria, e 

todos  os  demais  familiares  por  compreenderem  minha  ausência  nesses  dois 

anos de estudo, incentivando a cada dificuldade. A minha sogra e meu marido 

um agradecimento especial pelos litros de café feito por eles, que ajudaram a 

manter os alunos e os professores acordados durante os estudos.  

A  todos  os  amigos  que  sempre  me  apoiaram,  deram  forças  para 

continuar. 

Aos  colegas  que  tive  oportunidade  em  conhecer  neste  mestrado, 

colegas  esses  que  hoje  chamo  de  amigos,  pois  na  convivência  destes  anos, 

tivemos mais contato entre nós do que com nossos familiares e ainda, torcendo 

uns pelos outros, em cada novo desafio de nossas vidas. 

Aos  professores  do  PROFMAT  da  UNEMAT  campus  de  Sinop-MT, 

por  tudo  que  fizeram  por  nós,  nos  ensinando,  incentivando  a  cada  etapa,  em 

particular ao professor Dr. Oscar Gonzalez Chong, por acreditar em cada um de 

nós e não medir esforços para que todos concluíssem o mestrado.  

Ao  professor  Dr.  Rodrigo  Bruno  Zanin  por  orientar  este  trabalho,  e 

oportunizar um novo olhar para a matemática. 

Aos amigos William Foschiera, Jonas Lima pelo auxílio na execução 

da pesquisa, pelos livros emprestados e por contribuir para a realização deste 

trabalho. 

 
 
 
 
 
 
 
 
 
 
 
 
RESUMO 

6 

tem  como  objetivo  principal  apresentar  o  uso  de 

A  aplicação  da  matemática  hoje  se  constitui  como  ferramenta  essencial  no 
campo  tecnológico.  Conceitos  matemáticos  são  cotidianamente  utilizados,  por 
exemplo ao se capturar uma imagem, assim, estudar conceitos da matemática 
permitem aplicá-los  em  diversas  áreas  com  diferentes finalidades.  O  presente 
ferramentas 
estudo 
matemáticas no processamento digital de imagens e sua utilização nos índices 
espectrais ligados ao Sensoriamento Remoto. Para realizar a pesquisa, foram 
utilizadas cenas do satélite Landsat 8 e do CBERS – 4, todas pré-processadas. 
Nestas imagens foram aplicados os Índices NDVI e SAVI, resultando em uma 
imagem.  Os dados obtidos após a aplicação destes índices foram classificados 
e  permitiram  identificar  áreas de  vegetação na  região  urbana  do município de 
Sinop-MT. Utilizar a composição de imagens orbitais a fim de se obter resultados 
que visam atender objetivos específicos como por exemplo, identificar áreas de 
plantação,  área  alagada,  de  mudanças  antrópica,  entre  outras,  possibilitando 
explicar  fenômenos  ambientais  ou  então,  consequências  da  ação  do  homem, 
mostra a importância da matemática no desenvolvimento de novas tecnologias. 
Assim,  instigar  os  alunos  do  Ensino  Médio  a  utilizar  imagens  pode  ser  um 
caminho para que estes possam compreender a matemática como uma ciência 
com diversas aplicações e desta forma, a aprendizagem da matemática se torne 
mais significativa. 

Palavras-chave:  Índices  de  Vegetação;  Sensoriamento  Remoto;  Matemática 
Aplicada. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ABSTRACT 

7 

The  application  of  mathematics  today  is  an  essential  tool  in  the  technological 
field. Mathematical concepts are used every day, for example when capturing an 
image,  thus,  studying  concepts  of  mathematics  allow  to  apply  them  in  several 
areas with different purposes. The present study has as main objective to present 
the  use  of  mathematical  tools  in  the  digital  image  processing  and  its  use  in 
spectral indexes linked to Remote Sensing. To perform the research, scenes from 
the satellite Landsat 8 and CBERS – 4, all pre-processed, were used. In these 
images the NDVI and SAVI Indices were applied, resulting in an image. The data 
obtained  after  the  application  of  these  indices  were  classified  and  allowed  to 
identify areas of vegetation in the urban area of the municipality of Sinop-MT. To 
use orbital imaging in order to obtain results that aim to meet specific objectives 
such as identifying areas of plantation, flooded area, anthropic changes, among 
others,  making  it  possible  to  explain  environmental  phenomena  or,  as  a 
consequence  of  human  action,  shows  The  importance  of  mathematics  in  the 
development of new technologies. Thus, instigating high school students to use 
images  can  be  a  way  for  them  to  understand  mathematics  as  a  science  with 
diverse  applications  and  thus,  the  learning  of  mathematics  becomes  more 
meaningful. 

Keywords: Vegetation Indices; Remote Sensing; Applied Mathematics. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
LISTA DE FIGURAS 

8 

Figura  1  –  Princípio  para  obtenção  de  uma  imagem  (MENESES;  ALMEIDA, 

2012) ................................................................................................................ 18 

Figura  2  –  Representação  de  uma  imagem  digital  com  sua  modelagem 

matemática ....................................................................................................... 19 

Figura 3 – Exemplo do processo de amostragem – (a) Imagem no “contínuo” e 

(b) Imagem amostrada. Gonzalez e Woods (2010) .......................................... 20 

Figura 4 – Exemplo de uma quantização para uma imagem, com seu respectivo 

histograma de números de pixels para cada um dos percentuais de intensidades 

de tons de cinza do objeto em questão ............................................................ 20 

Figura 5 – Representação de um grid uniforme para representação matricial de 

uma imagem (VELHO et al., 2009) .................................................................. 22 

Figura 6 – Fluxo de aquisição e modelagem de uma imagem digital (GATTASS, 

2017) ................................................................................................................ 23 

Figura  7  –  Esboço  da  resposta  espectral em função  do  comprimento  de  onda 

para o olho humano, segundo modelo de Young (VELHO et al., 2009) ........... 24 

Figura  8  –  Espectro  eletromagnético  com  destaque  para  a  faixa  do  visível 

(JENSEN, 2009) ............................................................................................... 25 

Figura 9 – Olho humano com os sensores (GONZALEZ e WOODS, 2010) .... 26 

Figura 10 – Espaço de cores RGB ................................................................... 26 

Figura 11 – Diagrama de cromaticidade – plano de Maxwell (GOMES e VELHO, 

1994) ................................................................................................................ 28 

Figura 12 – Reflectância em função dos comprimentos de ondas para diversos 

tipos de alvos (terrenos) de SR (JENSEN, 2009) ............................................. 33 

Figura 13 – Imagem do sensor MUX, composição colorida do CBERS – 4 (INPE, 

2017) ................................................................................................................ 36 

Figura  14  –  Exemplo  de  uma  imagem  Landsat  8,  sensor  pancromático  com 

composição RGB ............................................................................................. 37 

Figura  15  –  Bandas  R,  G  e  B  da  imagem  CBERS  –  4  com  seus  respectivos 

histogramas ...................................................................................................... 39 

Figura  16  –  Exemplo  de  uma  transformação  de  intensidade  no  histograma  – 

Equalização do Histograma.............................................................................. 40 

 
 
9 

Figura  17  –  Operadores  de  transformações  T1  e  T2,  com  seus  respectivos 

gráficos (GONZALEZ e WOODS, 2010) .......................................................... 41 

Figura 18 – Exemplo de uma imagem com contrastes, baixo, normal e alto ... 42 

Figura 19 – Detector de bordas de Roberts (2x2); (a) Imagem original; (b) Bordas 

detectadas (GONZALEZ e WOODS, 2010) ..................................................... 44 

Figura  20  –  Modelo  de  operação  aritmética  executada  pixel  a  pixel  em  uma 

imagem multiespectral (MENESES; ALMEIDA, 2012) ..................................... 45 

Figura 21 – Curvas de reflectâncias em função dos comprimentos de ondas para 

solo, vegetação e água (ZHANG e ZHANG, 2016) .......................................... 47 

Figura 22 – Percentual de reflectância em função dos comprimentos de ondas 

para vários tipos de vegetação (GIBSON, 2000) ............................................. 48 

Figura  23  –  Resultado  da  aplicação  do  NDVI  na  imagem  Landsat  8,  para  o 

recorte da área urbana de Sinop, com imagem tomada em 13/04/2017 .......... 52 

Figura  24  –  Resultado  da  aplicação  do  NDVI  na  imagem  CBERS  –  4,  para  o 

recorte da área urbana de Sinop, com imagem tomada em 09/04/2017 .......... 53 

Figura 25 – Resultado da aplicação do SAVI com L=0,5 na imagem Landsat 8, 

para  o  recorte  da  área  urbana  de  Sinop,  com 

imagem 

tomada  em           

13/04/2017 ....................................................................................................... 54 

Figura 26 – Resultado da aplicação do SAVI com L=0,5 na imagem CBERS – 4, 

para  o  recorte  da  área  urbana  de  Sinop,  com 

imagem 

tomada  em           

09/04/2017 ....................................................................................................... 55 

Figura 27 – Esquema para o processo de classificação de imagens (CAETANO 

et al., 2007) ...................................................................................................... 57 

Figura 28 – Resultados da classificação da imagem Landsat 8, para as classes 

após aplicação dos índices espectrais: (a) NDVI e (b) SAVI ............................ 58 

Figura 29 – Resultados da classificação da imagem CBERS – 4, para as classes 

após aplicação dos índices espectrais: (a) NDVI e (b) SAVI ............................ 58 

 
 
 
 
 
 
 
LISTA DE TABELAS 

10 

Tabela  1  –  Características  dos  sensores  do  CBERS  –  4  (EPIPHANIO,             

2011) ................................................................................................................ 35 

Tabela 2 – Bandas dos sensores do Satélite Landasat 8 (NASA, 2013) ......... 38 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
SUMÁRIO 

11 

LISTA DE FIGURAS .......................................................................................... 8 

LISTA DE TABELAS ....................................................................................... 10 

1. 

INTRODUÇÃO .......................................................................................... 13 

1.1 Justificativa ............................................................................................. 14 

1.2 Objetivos ................................................................................................. 15 

1.3 Estrutura do trabalho ............................................................................... 15 

2.  REFERENCIAL TEÓRICO ........................................................................ 16 

2.1 Imagens Digitais ...................................................................................... 16 

2.1.1 Aquisição e Modelagem de uma Imagem Digital .............................. 18 

2.1.1.1 Amostragem ............................................................................... 19 

2.1.1.2 Quantização ............................................................................... 20 

2.1.1.3 Discretização .............................................................................. 21 

2.1.2 Espaço de Cores .............................................................................. 23 

2.1.2.1 Fundamentos de Cor .................................................................. 23 

2.1.2.2 Modelos de Cores ...................................................................... 25 

2.1.2.3 Sistema Padrão CIE-RGB .......................................................... 26 

2.1.2.4 Sistema CIE-XYZ ....................................................................... 27 

2.1.3 Imagem Multiespectral ...................................................................... 28 

2.2 Sensoriamento Remoto .......................................................................... 29 

2.2.1 Princípios Básicos ............................................................................. 29 

2.2.2 Princípios de Radiação Eletromagnética .......................................... 31 

2.2.3 Plataformas Orbitais ......................................................................... 33 

2.2.3.1 CBERS – 4 ................................................................................. 34 

2.2.3.2 LANDSAT 8 ................................................................................ 36 

2.3 Processamento de Imagens Digitais ....................................................... 38 

2.3.1 Processamento de Imagens Baseado em Histograma ..................... 39 

 
 
12 

2.3.2 Processamento de Imagens Baseado em Filtragem ........................ 42 

2.3.3 Processamento de Imagens Baseado em Aritmética de Bandas ..... 44 

3.  MÉTODO PROPOSTO .............................................................................. 46 

3.1 Índices Espectrais em Sensoriamento Remoto....................................... 46 

3.2 Aplicação dos Índices Espectrais ............................................................ 50 

3.2.1 Aplicação do NDVI ............................................................................ 51 

3.2.2 Aplicação do SAVI ............................................................................ 53 

3.3 Classificação dos resultados ................................................................... 55 

3.3.1 Classificação ..................................................................................... 56 

3.3.2 Classificações por classes ................................................................ 57 

4.  CONSIDERAÇÕES FINAIS ...................................................................... 60 

5.  REFERÊNCIAS BIBLIOGRÁFICAS ......................................................... 62 

6.  ANEXOS .................................................................................................... 65 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1.  INTRODUÇÃO 

13 

A necessidade por informações sobre o planeta Terra é incessante, 

desta forma, obter essas informações é uma necessidade constante, mas isso 

só é possível de se obter de uma maneira geral, quando são vistas do espaço. 

Assim, o sensoriamento remoto se mostra eficaz e, por isso, ele tem tido uma 

infinidade de estudos nos últimos anos. Desta forma, o sensoriamento remoto é 

a área de estudo que oferece as condições de se obter informações que podem 

ser processadas de acordo com a finalidade do estudo. 

Diversas  áreas  aplicam  as  imagens  orbitais  como,  por  exemplo,  a 

agricultura, onde é possível fazer o acompanhamento das safras de determinada 

região ao longo dos anos, ou fazer previsões de safra de determinado ano. Outro 

exemplo são as aplicações em questões ambientas como, acompanhamento de 

queimadas,  detecção  de  foco  de  incêndio,  o  avanço  do  desmatamento,  as 

mudanças climáticas, entre outros. 

Assim,  há  a  necessidade  em  se  extrair  informações  a  partir  das 

imagens orbitais,  ou  seja, analisar as  informações  que  podem  ser  obtidas por 

meio  da  imagem  e  transformar  estas  informações  em  números.  Para  isso,  a 

matemática contribui com diversas ferramentas em que informações obtidas por 

meio das imagens são expressas em dados matemáticos, sendo mais simples e 

de fácil interpretação. 

Informações  semânticas,  que  são  as  vinculadas  ao  conhecimento 

cognitivo  (entender  a 

informação)  só  são  possíveis  depois  de  alguns 

processamentos  que  ocorrem  na  imagem.  Nesse  sentido,  o  processamento 

digital de imagem ganha a sua importância e entre as técnicas utilizadas existe 

a segmentação que pode ser realizada de forma contextual ou não. Na forma 

contextual, se desenvolve ferramentas para extrair a informação de interesse e 

neste  trabalho,  propõe-se  a  utilização  de  Índices  Espectrais  para  extrair  a 

informação  expressa  por  feições  não  antrópicas,  tais  como  vegetação,  por 

exemplo. 

 
 
 
 
 
 
14 

1.1 Justificativa 

A Matemática se constituiu ao longo dos anos como uma ferramenta 

presente no cotidiano das pessoas, seja na construção de abrigo ou demarcação 

de terras onde a geometria tem grande importância, ou ainda, a comercialização 

de  produtos  ou  serviços  em  que  a  aritmética  é  muito  utilizada.  O  ensino  da 

matemática  ao  longo  dos  anos  tem  passado  por  mudanças,  no  início,  a 

matemática se constituía pela disciplina, havia fórmulas para se decorar, porém 

com uso e origem desconhecidos. 

Com o avanço da tecnologia grande importância começou a ser dada 

para  a  história  da  Matemática,  que  além  de  ensinar  as  fórmulas,  a 

contextualização  histórica  passou  a  ter  grande  importância,  pois  assim,  os 

alunos  percebiam  a  matemática  como  uma  ciência  que  surgiu  a  partir  da 

necessidade do  homem  e  não  uma  ciência pronta e  acabada.  Desta forma,  a 

Matemática  começou  a  ser  compreendida  como  uma  ciência  em  constante 

evolução e, do ponto de vista dos alunos, ela passou a ser humanizada. 

Nos dias atuais, a contextualização histórica já não consegue por si 

só despertar no aluno o interesse pelo ensino da Matemática, assim o professor 

da  educação  básica  tem  o  desafio  de  buscar  mostrar  a  Matemática  para  os 

alunos de uma maneira mais prática e apresentar aos alunos uma aplicação do 

conteúdo que é ensinado em sala, de forma que tem se constituído como uma 

ferramenta para despertar o interesse do aluno pelo ensino da Matemática. 

Diante  deste  contexto,  ao  lecionar  em  um  curso  técnico  em 

informática,  percebeu-se  a  falta  de  relação  entre  as  disciplinas  ligadas  a 

Informática e a Matemática, onde alunos utilizam ferramentas matemáticas para 

programar,  mas,  não  conseguem  relacionar  estas  ferramentas  ao  que  se  é 

ensinado  nas  aulas  de  Matemática.  Desta  forma,  a  Matemática  fica  isolada 

sendo  que  ela  possui  a  possibilidade  de  interagir  com  as  demais  áreas  do 

conhecimento.  Então  surge  a  ideia  de  realizar  este  trabalho  que  mostra  a 

importância  da  Matemática  como 

ferramenta  e 

linguagem  para  o 

desenvolvimento  tecnológico  de  uma  área  em  franca  expansão  como  o 

Sensoriamento Remoto. 

 
 
 
1.2 Objetivos 

Os  objetivos  desse  trabalho  podem  ser  resumidos  segundo  os 

itens a seguir: 

15 

•  Discutir os principais conceitos sobre as imagens digitais; 

•  Mostrar os princípios básicos de Sensoriamento Remoto; 

•  Apresentar  as  plataformas  orbitais  que  são  utilizadas  no 

trabalho; 

•  Realizar  uma 

revisão  de  algumas 

ferramentas  do 

processamento digital de imagens; 

•  Discutir e justificar a utilização dos índices de vegetação, 

como  um  elemento  dentro  da  área  de  Sensoriamento. 

Remoto que podem ser utilizados de forma multidisciplinar; 

•  Realizar  um  experimento  com  aplicação  dos  índices  e 

posterior  classificação  nas 

imagens  das  plataformas 

indicadas. 

1.3 Estrutura do trabalho 

Este trabalho é dividido em quatro capítulos. Além deste primeiro, os 

outros capítulos seguem organizados da seguinte forma: 

No  segundo  capítulo  é  realizado  uma  revisão  de  conceitos 

importantes que se referem à imagem digital, bem como definição e conceitos 

de  sensoriamento  remoto  e,  por  fim,  algumas  ferramentas  importantes  do 

processamento digital de imagens são apresentadas. 

No capítulo três, é apresentado o método utilizado para a realização 

do trabalho, baseando-se na apresentação dos índices de vegetação que foram 

utilizados  nas  imagens  selecionadas,  terminando  com  uma  apresentação  dos 

resultados obtidos. 

O  quarto  e  último  capítulo  apresenta  as  conclusões  obtidas  com  o 

desenvolvimento  do  trabalho  e  as  propostas  para  elaboração  de  trabalhos 

futuros. 

 
 
 
 
 
2.  REFERENCIAL TEÓRICO 

16 

A  imagem  é  um  dado  de  entrada  e,  também,  o  resultado  final  de 

grande parte dos processos de representação da informação, neste sentido, o 

estudo  da  aquisição  (formação),  representação  (modelo  matemático)  e 

processamento  da  imagem,  serão  apresentados  nessa  seção.  O  primeiro 

enfoque a ser abordado será o matemático e sua aplicação para as técnicas de 

melhoramento  de  imagens,  baseando-se  no  modelo  de  representação  da 

imagem  e  sua  composição  no  espaço  de  cores  (composição  de  bandas).  O 

segundo item a ser abordado nessa seção será a aquisição das imagens, que 

para  este  trabalho,  serão  as  plataformas  orbitais  e  seus  sensores,  na  seção 

sobre  Sensoriamento  Remoto  e  por  último  uma  breve  revisão  das  principais 

técnicas de processamento digital de imagens serão apresentadas. 

2.1 Imagens Digitais  

A  era  digital,  essa  é  a  classificação  popularmente  atribuída  aos 

tempos que vivemos, o avanço da tecnologia nesse meio tem feito com que a 

sociedade perceba as facilidades desse progresso, bem como deseje interagir e 

usufruir desses recursos, nesse contexto está a imagem, considerada um dos 

recursos que mais se destaca, tendo em vista a democratização dos meios de 

aquisição, armazenamento e transmissão, seja como fotografias ou vídeos, com 

um  extraordinário  desenvolvimento  dos 

instrumentos  de  captura,  que 

possibilitam uma maior riqueza de detalhes e/ou resolução, permitindo que seu 

estudo tenha um grande destaque. 

Embora  existam  vários  modelos  matemáticos  para  a  descrição  de 

imagens,  neste  trabalho,  o  modelo  utilizado  será  o  espacial,  que  é  o  mais 

adequado  para  aplicações  de  processamento  digital  de  imagens  e  visão 

computacional (VELHO et al., 2009). 

Ainda  segundo  Velho  et  al.  (2009),  uma  imagem,  no  formato  não 

discreta, é uma função 

, onde 

 é um subconjunto do plano, e 

é um espaço vetorial. Importante ressaltar que, na maioria das aplicações, 

(cid:1): (cid:3) ⟶ (cid:5)

(cid:5)
 é 

(cid:8)

(cid:3) ⊂ (cid:7)

um retângulo do plano e 

(cid:3)
 é um espaço de cores. Para generalizar, considere 

(cid:5)

(cid:5)

 
 
 
 
 
 
 
como qualquer espaço vetorial, contendo o espaço de cor como um subespaço. 

A função 

 é chamada função de imagem. O conjunto 

 é chamado de suporte 

da imagem, e o conjunto de valores de 

(cid:1)

 (um subconjunto de 

(cid:3)

) é chamado de 

17 

conjunto de valores da imagem, ou valores das cores da imagem. 

(cid:5)

(cid:1)

Quando 

  é  um  espaço  de  cor  unidimensional  o  espaço  é, 

normalmente, chamado de espaço de tons de cinza ou monocromático em tons 

(cid:5)

de cinza. Dessa forma a imagem pode ser considerada, geometricamente como 

um gráfico 

 da função de imagem 

: 

(cid:9)((cid:1))

(cid:1)

(cid:9)((cid:1)) = (cid:13)((cid:14), (cid:16), (cid:17)): ((cid:14), (cid:16)) ∈ (cid:3) (cid:20) (cid:17) = (cid:1)((cid:14), (cid:16))(cid:21)

                (1) 

em que os valores de intensidade são considerados como altura 

 do 

gráfico para cada ponto 

 do domínio. 

(cid:17) = (cid:1)((cid:14), (cid:16))

Gonzalez  e  Woods  (2010),  simplificam  o  modelo  matemático  de 

((cid:14), (cid:16))

imagem, definindo-a como uma função 

, dada por 

, em que 

→ (cid:7)
 são as coordenadas espaciais do plano e 

(cid:1): (cid:7)

(cid:8)

e 

 é a amplitude de 

(cid:1)((cid:14), (cid:16)) = (cid:17)

, que pode 

(cid:14) 
ser definida como nível de cinza. Considerando que os valores de 

(cid:16)

(cid:17)

(cid:1)

, 

 e 

 são 

(cid:14)
finitos e discretos e a imagem pode, então, ser definida como digital. 

(cid:16)

(cid:17)

No  modelo  digital  a  representação  mais  comum  de  uma  imagem 

,  está  baseada  em  tomar  um  subconjunto  discreto 

  no 

(cid:8)

(cid:1): (cid:3) ⊂ (cid:7)
domínio  da  imagem  e  realizar  uma  amostragem  da  função 

⟶ (cid:5)

(cid:23)

⊂ (cid:3)
(cid:3)
  no  conjunto 

. 

Neste caso, a imagem 

 será definida como discreta, como consequência, 

(cid:3)′

(cid:1)

as coordenadas 

(cid:1)((cid:14), (cid:16))
 de cada ponto variam no conjunto 

 e dessa forma cada 

ponto 

 do subconjunto discreto 

((cid:14), (cid:16))

 é chamado, então de pixel (VELHO et 

(cid:3)′

al., 2009). 

((cid:14)(cid:25), (cid:16)(cid:25))

(cid:3)′

O  modelo  matemático  de  uma  imagem,  também,  pode  levar  em 

consideração o processo de aquisição/formação, uma vez que, atualmente, há 

diversos  instrumentos  capazes  de  capturar  imagens,  com  tecnologias  que 

permitem obter cada vez mais a riqueza de detalhes, tais como cor e iluminação, 

por exemplo, e resoluções cada vez mais refinadas.  

O princípio para obter uma imagem é antigo e sempre está baseado 

no processo de sensibilizar um sensor com entrada de luz, gerando um registro 

da  interação  da  radiação  eletromagnética  do  objeto  e  da  luz  (espectro 

 
 
 
 
 
 
 
18 

eletromagnético),  como  mostra  a  Figura  1,  que  é  um  modelo  simplificado  de 

captação de uma imagem por um sensor. 

Figura 1 – Princípio para obtenção de uma imagem (MENESES; ALMEIDA, 
2012) 

Segundo  Meneses  e  Almeida  (2012),  o  modelo  simplificado  para  a 

captação de uma imagem (Figura 1), tem os seguintes elementos bem definidos: 

energia  radiante  Q  é  a  energia  que  se  propaga  da  fonte  de  ondas 

eletromagnéticas  (Figura  1  –  (1))  e  é  medida  em  Joules  (J);  o  fluxo  radiante 

(Figura 1 – (2)) que é a taxa na qual a energia radiante é transferida de um ponto 

ou superfície para outra, medida em watts (W), a irradiância (Figura 1 – (3)) que 

é o fluxo radiante solar incidente na superfície do terreno e/ou objeto, medido em 

watts por metro quadrado (W/m2); e por fim a radiância (Figura 1- (4)) que é a 

medida feita pelo sensor da densidade de fluxo que deixa um elemento de área 

da  superfície  do  terreno  ou  objeto  e  se  propaga  em  uma  direção  definida 

(JENSEN, 2009). 

2.1.1 Aquisição e Modelagem de uma Imagem Digital 

Após  a  captura,  o  sensor  transforma  as  informações  obtidas  em 

imagem,  que  será  considerada  uma  função  de  intensidade  luminosa  de  duas 

dimensões 

, combinando uma fonte de iluminação (energia radiante) com 

o resultado da reflexão ou absorção de energia. Um modelo matemático de uma 

(cid:1)((cid:14), (cid:16))

imagem  com  os elementos  que  constituem  a  incidência e  a  reflexão  estão na 

Figura 2. 

 
 
 
 
 
 
Figura 2 – Representação de uma imagem digital com sua modelagem 
matemática 

19 

(cid:1)((cid:14), (cid:16)) = (cid:26)((cid:14), (cid:16)). (cid:28)((cid:14), (cid:16))

0 < (cid:26)((cid:14), (cid:16)) < ∞ (cid:20) 

0 < (cid:28)((cid:14), (cid:16)) < 1

0 < (cid:1)((cid:14), (cid:16)) < ∞

A aquisição da imagem depende do sistema sensor que está sendo 

utilizado para transformação de sinal físico para um sinal digital. O sistema de 

aquisição  transforma  a  energia  eletromagnética  em  uma  tensão,  por  meio  da 

combinação  da  energia  elétrica  de  entrada  e  o  material  do  sensor,  que  é 

responsável em detectar um tipo específico de energia. 

A  transformação  do  sinal  físico  para  um  sinal  digital  passa  pelos 

processos de amostragem, quantização e digitalização. 

2.1.1.1 Amostragem 

No  processo  de  amostragem,  a  representação  passa  do  contínuo, 

para  o  discreto.  É  nesse  processo  que  os  valores  das  coordenadas  serão 

digitalizados,  ou  seja, um  subconjunto discreto 

  no domínio  da  imagem 

será criado para realizar uma amostragem da função 

 no conjunto 

(cid:3)

⊂ (cid:3)

(cid:23)

. Assim a 

imagem 

 passa a ser definida em função de suas coordenadas discretas 

(cid:3)′

(cid:1)

 em que cada ponto é tomado no conjunto 

(cid:1)((cid:14), (cid:16))

 definindo a função imagem 

((cid:14)(cid:25), (cid:16)(cid:25))
como  

 do subconjunto discreto 

, criando o elemento básico da imagem, 

(cid:3)′

(cid:3)′
que é o pixel (VELHO et al., 2009), como pode ser verificado na Figura 3 a seguir. 

(cid:1)((cid:14)(cid:25), (cid:16)(cid:25))

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figura 3 – Exemplo do processo de amostragem – (a) Imagem no “contínuo” e 
(b) Imagem amostrada. Gonzalez e Woods (2010) 

20 

 2.1.1.2 Quantização 

O  processo  de  quantização  está  baseado nos  valores de  amplitude 

(resposta espectral do sinal) que serão digitalizados, ou seja, cada coordenada 

 terá um valor 

, que será atribuído a ele, de maneira que este 

((cid:14), (cid:16)),
valor  represente  este  pixel,  ou  seja,  cada  elemento  da  futura  matriz  será 

(cid:17) = (cid:1)((cid:14), (cid:16))

representado por um elemento de um conjunto finito de valores discretos. 

Figura 4 – Exemplo de uma quantização para uma imagem, com seu 
respectivo histograma de números de pixels para cada um dos percentuais de 
intensidades de tons de cinza do objeto em questão 

10

3

10

7

Valores Y

51

100

0

C I N Z A   8 0 % C I N Z A   6 0 % C I N Z A   5 0 % C I N Z A   3 0 %

B R A N C O

 
 
 
 
 
 
 
21 

2.1.1.3 Discretização 

Após a quantização, cada pixel precisa ser transformado em um valor, 

que é o chamado DN (Digital Number), sendo esse o processo definido como 

discretização. O valor definido é o resultado da função 

  e a mesma 

define o espaço necessário para armazenar uma imagem digitalizada. 

(cid:1)((cid:14), (cid:16)) = (cid:17)

Segundo  Velho  et  al.  (2009),  o  caso  mais  comum  de  discretização 

espacial de uma imagem consiste em tomar como domínio um retângulo 

(cid:3) = !", #$ × !&, ’$ = (cid:13)((cid:14), (cid:16)) ∈ (cid:7)

(cid:8)

: " ≤ (cid:14) ≤ # (cid:20) & ≤ (cid:16) ≤ ’(cid:21)

                                   (2) 

tais que os números reais positivos 

 e 

, compõem a escolha para discretizar 

o retângulo 

(cid:3)

 em um grid bidimensional 

Δ(cid:14)

Δ(cid:16)

               (3) 

*+(cid:14),, (cid:16)-. ∈ (cid:3): (cid:14), = /. Δ(cid:14), (cid:20)     (cid:16)- = 0. Δ(cid:14);   &23 /, 0  ∈ 45

A relação indicada na equação (3), é exemplificada na Figura 5, em 

que  cada  um  dos  pixels  (xj,  yk)  da  imagem  pode  ser  representado  pelas 

coordenadas inteiras (j, k). Dessa forma, a imagem pode ser representada na 

forma matricial por meio de uma matriz Amxn com entradas ajk = f(xj, yk), de modo 

que as entradas ajk representam os valores de f em um ponto do grid (xj,yk). 

No caso do espaço de cores, a cor do pixel com coordenadas (j, k), 

representa um vetor, de forma que para uma imagem monocromática, A = (ajk) 

é uma matriz real, sendo cada entrada um escalar que expressa a luminância do 

pixel correspondente. Os números 

 de linhas e 

 de colunas em 

 representam 

a resolução espacial da imagem (VELHO et al., 2009). 

3

6

7

 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Figura 5 – Representação de um grid uniforme para representação matricial de 
uma imagem (VELHO et al., 2009) 

22 

A  equação  (4)  a  seguir,  explicita  o  formato  de  representação 

matemático da imagem no seu formato matricial. 

0 < (cid:14) < 8 9 1     (cid:20)      0 < (cid:14) < : 9 1 

(cid:1)((cid:14), (cid:16)) = ;

(cid:1)(0,0)
(cid:1)(0,1)
⋮

(cid:1)(0,1)
(cid:1)(1,1)
⋮

…
…
⋮

(cid:1)(0, : 9 1)
⋮
⋮

(cid:1)(8 9 1,0) … … (cid:1)(8 9 1, : 9 1)

                                              (4) 

>

A resolução de uma imagem envolve vários fatores. Por exemplo, se 

existem  duas  imagens,  ambas  com  1024  x  1024  pixels,  a  que  representa  a 

menor área terá a melhor resolução e, desta forma, a qualidade da imagem não 

depende  apenas  da  quantidade  de  pixel,  mas  também,  da  dimensão  espacial 

que será imageada. 

Segundo  Velho  et  al.  (2009),  a  resolução  espacial  depende  do 

tamanho  do  pixel  e  do  dispositivo,  assim  a  medida  mais  apropriada  é  a 

densidade de resolução, que dá o número de pixels por unidade de comprimento. 

A unidade mais comum para a densidade de resolução é pixels por 

polegada (ppi), também conhecida como pontos por polegada (dpi). 

De forma geral, o fluxo de aquisição e modelagem de uma imagem 

digital para pode ser sintetizado na Figura 6 definido por Gattass (2017). 

 
 
 
 
 
 
 
 
 
 
Figura 6 – Fluxo de aquisição e modelagem de uma imagem digital 
(GATTASS, 2017) 

23 

2.1.2 Espaço de Cores  

Nesta seção será apresentada uma revisão dos principais conceitos 

referentes as cores em imagens digitais, tais como: Fundamentos da Cor e os 

principais  Modelos  de  Cores  utilizados  em  representações  e  processamentos 

digitais de imagens. 

2.1.2.1 Fundamentos de Cor 

Segundo Velho (2009), a presença ou ausência de luz é o que gera a 

sensação  de  cor.  No  entanto,  luz  é  um  fenômeno  físico  e  a  cor  depende  da 

interação da luz com o objeto de interesse, captada pelo aparelho visual.  

Existem vários modelos para representar a cor e o mais apropriado 

depende do contexto: um modelo que é válido do ponto de vista perceptual, por 

exemplo, pode produzir resultados imprecisos quando usado como um modelo 

computacional (VELHO et al., 2009). 

Um  sistema  receptor  físico  de  cores,  como  um  olho  humano  por 

exemplo, consiste de um número finito de sensores s1, s2, ..., sn, cada qual com 

sua  função  de  resposta  espectral 

.  Esta  função  fornece,  para  cada 

?(cid:25)(@)
comprimento de onda, o peso que a luz tem para cada um dos comprimentos de 

 
 
 
 
 
 
ondas. Assim, se um sistema é exposto à luz com distribuição espectral da cor 

, o sinal resultante é dado por n números (VELHO et al., 2009) 

24 

(cid:5)(@)

(cid:5)(cid:25) = AB(cid:5)(@)?(cid:25)(@)’@

    (5) 

Isaac  Newton  acreditava  que  o  olho  humano  possuía  infinitos 

sensores (células fotossensíveis), correspondentes às diferentes frequências do 

espectro visível. No entanto, no século XIX, o físico Thomas Young propôs, com 

base em experimentos, um modelo para o olho humano, definido como modelo 

tricromático. No modelo de Young, o olho humano possui apenas três tipos de 

células fotossensíveis, uma para as baixas frequências do espectro visível, uma 

para as frequências médias e outra para as altas frequências. Considerando a 

equação (5), o modelo de Young coloca o olho humano como um receptor de 

cor  com  três  sensores.  A  Figura  7  mostra  um  esboço  da  resposta  espectral 

destes sensores (VELHO et al., 2009). 

Figura 7 – Esboço da resposta espectral em função do comprimento de onda 
para o olho humano, segundo modelo de Young (VELHO et al., 2009) 

Considerando a teoria das três cores de Young, o espaço de cores do 

olho humano é um espaço vetorial tridimensional. As resistências iniciais deste 

modelo foram diminuindo com as várias experiências perceptuais realizadas por 

Maxwell e Helmholtz, fazendo com que Helmholtz apoiasse o modelo de Young, 

ficando conhecido como teoria de Young-Helmholtz. Essa teoria foi comprovada 

no início dos anos 1960, quando verificou-se que o olho humano possui, de fato, 

três tipos de células sensíveis à cor, como mostra a Figura 7. 

 
 
  
 
 
 
            
 
 
 
 
 
 
25 

De forma mais genérica, quando uma determinada cor é percebida, 

ela é resultado da radiação eletromagnética do comprimento de onda da faixa 

visível  do  espectro.  Considerando  que  o  olho  humano  tem  uma  sensibilidade 

para  as  três  cores  primárias  (azul,  verde  e  vermelho),  recebendo  radiações 

eletromagnéticas com diferentes comprimentos de onda, a produção das outras 

cores  são  combinações  destas.  Uma  Figura  do  espectro  eletromagnético 

destacando a parte do visível está na Figura 8. 

Figura 8 – Espectro eletromagnético com destaque para a faixa do visível 
(JENSEN, 2009) 

2.1.2.2 Modelos de Cores 

Como já foi visto na seção anterior, no século XIX, os físicos Young e 

Helmholtz1  introduziram  o  modelo  tricomático  (Red,  Green,  Blue  –  Vermelho, 

Verde, Azul). Este sistema é baseado nas células fotossensíveis do olho humano 

(Figura  9),  que  ao  receberem  uma  radiação  eletromagnética,  fazem  uma 

amostragem do espectro em três pontos distintos do espectro visível sendo uma 

amostra na faixa de baixa frequência (cor vermelha), outra amostra na faixa de 

médias frequências  (cor  verde)  e  a  outra  amostra,  na faixa  de  alta frequência 

(cor  azul).  Após  fazer  essas  amostras  do  espectro,  o  vetor  obtido  é  então 

processado e enviado ao cérebro (VELHO et al., 2009). 

1 Thomas Young (1773 – 1829); Hermann Ludwig Ferdinand von Helmholtz (1821 – 1894).  

 
 
 
 
 
 
 
                                                           
 
Figura 9 – Olho humano com os sensores (GONZALEZ e WOODS, 2010) 

26 

2.1.2.3 Sistema Padrão CIE-RGB 

O  sistema  padrão  CIE-RGB,  já  mencionado  anteriormente,  definido 

em 1931, define um espaço de cores tricromático (três cores), cuja base de cores 

primárias são as cores puras nas porções baixa, média e alta do espectro visível, 

ou seja, vermelho, verde e azul, respectivamente, e por isso abreviatura RGB. 

Assim  os  comprimentos  de  onda  destas  cores  são,  segundo  a  Comissão 

Internacional de Iluminação (CIE) de 

= 700mμ para o vermelho, 

= 546 mμ 

para o verde e 

= 435.8 mμ para o azul. A representação do espaço de cores 

@B

@C

RGB pode ser realizada pela Figura 10. 

@D

Figura 10 – Espaço de cores RGB 

 
 
 
 
 
A  linha  pontilhada,  indicada  com  uma  seta,  é  chamada  de  linha 

monocromática,  que  são  os  níveis  de  cinza  que  variam  do  preto  (0,0,0)  até 

27 

chegar no branco (1,1,1). 

2.1.2.4 Sistema CIE-XYZ 

Este  sistema,  estabelecido  em  1930  pela  CIE  utiliza  um  mapa 

(projeção  do  plano)  da  resposta  espectral  das  cores  para 

, 

  e 

. 

Neste  sistema,  que 

tem  como  objetivo 

refletir  os  valores  obtidos 

E(@)

(cid:9)(@)

(cid:7)(@)

experimentalmente e tabulados para a distribuição espectral das cores com base 

nas cores primarias, pode ser definida como: 

     (6) 

F(@) = ((cid:7)(@), (cid:9)(@), E(@))

Segundo  Velho  et  al.  (2009),  os  dois  extremos  do  mapa 

F(@)
representam as frequências nos limites do espectro visível, com o comprimento 

de onda mais longo representando o vermelho e o mais curto o azul. O segmento 

que  une  estes  pontos  contém  então  os  vários  tons  de  roxo,  obtidos  por 

interpolação de vermelho e azul. Uma vez que a imagem do mapa de cores 

F(@)
é composta de cores espectrais puras, então no limite do sólido de cor indicado 

na Figura 11. 

O  mapa 

  tem  sua  representação  definida  pelo,  chamado, 

diagrama  de  cromaticidade  do  sistema  de  cores  CIE-RGB,  sendo  este  uma 

F(@)

projeção do sólido para o plano Maxwell 

. 

(cid:14) + (cid:16) + (cid:17) = 1

 
 
 
 
   
            
 
 
 
 
 
 
 
Figura 11 – Diagrama de cromaticidade – plano de Maxwell (GOMES e 
VELHO, 1994) 

28 

Em Velho et al. (2009) é possível encontrar todo o desenvolvimento 

para conversão de um espaço de cor para outro, além dos outros espaços que 

existem na literatura para atender os dispositivos de impressão e/ou visualização 

de imagens digitais. 

2.1.3 Imagem Multiespectral 

Uma  imagem  multiespectral  consiste  de  uma  imagem  formada  por 

várias faixas do espectro eletromagnético. Para sua exibição, cada faixa é uma 

imagem e, normalmente é chamada, de banda. Cada uma das bandas é uma 

imagem em escala de cinzas (tons de cinza), ou em combinação destas bandas 

a  imagem  composta  ganha  características  de  cor.  A  interpretação  de  uma 

imagem  composta  exigirá  o  conhecimento  da  assinatura  de  reflectância 

 
 
 
 
 
 
espectral dos alvos na cena. Neste caso, o conteúdo de informação espectral da 

imagem é utilizado na interpretação. Detalhes adicionais sobre composição para 

imagens  multiespectrais  será apresentado  na  próxima  seção  que vai  tratar  de 

29 

sensoriamento remoto. 

2.2 Sensoriamento Remoto 

Nesta  seção  será  apresentada  uma  definição  de  Sensoriamento 

Remoto, bem como alguns conceitos importantes como: princípios de radiação 

eletromagnética,  algumas  plataformas  orbitais,  com  ênfase  nas  que  serão 

utilizadas  no  trabalho e,  por  último  a  representação  (composição)  de  imagens 

multiespectrais. 

2.2.1 Princípios Básicos 

Nos dias atuais, é indiscutível a importância no desenvolvimento de 

pesquisas, principalmente as que dizem respeito ao meio ambiente. Isso ocorre 

por diversos fatores, como, por exemplo, as mudanças climáticas que ocorreram 

nos últimos tempos.  

A necessidade por dados do meio ambiente de uma maneira global 

contribuiu  para  a  expansão  do  Sensoriamento  Remoto  (SR)  visto  que  existe 

diversos  enfoques  nos  quais  podem  ser  utilizados  a  coleta  de  dados  desta 

temática ainda, o campo de observação e análise é amplo e muitas vezes, a área 

estudada é extensa e assim, oportuniza a comparação e acompanhamento das 

consequências das modificações climáticas.  

Para tanto, SR pode ser definido como a maneira de se obter dados 

de  um  determinado  objeto  de  estudo  sem  tocá-lo.  De  uma  maneira  mais 

detalhada, conforme Jensen (2009), o SR é o registro da informação das regiões 

do espectro  eletromagnético,  sem  que  haja o  contato  com  o objeto,  utilizando 

instrumentos como câmeras instaladas em aeronaves ou satélites sendo que a 

análise destas informações obtidas é realizada de maneira visual ou então, por 

processamento digital de imagens. 

Assim, os instrumentos utilizados no SR são sensores que medem o 

resultado da interação da energia eletromagnética com o objeto, que pode ser 

 
  
 
 
 
30 

também uma área geográfica, em questão. Essa interação, como foi visto nas 

seções anteriores, é a parte refletida do espectro eletromagnético, além da parte 

absorvida.  Esta  medição  pode  ser  feita  a  uma  longa  distância,  por  sensores 

fixados em satélites orbitais. Os dados obtidos por estes sensores, possibilitam 

ser tratados de forma matemática assim, a análise destes dados bem como seu 

tratamento, baseiam-se em conceitos matemáticos. 

Os dados obtidos no SR podem ser analógicos ou digitais. Os dados 

digitais,  conforme  Jensen  (2009),  podem  ser  apresentados  em  forma  de  uma 

matriz, também chamada de raster, que podem ser apresentados em forma de 

uma  matriz  linear  ou  ainda,  como  uma  matriz  bidimensional,  bem  como  de 

valores de brilho obtidos por meio de um scâner. 

Para a representação destes dados, alguns termos são importantes 

de serem apresentados haja vista que são termos comumente utilizados no SR 

evitando assim, confusões e interpretações errôneas com termos utilizados no 

senso comum, segundo Jensen (2009), esses termos são: 

•  Informação  Espectral:  cada  objeto  possui  uma  informação 

de  quantidade  de  energia  eletromagnética  que  reflete,  emite  em 

frequências específicas devido a suas características físicas, biológicas e 

químicas; 

•  Resolução Espectral: é o número e o tamanho de intervalos 

de comprimento de ondas específicos no espectro eletromagnético que o 

instrumento de SR é sensível; 

•  Informação Espacial: cada pixel em uma imagem digital de 

sensoriamento  remoto  está  localizado  em  um  posição  específica  na 

imagem e associado com coordenadas x,y específicas no terreno. Depois 

de corrigida para uma projeção cartográfica padrão, a informação de cada 

pixel  permite  que  a  informação  oriunda  do  sensoriamento  remoto  seja 

utilizada com outros dados espaciais; 

•  Resolução Espacial: é a medida da menor separação linear 

entre  dois  objetos  que  pode  ser  determinada  pelo  sistema  de 

sensoriamento remoto; 

•  Informação  Temporal:  cada 

informação  coletada  no 

sensoriamento remoto é de um momento único. Um mesmo objeto pode 

 
31 

ser coletado várias vezes, mas, cada vez que se obtém uma nova coleta 

de informação é possível fazer um acompanhamento da evolução de um 

determinado fenômeno o que permite fazer previsões sobre determinados 

fenômenos;  

•  Resolução Temporal: é  a frequência  que o sensor  registra 

as imagens do objeto. 

2.2.2 Princípios de Radiação Eletromagnética 

A  radiação  eletromagnética,  depois  de  gerada,  se  propaga  na 

atmosfera  quase  que  na  velocidade  da  luz,  sendo  assim,  ela  pode  sofrer 

alterações  na  sua  velocidade,  comprimento  de  onda,  sua  intensidade  ou  sua 

distribuição espectral (JENSEN, 2009). 

Outras  características  importantes  devem  ser  apresentadas,  pois 

estas  interferem  no  resultado  do  sensoriamento  remoto.  Cada  uma  das 

características apresentadas a seguir, são importantes no resultado do SR.  

A radiação eletromagnética pode ainda, sofrer outras alterações como 

por exemplo, a refração onde há o desvio da direção. Ainda conforme Jensen 

(2009),  a  refração  ocorre  quando  a  radiação  eletromagnética  encontra 

substâncias  de  diferentes  densidades.  A  refração  acontece,  pois,  a  radiação 

eletromagnética, em meios diferentes, possui velocidades diferentes, ou seja, a 

velocidade  da  radiação  eletromagnética  depende  do  meio  pelo  qual  ela 

atravessa. Quanto maior a densidade do meio, mais lento é o deslocamento da 

luz neste meio.  

O índice de refração é uma razão entre velocidade da luz no vácuo e 

a velocidade da luz em uma substância, como a água, por exemplo. Assim: 

                (7) 

H

6 =

HI

onde: 

 = índice de refração; 

6
 = velocidade da luz no vácuo; 

= velocidade da luz em uma substância. 

&

&J

 
  
 
 
  
 
 
            
 
 
 
 
 
32 

Além  da  refração,  há  o  espalhamento,  que  é  similar  a  refração  e 

diferencia-se  pelo  fato  de  que  a  direção  associada  ao  espalhamento  é 

inesperada.  Conforme  Jensen  (2009),  há  três  tipos  de  espalhamento  e  são: 

espalhamento Rayleigh (molecular) que ocorre quando o diâmetro da matéria é 

muitas vezes menor que o comprimento de onda da radiação eletromagnética – 

a  maior  parte  deste  espalhamento  ocorre  de  2  a  8  km  acima  do  solo;  o 

espalhamento  Mie  (não-molecular  ou  partículas  de  aerossóis)  que  ocorre  em 

partículas esféricas de diâmetros com tamanho iguais ao comprimento de onda 

da energia incidente – ocorre nos 4,5 km inferiores da atmosfera; espalhamento 

não-seletivo onde todos os comprimentos de onda  são espalhados – ocorre nas 

porções mais baixas da atmosfera. 

A  absorção  é  quando  a  energia  radiante  é  absorvida  e  então, 

convertida  em  outra  forma  de  energia  e  esta,  pode  ocorrer  no  terreno  ou  na 

atmosfera. O intervalo de comprimento de onda do espectro eletromagnético no 

qual a energia radiante é absorvida por uma substância é chamada de banda de 

absorção. 

A refletância consiste no deslize da radiação eletromagnética em um 

objeto. Há vários tipos de superfícies refletoras conforme Jensen (2009) há: a 

reflexão  especular  –  quando  a  superfície  que  a  radiação  refletirá  é 

essencialmente lisa, ou seja, a altura média do perfil da superfície é menor que 

o  comprimento  de  onda  da  radiação;  reflexão  difusa  –  quando  a  superfície  é 

rugosa, ou seja, possui grande altura superficial. A Figura 12 mostra o resultado 

da reflectância nos comprimentos de ondas de diversos tipos de terrenos. 

 
 
 
 
 
 
 
 
 
 
 
Figura 12 – Reflectância em função dos comprimentos de ondas para diversos 
tipos de alvos (terrenos) de SR (JENSEN, 2009) 

33 

2.2.3 Plataformas Orbitais  

O desejo do homem voar não é algo novo, segundo Jensen (2009), 

desde a Grécia antiga é notável este desejo, como na história de Ícaro, que com 

asas de cera e pena, voou tão próximo ao Sol que estas derreteram e ele, Ícaro, 

caiu na Terra. Assim, desde a Grécia antiga o homem busca construir objetos 

capazes de fazê-lo voar. Os primeiros registros de objetos com esta finalidade 

são dos Ornitópteros, que datam desde 1010 até 1514. Já em 1783, foi inventado 

o balão de ar quente por Joseph e Etienne Montgolfier e, em 1858, Gaspard Felix 

Tournachon obteve a primeira fotografia aérea, capturada a bordo de um balão 

destes e nascia assim a Fotogrametria aérea. 

A dificuldade em manter o balão estável para capturar a imagem foi 

responsável  pelo  desenvolvimento  de  outros  métodos  para  obter  fotografias 

aéreas. Desta forma, o uso de câmeras aéreas presas a pipas para obtenção de 

fotografias aéreas datam de 1890. Com a construção do avião e com a primeira 

Guerra  Mundial,  a  necessidade  de  se  fotografar  o  campo  inimigo  a  bordo  de 

avião se tornou importante sendo, pelo menos, dois terços de toda informação 

militar  obtida  por meio  de fotografias  aéreas  (JENSEN,  2009).  Já na  segunda 

 
 
 
34 

Guerra  Mundial,  as fotografias  aéreas não  serviam  apenas  para  reconhecer o 

campo inimigo, mas também, para avaliar a destruição após bombardeá-los. 

Somente em 1957, com o lançamento do Sputnik, primeiro satélite a 

orbitar a Terra, que se deu início a programas de satélites de reconhecimento. 

Em  1959,  com  o  lançamento  do  projeto  Corona,  pelos  EUA,  possibilitou  a 

obtenção de imagens que depois de obtidas no espaço, retornavam a Terra em 

cápsulas, utilizando para este fim, paraquedas. 

Nesse  contexto,  diante  da  necessidade  constante  de  se  obter  mais 

dados e com melhor qualidade, desenvolveram tantos instrumentos de coleta de 

dados, sensores, como os satélites atuais. 

Apesar  de,  inicialmente,  as  imagens  aéreas  serem  amplamente 

utilizadas  como  informações  para  guerra,  percebeu-se  que  este  uso  poderia, 

também, ser aplicado a questões ambientais, planejamento urbano, prevenção 

de desastres entre outros. Assim, deu início o uso de plataformas espaciais de 

sensoriamento remoto. 

As  duas  plataformas  que  serão  utilizadas  neste  trabalho  são  a 

Landsat  8  e  o  CBERS  –  4,  assim  uma  breve  contextualização  dessas 

plataformas serão apresentadas a seguir. 

2.2.3.1 CBERS – 4 

O satélite CBERS – 4 é o quinto satélite do programa CBERS (China-

Brazil Earth Resources Satellite, Satélite Sino-Brasileiro de Recursos Terrestres), 

que  nasceu  de  uma  parceria  inédita  entre  Brasil  e  China  no  setor  técnico-

científico  espacial.  Com  essa parceria o  Brasil  passou  a  ter ferramenta,  muito 

importante, para monitorar seu território com satélites próprios de sensoriamento 

remoto. Segundo INPE (2017), a família de satélites de sensoriamento remoto 

CBERS  trouxe  avanços  importantes  para  o  Brasil,  no  monitoramento  ao  meio 

ambiente e recursos naturais com base em imagens CBERS. 

As  imagens  CBERS  são  importantes  aliadas  no  controle  do 

desmatamento e queimadas na Amazônia Legal, no monitoramento de recursos 

hídricos,  áreas  agrícolas,  crescimento  urbano,  ocupação  do  solo, entre  outras 

aplicações (INPE, 2017).  

 
 
 
35 

A carga útil do CBERS – 4 é composta de instrumentos diretamente 

relacionados com a aquisição dos dados científicos ou relacionados à missão do 

satélite 

(EPIPHANIO,  2011),  sendo  estes 

instrumentos,  uma  Câmera 

Pancromática  e  Multiespectral  (PAN),  uma  Câmera  Multiespectral  Regular 

(MUX), o Imageador Multiespectral e Termal (IRS), a Câmera de Campo Largo 

(WFI), além dos transmissores e gravadores que juntos compõem o sistema de 

coleta de dados. A tabela 1 resume as características dos sensores embarcados 

no CBERS – 4. 

Tabela 1 – Características dos sensores do CBERS – 4 (EPIPHANIO, 2011) 

Um  exemplo  de  imagem  tomada  pelo  sensor  MUX,  composição 

colorida do CBERS – 4 pode ser verificado na Figura 13. 

 
 
 
 
 
 
Figura 13 – Imagem do sensor MUX, composição colorida do CBERS – 4 
(INPE, 2017) 

36 

2.2.3.2 LANDSAT 8 

A série LANDSAT é a mais antiga série de dados de um programa de 

monitoramento terrestre  com base  em  imagens  orbitais.  A  série  teve  início  na 

segunda metade da década de 60, com a missão Earth Resources Technology 

Satellite  (ERTS),  passando  a  se  chamar  LANDSAT  (Land  Remote  Sensing 

Satellite) em 1975. O primeiro satélite, lançado em 1972 (ERTS-1 ou Landsat-

1), levou dois sensores a bordo: as câmeras RBV (Return Beam Vidicon) e MSS 

(Multispectral  Scanner  System).  Em  1975  e  1978,  com  os  mesmos  sensores, 

foram lançados os Landsat 2 e 3, respectivamente (NASA, 2013). 

O Landsat 4, lançado em 1982, foi o primeiro da série a contar, além 

do sensor MSS, com o sensor TM (Thematic Mapper), projetado para subsidiar 

pesquisas nas mais diversas áreas temáticas. Em 1984, dois anos mais tarde, 

entrou em órbita o Landsat 5, com os mesmos sensores. O MSS enviou dados 

até 1995, mas em contrapartida o sensor TM manteve-se ativo até novembro de 

2011, atingindo 28 anos de operação (NASA, 2013). Em 1993, o sexto satélite 

da série Landsat, projetado com o sensor ETM (Enhanced Thematic Mapper) e 

com  inclusão  da  banda  8,  pancromática,  que  tinha  15  metros  de  resolução 

espacial, não conseguiu atingir a órbita terrestre, devido à ocorrência de falhas 

no lançamento. Seis anos depois, em 1999 foi lançado ao LANDSAT 7, com o 

sensor ETM evoluído para o sensor ETM+ (Enhanced Thematic Mapper Plus). 

Este  instrumento  foi  capaz  de  ampliar  as  possibilidades  de  uso  dos  produtos 

LANDSAT. O L7 esteve operacional até 2003 e devido a problemas técnicos as 

 
 
 
37 

imagens  que  o  L7  continuam  gerando,  necessitam  de  correções  prévias  para 

suas aplicações (NASA, 2013). 

A série LANDSAT teve continuidade com o lançamento em 2013, do 

satélite LDCM (Landsat Data Continuity Mission), também, denominado Landsat 

8 que opera com os sensores OLI (Operational Land Imager) e TIRS (Thermal 

Infrared  Sensor).  O  sensor  OLI  tem  a  função  de  garantir  a  continuidade  dos 

produtos  gerados a partir  dos  sensores TM  e ETM+,  a bordo das  plataformas 

anteriores,  além  de  incluir  duas  novas  bandas  espectrais,  uma  projetada para 

estudos de áreas costeiras e outra para detecção de nuvens (NASA, 2013). 

Um exemplo de imagem utilizando o sensor OLI do satélite Landsat 

8, na composição multiespectral pode ser verificado na Figura 14. 

Figura 14 – Exemplo de uma imagem Landsat 8, sensor pancromático com 
composição RGB 

A descrição das bandas dos sensores OLI (Operational Land Imager) 

e TIRIS (Thermal Infrared Sensor) do Landsat 8 estão na tabela 2. 

 
 
 
 
 
 
 
 
 
 
Tabela 2 – Bandas dos sensores do Satélite Landasat 8 (NASA, 2013) 

38 

2.3 Processamento de Imagens Digitais 

Após obter a imagem, o segundo passo em um processo de extração 

da  informação  é  correção  e/ou  melhora  da  imagem.  Isso  é  necessário  por 

motivos  que  vão desde  problemas  na aquisição,  transmissão e  representação 

da  imagem,  até  o  processo  de  extração  de  informação  que  precisa  de  certas 

características  da  imagem  que  não  estão  explicitas.  Assim  o  processo  de 

correção e/ou melhoria é definido como Processamento Digital de Imagens.  

As correções das imagens, normalmente, geram melhorias na mesma 

de  forma  que,  a  informação  disponível  na  imagem  possa  ser  utilizada  para  o 

propósito  específico.  No  entanto,  pode  ocorrer  a  necessidade  de  processar  a 

imagem  para  evidenciar  uma  determinada  informação,  como  os  índices 

espectrais, por exemplo. Dessa forma esse texto vai tratar, tanto o processo de 

correção  como  o  de  evidenciar  uma  determinada 

informação,  como 

Processamento Digital de Imagens (PDI). 

Um  processamento  pode  ser  realizado  no  domínio  espacial  ou  no 

domínio  da 

frequência.  Processamentos  no  domínio  de 

frequência, 

normalmente,  são  baseados  em  transformadas  de  imagens.  A  transformada 

mais comum utilizada em PDI é a transforma de Fourier da imagem original. Por 

outro  lado,  o  aprimoramento  do  domínio  espacial  envolve  a  manipulação  dos 

pixels  em  uma  imagem  a  partir  do  próprio  plano  da  imagem  que  serão  os 

processos abordados nesse trabalho. 

 
  
 
39 

Existe  na  literatura  muitos  algoritmos  e  ferramentas  para  a  área  de 

PDI. No entanto esse trabalho se restringirá aos principais deles, de forma que 

os  mesmos  possam  ser  aplicados  em  imagens  orbitais  que  é  o  objeto  de 

processamento desse trabalho. 

2.3.1 Processamento de Imagens Baseado em Histograma 

Considerando  uma  imagem  digital  em  escalas  de  cinza  com 

8 (cid:14) :
pixels, em que cada pixel possui um valor na escala de cinza, então é possível 

obter  uma  representação  da  imagem  com  base  no  seu  Histograma,  que  é  o 

gráfico  com  a  distribuição  dos  seus  valores  de  tons  de  cinza  e  no  eixo  das 

abscissas e sua respectiva quantidade de pixels que a imagem contém com cada 

tom  nas  ordenadas  (CRÓSTA,  1992).  O  histograma  é  uma  das  formas  mais 

utilizadas  para  representar  a  distribuição  dos  Números  Digitais  (DN  –  Digital 

Number) de uma imagem, bem como na etapa de PDI. 

Figura 15 – Bandas R, G e B da imagem CBERS – 4 com seus respectivos 
histogramas 

(a)                                                     (b)                                                     (c) 

        (d)                                                      (e)                                                     (f) 

A Figura 15 contém os histogramas para cada uma das bandas R, G 

e B da imagem CBERS – 4 indicada na Figura 13. No PDI o histograma pode 

ser utilizado para mudanças nas intensidades dos tons de cinza. Esse processo 

é  chamado  de  transformações  de  intensidades.  A  Figura  16  mostra  uma 

 
 
 
 
 
 
 
 
  
  
 
 
  
  
 
 
40 

mudança  para  a  imagem  da  banda  R  da  CBERS  –  4  (Figura  15  –  a).  Nesta 

imagem o ajuste realizado é denominado de equalização do histograma. 

Figura 16 – Exemplo de uma transformação de intensidade no histograma – 
Equalização do Histograma 

A equalização do histograma é uma das várias formas de realizar a 

transformação de intensidade em uma representação baseada em histograma. 

De maneira simples uma transformação de intensidade pode ser expressa por: 

? = K((cid:28))

em que 

 e 

 são variáveis que indicam a intensidade de 

 (imagem de entrada) 

      (8) 

e 

(cid:1)

 (imagem de saída) em qualquer ponto 

?

(cid:28)

. 

L

((cid:14), (cid:16))
Segundo Gonzalez e Woods (2010) o operador de transformação 

pode ser: 

K

- Operador de Alargamento de contraste: 

? = KM((cid:28)) =

(MN(-/P)

Q

M

,                                                                                          (9) 

sendo 

, 

, fatores de ajuste da função. 

0

R

 
 
 
 
 
 
 
 
 
 
            
 
 
 
 
 
 
 
 
 
 
 
- Limiarização: 

0 ?(cid:20) (cid:28) (cid:30) 0
1 ?(cid:20) (cid:28) T 0

? = K(cid:8)((cid:28)) = S

41 

                                              (10) 

Esses operadores têm seus gráficos indicados na Figura 17 a seguir: 

Figura 17 – Operadores de transformações T1 e T2, com seus respectivos 
gráficos (GONZALEZ e WOODS, 2010) 

Ainda,  em  Gonzalez  e  Woods  (2010),  é  possível  encontrar  várias 

outras 

funções  de 

transformações, 

tais  como:  negativos  de 

imagens, 

transformações 

logarítmicas, 

transformações 

de 

potência 

(gama), 

transformações lineares definidas por partes, entre outras.  

De forma geral, o processamento baseado em histograma utiliza um 

princípio de que toda imagem possui um contraste podendo ser alto, médio ou 

baixo.  Analisando  o  seu  histograma  o  processo  a  ser  utilizado  vai  modificar  o 

contraste, concentrando em uma determinada região ou espalhar para obter a 

melhor forma de extrair da imagem a informação necessária. O melhoramento 

do contraste em uma imagem possibilita deixar mais nítida algumas informações 

que só podem ser obtidas por análise possível se o contraste está adequado. A 

Figura 18 apresenta essa diferença para o contraste (CRÓSTA, 1992). 

 
 
 
 
            
 
 
 
 
 
 
 
 
 
 
Figura 18 – Exemplo de uma imagem com contrastes, baixo, normal e alto 

42 

2.3.2 Processamento de Imagens Baseado em Filtragem 

Ao analisar uma imagem, é comum constatar vários “defeitos”, o que 

chama-se  de  ruídos  na  área  de  imagem.  Os  ruídos  podem  dificultar  a 

interpretação  de  informações  contidas  na  imagem,  então  existem  técnicas 

específicas  para  corrigir  esses  “defeitos”  na  imagem  que  são  as  técnicas  de 

filtragem. 

Na técnica de filtragem e o processamento digital de imagem também 

se divide em: filtragem no domínio da frequência, baseando-se em um processo 

conhecido  como  convolução,  com  modelo  matemático  bem  definido  para  ser 

aplicado nas transformadas de imagem, que tem na transformada de Fourier a 

sua  mais  conhecida;  e  a  filtragem  no  domínio  espacial,  que  também  tem  um 

processo que modela a convolução no domínio do espaço, mas baseando-se em 

máscaras  que  são  submatrizes  com  valores  aproximados  dos  processos 

necessários. 

Os filtros de convolução, tanto no domínio da frenquência, quanto no 

domínio do espaço, se dividem em três tipos básicos: os filtros passa baixas, os 

passa altas e os filtros passa bandas (CRÓSTA, 1992). No caso do domínio do 

espaço existem os filtros direcionais. 

Os filtros passa altas são responsáveis pelo processo de enfatizar as 

chamadas  altas  frequências,  assim  tornam  mais  nítidas  as  transições  entre 

regiões diferentes, conhecidas como bordas dos objetos. Um efeito indesejável 

 
 
 
 
 
43 

desses  filtros  é  o  de  enfatizar  o  ruído  presente  na  imagem  (MENESES; 

ALMEIDA, 2012). 

Os filtros passa baixas, tem uma situação contrário aos passa altas, 

e tendem a eliminar as altas frequências espaciais, gerando uma suavização na 

imagem.  Uma  vez  que  as  altas  frequências  correspondem  às  transições 

abruptas,  ao  atenuá-las,  a  suavização  tende  a  minimizar  o  efeito  do  ruído  na 

imagem (MENESES; ALMEIDA, 2012). 

Os filtros espaciais, que serão os abordados nesse trabalho podem 

ser baseados em operações definidas como pixel a pixel, ou de vizinhança dos 

pixels. Nas operações definidas como pixel a pixel, o resultado é a substituição 

do pixel por um processo baseado somente nele, tais como as transformações 

de intensidades no processamento baseado em histograma. 

Nos  filtros  espaciais  que  operam  com  base  na  vizinhança,  os 

resultados ocorrem para um conjunto de pixels tomados sempre em função de 

uma  máscara  que  define  o  operador  e  tipo  de  operação  em  questão.  Esses 

normalmente,  são  baseados  operadores  matemáticos  que  procuram  por 

descontinuidades nas imagens (bordas). 

Os  primeiros  e  mais  simples  são  os  operadores  baseados  em 

gradientes.  Assim  tomando  a  imagem  com  uma  superfície,  o  vetor  gradiente 

definido por: 

f
=∇


f
∂

x
∂

f
∂


y
∂









    (11) 

Tem um formato discreto dado por d1 na direção 135° e d2 na direção 45°: 

∇

),(1
yxfd

=

),(
yxf

−

(
xf

+

,1

y

+

)1

,  

∇

),(
yxfd

2

=

,(
yxf

)1
−+

(
xf

+

),1
y

    (12) 

    (13) 

 
 
 
 
 
            
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
44 

Esse operador é conhecido como o gradiente de Roberts (2x2). Um 

resultado  de  sua  aplicação  pode  ser  verificado  na  Figura  19  (GONZALEZ  E 

WOODS, 2010).  

Figura 19 – Detector de bordas de Roberts (2x2); (a) Imagem original; (b) 
Bordas detectadas (GONZALEZ e WOODS, 2010) 

(a)                                               (b) 

De  forma  mais  ampla,  a  teoria  sobre  detectores  de  bordas  é  um 

capítulo à parte no processamento digital de imagens. Uma boa revisão pode ser 

encontrada em (GONZALEZ e WOODS, 2010), pois aqui o assunto foi tratado 

de forma bem resumida apenas para mostrar sua capacidade, uma vez que não 

será útil neste trabalho. 

2.3.3 Processamento de Imagens Baseado em Aritmética de Bandas 

Segundo Meneses e Almeida (2012), a aritmética de bandas é a forma 

mais  simples  para  realizar  o  processamento  de  imagens,  com  resultados  que 

podem  ser  bastante  expressivos.  A execução  de operações matemáticas, tais 

como  soma,  subtração,  multiplicação  e  divisão,  de  forma  simples  é  a  maior 

vantagem do uso de imagens multiespectrais no processamento de imagem. 

Com esse tipo de processamento é possível, por exemplo, suavizar 

imagens ruidosas ou obter realces de toda uma área da imagem, ou então, de 

um alvo específico de forma bastante rápida. Através das operações aritméticas, 

um  processamento  é  realizado  a  partir  de  combinações  de 

imagens, 

transformando  os  dados  de  entrada  em  uma  nova  imagem  completamente 

distinta (MENESES; ALMEIDA, 2012). 

 
 
 
 
 
 
 
45 

Nesse  tipo  de  processamento,  o  processo  de  transformação  é 

executado  pixel  a  pixel  por  meio  de  uma  regra  matemática  pré-definida, 

envolvendo  pelo  menos,  duas  bandas  do  mesmo  sensor  ou  até  mesmo,  a 

mesma  banda,  porém,  em  datas  de  aquisição  diferentes.  Um  modelo  desse 

processo pode ser verificado na Figura 20. 

Figura 20 – Modelo de operação aritmética executada pixel a pixel em uma 
imagem multiespectral (MENESES; ALMEIDA, 2012) 

Ainda segundo Meneses e Almeida (2012), as operações de uso mais 

comuns, para o processamento de imagens baseado na aritmética de bandas, 

são  a  divisão  e  a  subtração,  com  reduzidas  aplicação  para  as  operações  de 

soma e  multiplicação. Mais  detalhes  sobre o  processamento de  imagens  com 

base  na  aritmética  de  bandas  para  as  operações  e  suas  aplicações, 

principalmente em Sensoriamento Remoto podem ser encontradas em Meneses 

e Almeida (2012). 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3.  MÉTODO PROPOSTO  

46 

O método proposto para realizar esta pesquisa, passa por três etapas 

complementares:  a  revisão  teórica  dos  principais  índices  espectrais  utilizados 

em  Sensoriamento  Remoto;  seguido  de  uma  aplicação  dos  principais  índices 

para  definir  a  área  verde  do  munícipio  de  Sinop  –  MT,  nas  imagens  MUX  do 

CBERS – 4 e OLI do Landasat 8; e por último a realização de uma classificação 

dos  resultados.  No  final  do  processo  essa  metodologia  pretende  mostrar  a 

potencialidade dessas  ferramentas,  não para  Sensoriamento  Remoto onde  as 

mesmas  já  são  consolidadas,  mas  sim  para  o  ensino  de  Matemática, 

considerando  a  característica 

interdisciplinar,  peculiar  que  a  área  de 

Sensoriamento Remoto possui. 

3.1 Índices Espectrais em Sensoriamento Remoto 

O principal processo no processamento digital de imagens, segundo 

(GILABERT  et  al.,  2002)  é  a  segmentação  eficiente  da  imagem,  que  é  um 

importante  passo  em  muitas  aplicações  na  análise  de  imagens,  como  por 

exemplo, na identificação de áreas com vegetação e, consequentemente, áreas 

definidas  como  não  antrópicas  (ZANIN  e    DAL  POZ,  2003).  Nesse  sentido, 

segundo (HUETE et al., 1994), os índices espectrais são fundamentais. 

Um  índice  espectral  é  o  resultado  de  operações  matemáticas  entre 

valores  numéricos  de  pixels  das  bandas  de  uma  imagem.  As  operações 

matemáticas, tratadas como combinações de reflectância superficial em dois ou 

mais  comprimentos  de  onda,  devem  definir  uma  abundância  relativa  das 

características de interesse. 

Os índices de vegetação são os índices espectrais mais utilizados na 

área  de  Sensoriamento  Remoto,  sendo  utilizados  desde  a  década  de  1970. 

Estes índices têm uma ampla gama de aplicações tais como: monitoramento de 

vegetação, modelagem hidrológica; atividades agrícolas e estudos vinculados a 

 
 
 
 
 
47 

variações  sazonais  da  ecologia  da  paisagem  dentre  outros  (VERSTRAETE  e 

PINTY, 1996). 

Em  geral,  vegetações  saudáveis  são  muito  bons  absorventes  de 

energia eletromagnética na região visível. Esta absorção é reduzida e a reflexão 

aumenta,  no  limite  vermelho/infravermelho,  perto  de  0,7  μm.  Dessa  forma  a 

reflectância  é  quase  constante  de  0,7-1,3  μm  e  depois  diminui  para  os 

comprimentos  de  onda  mais  longos.  O  comportamento  das  curvas  de 

reflectâncias  (absorção  e  reflexão)  para  o  solo,  a  vegetação  e  água  está  na 

Figura 21. 

Figura 21 – Curvas de reflectâncias em função dos comprimentos de ondas 
para solo, vegetação e água (ZHANG e ZHANG, 2016) 

Os índices de vegetação devem garantir indicadores numéricos para 

quantificar  a  vegetação  presente,  tais  como  percentual  de  cobertura  e 

quantidade  de  biomassa,  por  exemplo.  Os  índices  de  vegetação  devem, 

também, reduzir o efeito atmosférico e topográfico, se possível. 

Segundo Bannari et al. (1995), mais de quarenta índices de vegetação 

foram  desenvolvidos  nas  últimas  duas  décadas,  na  área  de  sensoriamento 

remoto. No trabalho de Bannari et al. (1995), é apresentado uma tabela com um 

 
 
 
48 

resumo  cronológico  da  maioria  dos  índices  de  vegetação  encontrados  na 

literatura. 

Pearson e Miller (1972) são pioneiros nos índices de vegetação, pois 

desenvolveram  as  duas  primeiras  formas  de  índices  de  vegetação:  o  “Ratio 

Vegetation  Index”  (RVI)  e  o  "Vegetation  Index  Number"  (VIN),  para  estimar  o 

monitoramento de coberturas de vegetação, indicados nas equações (14) e (15). 

(cid:7)UV =

UV: =

B

WXB

WXB

B

    (14) 

    (15) 

onde R é a reflectância no canal vermelho e NIR é a reflectância no infravermelho 

próximo.  

Figura 22 – Percentual de reflectância em função dos comprimentos de ondas 
para vários tipos de vegetação (GIBSON, 2000) 

Esses  índices  aumentam  o  contraste  entre o  solo  e  a  vegetação,  e 

segundo Baret e Guyot (1991), são menos afetados pelo efeito das condições 

 
 
 
 
 
 
 
            
 
 
 
 
 
 
 
 
 
            
      
 
 
 
49 

de  iluminação,  no  entanto  são  sensíveis  às  propriedades  do  solo  frente  aos 

sensores. Esse contraste pode ser verificado na diferença que os vários tipos de 

vegetação têm para as bandas vermelha e infravermelho próximo, como indica 

a Figura 22. 

A primeira versão do Índice de Vegetação da Diferença Normalizada 

(NDVI), foi proposta por Rouse et al. (1974). O NDVI é um dos principais índices 

utilizados  na  literatura  para  destacar  a  vegetação  em  uma  imagem  de 

Sensoriamento Remoto. Este índice, também, utiliza a relação entre as bandas 

vermelha  e  o  infravermelho  próximo  destacando  a  vegetação  do  restante  da 

imagem (HUETE et al. 2002). 

Como  a  energia  refletida  na  banda  vermelha  diminui  com  o 

desenvolvimento da planta (processo de absorção de clorofila na folha) e, por 

outro  lado,  a  energia  refletida  na  banda  infravermelho  aumenta  com  o 

desenvolvimento  da  planta  (processo  de  dispersão  em  folhas  saudáveis),  o 

índice  NDVI  (Normalized  Difference  Vegetation  Index)  consiste  na  diferença 

normalizada entre dois canais, como indica a equação (16): 

NDVI

=

NIR

ρρ
−
ρρ
+

NIR

RED

RED

    (16) 

em que 

REDρ  e  NIRρ  são os valores para as medidas de reflectância do vermelho 

e do infravermelho próximo, respectivamente. 

O NDVI varia de valores próximos a 0 em áreas áridas ou estéreis, 

até valores próximos a 1 em áreas de vegetação densa. Os valores negativos do 

NDVI geralmente correspondem a áreas urbanas e os muito próximos de -1 são 

atribuídos aos  corpos d’água. Isso ocorre por  causa  da  baixa  reflectância  dos 

corpos d’água na banda do infravermelho próximo, como pode ser verificado na 

Figura 21 (HUETE et al. 2002). 

Huete (1988) desenvolveu um novo índice de vegetação denominado 

índice de vegetação ajustada ao solo (SAVI - Soil Adjusted Vegetation Index). A 

originalidade  desse  índice  está  no  modelo  simples  que  permite  descrever 

adequadamente a relação entre o solo e a vegetação. O SAVI pode ser definido 

pela seguinte equação (17). 

 
   
 
 
 
 
 
 
 
Nessa equação, o acréscimo do fator L permite um ajuste de correção 

do efeito de brilho do solo na imagem. Os valores de L que podem ser utilizados 

são:  1  (densidade  de  vegetação  baixa);  0,5  (densidade  de  vegetação  média); 

0,25 (densidade de vegetação alta). Desta forma, este índice é expresso pela 

50 

seguinte equação: 

Y7UV =

(Z[\]^Z]Q_)
(‘NZ[\]NZ]Q_)

(1 + a) 

    (17) 

Se o valor de a for zero (a =

, o SAVI é igual ao NDVI, e apresenta 

0)
vantagem  de  descrever  as  mudanças  na  cobertura  de  vegetação  do  solo, 

independentemente do tipo de sensor utilizado. 

De  forma  geral  existem  vários  índices  espectrais,  para  várias 

aplicações.  Estes  índices  variam  quanto  a  fórmula,  os  sensores  e  as  bandas 

utilizadas.  Uma  revisão  ampla  sobre  os  índices  e  suas  aplicações  pode  ser 

encontrada em Bannari et al. (1995). 

3.2 Aplicação dos Índices Espectrais 

Para aplicar os índices espectrais nesse trabalho, utilizou-se imagens 

de dois satélites: Landsat 8 e CIBER 4, e seus, respectivos sensores OLI e MUX. 

As imagens obtidas são da cidade de Sinop – Mato Grosso, obtidas por meio do 

site do INPE2, mas, para realizar o estudo, estas imagens foram recortadas com 

base no shapefile da área urbana. 

De cada sensor foi escolhida uma imagem, do Landsat 8 com data de 

13 de abril de 2017 e do CBERS – 4, data de 9 de abril de 2017. A escolha das 

datas das imagens foi aleatória levando em consideração o menor percentual de 

nuvens do período. Para aplicar os índices foram utilizadas as bandas vermelho, 

infravermelho próximo. 

Para realizar o cálculo dos índices de vegetação, as imagens passam 

por  um  processo  de  calibração  radiométrica  através  de  processamentos, 

divididos  em  duas  etapas.  A  primeira  é  o  cálculo  de  radiância  das  bandas 

2 www.dgicatalogo.br 

 
 
 
 
 
            
 
 
 
 
                                                           
51 

utilizadas, ou seja, a vermelha (red) e o infravermelho próximo (NIR). O cálculo 

consiste da conversão dos valores de cada um dos pixels (Números Digitais – 

ND)  em  grandezas  de  radiância  espectral  no  topo  da  atmosfera  (MENESES; 

ALMEIDA, 2012), conforme (18). 

ab = 8‘cHde + 7‘

Onde 

 é a radiância espectral no topo da atmosfera; 

 é o fator 

multiplicativo da radiância para a banda específica; 

ab

 é o ND do pixel e 

8‘

 o 

              (18) 

fator aditivo da radiância para a banda específica (MENESES; ALMEIDA, 2012). 

cHde

7‘

Após a conversão das imagens para valores de radiância espectral, 

as  mesmas  ainda  foram  submetidas  ao  cálculo  de  reflectância  no  topo  da 

atmosfera e isso se faz com a equação (19). 

                         (19) 

fb = 8ZaZ + 7Z

Sendo 

  a  reflectância  no  topo  da  atmosfera,  sem  a  correção  de 

ângulo solar; 

fb

 o fator multiplicativo da reflectância para as bandas específica; 

8Z
  a  radiância  espectral  e 

  o  fator  aditivo  da  reflectância  para  a  banda 

aZ
específica (MENESES; ALMEIDA, 2012). 

7Z

Para  a  manipulação  das  imagens  foi  o  utilizado  o  software  QGis3 

aplicada para o conjunto de imagens segundo os resultados a seguir, para os 

respectivos índices espectrais. 

3.2.1 Aplicação do NDVI 

Para  as  imagens  com  as  datas  indicadas  na  seção  anterior,  dos 

referidos sensores (OLI – Landsat 8 e MUX – CBERS – 4) aplicou-se a equações 

(18) e (19) para as bandas vermelhas (red) e infravermelho próximo (NIR). Com 

3  Software  open  source  multiplataforma  de  sistema  de  georreferenciamento (GIS)  que  provê 
visualização, edição e análise de dados georreferenciados. 

 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
                                                           
52 

os resultados de reflectância para as bandas, então se aplica a equação para o 

cálculo do NDVI (equação (16)) obtendo os resultados indicados a seguir. 

Figura 23 – Resultado da aplicação do NDVI na imagem Landsat 8, para o 
recorte da área urbana de Sinop, com imagem tomada em 13/04/2017 

Na  Imagem  Landasat  8,  de  13  de  abril  de  2017,  o  resultado  da 

aplicação do NDVI gerou, para o recorte da área urbana de Sinop a Figura 23. 

Importante chamar atenção para a escala do NDVI, nesta imagem e os valores 

que a mesma indica, sendo 0,113 o valor mais baixo do NDVI, indicando regiões 

com pouca vegetação e os maiores valores na escala (0,495) que indicam as 

áreas com maior incidência de cobertura vegetal. 

 
 
 
 
 
 
 
 
Figura 24 – Resultado da aplicação do NDVI na imagem CBERS – 4, para o 
recorte da área urbana de Sinop, com imagem tomada em 09/04/2017 

53 

O resultado dos mesmos processos aplicado par a imagem CBERS – 

4 de 09 de abril de 2017, gerou os resultados de NDVI em uma escala que vai 

de  -0,034  até  0,694,  sendo  o  menor  valor  (-0,034)  a  indicação  de  menos 

cobertura de vegetação e o valor de 0,694, a indicação das regiões com maior 

área de cobertura vegetal, como pode ser verificado na Figura 24. 

3.2.2 Aplicação do SAVI 

Considerando  a  ampla  utilização  e  aceitação  do  NDVI,  na 

comunidade científica, no trabalho de Huete (1988), ficou claro que este pode 

não ser um indicador de cobertura de vegetação, considerando as condições da 

vegetação em áreas semiáridas ou áridas, por exemplo, e assim é proposto o 

SAVI  (seção  3.1).  Nesse  sentido,  considerando  que  o  SAVI  tem  o  mesmo 

 
 
 
 
 
54 

intervalo  de  variação  que  o  NDVI,  ou  seja  [-1,1],  é  possível  verificar  nos 

resultados a seguir como o comportamento deste índice mudo o resultado nas 

implicações propostas para este trabalho. 

Na imagem do recorte da área urbana de Sinop, do sensor Landsat 8, 

o  resultado  dos  processos  indicados  na  seção  3.1,  mas  agora  como  índice 

espectral SAVI com L = 0,5 (Vegetação média) a escala obteve valores que vão 

de 0,154 a 0,938, sendo o valor de 0,154 a região com menos cobertura vegetal 

e  0,938  a  região  com  cobertura  vegetal  mais  intensa.  Este  resultado  é 

apresentado na Figura 25. 

Figura 25 – Resultado da aplicação do SAVI com L=0,5 na imagem Landsat 8, 
para o recorte da área urbana de Sinop, com imagem tomada em 13/04/2017 

Os resultados de aplicação do SAVI na imagem CBERS – 4, utilizada 

neste  trabalho  seguem  a  mesma  tendência  que  os  encontrados  na  imagem 

Landsat  8,  ou  seja,  a  escala  dos  resultados  aumenta,  sendo  de  -0,0278  até 

 
 
 
 
55 

0,798, o que mostra uma variação maior nas medidas da cobertura da vegetação 

na área urbana da cidade de Sinop. 

Figura 26 – Resultado da aplicação do SAVI com L=0,5 na imagem CBERS – 
4, para o recorte da área urbana de Sinop, com imagem tomada em 
09/04/2017 

3.3 Classificação dos resultados 

Nesta  seção  os  resultados  encontrados  na  seção  anterior  serão 

classificados, segundo o método distância mínima (aplicação do QGIS), e assim 

as classes pré-definidas para avaliar qualitativamente o uso e cobertura do solo 

na  área  urbana  do  município  de  Sinop  poderão  ficar  mais  explícitas.  Na 

apresentação do método utilizado para realizar a classificação, bem como, nos 

 
 
 
 
 
resultados obtidos, o trabalho sempre fará menção ao carácter multidisciplinar 

que  a  aplicação  dos  índices  espectrais  pode  ter,  principalmente  na  educação 

56 

básica. 

3.3.1 Classificação  

Entre  os  principais  objetivos  do  Sensoriamento  Remoto,  está  a 

extração  das  informações  contidas  em  uma  imagem,  de  tal  forma  que  estas 

possam  ser  apresentadas  em  forma  de  tabelas,  gráficos  e/ou  mapas 

(MENESES; ALMEIDA, 2012). 

Para realizar a extração das informações nas imagens é necessário 

definir  métodos  com  regras  claras  e  lógicas,  para  que  outros  pesquisadores 

possam  replicar  essas  regras.  Nesse  contexto  surgem  as  técnicas  de 

classificação  digital  de  imagens,  que  automatizam  o  processo  de  extração  da 

informação  das  imagens  e  assim  eliminam  a  subjetividade  inerente  ao  ser 

humano,  reduzindo  o  esforço  e  o  tempo  de  trabalho.  Segundo  Meneses  e 

Almeida (2012), o resultado da classificação é uma imagem digital que constitui 

um mapa de pixels classificados, representando em polígonos, as regiões que 

são homogêneas para a classe ou alvo. Assim, de uma forma geral, o resultado 

da classificação é um mapa temático. 

Existe na literatura diversos métodos de classificação, de forma que 

estes  métodos  podem  classificados  como:  paramétricos,  não-paramétricos, 

espectral,  espacial,  supervisionada  ou  não-supervisionada.  Na  atualidade,  os 

classificadores também podem ser definidos como classificadores por pixel ou 

por regiões. 

A maioria dos métodos de classificação são baseados no pixel, que 

utilizam  somente  a  informação  espectral  de  cada  pixel  para  determinar  as 

regiões  homogêneas,  a  partir  de  medidas  que  podem  ser  de  distância  ou  de 

probabilidade  de  um  pixel  pertencer  a  uma  classe,  segundo  o  esquema 

apresentado na Figura 27. O método no processo de classificação deste trabalho 

é o definido como classificador de distância mínima definido e organizado dentro 

do QGIS. 

 
 
 
 
 
57 

Figura 27 – Esquema para o processo de classificação de imagens 
(CAETANO et al., 2007) 

As classes definidas para esse trabalho foram vegetação, construção 

e outras, que é a classe que agrega todas aquelas não definidas como vegetação 

ou  como  construções.  Para  isso  a  proposta  é  sempre  realizar  um  estudo 

matemático  para  definir  os  limiares  que  possam  interessar  para  cada  uma 

dessas classes. 

Por  exemplo,  a  título  de  apresentação  nesse  trabalho,  definiu-se 

como classe de vegetação aqueles pixels que se aproximem o máximo possível 

dos altos valores de NDVI e SAVI e os pixels que apresentam, ou se aproximam 

dos menores valores para os índices são classificados como áreas antrópicas 

ou de construções. 

3.3.2 Classificações por classes 

Os  resultados  da  classificação  segundo  o  método  proposto  e  os 

valores definidos para as respectivas classes, serão apresentados a seguir. Na 

Figura 28, é possível verificar o resultado da classificação para o resultado da 

 
 
 
 
 
 
imagem do Landasat 8, para os dois índices espectrais, ou seja, o NDVI (Figura 

28 – a) e o SAVI (Figura 28 – b). 

58 

Figura 28 – Resultados da classificação da imagem Landsat 8, para as 
classes após aplicação dos índices espectrais: (a) NDVI e (b) SAVI 

(a)                                                          (b) 

O resultado da classificação para a imagem CBERS – 4, para os dois 

índices espectrais e as mesmas classes definidas, ou seja, construções, outros 

e vegetação estão na Figura 29. 

Figura 29 – Resultados da classificação da imagem CBERS – 4, para as 
classes após aplicação dos índices espectrais: (a) NDVI e (b) SAVI 

(a)                                                                               (b) 

 
 
 
 
 
  
 
  
 
59 

Importante verificar que os resultados são visualmente muito similares 

e condizem com aquilo que se espera para a classificação em áreas urbanas e 

período  entre  safras  com  classificação  de  áreas  que  estão  em  fase  de 

colheita/plantação e para as áreas antrópicas com construções. 

Uma  aplicação  para  o  ensino  de  forma  integrada  e  multidisciplinar 

com base na metodologia de ensino através de projetos pode ser apresentado 

com  base  na  metodologia  proposta  nesse  capítulo  que  utiliza  os  índices 

espectrais indicados na seção 3.1, a aplicação dos mesmos na seção 3.2 e por 

último a classificação dos resultados na seção 3.3. Essa metodologia pode ser 

traduzida por um roteiro de aplicação (Anexo 1), para discutir de forma conjunta 

com as outras áreas da educação básica e com as perspectivas de ensino de 

Matemática. 

Para  introduzir  ou  então  consolidar  os  conceitos  de  imagem  nos 

alunos,  são  apresentadas  algumas  atividades  (Anexo  2)  que  podem  ser 

realizadas  em  sala  de  aula,  com  ou  sem  o  uso  de  computadores,  atividades 

estas que podem ser aplicadas tanto no Ensino Fundamental quanto no Ensino 

Médio. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4.  CONSIDERAÇÕES FINAIS  

60 

Este trabalho tinha como proposta fazer um estudo dos Índices Espectrais 

Aplicados ao Sensoriamento Remoto, e desse estudo definir uma metodologia 

de aplicação dos respectivos índices para classificar o uso e cobertura do solo 

em uma área urbana, tomando como base dois sensores/satélites conhecidos e 

com imagens de fácil acesso, para no final propor um roteiro de atividades para 

que os alunos e professores do Ensino Médio pudesse ter, nesse trabalho, um 

referencial  teórico  e  metodológico  para  aplicar  em  projetos  interdisciplinares 

estudos  de  uso e  ocupação  do  solo,  agregando a  Matemática,  a Geografia, a 

Computação e o Meio Ambiente. 

Considerando  a  recente  história  do  Sensoriamento  Remoto  e  suas 

aplicações, vinculadas à evolução dos vários sistemas sensores, que geraram 

uma democratização do acesso a imagens, ainda existe um vácuo entre aquilo 

que se gera de dados e como transformar esses dados em informação. Dessa 

forma  esse  trabalho  vem  no  sentido  de  começar  a  sedimentar  esse  vácuo 

existente entre os dados gerados e as informações obtidas com os mesmos. E 

isso só é possível, segundo os responsáveis por esse trabalho, se as técnicas e 

teorias amplamente difundidas em Sensoriamento Remoto ganharem a escala 

necessária para atingir esse objetivo. Escala, ou seja, quantidade de alunos e 

professores  que  utilizam  essas  ferramentas  só  será  possível  alcançar  se  a 

mesma chegar na educação básica. E a Matemática é a linguagem universal que 

permite o aluno entender todos os processos tecnológicos envolvidos. 

No trabalho uma revisão sobre os princípios envolvidos no processo de 

aplicar os índices espectrais tais como Princípios de em Sensoriamento Remoto, 

Princípios de uma Imagem Digital, bem como os processos que permeiam estes 

princípios,  tais  como  o  Processamento  Digital  de  Imagens  e  as  Plataformas 

Orbitais  utilizadas  no  processo  (Landsat  8  e  CBERS  –  4)  foram  utilizadas  no 

Capítulo 2 do trabalho, na forma de um Referencial Teórico necessário. 

O Capítulo 3, denominado de Método Proposto, apresenta uma sequência 

de utilizar os índices espectrais na Educação Básica (Ensino Médio) para que os 

alunos, utilizando uma metodologia baseada em projetos, possam aplicá-la de 

forma multidisciplinar. Assim uma revisão dos índices espectrais e a forma como 

 
 
 
 
 
 
 
61 

os  mesmos  são  aplicados  foram  colocados  neste  capítulo  para  substanciar 

conceitualmente os professores que irão utilizá-los. Após isso, a efetiva forma de 

aplicá-los  é  apresentada,  terminando  com  o  resultado  do  trabalho  que  é  a 

classificação e a geração de mapas de classes para um exemplo específico, que 

nesse caso foi a área urbana na cidade de Sinop-MT com aplicação nas imagens 

OLI/Landsat  8  e  MUX/CBERS  –  4,  aplicando  os  índices  NDVI  e  SAVI 

respectivamente  e  construindo  as  classes  de  áreas  construídas  (antrópicas), 

áreas de vegetação e outros. 

Por  último  fica  no  trabalho  as  perspectivas  futuras  para  que  os  Índices 

Espectrais  aplicados  ao  Sensoriamento  Remoto,  possa  ser  mais  amigável  e 

ganhe a adesão necessária na educação básica. Isso só será possível com a 

criação  de  uma  apostila  detalhada  do  roteiro  proposto  para  que  professores 

possam  aplicá-los  no  Ensino  Médio  de  forma  mais  independente.  No  entanto 

algumas  situações  são  fundamentais  para  que  isso  se  torne  uma  realidade, 

sendo estas: 

•  Forma mais amigável de tratar a busca das imagens e sua manipulação 

nos softwares como o QGIS, por exemplo; 

•  Definir  o  nível  de  aprofundamento  necessário  nos  conteúdos  de 

Matemática  (manipulação  e  processamento  digital  de  imagens),  Física 

(resposta  espectral  princípios  de  absorção,  reflectância,  refração, 

radiância  e  irradiância)  e  Geografia  (Cartografia  digital,  projeções 

cartográficas  entre  outros)  para  que  os  conteúdos  necessários  estejam 

acessíveis para alunos e professores da educação básica (Ensino Médio); 

•  Definir  uma  metodologia  para  que  os  resultados  tenham  um  grau  de 

significância desejado para os alunos e professores. Isso, pode inclusive 

acontecer  com  outras  áreas,  tais  como  História  e  Ciências  (Biologia  e 

Química, além da Física). 

Assim,  esse  trabalho  mostra  a  importância  que  o  conhecimento 

matemático, como linguagem universal das tecnologias, pode agregar as outras 

áreas, bem como as outras áreas podem, na forma de contrapartida, agregar ao 

ensino da Matemática, mostrando sua importância para as mais diversas áreas 

do conhecimento, como foi o caso deste trabalho. 

 
 
 
5.  REFERÊNCIAS BIBLIOGRÁFICAS 

62 

BANNARI, A. et al. A review of vegetation indices. Remote Sensing Reviews, 
v. 13, n. 1–2, p. 95–120, 1995.  

BARET,  F.;  GUYOT, G.  Potentials  and  limits  of  vegetation  indices  for  LAI  and 
APAR  assessment.  Remote  Sensing  of  Environment,  v.  35,  n.  2–3,  p. 161–
173, 1991.  

CAETANO, M.; SANTOS, T.; GONÇALVES, L. Cartografia de ocupação do solo 
em: 
estado 
com 
www.igeo.pt/serviços/CDI/biblioteca/publicaçõesIGP_files/esig_2002/papers 
. 
Acessado em: 10 de março de 2007. 

arte.  Disponível 

imagens 

satélite: 

da 

de 

CRÓSTA,  Alvaro  Penteado;  Processamento  digital  de 
sensoriamento remoto. Campinas :IG/UNICAMP,1992. 

imagens  de 

EPIPHANIO,  José  Carlos  Neves;  NOVO,  Evlyn  Márcia  Leão  de  Moraes; 
MACHADO, Luiz Augusto Toledo. Espaço. Vol. 8. São Paulo: Blucher, 2010. 

EPIPHANIO, J. C. N. CBER - 3/4: Caracteristicas e Potencialidades. Anais XV 
Simpósio Brasileiro de Sensoriamento Remoto - SBSR, p. 5615–5623, 2011.  

GATTASS,  M.,  Lecture  notes  in  Computer  Graphics,  Disponível  em 
http://webserver2.tecgraf.puc-rio.br/~mgattass/; Acessado em 28/05/2017. 

GIBSON,  P.J.  “Introductory  Remote  Sensing-  Principles  and  Concepts” 
Routledge, London. 2000.  

GILABERT,  M.  A.  et  al.  A  generalized  soil-adjusted  vegetation  index.  Remote 
Sensing of Environment, v. 82, n. 2–3, p. 303–310, 2002.  

GOMES, Jonas; VELHO, Luiz. Computação gráfica: Imagem. RJ. IMPA/SBM, 
1994. 

GOMES, Jonas; VELHO, Luiz. Computação gráfica. Vol 1. RJ. IMPA, 1998. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
63 

GONZALEZ,  Rafael  C.;  WOODS,  Richard  E.  Processamento  digital  de 
imagens. Marcelo Vieira e Maurício Escarpinati: [tradução Cristina Yamagami e 
Leonardo Piamonte]. 3ª ed. São Paulo: Pearson Prentice Hall. 2010. 

HUETE,  A.  R.  A  soil-adjusted  vegetation  index  (SAVI).  Remote  Sensing  of 
Environment, v. 25, n. 3, p. 295–309, 1988.  

HUETE, A. R.; JUSTICE, C.; LIU, H. Development of Vegetation and Soil Indexes 
for Modis-EOS. Remote Sensing of Environment, v. 49, n. 3, p. 224–234, 1994.  

HUETE,  A.  et  al.  MODIS_MOD13_NDVI_referenc.  v.  83,  p.  195–213,  2002. 

INPE,  2017. 
em:<http://www.cbers.inpe.br/noticias.php>. Acesso em 30/04/2017. 

Instituto  Nacional  de  Pesquisas  Espaciais.  Disponível 

JENSEN, John R. Sensoriamento remoto do ambiente: uma perspectiva em 
recursos terrestres. [tradução José Carlos Neves Epiphanio (coordenador)...[et 
al]]. SP. Parênteses. 2009. 

MENESES,  P.  R.;  ALMEIDA,  T.  DE. Introdução  ao  processamento  de 
imagem de sensoriamento remoto. 2012. 

NASA, 2013. National Aeronautics and Space Administration (NASA) - Landsat 
Data  Continuity  Mission:  Continuously  Observing  Your  World.  Disponível  em: 
<http://ldcm.gsfc.nasa.gov/mission_details.html>. Acesso em: 19/06/2013. 

PEARSON, R. L. and MILLER, L. D. (1972) Remote mapping of standing crop 
biomass  for  estimation  of  the  productivity  of  the  shortgrass  prairie,  Pawnee 
National Grasslands, Colorado. Proceedings of the 8th International Symposium 
on Remote Sensing of the Environment II: 1355-1379. 

ROUSE, J. W., HAAS, R. W., SCHELL, J. A., DEERING, D. W. and HARLAN, J. 
C.  (1974)  Monitoring  the  vernal  advancement  and  retrogradation  (Greenwave 
effect) of natural vegetatioa NASA/GSFCT Type 

SILVA, Antônio Machado e. Curso Processamento digital de imagens de satélite. 
Centro de Eventos da PUCRS - de 07 a 12 de outubro de 2001. Porto Alegre - 
RS. Disponível em www.cartografia.org.br. Acesso em: 19 fev. 2007. 

 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
64 

VELHO,  L.;  FRERY,  A.  C.;  GOMES,  J.  Image  Processing  for  Computer 
Graphics and Vision. Texts in Computer Scince, 2009.  

VERSTRAETE,  M.  M.  and  B.  Pinty  (1996).  Development  of  spectral  indices 
optimized for the vegetation instrument: Progress report. Report to the vegetation 
international user committee, Space Applications Institute. 

ZANIN,  R.  B.;  DAL  POZ,  A.  P.  Metodologia  Automatica  Para  Extração  De 
Cruzamentos De Rodovias Em Imagens De Alta Resolução. Revista Brasileira 
de Cartografia, v. 55, n. 2, 2003.  

ZHANG, X.; ZHANG, Q. Monitoring interannual variation in global crop yield using 
long-term  AVHRR  and  MODIS  observations. 
ISPRS  Journal  of 
Photogrammetry and Remote Sensing, v. 114, p. 191–205, 2016.  

 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
65 

6.  ANEXOS 

ANEXO 1 

Roteiro para atividade a ser realizada para Aplicação de Índices Espectrais em 
Sensoriamento Remoto 

Materiais necessário  

- Computador (verificar configurações mínimas) 

- Software QGIS (verificar a versão mais estável para aplicações básicas) 

* Realizar a instalação do software (atividade em conjunto com alunos 

ou técnico de laboratório) 

- Instalar o plug-in sextante no QGIS 

* Utilizar o seguinte endereço para auxiliar 

http://www.andersonmedeiros.com/extensao-sextante-para-quantum-gis/ 

-  Imagens  da  região  de  interesse  (atenção  para  necessidade  de  as  imagens 
serem multiespectrais, contendo as bandas R, G, B e NIR). 

Atividades 

1 – Dividir o grupo para definir qual será o produto final para cada um dos 
grupos. 

A seguir tem alguns exemplos que podem ser definidos para os grupos 

de forma independente ou todos os grupos fazem o mesmo produto, com áreas 
ou períodos diferentes. 

- Mapa temático de desmatamento 

- Mapa temático para áreas construídas  

- Mapa temático para áreas de APP (Áreas de Preservação Permanente) 

- Mapa temático para rio de uma dada região  

- Mapa temático para área plantada em um determinado período e área 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
- Mapa temático para rodovias vicinais 

66 

2 – Determinar área de desenvolvimento da pesquisa. 

Isso pode ser realizado no Google Earth, para ter um primeiro contato com 
a  região,  ou  no  próprio  site  do  INPE  (Institutos  de  Pesquisas  Espaciais  - 
http://www.dgi.inpe.br/CDSR/). 

Importante  prestar  atenção  para  o  tipo  de  produto  que  precisa  ser 
construído,  considerando  a  resolução  das  imagens  que  pretende-se  adquirir. 
Cabe nesse momento a primeira inferência matemática, com uma boa discussão 
sobre resolução de imagens. 

3 – Adquirir as imagens da região de interesse.  

As  imagens  devem  ser  adquiridas  levando  em  consideração  o  local 
(ponto/orbita),  a  data  de  interesse  e  o  percentual  de  cobertura  de  nuvens  no 
período. 

Nesse momento uma nova inferência importante deve ser feita, tanto do 
ponto  de  vista  matemático,  como  geográfico,  para  que  os  alunos  entendam  a 
relação ponto e orbita, que leva em consideração as características do satélite 
que está sendo utilizado, bem como conceitos matemáticos envolvido para que 
o satélite possa estar em orbita. 

4  –  Carregar  as  imagens  no  Software  QGIS,  considerando  as  bandas  da 
imagem de interesse. 

Neste momento, a discussão sobre modelo matemático de imagens, e os 
processos  matemáticos  para  processamento  digital  de  imagens  ganha  um 
espaço privilegiado para discussão. 

Alguns  exemplos  sobre  álgebra  de  bandas  podem  ser  realizados  para 

verificar como o processamento pode modificar a visualização. 

5 – Realizar a correção atmosférica das imagens que serão utilizadas. 

O processo de correção atmosférica é a conversão dos valores de pixel 
em  reflectância.  Isso  é  importante  para  aplicação  dos  índices  espectrais.  Um 
exemplo  de  como  fazer  isso  para  imagens  Landsat  8  está  no  endereço: 
http://www.geoluislopes.com/2015/07/converter-bandas-do-landsat-8-para-
reflectancia-no-qgis-correcao-atmosferica.html 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
67 

6 – Aplicar os índices espectrais  

Na  parte  de  álgebra  de  bandas,  tomando  como  base  as  imagens  já 

convertida aplica-se a regra para os índices espectrais de interesse.  

Nesse caso uma nova inferência matemática é possível, mostrando quais 
operações  são  possíveis  de  serem  realizadas,  considerando  que  as  imagens 
estão em formatos matriciais, ou seja, um trabalho de álgebra de matrizes pode 
ser realizado. 

Outra inferência importante que pode ocorrer é com relação aos conceitos 
de  Física,  para explicar  a necessidade  de  realizar  a  correção  atmosférica nas 
imagens.  Realizar  aplicações  de  índices  nas  imagens  sem  a  correção 
atmosférica mostram as diferenças e o porquê destas ocorrerem na imagem. 

7 – Aplicar a classificação nos resultados dos índices espectrais 

Nesta  parte  do  processo  é  importante  conhecer  os  vários  métodos  de 
classificação,  e  uma  inferência  sobre as técnicas  de processamento  digital de 
imagens  e  suas  aplicações  baseando-se  em  ferramentas  matemáticas  é  um 
espaço rico de discussão que pode ocorrer. 

Esta  etapa  é  realizada  no  software  QGIS  em  específico  no  plug-in 

sextante com suas várias técnicas disponíveis. 

Por fim o resultado do processo deve gerar um produto que deverá passar 
por uma validação no grupo de trabalho e no grupo maior, ou seja, a sala de aula 
e/ou disciplina em que se propôs realizar esta atividade. 

A atividade proposta nesse roteiro é apenas um exemplo amplo e aberto 
para  criar  um  primeiro  momento  de  discussão  da  aplicação  dos  Índices 
Espectrais  aplicados  em  Sensoriamento  Remoto.  Detalhes  e  parâmetros  de 
utilização  de  imagens,  software  e  processos  devem  ser  realizados  para 
atividades mais específicas em um formato de manual. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
68 

ANEXO 2 

Roteiro  de  atividades  a  serem 

realizadas  em  sala  de  aula,  para 

introduzir/consolidar alguns conceitos de Imagem. 

1  –  A  partir  de  uma  figura  (pancromática)  dada,  realizar  manualmente  os 

processos de amostragem, quantização e discretização. 

Sugestões: 

•  Para uma mesma imagem, realizar o processo com 9 pixels (matriz 3x3) 

e com 49 pixels (matriz 7x7). 

•  Após  realizar  estas  atividades,  propor  aos  alunos  o  processo  inverso, 

apresentar  os  dados  discretizados  para  então  ele  construírem  uma 

imagem. 

2 – Relacionar imagens aos seus respectivos histogramas. 

 
 
 
 
 
 
 
 
 
3  –  A  partir  de  uma  imagem  de  Sensoriamento  Remoto,  calcular  a  área  de 

vegetação de uma determinada localidade, em m2, de acordo com a resolução 

espacial da imagem. 

69 

 

TADEU ALEXANDRE RODRIGUES DOS SANTOS

A MATEMÁTICA POR TRÁS DO GOOGLE

Santo André, 2014

UNIVERSIDADE FEDERAL DO ABC

CENTRO DE MATEMÁTICA, COMPUTAÇÃO E COGNIÇÃO

TADEU ALEXANDRE RODRIGUES DOS SANTOS

A MATEMÁTICA POR TRÁS DO GOOGLE

Orientador: Prof. Dr. Rafael de Mattos Grisi

Dissertação de mestrado apresentada ao Centro de

Matemática, Computação e Cognição para

obtenção do título de Mestre

ESTE EXEMPLAR CORRESPONDE A VERSÃO FINAL DA DISSERTAÇÃO

DEFENDIDA PELO ALUNO TADEU ALEXANDRE RODRIGUES DOS SANTOS,

E ORIENTADA PELO PROF. DR. RAFAEL DE MATTOS GRISI.

SANTO ANDRÉ, 2014

R E S U M O

Neste trabalho apresentamos o algoritmo PageRank, usado pela Google para ordenar

páginas no resultado de buscas. No primeiro capítulo descrevemos de maneira detal-

hada as estruturas matemáticas por trás do algoritmo, apresentando uma interpretação

probabilística para suas estruturas e resultados. Para melhor entender a matemática

do Google, nos capítulos 2 e 3 trabalhamos conceitos básicos de Cadeias de Markov,

em especial a noção de medidas invariantes.

Palavras-chave: PageRank, Google, cadeias de Markov

iii

A B S T R A C T

In the present work we present the PageRank algorithm, used by Google to sort the

search results on the web. At the ﬁrst chapter we describe in details the mathematical

structures behind the algorithm, providing a probabilistic interpretation for it’s struc-

tures and results. For a better understanding of Google’s math, in chapters 2 and 3

we work on some basic concepts of Markov Chains, specially the notion of invariant

measures.

Keywords: PageRank, Google, Markov chains

v

C O N T E Ú D O

Introdução

1 O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

1.1 O PageRank de uma Página . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Calculando o PageRank . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.3 Casos Problemáticos para a Matriz de Hyperlinks . . . . . . . . . . . . .

1.3.1 Páginas sem links . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

3

4

7

9

9

1.3.2 Ciclos de Páginas . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

1.3.3 Conjuntos de Páginas Auto-referenciadas . . . . . . . . . . . . . . 11

1.4 Interpretação Probabilística do Algoritmo de PageRank . . . . . . . . . . 13

1.4.1 Alterando o modelo . . . . . . . . . . . . . . . . . . . . . . . . . 16

2 C A D E I A S D E M A R K O V

21

2.1 Cadeias de Markov . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

2.1.1 Medidas Invariantes . . . . . . . . . . . . . . . . . . . . . . . . . 29

2.2 Matriz de Transição Regular . . . . . . . . . . . . . . . . . . . . . . . . . 32

3 A C O P L A N D O C A D E I A S

35

3.1 Simulando uma Distribuição . . . . . . . . . . . . . . . . . . . . . . . . . 35

3.1.1 Acoplando duas distribuições . . . . . . . . . . . . . . . . . . . . 37

3.1.2 Acoplando três ou mais distribuições . . . . . . . . . . . . . . . . 40

3.2 Acoplando Cadeias de Markov . . . . . . . . . . . . . . . . . . . . . . . . 42

3.3 Convergência para a medida invariante . . . . . . . . . . . . . . . . . . . 47

Bibliograﬁa

51

vii

I N T R O D U Ç Ã O

Estamos vivendo e acompanhando uma revolução nos modos de pensar e agir das

pessoas em todo o mundo e a precursora deste fato é incontestavelmente a internet.

Ela tem o poder de alcançar todos os cantos do mundo, levando todo o tipo de informa-

ção e formação, aproximando pessoas e permitindo o contato com novas e diferentes

culturas, quer dizer, a internet abre um leque inﬁnito de possibilidades e, tudo isso,

sem a necessidade de se levantar do sofá de casa, bastando, para isso, ter um compu-

tador conectado a web.

Com a internet qualquer pessoa do mundo pode criar uma página e expressar suas

opiniões, ideias, devaneios e, além disso, divulgar, oferecer e vender uma inﬁnidade

de produtos e serviços com um enorme alcance. Agora, a grande força da internet

vem do fato que qualquer pessoa conectada em qualquer lugar do mundo pode ter

acesso a essa página e compartilhar do conteúdo dela, chegando em alguns casos, até

a dar suas contribuições para a página acessada. Enﬁm, a mágica da internet está na

inimaginável gama de possibilidades de interações entre as pessoas em todas as partes

do mundo e a internet é o veículo para que isso ocorra. Porém, as facilidades que a

grande rede oferece às pessoas gera um enorme imbróglio devido ao imenso número

de páginas - da ordem de bilhões - que ediﬁcam a rede e que são criadas a todo instante

e em vários lugares do mundo.

Diante disto, o presente trabalho de conclusão de curso visa investigar a matemática

por trás do Google, o maior e melhor site de buscas da internet. O Google utiliza

um método desenvolvido por Larry Page e Sergey Brin na Universidade de Stanford

e conhecido como PageRank, que é um sistema para dar notas a páginas na web.

Mesmo hoje, com todos os avanços na área de tecnologia, o algoritmo do PageRank

ainda continua a ser o âmago das buscas no Google.

O PageRank usa uma enorme cadeia de hyperlinks como um indicador do valor de

uma página, ou seja, o Google interpreta um link da página a para a página b como

uma espécie de voto de a para b, contudo o Google vai além da quantidade de votos,

ou links, que uma página recebe, ele analisa também a página que dá o voto. Os votos

dados por páginas com maiores PageRanks pesam mais do que os dados por outras

1

Conteúdo

com menores PageRanks. Pois bem, quando um internauta digita uma palavra ou

frase no Google, a ordem dos resultados para essa busca obedecem ao PageRank que

o Google atribui às páginas na internet.

No primeiro capítulo deste trabalho falaremos do ordenamento das páginas e dos

problemas que surgem na determinação do PageRank de algumas destas, provendo

um olhar probabilístico ao algoritmo do Google. Já no capítulo dois utilizaremos a

Cadeia de Markov para investigar, um pouco mais de perto, as características do vetor

estacionário de uma matriz de transição, com o intuito de entender um pouco melhor

as características e interpretações do PageRank. Finalizamos com o capitulo três que

trata do acoplamento de Cadeias de Markov, uma técnica simples mas poderosa, que

nos permite entender como ocorre a convergência do método iterativo utilizado no

algoritmo do PageRank.

2

1

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

De acordo com o site worldwidewebsize.com, a web é formada por dezenas de bi-

lhões de páginas que se multiplicam a cada momento, devido a facilidade e praticidade

de suas criações. Dados indicam que, aproximadamente, 95% dos textos em páginas

da web são compostos por cerca de 10 mil palavras, ou seja, quando o usuário digita

o objeto de sua pesquisa, haverá um grande número de páginas que contém, em seus

conteúdos, as palavras que estão sendo buscadas. Portanto, é necessário uma forma de

classiﬁcar a relevância das páginas da web que se enquadram nos critérios de pesqui-

sas, pois, assim, nos resultados das buscas, as páginas classiﬁcadas com o maior grau

de relevância aparecerão no topo da lista.

Cada página da web trata de um ou vários assuntos e, geralmente, quando um

internauta acessa um site é devido a algum tipo de interesse que tem por este. Quando

as páginas são construídas é natural que sejam incluídos caminhos (links) para outras

páginas que, de modo geral, apresentam conteúdos adjacentes de interesse.

Na inclusão de links, o criador de um site, de certa forma, está assumindo que esse

link é importante e nele existem informações valiosas e conﬁáveis que possivelmente

podem ser úteis ao internauta . Por exemplo, um site de automóveis, possivelmente,

disponibilizará links para outros sites que giram em torno do assunto automóveis.

O cerne da ideia dos criadores do PageRank, apresentado em [4] por Sergey Brin

e Lawrence Page, é atribuir maior importância às páginas mais visitadas. Assim, se

dentre duas páginas s1 e s2 que tratam do mesmo assunto, a página s1 recebe mais
acessos, então esta deveria aparecer na frente em resultados de busca.

Mas como fazer esta medida? Mesmo que toda página tivesse uma espécie de con-

tador de visitas, o google poderia não ter acesso a estas informações. Além disso, para

ter uma medida conﬁável seria necessário controlar a quanto tempo cada contador

está no ar, dentre outros problemas de difícil controle.

3

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

Para contornar estes problemas, Brin e Page decidiram olhar para os links que apon-

tavam para cada página. A ideia é que uma página com maior quantidade de links

apontados para ela, seria mais importante. A medida feita desta forma claramente

não é boa, pois uma página com muitos links de páginas pouco importantes poderiam

ter menor importância do que uma página com menos links provenientes de páginas

de maior importância. A seguir descrevemos a solução implementada por Brin e Page.

Seguiremos muito de perto a descrição dada em [1], mas diversos artigos e livros

foram escritos a respeito. O leitor interessado pode procurar mais informações em

[5, 7, 8], ou no próprio Google!

1.1 O PA G E R A N K D E U M A PÁ G I N A

Para corrigir o problema a ideia implementada foi a de “transferência de importân-

cia". Cada página “transfere” sua importância de maneira equânime a todas as páginas

para as quais possui um link. Do mesmo modo, ele “receberá” peso das páginas que

possuem links apontadas para ela.

Para determinar então a medida de importância de uma página web (ou PageRank)

r(s), suponha que a página sj tenha lj links, sendo um desses links a página si, dessa
forma a razão que sj vai passar de sua importância para si será de 1/lj. Com isso, o
PageRank de si será a soma de todas as contribuições feitas por páginas da web que
têm links de acesso para si . Nesse sentido, podemos chamar de Bi o conjunto de
páginas que possuem links para si, então para cada i ∈ {1, . . . , N}

r(si) = ∑
sj∈Bi

r(sj)
lj

,

(1.1)

onde N é o total de páginas da web.

Analisando a equação (1.1), o leitor menos experiente pode a princípio pensar que

estamos em um paradoxo, pois para determinarmos o PageRank de si, temos de saber
qual o PageRank de todas as páginas que se ligam a ela. Porém, o que temos é apenas

um sistema de equações (uma equação para cada página da web), e tudo o que (1.1)

nos diz é que as importâncias das diversas páginas dever satisfazer as equações deste

sistema.

Para simpliﬁcar a notação para cada i ∈ {1, . . . , N} chamaremos r(si) := ri.

4

1.1 O PA G E R A N K D E U M A PÁ G I N A

Para melhor representar o sistema acima, considere a matriz H = [Hij], que chama-

remos de matriz hyperlink dada por

(cid:40)

Hij =

1/lj,
0,

se sj ∈ Bi
se sj não tem links.

(1.2)

Deﬁnindo agora o vetor coluna r = [ri], no qual as componentes serão os PageRanks

das páginas web, vale que

r = Hr.

O vetor r assim deﬁnido é conhecido como vetor estacionário da matriz H.

No exemplo que segue, vamos encontrar a matriz de hyperlinks H de uma rede

formada por 5 páginas da web, com os links representados por ﬂechas, representada

na ﬁgura a seguir.

Figura 1: Rede considerada no exemplo 1.1

.

Exemplo 1.1. Considere a rede de páginas na Figura 1. Neste caso a matriz de hyper-

link da rede será

H =












0
1
3
1
3
0
1
3

1
1
3
2
0 0 1

0 0 0
1
1
3
2
1
0
3

0 0
1
3
1
3
1
3
0 0

0












.

5

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

O vetor estacionário deve satisfazer portanto























r1
r2
r3
r4
r5

=












0
1
3
1
3
0
1
3

1
1
3
2
0 0 1

0 0 0
1
1
3
2
1
0
3

0 0
1
3
1
3
1
3
0 0

0


































r1
r2
r3
r4
r5

.

Igualando os dois lados da equação acima linha por linha, obtemos






3 r5

1

1

1

2 r2 + 1
3 r3
3 r1 + r4 + 1
3 r1 + 1
3 r5
3 r3 + 1
2 r2 + 1
3 r1 + 1
3 r3

1

1

3 r5 = r4

= r1

= r2

= r3

= r5

= 0

= 0

= 0

.

ou ainda






3 r5

1

1

2 r2 + 1
−r1 + 1
3 r3
3 r1 − r2 + r4 + 1
3 r1 − r3 + 1
2 r2 + 1
3 r1 + 1

3 r5
3 r3 − r4 + 1
3 r3 − r5

1

1

3 r5 = 0

= 0

Se tentarmos resolver o sistema acima, perceberemos que existem inﬁnitas soluções

possíveis. Por razões que ﬁcarão claras mais a frente, tomaremos uma solução com
todos os termos positivos, e cuja soma total dos pesos é 1. Ou seja, queremos ri ≥ 0
para todo i e r1 + · · · + rN = 1. Com isso, neste exemplo temos

r =












6
29
10
29
3
29
7
29
3
29












=























.

0, 2069

0, 3448

0, 1034

0, 2414

0, 1034

(1.3)

Assim, de acordo com o vetor r, a página 2 é a mais importante, e aparecerá na

frente das demais no resultado de uma busca. Mais do que isso, se uma busca retornar

as páginas 2, 3 e 4 sua ordenação será r2, r4, r3.

6

1.2 C A L C U L A N D O O PA G E R A N K

1.2 C A L C U L A N D O O PA G E R A N K

Vimos no exemplo 1.1 que para encontramos as entradas do vetor r, basta resolver

um sistema linear em que o somatório das componentes de r seja igual a 1. Porém,

pensando na web, isso se torna um grande desaﬁo, pois a matriz H é uma matriz

quadrada onde cada coluna corresponde a uma página da web indexada pelo Google,

assim sendo, H teria cerca de N = 25 bilhões de colunas e linhas. É fato que a mai-

oria das entradas de H são iguais a 0, isso por que o total de links em uma página é

normalmente muito menor que o total de páginas na web. Apesar disso simpliﬁcar a

resolução do sistema, como veremos mais a frente causa problemas sérios na ordena-

ção das páginas, o que nos forçará a alterar a matriz H, fazendo com que esta ﬁque

menos esparsa. Precisamos ter em mãos um método diferente de solução.

Retomando ao exemplo da nossa rede com 5 páginas, vamos utilizar um método
iterativo para encontrarmos o vetor r. Primeiro escolhemos um vetor qualquer r0
como um candidato para r e, em seguida, produzimos uma sequência de vetores rk,
deﬁnido para cada k ≥ 0

porrk+1 = Hrk.

A ideia agora é que se rk ∼ v, para k suﬁcientemente grande, então teremos rk+1 ∼ v

e

e portanto v = r.

v = Hv,

Para ilustrar o método acima vamos estudar o caso em que

r0 =












.












1

0

0

0

0

Vale ressaltar que poderíamos escolher outros valores para r0, seguindo apenas a re-

gra estabelecida anteriormente de que as entradas devem ser não-negativas e somarem

1. Assim, teríamos os seguintes resultados:

Comparando com a solução encontrada em (1.3), vemos que estas coincidem com

pelo menos 4 casas decimais de precisão.

7

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

r0

1

0

0

0

0

r1

0

r2

r3

0,2778

0,0926

0,3333

0,1111

0,5185

0,3333

0,1111

0,1296

0

0,3889

0,1296

0,333

0,1111

0,1296

. . .

. . .

. . .

. . .

. . .

. . .

r60

0,2069

0,3448

0,1034

0,2414

0,1034

Tabela 1: Sequência de vetores rk com r0 = (1, 0, 0, 0, 0).

Observe que as entradas dos vetores rk são sempre não-negativas, e somam 1. Mais

a frente veremos por que isso acontece.

A tabela 1 mostra uma sequência em que escolhido r0 e feita algumas iterações,

convergimos naturalmente para o vetor estacionário r da matriz H. Neste exemplo,
esta convergência aconteceria mesmo se escolhêssemos um outro valor para r0, por

exemplo, se tomarmos

r0 =












0, 25

0

0, 25

0, 25

0, 25












,

r0

r1

r2

r3

. . .

r60

0,25

0,0833

0,2639

0,1528

0

0,4167

0,2500

0,4352

0,25

0,25

0,25

0,1667

0,0833

0,1157

0,1667

0,3194

0,1806

0,1667

0,0833

0,1157

...

...

...

...

...

0,2069

0,3448

0,1034

0,2414

0,1034

Tabela 2: Sequência de vetores rk com r0 = (1/4, 0, 1/4, 1/4, 1/4).

então

8

1.3 C A S O S P R O B L E M ÁT I C O S PA R A A M AT R I Z D E H Y P E R L I N K S

1.3 C A S O S P R O B L E M ÁT I C O S PA R A A M AT R I Z D E H Y P E R L I N K S

Observando os exemplos acima, somos levados a fazer três questionamentos:

• O vetor rk sempre converge?

• A convergência para o vetor r depende da escolha de r0?

• Os valores obtidos desta forma para os PageRanks sempre fornecem as informa-

ções que queremos?

Infelizmente a resposta para as três perguntas é não! A boa notícia é que se ﬁzermos

algumas modiﬁcações na matriz H teremos resposta aﬁrmativa para as três perguntas.

1.3.1 Páginas sem links

É bastante comum enquanto navegamos pela web, que os alvos de nossas buscas

sejam arquivos PDF, imagens ou mesmo páginas web sem links para nenhuma outra

página. Estas páginas ou arquivos existem em grande quantidade, e fazem parte da

rede. Infelizmente elas são também uma fonte de dor de cabeça para o PageRank.

Considere a seguinte rede com três páginas:

Figura 2: Rede com páginas sem link.

A matriz hyperlink correspondente a ﬁgura 2 é







H =







.

0

0

1
2
0 0 0
1
2

0

0

Com isso, aplicando o método iterativo, obtemos

9

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

r0

0

1

0

r1

0,5

0

0,5

r2

0

0

0

r3 = r

0

0

0

Tabela 3: Sequência de vetores rk para um rede com páginas sem link.

Neste exemplo, as componentes do vetor estacionário de H são iguais a zero e,

portanto, não é possível estabelecer um PageRank para as três páginas. Isso ocorre

devido as páginas 1 e 3 não possuírem ligações para outras páginas, ou seja, as páginas

1 e 3 tiram o grau de importância da página 2 mas não repassam para outras, e nem

permanecem com ele. Páginas que não possuem links são chamadas de dangling nodes

e na web existem milhares delas. Lidaremos com este problema modiﬁcando a matriz

H, mas deixaremos isso para mais tarde, depois de entendermos os demais problemas

relacionados a matriz de hyperlinks.

1.3.2 Ciclos de Páginas

O próximo problema é causado por páginas cujas sequências de links foram um

ciclo. Podemos imaginar um site de formulários, que após passar por todas as páginas

do formulário, volta à página inicial para novo preenchimento. Neste tipo de estrutura

toda a importância de um site é passada para o site seguinte, só retornando para a

primeira página depois de percorrer o ciclo, instante no qual recomeça o processo.

Para entender melhor este fenômeno, considere uma rede com as seguintes ligações

de páginas

A matriz hyperlink correspondente a ﬁgura 3 é










0 0 0 1

1 0 0 0

0 1 0 0

0 0 1 0










,

H =

de onde segue

10

1.3 C A S O S P R O B L E M ÁT I C O S PA R A A M AT R I Z D E H Y P E R L I N K S

Figura 3: Páginas em ciclo.

r0

r1

r2

r3

r4

r5

r6

r7

r8

1

0

0

0

0

1

0

0

0

0

1

0

0

0

0

1

1

0

0

0

0

1

0

0

0

0

1

0

0

0

0

1

1

0

0

0

Tabela 4: Sequência de vetores rk para uma rede circular.

O exemplo acima ilustra claramente como ocorre a transferência de importância,

que faz com que vetores rk se comportem de forma periódica.

Isso impede que o

método iterativo convirja para algum vetor estacionário r. É importante observar que

este método não necessariamente atrapalha na existência de um vetor estacionário. A
princípio tal vetor poderia ainda existir, mas a sequência rk pode não convergir para

ele.

1.3.3 Conjuntos de Páginas Auto-referenciadas

Suponha que um grupo de cervejeiros caseiros resolve entrar no mercado de cervejas

artesanais, e para isso abre uma escola onde ensinarão como se fazer a bebida em

casa. Para divulgar a escola eles criam um site simples, com a informações dos cursos

e contato. Como este é apenas o primeiro site, eles não colocam nenhum link para

sites externos à escola, de modo que todas as páginas do site possuem link apenas

para outras páginas do mesmo site. Para divulgar a escola eles conseguem colocar

propagandas em alguns sites especializados, com um link que leva para o site da escola.

11

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

Está criada assim uma situação bastante comum na internet: conjunto de páginas

auto-referenciadas, com ligações vindas de páginas externas.

A rede a seguir exempliﬁca tal situação.

Figura 4: Rede com grupo de páginas auto-referenciadas.

Analisando a rede da ﬁgura 4, encontramos a matriz hyperlink e vetor estacionário

dados respectivamente por















H =

0 0 0

1
0
2
1
0
2
1
1
2
2
0 0

0 0 0 0
1
3
0 0 0 0
1
1
2
3
1
1
2
3
0
0 0 0

0 0

1
2
0
1
2

0
1
2
1
2















e

r =















.















0

0

0
1
3
1
3
1
3

Escolhendo um vetor r0 como nos exemplos anteriores, e fazendo algumas iterações

encontramos

r0

1

0

0

0

0

0

r1

0

0,5

0,5

0

0

0

r2

r3

. . .

r40

0,25

0,0833

0,1667

0,2083

0,25

0,2083

0,1667

0,1667

0,1667

0,1667

0

0,1667

...

...

...

...

...

...

0

0

0

0,3333

0,3333

0,3333

Tabela 5: Sequência de vetores rk para uma rede com absorção.

12

1.4 I N T E R P R E TA Ç Ã O P R O B A B I L Í S T I C A D O A L G O R I T M O D E PA G E R A N K

Olhando a sequência vemos que a importância dos sites 1, 2 e 3 são lentamente

absorvidas pelas demais páginas.

Isso por que existem links de 3 para 4 e 5, não

existem links das páginas 4, 5 e 6 para as demais, como salientado na ﬁgura 5.

Figura 5: Rede com grupo de páginas auto-referenciadas.

Assim, quando o navegador chegar à rede em destaque, ele não encontrará links que

liguem o segundo bloco ao primeiro, permanecendo para sempre alí dentro. Ligações

desse tipo são dissipadoras de importância, pois drenam o grau de importância de ou-

tras três páginas. Isso não impede a convergência do método, e tampouco a existência

do vetor estacionário. O principal problema está em atribuir PageRank 0 a diversas

páginas, que poderiam ser inclusive mais relevantes que as páginas do grupo dissipa-

dor. Mas mesmo que não fosse, não há interesse em colocar nível de importância 0

a nenhuma página. Toda página tem seu nível de importância, mesmo que dentro de

parâmetros de busca muito especíﬁcos.

Isso signiﬁca que, mesmo que encontremos

um vetor estacionário r, este não carrega consigo as informações que buscamos.

Vistos os principais problemas existentes na web, e que atrapalham o funcionamento

perfeito do algoritmo de PageRank, está no hora de entendermos como resolvê-los.

Mas para isso, vamos primeiro introduzir uma forma diferente de olharmos para o

processo.

1.4 I N T E R P R E TA Ç Ã O P R O B A B I L Í S T I C A D O A L G O R I T M O D E PA G E R A N K

Como vimos na seção anterior, a matrix de hyperlinks, se usada sozinha, possui

problemas que podem inviabilizar o cálculo do vetor estacionário, falhando assim em

determinar o PageRank de cada página. Por isso será necessário que façamos algumas

mudanças no modelo, mas sem perder de vista nosso objetivo principal: atribuir a

cada página da web um índice de importância. Para melhor justiﬁcar as mudanças que

13

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

faremos, vamos antes propor uma nova interpretação do modelo. Uma nova forma de

olhar o processo, que nos permitirá justiﬁcar as mudanças a serem feitas.

Se acompanharmos de perto a navegação de um internauta ﬁxo, muito provavel-

mente identiﬁcaremos padrões para sua navegação, e diﬁcilmente poderemos dizer

que suas escolhas de páginas são fruto do acaso. Mas os padrões de navegação dos di-

versos internautas que hoje se utilizam da web são muito variados, e assim ao modelar

o comportamento de um internauta aleatoriamente escolhido, é plausível trabalhar-

mos com a hipótese de que sua navegação é de fato aleatória. Em outras palavras,

podemos supor que a cada passo da sua navegação o internauta sai de uma página,

escolhendo aleatoriamente dentre os links disponíveis nesta. Outra forma de colocar-

mos tal hipótese é supor que, dado a diversidade de padrões de navegação na internet,

é pouco razoável atribuirmos importância maior a um link com prejuízo aos demais

links na mesma página, de modo que a proporção de cliques em um link deve ser igual

para todos os links da página, isto é, o inverso do total de links na página.

Suponhamos então que um internauta esteja navegando pela web de forma aleató-

ria, ou seja, uma vez que ele chega ao site sj, que possui uma quantidade lj de links
para outras páginas, ele escolhe um dos links com probabilidade 1/lj, e segue para
onde este link o envia. Assim, a probabilidade deste internauta ir de sj para si é de /lj,
se existir um link de sj para si, e 0 caso contrário.

Desta forma, a entrada Hij da matriz H poderia ser interpretada como a probabi-
lidade do internauta ir da página sj para a página si. Como veremos mais a frente,
esta interpretação da matriz H ainda possui um pequeno problema, mas que pode ser

resolvido de forma bastante simples.

Antes de passarmos para a análise dos problemas listados na seção anterior, vamos

antes interpretar o PageRank sob este novo prisma. Para isso, considere a rede descrita

no exemplo 1.1, representada pela ﬁgura 6.

Chame de t1, t2, t3, t4 e t5 a proporção média de tempo que o internauta passa nos
sites s1, s2, s3, s4 e s5 respectivamente. Vamos nos concentrar por um momento no site
s1. Pelo modelo descrito, toda visita feita ao site s1 só pode ter sido originada do
site s2 ou s3. Deste modo, o total de visitas ao site s1 será dado pelo total de visitas
a s2 que seguiram para s1 somada ao total de visitas a s3 que seguiram para s1, e a
mesma argumentação vale para a proporção de tempo passada em cada site. Como

a probabilidade do internauta ir de s2 para s1 é 1/2, então aproximadamente metade

14

1.4 I N T E R P R E TA Ç Ã O P R O B A B I L Í S T I C A D O A L G O R I T M O D E PA G E R A N K

Figura 6: Exemplo de rede

das visitas a s2 seguiram para s1, e analogamente 1/3 das visitas a s3 seguiram para s1
(note que s3 tem 3 links). Isso tudo nos mostra que

t1 =

1
2

t2 +

1
3

t3.

Fazendo o mesmo raciocínio para as demais páginas da rede, concluímos que






3 t5

1

1

1

2 t2 + 1
3 t3
3 t1 + t4 + 1
3 t1 + 1
3 t5
2 t2 + 1
3 t3 + 1
3 t1 + 1
3 t3

1

1

= t1

= t2

= t3

3 t5 = t4

= t5.

Observe agora que os valores de t1, t2, t3, t4 e t5 obedecem ao mesmo sistema de
equações que r1, r2, r3, r4 e r5. Além disso, é interessante notar que a soma dos tempos
t1, t2, t3, t4 e t5 deve ser 1, uma vez que representa a proporção total de tempo que o
internauta passou navegando.

Deste modo, nesta visão probabilística do modelo, o PageRank de cada página pode

ser visto como a proporção de tempo que um internauta aleatório passa naquela pá-

gina. Esta é uma visão absolutamente compatível com a noção de importância de uma

página. Ou seja, uma página é mais importante que outras se um internauta aleatório

passa mais tempo nela do que nas demais.

Este tipo de modelo é conhecido como Cadeia de Markov, que será melhor estudada
nos próximos capítulos. No capítulo 2 veremos uma interpretação para os vetores rk,

usados no cálculo de r, o que nos levará a uma interpretação distinta (mas equivalente)

do vetor estacionário r.

15

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

1.4.1 Alterando o modelo

Como comentamos anteriormente, o uso apenas da matriz H pode causar proble-

mas na determinação do PageRank, dependendo de características das conexões da

rede. A seguir vamos abordar estes problemas, e ver como solucioná-los usando a

interpretação probabilíssima que acabamos de estudar.

O primeiro problema que descrevemos é causado por páginas que não possuem link,

ou seja, as chamadas dangling nodes. De fato, veja que a coluna correspondente a um

dangling node é de certa forma incompatível com o passeio aleatório do internauta.

Isso por que toda entrada desta coluna é nula, o que não nos permite interpretá-la da

mesma forma que as demais. Note que uma vez que o internauta, em seu caminho

aleatório, atinge um destes sites ele não sabe o que fazer. A probabilidade de ir para

outro site, até este momento, é nula. Mas isso signiﬁcaria que a probabilidade de

permanecer neste site é 1. Isto por que não queremos que o passeio acabe.

Poderíamos então modiﬁcar a matriz H colocando o valor 1 na entrada Hii sempre
que si for um dangling node. Mas isso causa um outro problema. Note que agora
temos uma subrede formada por apenas um site, que possui link apenas para si mesmo.

Entramos assim no mesmo problema das redes auto-referenciadas discutidas anterior-

mente. Como vimos, este tipo de rede rouba toda a importância das demais páginas.

Para resolver esta questão imaginemos que uma vez que o internauta acabe de nave-

gar uma dangling node ele volta a navegar, escolhendo uma página qualquer da rede

de forma aleatória. Isso é equivalente a dizer que cada dangling node possui links para

todas as outras páginas (incluindo ela mesma).

Com isso modiﬁcamos a matriz Hyperlink H, substituindo uma coluna de zeros cor-

respondentes a uma dangling nodes por uma coluna na qual cada entrada é /N, onde

N é o total de páginas na web. Desta forma, se modiﬁcarmos a matriz H, que repre-

senta o exemplo da subseção 1.3.1, e chamarmos essa nova matriz de S, ﬁcaríamos

com

S =







1
3
1
3
1
3

1
2
0
1
2







.

1
3
1
3
1
3

Esta modiﬁcação altera também o vetor estacionário, que agora deve responder à

relação

16

r = Sr.

1.4 I N T E R P R E TA Ç Ã O P R O B A B I L Í S T I C A D O A L G O R I T M O D E PA G E R A N K

Segue assim que

r =







.







3
8
1
4
3
8

Podemos pensar também na matriz S como sendo uma soma da matriz H com uma

matriz que vamos chamar de A que representaria as páginas sem links, isto é, a matriz

A usa o artifício de considerar cada dangling nodes com tendo uma saída para todas as

outras páginas da rede. Assim, o exemplo da subseção 1.3.1 ﬁca







H =

Então













e A =

0

0

1
2
0 0 0
1
2

0

0

S = H + A =







1
3
1
3
1
3

1
2
0
1
2

0

0

0







.

1
3
1
3
1
3







.

1
3
1
3
1
3

1
3
1
3
1
3

Note que a matriz S possui agora entradas não-negativas, e a soma de todas as

entradas de qualquer coluna é 1. Uma matriz com estas característica é chamada de

matriz de transição de probabilidades, e será estudada em mais detalhes nos próximos

capítulos.

Infelizmente esta modiﬁcação não resolve os problemas causados pelas páginas em

ciclo e pelas redes auto-referenciadas. Para resolver estes problemas, analisemos o

modelo um pouco mais de perto.

Do jeito que descrevemos o problema, a única forma do internauta chegar a uma

certa página é através de um link em alguma outra página. Mas isto nem sempre é

verdade. Frequentemente, ao navegarmos pela web, somos provocados por notícias,

imagens, artigos ou mesmo por pura curiosidade, a buscar informações em locais na

web para os quais a página que nos encontramos não possui links.

É razoável então pensarmos na seguinte modiﬁcação. Cada vez que nosso internauta

estiver um uma dada página, com probabilidade α ele escolhe permanecer no padrão
de navegação descrito por S, e com probabilidade (1 − α) ele pula para uma página
escolhida aleatoriamente, com probabilidade 1/N para cada página.

17

O A L G O R I T M O D E O R D E N A M E N T O D O G O O G L E

Assim, chamando de G a matriz utilizada pelo Google, temos

G = αS + (1 − α)

1
N

U,

(1.4)

onde S é a matriz de hiperlinks modiﬁcada, N é o número de páginas na web e U é a
matriz N × N com todas as entradas iguais a 1.

Com isso o PageRank de cada página é dado agora pelo vetor estacionário r, com

entradas positivas somando 1, que atende ao sistema

r = Gr.

(1.5)

É interessante notar que agora a matriz G possui todas as entradas positivas. Além

disso G é também uma matriz de transição.

Para exempliﬁcar, vamos calcular a matriz G para a rede descrita no problema de

redes auto-referenciadas, cuja ﬁgura copiamos abaixo. Para isso consideraremos α =

3/4.

Figura 7: Rede com problemas.

0 0 0

1
0
2
1
0
2
1
1
2
2
0 0

0 0 0 0
1
3
0 0 0 0
1
1
2
3
1
1
2
3
0
0 0 0

0 0

1
2
0
1
2

0
1
2
1
2















+

1
4

·

1
6

G =















1
24
5
12
5
12
1
24
1
24
1
24

5
12
1
24
5
12
1
24
1
24
1
24

1
24
7
24
1
24
7
24
7
24
1
24

1
24
1
24
1
24
1
24
5
12
5
12















1
24
1
24
1
24
5
12
1
24
5
12

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1















,















.

1
24
1
24
1
24
5
12
5
12
1
24

Temos















G =

3
4

e portanto

18

1.4 I N T E R P R E TA Ç Ã O P R O B A B I L Í S T I C A D O A L G O R I T M O D E PA G E R A N K

Calculando r encontramos

r =















.















4
51
5
51
11
102
25
102
25
102
23
102

No artigo citeBrin98, Brin e Page comentam que em geral o valor de α é estabelecido

como 0, 85.

Como mostraremos nos próximos capítulos, estas modiﬁcações resolvem todos os

problemas descritos anteriormente. Em particular, podemos agora responder positiva-

mente às três questões colocadas no início da seção 1.3. Para entender as respostas

para estes questionamentos precisamos entender um pouco melhor as chamas Cadeias

de Markov.

Infelizmente, não conseguiremos mostrar que o vetor estacionário sem-

pre existe, pois os conceitos necessários para tal fogem do escopo deste trabalho. No

entanto apresentaremos uma demonstração acessível para a convergência no método

iterativo.

Neste sentido note que, como todas as entradas da matriz são positivas, o cálculo

do PageRank via resolução do sistema linear é muito complexo, uma vez que todas as

variáveis estarão presentes em todas as equações. Isso torna o método iterativo ainda

mais importante, uma vez que ele possui um custo operacional mais baixo (ver [11]).

19

2

C A D E I A S D E M A R K O V

”De onde eu venho não importa pois já passou O que importa é saber pra onde vou"(Senhorita

- Zé Geraldo)

Ao longo da história homens brilhantes buscaram e buscam prever o futuro. Cer-

tamente os sentimentos de satisfação e prazer chegam ao ápice quando conseguimos

enxergar ou prever o que os outros não conseguem, principalmente quando essas pre-

visões partem da beleza de construções matemáticas.

Neste capítulo vamos estudar algumas propriedades básicas de uma estrutura mate-

mática aleatória conhecida como Cadeia de Markov. O que estudaremos aqui é apenas

o básico, suﬁciente para entendermos a matemática encontrada no PageRank. O leitor

interessado em maiores detalhes sobre a teoria de probabilidades e cadeias de Markov,

pode encontrar em [3, 6, 9, 10].

Para isso começaremos tentando entender o comportamento de um modelo simples.

Suponhamos então que em um jogo de dados tenhamos a seguinte comanda: um

jogador lança um dado, não viciado, com numeração de 1 a 6 em cada uma de suas

faces e submetido as seguintes condições, se ao lançar o dado, este cair com uma

das faces com numeração par voltada para cima, o jogador ganha e segue no jogo,

porém, para ganhar na próxima jogada, ele deverá obter um número menor do que

5 na face superior do dado, dando ao jogador uma leve vantagem. Deste modo, se

este jogador perde uma jogada ele teria probabilidade 1/2 para ganhar no lançamento

seguinte, pois para sair número par em um dado temos três possibilidades. Logo, a

probabilidade deste jogador perder é também 1/2. Agora, se o jogador ganhou uma

dada jogada, a probabilidade de ganhar a próxima jogada é de 4/6 = 2/3, e de perder

é 2/6 = 1/3.

O que descrevemos até agora é como o jogo se desenrola, como acontecem as tran-

sições de uma jogada para a próxima. Para o modelo ﬁcar bem deﬁnido precisamos

21

C A D E I A S D E M A R K O V

deﬁnir ainda como o jogo começa! Sem uma referência anterior, não sabemos quais

as probabilidades de vitória e derrota do jogador na primeira rodada. Assim, acompa-

nhando a sequência de vitórias e derrotas do jogador a cada jogada n, precisamos de

certa forma escolher se no instante 0 o jogador terá vitória ou derrota. Esta escolha
pode ser feita também de forma aleatória. Deﬁna então p(k)
, k = 0, 1, 2, . . ., as
probabilidades de vitória e derrota, respectivamente, na k−ésima rodada. Vamos a se-
guir tentar calcular os valores de p(k)
f para todo k, e estudar como se comportam
estas probabilidade depois de várias jogadas.

g e p(k)
f

g e p(k)

Para iniciar, vamos tabelar as probabilidades dadas no problema. Temos

g
2
3
1
3

g

f

E transformando em matriz obtemos

T =

(cid:34) 2
3
1
3

f
1
2
1
2

1
2
1
2

(cid:35)

.

Analisando a árvore de probabilidades vemos que

p(1)
g =

p(1)
f =

p(0)
g +

p(0)
g +

2
3
1
3

1
2
1
2

p(0)
f

p(0)
f

.

Repare também que

(cid:34)

T ·

p(0)
g
p(0)
f

(cid:35)

=

(cid:34) 2
3
1
3

1
2
1
2

(cid:35)

(cid:34)

·

p(0)
g
p(0)
f

(cid:35)



=



22

2

3 p(0)
3 p(0)

g + 1
g + 1

2 p(0)
2 p(0)

1

f

f





C A D E I A S D E M A R K O V

e portanto

E escrevendo

para n = 0, 1, 2, · · ·, temos

(cid:35)

(cid:34)

= T ·

(cid:34)

p(1)
g
p(1)
f

(cid:35)

.

p(0)
g
p(0)
f

p(n) =

(cid:34)

(cid:35)

,

p(n)
g
p(n)
f

p(1) = T · p(0).

Com o mesmo raciocínio encontramos que

p(2) = T · p(1)

p(3) = T · p(2)

...

p(n) = T · p(n−1).

(2.1)

É interessante observar também que para todo n = 0, 1, 2, . . .

p(n) = T · p(n−1) = T · T · p(n−2) = T2 · p(n−2) = · · · = Tn · p(0).

Ou seja

p(n) = Tn · p(0).

Com isso temos uma forma de calcular os valores de p(n) para diferentes valores de
n. Mas como mostra a expressão acima, precisamos primeiro escolher valores para p(0).
Tome então

p(0) =

(cid:34)

(cid:35)

1

0

.

Calculando então algumas iterações, encontramos

p(0)

p(1)

p(2)

p(3)

p(4)

p(5)

1

0

0,6667

0,6111

0,6019

0,6003

0,6001

0,3333

0,3889

0,3981

0,3997

0,3999

p(6)

0,6

0,4

. . .

. . .

. . .

p(10)

0,6

0,4

Tabela 6: Sequência de vetores p(k) para vários lançamentos.

23

C A D E I A S D E M A R K O V

Os valores da tabela acima são aproximados, e foram calculados com 4 casas deci-

mais de precisão. Mas ainda assim ela parece sugerir que a medida que o jogo passa
as probabilidades p(n) convergem para algum vetor

(cid:35)

.

(cid:34) 3
5
2
5

Mesmo que aceitemos que a sequência converge, o vetor limite pode ainda depender
do vetor inicial p(0). Para veriﬁcar tal dependência, assim como tentar entender se a
convergência ocorre, tome

p(0) =

(cid:34)

(cid:35)

0

1

.

Neste caso, calculando algumas iterações, encontramos

p(0)

0

1

p(1)

0,5

0,5

p(2)

p(3)

p(4)

p(5)

0,5833

0,5972

0,5995

0,5999

0,4167

0,4028

0,4005

0,4001

p(6)

0,6

0,4

. . .

. . .

. . .

p(10)

0,6

0,4

Tabela 7: Sequência de vetores p(k) para vários lançamentos.

Da mesma forma que na tabela 6, a tabela acima parece sugerir que p(n) converge

para o mesmo vetor

µ =

(cid:35)

.

(cid:34) 3
5
2
5

Mas se a convergência ocorre para estas duas escolhas de vetor inicial então, para

qualquer

com pg + p f = 1, temos

p(0) =

(cid:34)

(cid:35)

,

pg
p f

p(0) =

(cid:35)

(cid:34)

= pg

(cid:34)

pg
p f

Segue que

p(n) = Tn · p(0) = Tn

pg

(cid:32)

(cid:34)

(cid:35)

(cid:34)

+ p f

1

0

1

0

0

1

(cid:35)

(cid:34)

+ p f

(cid:35)

.

0

1

(cid:35)(cid:33)

= pgTn

(cid:35)

(cid:34)

1

0

+ p f Tn

(cid:35)

(cid:34)

0

1

24

C A D E I A S D E M A R K O V

e assim p(n) converge para

(cid:35)

pg

(cid:34) 3
5
2
5

+ p f

(cid:35)

(cid:34) 3
5
2
5

(cid:35)

=

(cid:34) 3
5
2
5

(cid:0)pg + p f

(cid:1) =

(cid:35)

.

(cid:34) 3
5
2
5

Segue que p(n) deve convergir para

µ =

(cid:35)

.

(cid:34) 3
5
2
5

para qualquer escolha de p(0).

Uma boa forma de entender qual deve ser o vetor µ, supondo que a convergência
ocorra, vem da equação (2.1). Como p(n) = T · p(n−1), se p(n) converge então o limite µ
deve satisfazer

Ou seja, se

com x + y = 1, então

de onde segue que

µ = Tµ.

µ =

(cid:34)

(cid:35)

,

x

y

(cid:34)

(cid:35)

=

(cid:34) 2
3
1
3

x

y

1
2
1
2

(cid:35) (cid:34)

(cid:35)

,

x

y





1

2

3 x + 1
3 x + 1
x + y

2 y = x

2 y = y

.

= 1

Basta agora resolver o sistema acima para encontrar

µ =

(cid:35)

.

(cid:34) 3
5
2
5

Uma forma de interpretar tal convergência é pensar que, de certo modo, a medida

que o jogo corre, o modelo “esquece” como o jogo começou e começa entrar em uma

espécie de equilíbrio. Este como consequência da vantagem recebida pelo jogador a

cada vitória, este equilíbrio é tal que o jogador, em média, ganha 3 a cada 5 jogadas e,

consequentemente, perde 2 a cada 5 jogadas. Ou seja, o jogador ganha em média 3/5

das jogadas, e perde 2/5 destas.

Apesar de aqui termos modelado um simples jogo de dados, o fenômeno descrito é o
mesmo estudado no algoritmo de PageRank. Se olharmos o vetor r0 como o vetor que

25

C A D E I A S D E M A R K O V

determina a probabilidade do internauta começar a navegar em cada página da web,
a convergência do vetor rk mostra que após algum tempo navegando, o internauta

“esquece” em que página começou, fazendo o processo entrar em equilíbrio. E assim,

como já comentamos anteriormente, as entradas do vetor limite r indicam então a

proporção média de tempo que o internauta passa em cada página.

A seguir vamos explicar brevemente a estrutura matemática onde podemos encaixar

estes dois problemas.

2.1 C A D E I A S D E M A R K O V

Processos como o descrito no exemplo anterior são conhecidos na matemática como

Cadeias de Markov, e são frequentemente usados para modelar processos com incer-

teza.

Uma Cadeia de Markov nada mais é do que uma sequência aleatória de elementos,

com uma regra de formação deﬁnida. Assim, para entender o que é uma Cadeia de

Markov, precisamos antes entender como se dá a transição de um elemento a outro

desta sequência. Para isso, considere a deﬁnição abaixo.

Deﬁnição 2.1. Uma matriz T = [Ti,j]m×m dada por

T =










p11
p21
...
pm1

p12
p22
...
pm2










. . .

. . .

p1m
p2m
...
. . . pmm

é chamada de matriz de probabilidades de transição, matriz estocástica ou simplesmente

matriz de transição se

1. pij ≥ 0, para quaisquer i, j ∈ {1, . . . , m};

2. Para qualquer j ∈ {1, . . . , m} vale que

p1j + p2j + · · · + pmj = 1.

Ou seja, a soma dos elementos de cada coluna é sempre 1.

26

2.1 C A D E I A S D E M A R K O V

Dada uma matriz de transição T, para construir agora o que chamaremos de cadeia

de Markov, proceda da seguinte forma:

• Tome um conjunto S = {a1, . . . , am} que chamaremos de espaço de estados, e em
seguida escolha um elemento de S para iniciar o processo, e chame este elemento

de X0. A escolha de X0 pode ser feita de forma aleatória ou determinística.

• A seguir, se X0 = aj escolha o estado X1 usando para isso a j-ésima coluna da
matriz de transição T. Ou seja, a probabilidade de X1 = ai se X0 = aj será pij.

• Siga da mesma forma para os estados seguintes. Ou seja, sempre que a cadeia

estiver em ak, ela saltará para al com probabilidade plk.

O terceiro passo acima será denotado por

P(Xn = al|Xn−1 = ak) = plk,

e leremos “a probabilidade de Xn ser igual a al dado que Xn−1 é igual a ak é plk”. É por
esta razão que precisamos que a soma os elementos de cada coluna seja 1.

Temos

Deﬁnição 2.2. Uma cadeia de Markov ou processo de Markov com matriz de transição
T e espaço de estados S = {a1, a2, ..., am} é uma sequência aleatória X0, X1, . . . , tal que

(i) P(Xn = ai|Xn−1 = aj) = pij para quaisquer i, j ∈ {1, . . . , m};

(ii) A trajetória feita para chegar até Xn−1 não muda as probabilidades de escolha

de Xn, dependendo apenas de Xn−1.

Assim, o jogo descrito no início do capítulo é um exemplo de Cadeia de Markov.

Da mesma forma, se considerarmos a interpretação probabilística do algoritmo de

PageRank descrito no capítulo 1, temos outro exemplo de Cadeia de Markov.

Agora, seguindo os passos do exemplo anterior, vamos considerar que a cadeia co-

meça em um estado aleatório, escolhido de acordo com um vetor de probabilidades




p(0) =









.

p(0)
1
...
p(0)
m

Ou seja, a probabilidade de iniciarmos o processo em um estado ak é dada por p(0)
k .
Perguntamos agora qual a probabilidade p(1)
i de estarmos em um estado ai no instante

27

C A D E I A S D E M A R K O V

1. Seguindo o mesmo raciocínio do exemplo, percebemos que, para estar em ai no
instante 1, temos que primeiro saber onde a cadeia estava no instante 0. Assim, se
a cadeia estava em a1, o que ocorre com probabilidade p(0)
1 , ela salta para ai com
probabilidade pi1. Do mesmo modo, se estava em a2 (e isso ocorre com probabilidade
p(0)
2 , a cadeia salta para ai com probabilidade pi2. Seguindo o mesmo raciocínio para
cada estado de S encontramos que

i = pi1 · p(0)
p(1)

1 + pi2 · p(0)

2 + · · · + pim · p(0)
m .

E assim, escrevendo as probabilidade p(1)

i

como um vetor coluna. Ou seja, se

encontramos que

p(1) =







,







p(1)
1
...
p(1)
m

p(1) = T · p(0).

(2.2)

Vamos aqui fazer um pequeno parêntese, para notar que se v = [vi]m×1 é um vetor

de probabilidades, isto é,

• vk ≥ 0 para todo k = 1, . . . , m;

• v1 + v2 + · · · + vm = 1,

então para u = Tv, temos

ui = Ti1v1 + Ti2v2 + Ti3v3 + . . . + Timvm ≥ 0.

Além disso

u1 + u2 + . . . + um = (T11v1 + . . . + T1mvm) + (T21v1 + . . . + T2mvm) + . . . + (Tm1v1 + . . . + Tmmvm)

e portanto, como T é uma matriz de transição, cada uma de suas colunas é um vetor

de probabilidades, e

u1 + u2 + . . . + um = (T11 + T21 + . . . + Tm1)v1 + . . . + (T1m + T2m + . . . + Tmm)vm

= v1 + v2 + . . . + vm

= 1.

Daí se T é uma matriz de transição e v é um vetor de probabilidades, então u = Tv
é também um vetor de probabilidades. Concluímos então que o vetor p(1) deﬁnido em
(2.2) é um vetor de probabilidades.

28

2.1 C A D E I A S D E M A R K O V

Voltando ao nosso problema, do mesmo modo que em (2.2), podemos deﬁnir vetor
de probabilidades p(n) como o vetor cuja a i-ésima linha indica a probabilidade de
observarmos o estado ai após n passos. E assim, teremos

e

p(n) =













p(n)
1
...
p(n)
m

p(n) = T · p(n−1).

Assim, abrindo a relação acima, encontramos que

p(n) = Tn · p(0).

(2.3)

(2.4)

Observação 2.1.1. A equação (2.4) nos permite interpretar a entrada (i, j) da matriz
Tn como a probabilidade da cadeia ir de aj para ai em n passos. Para ver isso, denote as
entradas de Tn por bij e observe que

p(n)
i = bi1 · p(0)

1 + bi2 · p(0)

2 + · · · + bim · p(0)
m .

2.1.1 Medidas Invariantes

No exemplo descrito no início do capítulo, mostramos que os vetores

p(n) =

(cid:34)

(cid:35)

p(n)
g
p(n)
f

convergiam para um certo vetor µ, e que esta convergência não dependia do vetor p(0)
escolhido. Mostramos também que o vetor é tal que µ = Tµ. Surge então a questão:

Isto é válido sempre?

Mais exatamente, queremos saber se dado um vetor de probabilidades p(0), a sequên-
cia p(n) deﬁnida pela equação (2.3) converge para algum vetor µ. E de que forma µ
depende de p(0). Esta pergunta já surgiu na descrição do algoritmo PageRank, e lá
mostramos que a convergência nem sempre ocorre. Surgem então algumas questões:

1. Sempre existe um vetor µ tal que µ = Tµ?

2. Caso exista, é único?

3. Em que situações p(n) converge para µ?

29

C A D E I A S D E M A R K O V

4. A convergência depende de p(0)?

Infelizmente, responder parte destas peguntas, como a existência e unicidade de tal

vetor, fogem do escopo deste trabalho. De todo modo vamos tentar dar alguns passos

no sentido das respostas. Começaremos estudando o vetor limite, e que características

ele deve ter. No próximo capítulo apresentaremos uma construção que permite mostrar

a convergência para tal vetor, uma vez que sabemos de sua existência e unicidade.

Suponhamos então que a sequência p(n) converge para um vetor de probabilidades

µ =










.










µ1
µ2
...
µm

Segue da equação (2.3), fazendo n crescer, que µ deve satisfazer

µ = Tµ.

(2.5)

Vetores de probabilidades satisfazendo (2.5) são conhecidos como medidas invari-

antes da cadeia de Markov com matriz de transição T, e razão para isso é que, se

escolhermos o estado inicial da cadeia de acordo com o vetor µ, então a probabilidade
da cadeia estar em ai no instante n é µi para qualquer instante n. De fato, da equação
(2.5), segue

e seguindo deste modo

Assim, se p(0) = µ então

T2µ = T(Tµ) = Tµ = µ,

Tnµ = µ.

p(n) = Tn · p(0) = Tnµ = µ.

É interessante observar também que, de (2.4), uma das formas de estudar a con-
vergência de p(n) é estudar a convergência da matriz Tn. Em particular, a existência e
unicidade de µ é equivalente a convergência de Tn para uma matriz M com todas as
colunas iguais. Isso segue do fato que, se

vk =













,













0
...
1
...
0

30

2.1 C A D E I A S D E M A R K O V

é o vetor com a k-ésima entrada 1 e as demais 0, então Mvk retorna a k-ésima coluna
da matriz M.

Assim se Tn converge para M com todas as colunas iguais a um vetor µ então,

Mvk = µ,

para todo k = 1, . . . , m. E como p(0) = p(0)

1 v1 + · · · + p(0)

m vm então

p(n) = Tn · p(0) −→ M · p(0), quando n → ∞.

Mp(0) = M

(cid:16)

1 v1 + · · · + p(0)
p(0)

m vm

(cid:17)

1 Mv1 + · · · + p(0)
= p(0)
m Mvm
(cid:16)
(cid:17)
p(0)
1 + · · · + p(0)
µ

=

m

= µ,

de onde segue que para qualquer escolha de p(0),

p(n) −→ µ,

quando n → ∞.

A invariância de µ sai diretamente de (2.3), fazendo n → ∞.

Reciprocamente, se p(n) −→ µ, quando n → ∞, para qualquer escolha de p(0), fa-
zendo p(0) = vk mostramos que Tn converge para uma matriz M com todas as colunas
iguais a µ.

Os cálculos acima mostram que µ pode ser visto como uma espécie de equilíbrio da

cadeia. Ou seja, se deixamos a cadeia rodar por tempo suﬁciente, o vetor de probabili-
dades p(n) ﬁca próximo de µ, e cadeia começa a se comportar aproximadamente como
se tivéssemos escolhido o estado inicial de acordo com µ. Em outras palavras, se para

n suﬁcientemente grande temos

p(n) ∼ µ

, então

e para todo k > n teremos

p(n+1) = T · p(n) ∼ Tµ = µ,

p(k) ∼ µ.

Assim, se quisermos calcular, por exemplo, o tempo médio que a cadeia passa em

cada estado, podemos observar o comportamento da cadeia apenas quando esta entra

31

C A D E I A S D E M A R K O V

em equilíbrio (ou quando está próximo disso), ou então considerar que a cadeia já foi

iniciada de acordo com µ.

A relação entre tempo médio passado em um estado e a medida invariante µ, é

a mesma explicada no exemplo do jogo de dados, e no algoritmo de PageRank. Lem-

brando, no caso do jogo de dados, após um número suﬁcientemente grande de jogadas,

o jogo esquece como foi iniciado e começa a observar uma média de 3 vitórias a cada

5 jogadas, proporção esta dada pelo vetor µ.

O mesmo ocorre para uma medida invariante qualquer. Considere uma cadeia de

Markov cujo estado inicial foi escolhido de acordo com uma medida invariante µ. Sa-
bemos que a probabilidade da cadeia estar em um estado ai em qualquer instante n
é dada por µi, e portanto depois de um tempo n suﬁcientemente grande, esperamos
observar ai aproximadamente nµi vezes. Assim, o tempo médio que a cadeia passa em
ai é exatamente µi.

O algoritmo PageRank pode ser visto então como uma cadeia de Markov, com ma-

triz de transição G dada por (1.4). O vetor de PageRank r é portanto exatamente a

medida invariante da cadeia, como vemos em (1.5). A idéia do algoritmo é se valer da
convergência da sequência rn e encontrar uma aproximação para r.

2.2 M AT R I Z D E T R A N S I Ç Ã O R E G U L A R

Nesta seção vamos enunciar condições nas quais a medida invariante existe, é única
e a convergência de p(n) ocorre independente de como escolhemos o estado inicial.
Como já comentamos, a demonstração de existência e unicidade da medida invariante

é técnica, e foge do escopo deste trabalho. A convergência, na situação que apresen-

taremos abaixo, é também técnica e sem interesse para nós. Mas no capítulo 3 estu-

daremos uma forma de mostrar tal convergência para algumas matrizes de transição,

incluindo a matriz usada no algoritmo de PageRank.

Antes de mais nada vamos lembrar os principais problemas que precisamos resolver

no algoritmo de PageRank.

Para começar, lembre dos problemas das páginas dispostas em ciclos. Neste caso, a

convergência não ocorria pois, se iniciássemos a cadeia em um certo estado no ciclo,

aconteceria um alternância entre estados, de modo que certos estados só poderiam

32

2.2 M AT R I Z D E T R A N S I Ç Ã O R E G U L A R

visados em certos instantes de tempo. Isso se reﬂete na sequência rk, de modo a torná-

la uma sequência periódica e, portanto, não convergente.

Os outros dois problemas, a saber as páginas sem links e os conjuntos de páginas

auto-referenciadas, levavam ao mesmo problema. Ao entrarmos nestes sites, nunca

mais sairíamos deles, fazendo com que o medida invariante fosse nula fora destes

pontos.

É fato que isso pode não afetar diretamente a existência da medida invariante, ou

na convergência para ela, mas a existência de mais de um destes conjuntos pode sim

afetar sua unicidade. Para isso basta observar que, caso tenhamos dois conjuntos auto-

referenciados distintos, e a cadeia inicie seu passeio dentro do primeiro, ela não sairá

mais de lá. Assim, a convergência, caso ocorra, será para uma medida invariante com

entrada nula para sites do segundo conjunto. Repetindo a mesma análise para uma

cadeia iniciada dentro do segundo grupo de páginas, encontramos uma possível me-

dida invariante nula nas páginas do primeiro grupo. Encontramos assim duas medidas

distintas!

Uma forma de corrigir este problema é tomar o que chamaremos de matriz de tran-

sição regular, que deﬁnimos abaixo.

Deﬁnição 2.3. Uma matriz de probabilidades de transição é regular se alguma de suas

potências tem todos os elementos não nulos.

Em particular, a matriz G usado no algoritmo do PageRank é uma matriz de transição

regular, uma vez que todas as suas entradas já são estritamente positivas.

Para terminar este capítulo, enunciaremos sem demonstrar um teorema que garante

o funcionamento do algoritmo de PageRank.

Teorema 2.4. Se T = [Ti,j]m×m é uma matriz de transição regular, então

(i) Existe um único vetor de probabilidades µ = [µi]m×1 tal que µ = Tµ;

(ii) Para qualquer vetor de probabilidades p(0) a sequência deﬁnida por

p(n) = T · p(n−1),

n ∈ {1, 2, 3, . . .}, converge para o vetor µ.

33

3

A C O P L A N D O C A D E I A S

Neste capítulo vamos mostrar uma maneira de construir cadeias de Markov, e a

partir de uma destas construções mostraremos a convergência para medida invariante

tratada do capítulo anterior. A maneira descrita abaixo é uma adaptação discreta do

método apresentado em [6], onde consideraremos apenas matrizes com entradas raci-

onais. Os cálculos para matrizes com entradas quaisquer são similares, mas pressupõe

do leitor um conhecimento um pouco mais profundo de teoria de probabilidades, e

por isso decidimos por esta adaptação.

3.1 S I M U L A N D O U M A D I S T R I B U I Ç Ã O

Considere a seguinte distribuição de probabilidades no conjunto Ω = {x1, x2, x3, x4, x5}

dada por

P1 =

(cid:26) 1
10

;

3
10

;

2
10

;

1
10

;

3
10

(cid:27)

.

Ou seja, a probabilidade de sortear x1 é 1/10, de sortear x2 é 3/10 e assim por diante.

Queremos agora simular a distribuição P1. Em outras palavras, queremos criar um
experimento aleatório no qual a probabilidade de observar um dado valor do conjunto
{x1, x2, x3, x4, x5} seja dada pelo valor correspondente em P1.

A primeira ideia que vem a mente é escolher uma série de bolas coloridas de cor
distinta, e marcá-las com elementos de Ω de modo que as proporções desejadas sejam

respeitadas. Precisaremos então de 1 bola marcada x1, 3 marcadas x2, 2 com x3, 1
com x4 e outras 3 com x5, em um total de 10 bolas.

Uma alternativa equivalente (e que mais a frente vai se mostrar útil) é separar 10

bolinhas de mesmo tamanho e ordená-las. Na ﬁgura 8 associamos a cada bola um

35

A C O P L A N D O C A D E I A S

Figura 8: Simulando uma distribuição discreta.

elemento do conjunto {x1, x2, x3, x4, x5} de modo que a proporção de bolas de um
certo tipo seja justamente a probabilidade de sortearmos este tipo. A ﬁgura 9 mostra

uma maneira de fazer isso.

Figura 9: Simulando uma distribuição discreta.

Deste modo se sortearmos, por exemplo, a bola de número 5 estaremos sorteando o

elemento x3, e da mesma forma sortear a bola 8 equivale a sortear o elemento x5.

É interessante observar que esta relação entre bola numerada e elemento do con-

junto pode ser feito de diversas formas diferentes, e as probabilidades serão as mes-
mas. A ﬁgura 10 mostra outras duas formas de relacionar os elementos de Ω com

bolas numeradas que simulam o mesmo sorteio.

Figura 10: Duas outras formas de relacionar elementos e bolas.

Apenas para ﬁxar ideia, vamos fazer mais um exemplo. Considere a distribuição de

Ω = {x1, x2, x3, x4} dada por

P =

(cid:26) 1
4

,

1
3

,

1
6

,

1
4

(cid:27)

.

Para determinar o número de bolas que necessitaremos, o primeiro passo é reescre-

ver as probabilidades de P com um denominador comum. Obtemos

P =

(cid:26) 3
12

,

4
12

,

2
12

,

3
12

(cid:27)

.

36

x1x2x2x2x3x3x4x5x5x512345678910x1x2x2x2x3x3x4x5x5x512345678910x1x2x3x4x5x2x3x5x2x5x5x5x5x1x3x3x4x2x2x23.1 S I M U L A N D O U M A D I S T R I B U I Ç Ã O

Tomamos então 12 bolas e relacionamos com os elementos de Ω na proporção indi-

cada por P, como na ﬁgura 11.

Figura 11: Duas outras formas de relacionar elementos e bolas.

Feito isso basta sortear uma das 12 bolas, e veriﬁcar qual o elemento de Ω está

associado a ela. Assim, se sortearmos a bola 6, por exemplo, estaremos sorteando de

fato o elemento x2.

3.1.1 Acoplando duas distribuições

Considere agora duas distribuições distintas no conjunto {x1, x2, x3, x4, x5} dadas

por

e

P1 =

(cid:26) 1
10

;

1
5

;

3
10

;

3
10

;

1
10

(cid:27)

P2 =

(cid:26) 1
5

;

1
5

;

1
5

;

1
5

;

1
5

(cid:27)

.

Seguindo a mesma ideia apresentada anteriormente queremos agora fazer um único

experimento aleatório que simule as duas distribuições simultaneamente.

Nós poderíamos usar dois conjuntos de bolas diferentes, e proceder da mesma forma

que ﬁzemos no caso de apenas uma distribuição, sorteando duas bolas (uma de cada

conjunto). Mas queremos um pouco mais do que isso, queremos sortear apenas uma

bola, e com isso simular as duas distribuições. A resposta na verdade não é muito

difícil: basta fazer duas atribuições diferentes ao mesmo conjunto de bolas.

Primeiro observe que o total de bolas necessárias para simular cada uma das distri-

buições é distinta: para P1 precisamos de 10 bolas, enquanto para P2 são necessárias
5 bolas. Assim, para corrigir o problema precisamos primeiro escrever todas as proba-

bilidades (em P1 e P2) usando um mesmo denominador. Temos

e

P1 =

(cid:26) 1
10

;

2
10

;

3
10

;

3
10

;

1
10

(cid:27)

P2 =

(cid:26) 2
10

;

2
10

;

2
10

;

2
10

;

2
10

(cid:27)

.

37

123456789101112x1x1x1x2x2x2x2x3x3x4x4x4A C O P L A N D O C A D E I A S

Agora, assim como ﬁzemos no caso de uma única distribuição, para cada distribuição
temos que associar uma bola a um estado de Ω. A maneira mais simples de fazer isso

é a sequencial, que mostramos na ﬁgura 12. Seguindo este arranjo de bolas e estados,

ao sortearmos a bola de número 2, estaremos sorteando x2 na distribuição P1 e x1 na
distribuição P2.

Figura 12: Simulando P1 e P2 simultaneamente. Em destaque estão os sorteios onde os valores
de P1 e P2 coincidem.

É interessante observar que ao sortearmos as bolas 1, 6, 8 ou 10, estaremos sorte-
ando o mesmo elemento de Ω nas duas distribuições. Isso signiﬁca que, nesta cons-

trução, a probabilidade dos estados coincidirem nas duas distribuições é de 4/10. O

evento

C = {O estado sorteado nas duas distribuições é o mesmo}

é conhecido como evento acoplante, e sua probabilidade P(C) é chamada de probabili-
dade de acoplamento.

Não é difícil ver que a probabilidade de acoplamento depende da construção (asso-

ciação de bolas e estados) escolhida. Analisando a construção dada na ﬁgura 12, por

exemplo, notamos que se em P2 tivéssemos associado as bolas 2 e 3 a x2 e as bolas 4 e
5 a x1, faríamos aumentar as coincidências com a distribuição P1, aumentando assim
a probabilidade de acoplamento.

Surge então a próxima questão: como fazer para maximizar a probabilidade de

acoplamento?

Para isso temos que aumentar o total de coincidências entre associações das bolas

nas duas distribuições. Analisemos as distribuições estado por estado.

• O estado x1 deverá ser associado a apenas uma bola em P1 e 3 bolas em P2, assim
só devemos separar uma bola que será associada a x1 em ambas as distribuições.

• x2 deve se associar a 2 estados em cada uma das distribuições, e portando sepa-

ramos 2 bolas para isso;

38

12345678910x1x2x2x3x3x3x4x4x4x5P1x1x1x1x2x2x3x3x4x5x5P23.1 S I M U L A N D O U M A D I S T R I B U I Ç Ã O

• x3 deve ser associado a 3 estados em P1 e 2 em P2. Separamos então 2 bolas para

isso;

• x4 precisará de apenas 1 bola de coincidência;

• x5 também precisará de apenas 1.

Assim podemos associar as 7 primeiras bolas aos estados de Ω de acordo com as

quantidades previstas acima. As demais, podemos distribuir da maneira que quisermos,

bastando que completemos as proporções necessárias para cada distribuição.

O procedimento acima pode ser descrito da seguinte forma:

• Deﬁna mi = min{P1(xi); P2(xi)};

• Deﬁna ni como o numerador de mi;

• Associe as n1 primeiras bolas à x1, as n2 bolas seguintes a x2 e assim até x5;

• Complete as proporções corretas de cada distribuição do jeito que preferir.

Veja a ﬁgura 13

Figura 13: Acoplando P1 e P2.

Assim, ao sortearmos uma das bolas numeradas, o valor correspondente nas duas

distribuições será o mesmo se, e somente se, a bola sorteada tiver valor menor ou igual

a 7. Segue então que a probabilidade de acoplamento é igual a 7/10.

De modo geral, para acoplar duas distribuições em {x1, . . . , xk} com entradas racio-

nais dadas por

e

P1 = {P1(x1), . . . , P1(xk)}

P2 = {P2(x1), . . . , P2(xk)},

basta seguir os seguintes passos:

• Escreva todas as entradas de P1 e P2 usando um único denominador comum. Este
denominador será exatamente o total de bolas que usaremos para o sorteio;

39

12345678910x1x2x2x3x3x4x5x3x4x4P1x1x2x2x3x3x4x5x1x1x5P2A C O P L A N D O C A D E I A S

• Deﬁna mi = min{P1(xi); P2(xi)}, para cada i = 1, . . . , k;

• Deﬁna ni como o numerador de mi;

• Associe as n1 primeiras bolas à x1, as n2 bolas seguintes a x2 e assim até xk;

• Complete as proporções corretas de cada distribuição do jeito que preferir.

Neste caso, o acoplamento acontecerá se a bola sorteada tiver numeração menor ou
igual a n1 + n2 + · · · + nk. E assim a probabilidade de acoplamento é igual a m1 + · · · +
mk.

3.1.2 Acoplando três ou mais distribuições

Agora que vimos como simular duas distribuições simultaneamente, preparar um

experimento que simule conjuntamente três ou mais distribuições em um mesmo con-
junto Ω não é exatamente um desaﬁo. Seguindo os passos vistos anteriormente, co-

meçamos determinando o total de bolas necessárias, e em seguida basta associar cada

bola aos estados correspondentes em cada distribuição.

Para maximizar a probabilidade de acoplamento, também podemos seguir os mes-

mos passos descritos na seção anterior. Para isso considere então l distribuições em
Ω = {x1, . . . , xk}, todas com entradas racionais, dadas por

Pi = {Pi(x1), . . . , Pi(xk)},

com i = 1, . . . , l.

Para preparar o experimento faça o seguinte:

• Escreva todas as entradas de P1, P2, . . . , Pl usando um único denominador co-
mum. Este denominador será exatamente o total de bolas que usaremos para o

sorteio;

• Deﬁna mi = min{P1(xi); P2(xi)}, para cada i = 1, . . . , k;

• Deﬁna ni como o numerador de mi;

• Associe as n1 primeiras bolas à x1, as n2 bolas seguintes a x2 e assim até xk;

• Complete as proporções corretas de cada distribuição do jeito que preferir.

No caso de três os mais distribuições diremos que aconteceu o acoplamento se o

elemento sorteado em todas as distribuições for igual. Não basta, portanto, que haja

40

3.1 S I M U L A N D O U M A D I S T R I B U I Ç Ã O

coincidência em uma parte das distribuições simuladas. Ou seja, neste caso o evento

acoplante pode ser deﬁnido como

C = {O estado sorteado nas l distribuições é o mesmo}.

Para exempliﬁcar melhor considere as seguintes distribuições em Ω = {x1, x2, x3, x4, x5}.

P1 =

P2 =

P3 =

P4 =

;

;

;

(cid:26) 1
12
(cid:26) 1
4
(cid:26) 1
12
(cid:26) 1
12

;

(cid:27)

1
4

;

1
4

;

1
3

;

1
12

(cid:27)

,

(cid:27)

1
3

;

1
6

; 0;

1
4

1
4

;

1
4

;

1
3

;

1
12

,

,

5
12

;

1
6

;

1
12

;

1
4

(cid:27)

.

;

;

;

;

(cid:27)

P1 =

4
12

3
12

1
12

3
12

Escrevendo todas as entradas com um mesmo denominador temos
(cid:26) 1
12
(cid:26) 3
12
(cid:26) 1
12
(cid:26) 1
12

5
12

2
12

4
12

3
12

1
12

1
12

3
12

2
12

3
12

4
12

3
12

P4 =

P3 =

P2 =

; 0;

(cid:27)

(cid:27)

(cid:27)

;

;

.

;

;

;

,

;

;

,

;

,

;

;

Isso nos diz que precisaremos de 12 bolas para realizar o experimento.

Para determinar as associações entre bolas e elementos de Ω, primeiro calculamos

;

m1 = min

os valores de m1, m2, m3, m4, m5. Assim
(cid:26) 1
12
(cid:26) 3
12
(cid:26) 3
12
(cid:26) 4
12

m4 = min

m2 = min

m3 = min

;

;

3
12

4
12

2
12

;

;

;

; 0;

m5 = min

(cid:26) 1
12

;

3
12

;

1
12

1
12

;

1
12

3
12

3
12

4
12

;

;

;

;

5
12

2
12

1
12

3
12

(cid:27)

(cid:27)

(cid:27)

(cid:27)

(cid:27)

=

=

=

1
12

3
12

2
12

,

,

,

= 0,

=

1
12

.

41

A C O P L A N D O C A D E I A S

Figura 14: Simulando 4 distribuições.

De onde segue que n1 = 1, n2 = 3, n3 = 2, n4 = 0 e n5 = 1, como ilustrado na ﬁgura

14.

Fica claro então que, para esta construção, a probabilidade de acoplamento é de

7/12.

3.2 A C O P L A N D O C A D E I A S D E M A R K O V

Nesta seção vamos ver como fazer para simular as trajetórias de uma cadeia de

Markov, a partir de um estado inicial dado. Feito isso vamos estudar uma técnica

para simular simultaneamente várias trajetórias de uma mesma cadeia, cada uma de-

las iniciando em um estado diferente, de modo que sempre que duas trajetórias se

encontrem, sigam iguais para sempre.

Para deixar as contas mais claras, vamos começar trabalhando com um exemplo

especíﬁco, para depois generalizar para outras cadeias. Considere então a cadeia de
Markov com espaço de estados Ω = {x1, x2, x3, x4} e matriz de transição dada por

T =










1
6
5
12
1
6
1
4

1
4
1
12
1
4
5
12

1
12
1
12
1
4
7
12










1
3
1
4
1
3
1
12

.

Lembrando, cada coluna representa uma distribuição de probabilidade, associada

a um estado da cadeia. Assim, sempre que a cadeia estiver no estado xk usaremos a
distribuição Pk descrita na linha k para escolher o próximo estado que iremos.

Para simular a cadeia acima precisamos primeiro simular cada uma das distribuições

acima. Assim, escrevendo todas as entradas com mesmo denominador, temos
(cid:26) 2
12

3
12

5
12

2
12

P1 =

(cid:27)

;

;

;

,

42

123456789101112x1x2x2x2x3x3x5x3x4x4x4x4P1x1x2x2x2x3x3x5x1x1x2x5x5P2x1x2x2x2x3x3x5x3x4x4x4x4P3x1x2x2x2x3x3x5x2x2x4x5x5P43.2 A C O P L A N D O C A D E I A S D E M A R K O V

P2 =

P3 =

P4 =

(cid:26) 3
12
(cid:26) 1
12
(cid:26) 4
12

;

;

;

1
12

1
12

3
12

;

;

;

3
12

3
12

4
12

;

;

;

5
12

7
12

1
12

(cid:27)

(cid:27)

(cid:27)

,

,

.

Na ﬁgura 15 ilustramos um acoplamento simples destas distribuições, onde associa-

mos cada bola aos estados de forma sequencial.

Figura 15: Acoplamento simples das distribuições relacionadas aos estados de uma cadeia.

Para simular a cadeia de Markov seguimos os seguintes passos:

• Escolhemos um estado inicial u;

• Simulamos a distribuição associada a u, e o seguimos para o estado indicado

pela simulação;

• Repetimos o passo anterior usando o novo estado no lugar de u.

Para ﬁcar mais claro, considere que escolhemos iniciar nossa cadeia no estado x2.
Assim, para dar o primeiro passo vamos simular a distribuição P2, e para isso considere
o acoplamento mostrado na ﬁgura 15. Suponha que sorteamos a bola de número 10.

Isso nos leva ao estado x3, e para o próximo passo temos que usar a distribuição P3.
Se sortearmos agora o número 9, saltamos para x4, e usaremos P4 para escolher o
próximo passo.

Na tabela abaixo ilustramos algumas simulações possíveis, considerando diferentes

estados iniciais para a cadeia. Denotaremos por Xi
tendo iniciado no estado xi, ou seja, Xi
das bolas sorteadas em cada passo da cadeia.

n o estado na cadeia no passo n
0 = xi. Chamaremos de U1, U2, U3, . . . os valores

43

123456789101112x1x1x2x2x2x2x2x3x3x4x4x4P1x1x1x1x2x3x3x3x4x4x4x4x4P2x1x2x3x3x3x4x4x4x4x4x4x4P3x1x1x1x1x2x2x2x3x3x3x3x4P4A C O P L A N D O C A D E I A S

n

Un
X1
n
X2
n
X3
n
X4
n

0

-

x1
x2

x3
x4

1

7

x2

x3
x4
x2

2

4

x2

x3
x1
x2

3

6

x3
x4
x2

x3

4

9

x4
x3
x4
x4

5

11

x3
x4
x3

x3

6

2

x2
x1
x2

x2

7

6

x3

x2

x3

x3

8

4

x3

x2

x3

x3

9

2

x2
x1
x2

x2

10 11 12 13 14

4

x2

x2

x2

x2

3

x1
x1
x1
x1

8

x3

x3

x3

x3

5

x3

x3

x3

x3

12

x4
x4
x4
x4

Na ﬁgura 16 colocamos um gráﬁco das trajetórias governadas pelos mesmos sorteios,

mas com estados iniciais distintos.

Figura 16: Simulação das trajetórias de uma Cadeia de Markov usando acoplamento simples

das transições.

Observe que as trajetórias se acoplam todas no passo 10, e a partir daí seguem juntas.

O instante do acoplamento é algo difícil de se determinar, mas podemos fazer algumas

estimativas se considerarmos a maneira como acoplamos as distribuições de transição.

Para isso, observe na ﬁgura 15 que os números 1 e 12 estão cada um deles relacionados

à um único estado em todas as distribuições. Ou seja, se sortearmos 1 ou 12 em algum

passo da simulação todas as trajetórias saltarão para o mesmo estado, independente

de onde estejam no passo anterior. Isso não quer dizer que ao sortearmos um outro

valor, não possa ocorrer o acoplamento. O exemplo acima mostra que isso é possível.

A diferença é que neste caso precisaremos saber exatamente onde estão as trajetórias

para poder garantir o acoplamento, e sorteando 1 ou 12 esta informação se torna

desnecessária.

Podemos então estimar probabilidades relacionadas ao tempo que uma cadeia de-

mora para se acoplar. Seja τ o tempo que todas as trajetórias simuladas como no

exemplo acima demorem para acoplar. Formalmente falando temos

τ = min{n > 0 : X1

n = X2

n = X3

n = X4

n}.

44

01234567891011121314x1x2x3x4X1nX2nX3nX4n3.2 A C O P L A N D O C A D E I A S D E M A R K O V

Note que se τ > n então U1 /∈ {1, 12}, U2 /∈ {1, 12}, . . . , Un /∈ {1, 12}, e portanto

P(τ > n) ≤

(cid:18)

1 −

(cid:19)n

2
12

(cid:18) 5
6

=

(cid:19)n

.

Fica claro assim que para “diminuir” o tempo que demora para as trajetórias acopla-

rem precisamos aumentar a probabilidade de acoplamento das distribuições de transi-

ção. Encontrar o acoplamento que maximiza esta probabilidade não é tarefa fácil, mas

podemos dar um primeiro passo.

Para isso vamos considerar o acoplamento de P1, P2, P3, P4 como descrito na seção
anterior. Primeiro devemos calcular os mínimos das probabilidades de cada estado.

Assim

m1 = min

m2 = min

m3 = min

m4 = min

(cid:26) 2
12
(cid:26) 5
12
(cid:26) 2
12
(cid:26) 3
12

;

;

;

;

(cid:27)

(cid:27)

(cid:27)

(cid:27)

3
12

1
12

3
12

5
12

;

;

;

;

1
12

1
12

3
12

7
12

;

;

;

;

4
12

3
12

4
12

1
12

=

=

=

=

1
12

1
12

2
12

1
12

,

,

,

.

Procedendo como na seção anterior teremos o acoplamento ilustrado na ﬁgura 17.

Figura 17: Acoplamento das distribuições de transição de uma Cadeira de Markov.

Fazendo agora a simulação das trajetórias usando os mesmos valores sorteados na

tabela anterior encontramos os valores da tabela a seguir, que são melhor visualizados

na ﬁgura 18.

45

123456789101112x1x2x3x3x4x1x2x2x2x2x4x4P1x1x2x3x3x4x1x1x3x4x4x4x4P2x1x2x3x3x4x3x4x4x4x4x4x4P3x1x2x3x3x4x1x1x1x2x2x3x3P4A C O P L A N D O C A D E I A S

n

Un
X1
n
X2
n
X3
n
X4
n

0

-

x1
x2

x3
x4

1

7

x2
x1
x4
x1

2

4

x3

x3

x3

x3

3

6

x3

x3

x3

x3

4

9

x4
x4
x4
x4

5

11

x3

x3

x3

x3

6

2

x2

x2

x2

x2

7

6

x1
x1
x1
x1

8

4

x3

x3

x3

x3

9

2

x2

x2

x2

x2

10 11 12 13 14

4

x3

x3

x3

x3

3

x3

x3

x3

x3

8

x4
x4
x4
x4

5

x4
x4
x4
x4

12

x3

x3

x3

x3

Figura 18: Simulação das trajetórias de uma Cadeia de Markov usando acoplamento “maximal”

das transições.

Neste caso as trajetórias se acoplaram já no passo 2 da simulação, que foi exata-

mente o primeiro passo no qual sorteamos um valor abaixo de 5 (ver ﬁgura 17). Tere-

mos assim que para este acoplamento vale que

P(τ > n) ≤

(cid:18)

1 −

(cid:19)n

5
12

(cid:18) 7
12

=

(cid:19)n

,

melhorando a estimativa conseguida com o acoplamento simples.

O procedimento exempliﬁcado acima pode ser usado para qualquer cadeia de Mar-

kov com transições regulares, nos levando ao seguinte teorema.

Teorema 3.1. Seja T = [Ti,j]m×m uma matriz de transição regular para uma cadeia de
Markov com m estados. Denote por Pk, k = 1, . . . , m, a distribuição de probabilidade
representada na k-ésima coluna de T. Nestas condições, se

β =

m
∑
k=1

min{P1(xk); . . . ; Pl(xk)} > 0

τ = min{n ≥ 0; X1

n = · · · = Xm

n },

e

46

01234567891011121314x1x2x3x4X1nX2nX3nX4n3.3 C O N V E R G Ê N C I A PA R A A M E D I D A I N VA R I A N T E

então existe um acoplamento {X1

n; . . . ; Xm

n }, n ≥ 0, com Xi

0 = xi tal que

P(τ > n) ≤ (1 − β)n.

3.3 C O N V E R G Ê N C I A PA R A A M E D I D A I N VA R I A N T E

Seja T a matriz de transição de uma cadeia de Markov. Ou seja, cada entrada pij
representa a probabilidade da cadeia ir do estado j para o estado i em um passo. Já
vimos que se p(n)
ij é o elemento ij da matriz Tn, n-ésima potência da matriz T, então
p(n)
ij

representa a probabilidade da cadeia ir de j para i em n passos.

Já estudamos também o conceito de medida invariante de uma cadeia de Markov. In-

tuitivamente µ é uma medida invariante se, ao escolhermos o estado inicial de acordo

com µ, a probabilidade de estarmos em cada estado em um instante n qualquer é ainda

dada por µ. Algebricamente, buscamos o vetor µ tal que

µ = Tµ.

Segue que µ = Tnµ para todo n ≥ 0.

A seguir vamos mostrar que, sob certas condições, p(n)
n → ∞, independente do estado j que iniciemos a cadeia.

ij converge para µ(i), quando

Vamos antes ﬁxar algumas notações.

Seja Xi

n uma cadeia de Markov para o qual o estado inicial é i. Ou seja,

P(Xi

n = a) = p(n)
ai ,

para quaisquer estados a, i e todo n ≥ 1.

Vale também que, como µ = Tnµ, então

µ(a) =

m
∑
j=1

p(n)
aj µ(j),

para todo estado i e todo n ≥ 1.

Como µ é um vetor de probabilidades, temos

p(n)
ai =

m
∑
j=1

µ(j)p(n)
ai ,

47

A C O P L A N D O C A D E I A S

para quaisquer estados a, i.

Vamos precisar também da conhecida desigualdade triangular. Recordando, ela diz

que para quaisquer valores a1, . . . , am, vale

ou ainda

|a1 + . . . + am| ≤ |a1| + . . . + |am| ,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

m
∑
k=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ak

≤

m
∑
k=1

|ak| .

Tome agora duas cadeias Xi

n e Xj

vamente. Observe que se em um instante qualquer n tivermos que Xi
então teremos que Xi

n. Concluímos assim que

n (cid:54)= Xj

n começando em estados distintos i e j, respecti-
n (cid:54)= a,

n = a e Xj

P(Xi

n = a; Xj

n (cid:54)= a) ≤ P(Xi

n (cid:54)= Xj

n).

Se considerarmos agora que as cadeias X1

n, . . . , Xm
com o acoplamento visto anteriormente, encontramos que

n, X2

n estão acopladas de acordo

P(Xi

n = a; Xj

n (cid:54)= a) ≤ P(Xi

n (cid:54)= Xj

n) ≤ P(τ > n) ≤ (1 − β)n,

para quaisquer estados i, j. Ou seja

P(Xi

n = a; Xj

n (cid:54)= a) ≤ (1 − β)n.

Outro ponto importante é perceber que

P(Xi
P(Xj

n = a) = P(Xi
n = a) = P(Xj

n = a; Xj
n = a, Xi

n (cid:54)= a) + P(Xi
n (cid:54)= a) + P(Xj

n = a; Xj
n = a, Xi

n = a)

n = a).

E portanto, para quaisquer estados i, j, segue pela desigualdade triangular que

P(Xi

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) =
(cid:12)
≤ P(Xi

n = a; Xj
n = a; Xj

n (cid:54)= a) − P(Xj
n (cid:54)= a) + P(Xj

n = a, Xi

n (cid:54)= a)

(cid:12)
(cid:12)
(cid:12)

n = a, Xi

n (cid:54)= a)

≤ 2(1 − β)n.

P(Xi

n = a) − P(Xj

n = a)

(cid:12)
(cid:12)
(cid:12)

48

3.3 C O N V E R G Ê N C I A PA R A A M E D I D A I N VA R I A N T E

p(n)
ai −

m
∑
j=1

µ(j)p(n)
aj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Com isso temos

(cid:12)
(cid:12)p(n)
(cid:12)

ai − µ(a)

(cid:12)
(cid:12)
(cid:12) =

=

=

≤

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

m
∑
j=1

m
∑
j=1

m
∑
j=1

m
∑
j=1

µ(j)

µ(j)

µ(j)p(n)

ai −

m
∑
j=1

µ(j)p(n)
aj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

µ(j)(p(n)

ai − p(n)
aj )

(cid:12)
(cid:12)p(n)
(cid:12)

ai − p(n)

aj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)P(Xi
(cid:12)

n = a) − P(Xj

n = a)

≤ 2

m
∑
j=1

µ(j)(1 − β)n

≤ 2(1 − β)n,

e portanto, se β > 0

para todo i e todo a.

(cid:12)
(cid:12)p(n)
(cid:12)

ai − µ(a)

(cid:12)
(cid:12) −→ 0, quando n → ∞,
(cid:12)

Mostramos assim o seguinte resultado.

(cid:12)
(cid:12)
(cid:12)

(3.1)

Teorema 3.2. Seja T = [Ti,j]m×m uma matriz de transição regular para uma cadeia de
Markov com m estados. Denote por Pk, k = 1, . . . , m, a distribuição de probabilidade
representada na k-ésima coluna de T. Nestas condições, se

β =

m
∑
k=1

min{P1(xk); . . . ; Pm(xk)} > 0,

então existe uma única medida invariante µ para T e, se p(n) é a sequência deﬁnida por

p(n) = T · p(n−1),

p(n) → µ, quando

paraqualquerescolhadevetordeprobabilidades

vale que

n→ ∞,

p^(0).

49

A C O P L A N D O C A D E I A S

Para terminar vamos veriﬁcar que a matriz G deﬁnida em (1.4), que é usada pelo

Google para determinar a importância das páginas da web, satisfaz as condições do

teorema 3.2.

Como já comentamos anteriormente, G é claramente regular.

Para mostrar que β > 0 bastaria notar que β é sempre maior que a menor entrada

da matriz, que no caso de G são todas positivas. Mas vamos conseguir uma estimativa

um pouco melhor. Note primeiro que, da equação (1.4), temos

Gij = αSij +

1 − α
N

,

onde Gij e Sij são as entradas (i, j) das matrizes G e S respectivamente, N é o total de
páginas na internet e α é a probabilidade de um internauta continuar navegando de

acordo com a matriz S. Logo

Gij ≥

1 − α
N

.

Segue que

para todo k, e portanto

min{Gk1; . . . ; GkN} >

1 − α
N

,

β =

N
∑
k=1

min{Gk1; . . . ; GkN} >

N
∑
k=1

1 − α
N

= 1 − α.

Fica como desaﬁo para o leitor perceber que, de fato,

e portanto

min{Gk1; . . . ; GkN} =

1 − α
N

,

β = 1 − α.

Assim, segue dos cálculos em (3.1) que para todo site si,

|rn

i − ri| < αn.

E se α = 0, 85 como comentado em [1], então

|rn

i − ri| < 0, 85n,

e com menos de 60 iterações a precisão estará além da quarta casa decimal.

50

B I B L I O G R A F I A

[1] David Austin, How Google Finds Your Needle in the Web’s Haystack, http://www.

ams.org/samplings/feature-column/fcarc-pagerank.

[2] Michael W. Berry and Murray Browne, Understanding search engines : mathe-

matical modeling and text retrieval, Software, environments, tools, Society for

industrial and applied mathematics, Philadelphia (Pa.), 1999.

[3] J.L. Boldrini, Algebra linear, HARBRA, 1986.

[4] Sergey Brin and Lawrence Page, The anatomy of a large-scale hypertextual Web

search engine, Computer Networks and ISDN Systems 30 (1998), no. 1–7, 107–

117.

[5] Kurt Bryan and Tanya Leise, The $25,000,000,000 eigenvector: the linear algebra

behind google, SIAM Review 48 (2006), 569–581.

[6] J.A. Ferrari, P.A. e Galves, Acoplamento e processos estocásticos, IMPA, 1997.

[7] Taher Haveliwala and Sepandar Kamvar, The second eigenvalue of the google ma-

trix, Technical Report 2003-20, Stanford InfoLab, 2003.

[8] Amy N. Langville and Carl D. Meyer, Google’s pagerank and beyond: the science of

search engine rankings, Princeton University Press, Princeton, NJ, 2006.

[9] Sheldon M. Ross, Introduction to probability models, Probability and Statistics,

Academic Press, 2007.

[10]

, Probabilidade: um curso moderno com aplicações, 8 ed., Bookman, Porto

Alegre, 2010.

[11] V.L. Ruggiero, M.A.G. e da Rocha Lopes, Cálculo numérico: aspectos teóricos e

computacionais, Makron Books do Brasil, 1996.

51


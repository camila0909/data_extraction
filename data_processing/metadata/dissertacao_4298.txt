Universidade de Brasília
Instituto de Ciências Exatas
Departamento de Matemática
Programa de Mestrado Profissional
em Matemática em Rede Nacional

Análise da prova da primeira fase da OBMEP
como subsídio para orientar a prática docente

Regiane Quezia Gomes da Costa

Brasília

2015

Regiane Quezia Gomes da Costa

Análise da prova da primeira fase da OBMEP como

subsídio para orientar a prática docente

Dissertação apresentada ao Departamento
de Matemática da Universidade de Brasí-
lia, como parte dos requisitos do “Programa”
de Mestrado Profissional em Matemática em
Rede Nacional - PROFMAT, para obtenção
do grau de Mestre.

Universidade de Brasília - UnB

Departamento de Matemática - MAT

PROFMAT - SBM

Orientador: Prof. Dr. Mauro Luiz Rabelo

Brasília

2015

—

Este trabalho é dedicado a Jesus Cristo, a meu amado filho Luís Antônio – presente de
Deus e ao meu amado esposo Edson Alves, pelo inestimável carinho e apoio.

Agradecimentos

Agradeço a Deus por me cobrir de bençãos e me ensinar a não perder as esperanças.
Agradeço a minha mãe Geralda do Rosário, que me ensinou o valor do trabalho e da
honestidade, e ao meu pai de coração, João Gualberto, por exigir e não me deixar desistir.

Agradeço a meus irmãos Agnaldo, Elias e Jorge por me ensinarem o valor de uma

boa companhia. E desejo que Deus diminua nossas distâncias.

Agradeço a todos que contribuíram de forma atuante neste momento privilegiado
de aprendizagem: João Gualberto, Euzébio, Cácio Fabrício, Ana Paula, Ronald, coorde-
nadores da OBMEP, Maria Terezinha, gestores, professores, coordenadores da OBMEP
nas escolas e alunos das escolas pesquisadas.

Agradeço a todos os professores do Departamento de Matemática da UnB que
contribuíram para minha formação de docente. Agradeço aos professores: Dr. Kellcio
Oliveira Araújo e Dra. Erondina Barbosa da Silva, que gentilmente aceitaram o convite
para participar da banca e, em especial, ao meu orientador, Professor Dr. Mauro Luiz
Rabelo, que marcou e edificou minha vida, pelo conhecimento científico e pelo exemplo
de docência.

Agradecimento especial: à doce Ana Paula Vilarinho, pelo incentivo e parceria
neste estudo; à guerreira Rosana de Andrade, pela amizade fiel; ao caro Kleber Xavier,
pela companhia nos momentos de estudo e a todos os colegas do PROFMAT.

Agradeço, por fim, ao meu amado esposo Edson Alves, que foi o melhor pai, nos
momentos que me ausentei como mãe. E ao meu filho Luís Antônio, por me esperar com
o abraço mais carinhoso do mundo.

Agradecimentos Institucionais

CEBRASPE - Centro Brasileiro de Pesquisa em Avaliação e Seleção e de Promoção

de Eventos

CAPES – Coordenação de Aperfeiçoamento de Pessoal de Nível Superior.

IMPA – Instituto Nacional de Matemática Pura e Aplicada.

UNB – Universidade de Brasília.

EAPE – Escola de Aperfeiçoamento dos Profissionais da Educação do DF.

SE – Secretaria de Estado de Educação do DF.

“Quem conheceu a alegria da compreensão conquistou um amigo infalível para a vida. O
pensar é para o homem, o que é o ar para os pássaros. Não toma como exemplo a
cotovia quando podes ser uma águia.”
Albert Einstein

Resumo

A Olimpíada Brasileira de Matemática das Escolas Públicas (OBMEP) é uma avaliação
de larga escala oferecida anualmente desde 2005 aos estudantes do ensino básico, que
tem como objetivo descobrir novos talentos matemáticos e contribuir para a melhoria do
ensino da matemática nessa etapa da escolaridade. Este projeto governamental inclui ações
e programas que contribuem muito para o aprendizado da Matemática, principalmente
para os alunos premiados. Este estudo vem contribuir para a ampliação dos objetivos
deste certame, com a análise da construção do instrumento de avaliação da primeira
fase do nível dois da OBMEP de 2014. O questionamento que motivou o estudo aqui
apresentado foi: este instrumento de larga escala pode ser usado como subsídio de uma
aprendizagem significativa? E a resposta foi investigada à luz dos pressupostos teóricos
relacionados a avaliação da aprendizagem e análise do erro, a partir de uma amostra, que
compreendia os alunos de cinco escolas públicas de educação básica do Distrito Federal,
com o objetivo de fazer um estudo do comportamento das marcações dos estudantes.
A metodologia utilizada no trabalho englobou análise de dados e conteúdo. Realizou-se
uma análise dos itens da prova, a partir de resultados oriundos da aplicação da Teoria
Clássica dos Testes e também das técnicas recomendadas pela Engenharia de Construção
de Itens. Foi inferida e categorizada a natureza dos erros apresentados pelo grupo de
estudantes pesquisado, diante da escolha dos distratores de cada questão objetiva da
prova, de forma a dar suporte para uma tomada de atitude dos professores frente aos
obstáculos da aprendizagem apresentados na realização das situações-problema propostas.

Palavras-chaves: Avaliação. Distratores. Engenharia de Itens. Análise do Erro. OBMEP.

Abstract

The Brazilian Mathematical Olympiad of Public Schools – BMOPS is a large-scale gov-
ernment evaluation offered annually since 2005 for Students of primary education, which
aims to discover young mathematical talents and contributes to the quality of education.
This government project includes actions and programs in order to improve mathematical
learning, especially for the awarded students. Also, this study contributes to enlarge the
objectives of this evaluation process, with one analysis of the assessment’s construction
as the instrument of the first phase of BMOPS of 2014, in the second level. The main
question that underwrote this study was: Can this large-scale’s instrument be used as
a subsidy for a significant learning? The answer was investigated according to theoret-
ical assumptions related in the assessment for apprenticeship and Analysis Error, with
a sample including students of five schools from Federal District, with the purpose of
making one study behavior on the markings of these students. The methodology used has
encompassed analysis of data and contents. One Analysis of the test items was done as
well according to the Classical Theory of Tests – CTT and the techniques recommended
by the Engineering Items construction. The nature of the errors of the researched stu-
dents was inferred and categorized, based on the choices of the distractors presented in
every question in the written test, in order to give teachers support to one decision in a
problem-situation and overcome the obstacles into the learning process.

Key-words: Assessment for learning. Distractors. Engineering Items. Analysis of Error.
OBMEP.

Lista de ilustrações

Figura 1 – AGI de item bom e de item ruim, respectivamente (RODRIGUES,

2006, p. 52) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

Figura 2 – AGI de item com discriminação ruim e de item difícil, respectivamente

(RODRIGUES, 2006, p. 52) . . . . . . . . . . . . . . . . . . . . . . . . 66
Figura 3 – Exemplo de item convencional . . . . . . . . . . . . . . . . . . . . . . . 67
Figura 4 – Exemplo de item discursivo . . . . . . . . . . . . . . . . . . . . . . . . 70
Figura 5 – Exemplo de item de resposta curta aberta – 2a Fase da OBMEP . . . . 71
Figura 6 – Estrutura Básica do Item (adaptado de (RABELO, 2013)) . . . . . . . 73
Figura 7 – Item com exemplificação no texto-base . . . . . . . . . . . . . . . . . . 74
Figura 8 – Exemplo de item de múltipla escolha de complementação simples.
. . . 75
. . . . . . . . . . . . . . . . . . . 75
Figura 9 – Exemplo de item de pergunta direta.
Figura 10 – Exemplo de item de múltipla escolha de interpretação.
. . . . . . . . . 76
Figura 11 – Item de múltipla escolha de resposta múltipla . . . . . . . . . . . . . . 79
Figura 12 – Solução apresentada pelo aluno E2A18. . . . . . . . . . . . . . . . . . . 123
Figura 13 – Solução apresentada pelo aluno E1A11. . . . . . . . . . . . . . . . . . . 125
Figura 14 – Solução apresentada pelo aluno E1A15. . . . . . . . . . . . . . . . . . . 127
Figura 15 – Solução apresentada pelo aluno E2A11. . . . . . . . . . . . . . . . . . . 127
Figura 16 – Solução da questão proposta pelo aluno E1A12.
. . . . . . . . . . . . . 128
Figura 17 – Visualização da solução da alternativa A . . . . . . . . . . . . . . . . . 136
Figura 18 – Visualização da solução da alternativa D . . . . . . . . . . . . . . . . . 136
Figura 19 – Solução apresentada pelo aluno E1A15. . . . . . . . . . . . . . . . . . . 139
Figura 20 – Solução apresentada pelo aluno E2A10. . . . . . . . . . . . . . . . . . . 147
Figura 21 – Solução apresentada pelo aluno E1A10. . . . . . . . . . . . . . . . . . . 153

Lista de tabelas

Tabela 1 – Objetivo geral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
Tabela 2 – Objetivos específicos . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
Tabela 3 – Distribuição dos itens da OBM (OBM, 2014a).
. . . . . . . . . . . . . 35
Tabela 4 – Inscrições na OBMEP na primeira e segunda fase e premiados por ano. 37
Tabela 5 – Classificação dos itens de acordo com o poder de discriminação na TCT

(RABELO, 2013, p. 136), com adaptações. . . . . . . . . . . . . . . . . 63
Tabela 6 – Questionamentos de verificação de itens (RABELO, 2013, p. 217) . . . 81
Tabela 7 – Taxonomia de Borasi para os Usos de Erros . . . . . . . . . . . . . . . 99
Tabela 8 – Análise de escore bruto dos candidatos . . . . . . . . . . . . . . . . . . 114
Tabela 9 – Análise Geral da Prova da OBMEP-2014 a partir da TCT na amostra 114
Tabela 10 – Distribuição dos itens em relação ao parâmetro dificuldade, segundo a

TCT.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
. . . . . 115
Tabela 11 – Distribuição dos itens em relação a discriminação, pela TCT.
Tabela 12 – Coeficientes bisseriais das alternativas de cada item.
. . . . . . . . . . 116
Tabela 13 – Porcentagem de marcação nas alternativas de cada item . . . . . . . . 116
Tabela 14 – Erro diante à construção de conhecimento em uma situação didática

de Matemática, segundo Bodin (1997)

. . . . . . . . . . . . . . . . . . 164

Tabela 15 – Erros de acordo com um modelo embasado nos mecanismos do proces-

samento de informação, segundo Radatz (1979) . . . . . . . . . . . . . 165

Tabela 16 – As causas dos erros, segundo Casey (CLEMENTS, 1980 apud CURY,

2007)

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166

Sumário

Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

FUNDAMENTAÇÃO TEÓRICA

29

OBMEP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

Histórico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

Olimpíada Internacional de Matemática . . . . . . . . . . . . . . . . . 32

Olimpíada Brasileira de Matemática . . . . . . . . . . . . . . . . . . . 34

Olimpíada Brasileira de Matemática das Escola Públicas . . . . . . . 36

Contribuições da OBMEP . . . . . . . . . . . . . . . . . . . . . . . . . 40

AVALIAÇÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

Avaliação a Serviço da Aprendizagem Matemática . . . . . . . . . . 45

Rompendo os Conceitos Avaliativos . . . . . . . . . . . . . . . . . . . 46

Avaliação e Educação Matemática . . . . . . . . . . . . . . . . . . . . 51

Intencionalidade – o objetivo ao avaliar

. . . . . . . . . . . . . . . . . . . 53

O conteúdo – o objeto de avaliação . . . . . . . . . . . . . . . . . . . . . 53

Forma – os procedimentos/instrumentos de avaliação . . . . . . . . . . . . 54

Um Instrumento para a Aprendizagem . . . . . . . . . . . . . . . . . 55

INSTRUMENTO AVALIATIVO E A PSICOMETRIA . . . . . . . . 59

Teoria de Resposta ao Item . . . . . . . . . . . . . . . . . . . . . . . . 59

Teoria Clássica dos Testes . . . . . . . . . . . . . . . . . . . . . . . . . 60

Análise Gráfica dos Itens

. . . . . . . . . . . . . . . . . . . . . . . . . 64

Ambiente construtivista . . . . . . . . . . . . . . . . . . . . . . . . . . 66

ENGENHARIA DE ITENS . . . . . . . . . . . . . . . . . . . . . . . 69

Conceitos básicos de elaboração de itens . . . . . . . . . . . . . . . . 69

Formatos comuns de itens

. . . . . . . . . . . . . . . . . . . . . . . . 69

Habilidade e Competência . . . . . . . . . . . . . . . . . . . . . . . . 72

Estrutura básica de um item de múltipla escolha . . . . . . . . . . . 73

O Texto-Base . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

O Comando . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75

As alternativas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77

O Correto Uso da Língua Portuguesa na Avaliação para a Aprendi-
zagem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

I

1

1.1

1.2

1.3

1.4

1.5

2

2.1

2.2

2.3

2.3.1

2.3.2

2.3.3

2.4

3

3.1

3.2

3.3

3.4

4

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

5

5.1

5.1.1

5.1.2

5.1.3

ANÁLISE DE CONTEÚDO . . . . . . . . . . . . . . . . . . . . . . . 83

A Análise de Conteúdo . . . . . . . . . . . . . . . . . . . . . . . . . . 83

Pré-análise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84

A Exploração do Material . . . . . . . . . . . . . . . . . . . . . . . . . . . 84

Tratamento dos Resultados Obtidos e Interpretação . . . . . . . . . . . . . 85

5.1.3.1

Categorização . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

85

6

6.1

6.2

6.3

6.4

6.5

II

7

7.1

7.2

8

8.1

8.2

8.2.1

8.2.2

8.2.3

8.2.4

8.3

8.3.1

8.3.2

8.3.3

8.3.4

8.3.5

8.3.6

8.3.7

8.3.8

8.3.9

8.3.10

8.3.11

8.3.12

ANÁLISE DO ERRO . . . . . . . . . . . . . . . . . . . . . . . . . . 87

Errar: Uma Ação para a Aprendizagem Significativa . . . . . . . . . 87

Erro: Bases Históricas . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

O Erro e o Ambiente Construtivista . . . . . . . . . . . . . . . . . . . 92

Enfoque Pedagógico do Erro . . . . . . . . . . . . . . . . . . . . . . . 96

Erro e a Avaliação de Larga Escala . . . . . . . . . . . . . . . . . . . 100

ANÁLISE E DISCUSSÃO

103

METODOLOGIA . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

Coleta de dados – estudo quantitativo . . . . . . . . . . . . . . . . . 105

Coleta de dados – estudo qualitativo . . . . . . . . . . . . . . . . . . 107

ANÁLISE DE RESULTADOS . . . . . . . . . . . . . . . . . . . . . . 111

Análise Geral do Instrumento . . . . . . . . . . . . . . . . . . . . . . . 111

Análise Geral da OBMEP-2014, nível 2, primeira fase . . . . . . . . 111

Matriz de Referência . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

Análise global dos itens . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

As alternativas

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

Análise quantitativa – TCT . . . . . . . . . . . . . . . . . . . . . . . . . . 113

Análise Individualizada dos Itens da OBMEP . . . . . . . . . . . . . 118

Item 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

Item 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120

Item 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

Item 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124

Item 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

Item 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

Item 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

Item 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133

Item 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135

Item 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138

Item 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140

Item 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142

8.3.13
8.3.14
8.3.15
8.3.16
8.3.17
8.3.18
8.3.19
8.3.20

Item 13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Item 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
Item 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
Item 16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
Item 17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
Item 18 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
Item 19 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
Item 20 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158

Considerações Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

Referências . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169

APÊNDICES

173

APÊNDICE A – TERMO DE CONSENTIMENTO . . . . . . . . . 175

APÊNDICE B – REQUERIMENTO CEBRASPE . . . . . . . . . . . 177

APÊNDICE C – ATIVIDADE EXTRA . . . . . . . . . . . . . . . . 179

APÊNDICE D – QUESTIONÁRIO DE ENTREVISTA . . . . . . . . 183

ANEXOS

187

ANEXO A – RAIG . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

ANEXO B – PROVA OBMEP 2014 . . . . . . . . . . . . . . . . . . 193

ANEXO C – SOLUÇÃO DA PROVA DA OBMEP 2014 . . . . . . 199

ANEXO D – RESPOSTAS AO QUESTIONÁRIO (APÊNDICE D) . 207

Índice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211

Introdução

23

Sabemos que pensar matematicamente exige, desde cedo, um esforço de abstração
e formalização que demanda, por sua vez, desvincular o pensamento de propósitos e
intenções imediatas. Ensinar Matemática é fazer ao aluno um convite à abstração1. Esse
convite, no entanto, parece que só pode ser aceito ou compreendido se o professor adotar
uma metodologia que possibilite mediações progressivas entre os significados matemáticos
e aqueles que o aluno domina.

Em uma pedagogia centrada na figura do professor, cabe ao docente a tarefa de
ensinar ou orquestrar em uma sala de aula todos os elementos envolvidos na aprendizagem.
Um dos elementos que envolve enorme discussão é a verificação da aprendizagem por meio
de um instrumento que revele, com maior fidedignidade possível, o que o aluno realmente
aprendeu, ou seja, uma avaliação que carrega em si um retrato do quadro de aprendizagem
que demonstre os conceitos aprendidos ou não.

É nesse sentido que a avaliação da aprendizagem escolar está sendo en-
tendida, como processo, como prática que busca respostas sobre como se
dão os processos com ela envolvidos. Nesta perspectiva, o que se busca
com a avaliação da aprendizagem escolar é interrogar o que é diretamente
observável, percorrer caminhos, compreender processos, seguir vestígios
e, com isso, inferir sobre o que não é diretamente observável, ou seja
- investigar. Por este motivo, adota-se a perspectiva de avaliação da
aprendizagem escolar como prática de investigação (BURIASCO; FER-
REIRA; CIANI, 2009, pg. 73).

E, mais ainda, como esse instrumento pode ser utilizado como propósito de ressig-
nificar a aprendizagem tanto para o professor quanto para o aluno? Se tomarmos numa
visão macro, como os instrumentos estão sendo utilizados pelos os órgãos governamentais
de forma a revelar a atual situação da aprendizagem em Matemática?

Esses questionamentos instigam a investigação tanto das avaliações em larga escala
quanto da avaliação em sala de aula, para entender como elas podem revelar e construir
para o aluno um significado para as atividades que ele realiza. Que no caso deste estudo
visa a construção de instrumento na esfera macro de ensino que pode ser aplicada de
forma a contribuir para um ambiente construtivista de aprendizagem de Matemática na
sala de aula, de forma que o professor seja agente de significação do instrumento como
um todo para o educando.

A avaliação da qualidade do trabalho ou do desempenho do aluno requer
que o professor possua concepção de qualidade apropriada à tarefa e

1 Abstração, para Piaget, é a internalização da ação. O conceito de abstração é amplo e tem diversas

interpretações dadas por outros autores.

24

Introdução

seja capaz de julgar de acordo com essa concepção. O aluno, por sua
vez, precisa ter concepção de qualidade similar à do professor, ser capaz
de monitorar continuamente a qualidade do que está sendo produzido
durante o próprio ato de produção e ter repertório de encaminhamentos
ou estratégias aos quais possa recorrer. Isso significa que ele tem de ser
capaz de julgar a qualidade da sua produção e de regular o que está
fazendo enquanto o faz (VILLAS-BOAS, 2006, p. 81).

Assim, com um instrumento bem elaborado pelo Estado aplicado ao estudante e
com relatórios de desempenho bem redigidos, na linguagem em que os docentes compre-
endem, o professor torna-se uma investigador dos resultados apresentados e pode tomar
posturas que reordene sua prática pedagógica. Para reorientar sua prática, sugere-se a
análise dos erros cometidos pelos estudantes como forma de investigação dos problemas
relacionados ao ensino e aprendizagem escolar de Matemática.

Os erros produzidos no processo de aprendizagem de Matemática devem ser enca-
rados como indicadores da atuação dos processos subjacentes à construção de um conceito
e das variáveis que influenciam externamente esses processos, sobretudo aquelas ligadas
ao processo de ensino e aprendizagem.

Para entender os erros mais frequentes é necessário investigar a natureza e a produ-
ção de conceitos de um dado campo de investigação, no caso a Matemática, explicitando
as principais dificuldades associadas à construção dos mesmos.

O erro auxilia na aquisição consciente e elaborada de uma conduta ou de uma
habilidade, bem como contribui para avançar um passo à frente na aprendizagem e no
desenvolvimento. Assim, ele serve como ponto de partida para novas investigações que
levarão o indivíduo a buscar soluções que satisfarão não apenas a situação proposta, mas
também como resposta a outras proposições. Desse modo, o erro se constitui importante
instrumento de intervenção didática, pois, a partir dele, o docente tem a possibilidade de
observar e valorizar a diversidade na sala de aula e, consequentemente, escolher a conduta
a ser utilizada no ensino de determinado conteúdo.

Como se espera analisar o erro, por quê não prevê-los com antecedência antes da
aplicação de um teste escrito? E, assim, ao se construir o instrumento, de larga escala ou
de sala de aula, o elaborador se coloca em sintonia com a prática de aprendizagem do
estudante. Desse modo, pode-se aplicar na construção dos itens que comporão a prova
escrita conceitos que justifiquem a aplicação do próprio instrumento, de forma a se ter
uma avaliação formativa. Cabe resgatar o que Villas Boas nos diz sobre a avaliação como
prática de investigação:

Assim, do levantamento dos verbetes acima apresentados e brevemente
discutidos, constituímos o que aqui entenderemos por “avaliação como
prática de investigação”: um processo de buscar conhecer ou, pelo menos,
obter esclarecimentos, informes sobre o desconhecido por meio de um
conjunto de ações previamente projetadas e/ou planejadas, processo no

qual se procura seguir rastros, vestígios, esquadrinhar, ir à pista do que
é observável, conhecido (VILLAS-BOAS, 2006, p. 82).

25

Assim, um estudo que perpassa um instrumento de larga escala e seu significado
para o estudante, merece relevância na perspectiva de todos os agentes que estão pre-
sentes no processo. Desde os idealizadores, os elaboradores e professores até o principal
ator, o aluno. O aluno que pode ressignificar os conceitos aprendidos, superar obstáculos
na aprendizagem, destacar-se no meio acadêmico e/ou, até mesmo, romper paradigmas
sociais.

Acredita-se que uma prova escrita, na perspectiva da avaliação como
prática de investigação, deve conter questões que possibilitem ao estu-
dante trabalhar do seu próprio “jeito” com as informações do enunciado
na busca não somente de resolver a questão, mas também de produzir
conhecimento matemático a partir dela, de proporcionar resoluções a
partir das quais o professor possa investigar as maneiras pelas quais os
sujeitos interpretam o enunciado, elaboram estratégias e utilizam pro-
cedimentos para resolver uma questão, que, em muitos casos, são resul-
tantes de processos sistemáticos, tanto sintáticos como semânticos, os
quais eles próprios constroem (SANTOS, 2007 apud BURIASCO; FER-
REIRA; CIANI, 2009, pg. 80).

Após estudos realizados na disciplina Avaliação Educacional do Mestrado Profis-
sional em Matemática, na qual, a partir de análises de avaliações de larga escala e da
“engenharia de construção itens” (RABELO, 2013, p. 177), constatou-se a importância
de se praticar uma metodologia de avaliação em Matemática diferente da que tradicional-
mente encontramos nas escolas e que seja mobilizadora do desenvolvimento de habilidades
e competências dos estudantes.

Com isso, surgiu a intenção de levar aos docentes de Matemática um pouco dessa
formação, que pode contribuir para a discussão sobre a intencionalidade de se avaliar para
a aprendizagem dos estudantes, em contraponto à tradicional avaliação das aprendizagens.
Estes novos paradigmas levaram a uma reformulação da minha própria prática docente,
corroborada com a visão de Esteban, acerca da postura investigativa do professor face a
avaliação da aprendizagem escolar.

Assumir a avaliação da aprendizagem escolar como prática de investi-
gação implica colocar-se em uma postura de investigação, o que exige,
por parte do professor, o reconhecimento da existência de uma multipli-
cidade de caminhos percorridos pelos estudantes, a admissão de que, tal
como eles, está em constante processo de elaboração de conhecimento.
Sob esta perspectiva, a avaliação é então realizada como uma prática que
possibilita ao professor a busca de desvelar o processo de aprendizagem
dos estudantes, bem como acompanhar e participar dele (ESTEBAN,
2003 apud BURIASCO; FERREIRA; CIANI, 2009, pg. 82).

Como ponto de partida, escolhi fazer uma análise da prova de primeira fase da
Olimpíada Brasileira de Matemática das Escolas Públicas (OBMEP), bem como das res-

26

Introdução

postas que os alunos de oitavo e nono anos do ensino fundamental apresentaram durante
a realização do exame. Será realizado um estudo de caso, que pode pontuar e contribuir
para uma nova visão do professor e dos elaboradores a respeito da relevância que um
instrumento, elaborado a partir de objetivos ligados ao alvo da aprendizagem - o aluno,
pode ter na aprendizagem Matemática em todo o território nacional.

O objetivo é fazer uma análise de conteúdo dos itens da prova no que diz respeito às
técnicas recomendadas pela metodologia de construção de itens e categorizar a natureza
dos erros apresentados pelo grupo de estudantes pesquisado, conforme objetivo geral,
objetivos específicos e procedimentos metodológicos utilizados para a coleta de dados da
pesquisa, apresentados na Tabelas 1 e 2.

Tabela 1 – Objetivo geral

Objetivo Geral

Analisar os itens e as respostas dos estudantes do 8𝑜 e 9𝑜 ano do ensino fundamental às provas da OBMEP como
meio para oferecer subsídios para a prática docente de professores de Matemática.

Tabela 2 – Objetivos específicos

Objetivos Específicos

Procedimentos

Investigar em que medida os itens das provas da OB-
MEP, nível 2, aplicadas no ano 2014 respeitam as reco-
mendações da técnica denominada Engenharia de Cons-
trução de Itens para uma avaliação de larga escala.

Determinar os índices a partir da TCT para análise dos
itens da OBMEP no grupo analisado.

Categorizar os erros cometidos pelo grupo de alunos que
respondeu às provas da OBMEP nas escolas pesquisa-
das.

Evidenciar formas de tratamento de erro para os profes-
sores de Matemática a partir das análises das respostas
dos estudantes do grupo em estudo.

Provocar um questionamento em relação a elaboração
de um instrumento de avaliação que contribua para uma
aprendizagem significativa.

Análise detalhada de cada item e do instrumento como
um todo, a partir da matriz de referência e da proposta
de solução dos itens pela OBMEP à luz da Engenharia
de Construção de Itens.
Verificar a intencionalidade na elaboração dos distrato-
res na prova da primeira fase da OBMEP.
A partir das folhas de respostas dos alunos preenchidas
quando da aplicação da OBMEP nas escolas investiga-
das, determinar a dificuldade, o índice de discriminação
e a análise gráfica do item (AGI) da prova analisada,
além dos percentuais de marcação e dos coeficientes bis-
seriais por alternativa de cada item.
Categorizar as inferências de erros, cometidos pelo
grupo pesquisado, a partir da análise dos distratores
de cada item da prova comparando-se com o referencial
teórico sobre análise do erro.
Após a categorização dos erros inferidos a a partir das
alternativas apresentadas em cada item, reforçar as for-
mas de tratamento ao erro de acordo com o referencial
teórico sobre análise do erro.
Apresentar o feedback dos resultados apresentados no
estudo às escolas pesquisadas.
Incentivar uma tomada de postura do docente frente a
investigação dos erros apresentados pelo estudante di-
ante de um instrumento avaliativo.

Para conseguir atingir os propósitos anteriormentes explicitados, dividiu-se este
trabalho em duas partes. Na primeira, apresentam-se os referenciais teóricos que funda-
mentam esta investigação. São eles:

Olimpíada Brasileira de Matemática das Escolas Públicas (OBMEP): apresen-
ta-se um breve histórico sobre as olimpíadas da Matemática, desde as competições
antigas até as olimpíadas modernas, comentando-se sobre as ideias de seus regula-
mentos e a relevância destes eventos para a produção cientifica e para a sociedade.

27

Avaliação: revela o caráter formativo de avaliações e denota a importância do estudo
de avaliações nos três níveis educacionais, concentrando-se numa perspectiva de
investigação realizada pelo professor.

Instrumento Avaliativo e a Psicometria: apresenta-se a importância dos estudos psi-

cométricos da avaliação com o apoio da TCT e da TRI.

Engenharia de Itens: estabelece critérios para a boa prática construção de itens em

uma avaliação de larga escala a partir dos estudo de Rabelo.

Análise de conteúdo: apresentam-se conceitos de uma pesquisa embasada na análise de
conteúdo como forma de investigação documental de forma a embasar este estudo.

Análise do Erro: uma ação para a aprendizagem significativa: estabelece como deve ser
o tratamento dos erros para uma aprendizagem Matemática significativa, apresen-
tando as concepções de tratamento de erros. E além disso, traz a categorização e o
tratamento de erros por diversos autores.

Na segunda parte, intitulada “Análise e Discussão”, são apresentados os capítulos

que qualificam este estudo:

Metodologia: esclarecimento acerca das escolhas metodológicas e do caminho percorrido

nessa investigação.

Análise de resultados: estudo do instrumento avaliativo da OBMEP agregado ao grupo
de estudo. Esta análise foi divida em duas seções: a Análise Geral do Instrumento
e a Análise Individualizada de Itens da OBMEP.

Considerações Finais: considerações sobre a investigação realizada.

Parte I

Fundamentação Teórica

31

1 OBMEP

1.1 Histórico

A Olimpíada Brasileira de Matemática das Escolas Públicas - OBMEP, além de
uma olimpíada de conhecimentos em Matemática, é uma avaliação de larga escala e uma
política pública, mundialmente reconhecida, segundo Maranhão. De acordo com a mesma
autora, é considerada

uma das maiores iniciativas governamentais voltadas ao processo de en-
sino aprendizagem em Matemática, visando melhorar a motivação, o
interesse e o desempenho dos alunos das escolas públicas brasileiras com
cobertura em quase todo território nacional (MARANHãO, 2011, p. 13).

Em busca de características do projeto da OBMEP é necessário um breve histórico
deste tipo de competições, de forma a entender o formato do projeto que hoje está em
sua 11a edição.

A realização de Olimpíadas de Matemática no mundo datam do século XIX. No
entanto, no século XVI, com características bem diferentes, já havia duelos matemáticos,
que eram famosos desafios nos quais importantes matemáticos empenhavam sua reputa-
ção, dinheiro e, até mesmo, suas cátedras em universidades italianas. Nessa época, segundo
Bellos (2011), grande parte dos matemáticos estavam empenhados em encontrar soluções
para problemas que pudessem ser apresentadas nas futuras competições de habilidade Ma-
temática. Um matemático, cujas habilidades permitissem que detivesse uma cátedra em
uma universidade, tinha reconhecimento público e uma condição econômica privilegiada.
Essa situação social despertava o interesse de outros matemáticos ainda sem prestígio,
que desafiavam publicamente matemáticos respeitados e experientes. Nessas competições,
em geral, um conjunto de trinta problemas era proposto por ambos, vencendo aquele que
resolvesse o maior número de problemas propostos pelo oponente.

Exemplo histórico da ocorrência de tais duelos é a competição entre Niccoló Tar-
taglia e Antonio Fiore. Eles eram chamados de coisistas, e detinham a fama de resolver
equações cúbicas. O concurso público, em questão, terminou com a vitória de Tartaglia,
que resolveu todos os problemas propostos por seu adversário. Tal feito incitou Girolamo
Cardano a investigar o método usado por Tartaglia. Após várias investidas de Cardano,
Tartaglia revelou seu método mas com o compromisso de sigilo daquele (BELLOS, 2011,
p. 216).

Mas Cardano contou o método ao seu secretário Ludovico Ferrari, que o aperfei-
çoou, descobrindo assim, uma maneira de resolver as equações quárticas. Cardano, em

32

Capítulo 1. OBMEP

um dilema moral do sigilo versus a publicação da descoberta por Ferrari, publicou o mé-
todo de Tartaglia, onde este último seria apenas o coinventor do método de resolução de
cúbicas (BELLOS, 2011, p. 218).

O evento, citado, demonstra que haviam competições Matemáticas, com formatos e
intenções diversas aos modelos contemporâneos, mas que trouxeram benefícios conceituais
à Matemática. A procura por matemáticos talentosos é um objetivo presente nas diversas
competições.

Segundo Maciel (2009), com inspiração nos jogos olímpicos, os quais foram influen-
ciados pelos festivais esportivos que os gregos realizavam na antiga Élida, realizou-se em
1894, na Hungria, a primeira Olimpíada de Matemática, em homenagem a Jósef Kürschák.

Estas competições matemáticas eram chamadas “Eotvos”. Devido à maneira com
que foram estruturadas, é possível afirmar que essas competições são as precursoras do que
hoje conhecemos como “Olimpíadas de Matemática”. Em 1934, foi organizada aquela que
pode ser considerada como a primeira Olimpíada de Matemática “moderna” na cidade de
Leningrado (URSS) . Assim, deu-se o primeiro passo para ser disseminada a elaboração
de competições matemáticas pelo resto da Europa e para todo o mundo (MACIEL, 2009).

Essas competições têm por objetivo desenvolver nos jovens o gosto e o prazer de
estudar Matemática – objetivo motivacional de aprendizagem –, e também, estimular
o ensino e a aprendizagem da Matemática em todos os seus níveis – objetivo político
educacional.

O programa de Olimpíadas de Matemática é reconhecido em todos os países do
mundo desenvolvido como eficiente instrumento para atingir o objetivo motivacional.
Aproveitando o natural gosto dos jovens pelas competições, as Olimpíadas de Matemá-
tica têm conseguido estimular alunos a estudar conteúdos além do currículo escolar e,
também, por outro lado, aumentar e desenvolver a competência dos professores. Entre as
Olimpíadas de Matemática hoje realizadas, destacam-se a Olimpíada Internacional de Ma-
temática (International Mathematical Olympiad – IMO) e a Olimpíada Ibero-Americana
de Matemática (OIAM).

1.2 Olimpíada Internacional de Matemática

De acordo com IMO (2014), a primeira edição da Olimpíada Internacional de
Matemática (International Mathematical Olympiad – IMO) foi realizada em 1959, com a
participação de alguns países como Bulgária, Hungria, Polônia e Romênia, além das, hoje
extintas, Alemanha Oriental, Tchecoslováquia e União Soviética (URSS). Com o passar
do tempo, o número de países foi aumentando consideravelmente, chegando aos 101 que
participaram da competição em 2014 na Africa do Sul. Em 1979, a competição realizou-

1.2. Olimpíada Internacional de Matemática

33

se em Londres, onde o Brasil teve a sua primeira participação, e, desde então, compete
anualmente de forma ininterrupta. Além disso, o Brasil será sede da IMO em 2017.

Nas primeiras edições da IMO, cada país podia inscrever até oito alunos na com-
petição. Em 1982, esse número foi reduzido para quatro, sendo aumentado para seis no
ano seguinte, número que permanece até hoje. Os competidores devem ter menos de 21
anos de idade, com nível de escolaridade igual ou inferior ao Ensino Médio.

A IMO é uma competição individual, não havendo delegações nacionais. A pre-
miação é composta de medalhas de ouro, prata e bronze, além de certificados de menção
honrosa. A distribuição dos prêmios é realizada de tal forma que as medalhas sejam en-
tregues à metade dos estudantes participantes. Os certificados de menção honrosa são
entregues ao estudante que, não tendo recebido qualquer tipo de medalha, tenha resol-
vido corretamente algum dos seis problemas propostos na competição, incentivando os
competidores a procurar desenvolver soluções completas às questões propostas.

Faltando aproximadamente quatro meses para o início da competição, cada país
participante sugere até seis questões à Comissão Organizadora da IMO. As questões de-
vem abordar assuntos tratados no Ensino Médio: Geometria, Teoria dos Números, Análise
Combinatória e Álgebra. A partir dessas sugestões, é formada uma lista com trinta ques-
tões.

A escolha das questões que irão compor a prova é realizada por um júri formado
pelos chefes das equipes de todos os países participantes, liderado por uma comissão de
quatro juízes indicados pelo país sede do evento. Há o descarte de questões com nível de
dificuldade muito fácil ou muito difícil, sem o uso de pré-teste, pelos juízes. Depois de um
debate, as questões são escolhidas em uma votação por maioria simples e as provas são
organizadas nos idiomas oficiais da IMO: alemão, francês, inglês e russo. Se necessário, os
chefes das equipes são os responsáveis pela tradução das questões para outros idiomas.

As provas têm seis questões, cada uma valendo sete pontos, fazendo com que a nota
máxima obtida por um candidato seja 42 pontos. As provas são realizadas em dois dias,
cada um com três questões. Cada prova tem a duração de 4 h 30 min e, tradicionalmente,
a primeira questão é a mais fácil e a última, a mais difícil.

O Brasil tem tido participação expressiva nas competições da IMO (IMO, 2014).
Nos últimos anos, o Brasil tem figurado entre os 35 países de melhor rendimento, con-
quistando, nas edições de 2009 e 2012, medalhas de ouro, além de medalhas de pratas,
bronze e menções honrosas nas edições dos últimos anos.

34

Capítulo 1. OBMEP

1.3 Olimpíada Brasileira de Matemática

Segundo o sítio da OBM1, no cenário nacional, em 1977, a Academia Paulista de
Ciências criou a Olimpíada Paulista de Matemática. A Olimpíada Brasileira de Matemá-
tica – OBM, organizada pela Sociedade Brasileira de Matemática (SBM) e que concluiu
sua 36a edição em 2014, surgiu dois anos mais tarde.

A OBM é uma competição organizada pela SBM, com a colaboração do IMPA –
Instituto Nacional de Matemática Pura e Aplicada, que passou por diversas mudanças
em seu formato, contemplando em seus trabalhos iniciais os seguintes objetivos:

1. descobrir jovens com talento matemático excepcional, e colocá-los em contato com
matemáticos profissionais e instituições de pesquisa de alto nível, propiciando con-
dições favoráveis para a formação e o desenvolvimento de uma carreira de pesquisa;

2. selecionar os estudantes que representarão o Brasil em competições internacionais

de Matemática; e

3. organizar no Brasil as diversas competições internacionais de Matemática.

Esse projeto foi ampliado e a Olimpíada Brasileira de Matemática foi realizada
a partir do ano de 1998 de forma bastante diferente da que vinha sendo praticada nos
anos anteriores. Isso porque passou a atingir os alunos desde a 5a. série (sexto ano) do
ensino fundamental. A partir deste marco, acrescentou-se o seguinte objetivo: “interferir
decisivamente na melhoria do ensino de Matemática em nosso país, estimulando alunos e
professores”.

Para a preparação dos alunos e para o aperfeiçoamento dos professores, a OBM
distribuiu revistas e cartazes às escolas, contendo material para estudo e pesquisa, dedi-
cados a cada faixa de escolaridade e desenvolvimento dos alunos. A realização das provas
é uma conclusão dessa atividade.

A OBM é realizada anualmente em quatro níveis, de acordo com a escolaridade

do aluno:

Nível 1: para alunos matriculados no 6o ou 7o ano do ensino fundamental na ocasião da

realização da primeira fase da OBM;

Nível 2: para alunos matriculados no 8o ou 9o ano do ensino fundamental na ocasião da
realização da primeira fase da OBM ou que, tendo concluído o ensino fundamental
menos de um ano antes, não tenham ingressado no ensino médio até a data da
realização da primeira fase da OBM;

1

http://www.obm.org.br/

1.3. Olimpíada Brasileira de Matemática

35

Nível 3: para alunos matriculados em qualquer série do ensino médio na ocasião da
realização da primeira fase da OBM ou que, tendo concluído o ensino médio menos
de um ano antes, não tenham ingressado em curso de nível superior até a data de
realização da primeira fase da OBM; e

Nível universitário: para alunos que ainda não tenham concluído o curso superior (nor-
malmente estudantes universitários em nível de graduação, podendo ser estudantes
de qualquer curso e qualquer período).

Para cada um dos níveis, a OBM contempla fases de acordo com o nível. Na
primeira, qualquer aluno interessado poderá participar. Para participar das outras, existirá
um critério de promoção.

A prova da primeira fase é de múltipla escolha, contendo de 20 a 25 questões sobre
conteúdo adequado a cada um dos níveis de escolaridade. Em todas as fases, serão apre-
sentadas nas questões situações inovadoras, porém embasadas em conteúdos tradicionais
das escolas, de acordo com a Tabela 3.

Tabela 3 – Distribuição dos itens da OBM (OBM, 2014a).

Fase

Nível

Formato da Prova

Primeira
Segunda

Terceira

-

Todos
Todos
1
2 e 3

Uma prova de múltipla escolha com 20 a 25 questões.
Uma prova mista.
Uma prova discursiva com 5 problemas.
Duas provas discursivas realizadas em dois dias conse-
cutivos, com 3 problemas em cada dia.
Universitário Uma prova discursiva com 6 problemas.

As provas da primeira e segunda fases da OBM são realizadas nas escolas que
se cadastraram. A correção das provas também é realizada nas escolas, com o envolvi-
mento de seus professores, de acordo com critérios determinados pela organização. Os
coordenadores devem oferecer locais alternativos aos alunos que desejarem participar da
Olimpíada, caso o colégio onde realizam seus estudos não venha a se inscrever. A prova da
terceira fase é realizada em um local central designado pelo coordenador local e a correção
é feita pelo comitê organizador da OBM.

Alunos que ganharam medalha de ouro, prata ou bronze na OBM de determinado
ano estão automaticamente classificados para todas as fases da OBM do ano subsequente,
inclusive se houver mudança de nível.

A pontuação final dos alunos que participaram das três fases é feita pelas Bancas
Examinadoras, organizadas pelas Coordenações Regionais, as quais atribuem um ponto
a cada questão da Primeira Fase, sessenta pontos para cada problema da Segunda Fase e
cinquenta pontos para cada problema da Terceira Fase. Além disso, na classificação final,

36

Capítulo 1. OBMEP

são levados em conta os pontos acumulados nas duas fases anteriores. A partir dessa clas-
sificação, a OBM premia os alunos com medalhas de ouro, prata e bronze e certificados
de menção honrosa. Entre os premiados são selecionados aqueles que formarão as equipes
brasileiras na Olimpíada do Cone Sul (4 estudantes, com até 16 anos); na Olimpíada
Internacional de Matemática (6 estudantes do ensino médio, com até 19 anos); na Olim-
píada Ibero-Americana (4 estudantes, com até 18 anos) e na Competição Internacional
de Matemática (universitários). Essas competições são realizadas anualmente, sempre em
um país diferente.

A OBM sempre foi dedicada a encontrar jovens talentos para a Matemática ou
para Ciências Exatas e, nesse aspecto, tem cumprido sua finalidade. Existem brilhantes
matemáticos e cientistas de renome mundial que tiveram origem nas Olimpíadas de Ma-
temática. A título de exemplo, cita-se o matemático Artur Avila Cordeiro de Melo, de 35
anos, que recebeu recentemente (2014) a Medalha Fields, o mais tradicional e prestigioso
prêmio da Matemática internacional (OBM, 2014b).

Artur é o primeiro pesquisador latino-americano a receber a medalha. O prêmio
é outorgado pela União Internacional de Matemáticos (IMU, da sigla em inglês) a cada
quatro anos a pesquisadores com menos de 40 anos, cujos trabalhos sejam considerados
fundamentais para o avanço da Matemática. O prêmio foi entregue durante a cerimônia de
abertura do Congresso Internacional de Matemáticos, realizado na cidade de Seul, Coreia
do Sul.

A Medalha Fields foi concedida pela primeira vez em 1936. Contornando a medalha
está a inscrição (em latim) “TRANSIRE SUUM PECTUS MUNDOQUE POTIRI ”, que
significa “Superar os limites da inteligência e conquistar o universo”.

Artur Avila coleciona medalhas desde 1992, quando conquistou uma medalha de
bronze na OBM. Nos anos que seguiram obteve medalhas de ouro na competição nacional
e uma medalha de ouro na Olimpíada Internacional de Matemática (IMO), em 1995.

1.4 Olimpíada Brasileira de Matemática das Escola Públicas

A primeira edição da Olimpíada de Matemática das Escolas Públicas (OBMEP)
foi realizada em 2005. O Brasil foi surpreendido por uma proposta de inscrição em uma
Olimpíada de Matemática que contemplava somente as escolas públicas de Educação
Básica. Este foi o ponto de partida para a criação da OBMEP, cujo lema era “Somando
Novos Talentos”.

Assim, a principal razão para a existência da OBMEP são os alunos
das escolas públicas, seus desempenhos, interesse e motivação pela Ma-
temática. Este grupo de atores individuais é o foco principal dessa po-
lítica porque está no cerne de problemas existentes e inter-relacionados:

1.4. Olimpíada Brasileira de Matemática das Escola Públicas

37

o baixo desempenho dos alunos em Matemática, a importância da Ma-
temática para o desenvolvimento tecnológico do país, a baixa adesão
dos profissionais a esta carreira, a necessidade de profissionais para a
formação de novos alunos (BARBOSA, 2014, p. 37).

Com uma estratégia de divulgação do evento bastante eficiente, os organizadores
conseguiram a participação de 10.520.831 inscritos, 30.031 escolas, contemplando 93,5%
dos municípios brasileiros. Essa adesão colocou o Brasil como recordista mundial em
número de participantes em competições de Matemática, “superando o último Concours
Kangourou, realizado na França, que contou com a participação de quatro milhões de
competidores oriundos de vários países do mundo” (MACIEL, 2009).

A Tabela 4 lista o número de participantes e premiados nos últimos 10 anos.

Tabela 4 – Inscrições na OBMEP na primeira e segunda fase e premiados por ano.

Ano Primeira Fase Segunda Fase Premiados

2005
2006
2007
2008
2009
2010
2011
2012
2013
2014

10.520.831
14.181.705
17.341.732
18.326.029
19.198.710
19.665.928
18.720.068
19.166.371
18.762.859
18.192.526

457.725
630.864
780.333
789.998
841.139
863.000
818.566
823.871
954.926
907.446

31.109
34.743
33.003
33.017
33.011
33.256
33.202
45.434
44.835
45.664

Segundo Schirlo e Meza (2013), o formato da OBMEP foi construído com base em
um projeto que inclui como objetivo o desenvolvimento de estratégias que possibilitem
melhorar a qualidade do Ensino de Matemática na Educação Básica. Trata-se do Projeto
NUMERATIZAR: “Descobrir, divulgar e aprimorar os talentos de nossa juventude é a
forma mais efetiva e rápida de inclusão social”.

Esse projeto, desenvolvido no estado do Ceará a partir de 2003, sob a supervisão
da Universidade Federal do Ceará (UFC), foi motivado pelos resultados obtidos pela
utilização da estratégia das Olimpíadas de Matemática nas escolas privadas de Fortaleza-
CE, cujos alunos se destacaram em Olimpíadas de Matemática e nos principais concursos
vestibulares do país (BELLOS, 2007).

Em sua primeira edição, o NUMERATIZAR organizou uma Olimpíada
de Matemática na qual participaram cerca de 110.000 alunos do 6o ao
8o ano do Ensino Fundamental e da 1a série do Ensino Médio de escolas
públicas do Ceará. Seus idealizadores o conceberam como um projeto
matemático de inclusão social, caracterizado por um conjunto de ati-
vidades que tinham como objetivo validar a hipótese de que é possível

38

Capítulo 1. OBMEP

encontrar grande número de jovens talentos em Matemática em todas as
classes sociais. Segundo um dos objetivos do projeto, após identificá-los
(1a Fase do Projeto), era necessário motivá-los a avançar nos estudos em
Matemática (2a Fase do Projeto) (SCHIRLO; MEZA, 2013, p. 5).

Com amplitude maior, a Olimpíada Brasileira de Matemática das Escolas Públicas
é uma realização do IMPA, com apoio da SBM, e promoção do Ministério da Ciência e
Tecnologia e Inovação (MCTI) e do Ministério da Educação (MEC). Esta competição
é dirigida aos alunos do 6o ao 9o ano do Ensino Fundamental e aos alunos do Ensino
Médio das escolas públicas municipais, estaduais e federais, que concorrem a prêmios de
acordo com a sua classificação nas provas. Professores, escolas e secretarias municipais
de educação também concorrem a prêmios. Segundo seu regulamento, os objetivos desta
competição são (IMPA; SBM, 2014a):

(a) estimular e promover o estudo da Matemática entre alunos das escolas públicas;

(b) contribuir para a melhoria da qualidade da Educação Básica;

(c) identificar jovens talentos e incentivar seu ingresso nas áreas científicas e tecnológi-

cas;

(d) incentivar o aperfeiçoamento dos professores das escolas públicas, contribuindo para

a sua valorização profissional;

(e) contribuir para a integração das escolas públicas com as universidades públicas, os

institutos de pesquisa e as sociedades científicas;

(f) promover a inclusão social por meio da difusão do conhecimento.

Os alunos participantes são divididos em 3 (três) níveis, de acordo com o seu grau

de escolaridade:

Nível 1: alunos matriculados no 6o ou 7o ano do Ensino Fundamental.

Nível 2: alunos matriculados no 8o ou 9o ano do Ensino Fundamental.

Nível 3: alunos matriculados em qualquer ano do Ensino Médio.

Participam das provas somente os alunos que, na data da realização das provas,
estiverem regularmente matriculados nas escolas inscritas. A OBMEP realiza-se em 2
(duas) etapas:

Primeira Fase: aplicação de prova objetiva (múltipla escolha) a todos os alunos inscritos

pelas escolas;

1.4. Olimpíada Brasileira de Matemática das Escola Públicas

39

Segunda Fase: aplicação de prova discursiva aos alunos selecionados pelas escolas, 5%
(cinco por cento) dos alunos que realizaram a primeira fase e obtiveram os melhores
resultados. Havendo empate, as escolas devem divulgar previamente os critérios de
desempate a serem aplicados.

A Primeira Fase caracteriza-se pela aplicação de prova com questões de múltipla
escolha pelos professores das escolas inscritas na OBMEP, seguindo instruções e gabari-
tos elaborados pela Coordenação Geral da OBMEP. As notas da Primeira Fase não são
consideradas para classificação final.

A Segunda Fase da OBMEP caracteriza-se pela aplicação de prova discursiva por

fiscais selecionados pela Coordenação Geral para esse fim.

A OBMEP premia alunos, professores, escolas e secretarias municipais de educa-

ção, ao alunos da seguinte forma:

i. 500 (quinhentas) medalhas de ouro;

ii. 1.500 (mil e quinhentas) medalhas de prata;

iii. 4.500 (quatro mil e quinhentas) medalhas de bronze;

iv. Até 46.200 (quarenta e seis mil e duzentos) certificados de Menção Honrosa;

v. Programa de Iniciação Científica Jr. (PIC): bolsas de Iniciação Científica Jr do
CNPq concedidas aos 6.500 alunos medalhistas matriculados em escolas públicas
no ano seguinte à aplicação das avaliações. Em caso de vacância de bolsas, um
medalhista poderá ser substituído por um aluno que tenha recebido uma Menção
Honrosa e esteja matriculado no ensino público, a critério da coordenação do PIC;
e

vi. Programa de Iniciação Científica e de Mestrado (PICME): bolsas concedidas aos
medalhistas de ouro, prata ou bronze de qualquer edição da OBMEP, regularmente
matriculados no ensino superior, concedidas por diversas Instituições de Ensino
Superior.

Aos professores, até o limite de 1.029 (mil e vinte e nove), e às Escolas, até 495
(quatrocentos e noventa e cinco), as premiação estarão vinculadas à pontuação de seus
alunos, segundo os seguintes critérios:

i. 10 (dez) pontos para cada aluno premiado com medalha de ouro;

ii. 8 (oito) pontos para cada aluno premiado com medalha de prata;

iii. 6 (seis) pontos para cada aluno premiado com medalha de bronze;

40

Capítulo 1. OBMEP

iv. 3 (três) pontos para cada aluno premiado com menção honrosa;

v. 1 (um) ponto para cada aluno que compareceu à Segunda Fase e não obteve premi-

ação.

A premiação dos docentes será de aparelhos eletrônicos e assinaturas de revistas

do professor. E serão distribuídos desde kits esportivos até material didático à escola.

Como visto, as escolas são responsáveis pela participação de seus alunos, não ha-
vendo limite para o número de inscritos e todos devem ser estimulados a participar. As
escolas são responsáveis pela organização e pela infraestrutura da aplicação das provas da
Primeira Fase e também pela sua correção, de acordo com o calendário determinado pela
OBMEP. As escolas são também responsáveis pela guarda do material de provas e pela
manutenção do sigilo do mesmo, desde o recebimento até a correção e envio da lista de
classificados , cabendo até desclassificação em caso de quebra de sigilo.

A Coordenação Geral da OBMEP, designada pela Diretoria do IMPA, tem as

seguintes responsabilidades:

(a) planejamento e organização do projeto;

(b) elaboração de material didático das provas e dos gabaritos;

(c) envio dos gabaritos das provas da Primeira Fase e de material didático às escolas;

(d) processamento das informações enviadas pelas escolas com os resultados da Primeira

Fase;

(e) aplicação das provas da Segunda Fase;

(f) correção das provas da Segunda Fase e indicação de todas as premiações;

(g) conservação das provas da Segunda Fase por um período de 4 (quatro) meses a

contar da data da divulgação dos resultados;

(h) manutenção da página do evento na internet atualizada com informações sobre a

Olimpíada;

(i) elaboração do Relatório Final dos resultados.

1.5 Contribuições da OBMEP

A OBMEP é uma ação política pública que nasce em um momento de grandes
transformações educacionais, principalmente no que se refere à avaliação em larga escala

1.5. Contribuições da OBMEP

41

e à criação do Índice de Desenvolvimento da Educação Básica (IDEB). As ações motivadas
pela Olimpíada podem ser confrontadas com os resultados de avaliações educacionais.

Entre as realizações da OBMEP desde sua criação até 2014, em sua décima edição,

destacam-se, segundo IMPA e SBM (2014b):

∙ o atendimento pelo PIC de 36 mil e 500 alunos, uma oportunidade de estudar

Matemática por 1 ano, com bolsa do CNPq;

∙ a distribuição para as escolas de material didático de qualidade, como apostilas do

PIC e Banco de Questões, também disponível em sítio específico;

∙ o atendimento pelo PICME de cerca de 1.321 alunos;

∙ a preparação de medalhistas de ouro, selecionados para participar de competições
internacionais, pelo PECI – Preparação Especial para Competições Internacionais;

∙ a preparação de competidores, em 2012, foi criado o POTI – Polos Olímpicos de
Treinamento Intensivo – em parceria com a OBM, com o objetivo ampliar o acesso
dos alunos brasileiros a treinamento para competições matemáticas;

∙ a preparação de docentes, em 2012, foi criado o PROF, programa destinado ao
aperfeiçoamento dos professores de Matemática. Este programa está em seu terceiro
ano no Estado de São Paulo, em parceria com a SEED;

∙ a preparação de estudantes, em 2013, a OBMEP lançou o programa Clubes de
Matemática, que já conta com a adesão de cerca de 3000 alunos em 389 clubes em
todo o Brasil;

∙ o lançamento do Portal da Matemática, com aplicativos e videoaulas que cobrem
todo o currículo da Matemática, do sexto ano do Ensino Fundamental ao terceiro
ano do Ensino Médio; e

∙ a mobilização dos Coordenadores Regionais da OBMEP para a realização de ativi-

dades, como seminários com professores e cerimônias de premiação.

Em 2015, com o apoio da CAPES, foi criado o programa OBMEP nas Escolas,
voltado para o professor de Matemática das escolas públicas. O programa quer estimular
atividades extraclasse com o uso dos materiais da OBMEP, tais como provas e Bancos de
Questões. Professores de todo o país são habilitados e preparados para desenvolver essa
atividade em sua escola ou em escolas vizinhas (OBMEP, 2015).

Ressalta-se que a contribuição da OBMEP vai além de criação, ampliação e manu-
tenção de projetos a ela vinculados. Uma contribuição que propostas dessa natureza po-
dem agregar à qualificação do Ensino de Matemática no país é a possibilidade de oferecer

42

Capítulo 1. OBMEP

uma formação na qual o aluno, ao concluir sua escolarização básica, esteja “alfabetizado
quantitativamente”.

Cidadãos quantitativamente alfabetizados precisam conhecer mais que
fórmulas e equações. Eles precisam de uma predisposição de olhar o
mundo através de olhos matemáticos, para ver os benefícios (e os riscos)
de pensar quantitativamente acerca de assuntos habituais e para abordar
problemas complexos com confiança no valor do raciocínio cuidadoso. Al-
fabetização quantitativa dá poder às pessoas ao oferecer-lhes ferramentas
para que pensem por si próprias, para fazer perguntas inteligentes aos
especialistas e para confrontar a autoridade com confiança. Estas são ha-
bilidades requeridas para prosperar no mundo moderno (OCED, 2014,
p. 5).

Essas habilidades vão ao encontro dos fundamentos filosóficos da Educação Mate-
mática Crítica, de Ole Skovsmose, que defende a necessidade do entendimento do papel da
Educação Matemática em uma sociedade democrática: “(...) a alfabetização Matemática,
como construto radical, tem de estar enraizada em um espírito de crítica e em um projeto
de possibilidades que habilite pessoas a participarem no entendimento e na transformação
da sociedade” (SKOVSMOSE, 2004, p. 95).

Esse caráter inclusivo associado à OBMEP fica explícito na análise de sua es-
trutura de funcionamento, com suas Coordenações Regionais preocupadas em viabilizar
a participação de alunos das mais diferentes regiões do país. Além disso, a sistemática
de premiação segue o que tradicionalmente é utilizado nas competições olímpicas, mas
proporcionou um avanço considerável na condução das atividades.

Além disso, é necessário ressaltar que houve movimento considerável
dentro de muitas escolas no sentido de divulgar e, até mesmo, preparar
seus alunos para a OBMEP. Esse movimento levou professores a pro-
curarem oportunidades de aprofundar e qualificar seu trabalho. Nesse
sentido, a discussão sobre os resultados obtidos pelos alunos nas Olim-
píadas pode oferecer subsídios à reflexão sobre a qualificação do Ensino
de Matemática no país (MACIEL, 2009, p. 7).

O desempenho do Brasil nas avaliações do PISA – Programa Internacional de Ava-
liação de Estudantes, os relatórios das secretarias de educação e os relatórios de programas
de capacitação de professores indicam que há no país uma deficiência séria na qualidade
do ensino de Português e Matemática, disciplinas fundamentais na formação profissional
e no exercício da cidadania. Em 2012, o resultado do PISA (OCED, 2014), apresenta uma
ligeira melhora em Matemática: o Brasil saiu de 386 pontos, em 2009, e foi a 391 pontos.
Mesmo assim não atingiu a média desejada que é de 494 pontos, ocupando a 58a posição
mundial. E quanto ao aprendizado, na escala de 6 níveis, a maior parte dos alunos situa-se
nos primeiros níveis.

Em contrapartida, em 2012, foram distribuídas 4.500 medalhas aos alunos com
melhor desempenho entre 19 milhões de alunos de mais de 99% dos municípios brasilei-

1.5. Contribuições da OBMEP

43

ros. Cocal dos Alves (PI) é exemplo entre as cidades com cerca de 12 mil habitantes que
receberam número expressivo de medalhas. A partir do envolvimento dos alunos premi-
ados em atividades de estudos em grupo ou monitorias acompanhadas por professores,
elevou-se o nível de aprendizagem dos alunos. Em 2011, 89% deles sabiam o esperado em
Matemática nas séries finais do ensino fundamental (QEDU, 2014). Estes dados sugerem
um impacto positivo da Olimpíada contribuiu no aprendizado dos estudantes de Cocal dos
Alves, embora seja necessário um estudo mais aprofundado para mensurar este possível
impacto.

No que diz respeito ao contato entre o aluno premiado e o meio universitário, na
OBMEP, este é promovido a partir do PIC, pois seus responsáveis são professores uni-
versitários e o Programa se desenvolve sobretudo em salas universitárias, o que traz uma
convivência natural do aluno da escola pública com a universidade. Enquetes realizadas
entre os medalhistas da OBMEP mostram que a vontade geral dos alunos é a de prosseguir
nos estudos universitários.

Observa-se ainda que uma parcela significativa não chega à universidade por causa
de suas limitações econômicas, o que tem levado a propor às agências de fomento a criação
de bolsas de manutenção para atender a esses alunos.

2 Avaliação

45

2.1 Avaliação a Serviço da Aprendizagem Matemática

Quando direciona-se o olhar a um aluno, e esse olhar determina a ação de trabalho
para o desenvolvimento da aprendizagem do mesmo ou do grupo no qual ele está inse-
rido, este ato intencional é uma avaliação para a aprendizagem. Sendo formal ou não, a
avaliação da aprendizagem corrobora para a formação de um indivíduo. Se utilizada de
forma errônea, pode causar a evasão escolar e até caracterizar os indivíduos, levando-os
à exclusão pelos seus pares.

As notas altas também podem resultar em exclusão, pois os alunos, ao receberem
elogios, parecem possuir padrões inalcançáveis ao grupo ao qual pertence. Em contrapar-
tida, as notas baixas podem destruir a autoimagem dos estudantes, por se considerarem
fora de um padrão esperado. Tanto uma como a outra classificação estigmatizam e podem
conduzir ao bullying na escola.

Estes são resultados informais de uma avaliação classificatória no foro do aluno,
que o rotulam no meio social de forma negativa, obtendo ou não resultados numéricos
positivos.

Na outra face, ao verificar resultados abaixo do esperado, o professor já classifica
o que pode ser ensinado e/ou como pode ensinar, determinando o que será apresentado
para suas diversas turmas. Esse é o traço da avaliação informal no processo de ensino-
aprendizagem.

Com a OBMEP não é diferente, com questões desafiadoras e fora do padrão li-
vresco, seus resultados numéricos denotam um senso de “dia perdido de aula” na escola.
O grupo escolar apresenta constantemente questionamentos do tipo: por que se deve pa-
rar a escola para uma atividade que revela o baixo nível de requisitos apresentados pelos
alunos? Por que um gasto excessivo com reproduções de materiais os quais os alunos nem
se dão o trabalho de ler?

Aqui se veem questionamentos de visões construídas na avaliação classificatória,
que, informalmente, vão reger o trato nas atividades de aplicação das provas da primeira
fase da Olimpíada na escola e até mesmo no uso desta atividade no âmbito escolar.

O processo de avaliação, formal ou informal, não deve ser norteador do trabalho
docente se não for embasado em objetivos claros. Assim a avaliação deve estar servindo
à aprendizagem almejada nos objetivos educacionais e a intencionalidade deve ser a raiz
do avaliar. Dependendo do objetivo traçado, os métodos e a temporalidade de avaliação

46

Capítulo 2. Avaliação

deverão se adaptar ao grupo de indivíduos e às suas necessidades. Logo, a avaliação deverá
ser vista como produto dos objetivos.

Em contrapartida, a avaliação traz um feedback para uma reconstrução dos objeti-
vos, ampliando-os ou até mesmo alterando-os. É uma relação biunívoca avaliação/objetivos,
na qual os resultados apresentados por alunos geram modificações no processo metodo-
lógico de ensino-aprendizagem, inclusive nos próprios objetivos. E os objetivos regem o
processo avaliativo em busca de resultados.

De acordo com Freitas, os objetivos orientam o caminho a seguir, contribuindo na
percepção se as atividades foram cumpridas a contento. E a avaliação é a concretização do
idealizado nos objetivos, permitindo a análise ideal e real. Além disso, “os objetivos, sem
alguma forma de avaliação, permaneceriam sem nenhum correlato prático que permitisse
verificar o estado concreto da objetivação” (FREITAS, 1995 apud VILLAS-BOAS, 2014,
p. 95).

Cabe neste momento um olhar conceitual para a avaliação para o melhor entendi-

mento dessa relação avaliação-objetivos.

2.2 Rompendo os Conceitos Avaliativos

A avaliação classificatória é o produto da avaliação somativa na escola. O professor

australiano Royce Sadler define:

que a avaliação somativa apresenta o balanço do desempenho do aluno
ao final de um período de estudos, geralmente com o propósito de cer-
tificação (...) é empregada para medir o que foi aprendido ao final de
determinado período; para promover os alunos; para assegurar que eles
alcancem os padrões de desempenho estabelecidos para conclusão de cur-
sos, para exercer certas ocupações ou para selecionar os que prosseguirão
os estudos (SADLER, 1989 apud VILLAS-BOAS, 2006).

Ou seja, a avaliação classificatória é definida por mensuração nos períodos de es-
tudos, denota a posição do estudante em face ao currículo escolar e a “medida” do seu
aprendizado. Essa é utilizada por gestores educacionais ao requererem subsídios governa-
mentais, na elaboração de históricos escolares e também na própria OBMEP, que tem o
caráter classificatório competitivo.

Conceitualmente, busca-se fugir da avaliação classificatória por medir e nesta men-
suração determinar o quanto foi aprendido, mas, na prática, é difícil romper com essa
forma de avaliar, pois o docente traz para sua sala de aula todos os processos avaliativos
que aprendeu em sua formação, e essa formação não é apenas a acadêmica, mas em toda
sua vida escolar. Como romper com a prática avaliativa, se o método tradicional levou
este profissional a uma vida acadêmica próspera?

2.2. Rompendo os Conceitos Avaliativos

47

Segundo Sadler (1989 apud VILLAS-BOAS, 2006), “o que diferencia a avaliação
somativa da formativa é o propósito e o efeito, e não o momento da sua realização”, ou
até mesmo a sua forma. Uma prova como a OBMEP é classificatória, mas se agregada
a esta propósitos de construção da aprendizagem durante a sua realização, o aluno ou
o professor tornam-se foco da construção de habilidades. E com esse enfoque soma-se, à
classificação, um processo de formação.

A avaliação formativa, segundo Villas-Boas (2014), toma o aprendiz como sua
própria referência de medida de aprendizado. É o momento onde o docente, de maneira
frequente e interativa, analisa o progresso dos alunos, para identificar quais as suas ha-
bilidades e competências e o que falta construir, de forma a orientar e/ou reorientar sua
ação pedagógica, levando em consideração as diferenças inerentes ao trabalho com cada
aluno, até mesmo a temporalidade individual de aprendizado.

Segundo a mesma autora, com a avaliação formativa, “pode-se atingir os objeti-
vos da aprendizagem permanente, seja elas: a promoção de desempenho de alto nível; a
adoção de tratamento equânime dos resultados da avaliação dos alunos; a construção de
habilidades para o aprender a aprender” (VILLAS-BOAS, 2014).

Os objetivos apontam o estado final e o estado final está em contradição
com o estado real do aluno, o que deve criar motivação, gerar movimento.
A avaliação é instrumento dessa superação. Aponta o estado real e serve
de ponto de referência para o aluno contrapor-se ao que é esperado em
termos de objetivos. Porém, esse processo deve ser assistido de forma a
garantir os elementos necessários para a superação das dificuldades dos
alunos [...] (FREITAS, 1995).

Nessa perspectiva formativa, o professor facilitador da aprendizagem pode ser con-
siderado um correlacionador de feedbacks e objetivos, reconhecendo e descrevendo o de-
sempenho desejável de seus alunos, indicando o que pode ser melhorado até que o próprio
aluno assuma o papel correlacionador. O professor oferece inicialmente o caminho em
busca dos objetivos até o alcance do auto-monitoramento pelo aluno, onde este é capaz
de gerar informação necessária para caminhar para aprendizagem, segundo Sadler:

A avaliação formativa é a que engloba todas as atividades desenvolvidas
pelos professores e seus alunos, com o intuito de fornecer informações a
serem usadas como feedback para reorganizar o trabalho pedagógico.

O feedback é o elemento-chave na avaliação formativa: diz respeito à
informação, ao próprio aluno, a quão bem-sucedido ele foi no desenvol-
vimento do seu trabalho.

Poucas habilidades físicas, intelectuais e sociais podem ser desenvolvidas
satisfatoriamente falando ao aluno sobre elas. A maioria requer a prá-
tica em ambiente apoiados, que favoreça o entrelaçamento de feedbacks
(SADLER, 1989 apud VILLAS-BOAS, 2014, p. 39-40).

48

Capítulo 2. Avaliação

Para Hadji, a avaliação formativa tem como ponto forte a característica de informar
aos envolvidos no processo de ensino os objetivos alcançados e potenciais de desenvolvi-
mento em ambos os atores: professores e alunos.

O professor será informado dos efeitos reais de seu trabalho pedagógico,
poderá regular sua ação a partir disso. O aluno, que não somente saberá
onde anda, mas poderá tomar consciência das dificuldades que encontra
e tornar-se-á capaz, na melhor das hipóteses, de reconhecer e corrigir ele
próprio seus erros (HADJI, 2001, p. 20).

De acordo com Villas-Boas (2014), para o alcance do auto-monitoramento é ne-

cessário que o aluno, motivado pelo professor:

1. saiba quais os objetivos de aprendizagem que devem ser alcançados no processo de

aprendizagem;

2. seja capaz de definir o quão distante ele está desta meta;

3. se torne agente, reduzindo a distância entre o nível em que ele se encontra e a meta

de aprendizado.

Um componente importante nesse processo formativo é a avaliação informal que
ocorre quando o professor dá ao aluno a orientação e o suporte que ele necessita, demons-
trando interesse pela aprendizagem individual; sem demonstrar preferências e usando as
dificuldades como suporte de amadurecimento de conceitos.

Tratando da avaliação informal, Freitas aponta que

Professores e alunos defrontam-se na sala de aula construindo represen-
tações uns dos outros. Tais representações e juízos orientam novas per-
cepções, traçam possibilidades, estimam desenlaces, abrem ou fecham
portas e, do lado do professor, afetam o próprio envolvimento deste com
os alunos, terminando por interferir positiva ou negativamente com as
estratégias de ensino postas em marcha na sala de aula. É aqui que se
joga o sucesso ou o fracasso do aluno – nesse plano informal e não no
plano formal. De fato, quando o aluno é reprovado pela nota, no plano
formal, ele já tinha sido, antes, reprovado no plano informal, no nível
dos juízos de valor e das representações do professor – durante o próprio
processo (FREITAS, 2002 apud VILLAS-BOAS, 2014, pg. 45).

Como citado, a avaliação informal está entrelaçada com a avaliação formal, onde
esta tem como exemplos – provas, relatórios, exercícios diversos, produção de textos e
outros – e é caracterizada pela documentação que serve de base para o olhar do docente.
Tradicionalmente utilizada para classificar, mas são os instrumentos que constroem fontes
para o julgamento do professor, que, ao pensar formativamente a aprendizagem de seu
aluno, verifica o distanciamento do mesmo com o objetivo esperado e toma atitudes de

2.2. Rompendo os Conceitos Avaliativos

49

orientação no processo pedagógico que visem a avaliação para aprendizagem, mesmo que
haja um número em seu topo.

Villas-Boas (2014), em suas pesquisas, emprega a expressão “avaliação para apren-

dizagem” introduzindo um novo paradigma para a avaliação.

Porque a avaliação para aprendizagem contribui para a reorganização do
trabalho pedagógico, ampliando a aprendizagem de professores. E, em
sentido mais amplo ainda, chega-se ao desenvolvimento da escola. Essa
perspectiva constrói cultura de avaliação formativa na escola (VILLAS-
BOAS, 2014, p. 57).

Ao docente cabe a função de cuidar de todo o desenvolvimento da avaliação, que

poderá incluir (BRASIL, 2000):

i. A definição dos objetivos educacionais que orientarão o trabalho pedagógico que

será desenvolvido;

ii. a delimitação dos conteúdos que serão abordados e como serão abordados;

iii. o envolvimento dos alunos no processo avaliativo;

iv. a definição dos procedimento/instrumentos de avaliação;

v. a análise dos resultados e feedback dos mesmos aos alunos; e

vi. as tomadas de atitudes a partir dos resultados apresentados pelos alunos.

Essa autonomia do professor frente a avaliação é dada pela hierarquia do sistema
educacional, que também dá subsídios para o processo de avaliação da aprendizagem. O
docente, embora autônomo, deve basear seu trabalho no PPP – Projeto Político Peda-
gógico, documento construído por toda comunidade escolar que se baseia na avaliação
institucional, na LDB – Lei de Diretrizes e Bases, nos PCN – Parâmetros Curriculares
Nacionais e em outras diretrizes nas esferas municipais, estaduais e nacionais.

Como dito acima, as posturas de avaliar do docente no âmbito da sala de aula
estão presentes na esfera educacional, que se apresenta em três níveis, segundo Freitas,
que se integram com o objetivo de analisar e discutir a qualidade de ensino-aprendizagem:
“avaliação em larga escala em redes de ensino; a avaliação institucional da escola; e a
avaliação da aprendizagem em sala de aula” (FREITAS, 2014, p. 10).

Ressalta-se a importância desses níveis para entender que o tema avaliação abrange
vários componentes. Desde o Estado e suas políticas – confrontos de resultados com outros
países e declarações de metas construídas por órgãos internacionais – perpassando pela
escola até chegar a sociedade e seus anseios.

50

Capítulo 2. Avaliação

No tocante à avaliação institucional, esta tem como objetivo criar indicadores que
contribuam para a reconstrução do ambiente escolar, em todos os seus níveis, desde o
espaço físico e intenções pedagógicas até os seus atores, do gestor até o aluno. A avalia-
ção institucional da escola “é um processo que envolve todos os seus atores, com vistas
a negociar patamares adequados de aprimoramento, a partir dos problemas concretos
vivenciados por ela” (FREITAS, 2014, p. 35).

Os resultados da escola na OBMEP podem ser utilizados neste nível de forma a
eleger procedimentos e projetos que contribuam para um resultado mais significativo nas
avaliações da competição, verificando o distanciamento da aprendizagem dos alunos ao
que se é esperado na realização de tais avaliações e também questionando o envolvimento
dos profissionais da instituição na olimpíada.

Estando um nível acima, de acordo com Freitas (2014), a avaliação externa em
larga escala ou avaliação de redes visa ao levantamento de dados que contribuam a gerar
informações que possam descrever a realidade educacional dos estados, municípios e, por
sua vez, do país. São realizadas pelos sistemas educacionais ou de ensino, normalmente com
institutos de pesquisa, órgãos governamentais ou outras entidades vinculadas à educação
e ao seu funcionamento.

Para Freitas, esse tipo de avaliação “quando conduzida com metodologia adequada
pode trazer importantes informações sobre o desempenho dos alunos, dados sobre os
professores, condições de trabalho e funcionamento das escolas de uma rede” (FREITAS,
2014, p. 47). Como exemplo temos o SINAES, o Saeb e a Prova Brasil.

Os resultados obtidos pelo Relatório de Acertos e Informações Gerais –
RAIG (Anexo A) ajudam na identificação do trabalho que o professor desenvolve com
seus alunos no tocante a OBMEP. Após a realização da primeira fase da OBMEP, o
coordenador do evento na escola é convidado a responder a um questionário sobre os
envolvidos no processo, quantificando notas dos participantes e verificando o uso dos
recursos disponibilizados pelo organizador da competição destinados aos educadores.

Em 2013, 35.062 unidades escolares enviaram o RAIG com devolutivas sobre a
OBMEP, representando 74,4% das escolas cadastradas. Nesse mesmo ano, verificou-se
que 48,5% das escolas afirmam desenvolver atividades extracurriculares de Matemática.
Entre estas, 21,8% indicam a realização de gincanas e competições internas, 20,2% de
grupos de estudos e 1,2% das unidades escolares relatam a criação de Clubes de Mate-
mática. Destaca-se ainda que, 10,9% afirmam realizar outras atividades, desde atividade
de reforço, treinamentos para OBMEP até projeto como o Superação Jovem, em parceria
com o instituto Ayrton Senna (RAIG 2014).

Neste tocante, Villas Boas acrescenta que a avaliação do desempenho dos alunos

em larga escala:

2.3. Avaliação e Educação Matemática

51

Embora sejam necessárias, estas iniciativas não tem sido acompanhadas
de ações que as associem adequadamente ao trabalho de toda a escola
e ao trabalho conduzido pelo professor em sala de aula. Avaliar é pre-
ciso. Mas de forma que contribua com a melhoria do trabalho escolar
(VILLAS-BOAS, 2014, p. 10).

2.3 Avaliação e Educação Matemática

A ação avaliativa para a aprendizagem é um romper de paradigmas, pois o ato
de medir é muitas vezes confundido com avaliar, em que o primeiro implica determinar
a extensão de uma característica pertencente a um indivíduo ou a um objeto e a se-
gunda significa comparar uma medida com um padrão e emitir um julgamento sobre a
comparação.

Como avaliar envolve um julgamento, são envolvidas também concepções intrín-
secas do indivíduo: crenças, valores, princípios, teorias e/ou conceitos. Assim, pode-se
confirmar que avaliar é mais amplo que apenas medir e que na prática pode-se usar ins-
trumentos avaliativos como meios para o ato de avaliar a aprendizagem dos alunos e
não apenas para medir ou quantificar. Além disso, pode-se questionar se o instrumento
utilizado, de fato, revela o que o aluno apreendeu.

Os PCN pautados numa perspectiva de ensino-aprendizagem da Matemática que
busca conduzir os alunos a experiência de situações que os levem a uma aprendizagem
significativa e prazerosa, afirma que:

[. . .] para tanto, é importante que a Matemática desempenhe, equilibrada
e indissociavelmente, seu papel na formação de capacidades intelectuais,
na estruturação do pensamento, na agilização do raciocínio dedutivo do
aluno, na sua aplicação a problemas, situações da vida cotidiana e ativi-
dades do mundo do trabalho e no apoio à construção de conhecimentos
em outras áreas curriculares.

Os resultados expressos pelos instrumentos de avaliação, seja eles provas,
trabalhos, postura em sala de aula, constituem indícios de competências
e como tal devem ser considerados. A tarefa do avaliador constitui um
permanente exercício de interpretação de sinais, de indícios, a partir dos
quais manifesta juízos de valor que lhe permitem reorganizar a atividade
pedagógica (BRASIL, 2000, V.3 p. 29).

Nesses apontamentos presentes nos PCN relativos à avaliação, os instrumentos
avaliativos devem ser embasados na intencionalidade de desempenho de habilidades e
competências que contemplem o conhecimento Matemático, com toda a sua abstração,
associado a suas aplicações no cotidiano da sociedade, contribuindo pelo melhor entendi-
mento de mundo pelo estudante.

O professor de Matemática deve manter o foco no objetivo principal do ensino, que
é a aprendizagem. Deve questionar constantemente se as atividades pedagógicas propostas

52

Capítulo 2. Avaliação

por ele, e isto inclui a avaliação, estão contribuindo para a formação do aprendiz como
um todo ou apenas focadas em classificar.

Com isso, vê-se que na visão de avaliação para a aprendizagem, o professor é
convidado a reconhecer a avaliação como parte do processo de ensino e aprendizagem e
a repensar as sua atitudes frente aos seus métodos pedagógicos, usando o princípio de
organização e reorganização do ato de ensinar, não podendo este ser reduzido a aplicações
de atividades avaliativas de forma isolada e dissociada do processo.

Os PCN (BRASIL, 2000) ressalta, ainda, a necessidade de o professor manter-se
atento quanto ao alcance dos objetivos pré-determinados, para que possa, se necessário,
reorganizar as atividades pedagógicas a tempo de alcançar os objetivos. Infere-se com isso
que avaliação da aprendizagem Matemática deve acontecer ao longo do processo de ensino-
aprendizagem tendo o professor que lançar mão de diversos procedimentos/instrumentos
e adaptar essa trajetória tendo como foco o aluno.

Atividades com caráter avaliativo devem auxiliar na investigação dos fatores que
contribuem de forma positiva e negativa para o desenvolvimento do saber matemático,
não só para auxiliar o professor em sua tarefa de ensinar, mas em esclarecer para os alunos
seu desempenho diante do objetivo de aprender, devem levá-los a um auto-monitoramento
das suas conquistas e revelá-los o caminho que ainda falta percorrer.

A prática avaliativa que visa à memorização de teoremas e à reprodução de técnicas
de resolução de exercícios acaba por se limitar a procedimentos que não vão além de
provas, tão conhecidas como classificatórias e excludentes. Professores e alunos precisam
enxergar no cotidiano escolar várias possibilidades de aprendizagem. A avaliação deve
ser entendida como uma atividade capaz de proporcionar oportunidades de aprender.
Abrantes corrobora com este pensamento ao dizer:

Ver as tarefas de avaliação como fontes de aprendizagem implica que
elas requerem atividades interessantes e significativas. Além disso, elas
devem proporcionar aos alunos novas oportunidades para aprender, para
melhorar e para refletir sobre seu próprio trabalho (ABRANTES, 1995,
p. 15).

Na avaliação da aprendizagem Matemática, as atenções devem estar voltadas para
todos os lados, todas as atividades desenvolvidas pelos alunos constituem-se como ele-
mentos de investigação da aprendizagem Matemática. Observar e analisar as estratégias
traçadas pelos alunos quando colocados frente a uma situação-problema mostra-se como
essencial no processo investigativo da avaliação. Estar atento ao plano de ação do aluno
requer que o professor, em especial, considere os registros escritos desse aluno.

Para enriquecer a análise de registros escritos, o professor pode ouvir o aluno para
melhor entender seu procedimento ao resolver uma situação Matemática. Essa prática

2.3. Avaliação e Educação Matemática

53

serve tanto para orientá-lo no processo de formalização, quanto na organização da lógica de
resolução. Isso se justifica pois algumas passagens na resolução de uma situação-problema
não são manifestas na escrita e estas podem esclarecer informalmente o porquê do caminho
utilizado.

Corroborando com essa ideia, o processo de avaliação em Matemática, segundo

Buriasco, deve evidenciar, entre outras coisas:

∙ a interpretação dada, diante a resolução de uma questão;

∙ as opções feitas durante a resolução;

∙ os conhecimentos matemáticos utilizados;

∙ se utilizaram a Matemática que é vista nas aulas; e

∙ a forma de comunicação Matemática, comprovando sua capacidade em
se expressar, oralmente ou por escrito (BURIASCO, 2002 apud BURI-
ASCO; SOARES, 2012, p. 114).

Vasconcellos (1998) aponta três dimensões que considera essenciais para a con-
cretização da avaliação da aprendizagem: a intencionalidade, o conteúdo e a forma. Em
acordo com a perspectiva apresentada por este autor, estas dimensões serão discutidas a
seguir com o intuito de orientar o desenvolvimento das práticas avaliativas que perpassam
a escolha dos procedimentos/instrumentos avaliativos.

2.3.1 Intencionalidade – o objetivo ao avaliar

É a ação que fundamenta a ação docente ao avaliar, é o estabelecimento do que se
pretende com a avaliação. O professor estará traçando a função da avaliação que poderá
variar entre classificatória e/ou formativa.

Vasconcellos (1998) considera este o momento determinante da avaliação, segundo
o autor a intencionalidade que o professor atribui à avaliação no seu cotidiano influirá em
todo seu desenvolvimento até o resultado.

2.3.2 O conteúdo – o objeto de avaliação

Aqui o termo conteúdo não se refere àquele estruturado pelos itens do conheci-
mento do currículo, mas ao que será observado para fazer juízo de avaliação. Mas sim a
delimitação do objeto de avaliação que norteará o trabalho docente ao longo do processo
avaliativo.

Aquele trabalho em sala, como parte constituinte da aprendizagem, provavelmente
será objeto de análise, entretanto sabe-se que durante a avaliação diversas situações po-
derão se apresentar levando o professor a ficar atento também a outras dimensões da

54

Capítulo 2. Avaliação

avaliação. Podem ser incluídas no processo de verificação da aprendizagem: a postura
do estudante, antes e durante as atividades avaliativas; as estratégias de resolução dos
exercícios; a interação com os colegas e professor, e outras fontes informais.

Na verdade, o conteúdo avaliado é o foco que o avaliador dará sobre a situação
avaliativa como um todo. São todas as características que este último julgará para dar
seu veredito final.

2.3.3 Forma – os procedimentos/instrumentos de avaliação

Os instrumentos escolhidos para avaliação deverão adequar-se ao objetivo e ao
objeto de avaliação. Se bem escolhidos e elaborados, poderão auxiliar de modo significativo
na investigação, análise e regulação do processo para que a aprendizagem seja conseguida.
De acordo com Vasconcellos,

O como avaliar, a qualidade do instrumento também é importante, pois a
própria transformação da postura do professor pode ficar comprometida
se ele se prender a instrumentos/formas de avaliar tradicionais (estando
em processo de mudança, precisará de um bom instrumento que lhe
ajude a perceber como está indo seu intento) (VASCONCELLOS, 1998,
p. 124).

As escolhas quanto aos procedimentos/instrumentos de avaliação (como avaliar)
apresenta-se aqui como último passo na elaboração e organização das práticas avaliativas,
tendo em vista que definir os objetivos (intenções) e determinar o que se quer avaliar
(conteúdo) constituem-se tarefas primeiras em busca de uma avaliação preocupada em
subsidiar e informar acerca da aprendizagem e desenvolvimento dos alunos.

Cabe ressaltar que a mudança da avaliação com o enfoque para a aprendizagem
Matemática não tem como fator determinante as práticas. “A questão principal não é a
mudança de técnicas; passa por técnicas” (VASCONCELLOS, 1998, p. 41), portanto faz-
se necessário ater-se apenas a forma, mas na intencionalidade do instrumento investigado.

Muito se diz sobre o uso de portfólios, até mesmo virtuais, como instrumental de
avaliação pois com estes se apoiam em uma documentação e uma análise do processo de
aprendizagem de forma contínua em busca de uma avaliação formativa. No entanto, uma
prova escrita pode ser empregada de significados no avaliar que rompe com o seu uso
classificatório e pode ser usada como instrumento investigativo que leve a uma formação
do educando cheia de significados. O procedimento é que qualifica o instrumento, ou seja,
o uso transforma-o em uma avaliação para a aprendizagem.

A seguir serão apresentadas algumas sugestões de elaboração desse instrumento,
que podem ampliar e auxiliar o professor na sua ação como avaliador. A intenção não
é apresentar receitas prontas de procedimentos/instrumentos avaliativos, mas apresentar

2.4. Um Instrumento para a Aprendizagem

55

propostas para que o elaborador/professor as utilize ou adapte a sua prática, podendo
ainda servir como ponto de partida para o surgimento de outros nortes na construção de
uma avaliação educacional no nível de sala de aula, ou até mesmo de larga escala, como
a OBMEP.

2.4 Um Instrumento para a Aprendizagem

Antes de discorrer sobre os procedimentos/instrumentos apresentados como pro-
postas a serem utilizadas no processo de avaliação, faz-se necessário enfatizar que o tra-
balho pedagógico pensado para o ensino da Matemática deve ser organizado a partir
de situações-problema, pois estas são consideradas ferramenta metodológica capaz de
construir e mobilizar conhecimentos e ainda dar significado às atividades matemáticas
desenvolvidas em sala de aula.

Nessa perspectiva, os PCN apontam a “resolução de problemas como eixo orga-
nizador do processo de ensino-aprendizagem” e, ainda, que “essa opção traz implícita a
convicção de que o conhecimento matemático ganha significado quando os alunos têm si-
tuações desafiadoras para resolver e trabalham para desenvolver estratégias de resolução”
(BRASIL, 2000, p. 40).

Se as situações-problema são o basilar do ensino em Matemática, estas devem
ser utilizadas em qualquer instrumento avaliativo. Os procedimentos/instrumentos são as
ferramentas e/ou os meios utilizados para auxiliar o processo de avaliação da aprendizagem
Matemática. Portanto, faz-se necessário que se tenha certa diversidade de instrumentos
para que a cada momento seja possível lançar mão de ferramentas adequadas a fim de
contribuir com o sucesso da avaliação. Ao encontro disso, Correia corrobora:

As metodologias utilizadas para acompanhar o desenvolvimento do raci-
ocínio e aquisição de conhecimentos devem ser diversificadas e utilizadas
em todos os momentos do processo educativo. A variedade de instrumen-
tos fornecerá ao professor, ao aluno e aos pais um retrato mais próximo
do que está ocorrendo em termos de raciocínio e aprendizado matemá-
tico (CORREIA, 2010a, p. 36).

No tocante aos instrumentos, não será relatado a fundo os outros tipos além da
prova escrita e seu uso, mas de forma nenhuma quer se restringir ao uso apenas deste
ferramental. Pretende-se apenas dar uma visão mais ampla de seu uso e ressignificar esta
prática.

A prova torna-se um mecanismo equivocado quando é usada como único
procedimento de avaliação, assumindo função classificatória. Isso acon-
tece sempre que os resultados por ela fornecidos servem tão somente
para atribuição de nota, sem que o aluno tenha chance de aprender o que
ainda não aprendeu. Na perspectiva classificatória, a nota que resulta

56

Capítulo 2. Avaliação

da prova é mantida. Ao contrário, na perspectiva formativa, por meio
dela constata-se o que cada aluno aprendeu e o que ainda não aprendeu,
para que o trabalho pedagógico seja reorganizado e a aprendizagem seja
garantida (VILLAS-BOAS, 2014, p. 91).

O cuidado ao elaborar a prova poderá definir seu papel no processo de ensino-
aprendizagem. Ao ser elaborada, o professor deverá cuidar para que as questões que serão
respondidas pelos alunos possam, além do resultado final, lhe trazer outras informações.
Estas podem esclarecer acerca do raciocínio, do domínio de conceitos matemáticos, do
poder de interpretação e da leitura da linguagem matemática que o aluno detém.

Durante a elaboração de itens, pode-se escolher qualquer formato: múltipla es-
colha, certo ou errado, resposta fechada, resposta construída e/ou dissertativa, levando
estudantes a conhecer diversos formatos de testes, os quais irão se defrontar durante a
vida. Após sua realização, o professor facilitador apresenta o feedback para os alunos e
pode retomar a aprendizagem com diversas abordagens. Segundo Villas Boas, cabe ao
professor:

[...] usar a prova com criatividade. Por exemplo: após sua realização pe-
los alunos e a análise feita por ele, as provas são devolvidas para que,
por meio de orientação e de novos estudos, sejam revistas as respos-
tas que demonstram essa necessidade. O que importa não é nota, mas
aprendizagem (VILLAS-BOAS, 2014, p. 92).

A prova deverá explorar os conhecimentos matemáticos dos alunos durante e após
sua aplicação. Deverá levar os alunos a analisarem e discutirem seus procedimentos de
resolução, possibilitando que eles tomem consciência do andamento da sua aprendizagem
e busquem o auto-monitoramento.

Com esse intuito, além de avaliações realizadas em dupla e em grupo, há a proposta
de avaliação pelos pares, onde após apreciação pelo docente, os colegas trocam atividades
entre si, verificam as resoluções apresentadas fazendo um comparativo entre as respostas.
Após essa etapa, eles apresentam de forma escrita ou verbal o seu parecer, mostrando o
distanciamento entre as respostas dadas e as esperadas.

Esta avaliação por pares eleva a participação do estudante no processo de apren-
dizagem e faz com que este tome consciência do seu distanciamento da meta esperada,
colaborando também para a construção do auto-monitoramento.

O feedback advindo de um grupo de colegas pode ser mais bem-aceito do
que o individual. Esse tipo de avaliação permite a participação de alunos
e aumenta a comunicação entre eles e o professor, sobre sua aprendiza-
gem. Ao possibilitar aos alunos reconhecerem suas próprias necessidades,
comunicando-as ao professor, este tem o seu trabalho facilitado e um
tempo maior para auxiliar aqueles que precisam de sua atenção. (. . . ) o
professor pode dedicar-se a observar o desenvolvimento das atividades,

2.4. Um Instrumento para a Aprendizagem

57

refletir sobre elas e fornecer intervenções necessárias (VILLAS-BOAS,
2014, p. 49).

O registro escrito em questões discursivas ajuda muito na tarefa do professor em
formar juízo de valor, pois demonstra as fragilidades na resolução das situações propostas.
Estas fragilidades são entendidas como erros, assunto a ser abordado com mais detalhes no
Capítulo 6. No entanto, as questões de múltipla escolha, se bem elaboradas, também po-
dem demonstrar essas fragilidades. Nesse caso, a utilização de distratores plausíveis pode
fornecer feedback de grande valia para docente e discente. O conceito de plausibilidade
será explorado a seguir.

3 Instrumento Avaliativo e a Psicometria

59

3.1 Teoria de Resposta ao Item

Ao apresentar uma perspectiva de avaliação da aprendizagem matemática que
evoca práticas dinâmicas e significativas para o processo de ensino-aprendizagem ao longo
de todo do período escolar, emerge questionamentos acerca de como estreitar a distância
entre toda a teoria apresentada e a prática em sala de aula.

A terminologia Engenharia de Itens não é considerada ainda no meio científico,
por ser muito moderna, mas neste estudo este termo ajuda a demonstrar a importância
de se construir bons itens para ampliar o uso de avaliações escritas em avaliações forma-
tivas. Esta é a contribuição dos trabalhos de Rabelo em avaliações em larga escala. Os
conceitos apresentados são embasados no modelo da Teoria de Resposta ao Item (TRI) e
nos trabalhos desenvolvidos por Rabelo (RABELO, 2013).

Para justificar a construção dos itens é importante ressaltar o que vem a ser a
Teoria de Resposta ao Item: um conjunto de modelos matemáticos que tem por objetivo
mensurar certas habilidades ou características de uma pessoa – traços latentes – a partir
das respostas dadas por ela a um conjunto de itens previamente definidos. Nesse modelo,
analisa-se a probabilidade de ser dada uma determinada resposta em função de certas
características do item.

Assim, quanto maior a habilidade do respondente maior será a probabilidade de ele
fornecer a resposta correta. Tomando as respostas encontradas e a escala de proficiência,
determina-se a habilidade do mesmo. Esta mensuração de mão dupla é decorrente de
modelos matemáticos que relacionam as variáveis envolvidas nessa situação.

O modelo utilizado no ENEM, por exemplo, é o modelo logístico de 3 parâmetros,
que permite que seja estimado o traço latente do candidato a partir de uma relação que
fornece a probabilidade de um indivíduo acertar o item, levando em consideração:

1. a dificuldade do item,

2. a discriminação e a

3. probabilidade de acerto ao acaso.

Para se construir um item, de acordo com a TRI, é importante que se preconize
duas características importantes de um item: a unidimensionalidade e a independência
local.

60

Capítulo 3.

Instrumento Avaliativo e a Psicometria

A unidimensionalidade é a hipótese segundo a qual há apenas uma aptidão do-
minante responsável pelo desempenho em um conjunto de itens de um teste (RABELO,
2013). Já a hipótese de independência local assume que – para uma dada habilidade, as
respostas aos diferentes itens da prova são independentes (RABELO, 2013), ou seja, –
mantidas constantes as aptidões que afetam o teste, o desempenho de um indivíduo em
um item não interfere no seu desempenho em outro item (RABELO, 2013). Isso não quer
dizer que os itens não possam estar correlacionados, mas que cada indivíduo dá respostas
independentes para cada item do teste.

O acerto ao acaso, ou chute, ocorre principalmente com os itens nos quais indiví-
duos de baixa aptidão não conhecem a resposta correta, mas arriscam qualquer resposta, e
acabam por acertar o item. Nesse caso, quando se constrói um item deve-se considerar que
a resposta correta não deve ter características de atração do respondente, pois pode levar
pessoas que não detêm determinada habilidade a acertar um item, não demonstrando,
assim, as habilidades reais do aluno diante da situação proposta e nem contribuindo para
que o item seja discriminativo.

A discriminação é concebida como a capacidade do item de diferenciar indivíduos
com diferentes habilidades. Na TRI, é definida como o poder do item para diferenciar in-
divíduos com magnitudes próximas da habilidade que está sendo aferida. Já a proficiência
é a característica do respondente em acertar o item proposto, desde que ele mobilize as
habilidades esperadas na interpretação e na resolução do item.

A partir destes apontamentos, deve se considerar que para alcançarmos uma avali-
ação escrita que se encontre em um ambiente construtivista, é necessário que a construção
e a elaboração de itens seja bem planejada e metódica, exigindo a definição de passos de
construção com rigor e metodologia própria. Para esse fim, sugere-se o uso da Engenharia
de Construção de Itens, apresentada por Rabelo para a elaboração de avaliações de larga
escala, mas que pode e deve ser utilizada por docentes em suas avaliações no ambiente de
sala de aula.

3.2 Teoria Clássica dos Testes

Para que um teste avalie com amplitude pedagógica, é necessário que os itens,
presentes no mesmo, contemplem as habilidades e competências a serem avaliadas; revelem
os processos usados pelo educando para responder o teste e se tornem instrumentos de
feedback tanto para o professor elaborador quanto para que o aluno se automonitore.

O elaborador do item tem que se preocupar com os objetivos prévios e as ações que
poderá desenvolver com os resultados em mãos. Se essa função de elaborador for embasada
com uma análise do instrumento de avaliação, a metodologia de avaliação escrita poderá
propiciar uma avaliação formativa significativa.

3.2. Teoria Clássica dos Testes

61

Para respaldar o trabalho pedagógico, há pressupostos teóricos de análise quan-
titativa que podem ajudar na construção dos itens tanto na Teoria de Resposta ao Item
(TRI) quanto na Teoria Clássica dos Testes (TCT), ambas confirmam análises qualitati-
vas dos pressupostos utilizados para responder o item. Ambas as análises, qualitativas e
quantitativas, visam avaliar a validade, a fidedignidade e a objetividade dos testes. “"De
forma geral, ambas fornecem informações relevantes para tomada de decisão dos itens que
comporão o teste definitivo, bem como sugerir ajustes na formulação de itens (CONDé,
2008, p. 33).

A TRI complementa as limitações da TCT, mas é embasada nos primeiros da-
dos gerados nesta teoria. Antes dos dados serem calibrados na TRI, é necessário que se
determine porcentagens de acerto e o coeficiente bisserial do item, para evidenciar pro-
blemas iniciais do item em estudo. Assim, alguns elementos da TCT são importantes na
interpretação dos resultados de um teste e serão abordados aqui.

Como visto anteriormente, a Teoria de Resposta ao Item contribui com repre-
sentações quantitativas que norteiam o entendimento da análise qualitativa do item. De
forma menos específica, os procedimentos de análise da TCT também embasam estudos
qualitativos, mas em relação ao teste. Esta teoria tem em sua metodologia a comparação
do indivíduo ante o teste como um todo.

Segundo Fletcher (2010), a Teoria Clássica tem sua origem no modelo de escore
verdadeiro e de erro apresentado pelo psicólogo britânico Charles Spearman (1863-1945),
em 1904.

O modelo da TCT é embasado em dados empíricos coletados de um conjunto
de itens agrupados. O teste é construído por meio da seleção de uma amostra de itens
coletados de um universo que parece medir um dado construto. Essa maneira de construir
instrumentos psicométricos está fundamentada na ideia de que existe, para cada construto,
um conjunto indefinido de itens do qual uma amostra é extraída para construir o teste.
Na TCT, os parâmetros do item e da habilidade são dependentes da amostra e do teste.

A validade na TCT consiste na verificação da hipótese de que o teste é
capaz de predizer um critério externo, o qual é representado por com-
portamentos. Assim, a demonstração da validade é uma questão de le-
gitimação do instrumento em relação ao erro de estimação, ou seja, é
a verificação da magnitude do escore verdadeiro que é concebido como
representante legítimo do traço latente (RODRIGUES, 2006, p. 52).

Em uma prova de múltipla escolha, o desempenho medido consiste das respostas
corretas do examinado aos itens de prova, onde este mobiliza habilidade diante o conceito
solicitado – dado construto. A resposta certa pode ser representada pelo valor 1, e, para os
erros, pelo valor 0. A partir de cada item de prova, acumula-se um conjunto de respostas

62

Capítulo 3.

Instrumento Avaliativo e a Psicometria

na forma de uma sequência de uns e zeros, 001101011010..., o que corresponde ao vetor
de respostas 𝑥 = (𝑥1, 𝑥2, . . . , 𝑥𝐿), em que 𝐿 é o número total de itens na prova.

A partir desta representação vetorial, destaca-se o primeiro índice numérico a ser
apresentado pela TCT – o escore bruto. Fletcher aponta que o número total de acertos
na prova – escore bruto, pode ser estipulado como a regra numérica a ser aplicada no ato
da mensuração. Nos termos mais gerais, a escala de uma prova pode ser definida por uma
fórmula de escores 𝑋, conforme apresentado na Equação 3.1,

𝑋𝑖 =

𝐿
∑︁

𝑗=1

𝜔𝑗𝑥𝑖𝑗

(3.1)

onde 𝑥𝑖𝑗 = 1, quando o item 𝑗 for acertado pela pessoa 𝑖 e 𝑥𝑖𝑗 = 0, caso contrário. E
quando 𝜔 = 1, a fórmula proporciona o total de acertos, ou seja, o escore bruto obtido
pelo estudante. Quando o valor de 𝜔 permanece constante, com peso igualitário para
todos os itens, obtém-se o modelo linear da chamada Teoria Clássica de Testes.

Um parâmetro importante a ser analisado, utilizando-se a TCT, é a dificuldade
dos itens (𝐷) que compõem um teste. Esta pode ser definida como a porcentagem de
examinandos que respondem corretamente aos itens. Ou seja, a dificuldade de cada item
é determinada pela razão entre o número de pessoas que acertaram o item e o número
total de pessoas que o responderam.

Associando-se os índices gerados por essa análise às informações pedagógicas do
item, podem-se obter dados que sugerem dificuldades dos alunos, em termos das compe-
tências que deveriam ter construído ou das aprendizagens esperadas.

Há uma parametrização numérica em que 0 significa que nenhum estudante acertou
e 1 significa que todos os estudantes acertaram. Segundo Rabelo (RABELO, 2013, p. 133),
quanto maior é o índice de dificuldade mais fácil é o item. Na vertente pedagógica, quanto
mais próximo de 1 for o valor de dificuldade, maior será o domínio das competências e
habilidades verificadas no item.

Pode-se utilizar a seguinte sugestão para interpretação (CONDé, 2001):

∙ item fácil: 𝐷 > 0, 70;

∙ item de dificuldade média: 0, 30 < 𝐷 ≤ 0, 70;

∙ item difícil: 𝐷 ≤ 0, 30.

De forma geral, “para fins de avaliação de larga escala, os testes devem ser compos-
tos de itens que alcancem todo o continuum da escala, ou seja, devem ter uma amplitude
que inclua itens fáceis, medianos e difíceis” (RODRIGUES, 2006, p. 50).

Outro parâmetro importante é a discriminação dos itens 𝐼𝐷, que se refere ao poder
que um item possui para distinguir sujeitos com magnitudes de traços diferentes, do qual

3.2. Teoria Clássica dos Testes

63

o item constitui a representação comportamental, segundo Pasquali (1997). Quanto mais
próximas forem as magnitudes do traço que o item puder diferenciar, mais discriminativo
ele será. Estatisticamente, esse conceito, na TCT, representa a correlação dos escores dos
sujeitos no item com seus escores no teste total.

Para estabelecer este conceito, de acordo com Rabelo (2013), inicialmente deve-se

dividir a mostra pesquisada em três grupos:

1. grupo superior: os 27% de maior desempenho;

2. grupo inferior: os 27% de menor desempenho;

3. grupo intermediário: os 46% restantes.

O esperado em um bom teste é que no grupo superior haja uma proporção de
acertos maior que no grupo intermediário, que, por sua vez, apresente uma proporção
maior de acertos que o grupo inferior, em cada item.

É recomendável que 𝑃𝐼𝑁 𝐹 < 𝑃𝐼𝑁 𝑇 < 𝑃𝑆𝑈 𝑃 , em que:

∙ 𝑃𝑆𝑈 𝑃 é o percentual de acerto no grupo superior;

∙ 𝑃𝐼𝑁 𝑇 é o percentual de acerto no grupo intermediário;e

∙ 𝑃𝐼𝑁 𝐹 é o percentual de acerto no grupo inferior.

E quanto maior for a diferença entre 𝑃𝑆𝑈 𝑃 e 𝑃𝐼𝑁 𝐹 , maior será o potencial de dis-
criminação do item. Adota-se, então, como discriminação, o valor 𝐼𝐷, conforme a Equação
3.2.

𝐼𝐷 = 𝑃𝑆𝑈 𝑃 − 𝑃𝐼𝑁 𝐹

(3.2)

Os valores de 𝐼𝐷 recomendáveis são apresentados na Tabela 5.

Tabela 5 – Classificação dos itens de acordo com o poder de discriminação na TCT (RA-

BELO, 2013, p. 136), com adaptações.

Valores

Classificação

𝐼𝐷 ≥ 0, 4
0, 3 ≤ 𝐼𝐷 < 0, 4
0, 2 ≤ 𝐼𝐷 < 0, 3
𝐼𝐷 < 0, 2

Item bom
Item bom, mas sujeito a aprimoramento
Item marginal, sujeito a reelaboração
Item deficiente, que deve ser rejeitado

Há outras medidas da TCT semelhantes ao parâmetro de discriminação. “A prin-
cipal delas é coeficiente de correlação ponto-bisserial, que varia no intervalo de -1 a 1.

64

Capítulo 3.

Instrumento Avaliativo e a Psicometria

Valores próximos do zero ou negativos indicam que indivíduos com maior nota no teste
como um todo estão errando o item, o que não é aceitável” (RABELO, 2013, p. 139).

O Saeb utiliza a correlação bisserial 𝑐𝑏. Esta é uma medida de associação entre o

desempenho no item e o desempenho no teste. Sua fórmula é dada na Equação 3.3,

𝑐𝑏 =

(︂ 𝑀𝑃 − 𝑀
𝜎

)︂ (︃ 𝑝

)︃

ℎ(𝑝)

(3.3)

onde 𝑀𝑝 é a média no teste dos sujeitos que acertam o item, 𝑀 é a média total do teste,
𝜎 é o desvio-padrão do teste, 𝑝 é a proporção de sujeitos que acertam o item e ℎ(𝑝) é a
ordenada da curva normal no ponto de divisão dos segmentos que contêm as proporções
𝑝 dos casos.

Os coeficientes bisseriais 𝑟𝑏 podem também ser determinados para cada alternativa
do item, substituindo-se em 𝑐𝑏 o valor de 𝑝 pela proporção de marcações para cada opção
do item, fazendo-se uma adaptação no coeficiente ponto-bisserial. Os itens com correlações
inferiores a 0,3 são considerados de baixa discriminação, segundo Rabelo.

Por meio da TCT, os índices 𝑝 e 𝑟 orientam a tarefa de desenvolvimento
do teste definitivo. O 𝑟𝑏 calculado por alternativa de itens de múltipla
escolha fornece informações preciosas, pois permite indicar um possí-
vel distrator (alternativa incorreta) atrativo para os estudantes que se
desempenharam bem no teste, o que não é esperado de um item discri-
minativo. Esses itens podem ser descartados ou mesmo sofrerem algum
ajuste pontual, com base nas informações estatísticas, de forma a serem
aproveitados no teste final (CONDé, 2008, p. 33).

3.3 Análise Gráfica dos Itens

Segundo Rodrigues (2006), esta abordagem técnica foi desenvolvida por T. A. van
Batenburg e J. A.Laros e é embasada no pressuposto de que os elabores de itens devem
dominar os conceitos da ciência avaliada e seus objetivos. Estes precisam de habilidades
específicas para construir um bom item de múltipla escolha.

Para que um item de múltipla escolha seja considerado bom é necessário que este
tenha indiscutivelmente um única resposta correta. As alternativas devem ser carregadas
de intenção na sua construção e claras no que se propõe. É importante não somente avaliar
o conteúdo, mas também a dimensão de compreensão.

Os dois pressupostos válidos para essa análise são:

(a) um aluno que dá uma resposta certa em um item de múltipla escolha possui habi-

lidades que o aluno que dá a resposta errada não alcançou ainda; e

(b) um aluno que tem mais itens certos possui uma gama de conhecimentos maiores

que um aluno que acertou menos.

3.3. Análise Gráfica dos Itens

65

Isso implica que aqueles que acertam todos os itens (o escore máximo)
têm probabilidade 1 de terem marcado a alternativa correta; e aqueles
que têm todos os itens errados, têm probabilidade 0 de terem marcado
a alternativa correta. Acredita-se, também, que as alternativas falsas
decresçam com o aumento do escore total. Até um certo escore, pode-
se esperar que as alternativas certas e as falsas fiquem nos valores da
chance de acerto ao acaso (0,25, neste caso). Depois deste escore total
específico, a proporção de marcação da alternativa correta aumenta, e a
proporção de marcação das alternativas falsas decresce (RODRIGUES,
2006, p. 52).

A Análise Gráfica dos Itens (AGI) dispõe de recursos visuais, em que é apresentada
a relação entre o escore total e as porcentagens de respostas às alternativas verdadeiras
e falsas dos itens. Essa análise permitiu identificar: bons itens; itens extremamente di-
fíceis; itens que apresentam uma ou mais alternativas falsas e mantêm um aumento da
porcentagem de respostas com o aumento do escore total (problema de discriminação);
e itens cujas alternativas verdadeiras apresentam um decréscimo na porcentagem de res-
postas em relação ao aumento do escore total (itens ruins). O principal pressuposto dessa
análise, segundo Van Batenburg e Laros (RODRIGUES, 2006, p. 68), é: “a proporção
da alternativa correta deve aumentar com um aumento do escore total, e a proporção de
alternativas falsas deve decrescer com um aumento do escore total”.

Se a proporção de respostas para a alternativa correta aumenta rapidamente com

o escore total, o item terá um alto poder discriminativo; caso contrário, será baixo.

Na Figuras 1 e 2 são apresentados exemplos de gráficos para a análise de itens.

Figura 1 – AGI de item bom e de item ruim, respectivamente (RODRIGUES, 2006, p.

52)

.

Tendo por base o escore total, esta análise demonstra uma tendência dos alunos
ao responderem o item. Segundo Rodrigues, quando a análise revela uma dispersão nas
respostas às alternativas, não significa que um item tem um problema de elaboração,
mas pode indicar uma falta coletiva de habilidades diante a objetivo de aprendizagem
verificado. “Assim, é importante que, em conjunto com a AGI, seja realizada uma análise
pedagógica desses itens. Essas análises poderão dar indicativos do processo mental utili-

66

Capítulo 3.

Instrumento Avaliativo e a Psicometria

Figura 2 – AGI de item com discriminação ruim e de item difícil, respectivamente (RO-

DRIGUES, 2006, p. 52)

.

zado para a solução da questão, associando-se o escore total e as respostas dos distratores”
(RODRIGUES, 2006, p. 69).

A Teoria Clássica dos Testes apresenta algumas limitações como modelo estatístico:
não permite comparar indivíduos que tenham respondido a testes distintos e não permite
fazer o acompanhamento de um mesmo sujeito durante as várias etapas do processo de
construção do conhecimento. Isso decorre do fato de que, na TCT, os resultados obtidos
dependem do conjunto de itens selecionados para a construção da referida prova, tornando
o resultado encontrado um caso particular.

No entanto, ela pode respaldar, de acordo com o instrumento escolhido e da amos-
tra, inferências com relação ao estudo dos erros cometidos pelos estudantes que estão
sendo investigados.

3.4 Ambiente construtivista

Quando se aborda o ensino de Matemática por situações-problema, torna-se pri-
mordial que se faça uso de situações mobilizadoras de competências durante a realização
de testes e provas. Além de ter um traço desafiador, as questões ou itens da prova de-
vem trazer características que contribuam para uma avaliação formativa. Devem carregar
em si informações que contribuam para a clareza e o entendimento de situações fora do
contexto escolar.

O estudante, ao se deparar com o teste, deve ter conhecimento técnico do conteúdo
estudado e o professor deve fornecer um instrumento que seja conciso com seus objetivos
de aprendizagem e que não contribua para o acerto ao acaso. Ao final do teste deve haver
uma relação mais próxima possível da realidade do grupo escolar. O aluno que sabe aquilo
que é avaliado no item deveria acertá-lo.

Como elaborar questões que permitam avaliar o desenvolvimento de certa habi-
lidade, necessária para o desenvolvimento de uma competência específica, por meio dos

3.4. Ambiente construtivista

67

conhecimentos estudados em sala de aula? Há muitas dúvidas não somente em relação a
“como” avaliar mas também a o “que” avaliar.

Para responder o que se deve avaliar é necessário que o docente tenha clareza dos
objetivos de aprendizagem que se deseja alcançar naquele momento específico, e, para
contribuir de forma mais efetiva com a intenção ao avaliar, pode-se elaborar uma matriz
de referência, como as que são utilizadas nos grandes certames: ENEM, Saeb, Prova Brasil.
Assim, o docente conseguirá focar na intencionalidade do instrumento avaliativo.

A partir dos PCN e das Diretrizes Curriculares Nacionais (DCN) para o ensino
médio houve debates que levaram a um modelo de criação de itens para os mais diversos
instrumentos de avaliação, e a prova escrita foi a que mais ganhou com essa nova abor-
dagem. Essa abordagem lança mão da contextualização e da interdisciplinaridade para a
elaboração de questões ou itens.

Os itens convencionais, diretos e marcados apenas pela verificação de aprendizagem
de conteúdos, foram perdendo seu espaço para os itens contextualizados. De acordo com
Rabelo, os itens convencionais refletem “uma cobrança estritamente voltada à capacidade
de se utilizar o conhecimento aprendido na reprodução de procedimentos rotineiros ou na
identificação ou reconhecimento de dados e informações” (RABELO, 2013).

Mas não se pode confundir contextualização com textualização: esta última é mar-
cada apenas pela apresentação de textos conjuntamente com a questão, que em nada
contribuem para a sua realização. Apesar de deixarem o teste mais interessante, trazendo
curiosidades e até mesmo gerando descontração durante a realização da prova, estes textos
não desafiam nem mobilizam habilidades necessárias a resolução da situação apresentada
no comando do item. A Figura 3 ilustra um item convencional.

Figura 3 – Exemplo de item convencional

A contextualização vai na contramão da textualização, pois caracteriza-se pela
consulta ao texto apresentado para melhor entendimento da situação-problema, pela mo-
bilização de habilidades necessárias para resolvê-la e ainda pela oferta de dados primordiais
para o processo de resolução.

A contextualização, além de cumprir o papel de possibilitar a descrição de uma

68

Capítulo 3.

Instrumento Avaliativo e a Psicometria

situação-problema a ser resolvida, de modo a propiciar que a competência ou a habi-
lidade a ser avaliada se expresse, tem o papel de motivar o estudante para resolver a
atividade proposta, além de favorecer o processo de criação de itens inéditos e de testes
interdisciplinares (RABELO, 2013, p. 179).

O contexto escolhido também determina a facilidade em se resolver o
item. Para Rabelo, se o contexto for próximo ao cotidiano dos alunos,
a contextualização se torna mais motivadora e de mais fácil entendi-
mento para estes, mas os contextos “abstratos ou técnico-científicos, que
demandam raciocínios mentais elaborados, costumam apresentar níveis
de complexidade de julgamentos mais sofisticados” (RABELO, 2013, p.
179).

O uso de situações-problema contextualizadas denota um ambiente construtivista
de aprendizagem, e o ineditismo dos itens apresentados também fortalece esse conceito. O
estudante, ao enfrentar situações propostas em itens inéditos, mobiliza conhecimentos e
habilidades e os aplica para confirmar competências almejadas nos objetivos. O ineditismo
não é aplicado aos itens apenas para estabelecer o equilíbrio entre os concorrentes, mas
também para que o estudante tenha a possibilidade de evidenciar o desenvolvimento de
competências e poder manifestá-las.

Depresbiteris e Tavares, apud Rabelo, sugerem que

os ambientes construtivistas são fundamentais para o ensino e a apren-
dizagem, principalmente quando fornecem situações-problema desenca-
deadoras de um processo de pensar fomentador da dúvida, do levan-
tamento, do comprovação de hipóteses, do pensamento inferencial, do
pensamento divergente, entre outros(RABELO, 2013).

4 Engenharia de Itens

69

é preciso ter em mente que o item é a base a partir da qual serão cons-
truídos os indicadores de qualidade que fornecerão insumos para formu-
lar ações educacionais, promover a melhoria dos processos de ensino-
aprendizagem e subsidiar tomadas de decisão dos gestores em todos os
níveis Se os itens não forem cuidadosamente construídos, os indicadores
não serão válidos nem fidedignos e toda a análise feita a partir desses
índices ficará comprometida (RABELO, 2013, p. 216).

4.1 Conceitos básicos de elaboração de itens

Com base nos cuidados em construir uma avaliação que revele níveis de aprendi-
zado, é necessário que se apresente os conceitos iniciais. Como este estudo é embasado
na Teoria de Resposta ao Item, o termo “questão” de prova não é utilizado, mas, sim,
o termo item de prova. Esta é apenas uma questão de terminologia, pois os itens são as
questões que o professores apresentam em suas listas de exercícios ou testes. É necessário
fazer essa diferenciação para que não se confunda com itens de julgamento, aqueles onde
se julgam a veracidade ou não da informação.

De acordo com Rabelo (2013), um item de prova

é uma situação criada para que o indivíduo dê uma resposta ou um
conjunto de respostas a um estímulo apresentado, constituindo-se em
uma amostra de desempenho em relação a um objeto específico previsto
em uma matriz de referência,

e uma prova “é uma situação na qual se solicita a alguém que demonstre certo aspecto
de seus conhecimentos ou de suas capacidades, com o objetivo de avaliar determinadas
características previamente estabelecidas”.

Uma avaliação escrita pode ser construída a partir de um item ou vários. É comum
em um teste dissertativo, por exemplo, o elaborador apresentar um item apenas a ser res-
pondido. Mas podem ser empregados vários itens em uma prova e estes podem apresentar
vários formatos. Na próxima seção são apresentados alguns exemplos que se baseiam na
forma com que o avaliado expressa sua resposta.

4.2 Formatos comuns de itens

Múltipla escolha: são itens nos quais o candidato ou estudante escolhe uma única res-
posta entre várias apresentadas, denominada chave de resposta ou gabarito, a qual

70

Capítulo 4. Engenharia de Itens

precisa ser inequivocamente certa, enquanto as demais devem ser incorretas e plau-
síveis. É o modelo adotado na primeira fase da OBMEP.

Certo ou Errado: são marcados pelo julgamento do respondente. Devem ser bem claros
e sua resposta é binária, respeitando o Principio do Terceiro Excluído, não havendo
uma outra opção além de certo ou errado. Na construção de testes com estes itens,
deve-se tomar cuidado para que não haja padrão no gabarito, pois se o estudante ve-
rifica que há uma padronização, ele obterá um resultado que não refletirá o objetivo
da avaliação.

Resposta fechada: é caracterizado por ter uma resposta correta que deve ser elaborada
pelo aluno, na qual ele pode completar uma ideia com uma única resposta possível.
Pode ser utilizado um padrão de gabarito que possibilite essa resposta, mas não são
apresentadas as opções de resposta. Como exemplo, há itens que exigem um cálculo
e a resposta é colocada em um gabarito que possibilita a marcação utilizando o
sistema posicional.

Dissertativo ou redação: utilizando textos, figuras ou tabelas como motivação. O ela-
borador leva o estudante a discorrer sobre determinado tema de forma textual. O
elaborador pode propor tópicos a serem apresentados ou não e o avaliador, também
apoiado em uma matriz de referência, busca evidências do domínio do assunto tra-
tado, além de avaliar o uso formal da língua e a formalização das ideias. A Figura
4 traz um exemplo de item discursivo.

Figura 4 – Exemplo de item discursivo

Resposta curta aberta ou de resposta construída: estes itens se diferenciam do an-
terior, por possuírem mais de uma resposta possível, mas ambas corretas. Estes itens
são avaliados por uma banca de corretores, que verificam se as respostas estão de
acordo com a proposta do elaborador, mesmo que elas sigam passos distintos de

4.2. Formatos comuns de itens

71

resolução. É montada uma matriz de correção apresentando as respostas possíveis
e requisitos a serem cumpridos. A Figura 5 exemplifica um item deste tipo.

Figura 5 – Exemplo de item de resposta curta aberta – 2a Fase da OBMEP

Em todos os formatos, o candidato/estudante deve ser informado previamente das
regras de apresentação dos itens e o que se espera dele diante de cada um. É importante
a verificação do tempo necessário para responder cada item. Se o itens forem dos tipos:
múltipla escolha, certo ou errado ou resposta fechada, o professor deve considerar que

72

Capítulo 4. Engenharia de Itens

um aluno com proficiência mediana leva em torno de 3 a 4 minutos para respondê-los,
enquanto os outros tipos podem ser mais demorados. Então, ao construir a matriz de
referência para os corretores, o elaborador pode redimensionar a questão para o tempo
disponível para sua resolução.

É importante também para uma avaliação formativa que se saiba o que vem a
ser a mobilização de habilidades para se articular competências, pois é um tema tratado
pela abordagem construtivista da aprendizagem e também pela Engenharia de Itens. A
contextualização e o ineditismo de itens se apoiam nesses conceitos.

4.3 Habilidade e Competência

Como o auto-monitoramento é um dos objetivos almejados pela avaliação forma-
tiva, quando os conceitos de competências e habilidades foram introduzidos, era enfati-
zado que o aluno aprendesse a aprender. Assim, no princípio, esses conceitos transmitiam
a ideia de que o conteúdo apresentado pelo professor fosse deixado de lado para que o
aluno fosse motivado a construir seu próprio aprendizado.

É um erro pensar que o professor não pode ensinar conceitos: ele deve sim apresentá-
los e discuti-los com seus alunos, incorporando a isso atividades que incentivem a mobili-
zação de recursos (habilidades, conhecimentos, atitudes, processos mentais, entre outros)
para o saber fazer. Rabelo apresenta a distinção entre habilidades e competências, apre-
sentada no Enem, e acrescenta que “o estudo intenso de conteúdos” se faz necessário para
articulação entre esses conceitos.

Competências são modalidades estruturais da inteligência, isto é, ações
e operações que utilizamos para estabelecer relações com e entre obje-
tos, situações, fenômenos e pessoas que desejamos conhecer, enquanto
habilidade são especificações das competências estruturais em contex-
tos específicos, decorrem da competências adquiridas e referem-se ao
plano imediato do saber fazer. Por meio das ações e operações, as habi-
lidades aperfeiçoam-se e articulam-se, possibilitando nova reorganização
das competências (RABELO, 2013, p. 187).

Perrenoud (2002 apud RABELO, 2013, p. 188) define que

competência é a capacidade do sujeito de selecionar, organizar, mobilizar
e utilizar, intencionalmente, recursos (conhecimentos, saberes, habilida-
des, esquemas mentais, afetos, crenças, princípios, posturas, comporta-
mentos e outros processos psicológicos ou comportamentais) e em ação
para o enfrentamento de uma situação problema especifica, não apenas
na dimensão técnico-especializada, mas também na dimensão sociopolí-
tica, comunicacional e de inter-relações pessoais.

Assim, durante a construção de um item, deve-se levar em consideração a mobiliza-
ção e articulação entre os diversos recursos para que se propicie uma avaliação significativa,

4.4. Estrutura básica de um item de múltipla escolha

73

de forma que o estudante verifique o quão distante ele está do que o professor espera dele
ao realizar as avaliações escritas. É importante frisar que o docente pode se apoiar na sua
matriz de referência de competências para elaboração de cada item e até mesmo para a
elaboração dos distratores de cada item, conceito apresentado na Seção 4.7.

4.4 Estrutura básica de um item de múltipla escolha

A estrutura dos itens de múltipla escolha é dividida em texto-base, enunciado ou
comando e as alternativas, onde estas partes se articulam com coerência e coesão, para
que as informações apresentadas levem o aluno a mobilizar os diversos recursos necessários
para responder o item.

A Figura 6 apresenta visualmente a estrutura básica de um item.

Figura 6 – Estrutura Básica do Item (adaptado de (RABELO, 2013))

4.5 O Texto-Base

Segundo Rabelo (2013, pg. 190), no processo de elaboração, primeiro deve-se es-
crever o texto-base, que também pode ser buscado em fontes externas, depois o comando
e, por fim, as alternativas. Antes de serem formulados, os itens devem ser enquadrados na

74

Capítulo 4. Engenharia de Itens

matriz de referência, contemplando a perspectiva de avaliação de uma habilidade e(ou)
competência com mais ênfase.

O texto-base deve servir de contextualização, ou seja, as informações apresentadas
devem ser relevantes para o respondente. Um bom teste para a relevância do texto é
verificar se, ao ser excluído, o aluno tem informações suficientes para encontrar a resposta
correta.

Os textos-base devem ser curtos, integrais e adequados à linguagem e ao nível dos
respondentes. Quando utilizados textos que não são de autoria do elaborador, é importante
buscar em fontes com reconhecimento científico, não sendo conveniente utilizar fontes
duvidosas ou incompletas em seus conceitos. O texto original pode ser alterado, mas
qualquer mudança no texto deve ser referenciada (RABELO, 2013).

Ainda sobre o texto-base, deve haver clareza nos fatos apresentados tanto no uso
correto da Língua Portuguesa, quanto nos conceitos científicos utilizados. Este deve ori-
entar o respondente a acessar os seus conhecimento prévios e construir novas perspectivas
quanto aos conceitos apresentados. Assim, quando houver controvérsias de base cientificas,
será preciso citar no texto-base a interpretação que deverá ser utilizada.

É bom conceituar e exemplificar no texto-base (dependendo da intencionalidade
do item, é claro), pois uso de exemplos e conceituação tendem a tornar o item mais
fácil. Se feito desta forma, deve-se observar que o conceito apresentado deve estar correto
cientificamente e não levar o respondente a aplicá-lo apenas na resolução do item em
questão.

A Figura 7 apresenta um item com exemplificação no texto-base.

Figura 7 – Item com exemplificação no texto-base

É bom que não se criem nomes fictícios ou jocosos, ou nomes que se refiram
a pessoas públicas. Para todos os modelos citados, observar o teor político, utilização
de marcas de produtos, nomes e imagens, pois podem ser utilizados para influenciar os
respondentes.

4.6. O Comando

4.6 O Comando

75

O comando pode ser dado como uma afirmação incompleta, a ser continuada por
uma das opções, onde o estudante deve encontrar, entre as opções oferecidas, aquela que
se ajusta corretamente ao comando que deve ser completado. São chamados de itens de
múltipla escolha de complementação simples. A Figura 8 exemplifica um item deste tipo.

Figura 8 – Exemplo de item de múltipla escolha de complementação simples.

Para estes deve-se atentar que o enunciado é redigido de forma que as alternativas o
complemente, assim todas as alternativas são trechos que completam a frase interrompida
no enunciado. Desse modo, as alternativas devem ser iniciadas com letras minúsculas e
terminam com ponto final, e devem obedecer a um paralelismo sintático entre si.

O comando também pode ser formulado por uma pergunta direta, em que se
apresenta um único e completo problema e cada opção de resposta é uma possível solução.
São chamados de itens de múltipla escolha de resposta única, e a diferença em relação ao
anterior diz respeito à redação das alternativas: estas serão redigidas de forma a responder
a pergunta do enunciado, de modo que iniciarão por letra maiúscula. A Figura 9 traz um
item de pergunta direta.

Figura 9 – Exemplo de item de pergunta direta.

76

Capítulo 4. Engenharia de Itens

Para os itens de múltipla escolha de interpretação, estes podem ser com enunciado
incompleto ou com pergunta, e a escolha deve priorizar a clareza do enunciado. Estes itens
são formulados a partir de uma situação-estímulo que compõe o enunciado e o respondente
organiza as ideias para solucionar o problema proposto. Este é o modelo utilizado no
ENEM. A situação-estímulo pode ser utilizada para mais de um item, desde que estes
sejam independentes. Em geral, é formado um banco de textos base para a situação-
estímulo, que são incorporados ao enunciado e as ideias que aparecem nas alternativas.
Deve-se atentar para que não existam itens excludentes. A Figura 10 é um exemplo de
item de múltipla escolha de interpretação.

Figura 10 – Exemplo de item de múltipla escolha de interpretação.

Nos itens de interpretação, evite utilizar as expressões “assinale a opção correta”

4.7. As alternativas

77

ou “é correto afirma que”, pois levam a cinco problema diferentes a serem julgados, não
deixam claro o desafio proposto, e podem extrapolar a habilidade a ser verificada.

É preciso também salientar que tudo que está escrito em cada afirmação é passível
de julgamento, salvo se explicitado como hipótese. Muitas vezes, o elaborador relata na
afirmação uma situação, mas não insere afirmações do tipo “Suponha que” ou “considere
que”, antes da descrição do problema. Trata-se de uma sutileza, mas que é fundamental
para a clareza do item e melhor compreensão por parte do estudante.

4.7 As alternativas

Cabe enfatizar que as informações para resolução não devem ser encadeadas nas
alternativas do item, pois as informações necessárias à resolução devem estar no texto-base
ou no comando. E ainda é importante salientar que não deve ser colocada a alternativa
correta com extensão ou formato diferente das demais para não haver atração, por causa
da diferenciação. Se as alternativas possuírem tamanhos diferenciados elas devem ser
organizadas de forma trapezoidal.

Além disso, se as alternativas forem numéricas, estas devem ser organizadas de
forma crescente ou decrescente, e não devem apresentar ponto final quando não houver
texto na sua composição e/ou estas não completarem um texto.

Fugir ao uso de expressões do tipo “nenhuma das anteriores” ou “todas as res-
postas anteriores” e, além destas expressões, alguns termos devem ser evitados, pois sua
generalidade já descarta a alternativa analisada. Abaixo segue uma relação de termos a
serem evitados:

somente, apenas, nunca, exclusivamente, unicamente, sempre, totalmente,
todo, jamais, raramente, exclusivamente, pode ser, tudo, ninguém, ne-
nhum, nada, algum, pode acontecer, pode haver, pouco, as vezes, qual-
quer, entre outros... (RABELO, 2013, p. 195).

As opções erradas, denominadas distratores, devem ser cuidadosamente construí-
das e analisadas, fazer parte do contexto do item e ser uma resposta possível para que o
aluno que não sabe o conteúdo ou que não desenvolveu a competência que está sendo ava-
liada. Deve-se construir distratores plausíveis que tenham a aparência de resposta correta,
mas que sejam inquestionavelmente incorretas. Se o contrário acontecer, o item possui er-
ros, ou seja, o item não discrimina, e deverá ser reformulado ou até mesmo retirado da
avaliação.

O distrator não deve ser um “peguinha”, ou seja, atrair a resposta de quem sabe
o conteúdo e que por um descuido fez essa escolha: deve ser a resposta possível para
um caminho errado de interpretação ou uso de conceitos errôneos. Aqui os distratores se

78

Capítulo 4. Engenharia de Itens

apoiam no conceito de discriminação do item, ou seja, alunos com proficiência igual ao
superior exigida pelo item devem acertá-lo e alunos com proficiência inferior ao item devem
errá-lo. “É desejável que cada distrator esteja vinculado a um nível de desenvolvimento
adequado da aprendizagem e ensejar um possível raciocínio que um respondente de baixo
desempenho faria para escolhê-lo como resposta”(RABELO, 2013, p. 191).

Um item elaborado com essa critério permitiria que fosse identificado, na fase de
análise de desempenho, os erros mais comuns nos diversos níveis de proficiência dos estu-
dantes e, assim, fornecer indícios sobre o processo resolução escolhido pelos respondentes.
A partir deste princípio, a prova de primeira fase da OBMEP em estudo será analisada
no Capítulo 8.3.

Quando planejamos e realizamos uma atividade de avaliação (sejam
quais forem sua natureza e características), temos de estar conscientes
de que os alunos também estão atribuindo-lhe um sentido, de que esse
sentido depende, em grande parte, de como a atividade é apresentada e
de como atuamos em seu desenvolvimento e de que, enfim, os resulta-
dos de avaliação dependerão tanto dos significados que eles construíram
e que sejamos capazes de suscitar, como no sentido que atribuíram às
atividades previas de ensino e aprendizagem e à própria atividade de
avaliação (RABELO, 2013, p. 196).

Com relação ao gabarito final, construa a chave de respostas de tal forma que as
combinações não forneçam pistas quanto a opção correta, ou seja, faça o balanceamento
da quantidade de vezes que o número de cada afirmação aparece nas alternativas corretas.

4.8 O Correto Uso da Língua Portuguesa na Avaliação para a

Aprendizagem

No momento de elaboração do item, deve-se atentar ao bom uso da Língua Por-

tuguesa. Na elaboração do texto do item:

∙ utilizar a ordem direta;

∙ adequar a simplicidade dos vocábulos;

∙ atentar à correção da linguagem, clareza, precisão, impessoalidade;

∙ evitar o uso de adjetivos ou advérbios, pois estes destacam ideias subjetivas; e

∙ não usar a primeira pessoa do plural, pois não se pode incluir o elaborador no grupo

de respondentes.

Para itens de múltipla escolha do tipo resposta múltipla, que consistem de 3 a 5
afirmações relacionadas com o enunciado, que devem ser avaliadas como verdadeiras ou

4.8. O Correto Uso da Língua Portuguesa na Avaliação para a Aprendizagem

79

falsas, deve-se, especialmente, levar em consideração que os julgamentos das afirmações
devem ter o mesmo nível de complexidade. Durante a análise, os números nas alterna-
tivas devem aparecer balanceadamente e na ordem crescente e os itens excludentes não
devem aparecer na mesma alternativa de resposta. Além disso, para o item de resposta
múltipla, em suas alternativas, não se deve combinar informações excludentes. A Figura
11 exemplifica um item deste tipo.

Figura 11 – Item de múltipla escolha de resposta múltipla

Após serem elaborados, um olhar externo é fundamental, para que haja uma cor-
reção quanto a clareza dos itens e a correspondência com a intenção dos aplicadores, pois
itens aparentemente perfeitos podem apresentar nuances que levem os respondentes a
tomarem posturas que não correspondam à intenção do elaborador.

80

Capítulo 4. Engenharia de Itens

É de grande relevância, também, a pré-testagem do item: o professor, ao apli-
car um item em determinado grupo, pode fazer alterações nos próximos testes. Pode-se
caracterizar esta atitude como uma ação da avaliação formativa para o professor avalia-
dor/elaborador.

Os tipos de item de asserção-razão, abertos e os dissertativos são itens que reque-
rem processos cognitivos mais elaborados, pois requerem julgamento de casualidade entre
fatos.

Quanto aos tipos de itens abertos e os dissertativos , além das diretrizes apresen-
tadas acrescenta-se que para o enunciado/comando deve se incluir todas as informações
necessárias para a resolução do item e que serão objeto de avaliação: textos motivadores,
informações técnicas especificas, tabelas, figura e fórmulas que sejam necessárias para a
resolução da proposta apresentadas. Não é recomendável o emprego de perguntas do tipo
“Que”, “Quem”, “Quando”, “Onde”, pois, possivelmente, não avaliam a mobilização de
habilidades complexas para a construção da resposta.

Se possível subdividir em subitens, objetivando clareza e contribuindo para uma
correção mais pontual. O avaliador deve redigir um padrão de resposta desejável se colo-
cando no papel do avaliado, evidenciando partes essenciais que devem ser usadas processo;
fazer previsão das diferentes respostas corretas e validas e estabelecer o critério de pon-
tos (quesitos da avaliação) – considerando a indicação do valor atribuído a cada item
contemplado.

O formato de um item deverá ser norteado pela intenção da avaliação: se o proce-
dimento de resolução não nos interessa é melhor escolher as questões de múltipla escolha,
caso contrário de itens abertos e os dissertativos podem esclarecer para o elaborador os
caminhos corretos utilizados e, mais que isso, os obstáculos enfrentados pelos alunos.

Cada instrumento de avaliação deve ser escolhido de acordo com a intencionalidade
do elaborador. No que tange à dificuldade dos itens, deve-se adequar os itens de forma
que se obtenha 30% de itens fáceis, 40% de itens medianos e 30% de itens difíceis em
uma prova de seleção, mas em uma avaliação de aprendizagem sugere-se que sejam 30%
de itens fáceis, 50% de itens medianos e 20% de itens difíceis.

Ao finalizar a construção de um item é bom fazer uso de uma série de questiona-
mentos que verificam rapidamente alguns dos pontos apresentados no texto de Engenharia
de Itens por Rabelo. Estes se apresentam na Tabela 6.

4.8. O Correto Uso da Língua Portuguesa na Avaliação para a Aprendizagem

81

Tabela 6 – Questionamentos de verificação de itens (RABELO, 2013, p. 217)

# Questionamento

1 A redação do contexto é adequada? O item de fato é contextualizado?
2 O tamanho do contexto é adequado ao tempo disponível para resolução?
3 Os dados têm razoabilidade e são todos necessários para a resolução?
4 Qual a competência ou habilidade que se deseja avaliar no item?
5 O enunciado está redigido sem o uso de termos que indicam negação?
6 O enunciado apresenta claramente um único problema a ser solucionado?
7 O enunciado apresenta falha técnica que pode induzir ao erro?
8 As opções/alternativas completam adequadamente o comando?
9 As opções/alternativa apresentam estrutura semelhante? São indepen-

dentes?

10 Há exatamente uma opção inequivocamente correta?
11 Os distratores são plausíveis?
12 Os distratores são claros, sem indução ao erro?
13 O item é isento de erros conceituais?
14 O item é isento de informações preconceituosas e controversas?
15 O item está redigido respeitando a norma padrão da língua portuguesa?

5 Análise de Conteúdo

83

Um conjunto de técnicas de análise de comunicação visando a obter,
por procedimentos sistemáticos e objetivos de descrição do conteúdo
das mensagens, indicadores. A intenção da Análise de Conteúdo é a in-
ferência de conhecimentos relativos às condições de produção (ou, even-
tualmente, de recepção), inferência esta que recorre a indicadores (quan-
titativos ou não) (BARDIN, 2011, p. 44).

5.1 A Análise de Conteúdo

Como se pode perceber pela definição apresentada, a Análise de Conteúdo oscila
entre os dois contrapontos que envolvem a investigação científica: o rigor da objetivi-
dade e a fecundidade da subjetividade. Esta abordagem gera elaboração de indicadores
quantitativos e(ou) qualitativos que devem levar o pesquisador a uma segunda leitura da
comunicação, baseando-se na dedução, na inferência. Visa revelar o que está escondido,
latente, ou subentendido na mensagem, mas com a presença de processos técnicos de
validação.

As análises quantitativas preocupam-se com a frequência com que surgem deter-
minados elementos nos instrumentos de pesquisa, preocupando-se com mensuração dos
dados apresentados. Por outro lado, os enfoques qualitativos voltam sua atenção para a
presença ou ausência de uma característica, ou conjunto de características, nas mensagens
analisadas, na busca de ultrapassar o alcance meramente descritivo das técnicas quantita-
tivas para atingir interpretações mais profundas com base na inferência (BARDIN, 2011).

A Análise de Conteúdo visa, portanto, “ultrapassar o nível do senso co-
mum e do subjetivismo na interpretação e alcançar uma vigilância crítica
em relação à comunicação de documentos, textos literários, biografias,
entrevistas ou observação” (MINAYO, 2000).

Em relação à Análise de Conteúdo, de acordo com Cury (2003, p. 7), entre “as
obras que apresentam elementos para entender esse método, a de Bardin foi sem dúvida a
que melhor o configurou em detalhes, especificando os conceitos, os princípios e a técnica
propriamente dita”.

Bardin (2011) caracteriza a Análise de Conteúdo como sendo empírica e, por esse
motivo, não pode ser desenvolvida com base em um modelo exato. Contudo, para sua
operacionalização, devem ser seguidas algumas regras de base, por meio das quais se
parte de uma leitura flutuante para atingir um nível mais aprofundado – a inferência
apoiada em dados organizados.

84

Capítulo 5. Análise de Conteúdo

Para Bardin (2011), não se trata de atravessar os significantes para atingir signifi-
cados, como se faz na leitura normal, mas de, por meio dos significantes e dos significados
(manipulados), buscar-se diferentes significados de natureza psicológica, sociológica, polí-
tica, histórica, educacional, entre outros. Muito empregada nas Ciências Sociais, a Análise
de Conteúdo vislumbra sua aplicação na Análise de Erros, ou seja, contempla os estudos
da Educação Matemática, fundamentando suas produções.

O processo de explicitação, sistematização e expressão do conteúdo de mensagens,
promovido pela Análise de Conteúdo, é organizado em três etapas, realizadas em confor-
midade com três momentos de estudo diferentes. De acordo com Bardin (2011) e Minayo
(2000), essas etapas compreendem a pré-análise, a exploração do material e o tratamento
dos resultados obtidos e interpretação.

5.1.1 Pré-análise

Fase de organização e sistematização das ideias, em que ocorre a escolha dos docu-
mentos a serem analisados, a retomada das hipóteses e dos objetivos iniciais da pesquisa
em relação ao material coletado, e a elaboração de indicadores que orientarão a interpre-
tação final.

A pré-análise pode ser decomposta em quatro etapas:

1. leitura flutuante, na qual deve haver um contato com o material de análise, deixando-

se invadir por impressões e orientações;

2. constituição do Corpus, que envolve a organização do material de forma a respon-
der a critérios de exaustividade (não deixar de fora qualquer elemento), represen-
tatividade da amostra, homogeneidade entre os objetos retidos e pertinência dos
documentos utilizados;

3. formulação de hipóteses e objetivos, ou de pressupostos iniciais flexíveis que permi-

tam a emergência de hipóteses a partir de procedimentos exploratórios;

4. referenciação dos índices e elaboração dos indicadores a serem adotados na análise,

e preparação do material .

5.1.2 A Exploração do Material

Trata-se da fase em que os dados brutos do material são codificados para se alcan-
çar o núcleo de compreensão do texto. A codificação envolve procedimentos de recorte,
contagem, classificação, desconto ou enumeração em função de regras previamente formu-
ladas.

5.1. A Análise de Conteúdo

85

Segundo Triviños (1987 apud CURY, 2003), esta etapa pode ser chamada de des-
crição analítica, envolve um estudo aprofundado do corpus, com procedimentos de unita-
rização e categorização.

A unitarização é o processo que consiste em reler o material para definir as unidades
de análise, que podem ser “palavras, frases, termos ou mesmo documentos em sua forma
integral” (MORAES, 1999, p. 16). Na releitura, cada unidade é codificada e, a seguir,
individualizada.

5.1.3 Tratamento dos Resultados Obtidos e Interpretação

Nessa fase, os dados brutos são submetidos a operações estatísticas, a fim de se

tornarem significativos e válidos e de evidenciarem as informações obtidas.

De posse das informações, o pesquisador infere e realiza suas interpretações de
acordo com o embasamento teórico e os objetivos propostos, ou identifica novas dimensões
teóricas sugeridas pela leitura do material.

Pode ser feita por meio da apresentação de tabelas ou quadros com indicação das
distribuições de frequência e das percentagens, nas pesquisas de cunho quantitativo, ou
com a produção de um “texto-síntese”, nas pesquisas predominantemente qualitativas.

Assim, nesta etapa, busca-se atingir a “compreensão mais aprofundada do con-
teúdo das mensagens mediante inferência e interpretação” (MORAES, 1999, p. 24). A
partir dessa compreensão, pode-se utilizar os resultados com fins teóricos ou práticos,
bem como partir para novas análises com objetivos diversos.

Mas, como diz Triviños (1987 apud CURY, 2003), “não é possível que o pesquisador
detenha sua atenção exclusivamente no conteúdo manifesto dos documentos. Ele deve
aprofundar sua análise tratando de desvendar o conteúdo latente que eles possuem.”

Cada pesquisador, ao deparar-se com um corpus, produz uma categorização que
evidencia sua visão específica. Em cada etapa, a intuição do pesquisador, orientada pelos
objetivos da pesquisa, já produz uma forma de interpretação, pois suas decisões não são
neutras, trazem todas as suas concepções sobre o tema objeto de análise.

5.1.3.1 Categorização

Tendo destacado as unidades, o próximo passo é a categorização, que “tem por
primeiro objetivo [...] fornecer, por condensação, uma representação simplificada dos dados
brutos.” (BARDIN, 2011, p. 119). Esse agrupamento é feito segundo critérios prévios, já
decididos anteriormente, acrescidos de outros que são estabelecidos ad hoc.

De acordo com Bardin (2011), deve-se seguir o seguinte roteiro: constituição do
corpus, preparação do material e etapas de análise (alinhamento e dinâmica do discurso

86

Capítulo 5. Análise de Conteúdo

para encontrar a lógica inerente à estrutura da mensagem, análise do estilo e análise dos
elementos atípicos e figuras de retórica). O confronto entre as etapas de análise percorridas
deve permitir a compreensão do seu significado.

De acordo com os objetivos almejados neste trabalho, pretende-se compreender
como os conceitos são utilizados pelos elaboradores de itens da OBMEP e, por meio dos
registro das sugestões de solução, recorrer à Análise de Conteúdo, por ser um instru-
mento de análise interpretativa que busca o sentido de um texto. Desse modo, a análise
do texto de cada item e da solução apresentada pelo elaborador pode evidenciar como
um instrumento avaliativo, na amostra pesquisada, apresenta características pedagógicas
importantes para o ensino de Matemática.

Logo, a Análise de Conteúdo tem um papel fundamental: ela ajuda a “quebrar” a
produção escrita dos elaboradores e as marcações dos estudantes. Assim, desconstruir e
construir as informações para poder realizar inferências, estabelecendo-se conexões entre
as informações encontradas e a intencionalidade do instrumento.

6 Análise do Erro

87

[. . .] na avaliação classificatória, em que o foco de atenção está voltado
para o acerto da resposta, não sendo utilizado como um instrumento
de reflexão, o erro provavelmente não será valorizado pelo professor. Em
outra concepção de avaliação, mais preocupada com a formação do aluno
em termos de aprendizagens significativas e duradouras, o erro deixa de
ser apenas uma resposta a ser analisada: ele passa a ser uma questão
desafiadora que o aluno coloca ao professor – portanto, um elemento
desencadeador de um amplo questionamento de ensino (SILVA; BURI-
ASCO, 2005, p. 501).

6.1 Errar: Uma Ação para a Aprendizagem Significativa

Ao tomarmos uma avaliação construída a partir de itens de múltipla escolha, em
que os distratores são plausíveis, ou seja, o elaborador dos itens fez um estudo prévio
de caminhos errôneos de estudantes que não dominam aquilo que se pretende avaliar
na situação-problema proposta e os expressou nas alternativas incorretas, temos uma
avaliação que pode ser considerada pelo docente como instrumento de investigação dos
erros, assim como ocorre em questões abertas ou dissertativas. Esta avaliação é certamente
embasada pelos objetivos de aprendizagem, pois foi concebida previamente.

Cabe aqui um breve comentário sobre as opções incorretas presentes nas
questões de múltipla escolha. Quando essas opções são bem elaboradas, a
análise do erro pode revelar resultados muito interessantes em termos de
aprendizagem por parte dos estudantes. Muitas vezes, essas inferências
são mais ricas do que as conclusões que são extraídas do próprio acerto
no item. Podem, inclusive, ser feitas inferências de ações pedagógicas
que poderiam ser praticadas a partir do comportamento revelado nas
escolhas das opções incorretas pelos estudantes (RABELO, 2013, p. 141).

Não quer dizer que o elaborador conseguirá esgotar nas alternativas todas as formas
possíveis de erros ou até mesmo confirmar que o aluno ao marcar o distrator cometeu o
erro da forma que o elaborador apresentou nas soluções. Nesta abordagem, o resultado da
análise será uma inferência do erro, pois o aluno pode ter tomado caminhos não previstos e
até mesmo marcado a alternativa ao acaso. Mesmo sendo uma inferência, o professor terá
um espectro de ações pedagógicas que contribuam para um refinamento das habilidades
construídas.

Os itens apresentados desta forma nos levam a uma análise de intenção dos res-
pondentes. Se tomarmos o acertos teremos em mão o processo findo de conhecimentos, ou
seja, o que o aluno aprendeu e podemos dar continuidade no estudo de conteúdos novos.
Mas se tomar os erros nas questões abertas, ou os distratores com marcação expressiva,

88

Capítulo 6. Análise do Erro

poderemos dar continuidade ao conteúdo, mas com um leque de adaptações nos objetivos
que levem os alunos a ressignificarem conceitos.

No momento de elaborar os itens de múltipla escolha, o caminho errôneo é usado
na construção de distratores plausíveis. Após a resolução do item, os distratores podem
ser contabilizados para obter resultados da amostra, quando houver uma marcação muito
expressiva, pode-se ter um embasamento que justifique a alteração ou não dos objetivos.
Da mesma forma, em itens abertos, os erros podem ser computados. Com os distratores
tem-se inferências dos processos errôneos, mas nos itens abertos temos a confirmação dos
erros, estes estarão expressos.

Com uma abordagem investigativa e questionadora nesse momento, o docente pode
refazer sua prática, retomar e reconstruir objetivos. Este pode, também, confeccionar
instrumentos de avaliação que sanem os erros ocasionados pela não conformidade com
a Engenharia de Itens, e, além disso, o docente terá na mão instrumentos para inferir
caminhos tomados pelos alunos e, assim, utilizar a avaliação proposta para aprendizagem.
Ou seja, com uma ou outra fonte de erro, o professor revê sua postura frente a avaliação,
reelaborando o instrumento ou revendo seu fazer didático – ele aprende com o erro.

Consideramos que a avaliação da aprendizagem matemática, em vez de
ser tratada como uma interrupção do processo de ensino-aprendizagem,
precisa ser entendida como um processo de investigação e, desse modo,
é de fundamental importância que sejam considerados os processos e
estratégias utilizadas pelos alunos nos seus registros escritos.

O tratamento da avaliação como prática de investigação tem, entre suas
características mais relevantes, o fato de poder contribuir com o desen-
volvimento dos alunos à medida que possibilita que estes compreendam
seus erros e, a partir disso, busquem superá-los. Também contribui com
o professor, favorecendo uma reflexão sobre seu planejamento, desen-
volvimento e avaliação da sua prática pedagógica (SILVA; BURIASCO,
2005, p. 500).

Aproveitar os erros na aprendizagem não quer dizer que estes serão descartados
na avaliação somativa, mas dar a importância devida aos processo errôneos na avaliação.
Pode-se tomá-los de forma a investigar as formas de erro e saná-los a partir da tomada
de consciência do erro com o feedback ao aluno, para que ele saiba o distanciamento com
o conceito formal e também para que o aluno supere os obstáculos na sua aprendizagem.

A análise do erro também pode contribuir com o aluno na medida em
que o professor o incentive a analisar sua própria produção. Com isso,
o aluno terá a oportunidade de identificar e compreender seus erros,
podendo assim geri-los, isto é, desenvolver processos de verificação e
autocorreção que o ajudem a refazer o caminho (SILVA; BURIASCO,
2005, p. 501).

Essa superação pode ser dada pelo questionamento dos alunos frente a suas res-
postas. Borasi (1996 apud CURY, 2007, p. 15) assume que a análise de erros é uma me-

6.1. Errar: Uma Ação para a Aprendizagem Significativa

89

todologia de pesquisa e de ensino, e esta análise é vista pela autora como um “trampolim
para a aprendizagem”.

A análise de erros é uma abordagem de pesquisa com fundamentações
teóricas variadas, objetivos distintos e participação de todos os níveis
de ensino nas amostras, mas também é uma metodologia de ensino, po-
dendo ser empregada quando se detectam dificuldades na aprendizagem
dos alunos e se quer explorá-las em sala de aula (CORREIA, 2010b, p.
17).

De acordo com Pinto (2000 apud CORREIA, 2010b), a reflexão sobre o erro é
necessária no âmbito da pesquisa educacional, pois este tema abrange simultaneamente
um saber científico – a Matemática –, um saber construído na prática em sala de aula e
um saber avaliativo, ou seja, saberes que o docente irá construir na sua profissão. Logo,
este tema deve ser aplicado na formação de professores já que pode gerar reflexões sobre
o processo de aprendizagem.

Entre os conceitos acerca do erro, Barichello (2008 apud CORREIA, 2010b) considera-

o como uma parte de um produto final que não esteja de acordo com a Matemática que se
espera que o aluno apresente, assim sendo, o erro fica caracterizado pela falta em relação
à Matemática. E complementarmente pode ser entendido por falta na aplicação de um
algoritmo para a tentativa de resolução de um problema, mas que na argumentação do
aluno haja um processo lógico para ter ocasionado, desde a aplicação equivocada de con-
ceitos até a má compreensão do enunciado. Para Correia (2010b), é importante observar
que o erro é um processo de “indução” do raciocínio lógico matemático, um encadeamento
do pensamento que conduz a uma falsa conclusão.

Para o aluno, o erro em geral permanece oculto até que alguém o aponte
na resolução. Ao resolver um problema, mesmo obtendo resposta dife-
rente daquela esperada, o aluno aplica estratégias que, por algum motivo,
lhe parecem relevantes em termos do problema proposto. Ele não age ar-
bitrariamente, mas, sim, de acordo com um conjunto de conhecimentos
estabelecido em seu aparato cognitivo (CORREIA, 2010b, p. 18).

Se o professor explorar a dificuldade dos alunos e utilizar os erros como ferramentas
para o aprendizado, elaborando estratégias que levem os estudantes a questionamentos
sobre suas respostas, pode-se ter um embasamento sólido para o auto-monitoramento.

Para o aluno, a avaliação pode servir para regular sua aprendizagem,
sendo subsídio capaz de orientá-lo para a autonomia de pensamento,
para perceber suas dificuldades, analisá-las e descobrir caminhos para
superá-las. Para o professor, deve contribuir para que ele possa repensar
e reorientar a sua prática pedagógica, além de possibilitar-lhe entender
e interferir nas estratégias utilizadas pelos alunos (SILVA; BURIASCO,
2005, p. 500).

90

Capítulo 6. Análise do Erro

Tomar consciência, retomar e corrigir o próprio raciocínio são ações que expressam
a autonomia discente. Mas a autonomia desenvolve-se a partir da interação do sujeito com
seus próprios conceitos, com outros sujeitos e os objetos de conhecimento e não, apenas,
com os apontamentos dos docentes. As ações educativas que a promovem estão associadas
às bases da construção do conhecimento e do desenvolvimento cognitivo.

6.2 Erro: Bases Históricas

Cury (2003) apresenta que as pesquisas acerca dos erros cometidos pelos alunos
em disciplinas matemáticas foram iniciadas em trabalhos desenvolvidos no início do século
XX, nos quais a concepção do erro estava de acordo com a teoria educacional vigente,
ou seja, ora eram priorizados os aspectos técnicos dos erros, ora as teorias psicológicas,
de ensino ou de aprendizagem. De acordo com Barichello (2008 apud CORREIA, 2010b),
desde o princípio destes estudos há a ênfase na proposição de sistemas de classificação
para os erros em Matemática cometidos por estudantes em diversos níveis.

Segundo o educador matemático Rico (1995 apud CORREIA, 2010b), as pesquisas
sobre o erro e sua análise ao redor do mundo apresentam importantes contribuições para
esta área.

De acordo com esse autor, por exemplo, na Alemanha no período entre as duas
grandes guerras mundiais, com o desenvolvimento da psicologia experimental, o erro, nos
trabalhos de Weiner em 1922, era utilizado para estabelecer padrões explicativos para os
equívocos individuais em diferentes idades. Já nos estudos de Kiessling em 1925, o erro
era determinado pela predisposição que algumas pessoas tinham em se equivocar. Já em
1931, Seseman distinguiu três tipos de erros: mecânicos, associativos e funcionais.

Rico destaca que, a partir dos anos 60, a linha de pesquisa era de investigação
quanto às deficiências no cálculo aritmético, buscando descobrir causas de erros nas fases
do processo de solução. Erlwanger, em 1975, e Ginsburg, em 1977, influenciaram o ensino
de Matemática por meio de suas investigações sobre as estruturas básicas dos processos de
ensino e aprendizagem, empregando como método de investigação as entrevistas clínicas
e os estudos de casos.

Rico (1995) descreve que na Espanha, a partir de 1953, Villarejo e Fernández Hu-
erta investigaram os erros mais frequentes na aritmética escolar e, na União Soviética,
nos anos 60, dois trabalhos sobre as causas dos erros nas operações fundamentais mere-
cem citação. Primeiramente, o de Kuzmitskaya que localiza quatro causas de erros nas
operações aritméticas:

1. insuficiência de memória de curto prazo;

2. compreensão insuficiente das condições do problema;

6.2. Erro: Bases Históricas

91

3. ausência de regras verbais para realização de cálculos;

4. uso incorreto das quatro operações.

Posteriormente, os estudos de Menchinskaya destacam, da mesma forma, quatro

causas:

1. a realização incorreta de uma operação;

2. a compreensão conceitual insuficiente;

3. a distração, que provoca erros mecânicos;

4. a aplicação indevida das regras algorítmicas.

Nos Estados Unidos, de acordo com Rico (1995), o trabalho de Thorndike em 1917,
intitulado “Psicologia da Aritmética”, se caracteriza como pioneiro nos estudos acerca dos
erros que ocorreram nas operações aritméticas fundamentais, enquanto Buswell conseguiu
detectar um maior número de erros típicos pelo método de análise, incluindo, ao lado de
exercícios escritos, observações em aula e entrevista para diagnóstico. Brueckner, em 1935,
propunha alguns objetivos para o trabalho com os erros:

(a) listar as técnicas errôneas;

(b) determinar a distribuição de frequências dessas técnicas, segundo as idades dos

alunos;

(c) analisar dificuldades especiais, como as encontradas na divisão e nas operações com

o zero;

(d) classificar e agrupar os erros.

A linha psicométrica utilizada nessas investigações iniciais influenciou as avaliações
da aprendizagem. Entre os seguidores dessa linha de pesquisa surgem os trabalhos de Tyler
e Bloom, que são os autores que mais introduziram mudanças substanciais no modo de
avaliar os alunos, com as ideias de que as provas devem seguir certos critérios e de que os
objetivos de cada disciplina devem servir como padrões avaliativos (CORREIA, 2010b, p.
21).

Esse autor ainda lembra que, como aponta Gutierrez em 1991, com o avanço da
didática da Matemática, principalmente na França e na Espanha, aumentou o interesse
pela investigação dos erros cometidos pelos alunos.

92

Capítulo 6. Análise do Erro

6.3 O Erro e o Ambiente Construtivista

De acordo com Pinto (2000 apud CORREIA, 2010b, p. 22), “a nova concepção do
erro, a partir dos fundamentos psicogenéticos, é encontrada, com mais profundidade, na
literatura sobre o construtivismo”. À luz do construtivismo, os erros que se apresentam
no processo de desenvolvimento da criança denotam a apropriação dos conhecimentos.
Segundo essa autora, entre outros, os trabalhos de Macedo e La Taille, utilizam essa
teoria para discutir o papel construtivo do erro da criança.

Na sua definição geral, construtivismo refere-se a um conjunto de teorias
que afirmam que a evolução da inteligência é fruto da interação do sujeito
com seu meio, interação na qual, por meio de um trabalho ativo de ação
e reflexão, ele cria ferramentas cada vez mais complexas para conhecer
o universo (CORREIA, 2010b, p. 22).

De acordo com Macedo (1994 apud CORREIA, 2010b, p. 23), para Piaget o erro é
um elemento possível e até necessário que faz parte do processo no qual está se construindo
um conceito, ou seja, é um erro construtivo, onde a criança é capaz de refletir sobre o
mesmo.

O que se espera hoje, de acordo com essa visão, é conceber o erro como
um meio de desenvolvimento. É importante que primeiro se entenda a
situação que o motiva para depois procurar meios de superá-lo. Desse
modo, é necessário que o professor busque conhecer e entender os erros
cometidos pelos alunos nas atividades propostas, já que, “(...) quando
um aluno comete um erro, ele expressa o caráter incompleto de seu
conhecimento” (SILVA; BURIASCO, 2005, p. 501).

Teixeira (1997) cita Piaget e Vergnaud, afirmando que o primeiro diz que para
haver compreensão do processo de construção do conhecimento, é necessário analisar o
desenvolvimento das estruturas lógicas gerais; o segundo autor aponta que, para compre-
ender a construção do conhecimento, não é suficiente observar o processo, mas é preciso
transformá-lo. Daí, ao tomarmos a noção de erro na aprendizagem, retiramos a noção de
ser uma ação fracassada, mas que carrega em si estruturas com raciocínios lógicos obser-
váveis e que podem ser reelaborados para a aprendizagem do indivíduo em formação.

Também na abordagem piagetiana, no processo de construção das estruturas ló-
gicas, os erros, segundo Piaget (TEIXEIRA, 1997, p. 49), são resultados de conflitos
cognitivos onde os indivíduos se esforçam para se adaptarem a novos contextos.

Conflito cognitivo para Piaget é o termo usado para explicar o pro-
cesso através do qual ocorrem mudanças cognitivas, ou seja, passagem
de um estado de equilíbrio a outro (teoria da equilibração, através de
um período de transição em que há formas contraditórias de interpretar
e resolver um mesmo problema) (TEIXEIRA, 1997, p. 49).

6.3. O Erro e o Ambiente Construtivista

93

Segundo Piaget (1991 apud CORREIA, 2010b, p. 23), não interessa o erro, mas a
ação mental; erro e acerto são detalhes nessa ação mental. Nesta perspectiva, as respostas
dos indivíduos são apresentadas, ordenadas e classificadas em três níveis:

∙ no primeiro nível, o indivíduo não resolve e nem compreende o erro, por isso as
respostas contraditórias são negadas e recalcadas; não lhe causa problema responder
errado, pois não houve entendimento do problema proposto;

∙ no segundo nível, o da tentativa, o erro aparece como um problema a ser resolvido.
São comuns a ambivalência e a dúvida; nesta situação, a interferência adulta ou de
colega possibilita à criança avanço e a percepção do conflito em suas respostas;

∙ no terceiro nível, o erro passa a ter um sentido ao aluno, e este adquire certa autono-
mia na construção do conhecimento e na construção do conhecimento. Apresenta-se
uma resposta satisfatória para o problema, conseguindo o aprendiz antecipar-se e
corrigir-se. Neste caso, consegue-se sucesso com relativa autonomia frente às situa-
ções.

Se numa avaliação seletiva, o erro tem um papel delimitado pelos resul-
tados, ao perder sua função controladora, ele passa a ocupar um papel
relevante na aprendizagem: o erro é um conhecimento; ele mostra o ca-
minho do acerto que já está ali implícito. Nesta dialética, o erro aparece
como um divisor de águas de duas tendências fortes na educação. Se na
pedagogia tradicional, centrada no professor, o relevante era saber o que
se ensina na pedagogia nova a preocupação do professor é saber como
as crianças aprendem (CORREIA, 2010b, p. 25).

A ação errônea é o apontamento de um problema que suscita novas soluções, ao
mesmo tempo em que é uma resposta a determinada questão, onde no início se apresentava
como obstáculo, mas contribui para a maturação e reestruturação de processos cognitivos
mais elaborados.

Os níveis, apresentados por Piaget, possibilitam a compreensão das respostas em
função da estruturação cognitiva do sujeito, favorecendo o trabalho dos erros dentro da
história dos alunos. Por isso, o erro, na perspectiva infantil, difere da concepção que tem
a perspectiva adulta. Para a criança, não está em jogo somente o certo ou errado, mas
também a possibilidade de sua compreensão.

Para contribuir com o estudo destes níveis, Rosso acrescenta que:

No primeiro nível são erros derivados da limitação das estruturas neces-
sárias à solução da tarefa, ficando a criança impossibilitada de compre-
ender o que lhe é solicitado; no segundo, são erros construtivos, porque
sinalizam a formação de novas estruturas; no terceiro são erros de proce-
dimento, cometidos no emprego ou aprimoramento de conhecimentos já
construídos e que podem acontecer por distração ou falta de habilidade.

94

Capítulo 6. Análise do Erro

No primeiro e segundo níveis, as dificuldades são operativas, exigindo
procedimentos didático-pedagógicos mobilizadores dos processos opera-
tivos e cooperativos. Já no terceiro nível são obstáculos epistemológicos
por se apoiarem em conhecimentos anteriores, devendo a ação docente
promover conflitos que ponham em xeque a pertinência dessas informa-
ções (ROSSO; BERTI, 2010, p. 1010).

Com estas abordagens sustenta-se a prática docente de intervenção no processo
de ensino-aprendizagem. Ao construir um instrumento avaliativo, o professor deve levar
em consideração estes níveis de erro, até mesmo para construir os distratores, pois ao
perceber a marcação pelo aluno, já pode identificar o nível de percepção que o estudante
possui em relação ao conteúdo apresentado.

E mais ainda, no momento de correção e retomada da atividade, o professor pode
intervir nestes níveis em um trabalho quase que individual para reduzir o distanciamento
aos conceitos corretos. Para Taille (1997 apud CORREIA, 2010b, p. 26) “não basta o
aluno ficar sabendo que errou! Ele deve ter acesso à qualidade de seu erro”. Mas “tornar
o erro um observável nem sempre é fácil e pede muita criatividade pedagógica por parte
dos professores”.

Qualquer que seja a perspectiva que o erro seja abordado na escola, é necessário
distinguir os erros e utilizar condutas pedagógicas apropriadas, já existentes, na busca
de superação dos mesmos. A proposta de uma análise atenciosa da produção escrita dos
alunos busca levar professor e aluno a enxergarem o erro como indicador de algo que
precisa ser revisto e neste momento a investigação aparece para dar conta das indagações
que muito provavelmente vão aparecer durante o processo de análise. Cury destaca:

A ideia de que o erro se constitui como um conhecimento, é um saber que
o aluno possui, construído de alguma forma, e é necessário elaborar in-
tervenções didáticas que desestabilizem as certezas, levando o estudante
a um questionamento sobre as suas respostas (CURY, 2007, p. 80).

Análise ou correção de um item pelo professor gera alguns questionamentos acerca
do raciocínio do aluno; o que e o como pensou o aluno no momento e na situação propostos,
as operações que sustentam seu raciocínio, as representações, práticas cotidianas, quais
conceitos tentou utilizar e outras questões. O apanhado de respostas a estas perguntas
apresenta aos estudantes quais conhecimentos demonstram ter e quais ainda estão em
construção.

Nesse sentido, a suposta estratégia errônea pode ter sido elaborada com base em
algum conceito equivocado que esse aluno construiu, ou por tentar propor uma estratégia
que contornasse sua dificuldade na resolução, seja a dificuldade com qualquer conceito
matemático.

6.3. O Erro e o Ambiente Construtivista

95

Na perspectiva de construção de distratores, o docente se antecipa na inferência
de erros que poderão ocorrer, traça uma visão geral dos possíveis quadros que os discentes
construirão e, com essa postura, já revela-se em sua prática a preocupação com o refazer
dos conceitos. Demonstrará que sabe o fazer didático, e ao perceber esta postura o aluno
poderá tomar seus julgamentos e confiar na orientação de seu professor.

É importante que o aluno construa suas próprias ferramentas para resolver pro-
blemas. Contudo, há erros na resolução que nascem do estabelecimento de conexões entre
conceitos aprendidos ou estratégias utilizadas que não se aplicam à situação- problema
proposta. São falsas generalizações, são regras que não são verdadeiras.

Para justificar os caminhos errôneos que acompanham o estudante em suas respos-
tas, é necessário tomar os conceitos de Brousseau (TEIXEIRA, 1997, p. 50). Este autor
apresenta “que os erros, em um mesmo sujeito, comparecem ligados entre si por uma fonte
comum: um conhecimento antigo que foi eficiente em certas situações”, sendo que estes
podem ser resistentes e ressurgir várias vezes.

Com base nesta análise, Brousseau (TEIXEIRA, 1997) utiliza a ideia de obstáculo,
ampliando-a para interpretar questões da didática da Matemática. O autor aponta três
tipos de obstáculos: epistemológicos, didáticos e ontogenéticos.

(a) os obstáculos epistemológicos se encontram tanto no desenvolvimento histórico dos
conceitos, como se repetem nos conceitos espontâneos dos alunos. São concepções
constitutivas do conhecimento e inerentes a um sistema de conhecimentos. Assim,
todo conhecimento é suscetível de ser um obstáculo à aquisição de novos conheci-
mentos, na medida em que quanto mais sedimentado, maior resistência oferecerá à
ampliação do conhecimento. Não são meras dificuldades. Brousseau aponta algumas
condições que permitem identificar os obstáculos epistemológicos:

i. é conhecimento e não ausência do mesmo;

ii. o conhecimento-obstáculo é eficaz para certos contextos mas para outros conduz

a erros;

iii. resistente ao estabelecimento de novo conceito ou ampliação do mesmo;

iv. resiste às contradições com os quais é confrontado.

(b) Obstáculos de origem didática são aqueles que dependem da escolha de um pro-
jeto educativo, ou seja, “concepções de ensino que redundam numa transposição
didática”.

(c) Obstáculos de origem ontogenética são os provenientes das limitações do sujeito
num dado momento de aprendizagem. Podemos citar, como exemplo, a dificuldade
de entender a operação de adição nos inteiros como associação e não como acréscimo.

96

Capítulo 6. Análise do Erro

Se o erro for usado como motor de ação e reflexão em situações apropriadas,
fazendo o aluno evoluir, reestruturando e integrando seus conceitos anteriores com a
necessidade de expansão dos mesmos, os erros serão de papel positivo na aprendizagem.

Com essa abordagem, afirma Perrin-Giorian,

a noção de obstáculo é também um meio de olhar de outro modo os
erros do aluno: certos erros, recorrentes são resultado de conceitos que,
mesmo quando são falsos, não são acidentes mas aquisições muitas vezes
positivas (TEIXEIRA, 1997, p. 51).

6.4 Enfoque Pedagógico do Erro

As recentes abordagens cognitivas sobre o erro passaram a encará-lo como inte-
grante do processo de aprendizagem. Isto não significa estabelecer uma pedagogia do erro,
mas uma pedagogia que assuma a presença de obstáculos na construção do conhecimento
como parte do processo.

Conhecer os erros e criar estratégias visando auxiliar os alunos a superá-los deve
ser uma preocupação incluída no planejamento do professor. O professor precisa analisar
os erros dos alunos e categorizá-los, para entender como o processo de aprendizagem está
ocorrendo para seus ouvintes.

Assim, no momento da correção, ao verificar conclusões errôneas, o professor faz
inferências das premissas utilizadas, caracterizando a natureza dos erros produzidos. A
partir daí tomará decisões que retomem aprendizagem do conceito formal. “Ao levantar
indícios sobre o desempenho dos alunos, o professor deve ter claro o que pretende obter e
que uso fará desses indícios. Nesse sentido, a análise do erro pode ser uma pista interessante
e eficaz” (BRASIL, 2000, p. 59).

Os erros apontados são de naturezas diferentes e, por isso, precisam ser tratados
de forma diferenciada pelo professor. Assim, é importante que o professor identifique os
diferentes tipos de erros, distinga qual a natureza de cada um deles, bem como que ações
precisa realizar para explorá-los. De acordo com os PCN:

Quando o professor consegue identificar a causa do erro, ele planeja a
intervenção adequada para auxiliar o aluno a avaliar o caminho percor-
rido. Se, por outro lado, todos os erros forem tratados da mesma ma-
neira, assinalando-se os erros e explicando-se novamente, poderá ser útil
para alguns alunos, se a explicação for suficiente para esclarecer algum
tipo particular de dúvida, mas é bem provável que outros continuarão
sem compreender e sem condições de reverter a situação (BRASIL, 2000,
p. 59).

Ao tomar uma avaliação para a aprendizagem deve-se embasar em objetivos claros
de aprendizagem, Bodin (1997 apud BURIASCO, 2000, p. 11), apresenta que existem

6.4. Enfoque Pedagógico do Erro

97

quatro patamares onde se identifica o erro diante à construção de conhecimento em uma
situação didática de Matemática:

1. erros de saber: o aprendiz não tem conhecimento matemático sobre as definições, as

regras, os algoritmos, e outros;

2. erros de saber-fazer: o aprendiz não tem domínio da técnica de resolução, do algo-

ritmo, e outros;

3. erros ligados à utilização adequada ou não dos saberes ou do saber-fazer: o apren-
diz não reconhece o conceito correto para aplicar na resolução de uma situação-
problema;

4. erros de lógica ou de raciocínio: o aprendiz confunde hipótese e tese, encadeia mal

os cálculos, não sabe lidar com os dados apresentados.

Radatz (1979 apud CURY, 2007, p. 27) propõe a seguinte classificação de erros de

acordo com um modelo embasado nos mecanismos do processamento de informação:

(a) erros devido a dificuldade de linguagem: ou seja, relacionado ao formalismo simbó-

lico;

(b) erros devido a dificuldade de obter informação espacial: relacionado à falta de ca-

pacidade de visualização de diagramas, figuras, ”instruções icônicas”;

(c) erros devido ao domínio deficiente de conteúdos, fatos e habilidades consideradas

como pré-requisitos;

(d) erros devido a associações incorretas ou rigidez de pensamento, tanto conceitual

anterior quanto no uso de uma regra a caso específico;

(e) erros devido a aplicações de regras ou estratégias irrelevantes, o uso inadequado de

estratégias de solução.

Esta apresentação de categorização não implica a dissociação dos erros entre si,
sendo que estes podem ocorrer de forma conjunta. O mesmo autor reforça estas associa-
ções:

...é difícil fazer uma separação entre as possíveis causas de um dado
erro, porque há uma estreita interação entre as causas. O mesmo pro-
blema pode originar erros de diferentes origens e o mesmo erro pode
ser proveniente de diferentes processos de solução de problemas. Uma
classificação e hierarquia precisa das causas dos erros parece impossível
de ser realizada (CURY, 2007, p. 28).

98

Capítulo 6. Análise do Erro

Clements (1980 apud CURY, 2007, pg. 28) apresenta também os tipos de erros
apontados por Newman e Casey. O primeiro propôs um modelo de sequência de passos
para solucionar um problema de Matemática, em que o aluno apresenta uma só dificul-
dade, e que, durante o processo de solução, podem haver três causa prováveis do erro: a
motivação, a desatenção e a formulação da questão em alguns destes passos. De acordo
com Newman, as etapas são:

∙ leitura;

∙ compreensão;

∙ transformação;

∙ execução das habilidades necessárias ao processo;

∙ codificação.

Casey modificou e ampliou a classificação de Newman, tornando-a aplicável à aná-
lise de erros em problemas com mais de uma dificuldade. Para Casey, as etapas sugeridas
por Newman apresentam uma rigidez e, no entanto, o aluno, ao se deparar com um item
para ser solucionado, retoma ou salta passos, e nem sempre obedece uma ordem estabe-
lecida. Este autor preconiza que a formulação é o primeiro momento de interação entre
o problema a ser resolvido e o respondente, e ainda salienta que os erros que escapam a
essa classificação foram agrupados em duas categorias, as quais Casey chamou de “bloco
conhecido” e “bloco desconhecido”.

Sua classificação para as causas dos erros é a seguinte (CURY, 2007, p. 28):

1. formulação da questão;

2. leitura;

3. compreensão;

4. seleção de estratégias;

5. seleção das habilidades requeridas;

6. manipulação das habilidades;

7. apresentação da solução.

Aqui se justifica o uso da Engenharia de construção de itens, para que a má
formulação da questão não seja responsável pelos erros dos respondentes, mas que os
erros que por ventura venham a ocorrer sejam intrínsecos do indivíduo. Assim, poderão
ser norteadores do processo de aprendizagem dos mesmos.

6.4. Enfoque Pedagógico do Erro

99

Quando se toma a análise de erros como metodologia de pesquisa, Radatz (1979
apud CURY, 2007, p. 31) apresenta uma revisão dos trabalhos feitos desde o início do
século e, mesmo sem explicar o que significa cada um dos objetivos de estudo citados,
considera que o interesse das pesquisas está localizado em:

(a) listar todas as técnicas potenciais de erros;

(b) determinar as distribuições de frequências destas técnicas de erros através das faixas

etárias;

(c) analisar dificuldades especificas, encontradas na prática ao fazer divisões escritas e

operações com zero;

(d) determinar a persistência das técnicas individuais de erros;

(e) tentar classificar e agrupar erros.

Borasi (1996 apud CURY, 2007) propõe um esquema de categorização (apresen-
tada na Tabela 7) dos usos dos erros para o ensino, de acordo com o objetivo da apren-
dizagem e ação interventiva.

Tabela 7 – Taxonomia de Borasi para os Usos de Erros

Realização de uma tarefa
matemática específica

Compreensão de algum
conteúdo
técnico-
matemático

Compreensão sobre a na-
tureza da Matemática

Remediação Análise dos erros detectados,
para compreender o que houve
de errado e corrigir, de forma a
realizar a tarefa com sucesso.

Análise dos erros detecta-
dos, para esclarecer más
interpretações de um con-
teúdo técnico matemático.

Uso construtivo de erros ao
aprender novos conceitos.

Descoberta

Pesquisa

Uso construtivo de erros no
processo de resolução de um
novo problema ou tarefa; mo-
nitoramento do trabalho de al-
guém para identificar potenci-
ais enganos.
Erros e resultados intrigantes
motivam questões que geram
pesquisas em novas direções e
servem para desenvolver novas
tarefas matemáticas.

Análise dos erros detectados,
para esclarecer más interpreta-
ções sobre a natureza da Mate-
mática ou de conteúdos especí-
ficos.
Uso construtivo de erros ao
aprender sobre a Natureza da
Matemática ou de algum con-
ceito matemático

Erros e resultados intrigan-
tes motivam questões que
podem levar a novas pers-
pectivas sobre um conceito
regra ou tópico não con-
templado no planejamento
original.

Erros e resultados intrigantes
motivam questões que podem
leva a insights e perspectivas
inesperadas sobre a natureza
da Matemática ou de algum
conteúdo matemático.

Estes apontamentos de Borasi embasam as atitudes do professor frente ao erro
diante aos objetivos da aprendizagem e das atividades desempenhadas, e a autora enfatiza
que as formas de utilização podem aparecer separadas ou combinadas. “Assim dependendo
dos objetivos com que o erro é empregado e do nível de abstração com que é examinado,
podemos transitar por essas diversas formas de se trabalhar com análise de erros” Borasi
(1996 apud CURY, 2007, p. 40).

100

Capítulo 6. Análise do Erro

Na verdade é necessário conceber o erro como um meio de desenvolvimento da
aprendizagem: ao final da categorização, o professor toma ações fundamentadas na tipo-
logia do erro para haver reconstrução do conhecimento. Segundo Buriasco (2000, p. 169),
grande “(...) parte dos educadores matemáticos enfatiza que em lugar de ser protegido
do erro, o aluno deveria ser exposto ao erro muitas vezes, ser encorajado a detectar e a
demonstrar o que está errado, e por quê”.

Rosso e Berti (2010, p. 1007) determinam que o erro envolve, a priori, três enfoques:

1. o enfoque epistemológico, pois o erro pressupõe concepções sobre a construção do

conhecimento e a sua adaptação à realidade;

2. o enfoque psicológico, referindo-se na visão dos estudantes ao significado das atitudes
envolvidas, da interpretação das correções e do valor dado ao erro e ao conhecimento
matemático;

3. o enfoque pedagógico, que relaciona as ações assumidas pelo docente diante do erro

e das estratégias usadas para uma aprendizagem significativa.

Partindo dos enfoques epistemológico e psicológico, a resposta errônea serve como
ponto de partida para novas investigações que levarão o indivíduo a buscar soluções que
satisfarão não apenas a situação proposta, mas também servirão como resposta a outras
proposições.

O professor, levando em consideração o enfoque pedagógico do erro juntamente
com o epistemológico e psicológico, terá maiores possibilidades de reelaborar sua prática
de sala de aula, pois poderá buscar novos recursos e metodologias que têm como foco
não o repasse, mas a construção do conhecimento por meio do questionamento e da
autorreflexão.

Desse modo, o erro se constitui importante instrumento de intervenção didática,
pois, a partir dele, o docente tem a possibilidade de observar e valorizar a diversidade na
sala de aula, o diálogo e a troca de ideias e consequentemente escolher a conduta a ser
utilizada no ensino de determinado conteúdo.

6.5 Erro e a Avaliação de Larga Escala

A análise do erro em sala de aula pode ocorrer de forma significativa ao utilizar
questões abertas ou de múltipla escolha, mas, para uma avaliação de larga escala, o
segundo uso é mais factível, devido ao grande número de envolvidos no estudo.

Em uma avaliação de larga escala, o uso de distratores plausíveis possibilitará
um retorno ao docente da sua ação pedagógica, ao mesmo tempo em que estes podem

6.5. Erro e a Avaliação de Larga Escala

101

constituir fonte para índices de aprendizagem nacionais, dando ao Estado um respaldo
para as políticas educacionais que contribuam para uma democratização, de fato, do
ensino.

E a ação, que os resultados apresentados pela análise gerarão frente aos indiví-
duos, em estudo, será realizada pelo docente, mas com o aparato do Estado. Com uma
lente de aumento, utilizando um bom instrumento avaliativo, o Estado poderá observar o
conhecimento sendo construído e intervir de acordo com os objetivos gerais da avaliação,
por meio do professor.

Não se pode deixa de destacar também o papel do aluno nesta construção. Pinto
(2000) aponta que o trabalho com o erro se desenvolve a partir do momento em que ele
se torna observável, tanto pelo aluno quanto pelo professor, e coloca que no processo de
aprendizagem o “aluno deve perceber a qualidade do erro, interagindo com ele, desequi-
librando suas estruturas mentais, por meio dele, até poder superá-lo” (PINTO, 2000, p.
147).

Desse modo, a participação do aluno na análise dos erros, por meio do feedback
do seu trabalho, é essencial para que a ação interventiva do professor possibilite que o
aluno se coloque diante dessas ações como elemento ativo no processo de aprendizagem,
atuando, reconhecendo e dando significados aos erros apresentados.

[. . .] de modo geral os erros devem ser vistos como um indicativo de que
o aluno sabe alguma coisa, porém não totalmente ou corretamente e que,
portanto, é preciso trabalhar com esses erros e não apenas ignorá-los,
lembrando que, dependendo da natureza do erro e que se determina qual
conduta pedagógica deve ser adotada na busca de sua superação. Essa
é uma das contribuições pessoais que o professor pode fazer na busca de
diminuir o fracasso escolar (BRASIL, 2001, p. 55)1.

As situações de erro também podem servir ao aluno como meio de reflexão sobre
o que ele pensa de determinado assunto, para perceber que a partir delas também se
pode aprender. Para que isso aconteça, é importante que, em sala de aula, o aluno seja
incentivado e tenha a oportunidade de realizar tentativas, sabendo que estas, “corretas
ou não”, serão do mesmo modo fonte de aprendizagem.

Para que a análise do erro se torne uma alternativa didática, o professor
deve conhecer e buscar compreender o erro, investigando sua natureza,
tendo em vista que “(...) os erros da aprendizagem, (...)” servem po-
sitivamente de ponto de partida para o avanço, na medida em que são
identificados e compreendidos, e sua compreensão é o passo fundamental
para sua superação (SILVA; BURIASCO, 2005, p. 501).

1 AVA (Programa de Avaliação do Sistema Educacional do Paraná) da Secretaria de Estado de Educação
que contém 30 questões que avaliaram os alunos concluintes da 4a série do Ensino Fundamental em
Matemática em 2000

102

Capítulo 6. Análise do Erro

Assim, é necessário que todos os envolvidos na avaliação educacional, desde o
Estado até o aluno, percebam que a avaliação é uma dimensão do processo ensino-
aprendizagem, uma aliada para ambos no processo de desenvolvimento.

Em um país que só se implanta com continuidade aquilo que é fruto
de política de Estado (e não de governo), não se pode dispensar os
processos de avaliação feitos no âmbito do poder público. Muito menos
podemos colaborar para sua desresponsabilização quanto à avaliação
feitos no âmbito do poder público. Entretanto, é legítimo discordar da
forma como alguns governos querem conduzir os processos avaliativos
(FREITAS, 2014, p. 47).

No tocante aos instrumentos de avaliação em larga escala, a avaliação do Enem
– Exame Nacional de Ensino Médio – é um exemplo de provas que sofreram alterações
significativas na sua elaboração e podem ser utilizadas por professores e alunos para uma
ressignificação da aprendizagem. Com distratores bem elaborados podem ser usadas para
comparação dos estudantes no tempo e já trazem em si um caráter de acompanhamento de
competências construídas no ensino superior, pelo Sinaes – Sistema Nacional de Avaliação
da Educação Superior.

Com o intuito de contribuir na elaboração da prova de primeira fase da OBMEP, no
Capítulo 8.3 será apresentado um estudo acerca da elaboração deste instrumento e sobre
a aplicabilidade da análise de erro sobre os distratores no grupo analisado. A intenção não
é valorizar o erro, mas dá-lhe uma nova função no processo de ensino-aprendizagem. É a
preocupação com o caminho percorrido pelo aluno que, consequentemente, o levou a errar
que deve estar em questão e se houve problemas na elaboração e/ou se as habilidades
necessárias para responder os itens devem ainda ser exploradas pelos docentes.

Parte II

Análise e Discussão

7 Metodologia

105

O que se espera de uma avaliação numa perspectiva transformadora é
que os seus resultados constituam parte de um diagnóstico e que, a partir
dessa análise da realidade, sejam tomadas decisões sobre o que fazer para
superar os problemas constatados: perceber a necessidade do aluno e
intervir na realidade para ajudar a superá-la (VASCONCELLOS, 2005,
pg. 89).

Este trabalho começou a ser realizado em agosto de 2014, após a aplicação da pri-
meira fase da OBMEP, a respeito da qual se delineou o objeto de estudo aqui apresentado.
Entre as fases e níveis da Olimpíada, foi escolhido o instrumento de avaliação da primeira
fase do nível 2, sendo o público alvo os alunos que cursam o oitavo e o nono ano do ensino
fundamental.

A escolha da primeira fase foi motivada pela possibilidade de análise de um ins-
trumento composto de itens de múltipla escolha, no qual os distratores, ou alternativas
de respostas erradas, podem evidenciar os caminhos errôneos utilizados pelos responden-
tes, constituindo-se ferramenta pedagógica de grande valia para os professores que atuam
nessa etapa de escolaridade. Já a motivação principal de escolha do nível, reside no fato
de a pesquisadora atuar efetivamente no ensino fundamental, nesses anos em particular.

O levantamento de referencial teórico bibliográfico foi o segundo passo de elabora-
ção deste estudo, iniciado com uma investigação sobre o regulamento, a relevância e fatos
históricos relacionados à Olimpíada Brasileira de Matemática das Escolas Públicas e a
importância de uma avaliação de larga escala para a aprendizagem.

Também foram realizadas reuniões e conversas informais junto aos coordenadores
da OBMEP para confirmação de informações relativas ao certame e que não estavam
disponíveis no sítio do evento, gerando, assim, o acesso a RAIG de 2014 e uma entrevista
com o coordenador de elaboração dos itens, via correio eletrônico, que mais tarde foram
cedidas para o estudo.

O levantamento de bibliografias continuou com o estudo das teorias psicométricas
e estatísticas – a TRI e a TCT –, com o estudo da Engenharia de Construção de Itens e
a abordagem de Análise de Conteúdo e, por fim, com a análise de erros no processo de
ensino-aprendizagem.

7.1 Coleta de dados – estudo quantitativo

Para investigar as respostas dos estudantes, foram escolhidas cinco escolas do Dis-
trito Federal, situadas nas seguintes Regiões Administrativas: Brasília (duas), Ceilândia,

106

Capítulo 7. Metodologia

Recanto das Emas e São Sebastião. Nesses locais, todos os alunos realizaram a prova da
OBMEP - nível 2 (Anexo B), e foram relacionados 1.658 estudantes no total.

Foi requisitado junto ao professor coordenador da OBMEP na escola, a cessão dos
gabaritos dos estudantes. Estes foram mantidos na escola após a seleção dos candidatos
para segunda fase e cedidos para estudo, com a responsabilidade de retorno dos mesmos a
cada instituição. Para isso, foi redigido um Termo de Consentimento Livre e Esclarecido
(Apêndice A) , que estabelecia o objetivo do estudo e a necessidade de uso das respostas
dos estudantes, e, ainda, evidenciava a responsabilidade de não se divulgar o nome das
escolas nem os dados referentes aos alunos.

Em duas escolas, havia 100% das folhas de respostas respondidas pelos estudantes,
mas as folhas dos 5% escolhidos para segunda fase eram cópias escaneadas e as demais
correspondiam aos originais. Para as demais escolas, os gabaritos eram referentes aos
alunos não selecionados.

Os gabaritos foram numerados e separados em cinco grupos, mantendo-se sigilo
quanto à identidade da escola e do estudante. A pesquisadora retornou ao material apenas
para efeito de verificação de alguma divergência na digitação ou para comparar o resultado
com os escores determinados pelos corretores escolares.

Os dados foram tabulados em planilha eletrônica do software EXCEL, com a se-
guinte discriminação: identificação numérica do aluno, sexo, ano de ensino, 20 respostas
marcadas em cada item e escore bruto obtido. Caso houvesse dupla marcação ou questão
em branco, no campo referente ao item foi colocado um ponto ( . ) – posteriormente foi
denominada marcação em branco.

Esse arquivo citado foi convertido para uma novo arquivo intitulado Bancode-
Dados.xls, no qual as informações referente a sexo, ano de ensino e escore bruto foram
retiradas. Com contribuição de macros desenvolvida pelo CEBRASPE – Centro Brasi-
leiro de Pesquisa em Avaliação e Seleção e de Promoção de Eventos – foram elaborados
os resultados a partir da TCT. Estes resultados são apresentados em tabelas e gráficos
individuais por item, no Capítulo 8, logo após o enunciado do respectivo item.

Cada uma dessas tabelas possui os seguintes dados: número da questão, gabarito do
item, dificuldade, índice de discriminação do item, coeficiente bisserial do item, coeficientes
bisseriais de cada alternativa e porcentagem de marcação por alternativa, inclusive da
marcação em branco.

Foram também construídas as AGI de cada item, nas quais, no eixo das abscissas,
foram inseridos os escores brutos alcançados pelos estudantes, enquanto no eixo das orde-
nadas há a porcentagem de marcação de cada alternativa de acordo com o escore de cada
grupo de estudantes. As curvas presentes nas AGIs demonstram as marcações de cada
alternativa pelo grupo de estudantes que responderam o teste, de acordo com as faixas

7.2. Coleta de dados – estudo qualitativo

107

de escores brutos totais do teste, além daquela correspondente à marcação em branco.

Estas macros foram elaboradas no EXCEL, em arquivo intitulado TCTOBMEP.xls,
que possuía a planilha de banco de dados convertida agora em tabela de zeros e uns, na
qual cada item certo recebia o valor 1 e cada item errado recebia o valor 0, objetivando
verificar o escore obtido e formalizar os dados quantitativos do estudo. Além disso, esta úl-
tima planilha foi usada em outro arquivo intitulado GraficoTCT.xls, que possuía a macro
para gerar a AGI de cada item. Ao final, as AGIs foram salvas como figuras em arquivo
PDF.

A parceria realizada com o CEBRASPE ainda possibilitou a análise utilizando-se
o software BILOGMG 1.0, que gerou os parâmetros segundo a TRI: a discriminação, a
dificuldade do item, o acerto ao acaso e a proficiência dos estudantes, tanto na escala 0-1,
quanto na escala 500-100, modelo utilizado no ENEM. Além disso, foram geradas as CCIs.
Esses dados podem ser utilizados para confirmar algum apontamento, mas principalmente
serão utilizados em estudos futuros.

A parceria acima foi requisitada junto à Coordenação de Avaliação e Pesquisa,
por meio de documento (Apêndice B). Um profissional competente acompanhou todos os
procedimentos junto com a autora deste estudo, durante 8 horas, no departamento do
próprio órgão, além de orientar nas atividades externas relativas à análise dos dados.

7.2 Coleta de dados – estudo qualitativo

Como os itens da prova são de múltipla escolha, deve-se analisar a construção dos
itens e de seus distratores com base na Engenharia de Construção de Itens (Capítulo 4)
com o objetivo de haver um confronto entre a teoria apontada e o instrumento de avaliação,
verificando se a elaboração do item pode interferir no desempenho do estudante durante
a realização da prova. E, além disso, verificar se o instrumento, diante da amostra, pode
ser utilizado como fonte de investigação com relação aos erros dos estudantes. Esses erros
foram inferidos pelas marcações nas alternativas propostas pelo elaborador, de forma a
nortear o trabalho pedagógico das escolas em estudo.

Para o estudo qualitativo dos distratores, após tomar a quantificação de marcações
obtidas na fase de coleta de dados e resultados, descritos na seção anterior, foram inferidos
e classificados os erros dos alunos.

Após a classificação dos erros em categorias segundo as propostas de Bodin, Radatz
e Casey (Seção 6.4), com distribuição dos erros por classes, o próximo objetivo de trabalho
era buscar as possíveis causas para os mesmos apoiados nos conhecimentos de Matemática
que o aluno deveria utilizar na resolução das situações propostas. Nessa fase, foi utilizada
a abordagem de Análise de Conteúdo segundo Bardin (2011) (Capítulo 5).

108

Capítulo 7. Metodologia

Para realizar um trabalho de análise segundo esse método, Bardin (2011) assinala
três etapas básicas, que podem ser subdivididas de acordo com as necessidades: pré-
análise, exploração do material e tratamento dos resultados.

Na primeira fase, o material é organizado, partindo-se da escolha dos documentos,
da formulação de hipóteses e objetivos da análise, utilizando-se a leitura “flutuante”.
Escolhidos os documentos, delimita-se o corpus, que é o campo específico sobre o qual a
atenção vai ser fixada.

No caso deste estudo, a escolha do documento já foi apontada anteriormente, a
prova de primeira fase da OBMEP 2014, nível 2. A hipótese de estudo, ou questionamento
de estudo, é se o instrumento pode ser utilizado como subsídio de uma prática de avali-
ação para aprendizagem a partir da análise dos distratores de cada item, ou seja, se na
construção de cada item o elaborador contribui para a investigação de habilidades ou de
conteúdos que precisam ser melhor trabalhados pelo professor em sala de aula.

Entre os objetivos da análise temos:

∙ investigar em que medida os itens das provas da OBMEP, nível 2, aplicadas no ano
2014 respeitam as recomendações da técnica denominada Engenharia Construção
de Itens para uma avaliação de larga escala;

∙ categorizar os erros cometidos pelo grupo de alunos que respondeu às provas da

OBMEP nas escolas pesquisadas;

∙ investigar em que medida a avaliação está coerente com o propósito estabelecido na

matriz de referência e com os objetivos da OBMEP.

O corpus de estudo foram os itens e seus distratores. A fase de exploração do
material envolve um estudo do corpus, com procedimentos de unitarização e categorização,
onde cada item foi trabalhado individualmente de acordo com os dados quantitativos
obtidos pela TCT e a Análise de Conteúdo juntamente com a análise de erros.

De acordo com essa proposta, realizou-se um estudo interpretativo, já que buscou-
se compreender como os conceitos são utilizados pelos alunos, e, por meio de suas mar-
cações, desvelar o processo escolhido para realizá-lo. Por isso, recorreu-se à Análise de
Conteúdo, por ser um procedimento de análise interpretativa que busca o sentido de um
texto confrontando duas personagens: o elaborador e o aluno.

Já na fase de tratamento dos resultados, foi realizada a descrição dos itens, que foi
feita por meio da apresentação de tabelas e gráficos com indicação das distribuições dos
índices relevantes para a TCT nas pesquisas de cunho quantitativo.

Foi realizado o levantamento de possíveis tipo de erro pressupostos nos distratores,
inferindo-se e interpretando-se sua natureza. Nessa etapa, a metodologia de construção

7.2. Coleta de dados – estudo qualitativo

109

de itens foi retomada para se fazer uma análise detalhada dos textos-base, enunciado e
da elaboração de distratores, verificando se há elementos que induzam os estudantes a
errar o item. Essa análise foi embasada também na verificação da proposta de solução
(Anexo C) dos itens segundo a banca elaboradora do certame, na qual pode se inferir as
habilidades necessárias para a correta resolução do item.

Realizar inferências foi o ponto forte para que fossem levantadas hipóteses e esta-
belecer conexões entre as informações encontradas. Semelhante a isso, na medida em que
o professor se propõe a observar e a ouvir o que o aluno faz ao resolver um problema,
ele pode realizar “inferências” em sala de aula sobre como o aluno pensou, quais são suas
dificuldades, para, então, tomar decisões referentes à sua prática pedagógica.

Ao final dessas etapas, decidiu-se ainda retomar alguns itens e refazer a aplicação
dos mesmos para alunos que realizaram o certame anteriormente, mas com o intuito
de coletar as resoluções, a produção escrita dos alunos, já que no primeiro momento os
instrumentos de análise de dados foram as folhas de respostas contendo apenas as suas
marcações. Assim, a pesquisadora retornou a três das cinco escolas em questão e reaplicou
os itens 3, 4, 5, 10, 14 e 17, conforme a atividade (Apêndice C), para sanar dúvidas
quanto à marcação em algumas alternativas, com objetivo de verificar a plausibilidade
dos mesmos. A escolha dos itens poderia ser mais ampla, pois muitos itens apresentaram
alternativas sem que a pesquisadora inferisse formas de erros associadas, buscou-se os itens
com alguns atrativos na formação, mas que apresentassem valores muito discrepantes dos
processos de solução.

Como esta confirmação foi realizada no ano de 2015, apenas 280 listas de exercícios
foram aplicadas. Todos os participantes foram informados da intenção do estudo. No geral,
apenas as operações eram utilizadas como rascunho. Mesmo não possuindo justificativas
bem formalizadas, a Análise do Conteúdo expresso nas resoluções dos alunos possibilitou
confirmar algumas possíveis justificativas para o uso do distrator.

Analisar a produção escrita de alunos em questões de Matemática contribui, entre
outras coisas, para que o professor busque entender as respostas dadas e o porquê das
estratégias escolhidas. Com essa atitude investigativa, o professor pode (re)conhecer que
conhecimentos os alunos já possuem e quais ainda estão em construção.

8 Análise de Resultados

111

8.1 Análise Geral do Instrumento

O instrumento analisado encontra-se no Anexo B deste trabalho, e os itens serão
investigados com relação à amostra em questão, não objetivando uma generalização de
todos os instrumentos da OBMEP, nem deste instrumento em particular aplicado em todo
o território nacional, mas no universo de 1.658 alunos e suas respectivas escolas.

A amostra não é aleatória, mas de conveniência, e muito pequena para ser repre-
sentativa do universo. De acordo com a Tabela 4, o público alvo do estudo não chega a
0,1% do total de respondentes neste certame. Apesar disso, algumas inferências acerca do
comportamento da prova como um todo serão feitas, com as devidas ressalvas.

Em relação à verificação do respeito aos pressupostos da Engenharia de Itens
(Capítulo 4), tem-se um resultado descritivo muito relevante, podendo ser utilizado como
fundamentação para estruturação de um exame que contribua para uma seleção criteriosa
e, ainda, para uma avaliação que seja coloca a serviço das aprendizagens dos estudantes.

No que diz respeito à prática pedagógica, também serão feitas inferências sobre
os erros dos estudantes de forma a embasar o uso desse instrumento como referência aos
docentes, nas referidas instituições. O estudo serve também como um alerta da relevância
de construção de itens bem elaborados para a prática docente em Matemática no nível
da sala de aula.

8.2 Análise Geral da OBMEP-2014, nível 2, primeira fase

8.2.1 Matriz de Referência

Após pesquisa nos meios virtuais, não foi encontrada uma matriz de referência para
construção dos 20 itens que compõem a primeira fase da prova da OBMEP. Realizou-se
um contato com os responsáveis pela elaboração do certame, que divulgaram por meio de
resposta (Anexo D) a questionário de entrevista (Apêndice D), que não há um documento
formalizado que aponte uma matriz de referência para elaboração das provas da OBMEP,
mas respeitam-se as habilidades e competências por ano/série apresentadas nos PCN.

A metodologia de trabalho do Comitê de Provas da OBMEP é bastante
diferente de outras avaliações em larga escala realizadas no Brasil. Em
uma visão macro, a OBMEP segue rigorosamente os Parâmetros Curri-
culares Nacionais, segundo a seguinte divisão: (...)

112

Capítulo 8. Análise de Resultados

Mais especificamente, no que se refere aos conteúdos específicos são con-
sultados os Guias Curriculares dos Estados Brasileiros, atentando para
não levar em consideração as diferenças regionais, mas sim o corpo de
conhecimentos adequados ao exercício consciente da cidadania, corres-
pondentes a cada faixa etária. Em outras palavras, os conhecimentos
avaliados nas provas da OBMEP são os mesmos que constam nos livros
didáticos aprovados pelo PNLD; entretanto as questões das provas in-
tencionalmente não são livrescas, exigindo criatividade e inovação, com
ênfase no raciocínio e na capacidade de entender e tratar situações, e não
na repetição mecânica de procedimentos (Trecho retirado da resposta ao
questionamento sobre a existência de uma matriz de referência, pergunta
1).

Como não foi apresentada a matriz de referência, ao analisar os itens individu-
almente, para se inferir as habilidades necessárias para a solução, buscou-se apoio nas
habilidades e descritores sugeridas em outros certames e nos PCN. Entre os certames es-
colhidos, incluem-se aqueles que contemplam conceitos matemáticos em sua elaboração,
tais como o Enem e a Prova Brasil, apresentados em (RABELO, 2013).

8.2.2 Análise global dos itens

Todos os itens são inéditos. O tempo previsto para realização da avaliação con-
templa os 4 minutos geralmente sugeridos em uma prova dessa natureza. Todos os itens
atendem o correto uso da norma culta da Língua Portuguesa nos seus diversos quesitos.

Os 20 itens apresentados são de múltipla escolha, para os quais os comandos apre-
sentam uma pergunta direta e, indiscutivelmente, com apenas uma única alternativa cor-
reta. Os enunciados não apresentam termos que expressam negação, apresentam um único
problema a ser solucionado, não apresentando falha técnica.

Há quatro itens convencionais: 3, 9, 13 e 18. Os demais apresentam texto-base

contextualizado. O item 4 apresentou uma exemplificação do processo de solução.

Os textos-base são curtos, integrais e adequados à linguagem dos respondentes. A
adequação ao nível dos respondentes será discutida na análise individual dos itens, a ser
apresentada no Capítulo 8.3.

Os dados apresentados no texto-base tem razoabilidade e, apenas no item 10, há
um dado expresso desnecessário à resolução, os 32,5 litros. Quanto à clareza, infere-se que
os itens 10 e 20 possuem textos que não são muito claros para os respondentes.

Os nomes utilizados não se referem a pessoas públicas, nem são jocosos.

8.2.3 As alternativas

Na sua maioria, as alternativas são organizadas na forma trapezoidal, a exceção
dos itens 6 e 9, que não respeitam essa formatação. Todos as alternativas atendem ao

8.2. Análise Geral da OBMEP-2014, nível 2, primeira fase

113

correto uso da norma culta da Língua Portuguesa nos seus diversos quesitos, no entanto
não apresentam o ponto final nas respostas não numéricas, ou seja não completam ade-
quadamente o comando.

As alternativas apresentam, na sua maioria, estrutura semelhante, exceto nos itens
9, 12, 17 e 18, que não cumprem esta sugestão de elaboração. Há a presença marcante
de uso de numeração consecutiva nas alternativas e uso de respostas numéricas na ordem
crescente.

Quanto à plausibilidade dos distratores e à presença de fatores de atração, haverá

comentários a respeito na análise individual dos itens.

Mas de uma forma geral, foi apontado que os distratores não são construídos com
base na Engenharia de Itens, conforme depreende-se da resposta dada pelo coordenador
a uma das questões do questionário encaminhado:

A metodologia utilizada na OBMEP é diferente da do ENEM ou de
outros testes TRI. Intencionalmente não são colocados distratores nas
questões de múltipla escolha da primeira fase. O comitê de provas é
atento para evitar distratores, exceto em ocasiões muito raras e espe-
ciais. Evita-se, a todo custo, canalizar o aluno a respostas que não se-
jam as corretas ou que sejam atraídos por interpretações não presentes
nos enunciados (Trecho retirado da resposta ao questionamento sobre a
construção de distratores, pergunta 6).

Esta resposta sugere que a equipe de elaboradores da OBMEP pode estar enten-
dendo o conceito de distrator como “peguinha”, e não o sentido apresentado por Rabelo
(2013) na Seção 4.7 deste trabalho. A ideia de canalizar à respostas incorretas não está
vinculada à plausibilidade na construção dos distratores.

Quanto ao balanceamento dos itens, de acordo com o gabarito oficial apresentado
na solução da prova (Anexo C) e na Tabela 12, a distribuição de respostas por alternativa
foi bem equilibrada.

8.2.4 Análise quantitativa – TCT

As tabelas a seguir, obtidas na análise pela TCT, apresentam um resumo quanti-

tativo da amostra.

A Tabela 8 apresenta o número de candidatos, da amostra, que realizaram o cer-
tame distribuídos de acordo com o escore obtido por cada um. Associado a estes também
o percentual de candidatos em cada faixa e a frequência absoluta acumulada. Esta orga-
nização possibilita a visualização dos 27% dos candidatos que obtiveram as maiores e as
menores notas, respectivamente.

114

Capítulo 8. Análise de Resultados

Tabela 8 – Análise de escore bruto dos candidatos

Escore
Bruto

Número de
Candidatos

Frequência
Relativa

Frequência
acumulada

20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
0

0
1
0
3
3
7
8
7
7
11
9
14
226
112
224
318
361
278
198
67
4

0,0000
0,0006
0,0000
0,0018
0,0018
0,0042
0,0048
0,0042
0,0042
0,0066
0,0054
0,0084
0,0157
0,0676
0,1351
0,1918
0,2177
0,1677
0,1194
0,0404
0,0024

0,0000
0,0006
0,0006
0,0024
0,0042
0,0084
0,0132
0,0174
0,0217
0,0283
0,0337
0,0422
0,0579
0,1254
0,2605
0,4523
0,6700
0,8377
0,9571
0,9975
1,0000

Percebe-se que os 27% que obtiveram maiores notas (𝑃𝑆𝑈 𝑃 ) obtiveram um escore
de 5 ou mais no certame. Enquanto que os 27% com menores notas (𝑃𝐼𝑁 𝐹 ) obtiveram
escores menores que 4.

Tabela 9 – Análise Geral da Prova da OBMEP-2014 a partir da TCT na amostra

Item

𝐷

𝐼𝐷

𝑟𝑏

𝑃𝑆𝑈 𝑃

𝑃𝐼𝑁 𝑇

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

0,463
0,214
0,234
0,235
0,179
0,270
0,415
0,347
0,152
0,185
0,197
0,171
0,174
0,162
0,297
0,201
0,106
0,124
0,228
0,180

0,105
0,092
0,147
0,117
0,071
0,190
0,065
0,101
0,090
0,117
0,142
0,108
0,105
0,067
0,088
0,040
0,037
0,075
0,081
0,035

0,416
0,411
0,506
0,456
0,410
0,547
0,360
0,418
0,465
0,311
0,479
0,477
0,484
0,451
0,406
0,261
0,293
0,291
0,322
0,206

0,285
0,102
0,102
0,124
0,099
0,097
0,269
0,207
0,073
0,066
0,068
0,073
0,079
0,091
0,176
0,119
0,060
0,049
0,124
0,108

0,391
0,195
0,249
0,241
0,169
0,287
0,333
0,308
0,163
0,183
0,209
0,181
0,184
0,159
0,264
0,159
0,097
0,124
0,205
0,143

A Tabela 9 mostra que o item mais fácil da prova tem índice de dificuldade de
46%, que trata-se de um item de dificuldade mediana. De acordo com a classificação
recomendada na literatura, a prova apresentou a seguinte distribuição: nenhum item fácil;
três itens medianos e dezesseis itens difíceis. Em geral, segundo Rabelo (2013), o texto
deveria apresentar cerca de 30% de itens fáceis, 40% de itens medianos e 30% de itens
difíceis. A Tabela 10 mostra a distribuição dos itens de acordo com a dificuldade.

8.2. Análise Geral da OBMEP-2014, nível 2, primeira fase

115

Tabela 10 – Distribuição dos itens em relação ao parâmetro dificuldade, segundo a TCT.

Classificação

Muito Fácil
Fácil
Moderado
Difícil
Muito Difícil

Intervalo de
dificuldade 𝐷

𝐷 ≥ 0, 9
0, 7 ≤ 𝐷 < 0, 9
0, 3 ≤ 𝐷 < 0, 7
0, 1 ≤ 𝐷 < 0, 3
𝐷 < 0, 1

Itens

Percentual de
itens na prova

1, 7 e 8
2 a 6 e 9 a 20

0%
0%
15%
85%
0,00%

Quanto à discriminação 𝐼𝐷 (Tabela 9), de acordo com o poder de discriminação dos
itens, todos os itens deveriam ser descartados, pois apresentam índice de discriminação
𝐼𝐷 < 0, 2. Um resultado alarmante, mas justificável devido a proximidade de faixa de
escore entre os 27% candidatos com maiores notas e os 27% dos candidatos com menores
notas, onde a distancia entre escore de 2 pontos de acordo com a Tabela 8. A Tabela 11
apresenta a distribuição dos itens de acordo com o índice de discriminação via TCT.

Tabela 11 – Distribuição dos itens em relação a discriminação, pela TCT.

Classificação

Intervalo de
discriminação 𝐼𝐷

Item deficiente
Item marginal
Item bom, mas sujeito a aprimora-
mento
Item bom

até 0,2
0,2 ≤ 𝐼𝐷 < 0,3
0,3 ≤ 𝐼𝐷 < 0,4

𝐼𝐷 ≥ 0,4

Itens

1 ao 20

Percentual de
itens na prova

100%
0%
0%

0%

Em compensação, o coeficiente bisserial do item 𝑟𝑏 (Tabela 9), que se relaciona
com a marcação do item certo, demonstra que quatorze itens tem características de itens
bons quanto à discriminação, três itens estão sujeitos a aprimoramento e três marginais,
sujeitos a reelaboração.

De acordo com a Tabela 12, percebe-se 7 itens com coeficientes bisseriais positivos
em alternativas errôneas, o que será analisado na seção de estudo individual dos itens, para
justificar a presença ou não de fatores de atração para as alternativas erradas de indivíduos
com escore mais alto, que também pode ser verificado na Tabela 13, que evidencia presença
de proporções elevadas de marcação em alternativas incorretas.

116

Capítulo 8. Análise de Resultados

Tabela 12 – Coeficientes bisseriais das alternativas de cada item.

Item Gabarito

𝑟𝑏(𝐴)

𝑟𝑏(𝐵)

𝑟𝑏(𝐶)

𝑟𝑏(𝐷)

𝑟𝑏(𝐸)

𝑟𝑏(𝐵𝑟𝑎𝑛𝑐𝑜)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

B
D
D
B
A
D
A
A
E
B
C
D
E
C
C
C
C
E
B
D

-0,268
-0,126
-0,154
-0,100
0,410
-0,231
0,360
0,418
-0,112
-0,139
-0,109
-0,202
-0,067
-0,185
-0,169
-0,019
-0,125
-0,149
-0,086
-0,138

0,416
-0,146
-0,174
0,456
-0,085
-0,126
-0,136
-0,142
-0,162
0,311
-0,120
-0,093
-0,029
-0,072
-0,113
-0,028
-0,051
0,004
0,322
0,006

-0,148
-0,096
-0,086
-0,141
-0,022
-0,149
-0,171
-0,185
0,033
-0,095
0,479
-0,091
-0,193
0,451
0,406
0,261
0,293
0,023
-0,090
0,005

-0,179
0,411
0,506
-0,162
-0,117
0,547
-0,124
-0,149
-0,143
0,037
-0,076
0,477
-0,122
-0,141
-0,105
-0,088
0,080
-0,069
-0,078
0,206

-0,159
-0,084
-0,144
-0,148
-0,213
-0,183
-0,169
-0,142
0,465
-0,132
-0,169
0,018
0,484
0,023
-0,145
-0,135
-0,044
0,291
-0,115
-0,051

-0,132
-0,107
-0,138
-0,213
-0,075
-0,039
-0,263
-0,192
-0,246
-0,120
-0,240
-0,070
-0,202
-0,245
-0,266
-0,103
-0,112
-0,106
-0,218
-0,220

Tabela 13 – Porcentagem de marcação nas alternativas de cada item

Item Gabarito

𝑝(𝐴)

𝑝(𝐵)

𝑝(𝐶)

𝑝(𝐷)

𝑝(𝐸)

𝑝(𝐵𝑟𝑎𝑛𝑐𝑜)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

B
D
D
B
A
D
A
A
E
B
C
D
E
C
C
C
C
E
B
D

0,203
0,095
0,174
0,265
0,179
0,207
0,415
0,347
0,224
0,104
0,249
0,254
0,160
0,187
0,203
0,250
0,467
0,230
0,142
0,230

0,463
0,185
0,282
0,235
0,162
0,192
0,094
0,195
0,200
0,185
0,255
0,264
0,197
0,329
0,151
0,189
0,095
0,235
0,228
0,218

0,166
0,253
0,154
0,280
0,340
0,202
0,145
0,218
0,240
0,251
0,197
0,229
0,259
0,162
0,297
0,201
0,106
0,200
0,289
0,194

0,107
0,214
0,234
0,150
0,179
0,270
0,098
0,128
0,179
0,256
0,157
0,171
0,204
0,178
0,186
0,159
0,142
0,203
0,242
0,180

0,058
0,245
0,147
0,065
0,138
0,127
0,242
0,103
0,152
0,195
0,134
0,075
0,174
0,141
0,159
0,198
0,186
0,124
0,092
0,175

0,000
0,008
0,009
0,005
0,003
0,002
0,006
0,008
0,005
0,008
0,008
0,007
0,006
0,004
0,004
0,003
0,005
0,009
0,006
0,004

Esse fato, quando ocorre, segundo Rodrigues, não significa que um item tem um
problema de elaboração, mas pode indicar uma falta coletiva de habilidades diante ao
objetivo de aprendizagem verificado.

Assim, é importante que, em conjunto com a AGI, seja realizada uma
análise pedagógica desses itens. Essas análises poderão dar indicativos
do processo mental utilizado para a solução da questão, associando-se o
escore total e as respostas dos distratores (RODRIGUES, 2006).

Assim se faz necessário realizar uma análise mais detalhada de cada item, utili-
zando dados da TCT, da AGI por item, as recomendações constantes da engenharia de
itens, a Análise de Conteúdo e do erro, para realizar um retrato do item frente ao grupo

8.2. Análise Geral da OBMEP-2014, nível 2, primeira fase

117

pesquisado, o que pode contribuir para os elaboradores na confecção de novos instrumen-
tos da OBMEP no futuro.

118

Capítulo 8. Análise de Resultados

8.3 Análise Individualizada dos Itens da OBMEP

A seguir serão apresentadas uma análise individualizada dos itens presentes na
prova de primeira fase da OBMEP 2014, nível 2, de acordo com a investigação do grupo
pesquisado, embasando-se na Análise de Conteúdo, na Análise do Erro, dos pressupostos
da Engenharia de Construção de Itens e pela TCT.

8.3.1 Item 1

Paula numerou todas as casas do tabuleiro quadrado abaixo, da es-
querda para a direita e de cima para baixo, começando com o número 1. A
casa central recebeu o número 5. Se ela fizer o mesmo com outro tabuleiro
quadrado com 49 casas, qual número será escrito em sua casa central?

A) 23
B) 25
C) 27
D) 29
E) 31

Análise do Item 1

Questão Gabarito Dificuldade

Q1

B

0,463
Acerto: 27% maiores notas
0.285

𝑟𝑏(𝐴)
-0,268
𝑝(𝐴)
0,203

𝑟𝑏(𝐵)
0,416
𝑝(𝐵)
0,463

𝑟𝑏(𝐶)
-0,148
𝑝(𝐶)
0,166

Índice D
0,105

Bisserial
0,416

Acerto: 27% menores notas
0,391

𝑟𝑏(𝐷)
-0,179
𝑝(𝐷)
0,107

𝑟𝑏(𝐸)
-0.159
𝑝(𝐸)
0,058

𝑟𝑏()
-0,132
𝑝()
0,000

A habilidade necessária para resolver a situação proposta é a de ordenar os núme-
ros naturais e escolher o termo central da sequência de números consecutivos. Pode ser
interpretada, com o enfoque do tratamento de informação, como a mediana. Desta forma
podem ser verificadas as habilidades relacionadas a coleta, a organização e a descrição de
dados, ou seja, calcular medidas de tendência central.

Na solução apresentada pelo elaborador (Anexo C), há também, a possibilidade

de interpretação e resolução da situação-problema utilizando uma expressão algébrica.

A alternativa correta discriminou bem, seu coeficiente bisserial foi de 0,416, e a
AGI também denota que há uma concentração de itens errôneos entre os estudantes de
proficiência menor.

No que se refere aos distratores há problemas na construção do item, pois a al-
ternativa E teve uma marcação muito baixa. Infere-se que na escolha dos distratores não

8.3. Análise Individualizada dos Itens da OBMEP

119

houve construção plausível, apenas o ordenamento de números ímpares a partir do 23.

Após realizar várias tentativas de erro, inferiu-se um erro onde o aluno construiu
tabelas 3 × 3, e escreveu os números até 49, na mesma ordenação do exemplo. Onde
apareceram 5 tabelas completas, e ao relacionar desta forma o número 23 apareceu no
quadrado central da terceira tabela. Um erro relacionado a: lógica e raciocínio, segundo
Bodin (1997), aplicação de regras irrelevantes, segundo Radatz (1979) e, com exceção ao
erro relacionado a formulação da questão, todos os demais de acordo com Casey (CLE-
MENTS, 1980 apud CURY, 2007).

A alternativa E deveria ser descartada de acordo com os apontamento da Enge-
nharia de Itens (Capítulo 4) Como esta questão não apresenta muitos obstáculos em sua
resolução, a situação-problema deveria ser ampliada, pois há a dificuldade para elabo-
rar 4 distratores plausíveis, contribuindo para a análise pedagógica dos possíveis erros e
também para um instrumento de seleção com mais qualidade.

Todos os fatos acima podem ter contribuído para o nível de dificuldade – mediano,
como a marcação nas últimas alternativas foram baixas, a concentração porcentual na
alternativa correta aumenta proporcionalmente elevando a facilidade do item.

120

8.3.2 Item 2

Capítulo 8. Análise de Resultados

Ana Maria apertou as teclas de sua calculadora

e o re-
sultado 2014 apareceu no visor. Em seguida, ela limpou o visor e fez aparecer
novamente 2014 com uma multiplicação de dois números naturais, mas, desta
vez, apertando seis teclas em vez de sete. Nesta segunda multiplicação, qual
foi o maior algarismo cuja tecla ela apertou?

A) 5
B) 6
C) 7
D) 8
E) 9

Análise do Item 2

Questão Gabarito Dificuldade

Q2

D

0,214
Acerto: 27% maiores notas
0.102

𝑟𝑏(𝐴)
-0,126
𝑝(𝐴)
0,095

𝑟𝑏(𝐵)
-0,146
𝑝(𝐵)
0,185

𝑟𝑏(𝐶)
-0,096
𝑝(𝐶)
0,253

Índice D
0,092

Bisserial
0,411

Acerto: 27% menores notas
0,195
𝑟𝑏(𝐸)
-0.084
𝑝(𝐸)
0,245

𝑟𝑏(𝐷)
0,411
𝑝(𝐷)
0,214

𝑟𝑏()
-0,107
𝑝()
0,008

O nível de dificuldade foi de 0,214, caracterizando o item como difícil.

As habilidades exploradas no item são: resolver um problema com números na-
turais envolvendo diferentes significados das operações, no caso multiplicação; aplicar a
decomposição de número natural em fatores primos; empregar o conceito de algarismo e
valor absoluto do número.

A alternativa correta discriminou bem, seu coeficiente bisserial foi de 0,411, e a
AGI também denota que há uma concentração de itens errôneos entre os estudantes de
proficiência menor. No que se refere aos distratores há problemas na construção do item,
pois a alternativa A teve uma marcação muito baixa: 9% dos respondentes a escolheram.

Com relação a interpretação do item, sabe-se que 2014 decomposto em fatores
primos pode ser escrita unicamente, a menos da ordem dos fatores, da seguinte forma
2 × 19 × 53. Assim existem somente quatro formas possíveis de se fazer aparecer 2014
na calculadora como uma multiplicação de dois números naturais, onde a última opção
corresponde a situação proposta:

Usando sete teclas: 1 × 2014 =

Usando sete teclas: 2 × 1007 =

8.3. Análise Individualizada dos Itens da OBMEP

121

Usando sete teclas: 19 × 106 =

Usando seis teclas: 38 × 53 =

A partir desta solução apresentada, infere-se que:

∙ ao marcar a alternativa A, o aluno compreendeu o processo de resolução, conseguiu
fatorar o número corretamente, escolheu a opção que era exigida entre as fatorações,
mas não aplicou o conceito de valor absoluto do algarismo e escolheu na verdade o
número que possui maior valor posicional na multiplicação 38 × 53 =, que é o número
5. Em uma avaliação formativa na perspectiva de análise de erro, o distrator poderia
ser descartado caso a habilidade verificada fosse a fatoração de números primos, este
é um exemplo de “peguinha”, pois o aluno demonstrou o conhecimento necessário
para resolvê-la mas se confundiu por ver um possível resultado na sua resolução, de
acordo com a Seção 4.7);

∙ ao marcar a alternativa C, o aluno também fatorou corretamente, mas se confundiu
na escolha da opção correta de número de teclas apertadas e na opção 2 × 1007,
onde o maior algarismo é o sete. Analogamente pode ter ocorrido na alternativa
E, mas neste item ainda tem o atrativo desta fatoração ser o exemplo dado no
texto-base. O que justificaria a escolha destes distratores;

∙ ao marcar B, o estudante também fatorou corretamente , mas não se atentou ao
número de teclas para serem acionadas e utilizou a forma 38 × 53 = , e escolheu o
número 8.

Logo as alternativas A e E poderiam ser descartadas, de acordo com Rabelo (2013),
ou aconselha-se a reelaboração dos valores apresentados no texto base para diminuir o
fator de atração da alternativa E. Assim o item poderia ser reelaborado na perspectiva
da Engenharia de itens, o que caracteriza um item com problemas na construção para ser
utilizado numa avaliação formativa que utilize análise de erros e em um certame seletivo.

A marcação da alternativa A implica, de acordo com os apontamentos acima, que
erro de saber o conceito de algarismo, ver patamares de identificação de erros segundo
Bodin (1997), Seção 6.4. E segundo os mecanismos de processamento de informação de
Radatz (1979), é um erro devido ao domínio deficiente de conteúdos, fatos e habilidades
consideradas como pré-requisito.

Para as alternativas B e C, podem ser classificados quanto ao erro da seguinte
forma: erros de lógica ou de raciocínio, erros devido a associações incorretas ou rigidez
de pensamento e manipulação das habilidades, respectivamente segundo Bodin (1997),
Radatz (1979) e Casey (CLEMENTS, 1980 apud CURY, 2007).

122

8.3.3 Item 3

Capítulo 8. Análise de Resultados

Na figura, os pontos A, B e C estão alinhados. Qual é a soma dos ângulos

marcados em cinza?

A) 120o
B) 180o
C) 270o
D) 360o
E) 540o

Análise do Item 3

Questão Gabarito Dificuldade

Q3

D

0,234
Acerto: 27% maiores notas
0,102

𝑟𝑏(𝐴)
-0,154
𝑝(𝐴)
0,174

𝑟𝑏(𝐵)
-0,174
𝑝(𝐵)
0,282

𝑟𝑏(𝐶)
-0,086
𝑝(𝐶)
0,154

Índice D
0,147

Bisserial
0,506

Acerto: 27% menores notas
0,249
𝑟𝑏(𝐸)
-0,144
𝑝(𝐸)
0,147

𝑟𝑏(𝐷)
0,506
𝑝(𝐷)
0,234

𝑟𝑏()
-0,138
𝑝()
0,009

A alternativa correta discriminou bem, seu coeficiente bisserial foi de 0,506, e a
AGI também denota que há uma concentração de itens errôneos entre os estudantes de
proficiência menor.

Infere-se que as habilidades necessárias a resolução do item são:utilizar conheci-
mentos geométricos de espaço e forma na seleção de argumentos propostos como solução
de problema, resolver problema utilizando a propriedade dos polígonos: soma dos seus ân-
gulos internos e o ângulo externo de triângulos. E no tocante a plausibilidade em construir
os distratores:

∙ em relação a alternativa A, o aluno apenas considerou que os ângulos são de 20

graus, o que não é uma abordagem plausível;

∙ ao marcar o item B, que o estudante conhecia a propriedade da soma dos ângulos
internos de um triângulo, que é 180o, mas não analisou a situação proposta. Erro
ligados à utilização adequada ou não dos saberes ou do saber-fazer, erros devido a
associações incorretas ou rigidez de pensamento;

∙ ao marcar a alternativa C, poderia ter assumido erroneamente a característica dos
triângulos em estudo, confundindo com a propriedades dos triângulos retângulos, e
categorizando-os como triângulos retângulos erroneamente, considerou que os ân-
gulos sobre a hipotenusa somam 90o, e como são três triângulos obteve como total
270o (ver Figura 12);

8.3. Análise Individualizada dos Itens da OBMEP

123

Figura 12 – Solução apresentada pelo aluno E2A18.

∙ já na alternativa E, poderia ter assumido que três triângulos quaisquer somam 540o,

sem observar que nem todos os ângulos estavam destacados.

O nível de dificuldade foi de 0,234, logo o item foi difícil. Com relação aos distrato-
res, com exceção ao primeiro que poderia ser reelaborado de acordo com a Seção 4.7, todos
os outros poderiam ser justificados e analisados no tocante ao erro para reestruturação
dos conceitos.

Assim os caminhos errôneos preestabelecidos nos distratores C e E podem ser
classificados assim: erros de saber-fazer, erros ligados à utilização adequada ou não dos
saberes ou do saber-fazer, erros devido a associações incorretas ou rigidez de pensamento;
erros devido a dificuldade de obter informação espacial; seleção das estratégias requeridas
e manipulação das habilidades.

Sugere-se também, de acordo com Rabelo (2013), que haja uma contextualização,

para que o aluno mobilize competências e habilidades para sua resolução.

124

8.3.4 Item 4

Capítulo 8. Análise de Resultados

A sequência -6, 12, -18, 24, -30, 36, ... é obtida a partir dos múltiplos
positivos de 6, multiplicando-se os termos nas posições ímpares por -1. Observe
na figura que a soma dos dois primeiros termos da sequência é igual a 6 e a
soma dos três primeiros termos é igual a -12. Quantos termos consecutivos
dessa sequência devemos somar a partir do primeiro, para obter 180 como
resultado?

A) 30
B) 60
C) 90
D) 120
E) 180

Análise do Item 4

Questão Gabarito Dificuldade

Q4

B

0,235
Acerto: 27% maiores notas
0,124

𝑟𝑏(𝐴)
-0,100
𝑝(𝐴)
0,265

𝑟𝑏(𝐵)
0,456
𝑝(𝐵)
0,235

𝑟𝑏(𝐶)
-0,141
𝑝(𝐶)
0,280

Índice D
0,117

Bisserial
0,456

Acerto: 27% menores notas
0,241

𝑟𝑏(𝐷)
-0,162
𝑝(𝐷)
0,150

𝑟𝑏(𝐸)
-0,148
𝑝(𝐸)
0,065

𝑟𝑏()
-0,213
𝑝()
0,005

A alternativa correta discriminou bem, seu coeficiente bisserial foi de 0,456, e a
AGI também denota que há uma concentração de itens errôneos entre os estudantes de
proficiência menor.

No que se refere aos distratores há problemas na construção do item, pois a alter-
nativa E que teve uma marcação muito baixa, embora apresentasse um fator de atração,
pois o valor 180 está no comando do item, e sua reelaboração é indicada.

No tocante a plausibilidade em construir os distratores, vê se em relação a solução

proposta pelo elaborador:

podemos organizar as somas dos termos da sequência aos pares: (-6+12)+(-
18+24)+(-30+36)+(-42+48)+ . . . Observamos que, para cada par de
termos consecutivos, arranjados como acima, a soma é 6. Assim, para
obter 180 devemos somar os 180 / 6 = 30 primeiros pares, ou seja, os
30 × 2 = 60 primeiros termos da sequência (Anexo C).

∙ que ao escolher a alternativa A, o candidato realizou a adição das parcelas até
encontrar o 180, contabilizando 30 parcelas, como na solução do aluno apresentada
na Figura 13;

8.3. Análise Individualizada dos Itens da OBMEP

125

Figura 13 – Solução apresentada pelo aluno E1A11.

∙ que ao escolher a alternativa C, o aluno até observou que a soma de pares con-
secutivos deveria ser realizada e erroneamente dividiu 180 por 2 (característico do
pareamento) e obteve 90;

∙ e nada foi inferido ao resultado 120, alternativa D.

Os erros apresentados nos distratores justificados podem ser categorizados assim:
na alternativa A - erros ligados à utilização adequada ou não dos saberes ou do saber-fazer
e erros de lógica ou de raciocínio; e para a alternativa C - erros de lógica ou de raciocínio
e erros devido a aplicações de regras ou estratégias irrelevantes, leitura e compreensão e
para a alternativa E erro de formulação da questão, conforme Seção 6.4.

O nível de dificuldade foi de 0,235, logo o item foi difícil, embora a as habilidades
necessárias para resolução seriam: identificar padrões numéricos e realizar operações arit-
méticas com números inteiros. Talvez o exemplo dado na figura e o número desejado de
parcelas não tenham contribuído para a interpretação da situação proposta.

126

8.3.5 Item 5

Capítulo 8. Análise de Resultados

Os irmãos Luiz e Lúcio compraram um terreno cercado por um muro
de 340 metros. Eles construíram um muro interno para dividir o terreno em
duas partes. A parte de Luiz ficou cercada por um muro de 260 metros e a de
Lúcio, por um muro de 240 metros. Qual é o comprimento do muro interno?

A) 80 m
B) 100 m
C) 160 m
D) 180 m
E) 200 m

Análise do Item 5

Questão Gabarito Dificuldade

Q5

A

0,179
Acerto: 27% maiores notas
0,099

𝑟𝑏(𝐴)
0,410
𝑝(𝐴)
0,179

𝑟𝑏(𝐵)
-0,085
𝑝(𝐵)
0,162

𝑟𝑏(𝐶)
-0,022
𝑝(𝐶)
0,340

Índice D
0,071

Bisserial
0,410

Acerto: 27% menores notas
0,169
𝑟𝑏(𝐸)
-0,213
𝑝(𝐸)
0,138

𝑟𝑏(𝐷)
-0,117
𝑝(𝐷)
0,179

𝑟𝑏()
-0,075
𝑝()
0,003

A alternativa correta apresentou o coeficiente bisserial de 0,41, e a AGI denota que
há uma concentração de itens errôneos entre os estudantes de proficiência menor, mesmo
com o nível de dificuldade de 0,179 houve uma boa discriminação.

As habilidades, inferidas, deste item são: resolver problema envolvendo o cálculo
de perímetro de figuras planas, ou resolver situação-problema que envolva conhecimentos
geométricos de grandezas e medidas, ou utilizar conhecimentos geométricos de espaço e
forma na seleção de argumentos propostos como solução de problemas do cotidiano, ou
ainda, resolver situação-problema cuja modelagem envolva conhecimentos algébricos.

No que se refere aos distratores, vê se em relação a solução proposta pelo elabora-

dor:

somando as metragens dos muros de Luiz e de Lúcio, obtemos 240 + 260
= 500 m. Neste total estão computados o comprimento do muro original
(de 340 m) mais duas vezes o comprimento do muro interno. Logo, o
comprimento do muro interno é igual a [500 - 340] / 2 = 80 metros.

Podemos também resolver algebricamente: como o muro interno per-
tence ao cercado dos terrenos de Luiz e de Lúcio, se x é a medida do
muro interno, temos:

340 + 2x = 240 +260 Portanto x = 80 m (Anexo C).

∙ e levando em consideração os percentuais de marcação acima da alternativa correta,

8.3. Análise Individualizada dos Itens da OBMEP

127

infere-se o fator atrativo da alternativa C, pois 160 é o valor encontrado na operação
500 – 340. Traço que caracteriza um “peguinha” de acordo com a Seção 4.7, para
estudantes com um escore mais elevado que poderiam estar resolvendo de forma
correta e ao encontrar um valor presente nas alternativas, realiza a marcação pre-
cipitada. Fato observado AGI, onde aluno com escorre 15 realizou esta marcação,
assim é considerado um distrator não plausível devido ao “peguinha”;

∙ a marcação da alternativa B pode ser devida a diferença entre o perímetro total e
o muro de Lúcio. O mesmo pode ter ocorrido aos candidatos que marcaram a letra
A, que é o gabarito, com relação a diferença entre o muro total e o muro de Luiz;

∙ a marcação da alternativa D pode ser devida ao cálculo das diferenças entre o muro
total e o de Lúcio, igual a 80 metros para o muro interno, e do muro total com o
de Luiz , falam 100 metros para o muro interno. Que ao adicionar estes dois valores
totaliza-se 180 metros (ver Figuras 14 e 15).

Figura 14 – Solução apresentada pelo aluno E1A15.

Figura 15 – Solução apresentada pelo aluno E2A11.

∙ no que se refere a última alternativa nada foi inferido. Embora um aluno tenha
apresentado este erro durante a reaplicação do item. Como vemos na Figura 16, é

128

Capítulo 8. Análise de Resultados

um erro que abrange o não entendimento do problema e também de saber realizar
a operação de divisão de números naturais.

Figura 16 – Solução da questão proposta pelo aluno E1A12.

Assim, para haver maior conformidade com a Engenharia de itens (Capítulo 4),
sugere-se aplicar outros valores como dados, para que alunos com baixa proficiência não
acertem utilizando erros de interpretação. E a também, sugere se a retirada de alternativas
que caracterizem valores encontrados em procedimentos corretos, mas obtidas no meio do
percurso de resolução.

Quanto erros em análise nos distratores podem ser classificados assim, para a

marcação na alternativa:

B - erros ligados à utilização adequada ou não dos saberes ou do saber-fazer, erros
de lógica ou de raciocínio, erro devido a dificuldade de obter informação espacial, erros
devido a associações incorretas e aplicações de estratégias irrelevantes;

C - erro ligado a formulação e apresentação da solução;

D - erros ligados à utilização adequada ou não dos saberes ou do saber-fazer, erro
devido a dificuldade de obter informação espacial, erros devido a associações incorretas
e aplicações de estratégias irrelevantes, leitura, compreensão e seleção de estratégias, de
acordo com a Seção 6.4.

8.3. Análise Individualizada dos Itens da OBMEP

129

8.3.6 Item 6

Cinco meninas não estão totalmente de acordo sobre a data da prova

de Matemática.

∙ Andrea diz que será em agosto, dia 16, segunda- feira;

∙ Daniela diz que será em agosto, dia 16, terça-feira;

∙ Fernanda diz que será em setembro, dia 17, terça- feira;

∙ Patrícia diz que será em agosto, dia 17, segunda- feira;

∙ Tatiane diz que será em setembro, dia 17, segunda-feira.

Somente uma está certa, e as outras acertaram pelo menos uma das informa-
ções: o mês, o dia do mês ou o dia da semana. Quem está certa?

A) Andrea
B) Daniela
C) Fernanda
D) Patrícia
E) Tatiane

Análise do Item 6

Questão Gabarito Dificuldade

Q6

D

0,270
Acerto: 27% maiores notas
0,097

𝑟𝑏(𝐴)
-0,231
𝑝(𝐴)
0,207

𝑟𝑏(𝐵)
-0,126
𝑝(𝐵)
0,192

𝑟𝑏(𝐶)
-0,149
𝑝(𝐶)
0,202

Índice D
0,190

Bisserial
0,547

Acerto: 27% menores notas
0,287
𝑟𝑏(𝐸)
-0,183
𝑝(𝐸)
0,127

𝑟𝑏(𝐷)
0,547
𝑝(𝐷)
0,270

𝑟𝑏()
-0,039
𝑝()
0,002

A alternativa correta discriminou bem, já que seu coeficiente bisserial foi de 0,547,
o que também pode ser observado pela AGI, a qual revela que há maior proporção de
escolha das alternativas erradas entre os estudantes de baixa proficiência.

O nível de dificuldade foi de 0,270, o que leva o item a ser classificado como difícil.
A habilidade inferida é resolver problemas de raciocínio lógico a partir de dedução de
informações de relações arbitrárias entre objetos, lugares, pessoas e/ou eventos fictícios
dados.

Aqueles que escolheram alguma das alternativas erradas, seja A, B, C ou E, prova-
velmente desconsideraram a condição de que ao menos uma informação das outras estava
correta. Assim, todas as alternativas verificam erros de lógica ou de raciocínio, segundo

130

Capítulo 8. Análise de Resultados

Bodin (1997), e erros devido a associações incorretas ou rigidez de pensamento, segundo
Radatz (1979).

De acordo com os dados, com exceção do índice 𝐼𝐷, o item se comportou bem do

ponto de vista psicométrico e pedagógico.

8.3. Análise Individualizada dos Itens da OBMEP

131

8.3.7 Item 7

Rodrigo comprou três cadernos iguais em uma promoção na qual o
segundo e o terceiro cadernos eram vendidos, respectivamente, com 20% e
40% de desconto sobre o preço do primeiro. No dia seguinte, terminada a
promoção, Gustavo comprou três cadernos iguais aos de Rodrigo, todos sem
desconto. Percentualmente, quanto Rodrigo pagou a menos que Gustavo?

A) 20%
B) 22%
C) 25%
D) 28%
E) 30%

Análise do Item 7

Questão Gabarito Dificuldade

Q7

A

0,415
Acerto: 27% maiores notas
0,269

𝑟𝑏(𝐴)
0,360
𝑝(𝐴)
0,415

𝑟𝑏(𝐵)
-0,136
𝑝(𝐵)
0,094

𝑟𝑏(𝐶)
-0,171
𝑝(𝐶)
0,145

Índice D
0,065

Bisserial
0,360

Acerto: 27% menores notas
0,333

𝑟𝑏(𝐷)
-0,124
𝑝(𝐷)
0,098

𝑟𝑏(𝐸)
-0,169
𝑝(𝐸)
0,242

𝑟𝑏()
-0,263
𝑝()
0,006

A alternativa correta discriminou bem, seu coeficiente bisserial foi de 0,360, e a
AGI também denota que há maior proporção de alternativas erradas entre os estudantes
de proficiência menor.

No tocante às habilidades avaliadas, infere-se, em relação à solução proposta pelo
elaborador (Anexo C), que este objetivava avaliar: a resolução de situação-problema en-
volvendo a variação de grandezas diretamente proporcionais, e também, cuja modelagem
envolva conhecimentos algébricos.

As alternativas B e D tiveram uma marcação mais baixa que as demais, provavel-
mente por causa do formato dos números, pois não são múltiplos de 5 ou 10. Pode ser que
os alunos que marcaram ao acaso já descartam essas opções por não se assemelharem aos
valores apresentados no texto-base.

O distrator E pode ser justificado por ser o valor médio entre as porcentagens de
descontos, o que demonstra que houve erro na interpretação do problema, e na aprendi-
zagem relacionada a variação de grandezas, ou seja, erros de saber – o aprendiz não tem
conhecimento matemático sobre os conceitos (BODIN, 1997).

Os dados deste item também deveriam ser revistos, pois o fato de no texto-base
possuir número igual ao gabarito da questão é considerado um fator de atração (Seção

132

Capítulo 8. Análise de Resultados

4.7), o que pode ter introduzido um viés na marcação das respostas e alunos com baixa
proficiência podem ter sido beneficiados.

Nesse tipo de questionamento, com relação à comparação percentual, o item ava-
liaria melhor se a resposta correta não fosse igual a um dos valores apresentados no
texto-base.

O nível de dificuldade de 0,415 classifica o item como mediano para os responden-
tes, mas o fator de atração mencionado acima pode ter contribuído para a facilidade do
item. Aconselha-se rever os valores numéricos.

8.3. Análise Individualizada dos Itens da OBMEP

133

8.3.8 Item 8

O professor Michel aplicou duas provas a seus dez alunos e divulgou as
notas por meio do gráfico mostrado abaixo. Por exemplo, o aluno A obteve
notas 9 e 8 nas provas 1 e 2, respectivamente; já o aluno B obteve notas 3 e 5.
Para um aluno ser aprovado, a média aritmética de suas notas deve ser igual
a 6 ou maior do que 6. Quantos alunos foram aprovados?

A) 6
B) 7
C) 8
D) 9
E) 10

Análise do Item 8

Questão Gabarito Dificuldade

Q8

A

0,347
Acerto: 27% maiores notas
0,207

𝑟𝑏(𝐴)
0,418
𝑝(𝐴)
0,347

𝑟𝑏(𝐵)
-0,142
𝑝(𝐵)
0,195

𝑟𝑏(𝐶)
-0,185
𝑝(𝐶)
0,218

Índice D
0,101

Bisserial
0,418

Acerto: 27% menores notas
0,308

𝑟𝑏(𝐷)
-0,149
𝑝(𝐷)
0,128

𝑟𝑏(𝐸)
-0,142
𝑝(𝐸)
0,103

𝑟𝑏()
-0,192
𝑝()
0,008

As habilidades necessárias para responder o item, em relação à solução proposta
pelo elaborador (Anexo C), são: interpretar informações apresentadas por meio de coor-
denadas cartesianas, ou resolver situação-problema envolvendo informações apresentadas
em gráficos, identificar a localização de pontos no plano cartesiano, acrescidas de uma
habilidade não conexa a essas, resolver situação-problema que envolva medida de tendên-
cia central, coleta, organização e descrição de dados, o que é desaconselhável quando se
pretende interpretar os erros e acertos em um item de múltipla escolha ou utilizar a teoria
de resposta ao item para se fazer a análise de desempenho.

A alternativa correta discriminou bem pois seu coeficiente bisserial foi de 0,418. A
AGI também denota que há maior proporção de escolha de alternativas incorretas entre
os estudantes de proficiência menor.

No tocante à plausibilidade dos distratores, o processo de elaboração poderia ter
escolhido distratores com maior plausibilidade, em vez de simplesmente apresentar uma
sequência de números consecutivos dentre as alternativas.

Infere-se que, ao cometer o erro de saber (BODIN, 1997) no tocante à média
aritmética, o aluno que marcou a opção E, apenas adicionou as duas notas, e, como a
soma encontrada é maior que 6, concluiu que todos os alunos foram aprovados.

134

Capítulo 8. Análise de Resultados

Para as outras alternativas incorretas, podem ser adicionadas duas características
do erro cometido: erro de saber no tocante à média e erros de lógica ou de raciocínio ao
selecionar de acordo com a posição no plano cartesiano, situações que não contemplam o
desafio proposto, segundo Bodin (1997). Já na visão do Radatz (1979), há erros devido à
dificuldade de obter informação espacial e erros devido a aplicações de regras ou estratégias
irrelevantes, da seguinte forma:

∙ pode-se inferir que, se o aluno interpretar que quem possuir uma nota maior igual

a a 6 está aprovado, este irá marcar a alternativa D;

∙ ao marcar C, o aluno considerou que alunos que retiraram pelo menos uma nota
maior ou igual a 6 teria sido aprovado, ou seja, pode ter destacado um quadrado
de dimensões 6 × 6, iniciado no 0, e todos os pontos fora da região ou no contorno
seriam de alunos aprovados, considerando apenas os alunos B e J como reprovados.
Esta marcação foi alta, de 21,8%;

∙ ao marcar B, o aluno considerou que alunos que retiraram pelo menos uma nota
maior que 6 teria sido aprovado, ou seja, pode ter destacado um quadrado de di-
mensões 6 × 6, iniciado no 0, e todos os pontos fora da região seriam de alunos
aprovados, considerando apenas os alunos B, E e J como reprovados.

Logo, o item deveria ser melhorado no tocante a aplicação de distratores plausíveis
com abordagens de diferentes tipos de erro, visando a análise do erro para uma aprendi-
zagem significativa e, ainda, por utilizar mais de uma habilidade para o mesmo item. O
nível de dificuldade foi de 0,347, caracterizando-se como difícil. Aconselha-se reelaborar
os distratores e abordar uma única habilidade.

8.3. Análise Individualizada dos Itens da OBMEP

135

8.3.9 Item 9

O polígono ABCDEF é um hexágono regular. Os pontos M e N são
pontos médios dos lados AF e BC, respectivamente. O hexágono ABNGHM
é simétrico em relação à reta que passa por M e N. Qual é a razão entre as
áreas dos hexágonos ABNGHM e ABCDEF?

A) 3/10
B) 4/11
C) 3/7
D) 7/15
E) 5/12

Análise do Item 9

Questão Gabarito Dificuldade

Q9

E

0,152
Acerto: 27% maiores notas
0,073

𝑟𝑏(𝐴)
-0,112
𝑝(𝐴)
0,224

𝑟𝑏(𝐵)
-0,162
𝑝(𝐵)
0,200

𝑟𝑏(𝐶)
0,033
𝑝(𝐶)
0,240

Índice D
0,090

Bisserial
0,465

Acerto: 27% menores notas
0,163
𝑟𝑏(𝐸)
0,465
𝑝(𝐸)
0,152

𝑟𝑏(𝐷)
-0,143
𝑝(𝐷)
0,179

𝑟𝑏()
-0,246
𝑝()
0,005

Apesar de a alternativa correta apresentar um bom coeficiente bisserial – 0,465
–, a AGI sinaliza para um comportamento ruim do item, já que há maior proporção de
escolhas de alternativas erradas entre os estudantes de maior proficiência, ou até mesmo
de marcações em branco.

No que se refere aos distratores, há problemas na construção do item, pois a al-
ternativa C possui um fator de atração, confirmado pela porcentagem de marcação do
item e do seu bisserial positivo, o que demonstra que até alunos de bom desempenho
escolheram essa alternativa. Justifica-se o fator de atração devido à formatação do deno-
minador da fração, que possui apenas um dígito, enquanto os demais possuem dois dígitos
no denominador.

Como dito anteriormente na análise geral do instrumento, as alternativas desse
item não são organizadas de forma trapezoidal, nem em ordenação crescente ou decres-
cente.

Quanto à plausibilidade dos distratores, pode-se destacar que:

∙ ao marcar as alternativas A ou D, o aluno pode ter realizado uma decomposição
da figura, sem respeitar que decomposição deve ser realizada de forma que todas as
partes possuam mesma área, das seguintes formas:

136

Capítulo 8. Análise de Resultados

Para a opção A: escolhendo 3 partes compreendidas pelo hexágono ABNGHM no
total de 10 partes determinadas por ABCDEF.

Figura 17 – Visualização da solução da alternativa A

Para a opção D: escolhendo 7 partes compreendidas pelo hexágono ABNGHM no
total de 15 partes determinadas por ABCDEF.

Figura 18 – Visualização da solução da alternativa D

∙ Nada foi inferido a respeito da alternativa B.

Vê-se em relação à solução proposta pelo elaborador, que a habilidade necessária
para resolver o item é resolver problema envolvendo o cálculo de área de figura plana,
reconhecer a conservação ou modificação de medidas dos lados, da área utilizando malhas
triangulares.

Com relação aos erros cometidos:

8.3. Análise Individualizada dos Itens da OBMEP

137

∙ ao marcar as alternativas A ou D, infere-se que o erro cometido é relacionado à
utilização adequada ou não dos saberes ou do saber-fazer, ou devido ao domínio
deficiente de conteúdos, rigidez de pensamento e a aplicações de regras ou estratégias
irrelevantes, segundo Bodin (1997) e Radatz (1979), respectivamente; e

∙ ao escolher a alternativa C, infere-se que o erro cometido é devido à formulação da

questão, segundo Casey (CLEMENTS, 1980 apud CURY, 2007).

Sugere-se reordenar e reelaborar as alternativas, e também contextualizar o item.

138

Capítulo 8. Análise de Resultados

8.3.10 Item 10

Sempre que Yurika abastece seu carro, ela enche o tanque e anota a data,
a quilometragem marcada no painel e a quantidade de litros de combustível
colocada. Na tabela estão os dados registrados por Yurika em dois abasteci-
mentos consecutivos. Quantos quilômetros por litro, aproximadamente, fez o
carro de Yurika nesse período?

A) 5,6
B) 9,8
C) 11,1
D) 12,9
E) 40,1

Análise do Item 10

Questão Gabarito Dificuldade

Q10

B

0,185
Acerto: 27% maiores notas
0,066

𝑟𝑏(𝐴)
-0,139
𝑝(𝐴)
0,104

𝑟𝑏(𝐵)
0,311
𝑝(𝐵)
0,185

𝑟𝑏(𝐶)
-0,095
𝑝(𝐶)
0,251

Índice D
0,117

Bisserial
0,311

Acerto: 27% menores notas
0,183
𝑟𝑏(𝐸)
-0,132
𝑝(𝐸)
0,195

𝑟𝑏(𝐷)
0,037
𝑝(𝐷)
0,256

𝑟𝑏()
-0,120
𝑝()
0,008

Embora o coeficiente bisserial da alternativa correta seja de 0,311, a alternativa
incorreta D também apresentou bisserial positivo, evidenciando que alunos com maior
proficiência também foram atraídos para este distrator. Além disso, a AGI também denota
que há grande proporção de alternativas erradas entre os estudantes nas mais diversas
faixas de escore, sugerindo uma má qualidade do item.

No que se refere aos distratores, infere-se que para escolher a letra A, o aluno
encontrou a diferença entre os espaços percorridos e dividiu pela soma dos litros. Para a
opção D, a diferença entre os espaços foi divida por 32,5, enquanto, para chegar ao valor
40,1, na alternativa E, encontrou o quociente entre as diferenças dos espaços percorridos
e os litros de consumo.

Nada de plausível foi inferido em relação à alternativa C, além de ser o valor mais
próximo da diferença entre os dois consumos em litros, o que poderia justificar sua alta
marcação (ver Figura 19).

A habilidade avaliada no item é resolver problema que envolva variações proporci-
onais, diretas ou inversas entre grandezas. Logo, os distratores exploraram a variação de
acordo com essa habilidade. O nível de dificuldade foi de 0,185, sendo, assim, considerado
difícil.

8.3. Análise Individualizada dos Itens da OBMEP

139

Figura 19 – Solução apresentada pelo aluno E1A15.

Como apresentado na análise geral do instrumento, o dado 32,5 é considerado
irrelevante para a resolução do item. A formatação das alternativas não segue o mesmo
padrão, e, de acordo com a porcentagem de marcação, verifica-se que a menor parte dos
respondentes concentrou-se na alternativa A.

Os erros associados à marcação das alternativas são ligados à utilização adequada
ou não dos saberes ou do saber-fazer, segundo Bodin (1997), e erros devido a aplicações
de regras ou estratégias irrelevantes, segundo Radatz (1979). No entanto, não se pode
descartar que a informação a mais no texto-base pode contribuir para que haja confusão
durante a resolução, que ao buscar usar todos os dados apresentados, não haja opção que
contemple tal escolha. Ou seja, a formulação do item, segundo Casey (CLEMENTS, 1980
apud CURY, 2007), pode ser raiz dos erros. Segundo este mesmo autor, os erros cometidos,
descartando o uso do dado irrelevante, podem ser de natureza de má compreensão e seleção
de estratégias.

Como sugestão, o item deveria ser reelaborado para sanar as não conformidades

com a Engenharia de Construção de Itens e retirar o dado irrelevante.

140

Capítulo 8. Análise de Resultados

8.3.11 Item 11

Todos os números de 1 a 24 devem ser escritos nas faces de um cubo,

obedecendo-se às seguintes regras:

∙ em cada face devem ser escritos quatro números consecutivos;

∙ em cada par de faces opostas, a soma do maior número de uma com o

menor número da outra deve ser igual a 25.

Se os números 7 e 23 estiverem escritos no cubo como na figura, qual é o
menor número que pode ser escrito na face destacada em cinza?

A) 1
B) 5
C) 9
D) 11
E) 17

Análise do Item 11

Questão Gabarito Dificuldade

Q11

C

0,197
Acerto: 27% maiores notas
0,068

𝑟𝑏(𝐴)
-0,109
𝑝(𝐴)
0,249

𝑟𝑏(𝐵)
-0,120
𝑝(𝐵)
0,255

𝑟𝑏(𝐶)
0,479
𝑝(𝐶)
0,197

Índice D
0,142

Bisserial
0,479

Acerto: 27% menores notas
0,209

𝑟𝑏(𝐷)
-0,076
𝑝(𝐷)
0,157

𝑟𝑏(𝐸)
-0,169
𝑝(𝐸)
0,134

𝑟𝑏()
-0,240
𝑝()
0,008

Embora o coeficiente bisserial da alternativa correta foi de 0,479, analisando o
bisserial por alternativas percebe-se que este tem problemas na alternativa D, pois alunos
com maior proficiência foram atraídos também para este distrator. A AGI também denota
que há grande proporção de escolha de alternativas incorretas entre os estudantes de
proficiência menor, o que é esperado, mas que os alunos de maior proficiência também
marcaram opções diversas ao gabarito, e até realizaram marcação em branco.

A solução proposta pelo elaborador apresenta a solução para todas as faces, ou

seja:

∙ face da frente – 25, 24, 23 e 22

∙ face lateral direita – 5, 6, 7 e 8

∙ as outras faces seriam (1, 2, 3 e 4); ( 9, 10, 11 e 12); (13, 14,15 e 16); (17,18,19 e

20).

8.3. Análise Individualizada dos Itens da OBMEP

141

A habilidade inferida é resolver problemas de raciocínio lógico a partir de dedução

de informações de relações de eventos fictícios dados.

O item poderia ser a reelaborado, ainda mais quanto à plausibilidade para o uso
de erros que contribuem para a aprendizagem significativa. Quando se relaciona às faces
opostas, a escolha da alternativa A pode ter o fator de atração relacionado ao menor
número presente no conjunto de alternativas, ou seja, um erro de compreensão da situação
proposta (Casey (CLEMENTS, 1980 apud CURY, 2007)) fora esta possibilidade há como
caracterizar este erro de forma pedagógica.

Ao marcar a alternativa B = 5, supõe-se que o estudante pode ter escrito os
antecedentes do 7 sobre a face superior, o que denota um erro de saber-fazer ou erro
de lógica ou de raciocínio, segundo Bodin (1997). Ainda, segundo Radatz (1979), pode
ter cometido erros devido à dificuldade de obter informação espacial e erros devido a
associações incorretas ou rigidez de pensamento.

Para marcar a alternativa E, o estudante pode ter compreendido o preenchimento
para as faces que apresentam números, desconsiderando a face oposta ao 7, e assumiu que
as faces superior e inferior deveriam ser preenchidas com os valores de 13 até 20, como
13 não figurou entre os valos das alternativas, escolheu posicionar os números de 17 a 20
na face superior, realizando essa escolha, apresentando erros de lógica ou de raciocínio e
erros devido a associações incorretas ou rigidez de pensamento, segundo Bodin (1997) e
Radatz (1979) respectivamente. Acrescentando os apontamentos de Casey (CLEMENTS,
1980 apud CURY, 2007), há também erro de compreensão e apresentação da solução.

Não foi inferido um processo que justifique a escolha da alternativa D. E, nova-

mente, há a presença de alternativas que seguem um padrão de numeração ímpar.

Logo, a situação proposta poderia ser reelaborada de forma a priorizar a elaboração
de distratores que demonstrem proposições falsas plausíveis e também, ajustando o nível
de dificuldade do item.

142

Capítulo 8. Análise de Resultados

8.3.12 Item 12

Começando com um quadrado de 1 cm de lado, formamos uma sequência
de figuras, como na ilustração. Cada figura, a partir da segunda, é formada
unindo-se três cópias da anterior. Os contornos destacados em vermelho das
quatro primeiras figuras medem, respectivamente, 4 cm, 8 cm, 20 cm e 56 cm.
Quanto mede o contorno da Figura 6?

A) 88 cm
B) 164 cm
C) 72 cm
D) 488 cm
E) 492 cm

Análise do Item 12

Questão Gabarito Dificuldade

Q12

D

0,171
Acerto: 27% maiores notas
0,073

𝑟𝑏(𝐴)
-0,202
𝑝(𝐴)
0,254

𝑟𝑏(𝐵)
-0,093
𝑝(𝐵)
0,264

𝑟𝑏(𝐶)
-0,091
𝑝(𝐶)
0,229

Índice D
0,108

Bisserial
0,477

Acerto: 27% menores notas
0,181
𝑟𝑏(𝐸)
0,018
𝑝(𝐸)
0,075

𝑟𝑏(𝐷)
0,477
𝑝(𝐷)
0,171

𝑟𝑏()
-0,070
𝑝()
0,007

Infere-se que as habilidades necessárias para a resolução do item são: reconhecer
a conservação ou modificação de medidas dos lados, do perímetro em figuras poligonais
usando malha quadriculada, identificar uma expressão algébrica que expressa uma regula-
ridade observada em sequências de números ou figuras (padrões).

Embora o coeficiente bisserial da alternativa correta seja de 0,477, analisando-
se o bisserial por alternativa, percebe-se que este tem problemas na alternativa E, pois
alunos com com proficiência até o escore de 14 pontos foram atraídos também para este
distrator, o que é confirmado pela AGI, mesmo que esta alternativa tenha apresentado
uma marcação baixa de respostas.

Além disso, os bisseriais das alternativas B e C foram muito próximos de zero,

evidenciando a baixa discriminação das alternativas.

No tocante à plausibilidade dos distratores, observa-se que, provavelmente, quem

escolheu a alternativa:

∙ A, adicionou todos os números do comando que indicam os primeiros contornos, 4
cm + 8 cm + 20 cm + 56 cm = 88 cm, presentes no texto-base, caracterizando um
fator de atração. Um distrator elaborado nessa perspectiva traz pouca informação
sobre a aprendizagem dos estudantes, permitindo apenas a caracterização como erro

8.3. Análise Individualizada dos Itens da OBMEP

143

de compreensão.

∙ B, calculou o contorno da quinta figura, e não o da sexta, como era desejado. Ou
seja, ao realizar o processo correto, o aluno parou numa etapa intermediária, por
encontrar esse valor entre as alternativas, caracterizando-se erro levado por atração,
ou de apresentação de solução, segundo Casey (CLEMENTS, 1980 apud CURY,
2007).

Pode-se afirmar também que, quem marcou a alternativa B, provavelmente inter-
pretou, aplicou um algoritmo certo de resolução, mas, por descuido, ao encontrar um valor
entre as alternativas, parou de realizar a análise da sentença. Isso pode ser considerado
um “peguinha”, pois o aluno realizou o processo correto mas o interrompeu. Nesse caso,
houve aplicação correta, só não foi realizada o número de iterações requisitadas.

Quanto as outras alternativas, nada foi inferido pela pesquisadora.

Logo, a alternativa E poderia ser descartada por não haver uma marcação expres-
siva, e as alternativas A e B deveriam ser reelaboradas, ou até mesmo o texto-base, para
sanar a desconformidade com a Engenharia de Construção de Itens. O nível de dificuldade
foi de 0,171, revelando-se muito difícil para os estudantes.

144

Capítulo 8. Análise de Resultados

8.3.13 Item 13

Na conta indicada a seguir, as letras X, Y e Z representam algarismos

distintos. Qual é o algarismo representado pela letra Z?

A) 1
B) 3
C) 5
D) 6
E) 8

Análise do Item 13

Questão Gabarito Dificuldade

Q13

E

0,174
Acerto: 27% maiores notas
0,079

𝑟𝑏(𝐴)
-0,067
𝑝(𝐴)
0,160

𝑟𝑏(𝐵)
-0,029
𝑝(𝐵)
0,197

𝑟𝑏(𝐶)
-0,193
𝑝(𝐶)
0,259

Índice D
0,105

Bisserial
0,484

Acerto: 27% menores notas
0,184
𝑟𝑏(𝐸)
0,484
𝑝(𝐸)
0,174

𝑟𝑏(𝐷)
-0,122
𝑝(𝐷)
0,204

𝑟𝑏()
-0,202
𝑝()
0,006

As habilidades que podem ser imputadas ao item são: resolver situação-problema
com números naturais, considerando as ordens e as classes de determinada base cuja
modelagem envolva conhecimentos algébricos.

Embora o coeficiente bisserial do item tenha sido de 0,484, há problemas em sua
elaboração, pois os bisseriais das alternativas A e B são muito próximos de zero, o que
revela a marcação dessas alternativas por alunos com escore mais alto.

No tocante à plausibilidade dos distratores, vê-se em relação à solução proposta
pelo elaborador que, quem escolheu a alternativa C, com 25,9% de marcação, considerou
o fato de, sendo Z = 5 , então X = 6 e Y = 4 nas parcelas. Durante o processo de adição,
a soma Z e X se confirmam nesta condição, mas o Y seria igual a 1, o que invalidava a
situação descrita.

Nada foi inferido das outras alternativas que justifiquem processos errôneos signi-
ficativos, apenas por descuido na resolução, onde os valores 1 e 6 aparecem no meio do
processo resolutivo, mas não representam o algarismo procurado.

Provavelmente, o erro de quem marcou a alternativa C foi de lógica ou de raciocínio
ou devido a associações incorretas ou rigidez de pensamento, respectivamente nas abor-
dagens de Bodin (1997) e Radatz (1979). Para Casey (CLEMENTS, 1980 apud CURY,
2007), seria na seleção de estratégias e apresentação de solução tanto na alternativa C
quanto para A e B.

O nível de dificuldade de 0,174, coloca o item na categoria difícil, e, como relatado

8.3. Análise Individualizada dos Itens da OBMEP

145

na análise do instrumento, o texto-base poderia ser melhor explorado para mobilizar
competências para sua resolução.

146

Capítulo 8. Análise de Resultados

8.3.14 Item 14

Rosane percebeu que seu antigo relógio de parede tinha parado às 9
horas. Ela deu corda no relógio, colocando-o para funcionar sem acertar o
horário, e foi imediatamente ao mercado. Chegou ao mercado às 10 horas e
10 minutos. Fez suas compras em 1 hora e voltou para casa. Entrando em
casa, notou que o relógio de parede marcava 10 horas e 40 minutos. Se Rosane
realizou os percursos de ida e volta ao mercado em tempos iguais, a que horas
ela entrou em casa?

A) 10 horas e 50 minutos
B) 11 horas e 10 minutos
C) 11 horas e 30 minutos
D) 11 horas e 40 minutos
E) 11 horas e 50 minutos

Análise do Item 14

Questão Gabarito Dificuldade

Q14

C

0,162
Acerto: 27% maiores notas
0,091

𝑟𝑏(𝐴)
-0,185
𝑝(𝐴)
0,187

𝑟𝑏(𝐵)
-0,072
𝑝(𝐵)
0,329

𝑟𝑏(𝐶)
0,451
𝑝(𝐶)
0,162

Índice D
0,067

Bisserial
0,451

Acerto: 27% menores notas
0,159
𝑟𝑏(𝐸)
0,023
𝑝(𝐸)
0,141

𝑟𝑏(𝐷)
-0,141
𝑝(𝐷)
0,178

𝑟𝑏()
-0,245
𝑝()
0,004

Analisando a plausibilidade dos distratores:

∙ a alternativa B, embora incorreta, atraiu significativa parcela dos estudantes, 32,9%,
pois possui um resultado incompleto da interpretação, com dados no texto-base
“Chegou ao mercado às 10 horas e 10 minutos. Fez suas compras em 1 hora e voltou
para casa”, logo, o respondente adicionou esses valores, obtendo 11h10min;

∙ a alternativa D, da mesma forma que a B, como no texto-base tem-se que “Fez
suas compras em 1 hora e voltou para casa. Entrando em casa, notou que o relógio
de parede marcava 10 horas e 40 minutos”, assim o aluno ao escolher esta opção
adicionou os valores deste trecho e obteve 11 hora e 40 minutos;

∙ as alternativas A e E, com marcações de 18,7% e 14,1%, respectivamente, podem ser
justificadas por uma leitura flutuante e sem significado do texto-base, adicionando
valores nele encontrados (ver Figura 20).

8.3. Análise Individualizada dos Itens da OBMEP

147

Figura 20 – Solução apresentada pelo aluno E2A10.

Associando essas escolhas às categorização dos erros temos como inferência para
as alternativas B e D, que há erros relacionados à utilização adequada ou não dos saberes
ou do saber-fazer e erros de lógica e raciocínio, para Bodin (1997). Para Radatz (1979),
há erro devido a associações incorretas ou rigidez de pensamento. E, para Casey (CLE-
MENTS, 1980 apud CURY, 2007), erro causado pela leitura, compreensão e seleção de
estratégias, para todas as inferências.

Já para as alternativas A e E, acrescentam-se erros relacionados à aplicação de
regras ou estratégias irrelevantes e erros de saber-fazer, segundo Radatz (1979) e Bodin
(1997), respectivamente.

As habilidades inferidas para o desafio proposto no item dizem respeito a resolver
problema envolvendo operação com sistema de medida de tempo juntamente com resolver
problemas de raciocínio lógico a partir de dedução de informações de relações arbitrárias
entre objetos, lugares, pessoas e/ou eventos fictícios dados.

Embora o coeficiente bisserial do item tenha sido de 0,451, analisando-se o bisserial
por alternativa, percebe-se que este item tem problema na alternativa E, pois alunos com
maior proficiência foram atraídos também para este distrator, o que é confirmado pelo
comportamento da AGI.

Assim, como sugestão, a alternativa E poderia ser descartada ou substituída e o
texto-base poderia ser reelaborado. O nível de dificuldade de 0,162 caracteriza o item
como difícil para os respondentes.

148

Capítulo 8. Análise de Resultados

8.3.15 Item 15

Télio comprou laranjas, maçãs e uvas no mercado. O preço por quilo-
grama de cada fruta está na tabela abaixo. Metade do peso total da compra
era de maçãs e o peso das uvas era o dobro do peso das laranjas. Se Télio
gastou R$ 38,00, quantos quilogramas de frutas ele comprou?

A) 10
B) 11
C) 12
D) 13
E) 14

Análise do Item 15

Questão Gabarito Dificuldade

Q15

C

0,297
Acerto: 27% maiores notas
0,176

𝑟𝑏(𝐴)
-0,169
𝑝(𝐴)
0,203

𝑟𝑏(𝐵)
-0,113
𝑝(𝐵)
0,151

𝑟𝑏(𝐶)
0,406
𝑝(𝐶)
0,297

Índice D
0,088

Bisserial
0,406

Acerto: 27% menores notas
0,264

𝑟𝑏(𝐷)
-0,105
𝑝(𝐷)
0,186

𝑟𝑏(𝐸)
-0,145
𝑝(𝐸)
0,159

𝑟𝑏()
-0,266
𝑝()
0,004

Infere-se em relação à solução proposta pelo elaborador que a habilidade necessária
para se resolver o item é resolver situação-problema cuja modelagem envolva conhecimen-
tos algébricos.

À luz da Engenharia de Construção de Itens o item, com coeficiente bisserial do
item de 0,406, obteve boa distribuição de marcação de respostas entre as alternativas
incorretas, sendo o gabarito o de maior escolha pelos estudantes, embora candidatos de
maior proficiência, segundo a AGI, tenham optado pela alternativa D. Com coeficiente de
dificuldade de 0,297, o item enquadra-se como difícil.

Com relação aos distratores, infere-se a não construção dos mesmo de forma a
justificar caminhos errôneos para a resolução do item, já que são apresentados apenas
como números consecutivos, sem justificativas claras de possíveis caminhos que poderiam
ser seguidos pelos estudantes que desconhecem a resposta correta.

No entanto, infere-se que, ao marcar a alternativa B, o aluno apenas realizou uma
testagem para encontrar algum valor entre as alternativas, ou seja, com 5 kg de uva e 6
kg de maça, obtém-se R$ 38,00. Assim, com 11 kg dessas frutas, obtém o valor procurado,
mas desconsidera as condições de comprar todos os tipos de frutas e a quantidade que
se relaciona entre uvas e maças. Ao escolher a opção D, possivelmente desconsiderou as
condições, trabalhando com 7 kg de laranjas e 6 kg de uvas.

8.3. Análise Individualizada dos Itens da OBMEP

149

De acordo com estes apontamentos, os erros inferidos são erro de saber (BODIN,
1997) e de domínio deficiente de conteúdos e aplicação de regras e estratégias irrelevantes
(RADATZ, 1979). Além de erro de compreensão e seleção de estratégias (Casey (CLE-
MENTS, 1980 apud CURY, 2007)).

Logo, há necessidade de reelaboração dos distratores.

150

Capítulo 8. Análise de Resultados

8.3.16 Item 16

A mãe de Lúcia pediu para ela não comer mais de 10 docinhos por dia.
Além disso, se em um dia ela comer mais de 7 docinhos, nos dois dias seguintes
não poderá comer mais de 5 docinhos em cada dia. Qual é o maior número
de docinhos que Lúcia pode comer durante um período de 29 dias seguidos,
obedecendo ao pedido de sua mãe?

A) 203
B) 204
C) 206
D) 213
E) 290

Análise do Item 16

Questão Gabarito Dificuldade

Q16

C

0,201
Acerto: 27% maiores notas
0,119

𝑟𝑏(𝐴)
-0,019
𝑝(𝐴)
0,250

𝑟𝑏(𝐵)
-0,028
𝑝(𝐵)
0,189

𝑟𝑏(𝐶)
0,261
𝑝(𝐶)
0,201

Índice D
0,040

Bisserial
0,261

Acerto: 27% menores notas
0,159

𝑟𝑏(𝐷)
-0,088
𝑝(𝐷)
0,159

𝑟𝑏(𝐸)
-0,135
𝑝(𝐸)
0,198

𝑟𝑏()
-0,103
𝑝()
0,003

O nível de dificuldade de 0,201 o que caracteriza o item como difícil. O coeficiente
bisserial da alternativa correta foi de 0,261, pela a AGI verificamos que o item não discri-
minou adequadamente, fato pode ser confirmado ao tomamos os coeficientes bisseriais das
alternativas incorretas. Percebe-se que os bisseriais das alternativas A, B e D são muito
próximos de 0, mesmo sendo negativos, o que indica a escolha dos distratores por uma
proporção elevada de estudantes com escore mais alto.

Além disso, em várias alternativas incorretas, ocorreram percentuais de marcação
muito próximas do acerto ao acaso, inclusive no gabarito a marcação foi de 20,1%. o
que sugere marcação ao acaso para todas as alternativas, revelando que os alunos da
amostra não possuem habilidade necessária para responder o item, indicando necessidade
de análise pedagógica mais acurada do item. No tocante a plausibilidade dos distratores,
infere-se que as alternativas podem ser justificadas na sua maioria:

∙ a alternativa A foi marcada por quem interpretou que a melhor escolha seria a
que indicasse que Lúcia comesse 7 docinhos por dia, desconsiderando que nos dois
últimos dias poderia alterar sua dieta;

∙ ao escolher alternativa B, possivelmente o estudante considerou que a dieta poderia

ser modificada, mas escolheu comer 10 docinhos no penúltimo dia;

8.3. Análise Individualizada dos Itens da OBMEP

151

∙ provavelmente, a alternativa E foi escolhida por quem não considerou a penalidade
de se comer menos nos dois dias que se seguem se Lúcia comesse 10 docinhos em
um dia, e considerou uma dieta de 10 docinhos por dia durante todo o período;

∙ nada foi inferido de relevante para alternativa D.

Todas essas hipóteses de possíveis explicações para os erros cometidos são embasa-
das em uma mesma habilidade de validação da construção do item: resolver problemas de
raciocínio lógico a partir de dedução de informações de relações arbitrárias entre objetos,
lugares, pessoas e/ou eventos fictícios dados, com o objetivo de maximizar o evento.

Com relação a categorização dos erros inferidos, pode-se afirmar que:

∙ para a alternativa A, houve erros de lógica ou de raciocínio, segundo Bodin (1997),
e erros devido a associações incorretas ou rigidez de pensamento, de acordo com
Radatz (1979). Da mesma forma, pode-se explicar a escolha da opção E, mas neste
caso, como o aluno escolheu o valor máximo, provavelmente não compreendeu as
penalidade de seu consumo, ou seja, ocorreu erro de compreensão e seleção de es-
tratégias, segundo Casey (CLEMENTS, 1980 apud CURY, 2007);

∙ para quem escolheu a opção B, houve compreensão da condição da dieta, mas o aluno
cometeu erro devido a aplicação de regras ou estratégias irrelevantes, de acordo com
Radatz (1979), e de seleção de estratégias, segundo Casey (CLEMENTS, 1980 apud
CURY, 2007).

Sugere-se que o item seja reelaborado, devido ao coeficiente bisserial que evidenciou

a não-discriminação.

152

Capítulo 8. Análise de Resultados

8.3.17 Item 17

Gustavo possui certa quantidade de moedas de 1, 10, 25 e 50 centavos,
tendo pelo menos uma de cada valor. É impossível combiná-las de modo a obter
exatamente 1 real. Qual é o maior valor total possível para suas moedas?

A) 86 centavos
B) 1 real e 14 centavos
C) 1 real e 19 centavos
D) 1 real e 24 centavos
E) 1 real e 79 centavos

Análise do Item 17

Questão Gabarito Dificuldade

Q17

C

0,106
Acerto: 27% maiores notas
0,600

𝑟𝑏(𝐴)
-0,125
𝑝(𝐴)
0,467

𝑟𝑏(𝐵)
-0,051
𝑝(𝐵)
0,095

𝑟𝑏(𝐶)
0,293
𝑝(𝐶)
0,106

Índice D
0,037

Bisserial
0,293

Acerto: 27% menores notas
0,097
𝑟𝑏(𝐸)
-0,044
𝑝(𝐸)
0,186

𝑟𝑏(𝐷)
0,080
𝑝(𝐷)
0,142

𝑟𝑏()
-0,116
𝑝()
0,005

Embora o coeficiente bisserial do item tenha sido de 0,293, analisando o bisserial
por alternativa, percebe-se que este tem problemas na alternativa D, que apresentou
bisserial positivo, além das alternativas B e E, que evidenciaram valores próximos ao
zero. A AGI também confirma esse problema generalizado, com o sobe e desce das curvas
de proporção de marcação de cada alternativa.

Em relação a Engenharia de Construção Itens, a alternativa A apresenta forte
atração devido a sua estrutura, pois é a única que apresenta apenas centavos em seu
texto, além de ser o resultado da adição dos números do texto-base. Por conta desses
desvios, a alternativa A tornou-se tão atrativa, com 46,7% de marcação, evidenciando a
necessidade de ser descartada em um processo de reelaboração do item. A alternativa E
poderia ser marcada pela simples verificação de que é um valor que pode ser construído
com as moedas em questão, sem respeitar a impossibilidade de se ter um real. Além disso,
é o maior valor apresentado entre as alternativas.

As outras duas alternativas são semelhantes na construção, pois não respeitam a
condição imposta de impossibilidade de um real, e nem são os maiores valores (ver Figura
21).

A habilidade, inferida a partir da visão do elaborador, é resolver problemas de
raciocínio lógico a partir de dedução de informações de relações arbitrárias entre objetos,
lugares, pessoas e/ou eventos fictícios dados.

8.3. Análise Individualizada dos Itens da OBMEP

153

Figura 21 – Solução apresentada pelo aluno E1A10.

O nível de dificuldade de 0,106 caracteriza o item como difícil, possivelmente devido

ao poder de atração da alternativa A.

Com relação a categorização dos erros, de acordo com Bodin (1997), Radatz (1979)

e Casey (CLEMENTS, 1980 apud CURY, 2007):

∙ para a alternativa A, seria de formulação do item ou de seleção de estratégias e erro

devido a associações incorretas ou de rigidez de pensamento;

∙ para a alternativa E, seria de de saber fazer ou devido a aplicações de regras ou

estratégias irrelevantes ou de leitura, compreensão e seleção de estratégias;

∙ para as alternativas B e D, seria de saber fazer, de lógica e de raciocínio ou er-
ros devido a aplicações de regras, estratégias irrelevantes, de leitura, compreensão e
seleção de estratégias.

Assim, o item deveria ser reelaborado devido ao fator de atração.

154

Capítulo 8. Análise de Resultados

8.3.18 Item 18

O número 2014 tem quatro algarismos distintos, um ímpar e três pares,
sendo um deles 0. Quantos números possuem exatamente essas característi-
cas?

A) 60
B) 180
C) 360
D) 420
E) 540

Análise do Item 18

Questão Gabarito Dificuldade

Q18

E

0,124
Acerto: 27% maiores notas
0,049

𝑟𝑏(𝐴)
-0,149
𝑝(𝐴)
0,230

𝑟𝑏(𝐵)
0,004
𝑝(𝐵)
0,235

𝑟𝑏(𝐶)
0,023
𝑝(𝐶)
0,200

Índice D
0,075

Bisserial
0,291

Acerto: 27% menores notas
0,124
𝑟𝑏(𝐸)
0,291
𝑝(𝐸)
0,124

𝑟𝑏(𝐷)
-0,069
𝑝(𝐷)
0,203

𝑟𝑏()
-0,106
𝑝()
0,009

Infere-se em relação à solução proposta pelo elaborador que a habilidade verificada
no item é resolver o problema de contagem utilizando o princípio multiplicativo ou noções
de permutações e/ou combinações simples.

Com relação a marcação das alternativas:

∙ ao marcar a opção A, o aluno fixou o zero em uma posição e, pelo principio multi-
plicativo, preencheu as posições que restam com as possibilidades que necessitava:
5 números ímpares poderiam ocupar uma posição, 4 números pares (exceto o 0)
ocupariam a outra e, por ultimo, um dos outros 3 números pares ocuparia a ultima
posição, assim, encontrou 5 × 4 × 3 = 60;

∙ para marcar o opção B, o aluno acrescentaria que o zero poderia ser colocado em

três casas, ou seja, calcularia 60 × 3 = 180;

∙ para marcar letra C, o aluno pode ter considerado 2 formas possíveis de solução: a
primeira, iniciando com um número ímpar, fixando o zero em uma das três posições
e aplicando o princípio multiplicativo como a resposta dada na opção anterior; a
segunda, iniciando por um número par, com o mesmo raciocínio, teríamos pelo
principio multiplicativo 4 × 3 × 3 × 5. Adicionando ambas, chegaria a 180 + 180 =
360.

8.3. Análise Individualizada dos Itens da OBMEP

155

∙ para marcar a opção D, infere-se que o aluno realizou as operações justificadas para
o erro na alternativa A e adicionou o raciocínio utilizado em C, adicionando os
valores encontrados no final.

Com relação à categorização dos erros, infere-se para as alternativas A e B, o
erro de saber-fazer entrelaçado com erros de lógica ou de raciocínio; para C e D, erros
relacionados à utilização adequada ou não dos saberes ou do saber-fazer entrelaçado com
erros de lógica ou de raciocínio, do ponto de vista de Bodin (1997).

Para Radatz (1979), seriam erros devido a associações incorretas ou rigidez de
pensamento, para as alternativas A e B, e a aplicações de regras ou estratégias irrelevantes,
para marcação em C e D.

Complementando, para Casey (CLEMENTS, 1980 apud CURY, 2007), seria erro
de compreensão, seleção de estratégias, manipulação das habilidade e apresentação da
solução para todos os casos acima.

Embora o coeficiente bisserial da alternativa correta seja de 0,291, nota-se que
este tem problemas nas alternativas B e C, pois apresentaram bisseriais positivos, e na
alternativa D, com bisserial bem próximo de zero, apesar de negativo. Há fator de atração
pelo formato da alternativa A, que difere aos demais. Esses dados indicam que o item
não cumpriu o seu papel no que diz respeito à discriminação, fato evidenciado também
pelo sobe e desce das curvas representativas dos percentuais de marcação por alternativa
ilustradas na AGI.

Do ponto de vista pedagógico, o item apresenta-se contexto apenas escolar, na
própria Matemática. O resultado evidencia também o despreparo dos estudantes em re-
lação ao que foi avaliado no item, já que o nível de dificuldade alto foi evidenciado por
seu valor de 0,124, indicando que apenas 12,4% dos respondes acertaram.

156

Capítulo 8. Análise de Resultados

8.3.19 Item 19

Um cubo de madeira foi pintado de vermelho e depois cortado em n3
cubinhos iguais, n>2. Alguns desses cubinhos ficaram sem nenhuma face pin-
tada e outros com uma, duas ou três faces pintadas. Se o número de cubinhos
sem nenhuma face pintada é igual ao número de cubinhos com exatamente
uma face pintada, qual é o valor de n?

A) 7
B) 8
C) 9
D) 10
E) 11

Análise do Item 19

Questão Gabarito Dificuldade

Q19

B

0,228
Acerto: 27% maiores notas
0,124

𝑟𝑏(𝐴)
-0,086
𝑝(𝐴)
0,142

𝑟𝑏(𝐵)
0,322
𝑝(𝐵)
0,228

𝑟𝑏(𝐶)
-0,090
𝑝(𝐶)
0,289

Índice D
0,081

Bisserial
0,322

Acerto: 27% menores notas
0,205
𝑟𝑏(𝐸)
-0,115
𝑝(𝐸)
0,092

𝑟𝑏(𝐷)
-0,078
𝑝(𝐷)
0,242

𝑟𝑏()
-0,218
𝑝()
0,006

Embora o coeficiente bisserial da alternativa correta seja de 0,322, verifica-se que
os bisseriais das alternativas A, C e D possuem valores próximos ao zero, apesar de
negativos. Esses dados indicam que o item não cumpriu bem seu papel de discriminar,
conforme evidenciado na AGI, com o sobe e desce das curvas de proporção marcação por
alternativa à medida que se avança na escala de desempenho no teste

Assim como ocorreu em itens anteriores, observa-se uso de números consecutivos
como possibilidade de resposta nas alternativas, o que dificulta a inferência sobre a plau-
sibilidade de cada um deles do ponto de vista dos raciocínios possíveis dos estudantes
que não compreenderam o desafio proposto ou não desenvolveram alguma das habilidades
avaliada pelo item.

As alternativas C e D obtiveram proporção marcação de resposta superior à do
gabarito, onde se infere apenas a contagem dos cubos da base da figura para justificar
a marcação em C, ou a contagem das faces expostas dos cubos da base da figura, para
justificar a marcação em D. Fica claro, a partir desta inferência, o despreparo dos alunos
em frente a esta situação-problema.

Observa-se, em relação à solução proposta pelo elaborador, que as habilidades
inferidas para resolução deste item são: resolver problema envolvendo o cálculo de área

8.3. Análise Individualizada dos Itens da OBMEP

157

e volume de figuras geométricas, resolver situação-problema que envolva conhecimentos
geométricos de espaço e forma, utilizar conhecimentos geométricos de espaço e forma na
seleção de argumentos propostos como solução de problemas, resolver situação problema
cuja modelagem envolva conhecimentos algébricos.

O nível de dificuldade de 0,228 revela que o item apresentou-se difícil para os
respondentes, que é verificada pelo uso de expressão algébrica de terceiro grau, o que
não é trabalhado nos anos finais do ensino fundamental, logo os erros associados são
devido ao saber, dificuldade de linguagem, obter informação espacial, domínio deficiente
de habilidades.

158

Capítulo 8. Análise de Resultados

8.3.20 Item 20

Rodrigo brinca com uma fita de dois metros, com marcas de centímetro
em centímetro. Começando pela ponta da marca 0 cm, ele dobra a fita várias
vezes em zigue-zague, como na figura, sobrepondo pedaços de fita de mesmo
tamanho até dobrar um último pedaço, que pode ser menor do que os demais.
Ele observa que as marcas de 49 cm e de 71 cm ficaram sobrepostas em pedaços
vizinhos. Ele observa também que a marca de 139 cm ficou alinhada com elas.
Com qual marca do penúltimo pedaço a ponta final da fita ficou sobreposta?

A) 160 cm
B) 176 cm
C) 184 cm
D) 190 cm
E) 196 cm

Análise do Item 20

Questão Gabarito Dificuldade

Q20

D

0,180
Acerto: 27% maiores notas
0,108

𝑟𝑏(𝐴)
-0,138
𝑝(𝐴)
0,230

𝑟𝑏(𝐵)
0,006
𝑝(𝐵)
0,218

𝑟𝑏(𝐶)
0,005
𝑝(𝐶)
0,194

Índice D
0,035

Bisserial
0,206

Acerto: 27% menores notas
0,143
𝑟𝑏(𝐸)
-0,051
𝑝(𝐸)
0,175

𝑟𝑏(𝐷)
0,206
𝑝(𝐷)
0,180

𝑟𝑏()
-0,220
𝑝()
0,004

O item apresentou baixo coeficiente bisserial, de 0,206, além de duas das alterna-
tivas incorretas, B e C, com valores positivos, e a opção E, com valor negativo próximo
do zero. Esses dados, por si só, indicam que o item não discriminou. Esse fato é corrobo-
rando pelo formato da AGI, com curvas que se misturam sem evidenciar o que se deseja
em termos de escolhas dos respondentes à medida que se avança na escala de desempenho.

No tocante as habilidades necessárias para se resolver o item, infere-se as seguintes
em relação a solução proposta pelo elaborador: identificar regularidade observada em
sequências de números, identificar divisores e múltiplos de números naturais, interpretar
e localizar a movimentação de objetos e sua representação no espaço bidimensional e
utilizar conhecimentos geométricos de espaço e forma na seleção de argumentos propostos
como solução de problemas do cotidiano.

O nível elevado de dificuldade é demonstrado por seu valor de 0,18. Observa-se
também uma distribuição muito regular de marcação entre as alternativas, o que evidencia
marcação ao acaso de respostas em todas as alternativas.

Não foi encontrada uma justificativa para a plausibilidade dos valores apresentados

8.3. Análise Individualizada dos Itens da OBMEP

159

nas alternativas B e E.

Pode-se inferir que, ao escolher a alternativa A, o aluno considerou a dobra com
20 cm, ou seja 200 cm está sobre 160 cm. Essa escolha é devida à condição de todos os
pedaços de dobra terem o mesmo tamanho, verificando. a sobreposição de 49 cm e 71 cm,
mas não a condição relacionada à medida de 139 cm.

Quanto a escolher a alternativa C, o aluno possivelmente considerou que 49 cm e
71 cm se sobrepõem e são marcas de dobra, e, como sua distância é 22 cm, cada dobra
possui 11 cm de comprimento. Observando a regularidade, a última dobra seria em 193
cm. Além disso, como 200 cm dista 7 cm dessa última dobra, esse pedaço estará sobreposto
a 184 cm. Desse modo, o aluno desconsiderou a posição do 139 cm e a posição inicial.

Os erros podem ser categorizados como devido a associação incorretas ou rigidez
de pensamento para a alternativa A, considerando apenas a divisão em partes iguais; e
erro de lógica ou de raciocínio para a alternativa C. Para Casey (CLEMENTS, 1980
apud CURY, 2007), seria erro de compreensão, seleção de estratégias e apresentação de
solução.

Se a aplicação da primeira fase da OBMEP fosse pré-testada com o grupo que
respondeu o item, este não estaria adequado e precisaria ser reelaborado por apresentar
problemas quanto aos bisseriais das alternativas. Além disso, o texto-base deveria ser mais
claro com relação ao exemplo apresentado na figura.

Considerações Finais

161

Em relação ao estudo

Ao iniciar este estudo sobre a Olimpíada Brasileira de Matemática das Escolas
Públicas, havia uma hipótese de trabalho referente à aplicação de atividades pedagógicas
de forma a justificar e ampliar a atividade de aplicação da OBMEP nas escolas, fazendo-
se uma análise aprofundada da Matriz de Referência, suporte para elaboração dos itens,
conjuntamente com o estudo dos distratores, construindo-se transposições didáticas que
contribuíssem para o aprendizado dos estudantes brasileiros.

No entanto, ao se fazer as análises dos documentos existentes, o trabalho foi to-
mando a direção de revelar aos organizadores do evento a importância da Engenharia de
Itens na construção de uma avaliação que mostre, com mais fidedignidade, o nível de seus
participantes.

Embora o trabalho aqui desenvolvido tenha sido um estudo de caso, os resultados
fornecem uma pista do desempenho dos estudantes, como um todo, neste certame. Além
disso, a análise da construção do instrumento revela resultados mais robustos quando
da conformidade com a Engenharia de Itens. Neste quesito, a banca elaboradora do cer-
tame encontrará parâmetros que podem contribuir para a reavaliação da metodologia de
elaboração de avaliações que contemplem mais efetivamente seus objetivos, que incluem:

1. estimular e promover o estudo da Matemática entre alunos das escolas públicas,
elaborando o instrumento de avaliação de primeira fase da OBMEP e contemplando
itens em toda a escola de dificuldade;

2. contribuir para a melhoria da qualidade da educação básica, construindo os distra-
tores dos itens de forma a possibilitar a análise do erro das marcações dos estudantes
pelos professores;

3. identificar jovens talentos e incentivar seu ingresso nas áreas científicas e tecnológi-

cas;

4. incentivar o aperfeiçoamento dos professores das escolas públicas, contribuindo para
a sua valorização profissional, realizando estudos sobre a elaboração e uso de ins-
trumentos de avaliação de forma a alcançar uma aprendizagem significativa;

5. contribuir para a integração das escolas públicas com as universidades públicas, os

institutos de pesquisa e as sociedades científicas;

6. promover a inclusão social por meio da difusão do conhecimento.

162

Considerações Finais

Em relação a OBMEP

Devido à relevância da OBMEP no ensino de Matemática no Brasil, e considerando
os seus principais objetivos, cabe realizar algumas considerações em relação aos atores
envolvidos nesse certame.

Aos elaboradores do certame cabe um estudo mais amplo e semelhante ao feito
neste trabalho, no que tange à análise quantitativa, iniciando com o levantamento dos
dados, determinando os índices da TCT e as AGIs dos itens, tomando-se como base provas
futuras e uma amostra mais representativa da população. Isso deve ser feito para verificar
se os instrumentos elaborados são constituídos de itens que realmente discriminam os
sujeitos, já que o estudo revelou a predominância de índices de discriminação baixos, em
todos os itens, de acordo com o que preceitua a literatura na área de avaliação. O mesmo
ocorre com a distribuição de itens em relação à dificuldade em todo o teste.

Sugere-se também aos elaboradores, ao tomar ciência desta análise, elaborar uma
matriz de referência para dar suporte ao processo de construção dos itens das provas
futuras, de acordo com as orientações provenientes da teoria da medida para avaliação de
larga escala e da Engenharia de Itens.

Recomenda-se a aplicação dos pressupostos da TRI na elaboração dos itens, pois
isso possibilitaria a construção e interpretação de uma escala de proficiência, o que se-
ria excelente feedback para escolas e estudantes participantes, e proporcionaria selecionar
melhor os estudantes que participarão da fase seguinte. Além disso, o desempenho nessa
fase da Olimpíada poderia ser uma informação complementar àquela obtida nas provas
do SAEB e da Prova Brasil, no que diz respeito ao desempenho dos estudantes em Mate-
mática.

Da mesma forma, para os gestores das escolas participantes, sugere-se que os resul-
tados apresentados pelos alunos, no nível institucional, sejam utilizados como parâmetros
de reflexão de cada instituição, de modo a inserir ações e metas no seu PPP, de forma a
tornar a aprendizagem mais significativa para os estudantes, como, incluir projetos que
minimizem as dificuldades inferidas a partir do desempenho dos estudantes.

Aos docentes, sugere-se que, ao criarem seus instrumentos avaliativos, utilizem este
material de estudo como reflexão de sua prática pedagógica, e que utilizem a Engenharia
de Itens na construção de testes e provas. Principalmente, que repensem a intencionalidade
de um fazer avaliativo de qualidade, proporcionando uma reflexão ativa do seu estudante
nos mais diversos instrumentos.

E ainda que, ao utilizarem um instrumento de avaliação de larga escala, explorem
ao máximo os materiais propostos, não usando apenas como ferramenta de treinamento,
mas como uma investigação dos erros apresentados, para que sejam realizadas atividades
que deem significado aos conceitos aprendidos e reorientem as metas de aprendizagem

163

individual dos alunos, contribuindo para seu auto-monitoramento.

Dessa forma, pretende-se que professores e alunos sejam atuantes no processo
avaliativo, e que tornem a aplicação da prova da primeira fase da OBMEP um momento
real de aprendizagem matemática na escola, atribuindo a este instrumento classificatório
um caráter formativo.

Aos elaboradores de avaliação de larga escala ou não, sugere-se que estejam atentos
a dar intencionalidade na construção dos distratores, para que os resultados das análises
das marcações realizadas pelos estudantes contribuam de fato para o refazer pedagógico,
em sala de aula, dos objetivos de aprendizagem. Isso pode ser feito descartando-se a
enumeração consecutiva nas alternativas, eliminando os fatores de atração e utilizando a
categorização de erros para elaborar os distratores, distribuídos nos eixos de categorização
citados a seguir.

Assim, a categorização dos distratores poderá ser utilizada para traçar estratégias
de intervenções pedagógicas, contribuindo para a melhoria da aprendizagem de mate-
mática. Uma ação simples de repensar a construção do instrumento avaliativo, dando
plausibilidade aos distratores e suporte aos docentes para realizar as análises dos mes-
mos, pode ampliar as propostas dos idealizadores da OBMEP de forma a contemplar a
melhoria do ensino de Matemática nas escolas.

Quanto à categorização

Após a categorização dos erros inferidos, deve-se ter um olhar diferenciado frente
aos mesmos diante das atividades tanto do elaborador quanto do docente. Assim foram
construídas três tabelas-resumo com os itens, aqui estudados, enquadrados de acordo
com as categorizações de Bodin (1997), Radatz (1979) e Casey (CLEMENTS, 1980 apud
CURY, 2007), para melhor representar esta parte da pesquisa.

A partir dos dados apresentados nas Tabelas 14, 15 e 16, o elaborador de itens pre-
cisa considerar a categorização como um todo para construir os distratores previamente.

O item relacionado a erro devido à formulação da questão (Tabela 16) é, na ver-
dade, uma notificação do que se deve abandonar na prática de construção de itens.
Acrescenta-se a necessidade de se tomar o devido cuidado com os dados presentes no
texto-base e nas alternativas.

Agora, com relação ao docente, a discussão sobre esses resultados já é mais extensa.

No tocante aos erros relacionados a saber, a dificuldade com a linguagem e ao
domínio deficiente de conteúdos – Tabela 14 e 15, respectivamente – é necessário verificar
a deficiência dos estudantes no que tange à modelagem algébrica, a conceitos geométricos
de espaço e forma, a grandezas e medidas e à média aritmética.

164

Considerações Finais

Tabela 14 – Erro diante à construção de conhecimento em uma situação didática de Ma-

temática, segundo Bodin (1997)

Erros relacionados a:

Item
(Alternativa)

Habilidades relacionadas a:

Saber

o aprendiz não tem
conhecimento matemático
sobre as definições, as regras,
os algoritmos, e outros

Saber-fazer

o aprendiz não tem domínio
da técnica de resolução, do
algoritmo, e outros

Utilização
adequada
ou não dos
saberes ou
do
saber-fazer

o aprendiz não reconhece o
conceito correto para aplicar
na resolução de uma
situação-problema

Lógica ou
de
raciocínio

o aprendiz confunde hipótese
e tese, encadeia mal os
cálculos, não sabe lidar com
os dados apresentados

7(E)
8(E)

15 (B e D)
19

3(C e E)

11(B), 17
14(A e E)

18(A e B)

3(C e E)

4(A)

5(B)

9 (A e D)
10
14(B e D)

18(C e D)

1(A)
2(C)

4(A e C)

5(B)

14(B e D)

15 (B e D)
16 (A e E)

18
20 (C)

Grandezas proporcionais.
Medida de tendência central: média aritmé-
tica.
Modelagem algébrica.
Conhecimentos geométricos de espaço e forma
e modelagem algébrica.

Utilizar conhecimentos geométricos e proprie-
dades angulares de polígonos
Raciocínio lógico a partir de deduções
Raciocínio lógico a partir de deduções, aplica-
das a grandeza de tempo.
Contagem e principio multiplicativo.

Utilizar conhecimentos geométricos e proprie-
dades angulares de polígonos
Identificar padrões numéricos e operações com
numero inteiros.
Conhecimentos geométricos de grandezas e
medidas.
Razão entre áreas de figuras planas.
Variações de grandezas proporcionais.
Raciocínio lógico a partir de deduções, aplica-
das a grandeza de tempo.
Contagem e principio multiplicativo.

Termo central de sequência numérica.
Decomposição em fatores primos. Valor posi-
cional.
Identificar padrões numéricos e operações com
numero inteiros.
Conhecimentos geométricos de grandezas e
medidas.
Raciocínio lógico a partir de deduções
Posição no plano cartesiano.

Resolver situações-problema com numero na-
turais, valores posicionais.
Raciocínio lógico a partir de deduções, aplica-
das a grandeza de tempo.
Modelagem algébrica.
Raciocínio lógico a partir de deduções e maxi-
mização
Contagem e principio multiplicativo.
Identificar regularidades observada em se-
quencia de números naturais.

6
8
11(B e E), 17 (B e D) Raciocínio lógico a partir de deduções
13(C)

Neste eixo, o conteúdo é o foco da intervenção do professor. Conceitos que devem
ser retomados com uma postura de ressignificar o que no foi aprendido. Até mesmo,
retomando seu estudo durante todo o processo de aprendizagem, após a realização do
certame, pois são conceitos que embasam todo o ensino de Matemática após o nono ano.
Este eixo poderia ser chamado de eixo de erros conceituais, quando cabe ao professor uma
interferência no currículo de forma a trabalhar novamente os conceitos aqui especificados.

Quanto aos erros relacionados a saber-fazer, a utilização adequada dos saberes ou
do saber-fazer (Tabela 14); as associações incorretas ou rigidez de pensamento, a aplicação
de regras ou estratégias irrelevantes (Tabela 15), a seleção de estratégias, a manipulação
das habilidades e a apresentação da solução (Tabela 16), o qual poderia ser chamado

Tabela 15 – Erros de acordo com um modelo embasado nos mecanismos do processamento

de informação, segundo Radatz (1979)

Erros relacionados a:

Item
(Alternativa)

Habilidades relacionadas aos itens

a dificuldade de
linguagem

relacionado ao formalismo sim-
bólico

19

Conhecimentos geométricos de espaço e forma e
modelagem algébrica.

165

a dificuldade
de obter
informação
espacial

relacionado à falta de
capacidade de visualização de
diagramas, figuras, “instruções
icônicas”

ao domínio
deficiente de
conteúdos,
fatos e
habilidades

a associações
incorretas ou
rigidez de
pensamento

consideradas como
pré-requisitos

tanto conceitual anterior
quanto no uso de uma regra a
caso específico

a aplicações de
regras ou
estratégias
irrelevantes

o uso inadequado de
estratégias de solução

5(B)

8
11(B)
19

9 (A e D)
15 (B e D)
19

2(C)

3(C e E)

9 (A e D)
11(B e E), 17
13(C)

14(B e D)

16 (A e E)

18(A e B)
20 (A)

1(A)
3(C e E)

4(A e C)

5(B)

8
9 (A e D)
10
14(A e E)

15 (B e D)
16(B)

18(C e D)

Conhecimentos geométricos de grandezas e me-
didas.
Posição no plano cartesiano.
Raciocínio lógico a partir de deduções
Conhecimentos geométricos de espaço e forma e
modelagem algébrica.

Razão entre áreas de figuras planas.
Modelagem algébrica.
Conhecimentos geométricos de espaço e forma e
modelagem algébrica.
Decomposição em fatores primos. Valor posicio-
nal.

Utilizar conhecimentos geométricos e proprieda-
des angulares de polígonos
Razão entre áreas de figuras planas.
Raciocínio lógico a partir de deduções
Resolver situações-problema com numero natu-
rais, valores posicionais.
Raciocínio lógico a partir de deduções, aplicadas
a grandeza de tempo.
Raciocínio lógico a partir de deduções e maximi-
zação
Contagem e principio multiplicativo.
Identificar regularidades observada em sequencia
de números naturais.

Termo central de sequência numérica.
Utilizar conhecimentos geométricos e proprieda-
des angulares de polígonos
Identificar padrões numéricos e operações com
numero inteiros.
Utilizar conhecimentos geométricos e proprieda-
des angulares de polígonos
Posição no plano cartesiano.
Razão entre áreas de figuras planas.
Variações de grandezas proporcionais.
Raciocínio lógico a partir de deduções, aplicadas
a grandeza de tempo.
Modelagem algébrica.
Raciocínio lógico a partir de deduções e maximi-
zação
Contagem e principio multiplicativo.

de eixo prático-teórico. São erros relacionados à atitude do aluno diante da resolução
de situações proposta. Neste eixo prático-teórico, houve erros relacionados a todas as
habilidades inferidas no estudo, mostrando a fragilidade frente à tomada de decisão em
usar os conhecimentos aprendidos por parte dos estudantes.

O aluno é foco de trabalho neste eixo, no qual recomendado-se ao professor uma
intervenção individualizada, apresentando o que se esperava do aluno frente aos itens e
motivar a tomada de iniciativa do aluno em sanar tais erros. O professor pode distribuir
os alunos em grupo e sugerir um trabalho de correção pelos pares, discutindo aberta-
mente quais os erros apresentados ou até mesmo numa conversa individualizada. Pode
também realizar atividades após a tomada de consciência do erro, para verificar se após

166

Considerações Finais

Tabela 16 – As causas dos erros, segundo Casey (CLEMENTS, 1980 apud CURY, 2007)

Erros relacionados a:

Item (Alternativa)

Observações

Exemplo apresentado no texto-base.
Fator de atração: número presente no comando do item.
Fator de atração: resultado aparece no meio do processo de
resolução.
Resultado correto obtido por processo errôneo de interpre-
tação
Fator de atração: formato diferenciado das alternativas

Apresentação de dado irrelevante.
Fator de atração: soma de dados do texto-base.

formulação da
questão

leitura

compreensão

seleção de estratégias

manipulação das habilida-
des

apresentação da solução

2(E)
4(E)
5(C)

5(A), 7(A)

9(C), 10(A e B), 17(A),
18(A)
10
12(A) ,17(A)

1(A), 4(A e C), 5(D), 17

1(A), 4(A e C), 5(D),
10, 11(A e E), 12(A), 15,
16(E), 17,18, 20(A e C)

1(A), 3(C e E), 5(D),10,
13,15, 16(B e E), 17,18,
20(A e C)

1(A), 2(C), 3(C e E)

1(A), 5(C), 11(E), 12(B),
13, 18, 20(A e C)

o enfrentamento houveram melhoras.

Os erros relacionados com a dificuldade de obter informação espacial (Tabela 15),
leitura e compreensão (Tabela 16), podem ser resumidos em um eixo intitulado texto-
base, no qual a ação do professor com relação a interpretação de textos e figuras ligadas
a conceitos matemáticos presentes em situações-problema, avaliativas ou não. Este eixo
não é apenas matemático, mas ligado a linguagem escrita e sua compreensão.

É necessário apresentar estas dificuldades na realização dos itens para toda a equipe
escolar, objetivando uma intervenção com projetos interdisciplinares, para dar mais am-
plitude na visão e na interpretação do aluno dos mais diferentes conceitos, a partir da
linguagem escrita. Dando significado ao dia de aplicação da OBMEP na escola.

Por fim, o eixo de aprendizagem a partir dos erros em lógica ou de raciocínio, que
denota a maturidade do raciocínio lógico dedutivo do aluno. Para se ter uma intervenção
significativa, pressupõe-se que os eixos anteriores devam ser bem trabalhados, para depois
se montar atividades que evidenciem questionamentos lógicos aos alunos.

E finalmente, aos estudantes, sugere-se que tomem seus resultados nesta olim-
píada como o início de uma caminhada em busca da aprendizagem matemática de forma
permanente, contribuindo para desenvolver suas capacidades de crítica, argumentação e
raciocínio.

167

Trabalhos futuros

Frente a essas considerações, vê-se a relevância deste estudo e de sua continuidade
no sentido de embasar a formação de docentes, em todas as esferas de ensino. Da mesma
forma, objetiva-se contribuir para a formação dos elaboradores de avaliação de larga escala.

No entanto este estudo não se finaliza aqui, ainda há outro material de estudo desta
amostra. Os resultados de desempenho a partir da TRI, que podem ajudar a desenviesar os
resultados apresentados, serão usados a posteriori como continuação desta pesquisa. Falta
ainda realizar o feedback deste estudo para as escolas investigadas, e acompanhamento
de resultados futuros a partir da mobilização dos profissionais de tais instituições, de
forma a sanar os obstáculos apresentados pelos estudantes na realização desta edição da
OBMEP, ampliando-se o que está explícito no slogan da Olimpíada: SOMAR TALENTOS
E RESSIGNIFICAR APRENDIZAGENS.

168

—

Considerações Finais

Referências

169

ABRANTES, P. Avaliação e Educação Matemática. Rio de Janeiro: GEPEM, 1995. Ci-
tado na página 52.

BARBOSA, J. L. M. Olimpíadas de Matemática: uma experiência de sucesso em educa-
ção no Ceará. 2014. <http://www.sbpcnet.org.br/livro/57ra/programas/CONF_SIMP/
textos/joaolucasbarbosa-simp.htm>. Acesso: 04/12/2014. Citado na página 37.

BARDIN, L. Análise de conteúdo. Lisboa: Edições 70, 2011. Citado 5 vezes nas páginas
83, 84, 85, 107 e 108.

BARICHELLO, L. Análise de Resolução de Problemas de Cálculo Diferencial em um
Ambiente de Interação Escrita. Dissertação (Mestrado) — Universidade Estadual Pau-
lista/IGCE, São Paulo, 2008. Citado 2 vezes nas páginas 89 e 90.

BELLOS, A. Educação Crítica: incerteza, matemática, responsabilidade. São Paulo: Cor-
tez, 2007. Citado na página 37.

BELLOS, A. Alex no País dos Números – Uma viagem ao mundo maravilhoso da Mate-
mática. São Paulo: Companhia das Letras, 2011. Citado 2 vezes nas páginas 31 e 32.

BODIN, A. L’evaluation du savoir mathématique. Paris: mimeo, 1997. Citado 19 vezes
nas páginas 17, 96, 119, 121, 130, 131, 133, 134, 137, 139, 141, 144, 147, 149, 151, 153,
155, 163 e 164.

BORASI, R. Reconceiving mathematics Instruction: a Focus on Erros. Norwood, NJ:
Ablex Publishing Corporation, 1996. Citado 2 vezes nas páginas 88 e 99.

BRASIL. Parâmetros Curriculares Nacionais. Matemática: ensino de quinta à oitava sé-
rie. Brasília: Secretaria de Educação Fundamental, 2000. Citado 5 vezes nas páginas 49,
51, 52, 55 e 96.

BRASIL. Caderno AVA 2000 – Matemática: Uma Análise Pedagógica. Curitiba: Secretaria
de Estado de Educação, 2001. Citado na página 101.

BURIASCO, L. C. Sobre a avaliação em matemática: Uma reflexão. Educação em Revista,
Belo Horizonte, v. 36, p. 255 – 263, dez. 2002. Citado na página 53.

BURIASCO, L. C.; SOARES, M. T. C. Avaliação de sistemas escolares: da classificação
dos alunos à perspectiva de análise de sua produção matemática. In: (ORG), W. R. V.
(Ed.). Avaliação em Matemática: História e Perspectivas Atuais. [S.l.]: Papirus, 2012. p.
101 – 140. Citado na página 53.

BURIASCO, R. L. C. Algumas considerações sobre avaliação educacional. In: Estudos em
Avaliação Educacional. São Paulo: [s.n.], 2000. v. 1, n. 22, p. 175 – 178. Citado 2 vezes
nas páginas 96 e 100.

BURIASCO, R. L. C. de; FERREIRA, P. E. A.; CIANI, A. B. Avaliação como prática
de investigação. BOLEMA, v. 22, n. 33, p. 69 – 96, 2009. Citado 2 vezes nas páginas 23
e 25.

170

Referências

CLEMENTS, M. A. K. Analyzing children’s errors on written mathematical tasks. In:
Educational Studies in Mathematics. [S.l.: s.n.], 1980. v. 11, n. 1, p. 1 – 21. Citado 17
vezes nas páginas 17, 98, 119, 121, 137, 139, 141, 143, 144, 147, 149, 151, 153, 155, 159,
163 e 166.

CONDé, F. N. Análise empírica de itens. [S.l.], 2001. Citado na página 62.

CONDé, F. N. Relação entre Características do Teste Educacional e Estimativa de Habi-
lidade do Estudante. Brasília: UnB, 2008. Citado 2 vezes nas páginas 61 e 64.

CORREIA, C. E. F. Matemática, Análise de Erros e Formação Continuada de Professores
Polivalentes. São Paulo: Porto de Ideias, 2010. Citado na página 55.

CORREIA, C. E. F. Matemática, análise de erros e formação continuada de professores
polivalentes. São Paulo: Porto de ideais, 2010. Citado 6 vezes nas páginas 89, 90, 91, 92,
93 e 94.

CURY, H. N. Análise de erros e análise de conteúdo: subsídios para uma proposta meto-
dológica. In: Seminário Internacional de Pesquisa em Educação Matemática. [S.l.: s.n.],
2003. v. 2. Citado 3 vezes nas páginas 83, 85 e 90.

CURY, H. N. Análise de erros: o que podemos aprender com as respostas dos alunos. Belo
Horizonte: Editora Autência, 2007. Citado 21 vezes nas páginas 17, 88, 94, 97, 98, 99,
119, 121, 137, 139, 141, 143, 144, 147, 149, 151, 153, 155, 159, 163 e 166.

ESTEBAN, M. T. Ser professora: avaliar e ser avaliada. In: ESTEBAN, M. T. (Ed.).
Escola, currículo e avaliação. São Paulo: Cortez, 2003. p. 13 – 37. Citado na página 25.

FLETCHER, P. R. Da Teoria Clássica dos Testes para os Modelos de Resposta ao Item.
Rio de Janeiro: Escola Nacional de Ciências, 2010. Citado na página 61.

FREITAS, L. C. Crítica e Organização do Trabalho Pedagógico e da Didática. São Paulo:
Papirus, 1995. Citado 2 vezes nas páginas 46 e 47.

FREITAS, L. C. Avalição Educacional: Caminhando Pela Contramão. Rio de Janeiro:
Ed. Petrópolis, 2014. Citado 3 vezes nas páginas 49, 50 e 102.

FREITAS, L. C. de. A internalização da exclusão. Educação & Sociedade, v. 23, n. 80, p.
301 – 327, set. 2002. Citado na página 48.

HADJI, C. Avaliação Desmistificada. Porto Alegre: Artmed, 2001. Citado na página 48.

IMO. 2014. <http://www.imo-official.org>. Acesso: 14/12/2014. Citado 2 vezes nas
páginas 32 e 33.

IMPA; SBM. OBMEP Regulamento. 2014. <http://www.obmep.org.br/regulamento.
html>. Acesso: 14/12/2014. Citado na página 38.

IMPA; SBM. OBMEP. Sítio Oficial. 2014. <http://www.obmep.org.br>. Acesso:
14/12/2014. Citado na página 41.

MACEDO, L. de. Ensaios Construtivistas. São Paulo: Casa do Psicólogo, 1994. Citado
na página 92.

Referências

171

MACIEL, M. V. M. Olimpíada brasileira de matemática das escolas públicas (obmep):
as origens de um projeto de qualificação do ensino de matemática na educação básica.
In: Anais do Encontro Gaúcho de Educação Matemática. Ijuí, RS: [s.n.], 2009. Citado 3
vezes nas páginas 32, 37 e 42.

MARANHãO, T. de P. A. Avaliação do Impacto da Olimpíada Brasileira de Matemá-
tica nas Escolas Públicas 2010. Brasília: Centro de Gestão e Estudos Estratégicos, 2011.
Citado na página 31.

MINAYO, M. C. de S. O desafio do conhecimento: pesquisa qualitativa em saúde. São
Paulo: Hucitec, 2000. Citado 2 vezes nas páginas 83 e 84.

MORAES, R. Análise de conteúdo. In: Educação. Porto Alegre: [s.n.], 1999. v. 22, n. 37.
Citado na página 85.

OBM. Sítio Oficial. 2014. <http://obm.org>. Acesso: 14/12/2014. Citado 2 vezes nas
páginas 17 e 35.

OBM. Sítio Oficial. Brasileiro Ganha Medalha Fields. 2014. <http://obm.org/opencms/
fique_por_dentro/novidades/novidade_0038.hmtl>. Acesso: 14/12/2014. Citado na pá-
gina 36.

OBMEP. OBMEP na Escola. 2015. <http://www.obmep.org.br/OBMEP_na_escola.
html>. Acesso: 24/03/2015. Citado na página 41.

OCED. Relatório Nacional PISA 2012. 2014. <http://download.inep.gov.br/acoes_
internacionais/pisa/resultados/2014/relatorio_nacional_pisa_2012_resultados_
brasileiros.pdf>. Acesso: 05/12/2014. Citado na página 42.

PASQUALI, L. Psicometria: Teoria e Aplicações. Brasília: Editora UnB, 1997. Citado
na página 63.

PERRENOUD, P. A prática reflexiva no ofício de professor: profissionalização e razão
pedagógica. Porto Alegre: Artmed, 2002. Citado na página 72.

PIAGET, J. Seis estudos de psicologia. São Paulo: Forense Universitária, 1991. Citado
na página 93.

PINTO, N. B. O erro como estratégia didática: Estudo do erro no ensino da matemática
elementar. Campinas: Papirus, 2000. Citado 3 vezes nas páginas 89, 92 e 101.

QEDU. Sítio Oficial. 2014. <http://www.qedu.org.br>. Acesso: 14/12/2014. Citado na
página 43.

RABELO, M. Avaliação educacional: fundamentos, metodologia e aplicações no contexto
brasileiro. Rio de Janeiro: SBM, 2013. Citado 23 vezes nas páginas 15, 17, 25, 59, 60, 62,
63, 64, 67, 68, 69, 72, 73, 74, 77, 78, 81, 87, 112, 113, 114, 121 e 123.

RADATZ, H. Errors analysis in mathematics education. In: Journal for Research in
Mathematics Education. [S.l.: s.n.], 1979. v. 10, n. 3, p. 163 – 72. Citado 18 vezes
nas páginas 17, 97, 99, 119, 121, 130, 134, 137, 139, 141, 144, 147, 149, 151, 153, 155, 163
e 165.

172

Referências

RICO, L. Errores y dificuldades em el aprendizaje de lãs matemática. In: KIPRATICK,
J.; GOMES, P.; RICO, L. (Ed.). Educación matemática. Colômbia: Grupo editorial ibe-
roamérica, 1995. p. 69 – 108. Citado 2 vezes nas páginas 90 e 91.

RODRIGUES, M. M. Proposta de análise de itens das provas do saeb sob a perspetiva
pedagógica e a psicométrica. In: Estudos em Avaliação Educacional. [S.l.: s.n.], 2006. v. 17,
n. 34. Citado 7 vezes nas páginas 15, 61, 62, 64, 65, 66 e 116.

ROSSO, A. J.; BERTI, N. M. O erro e o ensino-aprendizagem de matemática na perspec-
tiva do desenvolvimento da autonomia do aluno. In: Boletim de Educação Matemática –
UNESP. [S.l.: s.n.], 2010. v. 23, p. 1005 – 1035. Citado 2 vezes nas páginas 94 e 100.

SADLER, R. Formative assessment and the design of instructional systems. Instructional
Science, v. 18, p. 119 – 144, jun. 1989. Citado 2 vezes nas páginas 46 e 47.

SANTOS, J. R. V. dos. O que alunos da escola básica mostram saber por meio de sua
produção escrita em matemática. Dissertação (Mestrado) — Universidade Estadual de
Londrina, 2007. Citado na página 25.

SCHIRLO, A. C.; MEZA, E. dos S. Obmep: Projeto de política pública para a inclusão
social de estudantes com talento em matemática. In: Anais do XI Encontro Nacional
de Educação Matemática.XI Encontro Nacional de Educação Matemática. Curitiba, PR:
[s.n.], 2013. Citado 2 vezes nas páginas 37 e 38.

SILVA, M. C. N.; BURIASCO, R. L. C. Análise da produção escrita em matemática:
Algumas considerações. In: Ciência e Educação. [S.l.: s.n.], 2005. v. 11, n. 3, p. 499 – 512.
Citado 5 vezes nas páginas 87, 88, 89, 92 e 101.

SKOVSMOSE, O. Educação Matemática Crítica: a questão da democracia. 2. ed. Cam-
pinas: Papirus, 2004. Citado na página 42.

TAILLE, Y. de L. O erro na perspectiva piagetiana. In: AQUINO, J. G. (Ed.). Erro e
fracasso na escola: alternativas teóricas e práticas. São Paulo: Summus, 1997. p. 25 – 44.
Citado na página 94.

TEIXEIRA, L. R. Análise de erros: Uma perspectiva cognitiva para compreender o pro-
cesso de aprendizagem de conteúdos matemáticos. In: Nuances. [S.l.: s.n.], 1997. v. 2.
Citado 3 vezes nas páginas 92, 95 e 96.

TRIVIñOS, A. N. S. Introdução à pesquisa em ciências sociais: a pesquisa qualitativa em
educação. São Paulo: Atlas, 1987. Citado na página 85.

VASCONCELLOS, C. Avaliação: concepção dialética libertadora do processo de avaliação
escolar. 17. ed. São Paulo: Libertad, 2005. Citado na página 105.

VASCONCELLOS, C. do S. Avaliação da aprendizagem: práticas de mudança. São Paulo:
Libertad, 1998. Citado 2 vezes nas páginas 53 e 54.

VILLAS-BOAS, B. M. de F. Avaliação formativa e formação de professores: Ainda um
. Linhas Críticas. Brasília: [s.n.], 2006. v. 12, n. 22, p. 75 – 90. Citado
desafio. In:
4 vezes nas páginas 24, 25, 46 e 47.

VILLAS-BOAS, B. M. de F. Virando a Escola ao Avesso por Meio da Avaliação. São
Paulo: Papirus, 2014. Citado 7 vezes nas páginas 46, 47, 48, 49, 51, 56 e 57.

Apêndices

APÊNDICE A – Termo de Consentimento

175

TERMO DE CONSENTIMENTO LIVRE E ESCLARECIDOPrezado(a) participante:Sou estudante do curso de pós-graduação do programa PROFMAT - MestradoProfissional em Matemática, do Departamento de Matemática da Universidade de Brasília.Estou realizando uma pesquisa sob supervisão do professor Mauro Luiz Rabelo, cujo objetivoé: Analisar os itens e as respostas dos estudantes do 8° e 9° ano do ensino fundamental àsprovas da  OBMEP como meio para oferecer subsídios para a prática docente de professoresde matemática. .Sua participação envolve ceder o uso dos gabaritos respondidos pelos   estudantes do8  °   e 9  °   ano do ensino fundamental às provas da OBMEP de 2014 e possibilitar a divulgação doresultado da pesquisa e as propostas de ação ao grupo de docentes. A participação nesse estudo é voluntária e se você decidir não participar ou quiserdesistir de continuar em qualquer momento, tem  absoluta liberdade de fazê-lo.Na publicação dos resultados desta pesquisa, sua identidade será mantida no maisrigoroso sigilo. Serão omitidas todas as informações que permitam identificá-lo, identificar aescola e/ou identificar os estudantes em estudo. Mesmo não tendo benefícios diretos em participar, indiretamente você estarácontribuindo para a compreensão do fenômeno estudado e para a produção de conhecimentocientífico.Quaisquer dúvidas relativas à pesquisa poderão ser esclarecidas pelo pesquisadorRegiane Quezia Gomes da Costa por telefone 92685976 ou por e-mailregianegomez@gmail.com.Atenciosamente___________________________            Nome e assinatura do(a) estudante____________________________Local e data      __________________________________________________      Nome e assinatura do professor orientadorConsinto em participar deste estudo e declaro ter recebido uma cópia deste termo deconsentimento._____________________________Nome e assinatura do participante______________________________Local e dataUniversidade de Brasília - UnBInstituto de Exatas - IEDepartamento de Matemática - MATMestrado Profissional em Matemática em Rede Nacional - PROFMAT APÊNDICE B – Requerimento CEBRASPE

177

RequerimentoSomos estudantes do curso de pós-graduação do programa PROFMAT-Mestrado Profissional em Matemática, do Departamento de Matemática daUniversidade de Brasília. Estamos realizando dois estudos sob supervisão doprofessor Mauro Luiz Rabelo. O material de estudo são as avaliações daprimeira fase da OBMEP 2014, nível 2, de escolas do Distrito Federal .Viemos requerer junto a Centro Brasileiro de Pesquisa em Avaliação eSeleção e de Promoção de Eventos – CEBRASPE para que elabore, a partirdos dados em anexo, os seguintes documentos:•AGI•CCI•DIFF por sexo e ano do aluno.Desde já agradecemos pela contribuição.Quaisquer dúvidas relativas à pesquisa poderão ser esclarecidas pelaspesquisadoras:Ana Paula Lima Vilarinho, e-mail:  anaplvilarinho@gmail.com ou Regiane Quezia Gomes da Costa, e-mail regianegomez@gmail.com  ,autoras dos respectivos estudos.Atenciosamente___________________________                Ana Paula Lima Vilarinho___________________________       Regiane Quezia Gomes da Costa  __________________________________________      Professor orientador____________________________Local e dataUniversidade de Brasília - UnBInstituto de Exatas - IEDepartamento de Matemática - MATMestrado Profissional em Matemática em Rede Nacional - PROFMAT APÊNDICE C – Atividade Extra

179

Não é necessário se identificar.Olimpíada Brasileira de MatemáticaDas escolas públicasOBMEP 2014Professor(a):_________________________Aluno(a):___________________________Nº:____   Turma:___________  Data:__/__/2014Preparação para Olimpíada Brasileira de Matemática 2014Somando Novos Talentos para o Brasil. E com grande alegria que contamos com sua participacao, de seus professores e de sua escola narealizacao desta atividade. Encare as questoes desta prova como quebra-cabecas interessantes e divirta-secom a busca de suas solucoes. Em folha em anexo coloque as suas solucoes de forma organizadanumerando de acordo com as questoes respondidas.  Grata pela sua participacao.14. Rosane percebeu que seu antigo relógio de paredetinha parado às 9 horas. Ela deu corda no relógio,colocando-o para funcionar sem acertar o horário, e foiimediatamente ao mercado. Chegou ao mercado às 10horas e 10 minutos. Fez suas compras em 1 hora e voltoupara casa. Entrando em casa, notou que o relógio deparede marcava 10 horas e 40 minutos. Se Rosanerealizou os percursos de ida e volta ao mercado emtempos iguais, a que horas ela entrou em casa? A)10 horas e 50 minutos B)11 horas e 10 minutos C)11 horas e 30 minutos D)11 horas e 40 minutos E)11 horas e 50 minutos17. Gustavo possui certa quantidade de moedas de 1, 10,25 e 50 centavos, tendo pelo menos uma de cada valor. Éimpossível combiná-las de modo a obter exatamente 1real. Qual é o maior valor total possível para suasmoedas?A)86 centavos B)1 real e 14 centavos C)1 real e 19 centavos D)1 real e 24 centavos E)1 real e 79 centavos Atividade realizada para estudo de itens e resoluções da OBMEP para estudopós-graduação do programa PROFMAT -Mestrado Profissional em Matemática, doDepartamento de Matemática da Universidade de Brasília. Estudo sob supervisão doprofessor Mauro Luiz Rabelo, cujo objetivo é:Analisar os itens e as respostas dosestudantes do 8° e 9°ano do ensino fundamental às provas da  OBMEP como meio paraoferecer subsídios para a prática docente de professores de matemática. Questões retiradas da prova da primeira fase da OBMEP de 2014 com intuitoverificar as resoluções dos participantes.APÊNDICE D – Questionário de Entrevista

183

Questionamentos para Estudo da Primeira Fase da OBMEPPrezado(a) participante:Somos estudantes do curso de pós-graduação do programa PROFMAT - MestradoProfissional em Matemática, do Departamento de Matemática da Universidade de Brasília.Estamos realizando dois estudos sob supervisão do professor Mauro Luiz Rabelo. O materialde estudo é o mesmo - as avaliações da primeira fase da OBMEP de escolas do DistritoFederal - mas com enfoques diferentes. O objetivo do primeiro estudo é : analisar os itens e as respostas dos estudantes do 8°e 9° ano do Ensino Fundamental às provas da primeira fase da OBMEP como meio paraoferecer um feedback ao aluno e promover a valorização dessa avaliação O objetivo do segundo estudo é : analisar os itens e as respostas dos estudantes do8° e 9° ano do ensino fundamental às provas da  OBMEP como meio para oferecer subsídiospara a prática docente de professores de matemática. Mas para dar continuidade aos nossos estudos precisamos saber mais sobre aelaboração dos itens da prova de primeira fase e sobre os resultados obtidos na RAIG dasescolas que enviaram este documento para o IMPA.Temos alguns questionamentos:1- Se há uma matriz de referência para elaboração das questões?2- Se é possível termos acesso a essa matriz de referência?3- Como são utilizados os itens de ligação que estão presentes nos três níveis daOBMEP?4- Como são caracterizados os itens pelo nível de dificuldade? E qual a suadistribuição na avaliação?5- Se já foram computados os dados da RAIG? Se é possível disponibilizá-los?6- Como são construídos os distratores de cada item?7- Se há incentivo de uso de itens inéditos?8-  Se há normas de construção dos itens?9- Se os itens são apenas desafiadores ou há pré-estabelecimento de avaliação decompetências ou habilidades em cada item?Na publicação dos resultados desta pesquisa, sua identidade será mantida no maisrigoroso sigilo. Serão omitidas todas as informações que permitam identificá-lo, identificar aescola e/ou identificar os estudantes em estudo. Universidade de Brasília - UnBInstituto de Exatas - IEDepartamento de Matemática - MATMestrado Profissional em Matemática em Rede Nacional - PROFMAT Mesmo não tendo benefícios diretos em participar, indiretamente você estarácontribuindo para a compreensão do fenômeno estudado e para a produção de conhecimentocientífico.Desde já agradecemos pela contribuição.Quaisquer dúvidas relativas à pesquisa poderão ser esclarecidas pelas pesquisadoras:Ana Paula Lima Vilarinho, e-mail:  anaplvilarinho@gmail.com ou Regiane Quezia Gomes da Costa, e-mail regianegomez@gmail.com  ,autoras dos respectivos estudos.Anexos

ANEXO A – RAIG

189

I.	Do	total	de	alunos	de	sua	Escola	que	fizeram	as	provas	da	1a	Fase	da	OBMEP,	quantos	são,	em	cada	nível,	do	sexo	masculino	e	do	sexo	feminino?	Nível	1	do	sexo	feminino	do	sexo	masculino	Nível	2	do	sexo	feminino	do	sexo	masculino	Nível	3	do	sexo	feminino	do	sexo	masculinoII.	Preencha	nos	quadros	abaixo	o	total	de	alunos	que	obtiveram	a	nota	indicada,	em	cada	nível.Nível 1Nota 01234567891011121314151617181920Total de alunos observadosNúmero	de	alunos	que	obtiveram	a	nota	indicadaNível 2Nota 01234567891011121314151617181920Total de alunos observadosNúmero	de	alunos	que	obtiveram	a	nota	indicadaNível 3Nota 01234567891011121314151617181920Total de alunos observadosNúmero	de	alunos	que	obtiveram	a	nota	indicadaRELATÓRIO DE ACERTOS E INFORMAÇÕES GERAIS – RAIGPrezado(a)	Diretor(a)	e/ou	Professor(a)	Responsável,Solicitamos a sua preciosa colaboração preenchendo os dados a seguir. Esse relatório não tem por objetivo avaliar as escolas,  e dele não consta qualquer informação que permita identificá-las. Mais uma vez agradecemos a sua colaboração!Vire a página aIII.	Informações	Gerais:	1)	A	sua	escola	desenvolve	atividades	extracurriculares	de	Matemática? q Sim							Quais?	q Clubes	de	Matemática     q Gincanas	e	competições	internas     q Grupos	de	estudo     q Outras________________________________		Informe	o	material	utilizado	nas	atividades	__________________________		____________________________________________________________		____________________________________________________________ q Não	2)	Sobre	o	material	preparado	pela	OBMEP:		a.	Os	professores	de	Matemática	de	sua	escola	conhecem	o	 			Banco	de	Questões	?				   q Sim					Ele	é	trabalhado	pelos	professores	em	sala	de	aula?	q Sim           q Não   q Não		b.	Sobre	o	Banco	de	Questões,	assinale	quantas	alternativas	julgar	 			conveniente:   q É	difícil	ou	muito	difícil	para	os	alunos	   q É	adequado	para	a	preparação	dos	alunos	   q Deveria	apresentar	número	maior	de	questões	   q As	soluções	das	questões	propostas	são	bem	explicadas	   q As	soluções	das	questões	propostas	deveriam	ser	mais	detalhadas	   q Deveria	ser	distribuído	em	maior	quantidade	em	cada	escola	   q Muitos	alunos	o	utilizam		q Poucos	alunos	o	utilizam	   q Serve	de	inspiração	aos	professores	para	elaborar	as	provas	da	escola			c.		Os	professores	de	Matemática	da	sua	escola	trabalham	em	sala	de	aula	 			as	provas	e	as	soluções	da	OBMEP?   q Sim,	apenas	da	1ª	Fase		q Sim,	apenas	da	2ª	Fase	   q Sim,	das	duas	Fases	   q Não		 Por	quê?	__________________________________		d.		Coloque	aqui	observações	e	comentários	sobre	as	provas	da	1ª	Fase:			__________________________________________________________			__________________________________________________________			__________________________________________________________			__________________________________________________________		e.	Os	professores	de	Matemática	de	sua	escola	conhecem	os	vídeos	com				as	soluções	das	provas	da	Obmep?   q Sim   q Não		f.	Os	vídeos	com	as	soluções	das	provas	da	Obmep	são	utilizados			•	em	sala	de	aula	com	alunos?	q Sim	q Não			•	para	discussão	entre	professores?	q Sim	q Não			•	para	planejamento	de	aulas	e/ou	atividades?	q Sim	q Não	3)		Com	que	frequência	você	e	os	professores	de	Matemática	de	sua	escola	 		acessam	o	site	da	OBMEP	(www.obmep.org.br)?  q Nunca  q Raramente  q Frequentemente		4)		O	que	você	e	os	professores	de	sua	escola	procuram	no	site	da	OBMEP?	 		(escolha	até	2	opções)  q Notícias	gerais	sobre	eventos	  q Material	didático	  q Informações	sobre	as	fases	da	OBMEP	  q Regulamento	e	outras	instruções	  q Outros	___________________________________________________	5)		Sobre	o	Programa	de	Iniciação	Científica	(PIC)	para	os	medalhistas	da	 		OBMEP:		a.		Os	professores	de	sua	escola	conhecem	o	PIC?	   q Sim	   q Não	   q Não,	mas	gostariam	de	conhecer			b.		E	o	material	(apostilas,	etc.)	do	PIC?	         q Conhecem	   q Não	conhecem	   q Não,	mas	gostariam	de	receber		6)		A	OBMEP	vem	sendo	realizada	há	dez	anos.	No	decorrer	desse	tempo,	 		você	e	seus	colegas	professores	notaram	em	sua	escola:		a.	que	os	alunos	em	geral	se	interessam	mais	pela	OBMEP,	seus	prêmios	 			e	programas?	   q Sim   q Não			b.		que	aqueles	alunos	que	participam	da	OBMEP	apresentam	progressos	 			em	Matemática?   q Sim   q Não	ANEXO B – Prova OBMEP 2014

193

1. Paula numerou todas as casas do tabuleiro quadrado abaixo, da esquerda para a direita e de cima para baixo, começando com o número 1. A casa central recebeu (cid:82)(cid:3)(cid:81)(cid:126)(cid:80)(cid:72)(cid:85)(cid:82)(cid:3)(cid:24)(cid:17)(cid:3)(cid:54)(cid:72)(cid:3)(cid:72)(cid:79)(cid:68)(cid:3)(cid:191)(cid:3)(cid:93)(cid:72)(cid:85)(cid:3)(cid:82)(cid:3)(cid:80)(cid:72)(cid:86)(cid:80)(cid:82)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)(cid:82)(cid:88)(cid:87)(cid:85)(cid:82)(cid:3)(cid:87)(cid:68)(cid:69)(cid:88)(cid:79)(cid:72)(cid:76)(cid:85)(cid:82)(cid:3)quadrado com 49 casas, qual número será escrito em sua  casa central? A) 23B) 25C) 27D) 29E) 312. Ana Maria apertou as teclas 19!106= de sua calculadora e o resultado 2014 apareceu no visor. (cid:40)(cid:80)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:76)(cid:71)(cid:68)(cid:15)(cid:3)(cid:72)(cid:79)(cid:68)(cid:3)(cid:79)(cid:76)(cid:80)(cid:83)(cid:82)(cid:88)(cid:3)(cid:82)(cid:3)(cid:89)(cid:76)(cid:86)(cid:82)(cid:85)(cid:3)(cid:72)(cid:3)(cid:73)(cid:72)(cid:93)(cid:3)(cid:68)(cid:83)(cid:68)(cid:85)(cid:72)(cid:70)(cid:72)(cid:85)(cid:3)(cid:81)(cid:82)(cid:89)(cid:68)(cid:80)(cid:72)(cid:81)(cid:87)(cid:72)(cid:3)2014 com uma multiplicação de dois números naturais, (cid:80)(cid:68)(cid:86)(cid:15)(cid:3)(cid:71)(cid:72)(cid:86)(cid:87)(cid:68)(cid:3)(cid:89)(cid:72)(cid:93)(cid:15)(cid:3)(cid:68)(cid:83)(cid:72)(cid:85)(cid:87)(cid:68)(cid:81)(cid:71)(cid:82)(cid:3)(cid:86)(cid:72)(cid:76)(cid:86)(cid:3)(cid:87)(cid:72)(cid:70)(cid:79)(cid:68)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:89)(cid:72)(cid:93)(cid:3)(cid:71)(cid:72)(cid:3)(cid:86)(cid:72)(cid:87)(cid:72)(cid:17)(cid:3)(cid:49)(cid:72)(cid:86)(cid:87)(cid:68)(cid:3)segunda multiplicação, qual foi o maior algarismo cuja tecla ela apertou?A) 5B) 6C) 7D) 8E) 92Nível8º e 9º anos do Ensino Fundamental1ª FASE – 27 de maio de 2014Nome completo do(a) aluno(a):  _________________________________________________________________INSTRUÇÕES1. Preencha o cartão-resposta com seu nome completo, sexo, telefone, endereço eletrônico, data de nascimento, ano e turno em que estuda, e lembre-se de assiná-lo.2. A duração da prova é de 2 horas e 30 minutos.3. Cada questão tem cinco alternativas de resposta: (A), (B), (C), (D) e (E) e apenas uma delas é correta.4. Para cada questão marque a alternativa escolhida no cartão-resposta, preenchendo todo o espaço dentro do círculo (cid:70)(cid:82)(cid:85)(cid:85)(cid:72)(cid:86)(cid:83)(cid:82)(cid:81)(cid:71)(cid:72)(cid:81)(cid:87)(cid:72)(cid:3)(cid:68)(cid:3)(cid:79)(cid:105)(cid:83)(cid:76)(cid:86)(cid:3)(cid:82)(cid:88)(cid:3)(cid:68)(cid:3)(cid:70)(cid:68)(cid:81)(cid:72)(cid:87)(cid:68)(cid:3)(cid:72)(cid:86)(cid:73)(cid:72)(cid:85)(cid:82)(cid:74)(cid:85)(cid:105)(cid:191)(cid:3)(cid:70)(cid:68)(cid:3)(cid:68)(cid:93)(cid:88)(cid:79)(cid:3)(cid:82)(cid:88)(cid:3)(cid:83)(cid:85)(cid:72)(cid:87)(cid:68)(cid:3)(cid:11)(cid:112)(cid:3)(cid:83)(cid:85)(cid:72)(cid:73)(cid:72)(cid:85)(cid:116)(cid:89)(cid:72)(cid:79)(cid:3)(cid:68)(cid:3)(cid:70)(cid:68)(cid:81)(cid:72)(cid:87)(cid:68)(cid:12)(cid:17)(cid:3)5. Marque apenas uma alternativa para cada questão. Atenção: se você marcar mais de uma alternativa, perderá os pontos da questão, mesmo que uma das alternativas marcadas seja correta.6.(cid:3)(cid:49)(cid:109)(cid:82)(cid:3)(cid:112)(cid:3)(cid:83)(cid:72)(cid:85)(cid:80)(cid:76)(cid:87)(cid:76)(cid:71)(cid:82)(cid:3)(cid:82)(cid:3)(cid:88)(cid:86)(cid:82)(cid:3)(cid:71)(cid:72)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:85)(cid:88)(cid:80)(cid:72)(cid:81)(cid:87)(cid:82)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:72)(cid:81)(cid:75)(cid:82)(cid:15)(cid:3)(cid:70)(cid:68)(cid:79)(cid:70)(cid:88)(cid:79)(cid:68)(cid:71)(cid:82)(cid:85)(cid:68)(cid:86)(cid:3)(cid:82)(cid:88)(cid:3)(cid:84)(cid:88)(cid:68)(cid:76)(cid:86)(cid:84)(cid:88)(cid:72)(cid:85)(cid:3)(cid:73)(cid:82)(cid:81)(cid:87)(cid:72)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:70)(cid:82)(cid:81)(cid:86)(cid:88)(cid:79)(cid:87)(cid:68)(cid:17)7. Os espaços em branco na prova podem ser usados para rascunho.8.(cid:3)(cid:36)(cid:82)(cid:3)(cid:191)(cid:3)(cid:81)(cid:68)(cid:79)(cid:3)(cid:71)(cid:68)(cid:3)(cid:83)(cid:85)(cid:82)(cid:89)(cid:68)(cid:15)(cid:3)(cid:72)(cid:81)(cid:87)(cid:85)(cid:72)(cid:74)(cid:88)(cid:72)(cid:16)(cid:68)(cid:3)(cid:68)(cid:82)(cid:3)(cid:83)(cid:85)(cid:82)(cid:73)(cid:72)(cid:86)(cid:86)(cid:82)(cid:85)(cid:3)(cid:77)(cid:88)(cid:81)(cid:87)(cid:82)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)(cid:82)(cid:3)(cid:70)(cid:68)(cid:85)(cid:87)(cid:109)(cid:82)(cid:16)(cid:85)(cid:72)(cid:86)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:17)3.(cid:3)(cid:49)(cid:68)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:15)(cid:3)(cid:82)(cid:86)(cid:3)(cid:83)(cid:82)(cid:81)(cid:87)(cid:82)(cid:86)(cid:3)A, B e C estão alinhados. Qual é a (cid:86)(cid:82)(cid:80)(cid:68)(cid:3)(cid:71)(cid:82)(cid:86)(cid:3)(cid:107)(cid:81)(cid:74)(cid:88)(cid:79)(cid:82)(cid:86)(cid:3)(cid:80)(cid:68)(cid:85)(cid:70)(cid:68)(cid:71)(cid:82)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:70)(cid:76)(cid:81)(cid:93)(cid:68)(cid:34)A) 120oB) 180oC) 270oD) 360oE) 540o4. A sequência  6(cid:16), 12, 18(cid:16), 24, 30(cid:16), 36, ... é obtida a partir dos múltiplos positivos de 6, multiplicando-se os termos nas posições ímpares por 1(cid:16)(cid:17)(cid:3)(cid:50)(cid:69)(cid:86)(cid:72)(cid:85)(cid:89)(cid:72)(cid:3)(cid:81)(cid:68)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)a soma dos dois primeiros termos da sequência é igual a 6 e a soma dos três primeiros termos é igual a 12(cid:16). Quantos termos consecutivos dessa sequência devemos somar, a partir do primeiro, para obter 180 como resultado?A) 30B) 60C) 90D) 120E) 180www.obmep.org.brwww.facebook.com/obmepVisite nossas páginas na Internet:termos consecutivos dessa sequência devemos somar, a partir do primeiro, para obter 180 como resultado?147258369ABC2NÍVEL 2OBMEP 201425.(cid:3)(cid:50)(cid:86)(cid:3)(cid:76)(cid:85)(cid:80)(cid:109)(cid:82)(cid:86)(cid:3)(cid:47)(cid:88)(cid:76)(cid:93)(cid:3)(cid:72)(cid:3)(cid:47)(cid:126)(cid:70)(cid:76)(cid:82)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:85)(cid:68)(cid:85)(cid:68)(cid:80)(cid:3)(cid:88)(cid:80)(cid:3)(cid:87)(cid:72)(cid:85)(cid:85)(cid:72)(cid:81)(cid:82)(cid:3)(cid:70)(cid:72)(cid:85)(cid:70)(cid:68)(cid:71)(cid:82)(cid:3)por um muro de 340 metros. Eles construíram um muro interno para dividir o terreno em duas partes. A parte de (cid:47)(cid:88)(cid:76)(cid:93)(cid:3)(cid:191)(cid:3)(cid:70)(cid:82)(cid:88)(cid:3)(cid:70)(cid:72)(cid:85)(cid:70)(cid:68)(cid:71)(cid:68)(cid:3)(cid:83)(cid:82)(cid:85)(cid:3)(cid:88)(cid:80)(cid:3)(cid:80)(cid:88)(cid:85)(cid:82)(cid:3)(cid:71)(cid:72)(cid:3)(cid:21)(cid:25)(cid:19)(cid:3)(cid:80)(cid:72)(cid:87)(cid:85)(cid:82)(cid:86)(cid:3)(cid:72)(cid:3)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:47)(cid:126)(cid:70)(cid:76)(cid:82)(cid:15)(cid:3)por um muro de 240 metros. Qual é o comprimento do muro interno?A) 80 mB) 100 m C) 160 mD) 180 mE) 200 m6. Cinco meninas não estão totalmente de acordo sobre a data da prova de Matemática.(cid:135)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:68)(cid:3)(cid:71)(cid:76)(cid:93)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:72)(cid:80)(cid:3)(cid:68)(cid:74)(cid:82)(cid:86)(cid:87)(cid:82)(cid:15)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:20)(cid:25)(cid:15)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:81)(cid:71)(cid:68)(cid:16)feira; (cid:135)(cid:3)(cid:39)(cid:68)(cid:81)(cid:76)(cid:72)(cid:79)(cid:68)(cid:3)(cid:71)(cid:76)(cid:93)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:72)(cid:80)(cid:3)(cid:68)(cid:74)(cid:82)(cid:86)(cid:87)(cid:82)(cid:15)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:20)(cid:25)(cid:15)(cid:3)(cid:87)(cid:72)(cid:85)(cid:111)(cid:68)(cid:16)(cid:73)(cid:72)(cid:76)(cid:85)(cid:68)(cid:30)(cid:135)(cid:3)(cid:41)(cid:72)(cid:85)(cid:81)(cid:68)(cid:81)(cid:71)(cid:68)(cid:3)(cid:71)(cid:76)(cid:93)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:72)(cid:80)(cid:3)(cid:86)(cid:72)(cid:87)(cid:72)(cid:80)(cid:69)(cid:85)(cid:82)(cid:15)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:20)(cid:26)(cid:15)(cid:3)(cid:87)(cid:72)(cid:85)(cid:111)(cid:68)(cid:16)feira; (cid:135)(cid:3)(cid:51)(cid:68)(cid:87)(cid:85)(cid:116)(cid:70)(cid:76)(cid:68)(cid:3)(cid:71)(cid:76)(cid:93)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:72)(cid:80)(cid:3)(cid:68)(cid:74)(cid:82)(cid:86)(cid:87)(cid:82)(cid:15)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:20)(cid:26)(cid:15)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:81)(cid:71)(cid:68)(cid:16)feira; (cid:135)(cid:3)(cid:55)(cid:68)(cid:87)(cid:76)(cid:68)(cid:81)(cid:72)(cid:3)(cid:71)(cid:76)(cid:93)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:72)(cid:80)(cid:3)(cid:86)(cid:72)(cid:87)(cid:72)(cid:80)(cid:69)(cid:85)(cid:82)(cid:15)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:20)(cid:26)(cid:15)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:81)(cid:71)(cid:68)(cid:16)feira.Somente uma está certa, e as outras acertaram pelo menos uma das informações: o mês, o dia do mês ou o dia da semana. Quem está certa?A) AndreaB) Daniela (cid:38)(cid:12)(cid:3)(cid:41)(cid:72)(cid:85)(cid:81)(cid:68)(cid:81)(cid:71)(cid:68)(cid:3)D) Patrícia (cid:40)(cid:12)(cid:3)(cid:55)(cid:68)(cid:87)(cid:76)(cid:68)(cid:81)(cid:72)(cid:3)7. Rodrigo comprou três cadernos iguais em uma promoção na qual o segundo e o terceiro cadernos eram vendidos, respectivamente, com 20% e 40% de desconto (cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:3)(cid:82)(cid:3)(cid:83)(cid:85)(cid:72)(cid:111)(cid:82)(cid:3)(cid:71)(cid:82)(cid:3)(cid:83)(cid:85)(cid:76)(cid:80)(cid:72)(cid:76)(cid:85)(cid:82)(cid:17)(cid:3)(cid:49)(cid:82)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:76)(cid:81)(cid:87)(cid:72)(cid:15)(cid:3)(cid:87)(cid:72)(cid:85)(cid:80)(cid:76)(cid:81)(cid:68)(cid:71)(cid:68)(cid:3)(cid:68)(cid:3)promoção, Gustavo comprou três cadernos iguais aos de Rodrigo, todos sem desconto. Percentualmente, quanto Rodrigo pagou a menos que Gustavo? A)  20%B) 22%C)  25%D) 28%E)  30%8.(cid:3)(cid:50)(cid:3)(cid:83)(cid:85)(cid:82)(cid:73)(cid:72)(cid:86)(cid:86)(cid:82)(cid:85)(cid:3)(cid:48)(cid:76)(cid:70)(cid:75)(cid:72)(cid:79)(cid:3)(cid:68)(cid:83)(cid:79)(cid:76)(cid:70)(cid:82)(cid:88)(cid:3)(cid:71)(cid:88)(cid:68)(cid:86)(cid:3)(cid:83)(cid:85)(cid:82)(cid:89)(cid:68)(cid:86)(cid:3)(cid:68)(cid:3)(cid:86)(cid:72)(cid:88)(cid:86)(cid:3)(cid:71)(cid:72)(cid:93)(cid:3)(cid:68)(cid:79)(cid:88)(cid:81)(cid:82)(cid:86)(cid:3)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:88)(cid:79)(cid:74)(cid:82)(cid:88)(cid:3)(cid:68)(cid:86)(cid:3)(cid:81)(cid:82)(cid:87)(cid:68)(cid:86)(cid:3)(cid:83)(cid:82)(cid:85)(cid:3)(cid:80)(cid:72)(cid:76)(cid:82)(cid:3)(cid:71)(cid:82)(cid:3)(cid:74)(cid:85)(cid:105)(cid:191)(cid:3)(cid:70)(cid:82)(cid:3)(cid:80)(cid:82)(cid:86)(cid:87)(cid:85)(cid:68)(cid:71)(cid:82)(cid:3)abaixo. Por exemplo, o aluno A obteve notas 9 e 8 nas provas 1 e 2, respectivamente; já o aluno B obteve notas 3 e 5. Para um aluno ser aprovado, a média aritmética de suas notas deve ser igual a 6 ou maior do que 6. Quantos alunos foram aprovados?A) 6B) 7C) 8D) 9E) 109. O polígono ABCDEF é um hexágono regular. Os pontos M e N são pontos médios dos lados AF e BC, respectivamente. O hexágono ABNGHM é simétrico em relação à reta que passa por M e N(cid:17)(cid:3)(cid:52)(cid:88)(cid:68)(cid:79)(cid:3)(cid:112)(cid:3)(cid:68)(cid:3)(cid:85)(cid:68)(cid:93)(cid:109)(cid:82)(cid:3)(cid:72)(cid:81)(cid:87)(cid:85)(cid:72)(cid:3)(cid:68)(cid:86)(cid:3)áreas dos hexágonos ABNGHM e ABCDEF?A) 310B) 411C) 37D) 715 E) 512 10. Sempre que Yurika abastece seu carro, ela enche o tanque e anota a data, a quilometragem marcada no painel e a quantidade de litros de combustível colocada. (cid:49)(cid:68)(cid:3)(cid:87)(cid:68)(cid:69)(cid:72)(cid:79)(cid:68)(cid:3)(cid:72)(cid:86)(cid:87)(cid:109)(cid:82)(cid:3)(cid:82)(cid:86)(cid:3)(cid:71)(cid:68)(cid:71)(cid:82)(cid:86)(cid:3)(cid:85)(cid:72)(cid:74)(cid:76)(cid:86)(cid:87)(cid:85)(cid:68)(cid:71)(cid:82)(cid:86)(cid:3)(cid:83)(cid:82)(cid:85)(cid:3)(cid:60)(cid:88)(cid:85)(cid:76)(cid:78)(cid:68)(cid:3)(cid:72)(cid:80)(cid:3)(cid:71)(cid:82)(cid:76)(cid:86)(cid:3)abastecimentos consecutivos. Quantos quilômetros por litro, (cid:68)(cid:83)(cid:85)(cid:82)(cid:91)(cid:76)(cid:80)(cid:68)(cid:71)(cid:68)(cid:80)(cid:72)(cid:81)(cid:87)(cid:72)(cid:15)(cid:3)(cid:73)(cid:72)(cid:93)(cid:3)(cid:82)(cid:3)(cid:70)(cid:68)(cid:85)(cid:85)(cid:82)(cid:3)(cid:71)(cid:72)(cid:3)(cid:60)(cid:88)(cid:85)(cid:76)(cid:78)(cid:68)(cid:3)(cid:81)(cid:72)(cid:86)(cid:86)(cid:72)(cid:3)(cid:83)(cid:72)(cid:85)(cid:116)(cid:82)(cid:71)(cid:82)(cid:34)A) 5,6B) 9,8C) 11,1D) 12,9E) 40,1murointernoLúcioLuizProva 1Prova 20ADFGEBHICJ551010ABEDGHFMNCdatakmlitros01/0235 72332,507/0236 14443,0..........................................3NÍVEL 2OBMEP 2014311.(cid:3)(cid:55)(cid:82)(cid:71)(cid:82)(cid:86)(cid:3)(cid:82)(cid:86)(cid:3)(cid:81)(cid:126)(cid:80)(cid:72)(cid:85)(cid:82)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:20)(cid:3)(cid:68)(cid:3)(cid:21)(cid:23)(cid:3)(cid:71)(cid:72)(cid:89)(cid:72)(cid:80)(cid:3)(cid:86)(cid:72)(cid:85)(cid:3)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:87)(cid:82)(cid:86)(cid:3)(cid:81)(cid:68)(cid:86)(cid:3)faces de um cubo, obedecendo-se às seguintes regras: (cid:135)(cid:3)(cid:72)(cid:80)(cid:3)(cid:70)(cid:68)(cid:71)(cid:68)(cid:3)(cid:73)(cid:68)(cid:70)(cid:72)(cid:3)(cid:71)(cid:72)(cid:89)(cid:72)(cid:80)(cid:3)(cid:86)(cid:72)(cid:85)(cid:3)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:87)(cid:82)(cid:86)(cid:3)(cid:84)(cid:88)(cid:68)(cid:87)(cid:85)(cid:82)(cid:3)(cid:81)(cid:126)(cid:80)(cid:72)(cid:85)(cid:82)(cid:86)(cid:3)consecutivos;(cid:135)(cid:3)(cid:72)(cid:80)(cid:3)(cid:70)(cid:68)(cid:71)(cid:68)(cid:3)(cid:83)(cid:68)(cid:85)(cid:3)(cid:71)(cid:72)(cid:3)(cid:73)(cid:68)(cid:70)(cid:72)(cid:86)(cid:3)(cid:82)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:86)(cid:15)(cid:3)(cid:68)(cid:3)(cid:86)(cid:82)(cid:80)(cid:68)(cid:3)(cid:71)(cid:82)(cid:3)(cid:80)(cid:68)(cid:76)(cid:82)(cid:85)(cid:3)número de uma com o menor número da outra deve ser igual a 25. Se os números 7 e 23 estiverem escritos no cubo como na (cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:15)(cid:3)(cid:84)(cid:88)(cid:68)(cid:79)(cid:3)(cid:112)(cid:3)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:82)(cid:85)(cid:3)(cid:81)(cid:126)(cid:80)(cid:72)(cid:85)(cid:82)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:83)(cid:82)(cid:71)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:3)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:87)(cid:82)(cid:3)(cid:81)(cid:68)(cid:3)(cid:73)(cid:68)(cid:70)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:87)(cid:68)(cid:70)(cid:68)(cid:71)(cid:68)(cid:3)(cid:72)(cid:80)(cid:3)(cid:70)(cid:76)(cid:81)(cid:93)(cid:68)(cid:34)A) 1B) 5C) 9D) 11E) 1712. Começando com um quadrado de 1 cm de lado, (cid:73)(cid:82)(cid:85)(cid:80)(cid:68)(cid:80)(cid:82)(cid:86)(cid:3)(cid:88)(cid:80)(cid:68)(cid:3)(cid:86)(cid:72)(cid:84)(cid:88)(cid:114)(cid:81)(cid:70)(cid:76)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:86)(cid:15)(cid:3)(cid:70)(cid:82)(cid:80)(cid:82)(cid:3)(cid:81)(cid:68)(cid:3)(cid:76)(cid:79)(cid:88)(cid:86)(cid:87)(cid:85)(cid:68)(cid:111)(cid:109)(cid:82)(cid:17)(cid:3)(cid:38)(cid:68)(cid:71)(cid:68)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:15)(cid:3)(cid:68)(cid:3)(cid:83)(cid:68)(cid:85)(cid:87)(cid:76)(cid:85)(cid:3)(cid:71)(cid:68)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:81)(cid:71)(cid:68)(cid:15)(cid:3)(cid:112)(cid:3)(cid:73)(cid:82)(cid:85)(cid:80)(cid:68)(cid:71)(cid:68)(cid:3)(cid:88)(cid:81)(cid:76)(cid:81)(cid:71)(cid:82)(cid:16)(cid:86)(cid:72)(cid:3)(cid:3)(cid:87)(cid:85)(cid:114)(cid:86)(cid:3)cópias da anterior. Os contornos destacados em vermelho (cid:71)(cid:68)(cid:86)(cid:3)(cid:84)(cid:88)(cid:68)(cid:87)(cid:85)(cid:82)(cid:3)(cid:83)(cid:85)(cid:76)(cid:80)(cid:72)(cid:76)(cid:85)(cid:68)(cid:86)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:86)(cid:3)(cid:80)(cid:72)(cid:71)(cid:72)(cid:80)(cid:15)(cid:3)(cid:85)(cid:72)(cid:86)(cid:83)(cid:72)(cid:70)(cid:87)(cid:76)(cid:89)(cid:68)(cid:80)(cid:72)(cid:81)(cid:87)(cid:72)(cid:15)(cid:3)4 cm, 8 cm, 20 cm e 56 cm. Quanto mede o contorno da (cid:41)(cid:76)(cid:74)(cid:88)(cid:85)(cid:68)(cid:3)(cid:25)(cid:34)A) 88 cmB) 164 cmC) 172 cmD) 488 cmE) 492 cm13.(cid:3)(cid:49)(cid:68)(cid:3)(cid:70)(cid:82)(cid:81)(cid:87)(cid:68)(cid:3)(cid:76)(cid:81)(cid:71)(cid:76)(cid:70)(cid:68)(cid:71)(cid:68)(cid:3)(cid:68)(cid:3)(cid:86)(cid:72)(cid:74)(cid:88)(cid:76)(cid:85)(cid:15)(cid:3)(cid:68)(cid:86)(cid:3)(cid:79)(cid:72)(cid:87)(cid:85)(cid:68)(cid:86)(cid:3)(cid:59)(cid:15)(cid:3)(cid:60)(cid:3)(cid:72)(cid:3)(cid:61)(cid:3)representam algarismos distintos. Qual é o algarismo (cid:85)(cid:72)(cid:83)(cid:85)(cid:72)(cid:86)(cid:72)(cid:81)(cid:87)(cid:68)(cid:71)(cid:82)(cid:3)(cid:83)(cid:72)(cid:79)(cid:68)(cid:3)(cid:79)(cid:72)(cid:87)(cid:85)(cid:68)(cid:3)(cid:61)(cid:34)A) 1B) 3C) 5D) 6E) 814. Rosane percebeu que seu antigo relógio de parede tinha parado às 9 horas. Ela deu corda no relógio, colocando-o para funcionar sem acertar o horário, e foi imediatamente ao mercado. Chegou ao mercado às 10 horas e 10 minutos. (cid:41)(cid:72)(cid:93)(cid:3)(cid:86)(cid:88)(cid:68)(cid:86)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:85)(cid:68)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:20)(cid:3)(cid:75)(cid:82)(cid:85)(cid:68)(cid:3)(cid:72)(cid:3)(cid:89)(cid:82)(cid:79)(cid:87)(cid:82)(cid:88)(cid:3)(cid:83)(cid:68)(cid:85)(cid:68)(cid:3)(cid:70)(cid:68)(cid:86)(cid:68)(cid:17)(cid:3)(cid:40)(cid:81)(cid:87)(cid:85)(cid:68)(cid:81)(cid:71)(cid:82)(cid:3)em casa, notou que o relógio de parede marcava 10 horas (cid:72)(cid:3)(cid:23)(cid:19)(cid:3)(cid:80)(cid:76)(cid:81)(cid:88)(cid:87)(cid:82)(cid:86)(cid:17)(cid:3)(cid:54)(cid:72)(cid:3)(cid:53)(cid:82)(cid:86)(cid:68)(cid:81)(cid:72)(cid:3)(cid:85)(cid:72)(cid:68)(cid:79)(cid:76)(cid:93)(cid:82)(cid:88)(cid:3)(cid:82)(cid:86)(cid:3)(cid:83)(cid:72)(cid:85)(cid:70)(cid:88)(cid:85)(cid:86)(cid:82)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:76)(cid:71)(cid:68)(cid:3)(cid:72)(cid:3)volta ao mercado em tempos iguais, a que horas ela entrou em casa?A) 10 horas e 50 minutos B) 11 horas e 10 minutosC) 11 horas e 30 minutosD) 11 horas e 40 minutosE) 11 horas e 50 minutos15.(cid:3)(cid:55)(cid:112)(cid:79)(cid:76)(cid:82)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:85)(cid:82)(cid:88)(cid:3)(cid:79)(cid:68)(cid:85)(cid:68)(cid:81)(cid:77)(cid:68)(cid:86)(cid:15)(cid:3)(cid:80)(cid:68)(cid:111)(cid:109)(cid:86)(cid:3)(cid:72)(cid:3)(cid:88)(cid:89)(cid:68)(cid:86)(cid:3)(cid:81)(cid:82)(cid:3)(cid:80)(cid:72)(cid:85)(cid:70)(cid:68)(cid:71)(cid:82)(cid:17)(cid:3)(cid:50)(cid:3)preço por quilograma de cada fruta está na tabela abaixo. Metade do peso total da compra era de maçãs e o peso (cid:71)(cid:68)(cid:86)(cid:3)(cid:88)(cid:89)(cid:68)(cid:86)(cid:3)(cid:72)(cid:85)(cid:68)(cid:3)(cid:82)(cid:3)(cid:71)(cid:82)(cid:69)(cid:85)(cid:82)(cid:3)(cid:71)(cid:82)(cid:3)(cid:83)(cid:72)(cid:86)(cid:82)(cid:3)(cid:71)(cid:68)(cid:86)(cid:3)(cid:79)(cid:68)(cid:85)(cid:68)(cid:81)(cid:77)(cid:68)(cid:86)(cid:17)(cid:3)(cid:54)(cid:72)(cid:3)(cid:55)(cid:112)(cid:79)(cid:76)(cid:82)(cid:3)(cid:74)(cid:68)(cid:86)(cid:87)(cid:82)(cid:88)(cid:3)R$ 38,00, quantos quilogramas de frutas ele comprou?A) 10B) 11C) 12D) 13E) 1416. A mãe de Lúcia pediu para ela não comer mais de 10 docinhos por dia. Além disso, se em um dia ela comer mais de 7 docinhos, nos dois dias seguintes não poderá comer mais de 5 docinhos em cada dia. Qual é o maior número de docinhos que Lúcia pode comer durante um período de 29 dias seguidos, obedecendo ao pedido de sua mãe?A) 203B) 204C) 206D) 213E) 290volta ao mercado em tempos iguais, a que horas ela entrou 237X X X XYYYYZ Z Z ZYX X X Z+Preços (R$) por quilogramaMaçã3,00Uva4,00Laranja2,00Figura 1Figura 2Figura 3Figura 4...19. Um cubo de madeira foi pintado de vermelho e depois cortado em n3 cubinhos iguais, 2n(cid:33). Alguns desses (cid:70)(cid:88)(cid:69)(cid:76)(cid:81)(cid:75)(cid:82)(cid:86)(cid:3)(cid:191)(cid:3)(cid:70)(cid:68)(cid:85)(cid:68)(cid:80)(cid:3)(cid:86)(cid:72)(cid:80)(cid:3)(cid:81)(cid:72)(cid:81)(cid:75)(cid:88)(cid:80)(cid:68)(cid:3)(cid:73)(cid:68)(cid:70)(cid:72)(cid:3)(cid:83)(cid:76)(cid:81)(cid:87)(cid:68)(cid:71)(cid:68)(cid:3)(cid:72)(cid:3)(cid:82)(cid:88)(cid:87)(cid:85)(cid:82)(cid:86)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)uma, duas ou três faces pintadas. Se o número de cubinhos sem nenhuma face pintada é igual ao número de cubinhos com exatamente uma face pintada, qual é o valor de n?A) 7B) 8C) 9D) 10E) 1120.(cid:3)(cid:53)(cid:82)(cid:71)(cid:85)(cid:76)(cid:74)(cid:82)(cid:3)(cid:69)(cid:85)(cid:76)(cid:81)(cid:70)(cid:68)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)(cid:88)(cid:80)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:71)(cid:82)(cid:76)(cid:86)(cid:3)(cid:80)(cid:72)(cid:87)(cid:85)(cid:82)(cid:86)(cid:15)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)marcas de centímetro em centímetro. Começando pela (cid:83)(cid:82)(cid:81)(cid:87)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:80)(cid:68)(cid:85)(cid:70)(cid:68)(cid:3)(cid:19)(cid:3)(cid:70)(cid:80)(cid:15)(cid:3)(cid:72)(cid:79)(cid:72)(cid:3)(cid:71)(cid:82)(cid:69)(cid:85)(cid:68)(cid:3)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:89)(cid:105)(cid:85)(cid:76)(cid:68)(cid:86)(cid:3)(cid:89)(cid:72)(cid:93)(cid:72)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:93)(cid:76)(cid:74)(cid:88)(cid:72)(cid:16)(cid:93)(cid:68)(cid:74)(cid:88)(cid:72)(cid:15)(cid:3)(cid:70)(cid:82)(cid:80)(cid:82)(cid:3)(cid:81)(cid:68)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:15)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:81)(cid:71)(cid:82)(cid:3)(cid:83)(cid:72)(cid:71)(cid:68)(cid:111)(cid:82)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)de mesmo tamanho até dobrar um último pedaço, que pode ser menor do que os demais. Ele observa que as marcas (cid:71)(cid:72)(cid:3)(cid:23)(cid:28)(cid:3)(cid:70)(cid:80)(cid:3)(cid:72)(cid:3)(cid:71)(cid:72)(cid:3)(cid:26)(cid:20)(cid:3)(cid:70)(cid:80)(cid:3)(cid:191)(cid:3)(cid:70)(cid:68)(cid:85)(cid:68)(cid:80)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:83)(cid:72)(cid:71)(cid:68)(cid:111)(cid:82)(cid:86)(cid:3)(cid:89)(cid:76)(cid:93)(cid:76)(cid:81)(cid:75)(cid:82)(cid:86)(cid:17)(cid:3)(cid:40)(cid:79)(cid:72)(cid:3)(cid:82)(cid:69)(cid:86)(cid:72)(cid:85)(cid:89)(cid:68)(cid:3)(cid:87)(cid:68)(cid:80)(cid:69)(cid:112)(cid:80)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:68)(cid:3)(cid:80)(cid:68)(cid:85)(cid:70)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:20)(cid:22)(cid:28)(cid:3)(cid:70)(cid:80)(cid:3)(cid:191)(cid:3)(cid:70)(cid:82)(cid:88)(cid:3)alinhada com elas.  Com qual marca do penúltimo pedaço a (cid:83)(cid:82)(cid:81)(cid:87)(cid:68)(cid:3)(cid:191)(cid:3)(cid:81)(cid:68)(cid:79)(cid:3)(cid:71)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:191)(cid:3)(cid:70)(cid:82)(cid:88)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:34)A) 160 cmB) 176 cmC) 184 cmD) 190 cmE) 196 cmNÍVEL 2OBMEP 2014Operacionalização:19. Um cubo de madeira foi pintado de vermelho e depois cortado em n3 cubinhos iguais, 2n(cid:33). Alguns desses (cid:70)(cid:88)(cid:69)(cid:76)(cid:81)(cid:75)(cid:82)(cid:86)(cid:3)(cid:191)(cid:3)(cid:70)(cid:68)(cid:85)(cid:68)(cid:80)(cid:3)(cid:86)(cid:72)(cid:80)(cid:3)(cid:81)(cid:72)(cid:81)(cid:75)(cid:88)(cid:80)(cid:68)(cid:3)(cid:73)(cid:68)(cid:70)(cid:72)(cid:3)(cid:83)(cid:76)(cid:81)(cid:87)(cid:68)(cid:71)(cid:68)(cid:3)(cid:72)(cid:3)(cid:82)(cid:88)(cid:87)(cid:85)(cid:82)(cid:86)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)uma, duas ou três faces pintadas. Se o número de cubinhos sem nenhuma face pintada é igual ao número de cubinhos com exatamente uma face pintada, qual é o valor de n?A) 7B) 8C) 9D) 10E) 1120.(cid:3)(cid:53)(cid:82)(cid:71)(cid:85)(cid:76)(cid:74)(cid:82)(cid:3)(cid:69)(cid:85)(cid:76)(cid:81)(cid:70)(cid:68)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)(cid:88)(cid:80)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:71)(cid:82)(cid:76)(cid:86)(cid:3)(cid:80)(cid:72)(cid:87)(cid:85)(cid:82)(cid:86)(cid:15)(cid:3)(cid:70)(cid:82)(cid:80)(cid:3)marcas de centímetro em centímetro. Começando pela (cid:83)(cid:82)(cid:81)(cid:87)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:80)(cid:68)(cid:85)(cid:70)(cid:68)(cid:3)(cid:19)(cid:3)(cid:70)(cid:80)(cid:15)(cid:3)(cid:72)(cid:79)(cid:72)(cid:3)(cid:71)(cid:82)(cid:69)(cid:85)(cid:68)(cid:3)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:89)(cid:105)(cid:85)(cid:76)(cid:68)(cid:86)(cid:3)(cid:89)(cid:72)(cid:93)(cid:72)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:93)(cid:76)(cid:74)(cid:88)(cid:72)(cid:16)(cid:93)(cid:68)(cid:74)(cid:88)(cid:72)(cid:15)(cid:3)(cid:70)(cid:82)(cid:80)(cid:82)(cid:3)(cid:81)(cid:68)(cid:3)(cid:191)(cid:3)(cid:74)(cid:88)(cid:85)(cid:68)(cid:15)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:81)(cid:71)(cid:82)(cid:3)(cid:83)(cid:72)(cid:71)(cid:68)(cid:111)(cid:82)(cid:86)(cid:3)(cid:71)(cid:72)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)de mesmo tamanho até dobrar um último pedaço, que pode ser menor do que os demais. Ele observa que as marcas (cid:71)(cid:72)(cid:3)(cid:23)(cid:28)(cid:3)(cid:70)(cid:80)(cid:3)(cid:72)(cid:3)(cid:71)(cid:72)(cid:3)(cid:26)(cid:20)(cid:3)(cid:70)(cid:80)(cid:3)(cid:191)(cid:3)(cid:70)(cid:68)(cid:85)(cid:68)(cid:80)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:86)(cid:3)(cid:72)(cid:80)(cid:3)(cid:83)(cid:72)(cid:71)(cid:68)(cid:111)(cid:82)(cid:86)(cid:3)(cid:89)(cid:76)(cid:93)(cid:76)(cid:81)(cid:75)(cid:82)(cid:86)(cid:17)(cid:3)(cid:40)(cid:79)(cid:72)(cid:3)(cid:82)(cid:69)(cid:86)(cid:72)(cid:85)(cid:89)(cid:68)(cid:3)(cid:87)(cid:68)(cid:80)(cid:69)(cid:112)(cid:80)(cid:3)(cid:84)(cid:88)(cid:72)(cid:3)(cid:68)(cid:3)(cid:80)(cid:68)(cid:85)(cid:70)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:20)(cid:22)(cid:28)(cid:3)(cid:70)(cid:80)(cid:3)(cid:191)(cid:3)(cid:70)(cid:82)(cid:88)(cid:3)alinhada com elas.  Com qual marca do penúltimo pedaço a (cid:83)(cid:82)(cid:81)(cid:87)(cid:68)(cid:3)(cid:191)(cid:3)(cid:81)(cid:68)(cid:79)(cid:3)(cid:71)(cid:68)(cid:3)(cid:191)(cid:3)(cid:87)(cid:68)(cid:3)(cid:191)(cid:3)(cid:70)(cid:82)(cid:88)(cid:3)(cid:86)(cid:82)(cid:69)(cid:85)(cid:72)(cid:83)(cid:82)(cid:86)(cid:87)(cid:68)(cid:34)A) 160 cmB) 176 cmC) 184 cmD) 190 cmE) 196 cmNÍVEL 2OBMEP 2014Operacionalização:417. Gustavo possui certa quantidade de moedas de 1, 10, 25 e 50 centavos, tendo pelo menos uma de cada valor. É impossível combiná-las de modo a obter exatamente 1 real. Qual é o maior valor total possível para suas moedas?A) 86 centavosB) 1 real e 14 centavosC) 1 real e 19 centavosD) 1 real e 24 centavosE) 1 real e 79 centavos18. O número 2014 tem quatro algarismos distintos, um ímpar e três pares, sendo um deles 0. Quantos números possuem exatamente essas características?A) 60B) 180C) 360D) 420E) 540(cid:36)(cid:3)(cid:79)(cid:76)(cid:86)(cid:87)(cid:68)(cid:3)(cid:71)(cid:72)(cid:3)(cid:70)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:191)(cid:3)(cid:70)(cid:68)(cid:71)(cid:82)(cid:86)(cid:3)(cid:83)(cid:68)(cid:85)(cid:68)(cid:3)(cid:68)(cid:3)(cid:21)(cid:157)(cid:3)(cid:41)(cid:68)(cid:86)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:71)(cid:76)(cid:89)(cid:88)(cid:79)(cid:74)(cid:68)(cid:71)(cid:68)(cid:3)(cid:68)(cid:3)(cid:83)(cid:68)(cid:85)(cid:87)(cid:76)(cid:85)(cid:3)(cid:71)(cid:72)(cid:3)13 de agosto. (cid:36)(cid:3)(cid:83)(cid:85)(cid:82)(cid:89)(cid:68)(cid:3)(cid:71)(cid:68)(cid:3)(cid:21)(cid:157)(cid:3)(cid:41)(cid:68)(cid:86)(cid:72)(cid:3)(cid:86)(cid:72)(cid:85)(cid:105)(cid:3)(cid:85)(cid:72)(cid:68)(cid:79)(cid:76)(cid:93)(cid:68)(cid:71)(cid:68)(cid:3)(cid:81)(cid:82)(cid:3)(cid:71)(cid:76)(cid:68)(cid:3)13 de setembro(cid:17)(cid:3)(cid:41)(cid:76)(cid:84)(cid:88)(cid:72)(cid:3)(cid:68)(cid:87)(cid:72)(cid:81)(cid:87)(cid:82)(cid:4)ANEXO C – Solução da Prova da OBMEP
2014

199

    Solução da prova da 1a fase OBMEP 2014 − Nível 2  1   QUESTÃO 1 ALTERNATIVA B O tabuleiro 77× pode ser facilmente preenchido e constata-se que na casa central deve aparecer o número 25, mas existe uma maneira melhor de fazer isto: no tabuleiro quadrado de 49 casas, a quantidade de números antes da casa central é igual à quantidade de números distribuídos depois da casa central. Logo, chamando de x o número que ocupa a casa central temos 1x− números antes dele e 49x− depois dele. Portanto, 149xx−=−, donde 250x=. Portanto, 25x=. De modo geral, para qualquer tabuleiro quadrado de 21n+ casas (um número ímpar), o número x que aparece na casa central satisfaz a igualdade 1(21)xnx−=+−. Logo, 222xn=+ e, portanto, 1xn=+.    QUESTÃO 2 ALTERNATIVA D Observe que 20141910621953=×=××. Assim, a menos da ordem dos fatores, existem somente quatro formas possíveis de se fazer aparecer 2014 na calculadora como uma multiplicação de dois números naturais: • Apertando sete teclas: 12014×= • Apertando sete teclas: 21007×= • Apertando sete teclas: 19106×= • Apertando seis teclas: 3853×=  (Este fato se deve à decomposição única de um número inteiro positivo em fatores primos, a menos da ordem dos fatores. Os fatores primos de 2014 são 2, 19 e 53). Dentre as quatro possibilidades, em só uma delas seis teclas são pressionadas; concluímos então que as seis teclas que Ana Maria apertou foram 3, 8, x, 5, 3 e =. Portanto, o maior algarismo cuja tecla ela apertou foi 8.   QUESTÃO 3 ALTERNATIVA D A soma dos ângulos internos de um triângulo é 180o. Observe que os três ângulos não marcados dos triângulos (com vértices em B) somam 180o, já que A, B e C estão alinhados. Assim, a soma dos ângulos marcados é ooo(1803)1 80360×−=.   QUESTÃO 4 ALTERNATIVA B Podemos organizar as somas dos termos da sequência aos pares: (612)(1824)(3036)(4248) −++−++−++−++⋅⋅⋅ Observamos que, para cada par de termos consecutivos, arranjados como acima, a soma é 6. Assim, para obter 180 devemos somar os 180630÷= primeiros pares, ou seja, os 30260×= primeiros termos da sequência.   QUESTÃO 5 ALTERNATIVA A Somando as metragens dos muros de Luiz e de Lúcio, obtemos 240260500+= m. Neste total estão computados o comprimento do muro original (de 340 m) mais duas vezes o comprimento do muro interno. Logo, o comprimento do muro interno é igual a [500340]/280−= metros. Podemos também resolver algebricamente: como o muro interno pertence ao cercado dos terrenos de Luiz e de Lúcio, se x é a medida do muro interno, temos:  3402240260x+=+ Portanto 80x= m.         Solução da prova da 1a fase OBMEP 2014 − Nível 2  2   QUESTÃO 6 ALTERNATIVA D Podemos organizar as informações numa tabela:   mês dia do mês dia da semana Andrea agosto 16 segunda Daniela agosto 16 terça Fernanda setembro 17 terça Patrícia agosto 17 segunda Tatiane setembro 17 segunda  Se Andrea estivesse certa, então Fernanda não acertaria nenhuma das informações. Logo, não é ela que está certa, nem Fernanda (pelo mesmo motivo). Se Daniela estivesse certa, então Tatiane também nada acertaria. Logo Daniele e Tatiane não estão certas. Se Patrícia acertar tudo, as demais também acertarão alguma informação e, portanto, Patrícia é a única que está certa.   QUESTÃO 7 ALTERNATIVA A Se P é o preço de um caderno, Rodrigo pagou pela sua compra 80600,80,62,4100100PPPPPPP++=++=, enquanto que Gustavo, no dia seguinte, pagou 3P. Portanto, Rodrigo pagou 32,40,6PPP⋅−=  a menos que Gustavo. Assim, para saber percentualmente quanto Rodrigo pagou a menos do que Gustavo, fazemos 3P ____ 100% 0,6P ____ x  Logo, 0,6200,23100PxP===, ou seja, Rodrigo pagou 20% a menos que Gustavo.   QUESTÃO 8 ALTERNATIVA A De acordo com o gráfico, os alunos obtiveram as seguintes notas e médias:   Prova 1 Prova 2 Média Aritmética A 9 8 8,5 B 3 5 4 C 8 3 5,5 D 8 10 9 E 7 6 6,5 F 3 9 6 G 8 7 7,5 H 10 5 7,5 I 10 1 5,5 J 6 3 4,5  Assim, somente os alunos A, D, E, F, G e H ficaram com média aritmética maior do que ou igual a 6 e, dos dez alunos, somente seis foram aprovados.          Solução da prova da 1a fase OBMEP 2014 − Nível 2  3   O OQUESTÃO 9 ALTERNATIVA E As diagonais que ligam vértices opostos dividem o hexágono regular em seis triângulos equiláteros congruentes, com lado igual ao do hexágono. Por outro lado, os segmentos MH e GN determinam triângulos equiláteros FHM e CGN com lado igual à metade do lado do hexágono. Logo, a área de cada um destes dois triângulos é igual a 4S, sendo S a área dos triângulos equiláteros maiores. Assim, a razão entre as áreas dos hexágonos ABNGHM e ABCDEF é  3254612SSS−=     Uma outra solução consiste em decompor o hexágono regular em 24 pequenos triângulos equiláteros congruentes e verificar que o hexágono cinza é formado por 10 de tais triângulos pequenos. Assim, a razão entre as áreas é 1052412=.     QUESTÃO 10 ALTERNATIVA B Yurika andou 3614435723421−= km. Ela gastou 43 litros para andar esta quilometragem; portanto, o rendimento de seu carro foi de 42143÷ km/l, ou seja, aproximadamente 9,8 km/l. O dado 32,5 é irrelevante para resolver o problema, já que ela sempre enche o tanque quando abastece.   QUESTÃO 11 ALTERNATIVA C Como em cada face aparecem quatro números consecutivos, então na face onde estiver o número 1, obrigatoriamente estarão os números 1, 2, 3 e 4. Logo, na face onde estiver o número 5 estarão os números 5, 6, 7 e 8, e assim, sucessivamente, até chegarmos à face com os números 21, 22, 23 e 24. Sendo assim, no cubo apresentado a face com o número 23 também apresenta os números 21, 22 e 24. Como o enunciado diz que a soma do maior número de uma face com o menor da face oposta é igual a 25, podemos concluir que na face oposta à que contém o 23 estão os números 1, 2, 3 e 4. Na face em que aparece o número 7 aparecem os números 5, 6 e 8, e na face oposta a esta estão os números 17, 18, 19 e 20. Logo, na face destacada (em cinza) pode estar qualquer número de 9 até 16.  Como a pergunta é qual é o menor número que pode aparecer na face cinza, a resposta é 9.         Solução da prova da 1a fase OBMEP 2014 − Nível 2  4   QUESTÃO 12 ALTERNATIVA D  Cada figura é formada por 3 cópias da figura anterior, posicionadas de modo a colocar em contato apenas dois pares de quadradinhos das cópias das figuras. Em consequência, o comprimento do contorno da nova figura é igual a 3 vezes o comprimento do contorno da anterior, menos 4 cm (correspondentes aos lados em contato). A tabela abaixo dá o comprimento do contorno das sucessivas figuras.  Figura Contorno (cm) 1 4 2 34–48×= 3 38–420×= 4 320–456×= 5 356–4164×= 6 3164–4488×=  Portanto, o contorno da Figura 6 mede 488 cm.   QUESTÃO 13 ALTERNATIVA E Observe a soma das unidades. Como 0XY18<+≤, temos que XY10+=, pois XYZ++ e Z devem ter o mesmo algarismo na casa das unidades. Segue também que somando-se os números na casa das unidades, “vai um” para a casa das dezenas. A partir da soma das dezenas temos que 1XYZ11Z+++=+ e X devem ter o mesmo algarismo na casa das unidades, isto só é possível se XZ1=+. Observando a casa do milhar, vemos que a soma 1XYZ11Z+++=+ deve ser igual ao número com dezena Y e unidade X. Logo, Y1= e como XY10+=, X9=. Mas XZ1=+, o que fornece Z8=. Assim, a conta apresentada é, de fato,   Uma outra solução é a seguinte: Olhando a casa das unidades, concluímos, como antes, que XY10+=, pois XYZ++ e Z devem ter o mesmo algarismo na casa das unidades. Devido à posição da letra Y no resultado, podemos concluir que Y2= ou Y1=, pois X, Y e Z sendo algarismos, são, no máximo, iguais a 9. Vejamos o que ocorre em cada caso: Se Y2=, então X8= e, olhando a casa dos milhares, vemos que 182Z28+++=, donde Z17=, o que é impossível, pois Z é um algarismo (Z10<). Se Y1=, como XY10+=, então X9= e, olhando novamente a casa dos milhares, vemos que 191Z19+++=, donde Z8=.   QUESTÃO 14 ALTERNATIVA C Supondo que o relógio de parede começou a funcionar normalmente quando marcava 9h, ao mostrar 10h 40min o tempo que passou foi de 1h e 40min. Como Rosane ficou exatamente uma hora fazendo compras, conclui-se que ela levou 40 min para ir e voltar e, como esses tempos são iguais, levou 20 min para voltar. Admitindo-se que o relógio do mercado que marcava 10h 10min estava correto, então ela chegou em casa 1h e 20 min depois das 10h e 10 min, ou seja, ela chegou em casa às 11 horas e 30 minutos.         Solução da prova da 1a fase OBMEP 2014 − Nível 2  5   QUESTÃO 15 ALTERNATIVA C Chamando de T o peso total das frutas, m o peso (massa) das maçãs, u o peso das uvas e l o peso das laranjas, os dados do problema nos fornecem /2mT=, /2ulT+= e 2ul= donde concluímos que /2mT=, /3uT= e /6lT=. Portanto, de acordo com a tabela de preços, teremos: TTT3+4+2=38 T=12236⋅⋅⋅∴ Logo, Télio comprou 12 kg de frutas.   QUESTÃO 16 ALTERNATIVA C A cada grupo de 3 dias Lúcia pode comer 7+7+7=21  docinhosou10+5+5=20 docinhos(cid:173)(cid:176)(cid:174)(cid:176)(cid:175).  Portanto, para maximizar a quantidade de docinhos ela deverá sempre fazer a primeira escolha a cada grupo de 3 dias. Como 29932=×+, já podemos concluir que nos 9 períodos de 3 dias ela comerá 9x21189= docinhos. Resta analisar de que maneiras ela pode tentar maximizar a quantidade de docinhos nos dois últimos dias.  Opções: 7+7=14 docinhos10+5=15 docinhos7+10=17 docinhos(cid:173)(cid:176)(cid:174)(cid:176)(cid:175) A terceira possibilidade é a maior de todas. Logo, a maior quantidade de docinhos que ela pode comer é 18917206+=.   QUESTÃO 17 ALTERNATIVA C Como José possui pelo menos uma moeda de cada tipo, ele não pode ter 2 moedas de 50 centavos, senão formaria 1 real. Ele também não pode ter 2 moedas de 25 centavos. Com a moeda de 50 centavos e com uma moeda de 25 centavos ele também não pode formar 1 real. Concluímos assim, que José possui uma moeda de 50 centavos e uma moeda de 25 centavos. José não pode ter 5 moedas de 10 centavos, senão junto com a moeda de 50 centavos ele formaria 1 real. Para maximizar, podemos supor que ele tem, então, quatro moedas de 10 centavos. Com elas e com as moedas de 50 e 25 centavos ele não consegue formar 1 real. Por fim, ele não pode ter cinco moedas de 1 centavo, pois se tivesse, formaria 1 real juntando a elas a moeda de 50 centavos com a de 25 centavos e mais duas de 10 centavos. Assim, José deve ter, no máximo, quatro moedas de 1 centavo. Logo, o maior valor total possível que José pode ter é 502541041119++⋅+⋅= centavos, ou seja, R$ 1,19.   QUESTÃO 18 ALTERNATIVA E Vamos fazer essa contagem pensando em colocar os algarismos na unidade, dezena, centena e unidade de milhar do número. Como se trata de um número de quatro algarismos, o algarismo 0 não pode ser colocado na unidade de milhar. Temos então 3 possibilidades para se colocar o algarismo 0. Colocado o zero sobram então três posições para se colocar o algarismo ímpar, e como há cinco algarismos ímpares, temos um total de 15 possibilidades para se colocar o algarismo ímpar no número. Colocado o algarismo 0 e o algarismo ímpar, sobram duas posições para se colocar os dois algarismos pares não nulos e distintos. Fazemos a escolha do primeiro algarismo par não nulo e o colocamos na primeira posição ainda não preenchida do número (há apenas 4 possibilidades de escolha: 2, 4, 6 e 8). Finalmente, preenchemos a última posição com outro número par não nulo, diferente daquele anteriormente colocado (3 possibilidades). Temos assim 12 possibilidades de se colocar os dois algarismos pares não nulos e distintos no número. Pelo Princípio Multiplicativo, o total de possibilidades é 31512540××=.      Solução da prova da 1a fase OBMEP 2014 − Nível 2  6   QUESTÃO 19 ALTERNATIVA B Os cubinhos que não têm nenhuma face pintada são os que ficam internos ao cubo maior. Eles fazem parte de um cubo de dimensões (–2)(–2)(–2)nnn××, o que dá um total de 3(–2)n tais cubinhos. Os que têm exatamente uma face pintada são os cubinhos das faces do cubo maior que não tocam suas arestas. Em cada face há 2(–2)n desses cubinhos, o que dá um total de 26(–2)n cubinhos com exatamente uma face pintada. Logo, deve-se ter  32(–2)6(–2)nn=⋅ Como 2n>, esta equação é equivalente a 26n−=, cuja solução é 8n=.   QUESTÃO 20 ALTERNATIVA D Como as marcas 49 e 71 ficaram sobrepostas em pedaços que são vizinhos, houve uma dobra exatamente no ponto médio, isto é, em (4971)/260+=. Como o processo iniciou-se com a marca 0, o tamanho de cada pedaço, isto é, a distância entre duas dobras sucessivas, deve ser um divisor de 60. Os divisores de 60 são 1, 2, 3, 4, 5, 6, 10, 12, 15, 20, 30 e o próprio 60. Mas, estando 49 e 71 em pedaços vizinhos, descartamos os divisores 1, 2, 3, 4, 5, 6 e 10 pois a distância de 49 (ou 71) até a dobra 60 é 11, maior do que todos eles. Resta decidir qual é o tamanho de cada pedaço dentre as possibilidades 12, 15, 20, 30 ou 60 e, para isto, usaremos a informação de que a marca 139 ficou alinhada com 49 e 71. As distâncias da marca de 139 aos dois pontos anteriores são, respectivamente, 90 e 68. Como a marcação de 139 coincide com as anteriores, uma dessas distâncias deve ser um múltiplo do dobro do tamanho da dobra, ou seja, deve ser um múltiplo de 24, 30, 40, 60 ou 120. Mas 68 não é um múltiplo de nenhum desses números, enquanto 90 é múltiplo apenas de 30. Portanto, o tamanho de cada pedaço é 15, o que faz com que a última dobra ocorra na marca de 195 cm e, daí, ao dobrar-se o último pedaço, a marca de 200 cm fica sobre 195(200195)190−−= cm.   As figuras a seguir ilustram o que acontece para os cinco possíveis valores das medidas dos pedaços. Se o tamanho de cada pedaço fosse igual a 12, teríamos a situação descrita pela figura ao lado e a marca 139 não estaria alinhada com 71 e 49. Logo, este caso não ocorre.               Se o tamanho de cada pedaço fosse igual a 15, teríamos a seguinte situação:     1 0 12 24 36 48 60 72 84 96 108 120 132 144 49 71 139 4 0 15 30 45 60 75 90 105 120 135 150 165 180 49 71 139 195 200 190 4     Solução da prova da 1a fase OBMEP 2014 − Nível 2  7   Este é o único caso correto. De fato, veremos a seguir que os demais casos não podem ocorrer:    Se o tamanho de cada pedaço fosse igual a 20, teríamos a seguinte situação:   Este caso também não pode ocorrer pois 139 não se alinha com 49 e 71.             Se o tamanho de cada pedaço fosse igual a 30, teríamos a seguinte situação:                E vemos que também este caso também não ocorre. Finalmente, se o tamanho de cada pedaço fosse igual a 60, teríamos a seguinte situação: Este último caso também não ocorre.       Logo o comprimento de cada pedaço é 15 cm e a última dobra é feita na marca 195; assim a marca 200 alinha-se com a marca 190, a qual está no penúltimo pedaço.  0 20 40 60 80 100 120 140 160 180 200 49 71 139 1 10 0 60 120 180 200 49 71 139 49 19 0 30 60 90 120 150 180 200 49 71 139 11 19 ANEXO D – Respostas ao Questionário

207

Respostas para o questionário encaminhado à coordenação de elaboração dos itens da prova daprimeira fase daOBMEP 2014.1- Se há uma matriz de referência para elaboração das questões?Inicialmente vale lembrar que a OBMEP é bem mais do que uma olimpíada feita por desafiosapresentados na forma de questões para a posterior seleção de medalhistas. Trata-se de um programaarquitetado em rede, com o sério intuito de melhorar o ensino da Matemática nas escolas públicasbrasileiras. Destacam-se a enorme capilaridade –feita por meio de uma logística ímpar talvez nunca antesconseguida, mesmo em países mais desenvolvidos que o Brasil – e o impacto na formação de alunos eprofessores.(sugiro consultar as atividades presentes no site da OBMEP).Como devem saber, os objetivos da OBMEP são os seguintes:•Estimular e promover o estudo da Matemática entre alunos das escolas públicas.•Contribuir para a melhoria da qualidade da Educação Básica.•Identificar jovens talentos e incentivar seu ingresso nas áreas científicas e tecnológicas.•Incentivar o aperfeiçoamento dos professores das escolas públicas, contribuindo para a suavalorização profissional.•Contribuir para a integração das escolas públicas com as universidades públicas, os institutos depesquisa e as sociedades científicas.•Promover a inclusão social por meio da difusão do conhecimento.Quanto ao trabalho do Comitê de Provas, apresento, a seguir, algumas informações que podem ser deinteresse na dissertação que estão realizando.A metodologia de trabalho do Comitê de Provas da OBMEP é bastante diferente de outrasavaliações em larga escala realizadas no Brasil. Em uma visão macro, a OBMEP segue rigorosamente osParâmetros Curriculares Nacionais, segundo a seguinte divisão:Nível 1: as questões referem-se aos conteúdos tradicionais do Ensino Fundamental I (1º. ao 5º.anos). Esta prova é feita por alunos dos 6º.. e 7º. anosNível 2: as questões referem-se aos conteúdos tradicionais do Ensino Fundamental I e tambémdos 6º.. Esta prova é feita por alunos dos 8º.. e 9º. anosNível 3: as questões referem-se aos conteúdos tradicionais do Ensino Fundamental I e II (1º. ao9.o anos). Esta prova é feita por alunos do Ensino Médio.A OBMEP é dividida em duas fases, a primeira com questões de múltipla escolha aplicadas nasescolas pelos professores, como instrumento de seleção para os alunos que realizarão a segunda fase e asegunda fase é feita em centros de aplicação com provas formadas por seis questões discursivas.Mais especificamente, no que se refere aos conteúdos específicos são consultados os GuiasCurriculares dos Estados Brasileiros, atentando para não levar em consideração as diferenças regionais,mas sim o corpo de conhecimentos adequados ao exercício consciente da cidadania, correspondentes acada faixa etária. Em outras palavras, os conhecimentos avaliados nas provas da OBMEP são os mesmosque constam nos livros didáticos aprovados pelo PNLD; entretanto as questões das provasintencionalmente não são livrescas, exigindo criatividade e inovação, com ênfase no raciocínio e nacapacidade de entender e tratar situações, e não na repetição mecânica de procedimentos.2- Se é possível termos acesso a essa matriz de referência?Sim, basta consultar os documentos oficiais que regem a Educação Brasileira (PCN´s e GuiasCurriculares oficiais dos estados)3- Como são utilizados os itens de ligação que estão presentes nos três níveis da OBMEP?A confecção da prova é feita por um grupo de 10 pessoas, o qual, trabalhando a distância,constroem, ano a ano, um banco de questões sobre os variados conteúdos de Matemática (Geometria,Álgebra, Aritmética, Funções, Contagem, Probabilidade, Tratamento da Informação) e com os mais variadosníveis de dificuldade. O grupo se reúne periodicamente para depurar este banco, classificar as questões pornível e dificuldade e apresentar propostas de provas que são discutidas por todos e também por membrosexternos para que, artesanalmente sejam apresentadas as versões finais para o envio às escolas ou aoscentros de aplicação. O processo todo é contínuo e demora em torno de 8 a 10 meses para ser concluído.Este trabalho todo deixa muito claro ao final quais são os itens de ligação entre os vários níveis.Evidentemente certos conteúdos não podem ser usados pois são específicos de um determinado nível.4- Como são caracterizados os itens pelo nível de dificuldade? E qual a sua distribuição naavaliação?Os membros do Comitê de Provas são profissionais experientes que trabalham ha muitos anoscom alunos e professores da escola básica. Os níveis de dificuldade são apontados pelos participantes ediscutidos coletivamente. Muitas vezes não há concordâncias plenas; quando isto ocorre a questão énovamente avaliada, levando-se em conta os pré-requisitos e as dificuldades comumente apresentadaspelos alunos na resolução de problemas. Por exemplo, é fato conhecido que a área de Geometria épouquíssima trabalhada nas escolas, o que faz com que questões aparentemente simples apresentem-seaos alunos como extremamente difíceis.5- Se já foram computados os dados da RAIG? Se é possível disponibilizá-los?Sim, a coordenação está providenciando as informações.6- Como são construídos os distratores de cada item?A metodologia utilizada na OBMEP é diferente da do ENEM ou de outros testes TRI.Intencionalmente não são colocados distratores nas questões de múltipla escolha da primeira fase. Ocomitê de provas é atento para evitar distratores, exceto em ocasiões muito raras e especiais. Evita-se, atodo custo, canalizar o aluno a respostas que não sejam as corretas ou que sejam atraídos porinterpretações não presentes nos enunciados7- Se há incentivo de uso de itens inéditos?Total. Partimos sempre com a expectativa de fazer uma prova com questões inéditas, oumesmo com situações inovadoras construídas a partir de situações já conhecidas. Uma análise feita nasprovas anteriores deve mostrar a grande variedade de situações novas presentes nas questões.8- Se há normas de construção dos itens?Inicialmente não. Mas há padrão que vem sendo construído ao logo dos anos, que possochamar orgulhosamente de padrão OBMEP. São questões com enunciado claro e curto, inspiradoras.Acreditamos que as questões da OBMEP constituem um instrumento precioso para incentivar os alunoscom gosto pela matemática, aflorando suas aptidões, inclusive para aqueles que não se destacam nastradicionais avaliações escolares.9- Se os itens são apenas desafiadores ou há pré-estabelecimento de avaliação de competências ouhabilidades em cada item?Não há pré-estabelecimentos, exceto os impostos pelos pré-requisitos que o aluno deve ter nassuas diferentes faixas etárias.Há bastante preocupação em não confeccionar provas concentradas em umaúnica área da Matemática, mas sim a tentativa de contemplar todas elas. As questões não são avaliadasapenas individualmente, elas também devem coexistir de maneira coerente com as demais.211

Índice

𝑃𝐼𝑁 𝐹 , 63
𝑃𝐼𝑁 𝑇 , 63
𝑃𝑆𝑈 𝑃 , 63

ação errônea, 93

acerto ao acaso, 60

AGI, 65

ambiente construtivista, 68

Análise de Conteúdo, 83

análise de erros, 89

auto-monitoramento, 47

autonomia, 90

avaliação

classificatória, 46

em larga escala, 50

formal, 48

formativa, 47

informal, 48

institucional, 50

para aprendizagem, 49

somativa, 46

categorização, 85

classificação de erros, 97

coeficientes bisseriais, 64

comando, 75

competências, 72

conflito cognitivo, 92

constituição do corpus, 84

construção do conhecimento, 92

construtivismo, 92

contextualização, 67

correlação bisserial, 64

dado construto, 61

DCN, 67

discriminação, 60

discriminação dos itens, 62

distratores, 77

Educação Matemática Crítica, 42

ENEM, 59

enfoque

epistemológico, 100

pedagógico, 100

psicológico, 100

enfoques do erro, 100

erro, 89

erros

de adequação, 97

de aplicações de regras, 97

de associações incorretas, 97

de deficiência de conteúdo, 97

de dificuldade de linguagem, 97

de informação espacial, 97

de lógica, 97

de saber, 97

de saber-fazer, 97

escore bruto, 62

exploração do material, 84

formatos de itens

certo ou errado, 70

dissertativo, 70

múltipla escolha, 69

resposta curta aberta, 70

resposta fechada, 70

formulação de hipóteses, 84

gabarito, 78

habilidade, 72

dificuldade dos itens, 62

IMO, 32

Índice

situações-problema, 55

TCT, 61
Teoria Clássica dos Testes, 61
Teoria de Resposta ao Item, 59
texto-base, 74
textualização, 67
tratamento dos resultados, 85
TRI, 59

unidimensionalidade, 59

212

IMPA, 34
IMU, 36
independência local, 59
inferência, 83
item, 69
itens convencionais, 67

LDB, 49
leitura flutuante, 84

medir, 51

níveis de resposta, 93
NUMERATIZAR, 37

OBM, 34
OBMEP, 36
obstáculo, 95
obstáculos

de origem didática, 95
de origem ontogenética, 95
epistemológicos, 95

OIAM, 32

patamares do erro, 97
PCN, 49
peguinha, 77
percentual de acerto, 63
PISA, 42
plausibilidade, 87
PPP, 49
pré-análise, 84
pré-testagem, 80
proficiência, 60
prova, 69
Prova Brasil, 50
prova escrita, 54

referenciação dos índices, 84

Saeb, 50
SBM, 34
SINAES, 50


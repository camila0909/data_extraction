UNIVERSIDADE FEDERAL DO AMAZONAS
INSTITUTO DE CIˆENCIAS EXATAS
PROGRAMA DE P ´OS-GRADUAC¸ ˜AO EM MATEM ´ATICA
MESTRADO PROFISSIONALIZANTE EM MATEM ´ATICA

CADEIAS DE MARKOV REGULARES: UMA ABORDAGEM PARA
ALUNOS E PROFESSORES DO ENSINO M ´EDIO

F´abio de Souza Costa

MANAUS

2017

UNIVERSIDADE FEDERAL DO AMAZONAS
INSTITUTO DE CIˆENCIAS EXATAS
PROGRAMA DE P ´OS-GRADUAC¸ ˜AO EM MATEM ´ATICA
PROGRAMA DE MESTRADO PROFISSIONALIZANTE EM MATEM ´ATICA

F´abio de Souza Costa

CADEIAS DE MARKOV REGULARES: UMA ABORDAGEM PARA
ALUNOS E PROFESSORES DO ENSINO M ´EDIO

Trabalho de Conclus˜ao de Curso apresentado

ao Programa de Mestrado Proﬁssional em Ma-

tem´atica da Universidade Federal do Amazo-

nas, como requisito parcial para obten¸c˜ao do

t´ıtulo de Mestre em Matem´atica.

Orientador: Prof. Dr. Nilomar Vieira de Oliveira

MANAUS

2017

Agradecimentos

Agrade¸co a Deus, pelo sopro de vida a mim oferecido e por mostrar que a nossa

caminhada se divide em amar ao pr´oximo, dedica¸c˜oes e escolhas.

Minha amada esposa Raika pela compreens˜ao e incentivos a mim desprendidos, prin-

cipalmente nas horas mais dif´ıceis dessa caminhada e que sem seu apoio, seria imposs´ıvel

realizar esse sonho.

Meu amado ﬁlho, primogˆenito, Mikael, um exemplo de bondade e solidariedade, dono

de um car´ater primoroso, por me fazer entender que quando a fam´ılia est´a unida, perseguir

um sonho e alcan¸c´a-lo ´e bem mais f´acil.

Meu amado ﬁlho Gabriel, meu amig˜ao, sua presen¸ca era sempre constante, principal-

mente nas horas noturnas e solit´arias de estudo. Um ﬁlho que em meus momentos dif´ıceis

sempre me alegrava com um simples sorriso.

A minha amada m˜ae Fransquinha, por ter me ensinado que somente crescemos com

o aumentar do nosso conhecimento. Tamb´em, pelas constantes ora¸c˜oes a Deus, solicitando

sempre sa´ude e prote¸c˜ao para minha fam´ılia.

Ao meu irm˜ao Alcy, pelas ora¸c˜oes pedindo a Deus que me iluminasse nas mais dif´ıceis

tomadas de decis˜oes.

Ao Prof. Dr. Nilomar Oliveira, Orientador desta disserta¸c˜ao, um apaixonado pela

educa¸c˜ao, pessoa digna, dedicada e paciente, com a fun¸c˜ao cont´ınua de ajudar ao pr´oximo,

e que me fez entender melhor o signiﬁcado da vida.

Ao meu Amigo Prof. MSc. Alessandro Monteiro, pessoa capaz de doar seu tempo e

conhecimento em favor do pr´oximo sem pedir retribui¸c˜ao, um grande companheiro, simples

e humilde que muito me incentivou a concluir essa jornada.

Ao Prof. Armando, meu primeiro professor de matem´atica na 5a s´erie ginasial, por

me ensinar que a beleza matem´atica est´a na compreens˜ao de sua utilidade.

Ao Prof. Dr. Henrique Herfert, proﬁssional de did´atica e conhecimento invej´avel,

humilde, detentor de um poder modiﬁcador da compreens˜ao e vis˜ao do aluno sobre a ma-

tem´atica, mostrando o quanto temos ainda que aprender e evoluir.

Ao Prof. Dr. M´ario Salvatierra, por ter plena conﬁan¸ca em minha caminhada, sendo

que em muitos momentos seu conhecimento matem´atico e positivismo de vida me incentiva-

ram a buscar for¸cas para o cumprimento dos meus objetivos.

Ao Prof. Dr. Roberto Prata pelas conversas e depoimentos apaixonados sobre a be-

leza e a importˆancia da matem´atica aplicada que me ﬁzeram enxergar o quanto ´e necess´ario

implementarmos ferramentas para melhorarmos a aprendizagem na ´area matem´atica, prin-

cipalmente na rede p´ublica de ensino.

Ao Prof. Dr. Disney pela imensur´avel capacidade de criar, facilmente, um elo entre a

matem´atica e as novas tecnologias educacionais.

A SBM, pela corajosa e brilhante idealiza¸c˜ao do mestrado com o intuito de promover

uma substancial melhora na educa¸c˜ao matem´atica do nosso pa´ıs.

A UFAM e seu corpo docente pelo comprometimento, entusiasmo e dedica¸c˜ao dados

aos alunos desse importante mestrado.

In mathematics you don’t understand

things. You just get used to them.”A

Matem´atica n˜ao mente. Mente quem

faz mau uso dela”.

Albert Einstein

Resumo

O principal objetivo desse Trabalho de Conclus˜ao de Curso ´e a apresenta¸c˜ao para os

alunos do ensino m´edio, graduandos do ensino superior e professores de matem´atica, algu-

mas aplica¸c˜oes matem´aticas nas mais diversas ´areas do conhecimento humano atrav´es de

ferramentas fundamentadas nas Cadeias de Markov Regulares. A abordagem segue um de-

senvolvimento pautado em sequˆencias de deﬁni¸c˜oes e esclarecimentos das principais fun¸c˜oes

dos elementos de uma cadeia, tais como: probabilidades de transi¸c˜ao, matriz de transi¸c˜ao e

distribui¸c˜ao de probabilidade. Chegamos ao ´apice, quando elaboramos a sistematiza¸c˜ao de

alguns m´etodos utilizados para calcular a distribui¸c˜ao limite de probabilidade de uma cadeia

de Markov regular, particularmente, o m´etodo do Fluxo Probabil´ıstico.

PALAVRAS-CHAVE: Cadeia de Markov, Probabilidade de Transi¸c˜ao, Matriz de

Transi¸c˜ao, Distribui¸c˜ao Limite de Probabilidade, Fluxo Probabil´ıstico e Aplica¸c˜oes.

Abstract

The main objective of this Dissertation of Conclusion Course is the presentation for

high school students, undergraduates of higher education and mathematics teachers, some

mathematical applications in the most diverse areas of human knowledge through tools based

on Regular Markov Chains. The approach follows a development based on sequences od deﬁ-

nitions and clariﬁcations of the main functions of the elements of a chain, such as: transition

probabilities, transition matrix and probability distribution. We arrive at the apex of the

work when we elaborate the systematization of some methods used to calculate the probabi-

lity limit distribution of a regular Markov chain, particularty, the Probabilistic Flow method.

Keywords: Markov Chains, Transition Probability, Transition Matrix, Probability

Limit Distribution, Probabilistic Flow, and Applications.

LISTA DE S´IMBOLOS

Conjunto dos n´umeros naturais.

Conjunto dos n´umeros reais positivos.

Valor absoluto de x.

Igual.

Diferente.

Maior.

Menor.

Maior ou igual.

Menor ou igual.

Somat´orio variando de 1 a n.

Limite de xn com n tendendo ao inﬁnito.
Indica o ﬁm de uma demonstra¸c˜ao.

Probabilidade complementar de ocorrer um evento X.

Indica uma matriz de ordem n.







. . . p1n
...
. . .
pnn
· · ·

N

P

|x|

=

(cid:54)=

>

<

≥

≤
n
(cid:88)

i=1
lim xn
(cid:3)

P C(X)






p11
...
pn1

Sum´ario

Introdu¸c˜ao

1 Cadeias de Markov

Cadeias de Markov

1.1 Hist´orico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Motiva¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Conceitos e Propriedades Fundamentais . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1 Estados
1.3.2 Probabilidade de transi¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . .
1.3.3 Matriz de Transi¸c˜ao
. . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.4 Propriedades da Matriz de Transi¸c˜ao . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.5 Deﬁni¸c˜ao
1.4 Vetor Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.5 Distribui¸c˜ao de probabilidade inicial . . . . . . . . . . . . . . . . . . . . . . .
1.6 Distribui¸c˜ao da probabilidade ap´os r observa¸c˜oes . . . . . . . . . . . . . . . .
1.7 Matriz de transi¸c˜ao ap´os r observa¸c˜oes ou passos . . . . . . . . . . . . . . . .

2 Cadeias de Markov Regulares

2.1 Convergˆencia da distribui¸c˜ao de probabilidade . . . . . . . . . . . . . . . . .
2.2 Fluxo Probabil´ıstico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Aplica¸c˜oes das Cadeias de Markov

3.1 Modelagem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Aplica¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Vendas - Lealdade do consumidor . . . . . . . . . . . . . . . . . . . .
3.2.2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Experimento de Comportamento (Adaptado de Lay, 2013) . . . . . .
Propaga¸c˜ao de Rumor (Adaptado de Sullivan, 2013) . . . . . . . . .
3.2.4

Sa´ude

16

17

17
17
18
20
20
21
23
27
28
28
29
31
38

41
44
52

55
55
56
56
60
62
66

3.2.5 Teoria Social

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

69

Considera¸c˜oes Finais

Referˆencias Bibliogr´aﬁcas

A Uso do Microsoft Excel para multiplica¸c˜ao de matrizes

B Pr´e-Requisitos

B.1 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.1 Nota¸c˜ao Geral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.2 Matriz Quadrada . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.3 Matriz Identidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.4 Matriz Linha . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.5 Matriz Nula ou Elemento Neutro . . . . . . . . . . . . . . . . . . . .
B.1.6 Matriz Triangular Superior . . . . . . . . . . . . . . . . . . . . . . . .
B.1.7 Matriz Oposta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.8 Matriz Inversa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.9 Igualdade de Matrizes
. . . . . . . . . . . . . . . . . . . . . . . . . .
B.1.10 Opera¸c˜oes com Matrizes . . . . . . . . . . . . . . . . . . . . . . . . .
B.2 Equa¸c˜oes Lineares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.3 Sistemas Lineares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . .
B.4 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.4.1 Axiomas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.4.2 Espa¸cos de probabilidade . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . .
B.4.3 Probabilidade condicional

B.3.1 Solu¸c˜ao de Sistemas de Equa¸c˜oes Lineares

74

75

77

81
81
82
83
83
84
84
85
85
85
86
86
88
89
91
94
95
95
96

Lista de Figuras

1.1
1.2
1.3
1.4
1.5
1.6
1.7

2.1
2.2
2.3

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.7
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.8
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.9
3.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

22
22
25
26
31
39
40

43
53
54

57
58
58
61
62
62
63
63
64
64
66
68
68
69
70
70
71

13

A.1
A.2
A.3
A.4

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

78
79
79
80

Lista de Tabelas

1.1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Fra¸c˜ao por categoria de ﬁlmes . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1
3.2
3.3
3.4
3.5
3.6

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

23
29

56
62
63
63
64
64

16

Introdu¸c˜ao

“Aplica¸c˜ao Matem´atica” eis um termo que expande sua deﬁni¸c˜ao para al´em das fron-
teiras matem´aticas. E ´e reﬂetindo essa ideia que apresentaremos as cadeias de Markov, como
instrumento de contextualiza¸c˜ao da realidade, isto ´e, uma ferramenta que tem o objetivo de
oferecer a alunos e professores do Ensino M´edio, uma proposta de mesclar e interagir o co-
nhecimento de Matrizes, Sistemas Lineares e Probabilidade, no intuito de modelar, esclarecer
e resolver problemas cotidianos.

As Cadeias de Markov s˜ao pe¸cas importante na compreens˜ao de fenˆomenos aleat´orios
e foi Andrei Markov seu idealizador, no qual utilizava estudos probabil´ısticos orientados no
comportamento das vogais e consoantes utilizadas em poemas.

E para expormos as ideias vinculadas ao tema proposto, foi necess´ario limitarmos o
assunto principal, isto ´e, ater-se apenas a cadeias de Markov regulares. Para obtermos ˆexito,
precisaremos de certa intimidade com os trˆes conte´udos do Ensino M´edio j´a referidos acima.
Esses assuntos ser˜ao base de utiliza¸c˜ao para solucionarmos muitos problemas relacionados
`a aplica¸c˜oes das cadeias de Markov. Por isso, colocaremos esses t´opicos matem´aticos no
apˆendice, para que o leitor, caso necessite, possa us´a-lo como suporte para relembrar assuntos
que delinear˜ao uma compreens˜ao mais apurada do tema abordado.

A apresenta¸c˜ao das cadeias de Markov, expondo suas deﬁni¸c˜oes, indicando os elemen-

tos formadores e suas propriedades s˜ao os principais objetivos do Cap´ıtulo 1.

J´a no Cap´ıtulo 2, entraremos no cerne deste trabalho, colocando de modo detalhado as
cadeias de Markov regulares e a sua importˆancia, mostrando suas caracter´ısticas principais,
e ´e claro, chegando ao ´apice no c´alculo da distribui¸c˜ao limite de probabilidade, mediante a
utiliza¸c˜ao de alguns m´etodos, tendo destaque o Fluxo Probabil´ıstico.

Consequentemente, as aplica¸c˜oes contidas no Cap´ıtulo 3 e ´ultimo deste trabalho, ser˜ao
desenvolvidas com o prop´osito de externar algumas ´areas do saber, evidenciando desse modo,
o qu˜ao esse assunto ´e utilizado e difundido em nosso dia a dia.

E por ﬁm, faremos nossas ´ultimas considera¸c˜oes real¸cando a importˆancia do tema

escolhido e de sua aplicabilidade di´aria em diversas ´areas do conhecimento.

17

Cap´ıtulo 1

Cadeias de Markov

1.1 Hist´orico

No s´eculo XIX o matem´atico russo Andrei Andreyevich Markov, iniciava seus trabalhos

em teoria dos n´umeros, fra¸c˜oes alg´ebricas e teoria das aproxima¸c˜oes.

Anton e Rorres (2012) declaram que Markov era um amante da poesia, seu trabalho
tinha o objetivo de analisar a frequˆencia com que as vogais e consoantes apareciam nos textos
no poema Eugene Onegin, de Pushkin. Markov tinha plena convic¸c˜ao que a aplica¸c˜ao de suas
cadeias se restringiam a obras liter´arias.

Conforme Silva (2013), Markov suponha que a probabilidade de ocorrer uma consoante

dependia apenas da letra antecessora a consoante.

Markov pertencia a famosa escola matem´atica de S˜ao Petersburgo, fundada por Paf-
nuty Chebyshev, foi l´a que iniciou seus estudos acadˆemicos at´e ﬁnalizar seu Doutorado. Em
1883, assumiu na universidade o Curso de Teoria da Probabilidade.

Rosa (2012) aﬁrma que renomados matem´aticos como o Croata-Americano, William
Feller, que estudou a rela¸c˜ao entre as cadeias de Markov e as Equa¸c˜oes Diferenciais, impuse-
ram grande desenvolvimento a aplicabilidade das cadeias no cotidiano.

J´a Gadelha (2004) sustenta que o matem´atico russo Andrei Nikolaievitch Kolmogo-
rov, dedicou-se a estud´a-la utilizando vari´aveis cont´ınuas, fazendo com que a R´ussia, naquela
´epoca, se tornasse o ´unico centro de estudos que buscavam solidiﬁcar os fundamentos ma-
tem´aticos da Teoria da Probabilidade.

Andrey Markov faleceu em 20 de julho de 1922 aos 66 anos em San Petersburgo.
Diversos fenˆomenos sociais, econˆomicos, pol´ıticos e cient´ıﬁcos podem ser modelados pelo
m´etodo que hoje leva seu nome.

18

1.2 Motiva¸c˜ao

Uma empresa de consultoria foi contratada para realizar an´alise de mercado, com o
objetivo de veriﬁcar, mensalmente, o v´ınculo de ﬁdelidade dos clientes em rela¸c˜ao a duas
empresas a´ereas, A e B. Estimou-se que atualmente 60% das pessoas utilizam a empresa
A e 40% a empresa B. Tamb´em foi constatado que dos clientes que compram passagem na
empresa A, no mˆes, 30% ir˜ao migrar para a empresa B no mˆes seguinte. E dos que viajaram
pela empresa B, no mˆes, 20% estar˜ao comprando passagem a´erea pela empresa A, no mˆes
subsequente.

Sabendo que a estimativa mensal do n´umero de pessoas que costumam viajar ´e de
10.000, qual a propor¸c˜ao de pessoas que viajar˜ao pela empresa A no segundo mˆes de ob-
serva¸c˜ao da consultoria? E no terceiro mˆes? Existir´a uma tendˆencia na distribui¸c˜ao de
probabilidade que representa a fra¸c˜ao dos consumidores?

Esse ´e um t´ıpico problema de probabilidade que poder´a ser resolvido por meio de
processos j´a conhecidos, como por exemplo, elaborar a ´arvore de probabilidades, ou fazendo
uso das propriedades e deﬁni¸c˜oes de probabilidade condicional. No entanto, com o aumento
do n´umero de observa¸c˜oes (meses), esse e outros m´etodos ﬁcariam invi´aveis devido ao grande
n´umero de c´alculos a serem produzidos. ´E por esse motivo, que vamos empregar as chamadas
Cadeias de Markov, para solucion´a-lo.

Mas o que seria uma Cadeia de Markov? Se pararmos para reﬂetir, a palavra cadeia nos
remete a uma s´erie de signiﬁcados, por´em, a deﬁni¸c˜ao que apresentaremos, a designar´a como
sendo um processo continuado ou sequencial. Entretanto, ´e preciso saber o que indicaria esse
processo. Bem! Estamos interessados em apresentar um modelo de probabilidade, no qual
exista apenas a rela¸c˜ao entre a tentativa atual e a posterior, isto ´e, somente a probabilidade
observada no presente determinar´a ou n˜ao, altera¸c˜oes na probabilidade do estado futuro.
Logo, de um modo diferente, podemos aﬁrmar que qualquer conhecimento da probabilidade
relativa a observa¸c˜ao (tentativa) no passado n˜ao alterar´a seu comportamento futuro.

Existem modelos de probabilidade, como a Distribui¸c˜ao Binomial, onde cada tentativa
independe das tentativas passadas, o que n˜ao acontece com as Cadeias de Markov. Vamos
entender a diferen¸ca entre os dois por meio de exemplos.

EXEMPLO 1.

Ao lan¸carmos uma dado normal considere os seguintes acontecimentos:
X- sair face ´ımpar;
Y- sair a face com o n´umero 2.
P(X) = Probabilidade de acontecer o evento X
P(Y) = Probabilidade de acontecer o evento Y

Se jogarmos o dado pela primeira vez, teremos as seguintes probabilidades:

19

P(X) = 3

6 e P(Y) = 1

6

Se jogarmos o dado pela segunda vez, obteremos as seguintes probabilidades:

P(X) = 3

6 e P(Y) = 1

6

Ora, veja que as probabilidades do segundo lance n˜ao se alteraram em rela¸c˜ao ao
primeiro. Se continuarmos a jogar o dado pela en´esima vez, teremos a mesma probabilidade
do primeiro lance, isto ´e, tanto a probabilidade de se obter uma face ´ımpar quanto a proba-
bilidade de sair uma face com o n´umero dois, em uma lance no tempo presente (atual), n˜ao
inﬂuenciar´a no resultado da jogada seguinte (futuro).

Este mesmo pensamento tamb´em pode ser utilizado para o lan¸camento de uma moeda
honesta, pois a probabilidade de se obter cara ou coroa, independe do n´umero de vezes que
a jogarmos, j´a que teremos sempre,

P(CARA) = P(COROA)= 1
2.

EXEMPLO 2.

(Adaptado de Wooldridge, 2011)

Considere um jogador de basquetebol fazendo dois lances livres e suponha que ele

converta 80% dos arremessos.

E sejam os eventos:
X - acertar o primeiro lance;
Y - acertar o segundo lance.
Qual ´e a probabilidade do jogador converter os dois arremessos? E de errar os dois

lan¸camentos?

Resolu¸c˜ao:

Se X e Y forem independentes, a resposta ´e trivial, P (X) · P (Y ) = 0,8 ·0, 8 = 0,64 ou

seja, h´a 64% de probabilidade de os dois lances livres serem convertidos.

Agora, se os dois lances forem desperdi¸cados teremos: P C(X) · P C(Y ) = 0, 2 · 0, 2 =

0,04, isto ´e, h´a 4% de probabilidade de os dois lances livres n˜ao serem convertidos.

Por´em, se a probabilidade de converter o segundo arremesso depender do primeiro
lance, quer dizer, se X e Y forem dependentes entre si, o resultado se modiﬁcar´a, tendo em
vista que a probabilidade porvir depende do resultado imediatamente anterior.

20

EXEMPLO 3.

Admita que a probabilidade do jogador acertar o segundo lance dependa do primeiro
ter sido convertido, sendo de 80%, a probabilidade de acertar o primeiro lance. Se a primeira
jogada for convertida, a probabilidade de converter o segundo lance ´e de 85%, mas se o
jogador errar o primeiro lance, a probabilidade de converter o segundo passa a ser de 70%.
Esse novo enredo para o problema nos coloca X e Y dependentes. Nessa situa¸c˜ao,

qual ´e a probabilidade do jogador acertar os dois arremessos? E errar os dois lances?

A probabilidade do jogador arremessar e acertar os dois lances ´e:
P (X) · P (Y ) = 0, 8 · 0, 85 = 0,68, ou 68% de chances de concluir positivamente os dois

arremessos.

A probabilidade do jogador arremessar e errar os dois lances ´e:
P C(X) · P C(Y ) = 0, 2 · 0, 3 = 0,06 ou 6% de chances de concluir negativamente os dois

arremessos.

Note, o quanto ´e importante sabermos se os eventos s˜ao ou n˜ao independentes.

EXEMPLO 4.

Considere que em uma cidade existam apenas revendedores de duas marcas de refri-
gerantes a base de guaran´a: Bar´e e Real. Se uma pessoa escolhe consumir o guaran´a Bar´e,
existem 20% de chances de beber o refrigerante Real da pr´oxima vez, mas se beber o guaran´a
Real, a probabilidade de trocar de marca ´e de 60%.

Repare que tamb´em neste exemplo, existe uma completa rela¸c˜ao de dependˆencia entre
presente e futuro pr´oximo, onde a probabilidade de escolha de um guaran´a no momento
imediatamente posterior, depende somente da probabilidade de escolha do refrigerante no
estado atual. Podemos ent˜ao, interpretar este enunciado como sendo um t´ıpico modelo de
Cadeia de Markov.

Quando nos deparamos com modelos matem´aticos onde a probabilidade possui um
v´ınculo de dependˆencia entre presente e futuro, ou comumente denominado de ”memoryless
system”(sistema sem mem´oria), onde o passado ´e descartado, dizemos que o mesmo apresenta
a Propriedade Markoviana.

1.3 Conceitos e Propriedades Fundamentais

1.3.1 Estados

No exemplo passado, veriﬁcamos a presen¸ca de duas condi¸c˜oes ou locais, onde as

probabilidades presentes e futuras s˜ao trabalhadas.

21

Vejamos:

E1= estado 1 = Guaran´a Bar´e
E2= estado 2 = Guaran´a Real

Os estados s˜ao como os personagens principais de uma cadeia de Markov, no qual cada
movimento entre estados s˜ao chamados de transi¸c˜oes ou passos. Nesta disserta¸c˜ao, daremos
importˆancia apenas as cadeias de Markov que possuam um n´umero ﬁnito de estados.

EXEMPLO 5.

Suponha que em determinada regi˜ao do Amazonas, as previs˜oes clim´aticas entre os
meses de junho e novembro, indicam tempo ensolarado ou nublado. Sabendo que o clima ´e
analisado diariamente, considere as seguintes aﬁrma¸c˜oes: Se o dia for ensolarado, a probabi-
lidade do pr´oximo dia ser ensolarado ´e de 90%, mas se o dia for nublado, a probabilidade do
dia seguinte tamb´em ser nublado ´e de 50%. Quais s˜ao os estados desse exemplo?

Primeiramente, precisamos veriﬁcar se o experimento(sistema), pode ser considerado
uma cadeia de Markov. No exemplo, ﬁca n´ıtida a liga¸c˜ao entre as previs˜oes clim´aticas
entre dois dias seguidos, ou seja, a dependˆencia entre as probabilidades futuras e presentes.
Portanto, nesse caso, temos uma cadeia de Markov com os seguintes estados:

E1 = estado 1 = ensolarado.
E2 = estado 2 = nublado.

1.3.2 Probabilidade de transi¸c˜ao

”´E de nosso interesse que possamos conhecer as probabilidades de movimenta¸c˜ao da
cadeia ir de um estado i para o estado j em um ´unico passo. A essa probabilidade chamamos
de probabilidade de transi¸c˜ao (LAY, 2014, p.49).”

Em uma cadeia de Markov, Poole (2004) defende que cada passo ou ponto no tempo, o
experimento pode est´a em qualquer dos estados, sendo que ao passar para o pr´oximo passo,
o estado se movimentar´a para outro estado ou permanecer´a no mesmo estado. E a toda
probabilidade que indica a mudan¸ca de um estado para outro no momento subsequente,
deﬁnimos como probabilidade de transi¸c˜ao. representada pela seguinte nomenclatura:

lˆe-se, a probabilidade de passar(mudar) do estado i para o estado j.

Pij

Utilizando o exemplo 4, referente aos guaran´as Real e Bar´e, e buscando uma melhor

assimila¸c˜ao para o leitor, representaremos as transi¸c˜oes entre estados de dois modos.

1o Modo - Diagrama de ´arvore

22

Figura 1.1

E1

E2

0, 8

0, 2

0, 6

0, 4

E1

E2

E1

E2

2o Modo - Grafos

Figura 1.2

0.2

0.6

E2

0.4

0.8

E1

Optando por qualquer um dos dois modos acima, podemos detalhar as probabilidades

atribuindo seus respectivos valores.

PE1E1 = Probabilidade de se manter no estado 1 = 0,8
PE1E2 = Probabilidade de transitar do estado 1 para o estado 2 = 0,2
PE2E1 = Probabilidade de passar do estado 2 para o estado 1 = 0,6
PE2E2 = Probabilidade de se manter no estado 2 = 0,4

23

1.3.3 Matriz de Transi¸c˜ao

Chegamos a um elemento essencial da cadeia de Markov, chamado de matriz de

transi¸c˜ao.

Deﬁni¸c˜ao 1.3.1. Considere a existˆencia de uma cadeia de Markov com n estados (E1, E2
· · · · · · En), e Pij a representa¸c˜ao de todas probabilidades de transi¸c˜ao com 1≤i≤n e 1≤j≤n.
Denominamos de matriz de transi¸c˜ao, a matriz que tem como seus elementos as probabilida-
des de transi¸c˜ao, onde linhas e colunas representam os estados.

Considerando o exemplo 4, notamos a existˆencia de dois estados, Guaran´a Bar´e e
Guaran´a Real. Logo, a matriz de transi¸c˜ao possuir´a 2 linhas e 2 colunas e para montarmos
a matriz, projetaremos os estados e as probabilidades de transi¸c˜ao em uma tabela, com ﬁns
de alcan¸car uma adequada compreens˜ao.

Tabela 1.1

Estado tempo t+1
BAR´E
0,8
0,6

REAL
0,2
0,4

BAR´E
REAL

Estado tempo t

Observe que as linhas representam o estado no tempo atual (t) e as colunas o tempo

imediatamente posterior(t+1).

Se o sistema estiver inicialmente (tempo t) no estado Bar´e (olhe para a primeira
linha onde se encontra o campo Bar´e), teremos duas possibilidades para uma transi¸c˜ao do
experimento no tempo t+1: probabilidade de 80% para permanecer no estado Bar´e (coluna
com o campo Bar´e) ou probabilidade de 20% de passar para o estado Real (coluna com o
campo Real).

Caso o sistema, no tempo t, encontrar-se no estado Real (observe na segunda linha
onde est´a o campo Real), haver´a tamb´em duas possibilidade de movimenta¸c˜ao referente ao
tempo t+1: 60% de chances de mudar para o estado Bar´e (coluna com o campo Bar´e) e 40%
de probabilidade em permanecer no estado Real (coluna com o campo Real).

Note, que havendo dois estados, observamos quatro possibilidades de probabilidades
de transi¸c˜ao, que no nosso exemplo s˜ao representadas pelos valores: (0,8) (0,2), (0,6) e (0,4).
Em um primeiro momento, podemos veriﬁcar o porquˆe de surgirem quatro possibili-
dades para dois estados. E para esse ﬁm, usaremos o Princ´ıpio Aditivo da Contagem, j´a que
as transi¸c˜oes s˜ao realizadas partindo somente de um estado de cada vez.

24

Calculando:
Para o estado Bar´e h´a duas possibilidades, n˜ao se movimentar ou ir para o estado
Real. J´a,em rela¸c˜ao ao estado Real, existem duas possibilidades que ´e se manter no estado
Real ou ir para o estado Bar´e.

Logo, pelo Princ´ıpio Aditivo da Contagem, temos quatro transi¸c˜oes..
Como h´a quatro entradas para as probabilidades e a existˆencia de dois estados, temos
a conﬁrma¸c˜ao que uma matriz quadrada do tipo M2×2, poder´a comportar todas as probabi-
lidades.

Portanto, j´a podemos representar todas as probabilidades de transi¸c˜oes existentes

como elementos de uma Matriz M, conforme segue.

(cid:34)

(cid:35)

B R
0, 8 0, 2
0, 6 0, 4

B
R

M =

Suponhamos que existam n estados. Quantos elementos da matriz M ter´ıamos? Para

calcularmos basta utilizarmos novamente o Princ´ıpio Aditivo da Contagem.

Calculando:

• Para o estado 1 existem n possibilidades: se manter no estado 1 ou ir para o estado 2

ou ir para o estado 3 ou........ou ir para o estado n.

.

.

.

• Para o estado n-1 existem n possibilidades: se manter no estado n-1 ou ir para o estado

1 ou ir para o estado 3 ou........ou ir para o estado n.

• Para o estado n existem n possibilidades: se manter no estado n ou ir para o estado 1

ou ir para o estado 2 ou........ou ir para o estado n-1.

Logo, temos que o n´umero total de probabilidades de transi¸c˜oes ´e igual a:

n + n + n + ..... + n + n = n · (1 + 1 + ..... + 1) = n · n = n2

Como temos n estados a serem representados tantos nas linhas quanto nas colunas
da matriz e n2 de possibilidades de transi¸c˜oes entre os estados, utilizaremos uma matriz
quadrada de ordem n.

25

Abaixo, temos a nossa matriz M para n estados.







E1
p11
...
pn1

· · · En
. . . p1n
...
. . .
pnn
· · ·







E1
...
En

M =

EXEMPLO 6.

Em uma consultoria realizada semanalmente foi veriﬁcado que o p´ublico alvo, fre-
quentador de certo cinema da cidade de Manaus, est´a distribu´ıdo do seguinte modo: 60%
assistem ﬁlmes de terror, 15% preferem ﬁlmes policiais e 25% buscam ﬁlmes romˆanticos.

Das pessoas que assistem ﬁlmes de terror na semana, 10% comparecer˜ao ao cinema na
pr´oxima semana para ver ﬁlme policial e 20% para assistir um ﬁlme romˆantico. J´a, dos que
gostam de ﬁlmes romˆanticos, na semana seguinte, 40% passar˜ao a visualizar ﬁlme de terror
e 20% ﬁlmes policiais. E do grupo de pessoas que preferem ﬁlmes policiais, 50% voltar˜ao ao
cinema na semana posterior para ver ﬁlmes de terror e 15% assistir˜ao a ﬁlmes romˆanticos.

Antes de elaborarmos a matriz de transi¸c˜ao, para que um experimento ou sistema seja
uma cadeia de Markov ´e necess´ario que seja representado por uma sequˆencia de observa¸c˜oes,
uma a uma, com destino a um dos trˆes estados, que nesse caso s˜ao apresentados como (terror,
policial, romˆantico) e a probabilidade de estar em um estado qualquer dependa somente
da probabilidade do estado anterior (a semana posterior depende da semana atual), logo,
podemos d´a continuidade na constru¸c˜ao da matriz e para esse ﬁm, representaremos todas as
probabilidades de transi¸c˜ao entre os estados, por meio de Grafos e Diagrama da ´Arvore de
probabilidades.

1o Modo - Grafos

0.7

T

0.1

0.5

Figura 1.3

0.2

P

0.4

0.15

0.35

0.2

R

0.4

A utiliza¸c˜ao de Grafos nos ser´a bastante ´util, principalmente quando abordarmos um

t´opico chamado de Fluxo Probabil´ıstico.

2o Modo - Diagrama de ´arvore ou ´arvore das probabilidades

Figura 1.4

26

0.6

0.15

0
.
2

5

T

P

R
T

P

R
T

P

R

0.7

0.1

0.2

0.5

0.35

0.15

0.4

0.2

0.4

T

P

R

Utilizar o m´etodo da ´arvore de possibilidades, tr´as um fator positivo no tocante de
visualizarmos tanto a probabilidade de cada estado no momento inicial do experimento,
quanto as probabilidades de transi¸c˜ao de cada estado.

Escrevendo a Matriz de Transi¸c˜ao temos o seguinte:






T
P
R

R
P
T
PT T PT P PT R
PP T PP P PP R
PRT PRP PRR






M =

27

Nomenclatura:
PT T ⇐⇒ Probabilidade de transi¸c˜ao do estado T para o estado T;
PT P ⇐⇒ Probabilidade de transi¸c˜ao do estado T para o estado P;
PT R ⇐⇒ Probabilidade de transi¸c˜ao do estado T para o estado R;
PP T ⇐⇒ Probabilidade de transi¸c˜ao do estado P para o estado T;
PP P ⇐⇒ Probabilidade de transi¸c˜ao do estado P para o estado P;
PP R ⇐⇒ Probabilidade de transi¸c˜ao do estado P para o estado R;
PRT ⇐⇒ Probabilidade de transi¸c˜ao do estado R para o estado T;
PRP ⇐⇒ Probabilidade de transi¸c˜ao do estado R para o estado P;
PRR ⇐⇒ Probabilidade de transi¸c˜ao do estado R para o estado R.
Logo,






T
P
R

R
P
T
0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4






M =

1.3.4 Propriedades da Matriz de Transi¸c˜ao

Vimos que utilizar matrizes em problemas modelados por Cadeias de Markov, ´e algo
pr´atico, j´a que observamos cada elemento da matriz de transi¸c˜ao como uma probabilidade de
movimenta¸c˜ao entre os estados. Avan¸camos para apresentar algumas de suas propriedades.

1. (cid:80)n

j=1 Pij =1 , com i=1,2,3,.......n,

Em outras palavras, o somat´orio de todos os elementos de cada linha da matriz, re-
presentados pelas probabilidades de transi¸c˜ao referente a cada estado do experimento
´e igual a 1, ou melhor dizendo, a probabilidade do experimento ir do estado i para o
estado 1 (Pi1) mais a probabilidade do experimento ir do estado i para o estado 2 (Pi2)
e assim sucessivamente at´e o estado n (Pin) ´e igual a 1.

2. Pij ≥ 0, com Pij ∈ [0, 1]

As entradas da matriz P (probabilidades de transi¸c˜ao) s˜ao positivas e pertencem ao
intervalo 0 ≤ Pij ≤ 1

3. M= [ ]n×n Toda matriz de transi¸c˜ao com n estados possui n2 possibilidades de probabi-
lidade de transi¸c˜ao que ser˜ao alocadas em n linhas e n colunas, formando deste modo,
sempre uma matriz quadrada de ordem n.

4. Em toda matriz de transi¸c˜ao as probabilidades de transi¸c˜ao est˜ao postadas de um modo
que as linhas representam os estados presentes e as colunas os estados subsequentes.

1.3.5 Deﬁni¸c˜ao

Podemos neste momento, estabelecer deﬁni¸c˜oes formais para cadeia de Markov tendo

como base dois autores.

28

Uma Cadeia de Markov ´e uma sequˆencia de experimentos, cada um dos quais resul-
tando em um dentre um numero ﬁnito de estados, que s˜ao rotulados por 1,2,3,.....n.
A probabilidade de estar em um estado particular depende apenas do estado ocu-
pado. Se Pij for a probabilidade de mover-se do estado i para o estado j, ent˜ao a
Matriz de Transi¸c˜ao M=[Pij] de uma Cadeia de Markov ´e a matriz n × n.

M =







p11
...
pn1







. . . p1n
...
. . .
pnn
· · ·

(SULLIVAN, 2013, P.491).

e

Suponha que um tal sistema muda com o tempo de um estado para outro e que em
instantes pr´e-determinados observamos o estado do sistema. Se o estado do sistema
em qualquer observa¸c˜ao n˜ao puder ser predito com certeza, mas se a probabilidade
de um certo estado ocorrer puder ser predita unicamente a partir do conhecimento
do estado do sistema na observa¸c˜ao imediatamente anterior, ent˜ao o processo de
uma mudan¸ca de um estado para outro ´e chamado de uma cadeia ou um processo
de Markov. (ANTON E RORRES, 2002, p.390).

1.4 Vetor Probabilidade

Considere M, como sendo uma matriz de transi¸c˜ao qualquer com n estados, e obvia-

mente, da forma n × n. A cada linha desta matriz denominaremos de vetor probabilidade.

E pela propriedade 1 de uma matriz de transi¸c˜ao, veriﬁcamos que:

(cid:80)n

j=1 Pij =1 com i=1,2,3,.......n

Assim, dado o exemplo anterior, teremos trˆes vetores de probabilidade que represen-

tam as probabilidades de transi¸c˜ao de cada estado em rela¸c˜ao aos demais:






T
P
R

R
P
T
0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4






M =

29

(cid:104)

(cid:104)

(cid:104)

0.7 0.1 0.2

(cid:105)

- Vetor probabilidade do estado categoria ﬁlmes de terror.

0.5 0.35 0.15

(cid:105)

- Vetor probabilidade do estado categoria ﬁlmes policiais.

0.4 0.2 0.4

(cid:105)

- Vetor probabilidade do estado categoria ﬁlmes romˆanticos.

1.5 Distribui¸c˜ao de probabilidade inicial

No exemplo anterior nos foi dada a informa¸c˜ao de que inicialmente a porcentagem do

p´ublico que frequenta um certo cinema em rela¸c˜ao a categoria de ﬁlmes era:

Tabela 1.2: Fra¸c˜ao por categoria de ﬁlmes

CATEGORIA FRAC¸ ˜AO

Terror
Policial
Romance

0.60
0.15
0.25

Sullivan (2013) considera, que em uma Cadeia de Markov, para visualizarmos o que
acontecer´a no momento seguinte de um experimento, precisamos saber o que aconteceu ime-
diatamente antes. Logo, ´e de fundamental importˆancia que saibamos em que estado o nosso
experimento ir´a come¸car.

Deﬁni¸c˜ao 1.5.1. Denominamos de Distribui¸c˜ao de probabilidade inicial, a uma matriz linha
com n colunas representando os n estados existentes, onde a i-´esima coluna representa a
probabilidade do experimento est´a no estado i no in´ıcio das observa¸c˜oes e ser´a simbolizado
por

(cid:104)

1
P (0)
i

· · ·
n
· · · P (0)
n

(cid:105)

p(0) =

Fazendo alus˜ao ao nosso exemplo, o vetor de distribui¸c˜ao de probabilidade inicial ter´a

a seguinte forma:

(cid:104)

T
P (0)
T

P R
P (0)
P

P (0)
R

(cid:105)

p(0) =

30

Nomenclatura

p(0) ⇐⇒ Vetor de distribui¸c˜ao de probabilidade inicial.
P (0)
P (0)
P (0)

T ⇐⇒ Probabilidade de iniciar o experimento na categoria de ﬁlme de terror.
P ⇐⇒ Probabilidade de iniciar o experimento na categoria de ﬁlme policial.
R ⇐⇒ Probabilidade de iniciar o experimento na categoria de ﬁlme romˆantico.

Portanto,

(cid:104)

p(0) =

T

P

R

0.60 0.15 0.25

(cid:105)

Agora, suponha que no experimento n˜ao esteja determinado em que estado se iniciar´a
a observa¸c˜ao ou que n˜ao conste nenhuma evidˆencia de como est´a distribu´ıda a probabilidade
para os estados. ´E f´acil ver que isto nos levar´a a concluir que seja igualmente prov´avel
come¸car a experiˆencia em qualquer um dos estados existentes, ou seja, a probabilidade de
iniciar na categoria de ﬁlmes de terror ´e a mesma da categoria de ﬁlme policial e igual a de
ﬁlmes de romance, ou seja,

p(0) =

T P R
1
1
3
3

(cid:20) 1
3

(cid:21)

Por´em, se o experimento informar que o in´ıcio da observa¸c˜ao se dar´a pela categoria
de ﬁlme de terror, ter´ıamos uma grande mudan¸ca em compara¸c˜ao ao vetor de distribui¸c˜ao
de probabilidade anterior, conforme abaixo.

(cid:104)

p(0) =

T P R

1 0 0

(cid:105)

Consequentemente, o experimento ao iniciar no estado de categoria de ﬁlmes policiais,

observar´ıamos

(cid:104)

p(0) =

T P R

0 1 0

(cid:105)

E com o mesmo racioc´ınio, se o estado escolhido para come¸car o ensaio for a categoria

de ﬁlmes romˆanticos, nossa matriz linha ser´a

(cid:104)

p(0) =

T P R

0 0 1

(cid:105)

1.6 Distribui¸c˜ao da probabilidade ap´os r observa¸c˜oes

Deﬁni¸c˜ao 1.6.1. ´E a matriz linha que mostra como a probabilidade est´a distribu´ıda para
cada estado, ap´os r passos, com r ∈ N, em uma cadeia de Markov. E ser´a representado por

31

(cid:104)

1
P (r)
1

· · ·
n
· · · P (r)
n

(cid:105)

p(r) =

EXEMPLO 7. Em referˆencia ao exemplo 6, qual ser´a a distribui¸c˜ao de probabilidade das
categorias de ﬁlmes ap´os a primeira observa¸c˜ao?

Resolu¸c˜ao:

Seja P (1) a distribui¸c˜ao de probabilidade de cada estado (terror, policial e romance),

ap´os a 1a observa¸c˜ao. isto ´e,

(cid:104)

T
P (1)
T

P
P (1)
P

R
P (1)
R

(cid:105)

p(1) =

Empregando os dados do exemplo em uma ´arvore de possibilidades, temos:

Figura 1.5

T

—–P (T ∩ T ) =0.6·0.7

T

P

0 . 7
0.1
R0.2

—–P (T ∩ P ) =0.6·0.1

—–P (T ∩ R) =0.6·0.2

0.6

0.15

P

0
.
2

5

0 . 5
0.35
0.15

T

P

R

T

—–P (P ∩ T ) =0.15·0.5

—–P (P ∩ P ) =0.15·0.35

—–P (P ∩ R) =0.15·0.15

—–P (R ∩ T ) =0.25·0.4

R

P

0 . 4
0.2
R0.4

—–P (R ∩ P ) =0.25·0.2

—–P (R ∩ R) =0.25·0.4

32

1a Observa¸c˜ao
P (1)
P (1)
P (1)

T = P (T ∩ T ) + P (P ∩ T ) + P (R ∩ T )
T = 0.6 · 0.7 + 0.15 · 0.5 + 0.25 · 0.4
T = 0.595

P (1)
P (1)
P (1)

P = P (T ∩ P ) + P (P ∩ P ) + P (R ∩ P )
P = 0.6 · 0.1 + 0.15 · 0.35 + 0.25 · 0.2
P = 0.1625

P (1)
P (1)
P (1)

R = P (T ∩ R) + P (P ∩ R) + P (R ∩ R)
R = 0.6 · 0.2 + 0.15 · 0.15 + 0.25 · 0.4
R = 0.2425

Logo, a nossa resposta ´e a matriz

(cid:104)

p(1) =

T

P

R

0.595 0.1625 0.2425

(cid:105)

Vamos traduzir todo esse desenvolvimento utilizado por meio da ´arvore de possibili-
dades, readaptando-a para o modo matricial. Isto ser´a de grande valia para o entendimento
do uso conjunto de matrizes e probabilidade, dois conte´udos chaves que s˜ao utilizados em
cadeias de Markov.

Analisando a ´arvore de possibilidades, conclu´ımos que para a cadeia de markov,

encontrar-se no estado R, ap´os uma observa¸c˜ao, existir˜ao trˆes possibilidades.

· PT T

P (T ∩ T ) = P (0)
P (P ∩ T ) = P (0)
P (R ∩ T ) = P (0)

T
P · PP T
R · PRT

Ent˜ao:
T = P (0)
P (1)

T

· PT T + P (0)

P · PP T + P (0)

R · PRT

(cid:104)

P (1)
T

0 0

(cid:104)

(cid:105)

=

P (0)
T

P (0)
P

P (0)
R

Seguindo a mesma id´eia, temos:






(cid:105)

·

0 0
PT T
PP T 0 0
PRT 0 0






P = P (0)
P (1)

T

· PT P + P (0)

P · PP P + P (0)

R · PRP

(cid:104)

0 P (1)
P

(cid:104)

(cid:105)

=

0

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

0 PT P
0
0 PP P 0
0 PRP 0






E por ´ultimo, chegamos a:

33

R = P (0)
P (1)

T

· PT R + P (0)

P · PP R + P (0)

R · PRR

(cid:104)

0 0 P (1)
R

(cid:104)

(cid:105)

=

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

0 0 PT R
0 0 PP R
0 0 PRR






Somando cada membro dos trˆes resultados matriciais acima, teremos a seguinte equa¸c˜ao

matricial:

(cid:104)

P (1)
T

0 0

(cid:104)
(cid:105)
+

0 P (1)
P

(cid:105)

(cid:104)
+

0

0 0 P (1)
R

(cid:104)

(cid:105)

=

P (0)
T

P (0)
P

P (0)
R

(cid:104)

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

0 PT P
0
0 PP P 0
0 PRP 0



(cid:104)


 +

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

0 0 PT R
0 0 PP R
0 0 PRR

PT T
0 0
PP T 0 0
PRT 0 0




+

(cid:105)




·







Portanto,

(cid:104)

T + 0 + 0 0 + P (1)
P (1)

R + 0 0 + 0 + P (1)

R

(cid:105)

=

(cid:104)
=

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

PT T
0 0
PP T 0 0
PRT 0 0






 +




0 PT P
0
0 PP P 0
0 PRP 0






 +




0 0 PT R
0 0 PP R
0 0 PRR






(cid:104)

⇒

P (1)
T

P (1)
P

P (1)
R

(cid:104)

(cid:105)

=

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

PT T PT P PT R
PP T PP P PP R
PRT PRP PRT






J´a sabemos que,

(cid:104)

p(1) =

P (1)
T

P (1)
P

P (1)
R

(cid:105)

34

Ent˜ao,

Logo,

(cid:104)

p(1) =

P (0)
T

P (0)
P

P (0)
R






(cid:105)

·

PT T PT P PT R
PP T PP P PP R
PRT PRP PRT






p(1) = p(0) · M

Por isso, podemos aﬁrmar que para calcularmos a distribui¸c˜ao de probabilidade ap´os
uma observa¸c˜ao, basta termos em m˜ao a distribui¸c˜ao de probabilidade inicial P0 e a matriz
de transi¸c˜ao M.

Prosseguindo com a equa¸c˜ao anterior, vamos calcular os vetores de distribui¸c˜ao de

probabilidade ap´os r passos, com r ∈ N, segue que,

p(1) = p(0) · M
p(2) = p(1) · M
p(3) = p(2) · M
.
.
p(r−2) = p(r−3) · M
p(r−1) = p(r−2) · M
p(r) = p(r−1) · M

Teorema 1.6.1. Em um experimento que possua a propriedade Markoviana, a distribui¸c˜ao
de probabilidade P (r), ap´os r tentativas, com r ∈ N, ´e dada por:

P (r) = P (r−1) · M

Em outras palavras, a distribui¸c˜ao de probabilidade posterior ´e igual ao produto da

distribui¸c˜ao de probabilidade imediatamente anterior pela matriz de transi¸c˜ao M.

EXEMPLO 8.

Utilizando o teorema acima, podemos conﬁrmar o resultado j´a obtido no exemplo 7,

referente a distribui¸c˜ao de probabilidade das categorias de ﬁlmes ap´os uma observa¸c˜ao.

Consequentemente,

P (1) = P (0) · M

(cid:104)

(cid:104)

P (1) =

P (1) =

0.60 0.15 0.25






(cid:105)

·

0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4






0.595 0.1625 0.2425

(cid:105)

35

EXEMPLO 9.

Semelhante ao c´alculo para um passo, encontraremos os valores para a distribui¸c˜ao de

probabilidade das categorias de ﬁlmes ap´os duas observa¸c˜oes.

Como,

(cid:104)

P (1) =

T

P

R

0.595 0.1625 0.2425

(cid:105)

Resulta que,

P (2) = P (1) · M

(cid:104)

(cid:104)

P (2) =

P (2) =

0.595 0.1625 0.2425






(cid:105)

·

0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4






0.5947 0.1649 0.2404

(cid:105)

Analisando a distribui¸c˜ao de probabilidade ap´os a segunda observa¸c˜ao, veriﬁcamos
que o percentual de pessoas que preferem assistir ﬁlmes de terror ´e de 59,47%.
j´a os que
continuam a assistir ﬁlmes policiais passou a ser de 16,49% e as pessoas que assistem a um
ﬁlme romˆantico chegam ao patamar dos 24,04%. Esse resultado implica uma estagna¸c˜ao no
n´umero de pessoas que assistem a categoria de ﬁlmes de terror. J´a em rela¸c˜ao ao grupo que
visualiza ﬁlmes policiais houve um pequeno crescimento, enquanto a fra¸c˜ao que representa a
quantidade de pessoas que curtem ﬁlmes romˆanticos teve uma queda diminuta.

Para que haja um maior entendimento, calcularemos as distribui¸c˜oes de probabilidade

ap´os a 3a observa¸c˜ao.

P (3) = P (2) · M

(cid:104)

(cid:104)

P (3) =

P (3) =

0.5947 0.1649 0.2404

0.5949 0.1653 0.2398

0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4











(cid:105)

·

(cid:105)

36

Agora, ap´os a 3a observa¸c˜ao, tanto a categoria de ﬁlmes de terror quanto a de ﬁlmes
policiais tiveram um pequeno crescimento em rela¸c˜ao a observa¸c˜ao passada. Por´em, ao lhe
darmos com o p´ublico que prefere ﬁlmes romˆanticos veriﬁcamos mais uma queda.

Suponha darmos continuidade com esse experimento por 40 semanas seguidas. O leitor
notar´a que fazer esses c´alculos poder´a lhe trazer bastante trabalho, j´a que utilizar´ıamos o
teorema anterior por 40 vezes, precisamos ent˜ao, buscar uma nova maneira de calcular as
distribui¸c˜oes de probabilidade.

J´a ´e de nosso conhecimento que

P(1) = P(0) · M
P(2) = P(1) · M
.
.
P(r−1) = P(r−2) · M
P(r) = P(r−1) · M

Fazendo o produto membro a membro chegamos a seguinte express˜ao:

P (r) = P (0) · M · M · M · M........ · M
P (r) = P (0) · M r

De posse desse resultado, podemos enunciar o seguinte teorema:

Teorema 1.6.2. Em um experimento com propriedade Markoviana, formando desse modo
uma cadeia de Markov, a distribui¸c˜ao de probabilidade P (r), ap´os r tentativas ´e dada por:

P (r) = P (0) · M r

Isto ´e, a distribui¸c˜ao de probabilidade ap´os a e-r´esima observa¸c˜ao ´e dada pelo produto

da distribui¸c˜ao de probabilidade inicial pela e-r´esima potˆencia da matriz de transi¸c˜ao M.

A prova do dois teoremas anteriores n˜ao ser˜ao veriﬁcadas neste trabalho, por´em pode

ser encontrada no [3] e [7] das referˆencias bibliogr´aﬁcas.

EXEMPLO 10.

Fazendo uso do teorema acima, calcule as distribui¸c˜oes de probabilidade ap´os a pri-

meira, segunda e terceira observa¸c˜oes, todas relacionadas ao exemplo 7.

37

P (r) = P (0) · M r

P (1) = P (0) · M 1

P (1) = P (0) ·






PT T PT P PT R
PP T PP P PP R
PRT PRP PRT






0.6 0.15 0.25






(cid:105)

·






0.2
0.1
0.7
0.5 0.35 0.15
0.4
0.4
0.2
(cid:105)

0.595 0.1625 0.2425

Agora vamos calcular P (2)

P (2) = P (0) · M 2

0.6 0.15 0.25

0.6 0.15 0.25











(cid:105)

·

(cid:105)

·

0.2
0.1
0.7
0.5 0.35 0.15
0.4
0.2
0.4

2





0.235
0.145
0.62
0.585 0.2025 0.2125
0.27
0.19
0.54
(cid:105)






0.5947 0.1649 0.2404

(cid:104)

(cid:104)

P (1) =

P (1) =

(cid:104)

(cid:104)

(cid:104)

P (2) =

P (2) =

P (2) =

Calculando P (3)

P (3) = P (0) · M 3

(cid:104)

P (3) =

0.6 0.15 0.25






(cid:105)

·

0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4

3





38

(cid:104)

(cid:104)

P (3) =

P (3) =

0.6 0.15 0.25






(cid:105)

·

0.23975
0.15975
0.6005
0.59575 0.171875 0.232375
0.2445
0.1745
0.581






0.5949 0.1653 0.2398

(cid:105)

Perceba que, se precis´assemos calcular a distribui¸c˜ao de probabilidade ap´os a oitava
observa¸c˜ao, bastar´ıamos ter em m˜aos o resultado do quadrado da matriz de transi¸c˜ao, j´a
que M 8 = M 2 · M 2 · M 2 · M 2 = M 4 · M 4, diminuindo o n´umero de c´alculos e abreviando o
resultado em rela¸c˜ao ao teorema 1.6.1

1.7 Matriz de transi¸c˜ao ap´os r observa¸c˜oes ou passos

Segundo Ross (2009), em uma cadeia de Markov, a probabilidade de um sistema
que no in´ıcio da observa¸c˜ao se encontra no estado i, mudar para o estado j na observa¸c˜ao
subsequente, ´e representado por

Pij

Indo mais al´em, Gordon (1967) assegura que a probabilidade de que o sistema estar´a

no estado j depois de r passos e iniciando no estado i, ´e

Aproveitando que

P (r)
ij

P (r) = P (0) · M r

E considerando as matrizes abaixo, que reﬂex˜ao poder´ıamos ter em rela¸c˜ao ao signi-
ﬁcado das entradas (probabilidades de transi¸c˜ao), quando a matriz de transi¸c˜ao ´e exposta a
potˆencias? Que an´alise ter´ıamos de P (r)
ij , onde r indica que o sistema est´a em sua e-r´esima
observa¸c˜ao?

T

P

R

0.7
0.2
0.1
0.5 0.35 0.15
0.4
0.2
0.4






T
P
R




 e M2 =

T

P

R






T
P
R

0.235
0.145
0.62
0.585 0.2025 0.2125
0.27
0.19
0.54






M=

39

Tomemos o elemento de valor 0,235 de M 2.

0,235 representa a probabilidade do sistema, ap´os duas observa¸c˜oes, estar na categoria

de ﬁlmes romˆanticos sendo que o experimento foi iniciado na categoria de ﬁlmes de terror.

E o elemento de valor 0,585?

A entrada mostra a probabilidade de passar da categoria de ﬁlmes policiais para os

ﬁlmes de terror ap´os duas observa¸c˜oes.

O que signiﬁca a entrada 0,19?

Refere-se a probabilidade, ap´os duas observa¸c˜oes, de uma pessoa que frequentava a

categoria de ﬁlmes romˆanticos esteja assistindo um ﬁlme policial.

Consequentemente, os P (r)
ij

s˜ao os elementos da matriz Mr, de uma cadeia de Markov,
com a fun¸c˜ao de indicar a probabilidade de passar do estado i para o estado j ap´os r tentativas.
´E de vital importˆancia, o entendimento referente a origem dos elementos da matriz

M2 e quais as fun¸c˜oes de cada componente em uma cadeia de Markov.

Utilizando a ´arvore de possibilidades, temos que,

Figura 1.6

T

P

0 . 7
0.1
R0.2

—–P (T ∩ T ) =0.7·0.7

—–P (T ∩ P ) =0.7·0.1

—–P (T ∩ R) =0.7·0.2

T

0.7

T

P

0.1

0
.
2

0 . 5
0.35
0.15

T

P

R

T

—–P (P ∩ T ) =0.1·0.5

—–P (P ∩ P ) =0.1·0.35

—–P (P ∩ R) =0.1·0.15

—–P (R ∩ T ) =0.2·0.4

R

P

0 . 4
0.2
R0.4

—–P (R ∩ P ) =0.2·0.2

—–P (R ∩ R) =0.2·0.4

40

Na ´arvore, os elementos em vermelho representam os modos de sair da categoria de

ﬁlmes de terror (T) e chegar na categoria de ﬁlmes romˆanticos (R) ap´os duas observa¸c˜oes.

Somando apenas as probabilidades (caminhos vermelhos) que nos interessam, encon-
tramos, 0.7 · 0.2 + 0.1 · 0.15 + 0.2 · 0.4 = 0.235, valor esse, que corresponde na matriz M2, ao
elemento P (2)
T R, ou seja, representa a probabilidade de passar do estado ﬁlmes de terror para
o estado de ﬁlmes romˆanticos, ap´os duas observa¸c˜oes.

Do mesmo modo, a probabilidade do experimento iniciar no estado ﬁlmes policiais e
termina em ﬁlmes de terror, ap´os duas observa¸c˜oes, ´e dado pelos seguintes caminhos em azul

Figura 1.7

T

P

0 . 7
0.1
R0.2

—–P (T ∩ T ) =0.5·0.7

—–P (T ∩ P ) =0.5·0.1

—–P (T ∩ R) =0.5·0.2

T

0.5

P

0.35

P

0
.
1

5

0 . 5
0.35
0.15

T

P

R

T

—–P (P ∩ T ) =0.35·0.5

—–P (P ∩ P ) =0.35·0.35

—–P (P ∩ R) =0.35·0.15

—–P (R ∩ T ) =0.15·0.4

R

P

0 . 4
0.2
R0.4

—–P (R ∩ P ) =0.15·0.2

—–P (R ∩ R) =0.15·0.4

Consequentemente, 0.5 · 0.7 + 0.35 · 0.5 + 0.15 · 0.4 = 0.585, equivale ao elemento P (2)
P T ,
s˜ao as probabilidades de transi¸c˜ao ap´os r

de M2, logo, podemos dizer que os valores de P (r)
ij
passos (observa¸c˜oes) da matriz de transi¸c˜ao elevada a e-r´esima potˆencia, M r.

´E interessante notar que trabalhando a matriz de transi¸c˜ao por meio de potˆencias,
obtemos de um modo muito mais f´acil e ´agil, todas as probabilidades da cadeia de Markov
iniciar em um estado e terminar em outro, ap´os r per´ıodos de observa¸c˜oes.

Tamb´em, podemos calcular as P (r)

ij de M r, utilizando as chamadas Equa¸c˜oes de

Chapman-Kolmogorov, t´opico esse, que n˜ao ser´a abordado nesse trabalho.

41

Cap´ıtulo 2

Cadeias de Markov Regulares

No cap´ıtulo passado, estudamos de forma detalhada as cadeias de Markov. Agora
necessitamos analisar um certo tipo de cadeia que possui a propriedade de alcan¸car a estabi-
lidade, uma convergˆencia das distribui¸c˜oes de probabilidades quando aumentamos o n´umero
de observa¸c˜oes. Isto signiﬁca, que a distribui¸c˜ao de probabilidade nos estados a partir de um
certo momento n˜ao se alterar´a.

Deﬁni¸c˜ao 2.0.1. Em um experimento detentor de Propriedade Markoviana, onde as ob-
serva¸c˜oes ou tentativas s˜ao representadas por meio de distribui¸c˜oes das probabilidades dos
estados, tais que, para alguma r´esima potˆencia da sua matriz de transi¸c˜ao, nos apresen-
tar probabilidades de transi¸c˜ao (elementos da matriz) estritamente positivas, deﬁnimos como
sendo uma cadeia de Markov regular.

De modo sucinto, uma cadeia de Markov ´e regular quando qualquer potˆencia da matriz

de transi¸c˜ao resulta em elementos rigorosamente positivos.

EXEMPLO 11.

Seja a matriz de tansi¸c˜ao M =

(cid:35)

(cid:34)

0 1
1 0

Vamos veriﬁcar se a mesma ´e uma cadeia de Markov regular.

Para M 2 =

(cid:34)

0 1
1 0

(cid:35)

(cid:34)

·

0 1
1 0

(cid:35)

M 2 =

(cid:35)

(cid:34)

1 0
0 1

42

Para M 3 = M · M 2 =

(cid:34)

0 1
1 0

(cid:35)

(cid:34)

·

1 0
0 1

(cid:35)

(cid:34)

=

0 1
1 0

(cid:35)

Se continuarmos o processo, chegaremos a seguinte conclus˜ao:

Para M r, com r par temos,
M 2 = M 4 = M 6 = M 2n = I (matriz identidade)

Para M r, com r ´ımpar temos,
M 1 = M 3 = M 5 = M 2n−1 = M (matriz de transi¸c˜ao)

Esse exemplo nos mostra que por maior que seja o n´umero de observa¸c˜oes, isto ´e,
tender r a um n´umero elevado, as potˆencias da matriz de transi¸c˜ao oscilar˜ao entre a matriz
identidade e a pr´opria matriz de transi¸c˜ao, para r par e ´ımpar respectivamente, onde dois de
seus elementos n˜ao s˜ao extritamente positivos. Conclu´ımos ent˜ao, que a matriz de transi¸c˜ao
jamais convergir´a para uma matriz ﬁxa.

EXEMPLO 12.

Toda quarta-feira a noite, Mikael assiste jogo do campeonato brasileiro de futebol
da S´erie A ou vai ao cinema, de modo que ele nunca assiste futebol duas quartas seguidas,
entretanto se ele decidir ir nessa quarta ao cinema, ent˜ao a probabilidade dele ir novamente
ao cinema na pr´oxima quarta ´e de 1/3.

a) Represente a matriz de transi¸c˜ao se for o caso.
b) Ap´os trˆes quartas-feiras, qual a probabilidade de Mikael est´a assistindo futebol?
c) A cadeia de Markov ´e regular?

Resolu¸c˜ao:

a) Perceba que no exemplo dado h´a uma v´ınculo de dependˆencia nas a¸c˜oes que Mikael
ir´a realizar entre uma quarta-feira e a pr´oxima. Logo, podemos aﬁrmar que se trata de uma
cadeia de Markov.

Sendo assim, suponha que M seja a matriz de transi¸c˜ao solicitada. Pelo problema,
Mikael nunca assisti ao jogo de futebol duas vezes seguidas, mas se estiver no cinema, da
pr´oxima vez haver´a 2/3 de chances de assistir ao futebol e 1/3 de retornar ao cinema.

Logo, formaremos os seguintes estados:

F (estado) - Mikael assistir jogo de futebol
C (estado) - Mikael ir ao cinema

Agora, vamos representar as probabilidades de transi¸c˜ao por meio de grafos.

43

Figura 2.1

1

2
3

C

1
3

0

F

`A vista disso, obtemos a seguinte matriz de transi¸c˜ao M:

M =

(cid:35)

(cid:34)

F C
0 1
1
2
3
3

F
C

b) Utilizando o teorema 1.6.2, temos o seguinte:

P (3) = P (0) ·

(cid:35)3

(cid:34)

0 1
1
2
3
3

P (3) =

(cid:104) 1
2

P (3) =

(cid:104) 1
2

(cid:34)

(cid:105)

·

(cid:34)

(cid:105)

·

1
2

1
2

(cid:35)3

0 1
2
1
3
3

(cid:35)

0.2222 0.7778
0, 5185 0.4815

(cid:104)

P (3) =

0.3704 0.6296

(cid:105)

Desse modo, na pr´oxima quarta-feira, h´a 37,04% de chances de Mikael est´a no cinema

e 62,96% de assistir ao futebol.

44

c) Para comprovarmos se o problema ´e referente a uma cadeia de Markov regular,
basta colocarmos em pr´atica a deﬁni¸c˜ao, ou seja, ao elevarmos a matriz de transi¸c˜ao a qual-
quer r ∈ N, com r > 1, impreterivelmente, devemos obter todos os elementos estritamente
positivos.

(cid:34)

0 1
1
2
3
3

(cid:35)2

(cid:34)

=

0, 666667
0, 222222

0, 333333
0, 777778

(cid:35)

Note que todos os elementos da matriz, (Pij)2, s˜ao > 0. Dessa maneira, garantimos

que se trata de uma cadeia de Markov regular.

2.1 Convergˆencia da distribui¸c˜ao de probabilidade

Ao estudar cadeias de Markov, podemos nos perguntar o que acontecer´a com as distri-
bui¸c˜oes de probabilidade no decorrer do tempo. No exemplo passado, ap´os trˆes observa¸c˜oes,
veriﬁcamos que a distribui¸c˜ao de probabilidade que representa a perspectiva de que Mikael
esteja no cinema ou assistindo futebol ´e de 62,96% e 37,04% respectivamente.
Mas, o que acontecer´a se aumentarmos o n´umero de observa¸c˜oes?

Vamos calcular para 4 observa¸c˜oes:

P (4) =

P (4) =

(cid:104) 1
2

(cid:104) 1
2

(cid:34)

(cid:34)

(cid:105)

(cid:105)

·

·

1
2

1
2

(cid:35)4

0 1
1
2
3
3

0.5185 0.4815
0, 3210 0.6790

(cid:104)

P (4) =

0.4198 0.5802

(cid:105)

E para 5 observa¸c˜oes:

P (5) =

P (5) =

(cid:104) 1
2

(cid:104) 1
2

(cid:34)

(cid:34)

(cid:105)

(cid:105)

·

·

1
2

1
2

(cid:35)5

0 1
1
2
3
3

0.3210 0.6790
0, 4527 0.5473

(cid:104)

P (5) =

0.3868 0.6132

(cid:105)

(cid:35)

(cid:35)

At´e o momento n˜ao podemos tirar conclus˜oes. Ent˜ao, vamos dar continuidade ao

processo at´e contemplarmos alguma informa¸c˜ao valiosa.

45

Calculando a partir do P (6) encontraremos os seguintes resultados:

P (6) =

P (7) =

P (8) =

P (9) =

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

P (10) =

P (11) =

P (12) =

P (13) =

P (14) =

P (15) =

P (16) =

P (17) =

P (18) =

P (19) =

P (20) =

P (21) =

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:104) 1
2

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

·

·

·

·

1
2

1
2

1
2

1
2

0, 4527 0.5473
0, 3649 0.6351

0, 3649 0.6351
0, 4234 0.5766

0, 4234 0.5766
0, 3844 0.6156

0, 3844 0.6156
0, 4104 0.5896

(cid:35)

(cid:35)

(cid:35)

(cid:35)

=⇒ P (6) =

=⇒ P (7) =

=⇒ P (8) =

=⇒ P (9) =

(cid:104)

(cid:104)

(cid:104)

(cid:104)

0.4088 0.5912

0.3941 0.6059

0.4039 0.5961

0.3974 0.6026

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:34)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

·

·

·

·

·

·

·

·

·

·

·

·

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

0, 4104 0.5896
0, 3931 0.6069

0, 3931 0.6069
0, 4046 0.5954

0, 4046 0.5954
0, 3969 0.6031

0, 3969 0.6031
0, 4021 0.5979

0, 4021 0.5979
0, 3986 0.6014

0, 3986 0.6014
0, 4009 0.5991

0, 4009 0.5991
0, 3994 0.6006

0.3994 0.6006
0, 4004 0.5996

0, 4004 0.5996
0, 3997 0.6003

0, 3997 0.6003
0, 4002 0.5998

0, 4000 0.6000
0, 4000 0.6000

0, 4000 0.6000
0, 4000 0.6000

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

(cid:35)

=⇒ P (10) =

=⇒ P (11) =

=⇒ P (12) =

=⇒ P (13) =

=⇒ P (14) =

=⇒ P (15) =

=⇒ P (16) =

=⇒ P (17) =

=⇒ P (18) =

=⇒ P (19) =

=⇒ P (20) =

=⇒ P (21) =

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

(cid:104)

0.4017 0.5983

0.3988 0.6012

0.4008 0.5992

0.3995 0.6005

0.4003 0.5997

0.3998 0.6002

0.4002 0.5998

0.3999 0.6001

0.4001 0.5999

0.3999 0.6001

0.4000 0.6000

0.4000 0.6000

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

46

Note que a partir do P (20), veriﬁcamos a existˆencia de uma distribui¸c˜ao de probabi-
lidade que n˜ao se altera e uma matriz com todas suas linhas iguais. Quando isso acontece
dizemos que a cadeia de Markov atingiu a sua distribui¸c˜ao limite de probabilidade, isto ´e,
por mais que prossigamos nas observa¸c˜oes, tanto a distribui¸c˜ao de probabilidade quanto as
probabilidades de transi¸c˜ao das potˆencias da matriz de transi¸c˜ao n˜ao se alterar˜ao.

Teorema 2.1.1. Seja M uma Matriz de transi¸c˜ao pertencente a uma cadeia de Markov
regular, ent˜ao:

A sequˆencia M, M 2, M 3, .....M r..... com r ∈ N, converge para uma matriz X ;

Ao calcularmos o M 20 e M 21 do exemplo anterior veriﬁcamos a convergˆencia da matriz

de transi¸c˜ao para uma matriz ﬁxa, onde todas as linhas s˜ao iguais.

(cid:34)

(cid:34)

M 20 =

M 21 =

(cid:35)

(cid:35)

0, 4000 0.6000
0, 4000 0.6000

0, 4000 0.6000
0, 4000 0.6000

Teorema 2.1.2. Seja M uma Matriz de transi¸c˜ao pertencente a uma cadeia de Markov re-
gular, e r ∈ N, quando r → +∞, existir´a uma Matriz X = lim
M r, tal que, todas as suas
r→∞
. . .

(cid:105)
, chamada de vetor de

. . .

(cid:104)

t1

t2

tr

linhas ser˜ao idˆenticas a uma matriz linha t =
distribui¸c˜ao limite de probabilidade, ou seja,

lim
r→∞

M r = X =









t1
t1
...
t1

t2
t2
. . .
t2

. . .
. . .
...
. . .









tn
tn
...
tn

Observe que a matriz M 20, do exemplo passado, possui duas linhas iguais e idˆenticas

ao vetor de distribui¸c˜ao limite de probabilidade t.

(cid:34)

X =

0, 4000 0.6000
0, 4000 0.6000

(cid:35)

(cid:104)

, t =

0.4000 0.6000

(cid:105)

47

A prova, dos dois teoremas anteriores, utiliza t´opicos de an´alise real, logo, n˜ao ser´a
abordada nesse trabalho, mas para o leitor que queira veriﬁcar a demonstra¸c˜ao, indicamos o
[2] das referˆencias bibliogr´aﬁcas.

Teorema 2.1.3. Considere M uma Matriz de transi¸c˜ao pertencente a uma cadeia de Markov
regular, e v(0) qualquer vetor de distribui¸c˜ao de probabilidade inicial, ent˜ao quando r → +∞,
v(r)→ v(0) · X→ t,ou seja, t n˜ao depende de v(0).

Demonstra¸c˜ao. Seja v(0) =

(cid:104)

v1 v2

. . .

. . . vn

(cid:105)

Pelo teorema 2.1.2, quando r → +∞, temos que:

lim
r→∞

M r =















t1
t1
...
...
...
t1

t2
t2
. . .
. . .
. . .
t2

. . .
. . .
...
...
...
. . .















tn
tn
...
...
...
tn

v(0) · lim
r→∞

M r = v(0) · X

Ent˜ao,

Logo,

(cid:104)

v1 v2

. . .

. . . vn

(cid:105)

·















t1
t1
...
...
...
t1

t2
t2
. . .
. . .
. . .
t2

. . .
. . .
...
...
...
. . .















tn
tn
...
...
...
tn

=

(v1 + v2 + . . . + vn) · t1

(v1 + v2 + . . . + vn) · t2

. . .

(v1 + v2 + . . . + vn) · tn

(cid:105)

(cid:104)
=

Por´em, v(0) ´e um vetor de distribui¸c˜ao de probabilidade utilizado no in´ıcio do experi-

mento, logo v1 + v2 + v3 . . . . . . + vn = 1, e segue que

48

v(0) · lim
r→∞

M r = v(0) · X =

(cid:104)

1 · t1 1 · t2

. . . 1 · tn

(cid:104)

(cid:105)

=

t1

t2

. . .

. . .

tn

(cid:105)
= t

Consequentemente v(0) · lim
r→∞

M r = lim
r→∞

v(0) · M r = lim
r→∞

v(r) = t

Portanto, independente do vetor de distribui¸c˜ao inicial utilizado no experimento che-

garemos ao vetor de distribui¸c˜ao limite de probabilidade.

Teorema 2.1.4. Suponha M uma Matriz de transi¸c˜ao pertencente a uma cadeia de Markov
regular, ent˜ao, o vetor de distribui¸c˜ao limite de probabilidade t ´e um componente da Matriz
X se e somente se t ·M = t, melhor dizendo,

(cid:104)

t1

t2

. . .

. . .

tn







(cid:105)

·

p11
...
pn1

. . . p1n
...
. . .
pnn
· · ·







(cid:104)

=

t1

t2

. . .

. . .

tn

(cid:105)

M r, onde M ´e a
Demonstra¸c˜ao. De acordo com o teorema 2.1.2, ∃ uma matriz X= lim
r→∞
matriz de transi¸c˜ao de uma cadeia de Markov regular, com r ∈ N, ou melhor dizendo, a
partir de um valor qualquer, maior que r, o resultado nos conduzir´a tamb´em para a matriz
estacion´aria X.

Logo, lim
r→∞

M r+k = X, com k ∈ N

Portanto, lim
r→∞

M r+1 = X

Mas note que M · lim
r→∞

M r = M · X, seguindo que lim
r→∞

M · M r = M · X.

Assim sendo, lim
r→∞

M r+1 = M · X

Leithold (1994) aﬁrma que pelo Teorema da Unicidade do Limite, uma fun¸c˜ao n˜ao

tender´a a dois limites diferentes ao mesmo tempo, isto ´e, se o limite existir, ser´a ´unico.

Desse modo, lim
r→∞

M r+1 = M · X e lim
r→∞

M r+1 = X, ent˜ao M · X = X.

Multiplicando v(0) em ambos os termos teremos a seguinte express˜ao:
v(0) · M · X = v(0) · X, consequentemente v(0) · X · M = v(0) · X

Aplicando o limite em ambos os termos, teremos
lim
r→∞

v(0) · X · M = lim
r→∞

v(0) · X, ou seja, lim
r→∞
v(0) · X

Implica que, lim
r→∞

v(0) · X · M = lim
r→∞

v(0) · X · lim
r→∞

M = lim
r→∞

v(0) · X

Conforme o teorema 2.1.3, quando r → +∞, v(r) → v(0) ·X→ t, isto ´e, lim
r→∞

prosseguindo tˆem-se que t · M = t

v(0) ·X = t,

49

A opera¸c˜ao matricial abaixo, que representa a 20a observa¸c˜ao do exemplo dado, con-

ﬁrma a propriedade t · M = t.

(cid:104)

0.4000 0.6000

(cid:34)

(cid:105)

·

0 1
1
2
3
3

(cid:35)

(cid:104)

=

0.4000 0.6000

(cid:105)

Chegamos ao vetor de distribui¸c˜ao limite de probabilidade por meio de cont´ınuos
c´alculos (21 observa¸c˜oes), onde esses resultados eram veriﬁcados at´e encontrarmos uma dis-
tribui¸c˜ao convergente, mas depois da inser¸c˜ao do Teorema 3.2.4, n˜ao necessitaremos de todo
esse trabalho para chegarmos at´e o vetor limite, j´a que o teorema garante que se uma cadeia
de Markov ´e regular, existe um vetor limite de distribui¸c˜ao de probabilidade t, tal que, seu
produto pela matriz de transi¸c˜ao M, resulta no pr´oprio vetor limite, ou seja, t · M = t.

Por consequˆencia, vamos veriﬁcar esse resultado utilizando o Teorema 2.1.4

Seja t =

(cid:104)

t1

t2

(cid:105)

, como sabemos que M =

(cid:34)

(cid:35)

0 1
1
2
3
3

, segue que:

(cid:104)

(cid:104)

(cid:104)






(cid:34)

(cid:105)

·

t1

t2

0 1
1
2
3
3

(cid:35)

(cid:104)

=

(cid:105)

t1

t2

t1 · 0 + t2 · 2
3

t1 · 1 + t2 · 2
3

(cid:105)

(cid:104)

=

t1

t2

(cid:105)

t2 · 2
3

t1 + t2 · 2
3

(cid:105)

(cid:104)

=

t1

t2

(cid:105)

t2 ·

2
3
t1 + t2 ·

= t1
2
3

= t2

Observe que o sistema ´e indeterminado. Logo, precisamos de mais uma informa¸c˜ao

para prosseguirmos na resolu¸c˜ao.

Lembremos que t1 + t2 = 1, assim teremos,






t1 = 1 − t2
2
3

= t1

t2 ·

50

3 = 1 − t2, segue que, t2 · 2

t2 · 2
Logo, t2 = 0.6 e como t1 = 1 − t2, segue que t1 = 0.4

3 + t2 = 1, implicando em t2 · 5

3 = 1

Portanto, t =

(cid:104)

F

C

0.4 0.6

(cid:105)

, como j´a era esperado.

Teorema 2.1.5. Seja M uma Matriz de transi¸c˜ao pertencente a uma cadeia de Markov
regular, ent˜ao, o vetor de distribui¸c˜ao limite de probabilidade t, tal que t · M = t, ´e ´unico.

Demonstra¸c˜ao. Pelo Teorema 3.2.4 temos que t · M = t, suponha que exista um outro vetor
de distribui¸c˜ao limite de probabilidade t(cid:48), ou seja, t(cid:48) · M = t(cid:48). Analogamente t(cid:48) · M r = t(cid:48)
nos levando a aﬁrma¸c˜ao de que t(cid:48) · M r → t(cid:48). Agora pelo Teorema 3.2.3, quando r → +∞,
v(r)→ v(0) · X→ t, que equivale a dizer v(r)→ v(0) · M r→ t. Assim, sem perda de generalidade,
substituindo v(0) por t(cid:48), j´a que o vetor t n˜ao depende de qualquer vetor de distribui¸c˜ao de
probabilidade inicial, conclu´ımos que t(cid:48) ·M r → t. E como sabemos pela Teorema da Unicidade
do Limite, tˆem-se que t = t(cid:48).

Alicer¸cado nesse teorema, podemos aﬁrmar que a equa¸c˜ao matricial t · M = t possui

apenas uma solu¸c˜ao. Logo,

t · M = t
t · M = t · I
t · M − t · I = t · I − t · I
t · (M − I) = 0



(cid:104)

(cid:104)

t1

. . .

tn

t1

. . .

tn

(cid:105)

· (











(cid:105)

·

Segue que,

p11
...
pn1

. . . p1n
...
. . .
pnn
· · ·













−

...

p11 − 1 . . . p1n − 0
. . .
pn1 − 0 · · ·

...
pnn − 1







1 . . . 0
...
...
1
0 · · ·
1


(cid:104)

) =

0 . . . 0

(cid:105)

(cid:104)

=





(cid:105)

0 . . . 0






t1 · (p11 − 1) + · · · + tn · (pn1) = 0
t1 · (p12) + · · · + tn · (pn2) = 0
...
...
t1 · (p1n) + · · · + tn · (pnn − 1) = 0

Por ﬁm, encontrar as solu¸c˜oes do sistema de equa¸c˜oes acima, equivale a identiﬁcarmos

os elementos do vetor de distribui¸c˜ao limite de probabilidade.

Examinando a utiliza¸c˜ao do sistema de equa¸c˜oes acima, por meio do exemplo anterior,

51

teremos:

(cid:104)

t =

t1

t2

(cid:34)

(cid:105)

e M=

(cid:35)

0 1
1
2
3
3

t · M = t

t · M − t = 0

t · (M − I) = 0

(cid:104)

(cid:104)

(cid:34)

(cid:105)

·

t1

t2

0 − 1 1 − 0
3 − 0 1
2
3 − 1

(cid:35)

(cid:104)

=

0 0

(cid:105)

(cid:34)

(cid:105)

·

t1

t2

−1
2
3

1
−2
3

(cid:35)

(cid:104)

=

0 0

(cid:105)






−t1 +
2
3

t1 −

· t2 = 0

2
3
· t2 = 0

Veja, que a segunda equa¸c˜ao ´e combina¸c˜ao linear da primeira, portanto, precisamos

de mais uma equa¸c˜ao para prosseguirmos com a resolu¸c˜ao.

Recordemos que t1 + t2 = 1. Seguindo,




−t1 +

2
3

· t2 = 0

t1 + t2 = 1


Temos:
t1 = 1 − t2
−(1 − t2) + 2
−1 + t2 + 2
5
3 · t2 = 1

3 · t2 = 0

3 · t2 = 0

Desse modo, chegamos novamente ao resultado t2 = 0, 6 e t1 = 0, 4 .

52

2.2 Fluxo Probabil´ıstico

J´a vimos que existem m´etodos para identiﬁcar os valores do vetor de distribui¸c˜ao limite
de probabilidade. Agora, acrescentaremos mais um modo de determinar esses elementos, que
de acordo com Miranda (2016) ´e denominado de ”Equa¸c˜ao de Fluxo Probabil´ısticos”, que
assim consiste:

Teorema 2.2.1. Para cada estado com distribui¸c˜ao de probabilidade est´avel, de uma cadeia
de Markov regular, a soma dos ﬂuxos de probabilidades que chegam a esse estado ´e igual a
soma dos ﬂuxo probabil´ısticos que saem desse mesmo estado.

Demonstra¸c˜ao. Sabemos pelo Teorema 2.1.4 que se t ´e um vetor de distribui¸c˜ao limite de
probabilidade, ent˜ao t · M = t, em que M ´e a matriz de transi¸c˜ao de uma cadeia de Markov
regular, no qual segue que,

(cid:104)

t1

t2

. . .

tj

. . .

tn

(cid:105)







·





p11
...
...
...
pn1

. . . p1j
...
. . .
. . .
pjj
...
. . .
pnj
· · ·












. . . p1n
...
. . .
...
. . .
...
. . .
pnn
· · ·

(cid:104)

=

t1

t2

. . .

t(cid:13)j

. . .

tn

(cid:105)

Para uma melhor entendimento, suponha que decidimos calcular apenas o elemento

tj do vetor de distribui¸c˜ao limite de probabilidade t.

tj = t1 · p1j + t2 · p2j + . . . + tj · pjj + . . . + tn · pnj

Assim

Segue

Logo

Ent˜ao

tj = (cid:80)n

i=1 ti · Pij

tj = (cid:80)n

∀i(cid:54)=j ti · Pij + tj · Pjj, com i=1,2,3,.......n

(cid:80)n

∀i(cid:54)=j ti · Pij = tj − tj · Pjj

(cid:80)n

∀i(cid:54)=j ti · Pij = tj · (1 − Pjj)

Agora, considere todas as transi¸c˜oes de probabilidade do estado j em rela¸c˜ao aos n

estados. Desse modo, por ser um vetor probabilidade teremos

53

pj1 + pj2 + pj3 + . . . + pjj + . . . + pjn = 1

pj1 + pj2 + pj3 + . . . + pjn = 1 − pjj

Consequentemente

Mas lembremos que

Portanto

(cid:80)n

∀k(cid:54)=j Pjk = 1 − pjj

(cid:80)n

∀i(cid:54)=j ti · Pij = tj · (1 − Pjj)

(cid:80)n

∀i(cid:54)=j ti · Pij = tj · ((cid:80)n

∀k(cid:54)=j Pjk)

Antes de tecermos coment´arios sobre a equa¸c˜ao acima, representaremos a ideia de

ﬂuxo probabil´ıstico, atuantes em trˆes estados, por meio de grafos.

pii

i

pij

pji

Figura 2.2

pik

j

pki

pjk

pjj

pkj

k

pkk

Estado i - as ”ﬂechas”que chegam em i s˜ao: tj · Pji e tj · Pki e as ”ﬂechas”que saem

de i s˜ao: ti · Pij e ti · Pik

Estado j - as ”ﬂechas”que chegam em j s˜ao: ti · Pij e tk · Pkj e as ”ﬂechas”que saem

de j s˜ao: tj · Pji e tj · Pjk

Estado k - as ”ﬂechas”que chegam em k s˜ao: tj · Pjk e ti · Pik e as ”ﬂechas”que saem

de k s˜ao: tk · Pkj e tk · Pki

Ent˜ao, aplicando a equa¸c˜ao de ﬂuxo em cada estado, na qual a soma de tudo que

chega a esse estado ´e igual a soma de tudo que sai desse mesmo estado, teremos

54

Estado i
tj·Pji+ tk· Pki = ti· Pij + ti· Pik

Estado j
ti·Pij+tk· Pkj = tj· Pji + tj· Pjk

Estado k
tj·Pjk + ti· Pik = tk· Pkj + tk· Pki

Seguindo o mesmo pensamento, de utilizar o exemplo anterior, determinaremos o vetor

de distribui¸c˜ao de probabilidade de acordo com o Teorema dos Fluxos Probabil´ısticos.

E1 = Futebol
E2 = Cinema
tE1 = elemento do vetor limite de probabilidade referente ao estado 1
tE2 = elemento do vetor limite de probabilidade referente ao estado 2

Figura 2.3

1

2
3

E2

1
3

0

E1

Estado E1: tE1 ·1 = tE2 · 2
3
Estado E2: tE2 · 2
3 = tE1 ·1
Propriedade do vetor probabilidade: tE1 + tE2 = 1
Portanto,



2
3
= tE1 · 1

tE1 · 1 = tE2 ·
2
3

tE2 ·



Calculando, chegaremos a mesma resposta encontrada quando utilizamos os m´etodos

anteriores.

55

Cap´ıtulo 3

Aplica¸c˜oes das Cadeias de Markov

3.1 Modelagem

A modelagem matem´atica no ensino, para Hein (2000), pode ser uma estrada que
desperte o interesse do aluno por t´opicos de matem´atica desconhecidos, fazendo com que
estude situa¸c˜oes-problema por meio da pesquisa, desenvolvendo desse modo o seu interesse.

J´a Bassanezi, deﬁne que,

Modelagem Matem´atica ´e um processo dinˆamico utilizado para a obten¸c˜ao e va-
lida¸c˜ao de modelos matem´aticos. ´E uma forma de abstra¸c˜ao e generaliza¸c˜ao com
a ﬁnalidade de previs˜ao de tendˆencias. A modelagem consiste, essencialmente,
na arte de transformar situa¸c˜oes da realidade em problemas matem´aticos cujas
solu¸c˜oes devem ser interpretadas na linguagem usual. (Bassanezi, 2002, p.24).

As cadeias de Markov s˜ao aplicadas em diversos ramos da ciˆencia, podendo descrever
um modelo matem´atico que interage por meio de sequˆencias de etapas, relata Silva (2015).
Desta forma, estamos prontos para atravessarmos em dire¸c˜ao a uma nova estrada,
passando da teoria para pr´atica, mostrando que n˜ao basta apenas introduzirmos um certo
tema ou assunto matem´atico, mas sim, oferecermos uma continua¸c˜ao aplicada e constru´ıda
no cotidiano e na importˆancia de seus resultados.

Por outro lado, os Parˆametros Curriculares Nacionais – PCN do ensino m´edio (Brasil,
2002 ), sugerem que `a Matem´atica do Ensino M´edio tem a fun¸c˜ao de mostrar ao aluno um
universo de conhecimento atrelado a novas informa¸c˜oes e exibir ferramentas ´uteis para manter
a continuidade do aprendizado.

Logo, est´a na hora de mostrar que a aplicabilidade das cadeias de Markov s˜ao imensas.

Ent˜ao, m˜aos a obra.

56

3.2 Aplica¸c˜oes

3.2.1 Vendas - Lealdade do consumidor

Duas empresas estrangeiras dominam a ind´ustria automobil´ıstica de um certo pa´ıs,
produzindo duas marcas de carros: Fiat e Volkswagen. A cada trˆes anos, o comprador trocar´a
seu carro por um novo. Se uma pessoa compra um Fiat hoje, existem 90% de chances desse
mesmo comprador, ap´os um triˆenio, continuar com a marca Fiat. Agora, se o cliente comprar
um Volkswagen, h´a 80% de possibilidades de quem no pr´oximo triˆenio permane¸ca com a
marca Volkswagen.

a) Passado 6 anos, qual a probabilidade de um comprador que atualmente

tenha um carro da marca Fiat, compre um carro da marca Volkswagen?

Uma solu¸c˜ao:

Primeiramente, vamos avaliar se ´e vi´avel utiliza¸c˜ao de cadeias de Markov.
Veja, que a substitui¸c˜ao do carro se dar´a a cada triˆenio e a decis˜ao de efetuar a troca,
depende exclusivamente do autom´ovel que o comprador possui no triˆenio anterior, portanto,
podemos modelar o problema, utilizando cadeias de Markov, com a existˆencia dos seguintes
estados:

1 - Fiat - F
2 - Volkswagen - V

Agora, colocaremos os dados do problema em uma tabela para melhor visualiza¸c˜ao.

Tabela 3.1

Estado tempo t+1
FIAT VOLKSWAGEN

Estado tempo t

FIAT
VOLKSWAGEN

0,9
0,2

0,1
0,8

Feito isso, podemos ent˜ao elaborar nossa Matriz de Transi¸c˜ao

(cid:34)

(cid:35)

V
F
0, 9 0, 1
0, 2 0, 8

F
V

M =

57

Note que o sistema iniciar´a no estado 1 (carro Fiat). Logo,

(cid:104)

P (0) =

F

V

PF 0 PV 0

(cid:105)

(cid:104)

=

F V
(cid:105)

1 0

Para determinarmos a distribui¸c˜ao de probabilidade ap´os 6 anos (dois triˆenios), deve-

mos calcular P (2), utilizando o Teorema 1.6.2, conforme abaixo:

P (r) = P (0) · M r = P (0) · M 2

(cid:104)

(cid:104)

P (2) =

P (2) =

(cid:34)

(cid:105)

·

1 0

0, 9 0, 1
0, 2 0, 8

(cid:35)2

(cid:104)

=

1 0

(cid:34)

(cid:105)

·

(cid:35)

0, 83 0, 17
0.66
0, 34

F

V

0, 83 0, 17

(cid:105)

Portanto, ap´os 6 anos, h´a 17% de probabilidade de uma pessoa que possui um carro

Fiat, trocar por um outro da marca Volkswagem.

Outra solu¸c˜ao:
Utilizando Grafos e Fluxo Probabil´ıstico

Figura 3.1

0.9

F

0.1

0.2

V

0.8

Observe que, para obtermos p(2), primeiramente, calcularemos o valor de p(1), por
meio da veriﬁca¸c˜ao de quais setas (arestas) chegam em cada estado, logo depois, faremos
o produto da probabilidade de transi¸c˜ao destacada por cada seta pela componente de p(0)
referente a cada estado e assim sucessivamente.

Setas que chegam no Estado F

Figura 3.2

58

0.9

F

V

0.2

(cid:104)

(cid:104)

P (0) =

P (1) =

PF 0 PV 0

PF 1 PV 1

(cid:105)

(cid:105)

(cid:104)

=

1 0

(cid:105)

Calculando PF 1
PF 1 = 0, 9 · PF 0 + 0, 2 · PV 0 = 0, 9 · 1 + 0, 2 · 0 = 0.9

Setas que chegam no Estado V

Figura 3.3

0.1

F

V

0.8

Calculando PV 1
PV 1 = 0, 1 · PF 0 + 0, 8 · PV 0 = 0, 1 · 1 + 0, 8 · 0 = 0, 1
Logo,

(cid:104)

P (1) =

PF 1 PV 1

(cid:105)

(cid:104)

=

0.9 0.1

(cid:105)

59

Calculando PF 2
PF 2 = 0, 9 · PF 1 + 0, 2 · PV 1
PF 2 = 0, 9 · 0, 9 + 0, 2 · 0, 1 = 0, 83

Calculando PV 2
PV 2 = 0, 1 · PF 1 + 0, 8 · PV 1
PV 2 = 0, 1 · 0, 9 + 0, 8 · 0, 1 = 0, 17

Desse modo,

(cid:104)

P (2) =

PF 2 PV 2

(cid:105)

(cid:104)

=

0.83 0.17

(cid:105)

Sendo assim, 17% representa a probabilidade de uma pessoa que possui um carro ﬁat,

trocar por um carro com a marca Volkswagen ap´os seis anos (duas observa¸c˜oes).

b)Se o cliente ´e atualmente dono de um carro Volkswagen, qual a proba-

bilidade dele estar com a mesma marca daqui a 9 anos?

Uma solu¸c˜ao:
Ap´os 9 anos (trˆes triˆenios), devemos calcular P (3).

P (3) = P (0) · M 3

(cid:104)

(cid:104)

(cid:104)

P (3) =

P (3) =

P (3) =

(cid:34)

(cid:34)

(cid:105)

(cid:105)

·

·

0 1

0 1

(cid:35)3

0, 9 0, 1
0, 2 0, 8

(cid:35)

0, 7467 0, 2533
0.4934
0, 5066

F

V

0, 5066 0, 4934

(cid:105)

Logo, passado 9 anos, existem 49,34% de probabilidade de um propriet´ario de carro

marca Volkswagen substituir por outro ve´ıculo da mesma marca.

c) Uma pesquisa mostra que atualmente, entre as pessoas que possuem
carro, 60% s˜ao propriet´arios de um Fiat e 40% donas de um carro Volkswa-
gen. Em 9 anos, qual ser´a a parcela da popula¸c˜ao, que possuindo carro, s˜ao
propriet´arias de um Fiat?

Uma solu¸c˜ao:
Observe que nesse caso, a distribui¸c˜ao de probabilidade inicial indica que o sistema
tem 60% de chances de come¸car no estado Fiat e 40% de iniciar no estado Volkswagen,
enquanto nos itens anteriores, havia a certeza de qual estado iniciar o processo.

60

Usando o Teorema 1.6.2

P (r) = P (0) · M r

P (3) = P (0) · M 3

(cid:104)

(cid:104)

(cid:104)

P (3) =

P (3) =

P (3) =

(cid:34)

(cid:34)

(cid:105)

(cid:105)

·

·

0, 6 0, 4

0, 6 0, 4

(cid:35)3

0, 9 0, 1
0, 2 0, 8

(cid:35)

0, 7059 0, 2941
0.4118
0, 5882

F

V

0, 6588 0, 3412

(cid:105)

Ent˜ao, ap´os 3 triˆenios, 65,88% da popula¸c˜ao possuir´a um carro da marca Fiat.

3.2.2 Sa´ude

A Secretaria de Sa´ude de um certo munic´ıpio, por meio de formul´arios de atendimento
de pacientes, constatou o seguinte: metade da popula¸c˜ao ´e n˜ao fumante; 20% fumam at´e uma
carteira de cigarros e 30% fumam mais de uma carteira.

Foi observado que entre o ano corrente e o ano seguinte, no grupo de pessoas que
consomem at´e uma carteira de cigarros diariamente, existem 10% de chances de passar a
consumir mais de uma carteira e 20% de largar o h´abito de fumar. Tamb´em veriﬁcou-se que
entre os n˜ao fumantes, h´a 10% de probabilidade de que passar˜ao a fumar at´e uma carteira
de cigarros e 10% de fumarem mais de uma carteira. J´a para os que fumam mais de uma
carteira por dia, existem 20% de chances de reduzirem o consumo para uma carteira e 20%
de probabilidade para passar a ser um n˜ao fumante. Ap´os um biˆenio, fa¸ca uma an´alise da
nova distribui¸c˜ao da popula¸c˜ao em grupos de fumantes e n˜ao fumantes.

Uma solu¸c˜ao:

Primeiramente vamos identiﬁcar os estados poss´ıveis da cadeia de Markov.

NF - N˜ao fumantes.
F - Fumam at´e um masso de cigarros.
F+ - Fumam mais de um masso de cigarros.

Indicados os estados, representaremos as probabilidades de transi¸c˜ao por meio de

grafos.

61

F+

0.6

0.7

F

0.2

0.1

Figura 3.4

0.1

NF

0.2

0.1

0.8

0.2

Seguidamente, vamos construir a matriz de transi¸c˜ao.

F NF F+






F
NF
F+

0, 7 0, 2 0, 1
0, 1 0, 8 0, 1
0, 2 0, 2 0, 6






M =

A distribui¸c˜ao de probabilidade inicial ser´a representada pela seguinte matriz linha:

(cid:104)

p(0) =

F NF F+

0, 2 0, 5 0, 3

(cid:105)

E pelo teorema 1.6.2, decorre que,

P (2) = P (0) · M 2

(cid:104)

(cid:104)

(cid:104)

P (2) =

P (2) =

P (2) =

0, 2 0, 5 0, 3

0, 2 0, 5 0, 3











(cid:105)

·

(cid:105)

·

0, 7 0, 2 0, 1
0, 1 0, 8 0, 1
0, 2 0, 2 0, 6

2





0, 53 0, 32 0, 15
0, 17 0, 68 0, 15
0, 28 0, 32 0, 40






0, 275 0, 50 0, 225

(cid:105)

Consequentemente, 50% da popula¸c˜ao continuar´a n˜ao fumando, haver´a aumento no
n´umero de pessoas que fumam at´e uma carteira de cigarros por dia, passando de 20% para
27,5% e uma queda no grupo que fuma mais de um masso de cigarros di´ario, reduzindo de
30% para 21,25%.

3.2.3 Experimento de Comportamento (Adaptado de Lay, 2013)

Um rato ´e colocado no compartimento 2 de um labirinto conforme ﬁgura abaixo.
a) Elabore a matriz de transi¸c˜ao e indique o vetor de probabilidade inicial para o

movimento do camundongo.

b) Qual a probabilidade do camundongo est´a no compartimento 5 ap´os 3 movimentos?

62

Uma solu¸c˜ao:
Compartimento 1

Figura 3.5

Figura 3.6

Note que, o rato, em seu primeiro movimento, tem 3 possibilidades de locomo¸c˜ao:
permanecer no compartimento 1, ir para o 2 ou deslocar-se para o 3. Logo, as probabilidades
de movimenta¸c˜ao do camundongo estando inicialmente no compartimento 1 ´e:

Tabela 3.2

1
1/3

t

1

t+1
3
0

2
1/3

4
1/3

5
0

Procedendo com a mesma ideia para o restante dos compartimentos, estabeleceremos

as seguintes probabilidades des transi¸c˜ao:

Compartimento 2

63

Figura 3.7

Tabela 3.3

1
1/5

2
1/5

t

2

t+1
3
1/5

4
1/5

5
1/5

Compartimento 3

Figura 3.8

Tabela 3.4

1
0

2
1/3

t

3

t+1
3
1/3

4
0

5
1/3

Compartimento 4

64

Compartimento 5

Figura 3.9

Tabela 3.5

1
1/3

t

4

t+1
3
0

2
1/3

4
1/3

5
0

Figura 3.10

Tabela 3.6

1
0

2
1/3

t

5

t+1
3
1/3

4
0

5
1/3

Com os dados das tabelas, podemos elaborar a matriz de transi¸c˜ao.

1

2

3

4

5

65

M =

1
2
3
4
5











1/3 1/3
1/3 1/3
0
1/5 1/5 1/5 1/5 1/5
1/3
0
0
1/3 1/3
1/3
0

1/3 1/3
0
1/3 1/3

0
1/3
0











´E dado, que o camundongo iniciar´a o experimento no compartimento 2, desse modo,

a distribui¸c˜ao de probabilidade inicial ser´a representada pela seguinte matriz linha:

1
(cid:104)
0

2

1

3

0

4

0

5

(cid:105)
0

P (0) =

E pelo Teorema 1.6.2,

P (3) = P (0) · M 3

P (3) =

(cid:104)
0 1 0 0 0

(cid:105)

·

3












1/3 1/3
1/3 1/3
0
1/5 1/5 1/5 1/5 1/5
1/3
0
0
1/3 1/3
1/3
0

1/3 1/3
0
1/3 1/3

0
1/3
0









P (3) =

(cid:104)
0 1 0 0 0

(cid:105)

·











0, 2504 0, 2948 0, 1022 0, 2504 0, 1022
0, 1769 0, 2924 0, 1769 0, 1769 0, 1769
0, 1022 0, 2948 0, 2504 0, 1022 0, 2504
0, 2504 0, 2948 0, 1022 0, 2504 0, 1022
0, 1022 0, 2948 0, 2504 0, 1022 0, 2504











1

2

3

4

5

P (3) =

(cid:105)
(cid:104)
0, 1769 0, 2924 0, 1769 0, 1769 0, 1769

Isto posto, ao iniciar o experimento com o camundongo no compartimento 2, h´a
17,69% de probabilidade de encontrarmos o camundongo no compartimento 5, depois de 3
deslocamentos.

66

3.2.4 Propaga¸c˜ao de Rumor (Adaptado de Sullivan, 2013)

Um projeto de lei, referente a reforma da previdˆencia social, tramita no Congresso
Nacional Brasileiro. Um certo Deputado Federal decidiu se votaria sim ou n˜ao e comentou
com seu assessor. Logo ap´os, o assessor informou a um outro Deputado qual seria a decis˜ao
de seu chefe e este repassou a outro amigo parlamentar, que tamb´em transmitiu a outro
amigo e assim sucessivamente, a informa¸c˜ao ´e repassada para novos deputados.

Deﬁnindo P > 0 e P (cid:54)= 1 como sendo a probabilidade de uma pessoa passar a
informa¸c˜ao de forma ´ıntegra, isto ´e, o que ele ouviu repassar´a a outro. Ent˜ao, qual ser´a a
probabilidade da en´esima pessoa receber a informa¸c˜ao com um voto de n˜ao?

Uma solu¸c˜ao:

Note que, a probabilidade de um parlamentar repassar a mensagem sim ou n˜ao, de-
pende somente da informa¸c˜ao do parlamentar anterior, portanto ´e uma cadeia de Markov,
no qual h´a dois estados poss´ıveis, S (ouvir sim) e N (ouvir n˜ao). A probabilidade de ouvir e
repassar a mesma informa¸c˜ao ´e P, logo, ouvir e repassar o oposto ´e 1-P. Isto ´e, representado
no diagrama abaixo.

Figura 3.11

1-P

1-P

N

P

P

S

Com as probabilidades de transi¸c˜ao entre os estados j´a expostas, formaremos a matriz

de transi¸c˜ao.

S

N

(cid:34)

M =

S
N

P
1 − P

1 − P
P

(cid:35)

Para calcularmos a probabilidade da en´esima pessoa ter ouvido um voto de n˜ao, se
faz necess´ario buscarmos a distribui¸c˜ao limite de probabilidade (probabilidade estacion´aria
ou convergente) e para isso, utilizaremos o teorema 2.1.4.

Seja,

67

S N
(cid:105)

t2

(cid:104)
t1

t =

o vetor de distribui¸c˜ao limite de probabilidade, desse modo, teremos

t · M = t

(cid:34)

(cid:104)

t1

(cid:105)

·

t2

P
1 − P

1 − P
P

(cid:35)

(cid:104)
t1

=

(cid:105)

t2

Logo,

Sendo assim,

(cid:104)
t1 · P + t2 · (1 − P )

t1 · (1 − P ) + t2 · P

(cid:105)

(cid:104)
t1

=

(cid:105)

t2

Portanto,

(cid:40)

t1 · P + t2 · (1 − P ) = t1
t1 · (1 − P ) + t2 · P = t2

Resolvendo qualquer uma das equa¸c˜oes, o resultado ser´a t1 = t2, logo, precisamos de

mais uma equa¸c˜ao para calcularmos a solu¸c˜ao.

N˜ao podemos esquecer, que a matriz linha, representativa do vetor de distribui¸c˜ao
limite de probabilidade (t), possui como propriedade, a soma de seus elementos serem igual
a 1, ou seja, t1 + t2 = 1

Como,

(cid:40)

t2 = t1
t1 + t2 = 1

Conclu´ımos que t1 = t2 = 1/2, isto ´e, depois de um grande n´umero de troca de
informa¸c˜oes, 50% dos parlamentares ouvir´a que o voto do Senador ser´a sim e o restante
ouvir´a n˜ao, independente da opini˜ao inicial do Senador.

68

Outra solu¸c˜ao: utilizando o m´etodo do ﬂuxo probabil´ıstico

Figura 3.12

1-P

1-P

N

P

P

S

Estabelecendo o vetor de distribui¸c˜ao limite de probabilidade, segue que,

S N
(cid:105)

t2

(cid:104)
t1

t =

´E de nosso conhecimento que em uma cadeia de Markov regular, no qual a matriz de
transi¸c˜ao ´e estacion´aria, a soma dos ﬂuxos probabil´ısticos que chegam ao estado ´e igual ao
somat´orio dos ﬂuxos que saem desse mesmo estado (Teorema 2.2.1), melhor dizendo

(cid:80)n

∀i(cid:54)=j ti · Pij = (cid:80)n

∀k(cid:54)=j tj · Pjk

Fluxos que chegam no estado S

Figura 3.13

S

N

1-P

Logo,

(cid:80)n

∀i(cid:54)=j ti · Pij = t2 · (1 − P )

69

Fluxos que saem do estado S

Figura 3.14

1-P

S

N

Assim,

(cid:80)n

∀k(cid:54)=j tj · Pjk = t1 · (1 − P )

Desta forma, igualando os somat´orio dos ﬂuxos que chegam ao estado com a soma dos

ﬂuxos que saem, teremos:

t2 · (1 − P ) = t1 · (1 − P ) ⇔ t2 = t1

E, como j´a ´e de nosso conhecimento, que t1 + t2 = 1, encontramos t1 = t2 = 1/2.
Observa¸c˜ao: O leitor deve notar, que os loops (la¸cos) representados nos grafos, tanto
do estado S quanto do estado N, n˜ao s˜ao considerados no teorema dos ﬂuxos, j´a que, as setas
indicam ao mesmo tempo, uma chegada e uma sa´ıda, anulando desse modo as suas somas.

3.2.5 Teoria Social

Suponha, que uma popula¸c˜ao seja distribu´ıda em trˆes classes sociais: a baixa, a m´edia

e a alta. Levantamentos estat´ısticos determinaram as seguintes probabilidades:

Se uma pessoa pertence a classe baixa, h´a 60% de chances de seus ﬁlhos (1a gera¸c˜ao)
pertencerem tamb´em a classe baixa, 30% de estarem na classe m´edia e 10% de fazerem parte
da classe alta.

Para uma pessoa que faz parte da classe m´edia, as chances de seus ﬁlhos serem da
classe baixa ´e de 40%, 30% de estarem na classe alta e 30% de fazerem parte da mesma classe
que seus pais.

Estando na classe alta, h´a 10% de probabilidade de seus ﬁlhos passarem para a classe

baixa, 40% de estarem na classe m´edia e 50% de pertencerem a classe alta.

Sabendo que as observa¸c˜oes s˜ao realizadas de gera¸c˜ao em gera¸c˜ao, qual a probabilidade
de uma fam´ılia, que se encontra atualmente na classe baixa, ascender para a classe alta, ap´os
duas gera¸c˜oes? E, Quais as probabilidades de distribui¸c˜ao limites de cada estado?

Neste exemplo, planejaremos um ”algoritmo”ou passos a serem seguidos para soluci-

onarmos problemas que podem ser modelados por meio das cadeias de Markov.

1. Veriﬁcar se pode ser modelado por cadeia de Markov (elo entre o atual e o futuro);

70

2. Identiﬁcar os estados;

3. Descrever as probabilidades de transi¸c˜ao;

4. Elaborar a matriz de transi¸c˜ao;

5. Apontar a distribui¸c˜ao de probabilidade inicial ;

6. Calcular a distribui¸c˜ao de probabilidade ap´os r observa¸c˜oes;

7. Veriﬁcar o vetor de distribui¸c˜ao limite de probabilidade.

VAMOS SOLUCIONAR O PROBLEMA, PASSO A PASSO

Veriﬁcar se pode ser modelado por cadeia de Markov

O exemplo mostra que h´a sequˆencia de observa¸c˜oes e uma liga¸c˜ao entre a gera¸c˜ao atual
e a gera¸c˜ao seguinte (propriedade Markoviana), logo, pode ser modelado por uma cadeia de
Markov

Identiﬁcar os estados

B

Figura 3.15

Figura 3.16

M

A

Classe Baixa

Classe M´edia

Classe Alta.

Descrever as probabilidades de transi¸c˜ao

Utilizaremos Grafos para representar as probabilidades de transi¸c˜ao.

71

Figura 3.17

0.1

M

0.1

0.3

0.3

0.4

0.6

B

0.3

0.4

A

0.5

Elaborar a matriz de transi¸c˜ao

Identiﬁcadas todas as probabilidades de transi¸c˜ao, que foram expostas, sejam elas por
meio de grafos, tabelas ou diagrama da ´arvore de probabilidades, construiremos a matriz de
transi¸c˜ao M.

B M A






B
M
A

0, 6 0, 3 0, 1
0, 4 0, 3 0, 3
0, 1 0, 4 0, 5






M =

Apontar a distribui¸c˜ao de probabilidade inicial

Neste caso, o problema indica que o experimento iniciar´a na Classe Baixa, desse modo,

a nossa distribui¸c˜ao de probabilidade inicial ser´a descrita pela matriz linha abaixo.

(cid:104)

p(0) =

B M A

1 0 0

(cid:105)

Calcular a distribui¸c˜ao de probabilidade ap´os r observa¸c˜oes

A primeira pergunta solicita o valor da probabilidade de uma fam´ılia ascender a classe
alta ap´os duas gera¸c˜oes(netos). Note que neste caso, r ´e igual a 2, j´a que o experimento ser´a
observado por duas gera¸c˜oes.

Utilizando o teorema 1.6.2, segue que

72

Temos que

Logo

Desse modo

Portanto

P (r) = P (0) · M r

P (2) = P (0) · M 2

(cid:104)

P (2) =

1 0 0






(cid:105)

·

0, 6 0, 3 0, 1
0, 4 0, 3 0, 3
0, 1 0, 4 0, 5

2





(cid:104)

P (2) =

1 0 0






(cid:105)

·

0, 49 0, 31 0, 20
0, 39 0, 33 0, 28
0, 27 0, 35 0, 38






(cid:104)

p(2) =

B

M A

0, 49 0, 31 0, 20

(cid:105)

Ante o exposto, ap´os duas gera¸c˜oes, a probabilidade de uma fam´ılia que atualmente

se encontra na classe baixa, estar inserida na classe alta ´e de apenas 20%.

Veriﬁcar o vetor de distribui¸c˜ao limite de probabilidade.

Depois de todas as veriﬁca¸c˜oes, partimos para determinar o valor do vetor limite de

probabilidade, e para tanto, utilizaremos o teorema 2.1.5, em que

t · (M − I) = 0

Segue

(cid:104)

t1

t2

t3



(cid:105)

· (




0, 6 0, 3 0, 1
0, 4 0, 3 0, 3
0, 1 0, 4 0, 5






 −




1 0 0
0 1 0
0 0 1



(cid:104)


) =

(cid:105)

0 0 0

73

Logo

(cid:104)

t1

t2

t3






(cid:105)

·

0, 6 − 1 0, 3 − 0 0, 1 − 0
0, 4 − 0 0, 3 − 1 0, 3 − 0
0, 1 − 0 0, 4 − 0 0, 5 − 1



(cid:104)


 =

(cid:105)

0 0 0

Implicando em

(cid:104)

t1

t2

t3






(cid:105)

·

−0, 4
0, 3
0, 4 −0, 7
0, 1

0, 1
0, 3
0, 4 −0, 5



(cid:104)


 =

(cid:105)

0 0 0

Por consequˆencia






t1 · −0, 4 + t2 · 0, 4 + t3 · 0, 1 = 0 (I)
t1 · 0, 3 + t2 · −0, 7 + t3 · 0, 4 = 0 (II)
t1 · 0, 1 + t2 · 0, 3 + t3 · −0, 5 = 0 (III)

Por ﬁm, note que a 3a equa¸c˜ao ´e combina¸c˜ao da soma das outras duas pelo produto
por -1, de outro modo, III = −1 · (I + II). Por isso, utizaremos a propriedade do vetor
probabilidade.






−0, 4 · t1 + 0, 4 · t2 + 0, 1 · t3 = 0
0, 3 · t1 − 0, 7 · t2 + 0, 4 · t3 = 0
t1 + t2 + t3 = 1

Empregando o m´etodo do escalomanento, encontramos os seguintes resultados para

os elementos do vetor limite de probabilidade:

t1 = 0, 3965, t2 = 0, 3276 e t3 = 0, 2759

J´a sabemos que

(cid:104)

t =

B M A

t1

t2

t3

(cid:105)

Portanto, o nosso vetor de distribui¸c˜ao limite de probabilidade ´e

(cid:104)

t =

B

M

A

0, 3965 0, 3276 0, 2759

(cid:105)

Este resultado indica que ap´os um elevado n´umero de observa¸c˜oes, h´a 39,65% de
chances de a cadeia de markov estar no estado classe baixa, 37,26% de se encontrar no
estado classe m´edia e 27,59% de estar no estado classe alta.

74

Considera¸c˜oes ﬁnais

O Trabalho aqui apresentado, tem o prop´osito de mostrar, principalmente, aos
alunos do ensino m´edio, graduandos e professores de matem´atica, as diversas aplica¸c˜oes das
cadeias de Markov no cotidiano. Tamb´em, possui o intuito de expor a bela intera¸c˜ao entre
matrizes, sistemas lineares e probabilidade, almejando desse modo, ampliar as possibilidades
da utiliza¸c˜ao do conhecimento matem´atico de um modo simples e did´atico.

Por v´arias vezes, os exemplos pr´aticos aqui descritos, tiveram como perﬁl, a
utiliza¸c˜ao da modelagem matem´atica para buscar uma melhor comunica¸c˜ao entre teoria e
pr´atica, com o objetivo de fornecer uma perspectiva de ambiente matem´atico mais voltado
para an´alises de resultados, revelando aos alunos, estrat´egias que poder˜ao ser desencadeadas
em problemas que envolvam previs˜oes futuras e tomada de decis˜ao.

Portanto, creio que este tema, nunca abordado no ensino m´edio mas discorrido
neste trabalho, tem a fun¸c˜ao de servir como instrumento contextualizador da realidade, uma
ferramenta com poder de atrair a curiosidade do aluno, de mostrar a matem´atica como uma
ciˆencia amiga que possibilita uma aprendizagem voltada para estabelecer um senso cr´ıtico e
criativo.

75

Referˆencias Bibliogr´aﬁcas

[1] SULLIVAN, M. Finite Mathematics: An Applied Aproach. Chicago State Uni-

versity: John Wiley & Sons, Inc., 2013.

[2] LAY, D. Linear Algebra And Its Applications: Maryland University: Pearson

Education, Inc., 2012.

[3] STEWART, W.J. Probability, Markov Chains, Queues, and Simulation: The
Mathematical Basis of Performance Modeling: Princeton University Press,
2009.

[4] POOLE, D. Linear Algebra: a modern introduction: Trent University: Thom-

son, 2004.

[5] HOWARD, A.; RORRES, C. Algebra Linear com Aplica¸c˜oes:, 8.ed. Porto Ale-

gre: Bookman, 2001.

[6] ROSS, S. A First Course In Probability, 8.ed. University of Southern California:

Pearson Education, Inc., 2010.

[7] GAMERMAN, D. Markov chain Monte Carlo: Stochastic Simulation for Baye-
sian Inference: Texts in Statistical Sciences. London: Chapman and Hall, 1997.

[8] GORDON, P. Cadenas Finitas de Markov y Sus Aplicaciones: Barcelona: His-

pano Europea, 1967.

[9] CARREIRA, A.; PINTO, G.; SOUSA, B.C´alculo da Probabilidade. Lisboa:

Instituto Piaget, 2002.

[10] PUGACHEV, V. Introducci´on a la Teoria de las Probabilidades: Moscol: MIR,

1973.

[11] NETO, A. C. M. T´opicos de Matem´atica Elementar: Introdu¸c˜ao `a An´alise, v.3.

Rio de Janeiro: SBM, 2012.

76

[12] BOYER, C.; MERZBACH, U.Hist´oria da Matem´atica.S˜ao Paulo: Blucher,

2015.

[13] LINTZ, R. Hist´oria da Matem´atica. v.1, Blumenau: FURB, 1999.

[14] LIPSCHUTZ, S. Teoria e Problemas de Probabilidade. Cole¸c˜ao Shaum, Rio de

Janeiro: Mcgraw-Hill do Brasil, 1974.

[15] ROJO, H.; MIRANDA, M. Cadenas de Markov: Investiga¸ci´on Operativa. Uni-

versidade de Buenos Aires, 2009.

[16] GADELHA, A. Notas de Aula Teoria de Probabilidade I: Curso de P´os-

Gradua¸c˜ao em Estat´ıstica, Rio de janeiro: UFRJ, 2004.

[17] SILVA, C. Aplica¸c˜oes da Algebra Linear nas Cadeias de Markov: Goiˆania:

PROFMAT, 2013.

[18] J ´UNIOR, G. Cadeias de Markov: Uma Proposta de Ensino e Aprendizagem:

Vit´oria da Conquista: PROFMAT, 2014.

[19] J ´UNIOR, F. Matrizes: Cole¸c˜ao Shaum, Rio de Janeiro: Mcgraw-Hill do Brasil,

1971.

[20] BIEMBENGUT, M. Modelagem Matem´atica no Ensino: S˜ao Paulo: Contexto,

2009.

[21] BASSANEZZI, R. Modelagem Matem´atica, Teoria e Pr´atica: S˜ao Paulo: Con-

texto, 2015.

[22] BASSANEZZI, R. Ensino - Aprendizagem com Modelagem Matem´atica: Cam-

pinas: Contexto, 2015.

[23] BRASIL. Minist´erio da Educa¸c˜ao. Secretaria da Educa¸c˜ao M´edia e Tecnol´ogica.
Parˆametros Curriculares Nacionais + (PCN+) - Ciˆencias da Natureza e suas
Tecnologias. Bras´ılia: MEC, 2002.

[24] KOOTWITZ, S. Latex Cookbook: Birmingham: Packt, 2015.

77

Apˆendice A

Uso do Microsoft Excel para
multiplica¸c˜ao de matrizes

Escrever esta parte do trabalho tem o objetivo de explicar sucintamente, a fun¸c˜ao
MATRIZ.MULT do Microsoft Excel, um poderoso editor de planilhas, desenhado para com-
putadores que utilizam a plataforma Windows.

A fun¸c˜ao MATRIZ.MULT tem a ﬁnalidade de efetuar a multiplica¸c˜ao de duas matri-
zes, em que o n´umero de colunas da primeira matriz ´e igual ao n´umero de linhas da segunda
matriz. O resultado ´e uma matriz com o mesmo n´umero de linhas da primeira matriz e igual
n´umero de colunas da segunda matriz.

Para melhor entendimento, tome a seguinte matriz M do exemplo 5.

B M A

M =






B
M
A

0, 6 0, 3 0, 1
0, 4 0, 3 0, 3
0, 1 0, 4 0, 5






Ao calcular M 2, obtemos,

B M A

M =






B
M
A

0, 49 0, 31 0, 20
0, 39 0, 33 0, 28
0, 27 0, 35 0, 38






Agora, utilizando a fun¸c˜ao MATRIZ.MULT, vamos calcular novamente M 2, para isso,

veja a sequˆencia de ﬁguras abaixo.

78

Figura A.1

Veja que a matriz M ´e de ordem 3, ao efetuarmos a multiplica¸c˜ao M · M , seguimos a
regra fundamental da existˆencia do produto entre duas matrizes, no qual o n´umero de colunas
da primeira matriz deve ser igual ao n´umero de linhas da segunda matriz. Logo, obteremos
como resultado, uma matriz tamb´em de ordem 3. Assim, necessitamos de 9 c´elulas para
receber os elementos da matriz M 2, conforme representado na ﬁgura 1.

J´a na ﬁgura 2, efetivada a sele¸c˜ao das c´elulas necess´arias, introduziremos na c´elula

D10, a fun¸c˜ao MATRIZ.MULT, que tem a seguinte sintaxe:

MATRIZ.MULT(matriz1;matriz2), em que a matriz1 e a matriz2 indicam as matrizes

que ser˜ao multiplicadas.

79

Figura A.2

Neste momento, muitos usu´arios apertar˜ao a tecla enter, esperando que os 9 elementos
da matriz M 2 sejam indicados. Por´em, para nosso espanto, apenas surgir´a o valor da c´elula
D10 (primeira elemento da matriz M 2).

Para evitar esse desconforto, devemos pressionar simultaneamente as teclas CTRL +

SHIFT + ENTER, conforme ﬁgura abaixo.

Figura A.3

Assim sendo, a ﬁgura 4, nos mostra o resultado esperado.

80

Figura A.4

81

Apˆendice B

Pr´e-Requisitos

´E de fundamental importˆancia relembrarmos alguns t´opicos matem´aticos com o intuito
de alicer¸carmos com clareza, objetividade e eﬁc´acia, a constru¸c˜ao da teoria e utiliza¸c˜ao das
aplica¸c˜oes referente as cadeias de Markov regulares. Assim, este apˆendice se prender´a, t˜ao
somente, a mostrar conte´udos que s˜ao abordados nesta disserta¸c˜ao, evitando desse modo, o
emprego ou manuseio de demonstra¸c˜oes. Portanto, qualquer necessidade de aprofundamento
por parte do leitor, o mesmo poder´a utilizar as dicas da referˆencias bibliogr´aﬁcas.

B.1 Matrizes

Deﬁni¸c˜ao B.1.1. Matriz ´e um ordenamento retangular de elementos que podem ser vetores,
n´umeros, fun¸c˜oes, polinˆomios, etc., dispostos em linhas e colunas.











2 5 1
0 1 1
3 0 5

Note que a matriz acima possui 3 linhas (ﬁlas horizontais) e 3 colunas (ﬁlas verticais).









4
0
−2
√
1
π
2
7
0
8
1 −3 2
3









J´a este exemplo, nos mostra uma matriz com 4 linhas e 3 colunas. Observe que os

seguintes formatos ( ) e [ ] podem ser utilizados como a representa¸c˜ao de uma matriz.

82

B.1.1 Nota¸c˜ao Geral

Cada elemento da matriz ´e representado pela forma:

aij

a - simboliza o elemento da matriz.
i - representa a linha onde se encontra o elemento.
j - representa a coluna onde se localiza o elemento.

Para indicar uma matriz, usamos as letras mai´usculas, j´a os elementos com seus

sub´ındices, utilizamos as letras min´usculas.

M =












p11
...
...
...
pm1

. . .
. . .
. . .
. . .
· · ·

p1j
...
...
...
pmj

. . .
. . .
. . .
. . .
· · ·












p1n
...
...
...
pmn

M - representa uma matriz.
m - representa o n´umero de linhas, com m ∈ N∗.
n - representa o n´umero de colunas, com n ∈ N∗.
p - representa¸c˜ao do elemento da matriz.
i - representa a linha onde se localiza o elemento com i= 1,2,3.....m.
j - representa a coluna onde se localiza o elemento com j= 1,2,3.....n.

Podemos retratar uma matriz do seguinte modo:

M =

(cid:16)

pij

(cid:17)

m×n

ou

M =

(cid:105)

(cid:104)

pij

m×n

A representa¸c˜ao m × n identiﬁca a ordem de uma matriz.

B.1.2 Matriz Quadrada

Deﬁni¸c˜ao B.1.2. A toda matriz que possui o n´umero de linhas, iguais ao n´umero de colunas,
ou seja, de ordem m × m, denominamos de Matriz Quadrada

EXEMPLO 13.

83

M =












p11
...
...
...
pm1

. . . p1j
...
. . .
...
. . .
...
. . .
pnj
· · ·

. . .
. . .
. . .
. . .
· · ·












p1m
...
...
...
pmm

Diagonal principal

Deﬁni¸c˜ao B.1.3. Ao conjunto de todos os elementos aij de uma matriz quadrada de ordem
n, no qual i=j, chamamos de diagonal principal.

EXEMPLO 14.

X =











2 5 1
0 1 1
3 0 5

Os elementos a11= 2, a22= 1, e a33= 5, formam a diagonal principal da Matriz X.

B.1.3 Matriz Identidade

Deﬁni¸c˜ao B.1.4. A qualquer matriz quadrada que possua todos os elementos da diagonal
principal igual a 1 e o restante de seus elementos nulos, denominamos de Matriz identidade.

EXEMPLO 15.

M =












1 . . .
...
1
...
. . .
...
. . .
0 . . .

0
...
. . .
...
0












. . . 0
...
. . .
...
. . .
...
1
. . . 1

84

Portanto,

Para i=j, aij = 1; e quando i(cid:54)= j, aij = 0.
A matriz identidade pode ser simbolizada por In, onde n representa a ordem da matriz

quadrada.

EXEMPLO 16.

B.1.4 Matriz Linha

I3 =











1 0 0
0 1 0
0 0 1

Deﬁni¸c˜ao B.1.5. Chamamos de matriz linha, matriz ﬁla ou vetor linha, a qualquer matriz
que possua apenas uma linha.

(cid:16)

(cid:17)

M =

pij

1×n

EXEMPLO 17.

(cid:104) √

M =

5 . . . 5 . . . π

(cid:105)

B.1.5 Matriz Nula ou Elemento Neutro

Deﬁni¸c˜ao B.1.6. A qualquer matriz que possua todos os seus elementos iguais a zero, cha-
maremos de matriz nula, ou seja, ∀ aij = 0;

EXEMPLO 18.

M =












0 . . .
...
0
...
. . .
...
. . .
0 . . .

0
...
. . .
...
0












. . . 0
...
. . .
...
. . .
...
0
. . . 0

A matriz nula pode ser denotada por Om×n

EXEMPLO 19.

O3×5 =






0 0 0 0 0
0 0 0 0 0
0 0 0 0 0






B.1.6 Matriz Triangular Superior

Deﬁni¸c˜ao B.1.7. Qualquer matriz quadrada onde todos os elementos localizados abaixo da
diagonal principal s˜ao nulos, denominamos de Matriz Triangular Superior, melhor dizendo,
aij=0, para qualquer i > j.

85

EXEMPLO 20.

M =











2 5 1
0 1 1
0 0 5

B.1.7 Matriz Oposta

Deﬁni¸c˜ao B.1.8. Seja a Matriz M =

(cid:16)

pij

(cid:17)

matriz - M que tem a seguinte propriedade: M + (−M ) = Om×n.

, demonimamos Matriz Oposta de M, a

m×n

EXEMPLO 21.

Seja a matriz X =











2 5 1
0 1 1
3 0 5

Ent˜ao: −X =






−2 −5 −1
0 −1 −1
0 −5
−3






Logo:






2 5 1
0 1 1
3 0 5






 +




−2 −5 −1
0 −1 −1
0 −5
−3






 =









0 0 0
0 0 0
0 0 0

B.1.8 Matriz Inversa

Deﬁni¸c˜ao B.1.9. Sejam M e X matrizes quadradas de ordem n. Se M · X = X · M = In,
ent˜ao, denominamos de X de inversa de M. X pode ser representado por M −1.

86

EXEMPLO 22.

Seja a matriz M =

(cid:35)

(cid:34)

3
0
0 −5

e X =

(cid:35)

(cid:34) 1
0
3
0 −1
5

Segue que:

(cid:34)

3
0
0 −5

(cid:35)

(cid:34) 1
0
3
0 −1
5

·

(cid:35)

(cid:34)

=

1 0
0 1

(cid:34) 1
0
3
0 −1
5

(cid:35)

(cid:34)

·

3
0
0 −5

(cid:35)

(cid:34)

=

1 0
0 1

(cid:35)

(cid:35)

Desse modo, como M · X = X · M = In, implica que X = M −1, ou seja, X ´e a matriz

inversa de M.

B.1.9

Igualdade de Matrizes

Duas matrizes s˜ao consideradas iguais, se s˜ao de mesma ordem e se os elementos da

mesma posi¸c˜ao s˜ao iguais, isto ´e, sejam as matrizes:
(cid:16)

(cid:17)

(cid:16)

M=

pij

e P =

m×n

aij

(cid:17)

m×n

Ent˜ao: M ser´a igual a P, se e somente se pij = aij para i= 1,2,3.....m e j= 1,2,3.....m .

EXEMPLO 23.






2 5 1
0 1 1
3 0 5






 e









2 5 1
0 1 1
3 0 5

B.1.10 Opera¸c˜oes com Matrizes

Adi¸c˜ao de matrizes

Dadas dua matrizes de mesma ordem, M =

(cid:16)

chamamos de soma das matrizes, a matriz K =
´ındice i e j.

(cid:16)

kij

(cid:17)

m

× n e P =

(cid:16)

aij

(cid:17)

m

× n,

× n, tal que: kij = pij + aij, ∀

pij
(cid:17)

m

Logo, podemos denotar a adi¸c˜ao das matrizes acima como K= M + P

87

EXEMPLO 24.






2 5 1
0 1 1
3 3 5






 +




√

7 0
1
−2
4
1
4 −3 π






 =




√
7

5 +
2
0

3
−2
7






1
5
5 + π

Propriedades da adi¸c˜ao de matrizes

Sejam as matrizes de mesma ordem, M=

(cid:16)

pij

(cid:17)

m×n

(cid:16)

, P=

aij

(cid:17)

m×n

(cid:16)

e K=

kij

(cid:17)

m×n

Ent˜ao teremos as seguintes propriedades:

1. A adi¸c˜ao ´e Comutativa: M + P = P + M

2. A adi¸c˜ao ´e Associativa: M + (P + k) = (M + P) + K

3. H´a o Elemento neutro ”Om×n”na adi¸c˜ao: M = M + Om×n = Om×n + M = M

Subtra¸c˜ao de matrizes

Dadas dua matrizes de mesma ordem, M =
(cid:17)

(cid:16)

de subtra¸c˜ao das matrizes, a matriz K =

kij

m×n

(cid:16)

pij

(cid:17)

m×n

e P =

(cid:16)

aij

(cid:17)

m×n

, chamamos

, tal que: kij = pij − aij, ∀ ´ındice i e j.

Indicaremos a subtra¸c˜ao das matrizes acima como K= M - P

EXEMPLO 25.






2 5 1
0 1 1
3 3 5






 −




√

7 0
1
4
1
−2
4 −3 π






 =




7

√

5 −
0
6

1
2
−1






1
−3
5 − π

Propriedades da subtra¸c˜ao de matrizes

Sejam as matrizes de mesma ordem, M =

(cid:16)

pij

(cid:17)

m×n

e P =

(cid:16)

aij

(cid:17)

m×n

Toda subtra¸c˜ao de matrizes pode ser transformada em uma adi¸c˜ao, j´a que M − P =

M + (−P ), onde -P ´e a matriz oposta de P.

Portanto, a diferen¸ca de matrizes ao ser transformanda em uma soma, carregar con-

sigo, todas as propriedades da adi¸c˜ao de matrizes, na qual mostramos anteriormente.

Produto de matrizes

88

Sejam M e P duas matrizes que tenham a seguinte caracter´ıstica: o n´umero de colunas
e

de M seja igual ao n´umero de linhas de P, nesta ordem, isto ´e, se M =

(cid:16)

(cid:17)

(cid:16)

(cid:17)

ajq

, chamamos de produto de matrizes, a matriz K =

P =
, tal que: kiq
indica o elemento que ´e resultado do produto da ﬁla i da primeira matriz pela coluna q da
segunda matriz.

kiq

m×s

n×s

pij

m×n

(cid:16)

(cid:17)

(cid:16)

(cid:17)

kiq

, onde kiq = (cid:80)n

j=1 pij · ajq

m×s

Portanto, se K = M · P , segue que K =

EXEMPLO 26.



Sejam X =




2 5 1
0 1 1
3 3 5




 e Y =











1
−2
−1

Vamos calcular X · Y:

X · Y =






2 5 1
0 1 1
3 3 5






 ·




1
−2
−1






 =




2·1 + 5· − 2 + 1· − 1
5·1 + 1· − 2 + 3· − 1
3·1 + 3· − 2 + 5· − 1






 =









−9
0
−8

Propriedades do produto de matrizes

As propriedades que interessam a este trabalho s˜ao:

1. A multiplica¸c˜ao ´e Associativa: M ·(P + k) = (M + P)·K.

2. H´a o Elemento neutro ”I”na multiplica¸c˜ao: M = M ·I = I ·M = M, onde I ´e a matriz

identidade de ordem n e M uma matriz quadrada tamb´em de ordem n.

3. O Produto n˜ao garante a comutatividade: M · P (cid:54)= P · M .

B.2 Equa¸c˜oes Lineares

Ao entrarmos nesse assunto, adequamos a representa¸c˜ao usual de uma equa¸c˜ao li-
near no sentido de propiciar uma melhor vis˜ao para o leitor, da nomenclatura utilizada nas
resolu¸c˜oes de equa¸c˜oes, relacionadas as aplica¸c˜oes da cadeia de Markov.

89

Deﬁni¸c˜ao B.2.1. Denominaremos de Equa¸c˜ao Linear, a qualquer equa¸c˜ao que pode ser
representada na forma:

p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11

Onde:

1. p11, p21 .... pn1 s˜ao n´umeros reais denominados de coeﬁcentes da equa¸c˜ao;

2. t11, t12 ..... t1n s˜ao chamadas de incognitas da equa¸c˜ao;e

3. q11 ´e o termo independente.

EXEMPLO 27.

√

√

3x +

2y = 1

5t + 3p − 2z = 4 e 2
5, 2, -2, 2
3 e
t, p, z, x e y s˜ao as inc´ognitas;e
4 e 1 s˜ao os termos independentes.

2 s˜ao os coeﬁcientes;

Solu¸c˜ao de uma equa¸c˜ao linear

Uma equa¸c˜ao linear tem solu¸c˜ao se e somente se a seguinte senten¸ca for verdadeira:

p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11

EXEMPLO 28.

5t + 3p - 2z = 4, ser´a verdadeira para a seguinte sequˆencia:
t=2, p=2 z=6, ou seja, (2,2,6).

B.3 Sistemas Lineares

Deﬁni¸c˜ao B.3.1. Ao depararmos com uma cole¸c˜ao ou conjunto com mais de uma equa¸c˜ao
linear, denominaremos de sistema linear.

EXEMPLO 29.






p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11
p12 · t11 + p22 · t12 + · · · + pn2 · t1n = q12
p13 · t11 + p23 · t12 + · · · + pn3 · t1n = q13

90

Agora, faremos uma sec¸c˜ao neste t´opico, na dire¸c˜ao de trabalharmos somente com

sistemas lineares onde o n´umero de equa¸c˜oes ´e igual ao n´umero de inc´ognitas.

Seja uma matriz M de ordem n×n e uma matriz linha T, de ordem 1×n. chamaremos

de K a matriz que corresponde a seguinte equa¸c˜ao matricial.

(cid:104)

t11

. . .

t1j

. . .

t1n

(cid:105)

·

T · M = K












p11
...
...
...
pn1

. . . p1j
...
. . .
...
. . .
...
. . .
pnj
· · ·












. . . p1n
...
. . .
...
. . .
...
. . .
pnn
· · ·

(cid:104)

=

q11

. . . q1j

. . . q1n

(cid:105)

Utilizando as regras do produto e igualdade de matrizes, obtemos o seguinte sistema

de equa¸c˜oes lineares com n equa¸c˜oes e n vari´aveis:






p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1j · t11 + p2j · t12 + · · · + pnj · t1n = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1n · t11 + p2n · t12 + · · · + pnn · t1n = q1n

Seja T’uma matriz coluna com os mesmos elementos da matriz linha T. Note que
podemos obter o mesmo sistema acima, bastando para isso efetuarmos o seguinte produto:

M · T (cid:48) = P

Observe:












p11
...
...
...
pn1

. . . p1j
...
. . .
...
. . .
...
. . .
pnj
· · ·

. . . p1n
...
. . .
...
. . .
...
. . .
pnn
· · ·






















·











t11
. . .
t1j
. . .
t1n

=





















q11
. . .
q1j
. . .
q1n

Por escolha deste autor, utilizaremos em nosso trabalho, o produto de uma matriz
linha de ordem 1 × n por uma matriz quadrada de ordem n × n ao inv´es da multiplica¸c˜ao de
uma matriz quadrada de ordem n × n por uma matriz coluna de ordem n × 1.

91

B.3.1 Solu¸c˜ao de Sistemas de Equa¸c˜oes Lineares

Existem v´arios m´etodos e artif´ıcios para obtermos as solu¸c˜oes de uma sistema de
equa¸c˜oes lineares, por´em, utilizaremos apenas o processo denominado de escalonamento,
ﬁcando a crit´erio do leitor o uso de outros recursos.

Transforma¸c˜oes elementares

Deﬁni¸c˜ao B.3.2. S˜ao opera¸c˜oes elementares (troca de posi¸c˜ao, soma e multiplica¸c˜ao) que
transformam um certo sistema de equa¸c˜oes lineares em outro equivalente.

Vamos ent˜ao enumer´a-las:

1. troca de posi¸c˜ao de duas ou mais equa¸c˜oes

EXEMPLO 30.











p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1j · t11 + p2j · t12 + · · · + pnj · t1n = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1n · t11 + p2n · t12 + · · · + pnn · t1n = q1n

(cid:109)

p1n · t11 + p2n · t12 + · · · + pnn · t1n = q1n
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1j · t11 + p2j · t12 + · · · + pnj · t1n = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11

Nesse caso foram trocadas de posic˜ao entre si, as linhas 1 e en´esima (L1 e Ln).

2. multiplica¸c˜ao

Ao multiplicarmos uma ou mais equa¸c˜oes por um n´umero real qualquer, diferente de
zero, tamb´em chegaremos a um outro sistema equivalente.

EXEMPLO 31.

92






p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1j · t11 + p2j · t12 + · · · + pnj · t1n = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
p1n · t11 + p2n · t12 + · · · + pnn · t1n = q1n

(cid:109)






p11 · t11 + p21 · t12 + · · · + pn1 · t1n = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
3 · p1j · t11 + 3 · p2j · t12 + · · · + 3 · pnj · t1n = 3 · q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
2 · p1n · t11 + 2 · p2n · t12 + · · · + 2 · pnn · t1n = 2 · q1n

A ej´esima e en´esima linha foram multiplicadas por 3 e 2 respectivamente (3·Lj e 2·Ln).

3. multiplica¸c˜ao e soma

Obtemos um sistema equivalente ao somarmos uma equa¸c˜ao a outra j´a obtida do pro-
duto pelo n´umero real qualquer diferente de zero.

EXEMPLO 32.






t11 · p11 + t12 · p21 + · · · + t1n · pn1 = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
t11 · p1j + t12 · p2j + · · · + t(1n · pnj = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
t11 · p1n + t12 · p2n + · · · + t1n · pnn = q1n

(cid:109)






t11 · p11 + t12 · p21 + · · · + t1n · pn1 = q11
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
t11 · p1j + t12 · p2j + · · · + t(1n · pnj = q1j
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
t11 · (2 · p11 + p1n) + t12 · (2 · p21 + p2n) + · · · + t1n · (2 · pn1 + pnn) = 2 · q11 + q1n

O exemplo indica que a primeira linha foi multiplicada por 2 e somada a en´esima linha

(2 · L1 + Ln).

93

Escalonamento

Deﬁni¸c˜ao B.3.3. Dizemos que um sistema linear de equa¸c˜oes est´a escalonado quando:

1. O primeiro elemento n˜ao nulo de cada linha ´e igual a 1 (recebe o nome de pivˆo);
2. O pivˆo da linha subsequente se localiza sempre a direita do pivˆo da linha anterior;
3. As colunas que representam cada vari´avel do sistema( X, Y, Z ...) e que cont´em

um pivˆo, ter˜ao o restante dos seus elementos iguais a 0.

Considere o seguinte sistema:






X + Y + Z = 0
2X + Y − Z = 7
3X + 2Y + 2Z = 1

Vamos utilizar as opera¸c˜oes elementares com ﬁns de escalonar o sistema de equa¸c˜oes

acima.

Resolu¸c˜ao:
A 1a linha possui todas as incognitas e um pivˆo, assim, passaremos a tentar eliminar
a incognita X da 2a equa¸c˜ao e incluir um pivˆo. Para isso, multiplicaremos a linha 1 por 2 e
subtraremos `a 2a equa¸c˜ao (2L1 - L2).

Obtemos o seguinte sistema equivalente:






X + Y + Z = 0
Y + 3Z = −7
3X + 2Y + 2Z = 1

Passaremos nesse pr´oximo passo, a tentar eliminar as inc´ognitas X e Y da 3a equa¸c˜ao
e inserir um pivˆo para inc´ognita Z. Efetuando o produto da 1a equa¸c˜ao por -3 e somando a
3a equa¸c˜ao, obtem-se:






X + Y + Z = 0
Y + 3Z = −7
−Y − Z = 1

Pr´oximo estamos de escalonar todo sistema. Falta ainda eliminarmos a inc´ognita Y da
3a equa¸c˜ao e incluir o pivˆo para Z. Somando a 2a equa¸c˜ao com a 3a e depois multiplicarmos
o resultado por −1

2 , visualizaremos:






X + Y + Z = 0
Y + 3Z = −7
Z = −3

94

Pronto, o nosso sistema j´a est´a escalonado. Basta ent˜ao, resolvermos as equa¸c˜oes,

partindo da mais simples para a mais complexa.

Como Z= -3, temos que:
-Y-3Z=7, implica em Y=2.
E resolvendo a 1a equa¸c˜ao, X+Y+Z=0, enontramos X=1.
Assim, a solu¸c˜ao para o sistema ´e o seguinte terno:
(1,2,-3).

B.4 Probabilidade

Nos tempos atuais, dominar as deﬁni¸c˜oes e m´etodos do estudo da probabilidade tem
sido de vital importˆancia tanto para matem´aticos quanto para estudiosos de outras ´areas
do conhecimento. Quando necessitamos veriﬁcar ou analisar situa¸c˜oes buscando uma maior
clareza ou tomar decis˜oes que possam prever um resultado futuro, tomamos m˜ao da proba-
bilidade.

Desse modo, apresentaremos a seguir as suas principais deﬁni¸c˜oes e propriedades.

Deﬁni¸c˜ao B.4.1. Suponha que sejam realizados M testes aleat´orios, todos nos mesmos mol-
des e independentes. Se aumentarmos o n´umero de testes de tal modo que M se torne grande
e ao veriﬁcarmos que m desses testes representam o n´umero de ocorrˆencias de um certo
evento A, ent˜ao segue que a probabilidade de ocorrer o evento A ´e dado por:

P(A)= n(A)
n(S)

Onde:
A = Ocorrer o evento A.
P(A) = Probabilidade de ocorrer o evento A.
n(A) = m = N´umero de casos(testes) que ocorreram o evento A.
n(S) = M= N´umero total de casos (testes) ou espa¸co amostral.

95

EXEMPLO 33.

Suponha que uma moeda honesta seja lan¸cada 3 vezes para cima e considere o evento

A, como sendo a obten¸c˜ao de duas coroas em trˆes lan¸camentos.

Calcule a probabilidade de ocorrer o evento A.
Vejamos primeiramente, todas as possibilidades existentes na experiˆencia, ou seja,

vamos deﬁnir o espa¸co amostral S, sendo K = cara e C = coroa.

S = (k,k,k), (k,k,c), (k,c,c), (c,c,c), (c,c,k), (c,k,k), (c,k,c) e (k,c,k).
Assim, o n´umero total de elementos do espa¸co amostral n(S)= 8.
Agora, vamos veriﬁcar quais as ocorrˆencias do espa¸co amostral mostram a obten¸c˜ao

de duas coroas.

Seja n(A) o n´umero de casos favor´aveis, isto ´e, (c,c,k), (c,k,c), (k,c,c), implicando que

n(A) = 3

Portanto, pela deﬁni¸c˜ao acima, temos que P (A) = n(A)

n(S) = 3

8

B.4.1 Axiomas

Vamos supor a existˆencia de um experimento no qual veriﬁca-se o seguinte conjunto
de observa¸c˜oes: E = {E1, E2....Em}. Sabemos que o n´umero de subconjuntos de E ´e igual a
2m. Seja F o conjunto contendo todos esses subconjuntos que representam todos os poss´ıveis
acontecimentos, isto ´e, F = {F1, F2....F2m}. Ent˜ao, para qualquer Fi, com i = 1, 2, ....2m,
associaremos um n´umero real P (F1) ao qual denominaremos de probabilidade de veriﬁcarmos
o acontecimento F1 e que veriﬁca os seguintes axiomas:

1. 0 ≤ P (F1) ≤ 1, com i = 1, 2, ....2m.

2. Sejam Fi, Fj,...Fn uma sequˆencia de acontecimentos disjuntos ou multuamente exclu-

sivos, ent˜ao, temos que P (Fi ∪ Fj ∪ . . . ∪ Fn) = P (Fi) + P (Fj) + . . . + ∪(Fn)

3. P (E) = 1.

B.4.2 Espa¸cos de probabilidade

Deﬁni¸c˜ao B.4.2. Seja E = {E1, E2....Em} um espa¸co amostral ﬁnito. Denominamos de
Espa¸cos ﬁnitos de probabilidade, a cada associa¸c˜ao de Ei ∈ E a um n´umero real P (Ei) que
implicam nas seguintes propriedades:

1. (cid:80)m

i=1 P (Ei) = 1 , com i=1,2,3,.......m.

2. P (Ei) ≥ 0.

Utilizando o exemplo anterior, referente ao lan¸camento de uma moeda por trˆes vezes,

vamos veriﬁcar qual a probabilidade de obtermos ao menos uma cara.

Resolu¸c˜ao:
J´a sabemos que pela propriedade 2, todos os P (Ei) devem ser positivos. Ent˜ao,

96

E1 - Evento n˜ao obter cara = {(c,c,c)}
P1 - probabilidade de n˜ao se obter cara = 1
8

E2 - Evento obter uma cara = {(c,c,k)},{(c,k,c)}, {(k,c,c)}
P2 - probabilidade de se obter uma cara = 3
8

E3 - evento obter duas caras= {(c,k,k)},{(k,k,c)}, {(k,c,k)}
P3 - probabilidade de se obter duas caras = 3
8

E4 - evento obter trˆes caras{(k,k,k)}
P4 - probabilidade de se obter trˆes caras = 1
8

Assim, nosso espa¸co amostral ´e representado pelo seguinte conjunto:
E={E2, E3, E4}
Ao efetuar a soma de todas as probabilidades do espa¸co amostral do conjunto E,

chegaremos a:

(cid:80)4

i=2 P(Ei) = P(E2)+P(E3)+P(E4)= 3

8 + 3

8 + 1

8 = 7
8.

B.4.3 Probabilidade condicional

Deﬁni¸c˜ao B.4.3. Sejam A e B enventos onde P(B) (cid:54)= 0. Chamamos de probabilidade con-
dicional de A dado B por meio da seguinte representa¸c˜ao:

P(A/B) = P (A∩B)
P (B)

Ou seja, a probabilidade de ocorrer um evento A est´a condicionada a um evento B j´a

acontecido.

EXEMPLO 34.

Suponha que dois dados honestos sejam lan¸cados. Se a soma das faces voltadas para

cima totalizam seis, qual a probabilidade de ter ocorrido a face 4 em um dos dados?

97

Resolu¸c˜ao:

Seja os eventos:
A = a soma das faces voltadas para cima ´e igual a 6
B = a face com o n´umero 4 ocorre em pelo menos um dos dados.

Assim, A = {(1,5), (5,1), (2,4), (4,2), (3,3)}
e n(A)= 5.

J´a sabemos que a soma das faces ´e seis, por´em precisamos somente dos elementos de

A que possuam a face 4.

Ou seja,
P (A ∩ B) = {(2, 4), (4, 2)}

Logo, P (B/A) = P (B∩A)
P (A)

P (B/A) = 2
5.

A deﬁni¸c˜ao de probabilidade condicional implica no princ´ıpio de multiplica¸c˜ao das

probabilidades:

P (A ∩ B) = P (B) · P (A/B) = P (A) · P (B/A)

De outro modo, pode-se dizer que: A probabilidade de ocorrer dois eventos ´e igual a
probabilidade de um deles multiplicado pela probabilidade condicional do outro evento em
rela¸c˜ao ao primeiro.

Se P (A/B) (cid:54)= P (A), ent˜ao dizemos que os eventos A e B s˜ao dependentes e se

P (A/B) = P (A), ent˜ao teremos eventos independentes.

EXEMPLO 35.

Em uma caixa encontram-se 4 bolas vermelhas e 3 bolas azuis. Ser´a extraido uma
bola de cada vez e colocada novamente na caixa (com reposi¸c˜ao). Qual a probabilidade de
se obter duas bolas vermelhas nas duas primeiras retiradas.

Sejam os eventos:
A - retirar uma bola vermelha na primeira tentativa.
B - retirar uma bola vermelha na segunda tentativa.

98

Logo,
P (A) = 4

7 e P (B) = 4

7

Pelo princ´ıpio de multiplica¸c˜ao das probabilidades, temos:

P (A ∩ B) = P (A) · P (B/A) = 4

7· 4

7 = 16

49

EXEMPLO 36.

Suponha que agora, as bolas retiradas n˜ao sofrer˜ao reposi¸c˜ao. Ent˜ao, qual a probabi-

lidade de se obter novamente duas bolas vermelhas em duas retiradas?

Deﬁnimos os eventos

A - retirar uma bola vermelha na primeira tentativa.
B - retirar uma bola vermleha na segunda tentativa.

Ent˜ao,

P (A) = 4

7 e P (B) = 3

6 = 1

2

E pelo princ´ıpio de multiplica¸c˜ao das probabilidades, temos:

P (A ∩ B) = P (A) · P (B/A) = 4

7 · 1

2 = 4

14 = 2
7.

Utilizando novamente o exemplo da caixa e sabendo que n˜ao haver´a reposi¸c˜ao, calcular

a probabilidade de se obter nas duas primeiras extra¸c˜oes bolas com cores iguais.

Nesse caso, note que retirar bolas de mesma cor evidencia o acontecimento dos se-

guintes eventos:

X - evento retirar duas bolas azuis.
Y - evento retirar duas bolas vermelhas.

Ent˜ao, precisaremos calcular a probabilidade da uni˜ao desses dois eventos, isto ´e,
P (X ∪ Y ), e como s˜ao eventos multuamente excludentes, tˆem-se P (X ∩ Y ) = 0, pois retirar
duas bolas azuis em duas extra¸c˜oes, exclui a possibilidade de se retirar duas bolas vermelhas
e vice-versa.

Desse modo, precisaremos dividir os eventos X e Y em mais dois casos, (A1, A2) e
(V1, V2). E para termos uma melhor observa¸c˜ao das probabilidades a serem calculadas,
utilizaremos uma representa¸c˜ao chamada de diagrama da ´arvore de probabilidades ou ´arvore
das possibilidades e que seguir˜ao as seguintes nomenclaturas:

99

A1 - primeira bola extra´ıda ´e azul
A2 - segunda bola extra´ıda ´e azul
V1 - primeira bola extra´ıda ´e vermelha
V2 - segunda bola extra´ıda ´e vermelha

P(A1) - probabilidade da primeira bola extra´ıda ser azul
P(A2) - probabilidade da segunda bola extra´ıda ser azul
P(V1) - probabilidade da primeira bola extra´ıda ser vermelha
P(V2) - probabilidade da segunda bola extra´ıda ser vermelha
P (A1 ∩ A2) - probabilidade da primeira bola e segunda bola serem azuis
P (V1 ∩ V2) - probabilidade da primeira bola e segunda bola serem vermelhas

P(X) - probabilidade de acontecer o evento duas bolas azuis
P(Y) - probabilidade de acontecer o evento duas bolas vermelhas
P (X ∪ Y ) - Probabilidade da uni˜ao dos eventos X e Y.
P (X ∩ Y ) - Probabilidade da intersec¸c˜ao dos eventos X e Y.

3

7

4

7

A1

V1

A2

V2

A2

V2

1

3

2
3

1

2

1
2

100

Desse modo,

P (X) = P (A1 ∩ A2)
P (Y ) = P (V1 ∩ V2)
P (X ∪ Y ) = P (X) + P (Y ) − P (X ∩ Y ) , implicando em P (X ∪ Y ) = P (X) + P (Y ).
P (X ∪ Y ) = P (A1 ∩ A2 + P (V1 ∩ V2)

Pelo princ´ıpio de multiplica¸c˜ao das probabilidades, temos:

P (A1 ∩ A2) = P (A1) · P (A2/A1) = 3
7 · 1
P (V1 ∩ V2 = P (V1) · P (V2/V1) = 4

7 · 1
2 = 4

3 = 1

14 = 2

7

7

Logo, P (X ∪ Y ) = P (X) + P (Y ) = 1

7 + 2

7 = 3

7

Enﬁm, refor¸camos ao leitor que todos os pr´e-requisitos explanados neste apˆendice, tem
apenas o car´ater revisor. Qualquer aprofundamento ou complementa¸c˜ao necess´aria poder´a
ser encontrada em autores descritos nas referˆencias bibliogr´aﬁcas.


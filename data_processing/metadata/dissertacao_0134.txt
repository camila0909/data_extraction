FILIPE CÉSAR ARCHÂNGELO E SILVA

CADEIAS DE MARKOV - UMA SEQUÊNCIA DIDÁTICA PARA

O ENSINO MÉDIO

LAVRAS – MG

2020

FILIPE CÉSAR ARCHÂNGELO E SILVA

CADEIAS DE MARKOV - UMA SEQUÊNCIA DIDÁTICA PARA O ENSINO MÉDIO

Dissertação apresentada à Universidade Federal

de Lavras, como parte das exigências do

Programa de Pós-Graduação do Mestrado

Proﬁssional em Matemática em Rede Nacional

- PROFMAT - UFLA, para a obtenção do título

de Mestre.

Profa. Dra. Rita de Cássia Dornelas Sodré

Orientadora

LAVRAS – MG

2020

Ficha catalográﬁca elaborada pelo Sistema de Geração de Ficha Catalográﬁca da Biblioteca

Universitária da UFLA, com dados informados pelo(a) próprio(a) autor(a).

Silva, Filipe César Archângelo e

Cadeias de Markov - Uma Sequência Didática para o
Ensino Médio / Silva, Filipe César Archângelo e. – Lavras :
UFLA, 2020.
51 p. : il.

Dissertação(mestrado proﬁssional)–Universidade Federal

de Lavras, 2020.

Orientadora: Profa. Dra. Rita de Cássia Dornelas Sodré.
Bibliograﬁa.

1. Cadeias de Markov. 2. Probabilidade . 3. Sequência

Didática. I. Sodré, Rita de Cássia Dornelas. II. Título.

FILIPE CÉSAR ARCHÂNGELO E SILVA

CADEIAS DE MARKOV - UMA SEQUÊNCIA DIDÁTICA PARA O ENSINO MÉDIO

Dissertação apresentada à Universidade Federal
de Lavras, como parte das exigências do
Programa de Pós-Graduação do Mestrado
Proﬁssional em Matemática em Rede Nacional
- PROFMAT - UFLA, para a obtenção do título
de Mestre.

APROVADA em 15 de Dezembro de 2020.

Profa. Dra. Evelise Roman Corbalan Gois Freire UFLA
Prof. Dr. Emerson Souza Freire

UFF

Profa. Dra. Rita de Cássia Dornelas Sodré
Orientadora

LAVRAS – MG
2020

AGRADECIMENTOS

Agradeço primeiramente a Deus, pelo maravilhoso dom da vida, por ser autor de meu destino,
meu guia e socorro presente nos momentos de angústias e frustrações - obrigado, meu Pai,
por tudo que me deste. Agradeço de todo coração, à minha madrinha Maria Manoelina, in
memorian, que em vida proporcionou-me os maiores sorrisos e afetos, que tomou-me como
ﬁlho, fornecendo um incondicional carinho de mãe e, assim, tornou-se a pessoa que mesmo
sem escolaridade, me ensinou o que é o verdadeiro amor.

Agradeço ao meu pai Edson Marques, por ser um exemplo de fé e minha calmaria em
momentos de tempestades, tornando-se assim, referência de serenidade e mansidão. Agradeço
à minha irmã Soﬁa Laura, por continuamente impulsionar-me a prosseguir decididamente, por
ser minha conselheira particular e sempre lembrar-me do porquê de minhas batalhas diárias.
Agradeço à minha namorada e melhor amiga Karoline Figueiredo, por muitas vezes enxergar-
me além do que os olhos podem ver, por ser minha companheira, minha incentivadora e por
acreditar em meus sonhos, aceitando trilhá-los ao meu lado.

Agradeço à minha orientadora Rita de Cássia, pela paciência em ter lido inúmeras vezes
os mesmos capítulos, por direcionar-me, de maneira majestosa, às prioridades deste trabalho e
por ter oportunizado a mim e aos meus colegas de pós-graduação, admiráveis aulas e ensina-
mentos, além de servir como espelho de uma excelente proﬁssional. Agradeço ao meu mentor,
antigo professor, recente colega de classe e eterno amigo Francisco Ragner, por estar presente
durante grande parte de minha formação, encorajando-me com belas palavras; compartindo de
minhas orações diárias e provocando-me altas gargalhadas, que muitas vezes tornaram-se meu
refúgio. Agradeço ao mais recente e prodigioso amigo Jonas Soares, por mostrar-se assíduo em
situações desesperadoras, por conﬁar em minha capacidade e competência, por ouvir tantos de-
sabafos e, acima de tudo, por comprovar que verdadeiras amizades não requerem grande tempo
de convivência.

Agradeço, em especial, aos colegas Antônio Marcos e Mariana Mercílio, grandes pes-
soas e de caráteres indiscutíveis, que ﬁzeram parte dessa minha trajetória, partilhando diversas
conquistas, sortidas risadas na hora do almoço, múltiplas histórias bizarras e provando serem
essenciais em meus momentos de diﬁculdades. Agradeço, também, a professora Evelise Freire,
que muitas vezes compartilhou de suas experiências e se fez uma grande encorajadora do pro-
cesso ao qual passei.

Meu último agradecimento vai para a minha mãe Joana D’Arc Archângelo, a pessoa que
me colocou nesse caminho, o meu maior orgulho nessa vida, a minha rainha e maior admira-
ção. A pessoa que educou, orientou e formou meu caráter. A pessoa que me ensinou valores,
princípios e preceitos - vencendo preconceitos, quebrando paradigmas e nunca desistindo de
seus sonhos. A pessoa que se manteve acordada junto a mim, enquanto eu virava noites. A
pessoa que respeitou o meu silêncio e soube dizer as palavras certas nos meus momentos de
crises existenciais.

E, por ﬁm, agradeço antecipadamente a todos que lerão esse trabalho.

RESUMO

Uma cadeia de Markov é um processo estocástico caracterizado pela perda de memória. Em
outras palavras, é um processo aleatório dependente do tempo que satisfaz a propriedade de
Markov, que é caracterizada por previsões para os estados futuros baseando-se no estado pre-
sente e independente dos estados passados. As cadeias de Markov têm aplicações em diversos
tópicos da Física, Economia, Biologia, teoria dos jogos, etc. Seu estudo envolve os conteúdos
de matrizes e probabilidade. Uma vez que esses conteúdos fazem parte da Educação Básica, há
a possibilidade de um estudo inicial de seus conceitos através de alguns exemplos e aplicações
no 2◦ ano do Ensino Médio. Assim, com o objetivo de apresentar interessantes aplicações da
Matemática e motivar os estudantes na sua aprendizagem, este trabalho traz uma proposta de
sequência didática, isto é, um conjunto de atividades planejadas para o estudo em grupo, com
previsão de duração de duas horas-aulas. Os estudantes terão a oportunidade de observar que
as linhas de raciocínio utilizadas nas resoluções dos problemas são muito semelhantes, apesar
dos temas de cada problema serem completamente diferentes. Tal situação mostra o caráter de
generalização da Matemática, que faz uso de uma mesma ferramenta para resolver problemas
de origens distintas.

Palavras-chave: Cadeias de Markov. Probabilidade. Sequência Didática.

ABSTRACT

A Markov chain is a stochastic process obtained by the loss of memory. In other words, it is
a random time-dependent process that satisﬁes the Markov property, which is characterized by
predictions for future states based on the present state and independent of past states. The chains
of Markov have applications in several topics of Physics, Economics, Biology, game theory,
etc. This study involves the contents of matrices and probability. Since these contents are part
of Basic Education, there are the possibility of an initial study of its concepts through some
examples and applications in the 2◦ year of High school. Thus, in order to present interesting
applications of mathematics and motivate students in their learning, this work presents a didactic
sequence proposal, that is, a set of activities planned for the group study, with a duration of
two class hours. Students will have the opportunity to note that the lines of reasoning used in
problem solving are very similar, although the themes of each problem are completely different.
Such a situation shows the character of generalization of Mathematics, which makes use of the
same tool to solve problems of different origins.

Keywords: Markov chains. Probability. Didactic Sequence.

LISTA DE FIGURAS

Figura 2.1 – Variável aleatória discreta X deﬁnida sobre Ω. . . . . . . . . . . . . . . . .

Figura 2.2 – Diagrama em árvore e suas probabilidades . . . . . . . . . . . . . . . . . .

Figura 2.3 – Esquema com as probabilidades de transição entre os quatro estados . . . .

Figura 3.1 – Esquema com as probabilidades de transição entre os dois estados possíveis

Figura 3.2 – Esquema com as probabilidades de transição entre os quatro estados . . . .

Figura 3.3 – Esquema com as probabilidades de transições entre os estados de E . . . .

Figura 3.4 – Nova reordenação dos estados de E = {1(cid:48), 2(cid:48), 3(cid:48), 4(cid:48), 5(cid:48)} . . . . . . . . . . .

21

21

23

26

32

34

35

Figura 4.1 – Esquema com as probabilidades de transição entre os dois estados do sistema 40

Figura 4.2 – Situação do Problema 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . .

Figura 4.3 – Esquema de migração entre as zonas urbana (U) e rural (R) do município .

Figura 4.4 – Esquema com as probabilidades de transição entre as três classes sociais . .

Figura 4.5 – Situação do Problema 4.3 . . . . . . . . . . . . . . . . . . . . . . . . . . .

Figura 4.6 – Esquema com as probabilidades de transição entre os três tipos de safra . .

Figura 4.7 – Situação do Problema 4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . .

42

44

46

46

48

48

LISTA DE TABELAS

Tabela 3.1 – Probabilidades para os resultados do próximo jogo . . . . . . . . . . . . .

Tabela 3.2 – Probabilidades para o próximo jogo baseadas no resultado do jogo atual . .

Tabela 4.1 – Probabilidades de vitória ou derrota para um determinado time.

. . . . . .

Tabela 4.2 – Porcentagens de migração entre as zonas urbana e rural do município.

. . .

Tabela 4.3 – Probabilidades de transição entre as classes A, M e B da próxima geração. .

25

27

40

44

46

SUMÁRIO

1

2

2.1

2.2

INTRODUÇÃO .

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

CONCEITOS FUNDAMENTAIS . . . . . . . . . . . . . . . . . . . . . . . .

Histórico sobre probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . .

Probabilidade

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2.1 Tipos e probabilidade de um evento . . . . . . . . . . . . . . . . . . . . . . .

2.2.2 Adição de probabilidades . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2.3 Probabilidade condicional . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2.4 Eventos independentes .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3

Conceitos básicos de processos estocásticos

. . . . . . . . . . . . . . . . . . .

3

3.1

3.2

3.3

3.4

4

CADEIAS DE MARKOV . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Vetor de probabilidade de estado . . . . . . . . . . . . . . . . . . . . . . . . .

Classiﬁcação de estados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Cadeias de Markov absorventes

. . . . . . . . . . . . . . . . . . . . . . . . .

Cadeias de Markov regulares . . . . . . . . . . . . . . . . . . . . . . . . . . .

UMA SEQUÊNCIA DIDÁTICA SOBRE CADEIAS DE MARKOV PARA O

ENSINO MÉDIO . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Considerações ﬁnais .

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

REFERÊNCIAS .

. .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

10

10

11

12

14

16

17

20

24

29

30

33

37

39

50

51

1 INTRODUÇÃO

8

Atualmente, a presença e o uso de probabilidades são frequentes no cotidiano de muitas

pessoas e em diversas situações: nas consultas sobre a previsão do tempo no aplicativo do

celular, sobre os possíveis congestionamentos no trânsito, sobre as chances de um time de

futebol ganhar uma determinada partida, sobre as chances de um aluno ser aprovado em um

vestibular, as chances de um apostador ganhar na loteria, etc. Assim, é notável que a teoria

probabilística está presente na vida das pessoas.

Nas ciências, a situação se repete, e o estudo de probabilidade e suas aplicações estão

em diversas áreas, como na Estatística, na Economia, nas Engenharias, na Física, na Química,

na Sociologia, entre outras.

Este trabalho apresenta um estudo introdutório de uma aplicação de probabilidade, mais

especiﬁcamente, as chamadas cadeias de Markov, que é um tipo especial de processo aleatório

caracterizado pela perda de memória. Considera-se a evolução de um processo em tempo dis-

creto, sendo o conjunto de estados possíveis também um conjunto discreto e, na maioria dos

exemplos, um conjunto ﬁnito. A probabilidade do processo assumir um determinado estado no

futuro, só depende do estado presente, ou seja, os estados anteriores do processo não interfe-

rem na probabilidade de estados futuros. São fornecidas as probabilidades de transição de um

estado para o outro e, por simplicidade, estas probabilidades não dependem do tempo, ou seja,

são estacionárias.

A escolha do tema de cadeias de Markov pelo autor, justiﬁca-se pela possibilidade de

inserção de alguns de seus conceitos no âmbito escolar a nível de Ensino Médio, mais espe-

ciﬁcamente, no 2◦ ano do Ensino Médio. Os conteúdos de matrizes e probabilidade são pré-

requisitos para tal inserção. Com este objetivo, o autor apresenta uma proposta de sequência

didática, isto é, um conjunto de atividades planejadas para o estudo introdutório de alguns con-

ceitos de cadeias de Markov através de situações problemas, que são baseadas em um exemplo

previamente discutido e estudado com o professor. A estimativa do tempo necessário para a

realização da sequência é de duas horas-aulas e sugere-se a dinâmica de trabalho em grupo.

A divisão desta dissertação é feita em quatro capítulos, incluindo este primeiro capítulo

introdutório.

O Capítulo 1 traz uma revisão dos conceitos básicos de probabilidade e processos esto-

cásticos, uma vez que, as cadeias de Markov são exemplos especiais desse tipo de processos. O

autor achou importante a inserção de tal revisão para o bom entendimento do trabalho.

9

O Capítulo 2 apresenta o tema principal do trabalho, as cadeias de Markov. Apesar do

conteúdo apresentado neste capítulo não ser voltado para os alunos do Ensino Médio, ele tem

por objetivo ampliar e melhorar a formação matemática do professor, um dos pontos centrais

do PROFMAT.

O Capítulo 3 traz a sequência didática para os alunos do 2◦ ano do Ensino Médio. Tal

sequência é formada por alguns problemas envolvendo as ideias de cadeias de Markov, prin-

cipalmente, o conceito de matriz de transição e o cálculo de probabilidades não triviais. As

resoluções das atividades e alguns comentários pertinentes também fazem parte do capítulo.

O autor acredita que a sequência didática apresentada neste trabalho possa incentivar o

interesse dos estudantes pela Matemática, em especial, pelo estudo de probabilidade, uma vez

que os problemas apresentados envolvem interessantes aplicações na vida cotidiana.

10

2 CONCEITOS FUNDAMENTAIS

Neste capítulo, será apresentada uma revisão dos conteúdos probabilidades relevantes

para o estudo das cadeias de Markov, bem como um breve histórico sobre o tema. Todos

os conceitos abordados remetem a uma futura aplicação para alunos de Ensino Médio, sendo

assim, limitaremos as ideias e exemplos para este público.

2.1 Histórico sobre probabilidade

O grande interesse do homem em estudar, e assim, aprofundar em fenômenos que en-

volvam determinadas possibilidades para ações, eventos e fenômenos, não é uma curiosidade

recente. Tal estudo foi o passo decisivo para o desenvolvimento do cálculo das probabilidades.

Segundo (SILVA, 2020), alguns indícios alegam que, o surgimento da Teoria da Probabilidade

teve início com os jogos de azar alastrado na Idade Média. Jogos desse tipo eram frequente-

mente praticados através de apostas e até mesmo como tentativas de predizer o futuro.

O avanço da Teoria da Probabilidade deve ser atribuído à diversos matemáticos. Sustenta-

se que cálculo das probabilidades teve a sua origem na Itália com Luca Pacioli (1445 - 1517)

, Niccolò Fontana Tartaglia (1499 - 1557) , Galileu Galilei (1564 - 1642) e Gerolamo Cardano

(1501 - 1576) , onde este último foi o autor de O Livro dos Jogos de Azar (1520), o primeiro

livro a tratar-se sobre o acaso, onde que apesar de cometer alguns equívocos, teve como sua

maior contribuição o que conhecemos hoje como espaço amostral.

Para o desenvolvimento do estudo em questão, pode-se ainda citar outros matemáticos

que contribuíram de forma satisfatória para a fundamentação dos cálculos probabilísticos, como

Pierre Simon Laplace (1749 - 1827), Carl Friedrich Gauss (1777 - 1855) e Lenis Poisson (1781 -

1840). Entretanto, e de acordo com (EVES, 2004), um marco interessante e, consequentemente,

importante na história deu-se em 1654, quando Antoine Gombaud, um nobre experimente apos-

tador,buscou o auxílio de Blaise Pascal (1623 - 1662) para a seguinte questão: "Dois jogadores

estão participando de um determinado jogo e ambos têm a mesma probabilidade de vencer. O

ganhador será aquele que atingir um certo número de pontos. Caso o jogo seja interrompido

em um dado momento, qual a maneira justa de dividir o valor apostado?". Para isso, Blaise

Pascal teve a ajuda de Pierre de Fermat (1601 - 1655), onde estes, ao encontrarem soluções

para o problema de maneiras distintas, representaram um signiﬁcativo avanço no domínio das

probabilidades.

11

Em 1655, Christiaan Huygens (1629 - 1695), em viagem à Paris, conheceu as corres-

pondências trocadas por Fermat e Pascal, e assim, em 1657 publicou On Reasoning in Games

of Chance, livro que apresenta de forma sistemática o problema discutido por Fermat e Pas-

cal e alguns outros problemas mais complexos envolvendo jogos de azar. Esta obra contribuiu

indiretamente em outras vertentes da Teoria da Probabilidade, pois serviu de inspiração para

Jacob Bernoulli (1654 - 1705) no estudo de experimentações. Bernoulli percebeu que as pro-

babilidades podiam ser calculadas por meio de observações, registrando-se as frequências de

eventos e as margens de erro, fato que posteriormente deu origem a Teoria da Medição, usada

para quantiﬁcar erros aleatórios, em meados do século XVIII.

As contribuições de Bernoulli evidenciaram os grandes números, abordando permuta-

ções, agrupamentos, combinações e a classiﬁcação binomial. Atualmente, a Teoria da Probabi-

lidade ainda é aplicada a jogos de azar, bem como em diversas áreas da medicina, engenharia,

Market, economia e, até mesmo, no direito. Os conceitos desenvolvidos alteraram o estudo dos

processos aleatórios, riscos e tomadas de decisões.

2.2 Probabilidade

Com a teoria da probabilidade, procura-se quantiﬁcar a chance de ocorrência de um

determinado resultado (evento), quando observa-se um fenômeno ou um experimento aleatório.

Tomando um experimento, este pode acontecer em duas vertentes (MORGADO, 2006).

Será dito que um experimento é determinístico no momento que, repetido em condições seme-

lhantes conduz a resultados fundamentalmente idênticos, podendo assim, determiná-los antes

de sua realização, por exemplo: quanto tempo levará um veículo para percorrer um trajeto de

300 km numa velocidade média de 60 km/h? Não há a necessidade de executar o experimento

para determinar a resposta de 5h.

Os experimentos que, quando repetidos sob as mesmas condições produzem resultados

geralmente diferentes, são chamados de experimentos aleatórios. Ou seja, são experimentos cu-

jos resultados somente são conhecidos após sua realização. Mesmo repetindo-se o experimento

ou mantendo-se as mesmas condições, ainda assim o resultado poderá não ser o mesmo. Por

exemplo, no lançamento de um dado comum (seis faces numeradas de 1 a 6) e honesto (todas

as faces têm a mesma chance de aparecer), que face ﬁcará voltada para cima? Para conhecer o

resultado, precisa-se lançar o dado.

12

O conjunto de todos os resultados possíveis de um experimento aleatório é chamado de

espaço amostral ou conjunto universo e será representado por Ω.

No caso do lançamento de um dado, tem-se Ω = {1, 2, 3, 4, 5, 6}. Além disso, deﬁne-se

como evento um subconjunto do espaço amostral.

Exemplo 2.1 No lançamento de três moedas, indica-se por ca e co as faces cara e coroa.

Assim, o espaço amostral é dado pelo conjunto

Ω = {(ca, ca, ca), (ca, ca, co), (ca, co, ca), (co, ca, ca), (co, co, co), (co, co, ca),

(co, ca, co), (ca, co, co)}.

represente os seguintes eventos:

Evento A: As três faces são iguais.

Evento B: Somente uma face ’cara’.

Evento C: Pelo menos uma face ’cara’.

São eles:

• A = {(ca, ca, ca), (co, co, co)}.

• B = {(ca, co, co), (co, ca, co), (co, co, ca)}.

• C = {(ca, ca, ca), (ca, ca, co), (ca, co, ca), (co, ca, ca), (co, co, ca), (co, ca, co), (ca, co, co)}.

Lembre-se que a quantidade de elementos do espaço amostral e de um evento de um experi-

mento aleatório são calculados geralmente com o auxílio da análise combinatória.

2.2.1 Tipos e probabilidade de um evento

Considere o lançamento de um dado comum e a observação da face voltada para cima.

O espaço amostral desse experimento é Ω = {1, 2, 3, 4, 5, 6}. Analisa-se a seguir diversos tipos

de eventos que podem ser deﬁnidos neste experimento.

Evento elementar: qualquer subconjunto unitário de Ω. Exemplo: a ocorrência de um número

múltiplo de 5, A = {5}.

13

Evento certo: o próprio espaço amostral Ω. Exemplo: a ocorrência de um número divisor de

60, B = {1, 2, 3, 4, 5, 6}.

Evento impossível: é um conjunto vazio /0. Exemplo: a ocorrência de um número múltiplo de

8: C = /0.

Evento união: é a reunião de eventos. Exemplo: seja D a ocorrência de um número primo,

D = {2, 3, 5}, e o evento E sendo a ocorrência de um número ímpar, E = {1, 3, 5}. O

evento D ∪ E será a ocorrência de um número primo ou ímpar, D ∪ E = {1, 2, 3, 5}.

Evento interseção: é a interseção de eventos. Exemplo: considere os eventos D e E do item

anterior. O evento D ∩ E é a ocorrência de um número primo e ímpar, D ∩ E = {3, 5}.

Eventos mutuamente exclusivos: dois eventos F e G são chamados mutuamente exclusivos

quando F ∩ G = /0. Exemplo: seja F a ocorrência de um número par, F = {2, 4, 6}, e G a

ocorrência de um número ímpar, G = {1, 3, 5}. Então F e G são mutuamente exclusivos.

Evento complementar: um evento ¯H é complementar do evento H, se ¯H = Ω − H. Exemplo:
seja H a ocorrência de um número primo, H = {2, 3, 5}. O evento ¯H sendo a ocorrência

de um número não primo,

¯H = {1, 4, 6}, é um evento complementar de H. No item

anterior, o evento F é complementar do evento G e vice-versa.

Diz-se que um espaço amostral é equiprovável quando a chance de ocorrência de cada um de

seus eventos elementares é sempre a mesma.

Deﬁnição 2.1 (Probabilidade clássica) Seja Ω um espaço amostral equiprovável e A um de

seus eventos. A probabilidade de ocorrência do evento A é deﬁnida por:

P(A) =

n(A)
n(Ω)

,

sendo n(A) e n(Ω) a quantidade de elementos em A e Ω, respectivamente.

Em outras palavras, pode-se dizer que a probabilidade de ocorrência de um evento A é a razão

entre o número de casos favoráveis ao evento A e o número de casos possíveis no experimento.

P(A) =

casos favoráveis
casos possíveis

.

14

Em muitas aplicações, o espaço amostral não é equiprovável, impossibilitando o cálculo

da probabilidade como deﬁnido anteriormente. Nestes casos, usa-se uma outra deﬁnição de

probabilidade conhecida como deﬁnição frequentista. Por exemplo, para determinar a proba-

bilidade de um determinado goleiro defender um pênalti em um jogo, faz-se uma análise dos

jogos realizados anteriormente pelo goleiro para fazer uma projeção com base em dados que já

aconteceram. Suponha que em 35 pênaltis ocorridos em jogos anteriores, o goleiro tenha de-

fendido 15. Então, tem-se uma estimativa para a probabilidade do goleiro defender um pênalti

no jogo, dada pela frequência relativa 15

7 = 0, 428..., ou seja, aproximadamente, 43%. Se-
gundo (SOARES J. F., 2002), pode-se aﬁrmar que, quanto maior for o número n de repetições

35 = 3

de um determinado experimento, melhor será a estimativa para a probalidade. Dessa forma, a

probabilidade de um evento A é dada pela frequência relativa desse evento

P(A) =

número de vezes de ocorrência do evento
número total de repetições do experimento

.

A seguir, são apresentadas algumas propriedades de probabilidade para certos eventos

de um espaço amostral Ω.

(I) P( /0) = 0

(II) P(Ω) = 1

(III) 0 ≤ P(A) ≤ 1

(IV) P( ¯A) = 1 − P(A)

2.2.2 Adição de probabilidades

Em um baralho comum tem-se 4 naipes:

• paus (♣, cor preta)

• copas (♥, cor vermelha)

• espadas (♠, cor preta)

• ouros (♦, cor vermelha)

Cada naipe possui 13 cartas, são elas: A (ás), 2, 3, 4, 5, 6, 7, 8, 9, 10, J (valete), Q(dama) e
K (rei). Ao extrair uma carta ao acaso, pergunta-se:

15

(a) Qual é a probabilidade de a carta retirada ser de copas?

(b) Qual é a probabilidade de a carta retirada ser um ás?

(c) Qual é a probabilidade de a carta retirada ser de copas ou um ás?

Para responder as questões acima, observa-se que como são 4 naipes, com 13 cartas cada um,

então tem-se um total de 4 · 13 = 52 cartas, portanto n(Ω) = 52.

(a) Casos favoráveis: são as 13 cartas de copas, assim, n(casos favoráveis) = 13. Logo, P(carta ser de copas) =

13
52 = 1
4.

(b) Casos favoráveis: são os 4 ases, assim, n(casos favoráveis) = 4. Logo, P(carta ser um ás) =

52 = 1
4
13.

(c) Casos favoráveis: 4 ases + 13 cartas de copas - 1 ás de copas = 16 cartas, assim, n(casos favoráveis) =

16. Logo,

P(carta ser de copas ou um ás) =

16
52

=

4
13

.

Percebe-se que, nesse exemplo, foi necessário retirar um elemento (ás de copas), que foi conta-

bilizado nos dois conjuntos. Em situações como essa, em que dois conjuntos possuem elemen-

tos repetidos, tem-se:

n(A ∪ B) = n(A) + n(B) − n(A ∩ B).

Em palavras, pode-se dizer que o número de elementos do conjunto união A ∪ B é igual ao

número de elementos de A mais o número de elementos de B, menos o número de elementos do

conjunto interseção A ∩ B.

Pode-se estender esse conceito para as probabilidades, uma vez que,

n(A ∪ B)
n(Ω)

=

n(A)
n(Ω)

+

n(B)
n(Ω)

−

n(A ∩ B)
n(Ω)

.

que é equivalente a

P(A ∪ B) = P(A) + P(B) − P(A ∩ B).

16

2.2.3 Probabilidade condicional

Muitas vezes, o conhecimento de alguma informação a respeito do resultado de um

experimento aleatório pode alterar a probabilidade de um determinado evento ligado a tal expe-

rimento.

Exemplo 2.2 Num jogo de dados, um jogador sempre aposta em obter um resultado maior do

que 3. A probabilidade de vencer tal aposta é facilmente calculada e vale 1/2. Certa vez, esse

mesmo jogador chegou no momento em que o dado já havia sido lançado. Como ainda não

havia visto o resultado, decidiu analisar se faria a mesma aposta como de costume. Porém ele

foi avisado de que o resultado era um número par. Sabendo disso, o jogador decidiu por não

apostar e esperar a próxima jogada. O jogador tomou uma boa decisão?

Para responder tal questionamento, basta calcular a probabilidade de sair um resultado maior

do que 3, sabendo que o resultado é um número par, e comparar o valor com 1/2.

Sendo o evento A a ocorrência de um resultado maior do que 3, A = {4, 5, 6}, tem-

se P(A) = 1/2. Chamando de B a ocorrência de resultado par, B = {2, 4, 6}, P(B) = 1/2.

A probabilidade de ocorrer um número maior do que 3, sabendo que ele é um número par,

será denotada por P(A|B). Diz-se que P(A|B) é a probabilidade de ocorrência do evento A,

condicionada à ocorrência do evento B.

Para realização desse cálculo, raciocina-se como se o espaço amostral tivesse diminuído
e passasse a ser ¯Ω = B. Já o evento A deve ser considerado como um outro evento ¯A nesse
novo espaço amostral ¯Ω = B. Na verdade, ¯A = A ∩ B. Os casos favoráveis para o evento ¯A é o

conjunto A ∩ B = {4, 6}. Portanto,

P(A|B) =

n( ¯A)
n( ¯Ω)

=

n(A ∩ B)
n(B)

=

2
3

.

(2.1)

Como a probabilidade encontrada é maior do que P(A) = 1/2, pode-se concluir que o jogador

não tomou uma boa decisão ao deixar de apostar.

De (2.1), tem-se uma outra forma de indicar P(A|B):

P(A|B) =

n(A ∩ B)
n(B)

=

n(A∩B)
n(Ω)
n(B)
n(Ω)

=

P(A ∩ B)
P(B)

.

17

De maneira análoga,

Logo, pode-se escrever:

P(B|A) =

P(B ∩ A)
P(A)

.

P(A|B) · P(B) = P(A ∩ B) = P(B ∩ A) = P(B|A) · P(A).

(2.2)

Equivalentemente,

P(A) =

P(A|B) · P(B)
P(B|A)

.

2.2.4 Eventos independentes

Se a probabilidade de um evento A condicionado a um evento B for igual à probabili-

dade do evento A, diz-se que o evento A é independente do evento B ou, equivalentemente, A

independe de B. Caso contrário, diz-se que o evento A depende de B.

Exemplo 2.3 Uma urna contém 4 bolas brancas e 6 bolas pretas. Duas bolas, escolhidas ao

acaso, são retiradas dessa urna, sucessivamente e sem reposição. Qual é a probabilidade que

a segunda bola seja branca?

Como não há reposição da bola na urna, n(Ω) = 10 · 9 = 90 possibilidades. Denote por A a

retirada da segunda bola na cor branca. Tem-se dois tipos de casos favoráveis a A: a retirada

de uma primeira bola na cor preta e a retirada de uma segunda bola na cor branca (6 · 4 = 24

possibilidades) ou a retirada de uma primeira bola branca e uma segunda bola branca (4 · 3 = 12

possibilidades), totalizando assim 36 = 24 + 12 possibilidades. Logo,

P(A) =

n(A)
n(Ω)

=

36
90

=

2
5

= 0, 4

Exemplo 2.4 Uma urna contém 4 bolas brancas e 6 bolas pretas. Duas bolas, escolhidas ao

acaso, são retiradas dessa urna, sucessivamente e sem reposição. Qual é a probabilidade que

a segunda bola seja branca, sabendo-se que a primeira bola retirada foi preta?

Denote por B a retirada da primeira bola na cor preta. Tem-se dois tipos de casos favoráveis a

B: a retirada de uma primeira bola na cor preta e a retirada de uma segunda bola na cor branca

(6 · 4 = 24 possibilidades) ou a retirada de uma primeira bola preta e uma segunda bola preta

18

(6 · 5 = 30 possibilidades), totalizando assim 54 = 24 + 30 possibilidades. Logo, n(B) = 54. O

evento interseção A ∩ B, seria retirar uma primeira bola preta e uma segunda bola branca, possui

6 · 4 = 24 casos favoráveis. Logo,

P(A|B) =

n(A ∩ B)
n(B)

=

24
54

=

4
9

≈ 0, 44.

Observa-se que, como P(A|B) (cid:54)= P(A), o evento A depende do evento B. Em outras palavras,

a condição ’retirar uma primeira bola na cor preta’ inﬂuenciou a probabilidade de sair uma

segunda bola na cor branca.

Exemplo 2.5 Uma urna contém 4 bolas brancas e 6 bolas pretas. Duas bolas, escolhidas ao

acaso, são retiradas dessa urna, sucessivamente e com reposição. Qual é a probabilidade que

a segunda bola seja branca?

Como há reposição da bola na urna, n(Ω) = 10 · 10 = 100 possibilidades. Denote por A a

retirada da segunda bola na cor branca. Tem-se dois tipos de casos favoráveis a A: a retirada

de uma primeira bola na cor preta e a retirada de uma segunda bola na cor branca (6 · 4 = 24

possibilidades) ou a retirada de uma primeira bola branca e uma segunda bola branca (4 · 4 = 16

possibilidades), totalizando assim 40 = 24 + 16 possibilidades. Logo,

P(A) =

n(A)
n(Ω)

=

40
100

=

2
5

= 0, 4.

Exemplo 2.6 Uma urna contém 4 bolas brancas e 6 bolas pretas. Duas bolas, escolhidas ao

acaso, são retiradas dessa urna, sucessivamente e com reposição. Qual é a probabilidade que

a segunda bola seja branca, sabendo-se que a primeira bola retirada foi preta?

Denote por B a retirada da primeira bola na cor preta. Tem-se dois tipos de casos favoráveis a

B: a retirada de uma primeira bola na cor preta e a retirada de uma segunda bola na cor branca

(6 · 4 = 24 possibilidades) ou a retirada de uma primeira bola preta e uma segunda bola preta

(6 · 6 = 36 possibilidades), totalizando assim 60 = 24 + 36 possibilidades. Logo, n(B) = 60. O

evento interseção A ∩ B, seria retirar uma primeira bola preta e uma segunda bola branca, possui

6 · 4 = 24 casos favoráveis. Logo,

P(A|B) =

n(A ∩ B)
n(B)

=

24
60

=

2
5

= 0, 4.

19

Observa-se que, neste exemplo, P(A|B) = P(A). Portanto, o evento A é independente do evento

B. Em outras palavras, a condição ’retirar uma primeira bola na cor preta’ não inﬂuenciou

a probabilidade de sair uma segunda bola na cor branca. O que foi essencial aqui, para a

independência do evento A de B, foi a reposição da primeira bola retirada na urna. Quando não

é feita a reposição da bola, o evento A passa a depender do evento B.

Esse raciocínio pode ser generalizado para a retirada de qualquer quantidade de bola em

uma urna, desde que haja a reposição da bola retirada em cada momento. Um outro exemplo, é

o lançamento de uma moeda por cem vezes. A probabilidade de obter a face cara em qualquer

um dos lançamentos é 1/2 e independe de qualquer resultado obtido anteriormente.

Agora, analisa-se uma questão interessante: se o evento A é independente do evento B,

então o evento B é independente do evento A? O teorema seguinte traz uma resposta aﬁrmativa

para essa pergunta.

Teorema 2.1 Sejam A e B eventos possíveis de um mesmo espaço amostral Ω. Se o evento A é

independente do evento B, então B também é independente de A. Em símbolos escreve-se:

P(A|B) = P(A) =⇒ P(B|A) = P(B).

Demonstração: Como A e B são eventos possíveis, segue que n(A) e n(B) são diferentes de

zero. Mostrou-se, anteriormente, que

P(A|B) =

P(A ∩ B)
P(B)

.

Por hipótese, P(A) = P(A|B) = P(A∩B)

P(B) , ou seja, P(A ∩ B) = P(A) · P(B). Portanto,

P(B|A) =

P(A ∩ B)
P(A)

=

P(A) · P(B)
P(A)

= P(B).

Logo, B é independente de A.

Exemplo 2.7 Uma urna contém 7 bolas brancas e 3 bolas azuis. Calcule a probabilidade de

obter duas bolas azuis em duas retiradas sucessivas, se as retiradas forem feitas

a) com reposição.

b) sem reposição.

a) Denote por A1 a retirada da primeira bola na cor azul e por A2 a retirada da segunda bola

também na cor azul. Deseja-se calcular P(A1 ∩ A2). Como o experimento é realizado com

20

reposição, os eventos A1 e A2 são independentes e, portanto, P(A1 ∩A2) = P(A1)·P(A2) =
3
10 · 3

100 = 0, 09.

10 = 9

b) Como não há reposição, os eventos A1 e A2 não são independentes. Assim, deve-se usar a

probabilidade condicional,

P(A1 ∩ A2) = P(A2 ∩ A1) = P(A2|A1) · P(A1) =

2
9

·

3
10

=

1
15

≈ 0, 067.

Em resumo, se A e B são eventos de um mesmo espaço amostral Ω, com P(B) (cid:54)= 0, é

válido que

P(A|B) =

P(A ∩ B)
P(B)

.

Além disso, se o evento A é independente do evento B, isto é, se P(A|B) = P(A), então

P(A ∩ B) = P(A) · P(B).

2.3 Conceitos básicos de processos estocásticos

Para entender o que é um processo estocástico é necessário o conceito de variável ale-

atória. Existem dois tipos de variável aleatória: a discreta e a contínua. Deﬁne-se a seguir a

variável aleatória discreta (CLARKE A. BRUCE, 1979), pois é ela que será utilizada no estudo

de cadeias de Markov.

Deﬁnição 2.2 Uma variável aleatória X é uma função deﬁnida sobre um espaço amostral Ω

que atribui um valor real a cada elemento de Ω. Diz-se que a variável aleatória é discreta

quando o conjunto de valores possíveis é ﬁnito ou inﬁnito e enumerável.

Com o objetivo de tornar mais claros tais conceitos apresenta-se o exemplo:

Exemplo 2.8 Uma urna contém duas bolas azuis A e três bolas vermelhas V . Suponha que são

sorteadas duas bolas ao acaso, sem reposição. Tem-se o espaço amostral

Ω = {ω1 = (A, A), ω2 = (A,V ), ω3 = (V, A), ω4 = (V,V )}.

Figura 2.1 – Variável aleatória discreta X deﬁnida sobre Ω.

21

Fonte: Do autor (2020)

Deﬁne-se a seguinte variável aleatória discreta X: número de bolas vermelhas retiradas. En-

tão, X(ω1) = 0, X(ω2) = 1, X(ω3) = 1 e X(ω4) = 2. Os valores assumidos por esta variável

aleatória discreta são: 0, 1 e 2.

No caso do exemplo anterior, usando o conceito de probabilidade condicional, tem-se o

diagrama:

Figura 2.2 – Diagrama em árvore e suas probabilidades

Fonte: Do autor (2020)

Deﬁnição 2.3 A distribuição de probabilidade para uma variável aleatória X é a descrição das

probabilidades associadas aos valores possíveis da variável. Para o caso de variável discreta, a

22

distribuição de probabilidade é apenas uma lista de valores possíveis com suas probabilidades

associadas.

Assim, para o exemplo anterior, tem-se a distribuição de probabilidade para a variável aleatória

X:

P(X = 0) = P(A, A) = 1
10,

P(X = 1) = P(A,V ) + P(V, A) = 3

10 + 3

10 = 6
10 ,

P(X = 2) = P(V,V ) = 3
10 .

Tem-se a seguir a deﬁnição de um processo estocástico.

Deﬁnição 2.4 Um processo estocástico {Xt : t ∈ I} é uma coleção de variáveis aleatórias deﬁ-

nidas sobre um mesmo espaço amostral Ω. O conjunto I será chamado de espaço de parâme-

tros, sendo na prática o período de tempo em que o processo estocástico é observado. Assume-

se I = [0, ∞] (parâmetro em tempo contínuo) ou I = {0, 1, 2, 3, · · · } (parâmetro em tempo dis-

creto). O conjunto de valores que a variável aleatória Xt pode assumir é chamado de espaço

de estados e será denotado por E.

• Se Xt representa alguma contagem, isto é, se Xt for uma variável aleatória discreta, o

espaço de estados E pode ser uma sequência ﬁnita ou inﬁnita e enumerável (processo de

estado discreto ou cadeia aleatória).

• Se Xt representa uma medida, isto é, se Xt for uma variável aleatória contínua, o espaço

de estados E pode ser um intervalo de números reais (processo de estado contínuo).

A seguir tem-se um exemplo de processo estocástico com variáveis aleatórias discretas que

podem assumir quatro estados, isto é, o conjunto E tem quatro elementos, além disso o tempo

também é discreto.

Exemplo 2.9 Um jogador tem R$10, 00 e decide apostar em um jogo de dado comum no qual

ele ganha 10 reais, caso saia um número par, ou perde 10 reais, caso saia um número ímpar.

Dessa forma, as probabilidades dele perder ou ganhar são ambas iguais a 1/2. O jogo acaba

quando o jogador tiver R$30, 00 ou R$0, 00.

Este exemplo dá origem a uma cadeia de Markov sendo a variável aleatória Xk a quantia acumu-

lada pelo jogador na k-ésima jogada. Tal variável aleatória pode assumir um dos estados: 1, 2,

3 e 4, sendo estes estados correspondentes às quantias: R$0, 00, R$10, 00, R$20, 00 e R$30, 00,

respectivamente. Desssa forma, o conjunto de estados é E = {1, 2, 3, 4} e o estado inicial é

23

X0 = 2. Já X1 pode ser o estado 1 (R$0, 00) ou o estado 3 (R$20, 00). Portanto a cadeia de

Markov será uma sequência numérica, a princípio ﬁnita, cujo primeiro termo é 2 e o último

termo é 1 ou 4. Os termos intermediários variam entre os números 2 e 3.

Figura 2.3 – Esquema com as probabilidades de transição entre os quatro estados

Fonte: Do autor (2020)

Como um processo estocástico tem a função de associar a um conjunto de índice I uma

coleção de variáveis aleatórias Xt, saber deﬁnir o comportamento dessas variáveis torna-se algo

fundamental, uma vez que essas variáveis deﬁnem a complexidade de um fenômeno.

24

3 CADEIAS DE MARKOV

Este capítulo é destinado ao estudo dos processos Markovianos, que é um tipo especíﬁco

de processo estocástico. Em um processo Markoviano, a distribuição de probabilidade para um

passo futuro depende apenas do estado presente. Se, por sua vez, o espaço de estados é discreto

(enumerável), então o processo é chamado de Cadeia de Markov (LEVIN, 2009).

Nas aplicações, a sequência {Xn : n = 0, 1, 2, · · · } representa a evolução no tempo de

um sistema, nos instantes n = 0, 1, 2, .... A variável aleatória Xn representa o estado do sistema

no instante n. O conjunto de valores que a variável Xn pode assumir é chamado de espaço

de estados e é denotado por E. Por exemplo, se Xn = i, diz-se que o processo encontra-se no

estado i ∈ E no tempo n. Admite-se que existe uma probabilidade ﬁxa pi j do processo transitar

do estado i para o estado j, independente de n, isto é,

pi j = P[Xn+1 = j|Xn = i], ∀n ≥ 0, ∀i, j ∈ E.

O fato de pi j ser independente de n, refere-se à deﬁnição de cadeias de Markov estacionárias

(ou homogêneas), às quais restringe-se estas notas.

Por exemplo, Xn poderia ser o saldo em uma conta corrente no dia n, sendo X0 o saldo
inicial no dia da abertura da conta. O espaço de estados seria E = R, pensando em saldos

negativos que é quando o cliente tem uma dívida com o banco. Neste caso, o saldo da conta

corrente no dia n, dado o saldo da conta nos dias anteriores Xn−1, Xn−2,···,X0, irá depender

apenas do saldo do dia anterior, isto é, de Xn−1. Como o espaço de estados não é enumerável,

este exemplo trata-se de um processo Markoviano, mas não é um exemplo de cadeia de Markov.

Uma cadeia de Markov é descrita da seguinte forma:

Deﬁnição 3.1 Um processo estocástico em tempo discreto {Xn : n = 0, 1, 2, · · · }, com espaço

de estados discreto (enumerável) E, é uma cadeia de Markov estacionária se, para todo i, j, i0,

i1,...,in−1 ∈ E, tem-se

f uturo
(cid:122)
(cid:125)(cid:124)
(cid:123)
P[
Xn+1 = j |

presente
(cid:122) (cid:125)(cid:124) (cid:123)
Xn = i,

f uturo
(cid:122)
(cid:123)
(cid:125)(cid:124)
(cid:122)
Xn+1 = j |
Xn−1 = in−1, · · · , X1 = i1, X0 = i0] = P[

passado
(cid:125)(cid:124)

(cid:123)

presente
(cid:122) (cid:125)(cid:124) (cid:123)
Xn = i] = pi j,

sendo pi j a probabilidade de transição do processo do estado i para o estado j, em um passo,

independente do instante de tempo n ≥ 0. Em outras palavras, a igualdade acima diz que essa

probabilidade não depende dos estados passados, depende somente do estado presente i. O

25

processo pode permanecer no estado em que se encontra e isso ocorre com probabilidade igual

a pii.

Como consequência da deﬁnição de cadeia de Markov estacionária tem-se

P[Xn+1 = j|Xn = i] = P[X1 = j|X0 = i] = pi j,

para todo i, j ∈ E e n = 0, 1, 2, · · · .

Exemplo 3.1 Em um jogo, onde não é possível a ocorrência de empate, foram observados al-

guns dados para um determinado time. Se o time obteve uma vitória no jogo atual, a chance de

vitória no próximo jogo é de 75%. Todavia, se no jogo atual ocorreu uma derrota, a chance de

vitória no próximo jogo é de 35%. Determine as probabilidades de transição entre os estados.

Resolução: A Tabela a seguir apresenta tais informações:

Tabela 3.1 – Probabilidades para os resultados do próximo jogo

Vitória no

Derrota no

Próximo Jogo Próximo Jogo

Vitória no Jogo Atual
Derrota no Jogo Atual

75%
35%

25%
65%

Essa situação pode ser modelada através de uma cadeia de Markov com dois estados

possíveis, E = {1, 2}, sendo o estado 1 indicando a vitória do time e 2 indicando a derrota.

Tem-se o esquema:

Figura 3.1 – Esquema com as probabilidades de transição entre os dois estados possíveis

26

Fonte: Do autor (2020)

Com as informações fornecidas tem-se as probabilidades de transição através de uma

matriz quadrada denominada matriz de transição:

P =





p11 p12

p21 p22



 =





0, 75 0, 25

0, 35 0, 65



 ,

sendo que as entradas da primeira linha da matriz representam as probabilidades para os dois

estados (resultados) possíveis após um jogo vitorioso. Da mesma forma, as entradas da segunda

linha representam as probabilidades para os dois estados possíveis após uma derrota.

De uma forma mais geral, considere uma cadeia de Markov cujo espaço de estados é

E = {1, 2, · · · , n}. Deﬁne-se a matriz de transição da cadeia de Markov como sendo a matriz

quadrada de ordem n, P = (pi j), sendo pi j a probabilidade de transição do estado i para o estado

j, 1 ≤ i, j ≤ n (BOLDRINI, 1986)

P =











p11 p12

· · · p1n

p21 p22
...
...
pn1 pn2

· · · p2n
...
. . .
· · · pnn











O objetivo a seguir é responder à pergunta: qual é a probabilidade do processo estar

no estado j daqui a duas unidades de tempo, sabendo que ele iniciou no estado i? Denota-se
esta probabilidade por p(2)

i j = P[X2 = j|X0 = i].

Como as probabilidades pi j independem de n, o valor da probabilidade p(2)
i j

também é a

probabilidade do processo ir para o estado j daqui a duas unidades de tempo, saindo do estado

27

i no tempo n, ou seja,

p(2)
i j = P[Xn+2 = j|Xn = i] = P[X2 = j|X0 = i].

De forma análoga, a probabilidade de transição em k-passos, denotada por p(k)

i j , é a probabili-
dade de transferência do estado i para o estado j em k etapas de tempo discreto, independente

do instante n ≥ 0, ou seja,

p(k)
i j = P{Xn+k = j|Xn = i} = P[Xk = j|X0 = i], ∀n ≥ 0.

Tem-se um exemplo para melhor compreensão.

Exemplo 3.2 Considere os seguintes dados para um determinado time de futebol:

a) O time nunca empata dois jogos consecutivos.

b) Se ele empata, a probabilidade de vencer ou perder o próximo jogo são iguais.

c) Se ele ganha, as probabilidades de ganhar ou empatar o próximo jogo são 75% e 15%,

respectivamente.

d) Se ele perde, a probabilidade de ganhar a próxima partida cai para 25% e a de perder

novamente aumenta para 50%.

Diante dessas informações, determine a probabilidade do time perder o segundo jogo, tendo

vencido o jogo atual.

Resolução: A tabela a seguir traz as informações:

Tabela 3.2 – Probabilidades para o próximo jogo baseadas no resultado do jogo atual

Vitória no Jogo Atual
Empate no Jogo Atual
Derrota no Jogo Atual

Vitória no

Derrota no

Empate no
Próximo Jogo Próximo Jogo Próximo Jogo
15%
0%
25%

75%
50%
25%

10%
50%
50%

Considerando o espaço de estados E = {1, 2, 3}, sendo 1 para vitória, 2 para empate e 3

para derrota, tem-se a matriz de transição:

28








0, 75 0, 15 0, 1

P =

0, 5

0

0, 5

0, 25 0, 25 0, 5








Nessa situação, nota-se que se o time vence uma partida, então a probabilidade dele

perder o segundo jogo será a união disjunta de três eventos:

i) vence o jogo atual, vence o próximo jogo e perde o segundo jogo;

ii) vence o jogo atual, empata o próximo jogo e perde o segundo jogo;

iii) vence o jogo atual, perde o próximo jogo e perde o segundo jogo;

Em outras palavras, pode ocorrer uma das três opções abaixo:

i) ganha

p11−→ ganha

p13−→ perde;

ii) ganha

p12−→ empata

p23−→ perde;

iii) ganha

p13−→ perde

p33−→ perde;

A probabilidade do primeiro evento desta lista ocorrer é o produto de duas probabilidades con-

dicionais, p11 · p13, sendo p11 a probabilidade condicional dele vencer o jogo seguinte, tendo

vencido o jogo atual, e p13 a probabilidade condicional dele perder o jogo seguinte, tendo ven-

cido o jogo atual.

Os outros dois eventos da lista seguem este mesmo raciocínio: a probabilidade do se-

gundo evento é o produto p12·23, e a probabilidade do terceiro evento é o produto p13·33. Por-

tanto, a probabilidade do time perder o segundo jogo, tendo vencido o jogo atual é a soma:

p(2)
13 = p11 · p13 + p12 · p23 + p13 · p33 = 0, 75 · 0, 1 + 0, 15 · 0, 5 + 0, 1 · 0, 5 = 0, 2

que é exatamente o elemento da matriz P2 que está na posição (1, 3), ou seja, na primeira linha

e terceira coluna.

P2 =








p11 p12 p13

p21 p22 p23

p31 p32 p33















·

p11 p12 p13

p21 p22 p23

p31 p32 p33








=








P2 =

p11 p11 + p12 p21 + p13 p31 p11 p12 + p12 p22 + p13 p32 p11 p13 + p12 p23 + p13 p33

p21 p11 + p22 p21 + p23 p31 p21 p12 + p22 p22 + p23 p32 p21 p13 + p22 p23 + p23 p33

p31 p11 + p32 p21 + p33 p31 p31 p12 + p32 p22 + p33 p32 p31 p13 + p32 p23 + p33 p33

29








Usando a notação de somatório, tem-se p(2)

3
∑
m=1
do processo estar no estado j daqui a duas unidades de tempo, sabendo que ele encontra-se no
estado i é p(2)

p1m · pm3. De forma análoga, a probabilidade

pim · pm j, sendo 1 ≤ i, j ≤ 3.

13 =

i j =

3
∑
m=1

Da mesma forma, as probabilidades para k jogos futuros são dadas pela matriz Pk, k =

1, 2, · · · . A seguir, estão algumas potências da matriz de transição P:

0, 66 0, 14 0, 2

0, 62 0, 15 0, 23

0, 6

0, 15 0, 25

P2 =

0, 5

0, 2

0, 3

0, 55 0, 15

0, 3

, P4 =

0, 56 0, 16 0, 28

0, 43 0, 17 0, 4

0, 51 0, 17 0, 32

0, 51 0, 17 0, 32






















, P3 =











































, P7 =















,








.

0, 59 0, 15 0, 26

0, 58 0, 15 0, 27

0, 58 0, 15 0, 27

P5 =

0, 57 0, 15 0, 28

, P6 =

0, 58 0, 15 0, 27

0, 58 0, 15 0, 27

0, 56 0, 16 0, 28

0, 57 0, 16 0, 27

0, 58 0, 15 0, 27

Através da primeira coluna da matriz P7, nota-se que a probabilidade do time vencer o

sétimo jogo é a mesma para os diferentes resultados do jogo atual, isto é, não importa se o time

venceu, empatou ou perdeu o jogo atual, a probabilidade dele vencer o sétimo jogo é de 58%.
Em símbolos, p(7)

31 = 0, 58. O mesmo ocorre com as segunda e terceira colunas,
que correspondem as probabilidades de empate e derrota no sétimo jogo, respectivamente. As

21 = p(7)

11 = p(7)

probabilidades dessa cadeia se estabilizarem independem de onde a cadeia é iniciada. Estas

características são das cadeias regulares, assunto a ser estudado posteriormente.

A n-ésima potência da matriz de transição P, Pn, é denominada matriz de transição de

passo n.

3.1 Vetor de probabilidade de estado

Considere um conjunto ﬁnito de estados E = {1, 2, · · · , k}. Um vetor −→v = (v1, · · · , vk) é
dito um vetor de probabilidade de estado se vi ≥ 0, para todo 1 ≤ i ≤ k, e v1 +v2 +· · ·+vk = 1.

30

Voltando ao exemplo anterior, pode-se representar a vitória no jogo atual pelo vetor de
probabilidade de estado −→v0 = (1, 0, 0). Ao multiplicar o vetor linha −→v0 pela matriz P2, obtém-se
o vetor −→v2 que contém as probabilidades para cada um dos três estados, depois de duas unidades
de tempo, estando inicialmente o time no estado 1.

−→v2 = −→v0 · P2 =

(cid:105)
(cid:104)
1 0 0

·








0, 66 0, 14 0, 2

0, 5

0, 2

0, 3

0, 43 0, 17 0, 4








(cid:104)
0, 66 0, 14 0, 2

(cid:105)

=

Portanto, a probabilidade do time sofrer uma derrota no segundo jogo, tendo vencido o jogo
atual, equivale a terceira entrada do vetor −→v2 correspondente ao estado 3, ou seja, 20%. Lem-
brando que tal probabilidade foi denotada por p(2)

13 , tem-se que

−→v2 = −→v0 · P2 = [p(2)

11 p(2)

12 p(2)
13 ],

sendo p(2)

1 j a probabilidade para cada um dos três possíveis resultados no segundo jogo, tendo

vencido o jogo atual (partindo do estado 1).

O resultado a seguir (GOLMAKANI, 2014) generaliza esses fatos.

Teorema 3.1 Seja P a matriz de transição de uma cadeia de Markov, e seja −→v0 o vetor de
probabilidade de estado que representa o estado inicial. Então a probabilidade de que a cadeia
esteja no estado j após n passos é a j-ésima entrada do vetor −→vn = −→v0 Pn.

Em outras palavras, se, inicialmente, o processo está no estado i ∈ E, então −→v0 =
(0, · · · , 1, · · · , 0), sendo 1 a i-ésima entrada de −→v0 . A probabilidade do processo ir para o es-
i j e equivale a j-ésima entrada do vetor −→vn = −→v0 · Pn,
tado j ∈ E em n passos é denotada por p(n)

sendo P a matriz de transição do processo.

3.2 Classiﬁcação de estados

Os estados são classiﬁcados da seguinte forma:

Estados alcançáveis: Diz-se que o estado j é alcançável a partir do estado i, se p(n)

i j > 0, para

algum n > 0.

31

Estados comunicantes: Diz-se que os estados i e j são comunicantes, se i é alcançável a partir

de j e vice-versa. Além disso, convenciona-se que todo estado é comunicante com ele

mesmo, pensando que o processo pode atingir qualquer estado i a partir de i em 0 passos.

Estados transientes: Diz-se que um estado i é transiente (ou transitório) se existir a possi-

bilidade do processo entrar neste estado e nunca mais retornar ao mesmo. Em outras

palavras, o estado i é transiente se, e somente se, existe um estado j, j (cid:54)= i, que é alcançá-

vel a partir do estado i, mas não vice-versa. Dessa forma, se o processo estiver no estado

i, existe uma probabilidade positiva de o processo mover-se para o estado j e não retornar

ao estado i.

Estados recorrentes: Diz-se que um estado i é recorrente se ele não for transiente. Em outras

palavras, quando o processo assume um estado recorrente, existe uma probabilidade po-

sitiva dele retornar a este estado, não necessariamente no próximo passo. Para processos

em tempo inﬁnito, um estado recorrente será atingido uma iniﬁnidade de vezes.

Estados absorventes: Diz-se que um estado i é absorvente se, ao entrar nesse estado, o pro-

cesso nunca deixá-lo, ou seja, pii = 1. Pode-se dizer que o estado absorvente é um tipo

especial de estado recorrente.

A relação de estados comunicantes é uma relação de equivalência deﬁnida no conjunto

de estados E, visto que ela satisfaz as três propriedades:

Reﬂexiva: Todo estado i ∈ E é comunicante com ele mesmo.

Simétrica: Se i é comunicante com j, j também é comunicante com i.

Transitiva: Se i é comunicante com k e k é comunicante com j, então i é comunicante com j.

Dessa forma, os estados que são comunicantes com um determinado estado i ∈ E estão em uma

mesma classe de equivalência, que denota-se por i.

Se todos os estados de uma cadeia são comunicantes com um único estado, então todos

os estados pertencem à uma mesma classe de equivalência, e, neste caso, diz-se que a cadeia é

irredutível.

Exemplo 3.3 Um jogador tem R$5, 00 e a cada vez que ele joga, ganha R$5, 00 com proba-

bilidade p > 0, ou perde R$5, 00 com probabilidade 1 − p. O jogo acaba quando o jogador

acumula R$15, 00 ou R$0, 00.

32

Observa-se que as possíveis quantias de dinheiro acumuladas pelo jogador a cada jogada são

R$0, 00, R$5, 00, R$10, 00 e R$15, 00, as quais serão associadas aos estados 1, 2, 3 e 4, respec-

tivamente. Dessa forma, o jogo pode ser visto como uma cadeia de Markov cujo conjunto de

estados é E = {1, 2, 3, 4}. Tem-se o esquema e a matriz de transição:

Figura 3.2 – Esquema com as probabilidades de transição entre os quatro estados

Fonte: Do autor (2020)

P =











1

1 − p

0

0

0 0

p 0

0

0

1 − p 0 p

0

0 1











De acordo com as deﬁnições anteriores, tem-se que o estado 4 é alcançável a partir do estado

3, mas não vale o contrário, isto é, o estado 3 não é alcançável a partir do estado 4. Portanto

os estados 3 e 4 não são comunicantes. Já os estados 2 e 3 são comunicantes. Os estados 1 e

4 são exemplos de estados absorventes, pois p11 = 1 e p44 = 1. Os estados 2 e 3 são exemplos

de estados transientes. Por ﬁm, existem três classes de equivalência nesta cadeia. São elas:

1 = {1}, 2 = {2, 3} e 4 = {4}.

Deﬁnição 3.2 Em uma cadeia de Markov, um conjunto não vazio C de estados é denominado

um conjunto fechado se o processo, ao assumir qualquer um de seus estados, permanecer

indeﬁnidamente nos estados pertencentes a C. Em outras palavras, C é um conjunto fechado

quando nenhum estado fora de C for alcançável a partir de qualquer estado de C. Logo, pode-

se aﬁrmar que C é um conjunto formado por estados recorrentes.

Voltando ao exemplo 3.3, além do conjunto fechado trivial E = {1, 2, 3, 4}, existem

somente dois conjuntos fechados: C1 = {1} e C2 = {4}.

33

3.3 Cadeias de Markov absorventes

Apresenta-se (GOLMAKANI, 2014) um tipo especial de cadeias de Markov.

Deﬁnição 3.3 Uma cadeia de Markov é dita absorvente, se nela existe pelo menos um estado

absorvente e, a partir de qualquer estado, é possível atingir algum estado absorvente, não

necessariamente em um passo. Em particular, não existem estados recorrentes em uma cadeia

absorvente.

Considere

uma

cadeia

de Markov

absorvente

com conjunto

de

estados

E = {1, 2, · · · , k} e matriz de transição (cid:98)P. Suponha que existam r estados absorventes e t estados

transientes, então k = r + t. Reordenando os estados de E de forma que os estados absorventes

sejam os últimos, determina-se P, matriz de transição canônica que tem a seguinte forma:

P =





Qt×t Rt×r

Or×t

Ir×r



 ,

sendo a matriz Or×t a matriz nula e Ir×r a matriz identidade. A matriz Q está relacionada com os

estados transientes, ou seja, ela traz as probabilidades de transição entre os estados transientes.

Além disso, é possível demonstrar que a matriz de transição em n passos é da forma:





Pn =

Qn

∗

Or×t

Ir×r



 ,

sendo Qn a n-ésima potência da matriz Qt×t que aparece em P e ∗ indica uma matriz de ordem

t × r que depende de Qt×t e Rt×r, porém não é apresentada aqui devido a sua complexidade.

Teorema 3.2 Quando n → +∞, a matriz de transição em n passos Pn converge para a matriz

P, sendo



P =



Ot×t

(I − Q)−1R

Or×t

Ir×r



 ,

que é denominada matriz de transição estável da cadeia absorvente. As entradas ni j da matriz
N = (I − Q)−1 representam o número esperado de vezes que o processo assume o estado tran-

siente j, dado que ele tenha iniciado no estado transiente i, antes do processo ser absorvido. A

matriz N é denominada matriz fundamental de P.

34

Tem-se do teorema, que limn→+∞ Qn = 0, ou seja, as probabilidades de transição entre

os estados transientes são muito pequenas, quando n é suﬁcientemente grande. Dessa forma,

o processo será absorvido pelos estados absorventes, para n suﬁcientemente grande. As en-

tradas da matriz P representam os valores limites para as probabilidades de transição para n

suﬁcientemente grande (NORRIS, 1997).

Tem-se um exemplo para melhor compreensão.

Exemplo 3.4 Considere uma cadeia de Markov cuja matriz de transição é dada por

(cid:98)P =

0, 25














1

0

0

0

0

0

0

0, 75

0

0

0, 5

0

0, 5

0

0

0

0

0

0, 7

0

0

0

0, 3

1














.

O diagrama abaixo contém as probabilidades de transições entre os cinco estados do conjunto

E = {1, 2, 3, 4, 5}.

Figura 3.3 – Esquema com as probabilidades de transições entre os estados de E

Fonte: Do autor (2020)

Reordenando o conjunto de estados de forma que os estados absorventes 1 e 5 sejam os

dois últimos 4(cid:48) = 1 e 5(cid:48) = 5 tem-se uma nova matriz de transição P.

P =














0

0,75

0

0,25

0,5

0

0,5

0

0

0

0,7

0

0

0

0

0

0

0

1

0














0

0

0,3

0

1

Figura 3.4 – Nova reordenação dos estados de E = {1(cid:48), 2(cid:48), 3(cid:48), 4(cid:48), 5(cid:48)}

35

Fonte: Do autor (2020)

Logo, com alguns arredondamentos naturais, tem-se que

Isso indica que, por exemplo, iniciando no estado 1(cid:48) = 2, o número esperado de vezes

que o sistema permanece nos estados 1(cid:48) = 2, 2(cid:48) = 3 e 3(cid:48) = 4 será 2, 3 e 1, respectivamente,

fazendo os arredondamentos.

A matriz de transição estável P é dada por:

2, 4 2, 7 1, 4

N = (I − Q)−1 =

1, 8 3, 6 1, 8

1, 3 2, 5 2, 3








.

P =














0

0

0

0

0

0

0

0

0

0














,

0,6

0,4

0,5

0,5

0,3

0,7

1

0

0

1








0

0

0

0

0








·

pois

(I − Q)−1R =








2, 4 2, 7 1, 4

0, 25

1, 8 3, 6 1, 8

1, 3 2, 5 2, 3








0

0








0

0

0, 3

=








0, 6 0, 4

0, 5 0, 5

0, 3 0, 7








.

se a cadeia iniciar no estado 2(cid:48) = 3,
Dessa forma, por exemplo,
−→v0 = (0, 1, 0, 0, 0). As probabilidades de absorção dos estados absorventes serão:

considera-se

36

−→v = −→v0 · P =

(cid:104)
0 1 0 0 0

(cid:105)

·














0 0 0 0, 6 0, 4

0 0 0 0, 5 0, 5

0 0 0 0, 3 0, 7

0 0 0

0 0 0

1

0

0

1














(cid:105)
(cid:104)
0 0 0 0, 5 0, 5

.

=

Logo, ambos os estados absorventes 4(cid:48) = 1 e 5(cid:48) = 5 têm a mesma probabilidade de absorção de

50%.

Por sua vez, se a cadeia iniciar no estado 1(cid:48) = 2, o estado absorvente 4(cid:48) = 1 terá 60% de

probabilidade de absorver o processo e o estado absorvente 5(cid:48) = 5 terá 40% de probabilidade

de absorver o processo.

Finalmente, se a cadeia iniciar no estado 3(cid:48) = 4, o estado absorvente 4(cid:48) = 1 terá so-

mente 30% de probabilidade de absorver o processo e o estado absorvente 5(cid:48) = 5 terá 70% de

probabilidade de absorver o processo.

Apresenta-se um último resultado para as cadeias absorventes.

Teorema 3.3 (Tempo necessário para a absorção da cadeia) Se uma cadeia absorvente iniciar

no estado i ∈ E, então o número esperado de passos ti antes dela ser absorvida é igual a i-ésima
entrada da matriz coluna T = (I − Q)−1 ·C, sendo C a matriz coluna com todas entradas iguais

a 1.

De acordo com o Teorema 3.2, a entrada ni j da matriz N = (I − Q)−1 é o número es-

perado de vezes que o estado j é assumido pela cadeia, tendo esta iniciado no estado i, antes

dela ser absorvida. Portanto a soma dos elementos de uma linha da matriz N = (I − Q)−1 será

o número esperado de passos antes da cadeia ser absorvida. O fato de multiplicar N pela matriz

coluna C, cujas entradas são todas iguais a 1, equivale a efetuar a soma dos elementos de cada

linha de N.

Para a cadeia absorvente do Exemplo 3.4, tem-se

T = (I − Q)−1 ·C = N ·C

1, 8 3, 6 1, 8








2, 4 2, 7 1, 4

1, 3 2, 5 2, 3
















1


1


1

·

=








6, 5

7, 2

.








6, 1

37

Assim, se a cadeia iniciar no estado 1(cid:48) = 2, o número esperado de passos antes dela ser

absorvida é 6. Se, por sua vez, ela iniciar no estado 2(cid:48), o número esperado de passos é igual a

7. Por ﬁm, se ela iniciar no estado 3(cid:48) = 4, o número esperado de passos é 6.

3.4 Cadeias de Markov regulares

Nesta seção, é apresentado um outro tipo especial de cadeias de Markov, as cadeias de

Markov regulares.

Deﬁnição 3.4 Considere uma cadeia de Markov com matriz de transição P. Se alguma potên-

cia da matriz P tiver todas as entradas positivas, diz-se que a cadeia é regular.

Tem-se o importante resultado válido para cadeias regulares (NORRIS, 1997).

Teorema 3.4 Considere uma cadeia de Markov regular com matriz de transição P. Então:

i) lim
n→∞

Pn = P.

ii) As linhas da matriz P são todas iguais e podem ser representadas por um vetor-linha

(cid:104)

−→v =

p1 p2

· · · pr

(cid:105)

,

com pi > 0, para todo 1 ≤ i ≤ r.

iii) Dado um vetor de probabilidade −→v0 , então lim

n→∞

−→v0 Pn = −→v , sendo −→v deﬁnido no item

anterior.

iv) O vetor −→v é o único vetor que satisfaz −→v = −→v P. O vetor de probabilidade de estado −→v

é chamado de estado estável da cadeia regular.

Observe que o vetor de probabilidade de estado −→v é ﬁxado pela matriz P. Dessa forma, −→v Pn =
−→v , para todo n inteiro positivo.

Tem-se um exemplo para melhor compreensão.

Exemplo 3.5 Em uma determinada região, observa-se que, quando chove bastante durante um

ano, a probabilidade de que chova bastante no ano seguinte é de 25%, e que a probabilidade de

que faça seca é de 75%. Ainda, se houver seca em um ano, no ano seguinte as probabilidades

de haver seca ou chuva são iguais a 50%. Suponha que estas probabilidades não mudem com

38

o decorrer do tempo. Estude o comportamento das probabilidades para seca e para chuva a

longo prazo.

Considerando o conjunto de estados E = {1, 2}, sendo 1 o estado ’chuva’ e 2 o estado

’seca’, tem-se a matriz de transição P:





P =



 .

0, 25 0, 75

0, 5

0, 5

Como todas as entradas da matriz P são postivivas, pode-se concluir que a cadeia de Markov

resultante é regular. Portanto, são válidos os resultados do Teorema 3.4. Calcula-se o vetor
estável −→v do processo. Para isso resolve-se a equação matricial −→v = −→v · P.

(cid:104)

(cid:105)

·

p1 p2





0, 25 0, 75

0, 5

0, 5



(cid:104)

(cid:105)

.

p1 p2

 =

Que dá origem ao sistema linear homogêneo




0, 25p1 + 0, 5p2 = p1



0, 75p1 + 0, 5p2 = p2

cujas soluções são p2 = 1, 5p1. Como p1 + p2 = 1, segue que p1 = 0, 4 e p2 = 0, 6. Logo
−→v =

(cid:104)
0, 4 0, 6

(cid:105)
.

Assim, a longo prazo, a probabilidade de se ter um ano com muita chuva é 40%, en-

quanto que a probabilidade de um ano com seca é 60%, ou seja, o clima na região tenderá a

uma ligeira aridez com o passar do tempo.

39

4 UMA SEQUÊNCIA DIDÁTICA SOBRE CADEIAS DE MARKOV PARA O ENSINO

MÉDIO

O presente capítulo traz uma proposta de sequência didática sobre uma introdução de

cadeias de Markov, indicada para os alunos do 2◦ ano do Ensino Médio, visto que os conteúdos

de matrizes e probabilidade são pré-requisitos para tal tema. As cadeias de Markov podem

ser aplicadas a diversos contextos nas ciências, dessa forma, seu estudo permite um ensino-

aprendizagem interdisciplinar da Matemática, além de despertar a curiosidade dos estudantes.

Esta sequência didática inicia-se com um exemplo introdutório, que deve ser explicado

aos estudantes, cujo objetivo é introduzir o conceito de matriz de transição de cadeias de Mar-

kov. Na sequência tem-se quatro problemas aplicados que seguem a linha de raciocínio do

exemplo para serem resolvidos pelos estudantes. Os comentários e as resoluções que acompa-

nham cada problema devem ser obviamente omitidos aos estudantes no momento da aplicação

das atividades, e estão aqui para dar suporte ao professor. Estima-se que o tempo necessário

para a realização das atividades seja de duas horas-aulas (100 minutos).

As atividades trabalham conceitos de probabilidade, eventos independentes, cálculo de

probabilidades não triviais e o conceito de matriz de transição, proveniente do estudo de cadeias

de Markov.

De forma superﬁcial, pode-se dizer que uma cadeia de Markov é um processo aleatório

que satisfaz a propriedade de Markov, que é caracterizada por previsões para estados futu-

ros com base somente no estado presente (atual), ou seja, independente do que aconteceu no

passado. Em outras palavras, as evoluções futuras dependem apenas do estado presente. Por

exemplo, a sequência dos saldos mensais de uma conta poupança pode ser considerada uma

cadeia de Markov, pois o saldo no mês seguinte depende apenas do saldo no mês atual e não

dos saldos em meses anteriores. A seguir tem-se um exemplo para compreensão e visualização

dos estados possíveis com suas probabilidades de transição de um estado para outro.

Exemplo 4.1 Em um jogo, onde não é possível a ocorrência de empate, foram observados

alguns dados para um determinado time. Se o time obteve uma vitória no jogo atual, a chance

de vitória no próximo jogo é de 75%. Todavia, se no jogo atual ocorreu uma derrota, a chance

de vitória no próximo jogo é de 35%.

A Tabela a seguir apresenta tais informações:

40

Tabela 4.1 – Probabilidades de vitória ou derrota para um determinado time.

Vitória no

Derrota no

Próximo Jogo Próximo Jogo

Vitória no Jogo Atual
Derrota no Jogo Atual

75%
35%

25%
65%

Essa situação pode ser modelada através de uma cadeia de Markov com dois estados

possíveis, E = {1, 2}, sendo o estado 1 indicando a vitória do time e 2 indicando a derrota.

Tem-se o diagrama:

Figura 4.1 – Esquema com as probabilidades de transição entre os dois estados do sistema

Fonte: Do autor (2020)

Interpreta-se o diagrama da seguinte forma:

• o número p11 signiﬁca a probabilidade do time vencer o jogo seguinte, tendo vencido o

jogo atual. Em outras palavras, o número p11 representa a probabilidade do time perma-

necer no estado de vencedor.

• o número p12 signiﬁca a probabilidade do time perder o jogo seguinte, tendo vencido o

jogo atual. Em outras palavras, o número p12 representa a probabilidade do time ir do

estado de vencedor para o estado de perdedor.

• o número p21 signiﬁca a probabilidade do time vencer o jogo seguinte, tendo perdido o

jogo atual. Em outras palavras, o número p21 representa a probabilidade do time ir do

estado de perdedor para o estado de vencedor.

• o número p22 signiﬁca a probabilidade do time perder o jogo seguinte, tendo perdido o

jogo atual. Em outras palavras, o número p22 representa a probabilidade do time perma-

necer no estado de perdedor.

41

De forma geral, diz-se que o número pi j é a probabilidade de transição do estado i para o estado

j, sendo i = 1, 2 e j = 1, 2.

Observe que as probabilidades p11 e p12 devem ter soma igual a 1, pois tendo o time

ganhado o jogo atual, as únicas possibilidades para o jogo seguinte é vencer ou perder, uma vez

que não é possível o empate nesse tipo de jogo, como foi mencionado no enunciado. Se a proba-

bilidade de vencer o jogo seguinte, tendo vencido o jogo atual, é de 75%, então a probabilidade

do time perder é de 25%, sabendo que o time vem de uma vitória. Ou seja, 75% + 25% = 100%.

O mesmo pode ser observado para as probabilidades p21 e p22.

Com as informações fornecidas tem-se as probabilidades de transição através de uma

matriz quadrada denominada matriz de transição:

P =





p11 p12

p21 p22



 =





0, 75 0, 25

0, 35 0, 65



 ,

sendo que as entradas da primeira linha da matriz representam as probabilidades para os dois

estados (resultados) possíveis após um jogo vitorioso. Da mesma forma, as entradas da segunda

linha representam as probabilidades para os dois estados possíveis após uma derrota.

O objetivo a seguir é responder à pergunta: qual é a probabilidade do time perder o

segundo jogo, sabendo que ele ganhou o jogo atual? Em outras palavras, qual é a probabi-

lidade do time ir para o estado 2 em duas unidades de tempo, partindo do estado 1. Denota-se
esta probabilidade por p(2)
12 .

Nesta situação, nota-se que se o time vence uma partida, então a probabilidade dele

perder o segundo jogo será a união disjunta de dois eventos:

i) Ele vence o próximo jogo e perde o segundo jogo;

ii) Ele perde o próximo jogo e também perde o segundo.

Em outras palavras, pode ocorrer uma das duas opções abaixo:

i) ganha

p11−→ ganha

p12−→ perde;

ii) ganha

p12−→ perde

p22−→ perde;

A probabilidade do primeiro evento desta lista ocorrer é o produto de duas probabilida-

des condicionais, p11 · p12, sendo p11 a probabilidade condicional dele vencer o jogo seguinte,

42

tendo vencido o jogo atual, e p12 a probabilidade condicional dele perder o jogo seguinte, tendo

vencido o jogo atual.

A probabilidade do segundo evento desta lista ocorrer é o produto de duas probabilidades

condicionais, p12 · p22, sendo p12 a probabilidade condicional dele perder o jogo seguinte, tendo

vencido o jogo atual, e p22 a probabilidade condicional dele perder o jogo seguinte, tendo

perdido o jogo atual. Portanto, a probabilidade do time perder o segundo jogo, tendo vencido o

jogo atual é a soma:

p(2)
12 = p11 · p12 + p12 · p22,

que é exatamente o elemento da matriz P2 = P · P que está na posição (1, 2), ou seja, na primeira

linha e segunda coluna.

P2 = P · P =





p11 p12

p21 p22





 ·



p11 p12

p21 p22



 =





p11 p11 + p12 p21 p11 p12 + p12 p22

p21 p11 + p22 p21 p21 p12 + p22 p22





P2 = P · P =





0, 75 0, 25

0, 75 0, 25

0, 65 0, 35



 =







 .



 ·





0, 35 0, 65

0, 35 0, 65

0, 49 0, 51

Assim, a probabilidade do time estar no estado 2 daqui a duas unidades de tempo, sabendo que

ele iniciou no estado 1, é de 35%. Em outras palavras, a probabilidade do time perder o segundo

jogo, tendo vencido o jogo atual, é de 35%.

Seguindo o exemplo acima, resolva o seguinte problema:

Problema 4.1 Qual é a probabilidade do time perder o terceiro jogo, sabendo que ele ganhou

o jogo atual? Em outras palavras, qual é a probabilidade do time ir para o estado 2 em três
unidades de tempo, partindo do estado 1. Denota-se esta probabilidade por p(3)
12 .

Figura 4.2 – Situação do Problema 4.1

Fonte: Do autor (2020)

Comentário

Espera-se que os alunos listem todas as 4 situações possíveis a seguir:

43

i) ganha

p11−→ ganha

p11−→ ganha

p12−→ perde;

ii) ganha

p11−→ ganha

p12−→ perde

p22−→ perde;

iii) ganha

p12−→ perde

p21−→ ganha

p12−→ perde;

iv) ganha

p12−→ perde

p22−→ perde

p22−→ perde;

Usando um raciocício análogo ao exemplo anterior, tem-se que a probabilidade dele

perder o terceiro jogo, tendo vencido o jogo atual, será a união disjunta dos quatros eventos

listados acima.

A probabilidade do primeiro evento desta lista ocorrer é o produto de três probabilidades

condicionais, p11 · p11 · p12, sendo p11 a probabilidade do time continuar no estado de vencedor,

isto é, vencer dois jogos consecutivos, e p12 a probabilidade do time perder um jogo depois

de alcançar uma vitória. A probabilidade dos outros três eventos seguem de forma análoga.

Portanto a probabilidade requerida é a soma das quatro probabilidades:

p(3)
12 = p11 · p11 · p12 + p11 · p12 · p22 + p12 · p21 · p12 + p12 · p22 · p22 =

= 0, 75 · 0, 75 · 0, 25 + 0, 75 · 0, 25 · 0, 65 + 0, 25 · 0, 35 · 0, 25 + 0, 25 · 0, 65 · 0, 65 = 0, 39.

Os alunos podem não perceber que tal expressão corresponde ao elemento na posição (1, 2)

(primeira linha e segunda coluna) da matriz P3 = P · P · P. Com a ajuda de uma calculadora

ou de um software eles podem calcular a matriz P3 e comparar tal elemento com o valor 0, 39

encontrado. Portanto, a resposta do problema é 39%.

Problema 4.2 Suponha que em um determinado município, a cada ano, 3% da população da

zona rural migra para a zona urbana, enquanto que apenas 1% da população da zona urbana

migra para a zona rural. Se estas porcentagens de migração não se alterarem anualmente, qual

será a porcentagem da população rural que migrará para a zona urbana após dois anos? Em
outras palavras, qual é o valor de p(2)

21 ? Encontre a matriz de transição P deste processo.

Comentário

Espera-se que os alunos entendam a existência de dois estados possíveis, já que um

habitante do município pode morar na zona urbana (U) ou na zona rutal (R). Indica-se a zona

urbana por estado 1 e a zona rural por estado 2, ou vice-versa. Observa-se o esquema e a tabela

com as informações do problema.

Figura 4.3 – Esquema de migração entre as zonas urbana (U) e rural (R) do município

44

Fonte: Do autor (2020)

Tabela 4.2 – Porcentagens de migração entre as zonas urbana e rural do município.

Zona Urbana Zona Rural

Zona Urbana
Zona Rural

99%
3%

1%
97%

A matriz de transição com as porcentagens de mudanças entre os estados 1 (U) e 2(R) é

dada por:

P =





p11 p12

p21 p22



 =







 .

0, 99 0, 01

0, 03 0, 97

Para este problema, tem-se as duas situações possíveis:

i) meio rural

p22−→ meio rural

p21−→ meio urbano;

ii) meio rural

p21−→ meio urbano

p11−→ meio urbano;

A primeira situação representa o indivíduo que se muda para a cidade no segundo ano. A

segunda situação representa o indivíduo que se muda para a cidade no primeiro ano.

Assim, a porcentagem da população rural que migra para o meio urbano em dois anos

será a soma:

p22 · p21 + p21 · p11 = 0, 97 · 0, 03 + 0, 03 · 0, 99 = 0, 03 · 1, 96 = 0, 0588.

Portanto 5, 88% da população rural migrará para a cidade em dois anos.

Outra possível solução seria calcular a matriz P2 com a utilização de uma calculadora

ou de um software e veriﬁcar o valor correspondente ao elemento na posição (2, 1) (segunda

linha e primeira coluna).

45





P2 =

0, 99 0, 01

0, 99 0, 01

0, 9804 0, 0196





 ·







 =



0, 03 0, 97

0, 03 0, 97

0, 0588 0, 9412





Assim, aproximadamente 6% da população rural terá migrado para a cidade no período de dois

anos.

Problema 4.3 A população de um país é dividida em três classes sociais: alta (A), média (M) e

baixa (B). Um estudo estatístico mostra que a probabilidade dos ﬁlhos de uma família de classe

alta permanecerem nesta classe é de 90%. Entretanto, há uma chance de 10% deles irem para

a classe média. O mesmo estudo aponta que os ﬁlhos de uma família de classe média têm 10%

de chance de irem para a classe alta e 30% de chance de irem para a classe baixa. Por ﬁm,

os ﬁlhos de uma família de classe baixa têm 20% de chance de irem para a classe média e

75% de chance de permanecerem na classe baixa. De acordo com essas informações, qual a

probabilidade dos netos de uma família de classe média irem para a classe alta?

Comentário

Espera-se que os alunos identiﬁquem os três possíveis estados - classe alta (A), classe

média (M) e classe baixa (B) - e suas respectivas probabilidades de transição. Tais informações

são descritas no esquema e na tabela abaixo, onde os estados 1, 2 e 3 representam as classes A,

B e C, respectivamente.

A matriz de transição com as probabilidades de mudanças entre as classes A, M e B é

dada por:

P =








p11 p12 p13

p21 p22 p23

p31 p32 p33








=








0, 9

0, 1

0, 1

0, 6

0

0, 3

0, 05 0, 2 0, 75








.

Observa-se que os ﬁlhos podem ocupar qualquer uma das três classes, contanto que

os pais e os netos pertençam às classes M e A, respectivamente. Assim, existe três situações

possíveis:

i) classe M

p21−→ classe A

p11−→ classe A;

ii) classe M

p22−→ classe M

p21−→ classe A;

Figura 4.4 – Esquema com as probabilidades de transição entre as três classes sociais

46

Fonte: Do autor (2020)

Tabela 4.3 – Probabilidades de transição entre as classes A, M e B da próxima geração.

Classe A
Classe M
Classe B

Classe A Classe M Classe B
10%
60%
20%

90%
10%
5%

0%
30%
75%

Figura 4.5 – Situação do Problema 4.3

Fonte: Do autor (2020)

iii) classe M

p23−→ classe B

p31−→ classe A;

O primeiro evento representa os ﬁlhos do casal de classe média que foram para a classe

alta. O segundo evento representa os ﬁlhos do casal de classe média que continuaram na classe

média. Por ﬁm, o terceiro evento representa os ﬁlhos do casal de classe média que foram para a

classe baixa. A probabilidade a ser calculada será a soma das probabilidades destes três eventos

47

independentes:

p21 · p11 + p22 · p21 + p23 · p31 = 0, 1 · 0, 9 + 0, 6 · 0, 1 + 0, 3 · 0, 05 = 0, 165.

Portanto, a probabilidade dos netos de uma família de classe média irem para a classe alta é de

16, 5%.

Uma solução alternativa seria calcular P2 com a utilização de uma calculadora ou de um

software e veriﬁcar o elemento na posição (2, 1), isto é, que ocupa a segunda linha e primeira

coluna.



P2 =






0, 9

0, 1

0, 1

0, 6

0

0, 3

0, 9

0, 1

0, 1

0, 6

0

0, 3

0, 82

0, 15

0, 03

0, 165

0, 43

0, 405

0, 05 0, 2 0, 75

0, 05 0, 2 0, 75

0, 1025 0, 275 0, 6225








=

















·













.

Observa-se que o elemento na posição (2, 1) é 0, 165, que representa 16, 5% de probabilidade

de uma família de classe média ter netos na classe alta.

Problema 4.4 Um determinado fruto tem sua safra classiﬁcada em três modalidades: boa,

média e ruim. Estudos revelam que, após uma safra boa, há probabilidades iguais a 50%

e 10% de a próxima safra ser média ou ruim, respectivamente. Após uma safra média, há

probabilidades iguais a 40% e 10% de a próxima safra ser boa ou ruim, respectivamente. E

após uma safra ruim, há probabilidades iguais a 30% e 60% de a safra no ano seguinte ser boa

ou média, respectivamente. Com base nestas informações, qual é a probabilidade da safra ser

boa daqui a dois anos, sabendo que ela foi ruim neste ano? Monte a matriz de transição.

Comentário

Espera-se que os alunos associem os três tipos de safra - boa(B), média (M) e ruim (R) -

aos estados E = {1, 2, 3}. Tem-se pela ordem descrita, a seguinte matriz de transição e situação

do problema:

P =








p11 p12 p13

p21 p22 p23

p31 p32 p33








=








0, 4 0, 5 0, 1

0, 4 0, 5 0, 1

0, 3 0, 6 0, 1








.

Dependendo da safra do ano seguinte, tem-se as três possibilidades:

i) safra ruim

p31−→ safra boa

p11−→ safra boa;

Figura 4.6 – Esquema com as probabilidades de transição entre os três tipos de safra

48

Fonte: Do autor (2020)

Figura 4.7 – Situação do Problema 4.4

Fonte: Do autor (2020)

ii) safra ruim

p32−→ safra média

p21−→ safra boa;

iii) safra ruim

p33−→ safra ruim

p31−→ safra boa.

Nos eventos listados acima, nota-se que a safra do ano atual e a safra do segundo ano

são, respectivamente, ruim e boa, isso implica que as variações de eventos estão exclusivamente

vinculadas ao primeiro ano ou ano seguinte. Assim, a probabilidade a ser calculada será a soma

das probabilidades destes três eventos independentes:

p31 · p11 + p32 · p21 + p33 · p31 = 0, 3 · 0, 4 + 0, 6 · 0, 4 + 0, 1 · 0, 3 = 0, 39.

É possível ainda, através da utilização de uma calculadora ou de um software, veriﬁcar o ele-

mento na posição (3, 1), da matriz P2.

49

0, 4 0, 5 0, 1

0, 4 0, 5 0, 1

0, 39 0, 51 0, 1

P2 =

0, 4 0, 5 0, 1

0, 4 0, 5 0, 1

=

0, 39 0, 51 0, 1

0, 3 0, 6 0, 1

0, 3 0, 6 0, 1

0, 39 0, 51 0, 1






















·






















.

Portanto, a probabilidade da safra ser boa no segundo ano, tendo uma safra atual ruim, é de

39%.

Este último problema é bem interessante, pois traz um exemplo de uma cadeia regular,

que pode ser conﬁrmado ao observar as colunas constantes da matriz P2. Quando tem-se uma

cadeia regular, a partir de um certo tempo, a probabilidade do processo estar em determinado

estado independente da estado inicial. No Problema 4.4, após dois anos, a probabilidade de se

ter uma boa safra, por exemplo, é de 39%, independentemente do tipo de safra do ano atual. O

mesmo vale para as probabilidades de uma safra ruim e de uma safra média.

50

CONSIDERAÇÕES FINAIS

O presente trabalho apresenta um estudo introdutório sobre processos estocásticos, em

especial, sobre as cadeias de Markov. Tal estudo foi realizado com o intuito de ampliar e me-

lhorar a formação matemática do professor, possibilitando a visualização de várias aplicações

em que as cadeias de Markov são utilizadas.

Com o objetivo de levar parte desse estudo para o Ensino Médio, elaborou-se uma pro-

posta de sequência didática com quatro problemas aplicados envolvendo conceitos iniciais de

cadeias de Markov com dois e três estados. Visto que os conteúdos de matrizes e probabilidade

são pré-requisitos para tal tema, o foco dos problemas foi o cálculo de algumas probabilidades

não triviais e a construção da matriz de transição da cadeia.

Finalizando, o autor acredita que tal proposta possa incentivar o interesse dos estudan-

tes pela Matemática, em especial, pelo estudo de probabilidade, uma vez que os problemas

apresentados envolvem aplicações na vida cotidiana.

REFERÊNCIAS

51

BOLDRINI, J. L. e. a. Algebra Linear. 3. ed. São Paulo: Harbra, 1986.

CLARKE A. BRUCE, D. R. L. Probabilidade e Processos Estocásticos. Rio de Janeiro: LTC,
1979.

EVES, H. Introdução a História da Matemática. Campinas: Editora UNICAMP, 2004.

GOLMAKANI, A. e. a. Cadeias de markov. VII Bienal da Sociedade Brasileira de Matemá-
tica, 2014.

LEVIN, D. A. Markov chains and mixing times. [S.l.]: American Mathematical Soc., 2009.

MORGADO, e. a. Análise Combinatória e Probabilidade. Rio de Janeiro: SBM, 2006.

NORRIS, J. Markov Chains. Cambridge University Press: Cambridge Series in Statistical and
Probabilistic Mathematics, 1997.

SILVA, M. N. P. d. Historia da probabilidade. Brasil Escola, 2020.

SOARES J. F., S. A. L. Introducão à Estatística Médica. Belo Horizonte: Coopmed, 2002.


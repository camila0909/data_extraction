UNIVERSIDADE DO ESTADO DE SANTA CATARINA â€“ UDESC 
CENTRO DE CIÃŠNCIAS TECNOLÃ“GICAS - CTT 
PROGRAMA DE PÃ“S GRADUAÃ‡ÃƒO PROFISSIONAL EM MATEMÃTICA EM REDE NACIONAL 

DISSERTAÃ‡ÃƒO DE MESTRADO 

ANÃLISE DE UM SIMULADO DE MATEMÃTICA 
UTILIZANDO A TEORIA DE RESPOSTA AO ITEM E 
A TEORIA CLÃSSICA DOS TESTES 

MARCOS ELIAS NUNES 

JOINVILLE, 2018 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ANÃLISE DE UM SIMULADO DE MATEMÃTICA UTILIZANDO A TEORIA DE 
RESPOSTA AO ITEM E A TEORIA CLÃSSICA DOS TESTES 

DissertaÃ§Ã£o submetida ao Programa de  
Mestrado Profissional em MatemÃ¡tica 
para obtenÃ§Ã£o do grau de mestre. 
Universidade do Estado de Santa Catarina. 
Orientadora: Profa. Dra. Elisa Henning 

Joinville 

2018 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Este trabalho Ã© dedicado... 
Aos meus pais: Manoel de Souza Nunes e Pedra Elias Nunes pelos valores ensinados com muito 
amor e dedicaÃ§Ã£o; 
As minhas irmÃ£s:Cristiane Elias Nunes, Cristina Elias Nunes e Gisele Elias Nunes por serem 
exemplos de honestidade e competÃªncia; 
A minha esposa: Rejeane de Lima por permanecer ao meu lado em todos os momentos, sejam 
eles bons ou ruins. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
Agradecimentos 

A Deus, Ã  minha famÃ­lia e Ã  minha esposa; A todos os meus amigos que me ajudam a manter 

o  equilÃ­brio  emocional;    Aos  meus  colegas  do  PROFMAT  pelo  auxÃ­lio  nos  momentos  de 

dificuldade  e  descontraÃ§Ã£o  nos  momentos  de  mais  tensÃ£o;  A  professora  Elisa  Henning,  pela 

dedicaÃ§Ã£o e competÃªncia ao me auxiliar em todas as etapas deste trabalho; Aos demais professores 

da  UDESC  pelo  aprendizado  proporcionado;  As  professoras  AndrÃ©a  Cristina  e  Regina  Helena 

Munhoz pelas consideraÃ§Ãµes que auxiliaram na finalizaÃ§Ã£o desta dissertaÃ§Ã£o; A esta universidade 

pela oportunidade de crescimento profissional e pessoal;     

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Resumo 

A  aplicaÃ§Ã£o  de  simulados  Ã©  uma  prÃ¡tica  comum  quando  se  deseja  avaliar  um  grupo  de 

estudantes. PorÃ©m, para que os resultados apresentados sejam vÃ¡lidos, Ã© necessÃ¡rio que os itens 

que  compÃµem  o  simulado  sejam  capazes  de  discriminar  os  participantes  que  possuem  as 

habilidades  que estÃ£o sendo medidas  dos estudantes que nÃ£o possuem. Desta forma, o presente 

trabalho se propÃ´s a analisar a qualidade dos itens de um simulado de MatemÃ¡tica aplicado na rede 

municipal  de  educaÃ§Ã£o  de  JaraguÃ¡  do  Sul.  Esta  anÃ¡lise  foi  feita  utilizando  e  comparando  os 

resultados da Teoria ClÃ¡ssica dos Testes (TCT) e da Teoria de Resposta ao Item (TRI). Concluiu-

se que a maior parte dos itens necessita de revisÃ£o. Os resultados obtidos com as anÃ¡lises da TCT 

e da TRI foram confrontados, garantindo uma maior fidedignidade nas conclusÃµes sobre os itens. 

Os resultados das duas teorias apresentaram divergÃªncias em relaÃ§Ã£o aos itens com maior poder de 

discriminaÃ§Ã£o. Por outro lado, o item considerado mais difÃ­cil do teste foi o mesmo nas duas teorias. 

AlÃ©m disso, foi realizada uma anÃ¡lise pedagÃ³gica nos itens considerados deficientes, com o intuito 

de contribuir com  futuros trabalhos  similares. Algumas sugestÃµes de alteraÃ§Ã£o no enunciado da 

questÃ£o e das alternativas foram feitas neste trabalho. 

Palavras-chave: Teoria ClÃ¡ssica dos Testes. Teoria de Resposta ao Item. MatemÃ¡tica. AvaliaÃ§Ã£o. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Abstract 

The  application  of  simulation  is  a  common  disease  when  one  has  a  diagnosis  about  a 

certain population. However, for results to be displayed, performance criteria need to be able to 

discriminate participants who possess skills that can be done by students who do not. In this way, 

the  present  work  has  properly  an  analysis  of  the  results  of  a  mathematical  questionnaire  in  the 

municipal  education  network  of  JaraguÃ¡  do  Sul.  This  research  was  done  using  the  results  of 

Classical Theory of Tests (CTT) and Item Response Theory (IRT). It was concluded that a larger 

part  of  the  items  needed  for  revision.  The  results  of  the  CTT  and  IRT  tests  were  confronted, 

guaranteeing greater reliability in the conclusions about the items. The data of the two historical 

series divergences in relation to the items with greater power of discrimination. On the other hand, 

the item was more difficult to apply in both theories. In addition, a pedagogical analysis was set up 

in the following previous issues, to achieve the next similar works. Some suggestions for change 

do not address the issue and the alternatives are made in this work. 

Key-words: Classical Theory of Tests. Item Response Theory. Mathematics. Assessment. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Lista de Figuras 

Figura 3.1 - Curva CaracterÃ­stica do Item - CCI ........................................................................... 32 

Figura 3.2 - ComparaÃ§Ã£o das CCIs de itens com diferentes nÃ­veis de dificuldade e mesma 

probabilidade de acerto ao acaso. .................................................................................................. 34 

Figura 3.3 - Exemplo da aplicaÃ§Ã£o do mÃ©todo scree-plot ............................................................. 38 

Figura 5.1 - LocalizaÃ§Ã£o do municÃ­pio de JaraguÃ¡ do Sul ............................................................. 44 

Figura 5.2 - VI Feira Municipal de EducaÃ§Ã£o MatemÃ¡tica de JaraguÃ¡ do Sul, e Feira Municipal 

CientÃ­fica e TecnolÃ³gica (FECITEC) 2017 ................................................................................... 45 

Figura 5.3 - AnÃ¡lises realizadas ..................................................................................................... 46 

Figura 6.1 - Histograma das notas dos alunos ............................................................................... 48 

Figura 6.2 - GrÃ¡fico scree-plot da prova JaraguÃ¡ .......................................................................... 51 

Figura 6.3 - CCIs considerando V2 = item 1 e assim sucessivamente atÃ© V11 = item 10. ........... 57 

Figura 6.4 - FunÃ§Ã£o de informaÃ§Ã£o de cada item. ......................................................................... 58 

Figura 6.5 - FunÃ§Ã£o de informaÃ§Ã£o dos 10 itens............................................................................ 59 

Figura 6.6 - Curvas de InformaÃ§Ã£o do Teste e Erro PadrÃ£o .......................................................... 59 

Figura 6.7 - ClassificaÃ§Ã£o dos itens por nÃ­vel de dificuldade ........................................................ 60 

Figura 6.8 - FunÃ§Ã£o de informaÃ§Ã£o do item 4................................................................................ 61 

Figura 6.9 - FunÃ§Ã£o de informaÃ§Ã£o do item 3................................................................................ 62 

Figura 8.1 - QuestÃ£o aplicada em uma prova de matemÃ¡tica ........................................................ 70 

 
 
 
 
 
 
 
 
 
 
Lista de Tabelas 

Tabela 2.1 - ClassificaÃ§Ã£o do item do teste, por nÃ­vel do Ã­ndice de discriminaÃ§Ã£o ....................... 28 

Tabela 2.2 - ClassificaÃ§Ã£o e percentual esperado para os Ã­ndices de dificuldade da TCT ............ 29 

Tabela 3.1 - ClassificaÃ§Ã£o e percentual esperado para os Ã­ndices de dificuldade da TRI ............. 34 

Tabela 3.2 - ClassificaÃ§Ã£o do item de acordo com a discriminaÃ§Ã£o pela TRI. .............................. 35 

Tabela 6.1 - FrequÃªncia das pontuaÃ§Ãµes totais .............................................................................. 47 

Tabela 6.2 - ProporÃ§Ãµes para cada nÃ­vel de resposta. .................................................................... 47 

Tabela 6.3 - Outras estatÃ­sticas descritivas .................................................................................... 48 

Tabela 6.4 - ConsequÃªncia no valor do alfa de Cronbach com a exclusÃ£o de cada item do teste. 49 

Tabela 6.5 - CorrelaÃ§Ã£o ponto-bisserial. ........................................................................................ 50 

Tabela 6.6 - CorrelaÃ§Ã£o Ponto Bisserial com Escores Total ......................................................... 50 

Tabela 6.7 - Cargas fatoriais .......................................................................................................... 51 

Tabela 6.8 - Itens da prova JaraguÃ¡ na escala de dificuldade da TCT .......................................... 52 

Tabela 6.9 - ParÃ¢metro de discriminaÃ§Ã£o dos itens da prova JaraguÃ¡ ........................................... 53 

Tabela 6.10 - ParÃ¢metro de dificuldade - TRI ............................................................................... 55 

Tabela 6.11 - ClassificaÃ§Ã£o dos itens em relaÃ§Ã£o ao nÃ­vel de dificuldade â€“ TRI .......................... 55 

Tabela 6.12 - DiscriminaÃ§Ã£o dos itens - TRI ................................................................................. 56 

Tabela 6.13 - Acerto ao acaso ....................................................................................................... 56 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Lista de AbreviaÃ§Ãµes e Siglas 

CCI 

Curva CaracterÃ­stica do Item 

ENEM  

Exame Nacional do Ensino MÃ©dio 

ENADE 

Exame Nacional de Desempenho de Estudantes 

IBGE   

IDEB   

INEP   

ML1 

ML2 

ML3 

Instituto Brasileiro de Geografia e EstatÃ­stica 

Ãndice de Desenvolvimento da EducaÃ§Ã£o BÃ¡sica 

Instituto Nacional de Estudos e Pesquisas Educacionais AnÃ­sio Teixeira 

Modelo LogÃ­stico de um ParÃ¢metro 

Modelo LogÃ­stico de dois ParÃ¢metros 

Modelo LogÃ­stico de trÃªs ParÃ¢metros 

OBM   

OlimpÃ­ada Brasileira de MatemÃ¡tica 

OBMEP 

OlimpÃ­ada Brasileira de MatemÃ¡tica das Escolas PÃºblicas e Privadas 

OPA 

Oportunidade para Aprender 

SAEB   

Sistema de AvaliaÃ§Ã£o da EducaÃ§Ã£o BÃ¡sica 

SEMED 

Secretaria Municipal de EducaÃ§Ã£o 

TCT 

TRI 

Teoria ClÃ¡ssica dos Testes 

Teoria de Resposta ao Item 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
SumÃ¡rio 

1 

IntroduÃ§Ã£o ........................................................................................................................... 21 

2  A Teoria ClÃ¡ssica dos Testes .............................................................................................. 25 

2.1 AvaliaÃ§Ã£o .......................................................................................................................... 25 

2.1  DiscriminaÃ§Ã£o do Item ................................................................................................. 27 

2.2  Dificuldade do Item ..................................................................................................... 29 

3  A Teoria de Resposta ao Item............................................................................................. 30 

3.1  Modelos para itens dicotÃ´micos .................................................................................. 30 

3.2  Dificuldade do item ..................................................................................................... 33 

3.3 DiscriminaÃ§Ã£o do item ...................................................................................................... 34 

3.4  Acerto ao acaso ............................................................................................................ 35 

3.5  CritÃ©rio dos distratores ................................................................................................. 36 

3.6  Confiabilidade do Teste ............................................................................................... 36 

3.7  Alfa de Cronbach ......................................................................................................... 37 

3.8   Unidimensionalidade do teste ......................................................................................... 37 

4  RevisÃ£o de Literatura .......................................................................................................... 40 

5  Metodologia ........................................................................................................................ 44 

6  Resultados e DiscussÃ£o ....................................................................................................... 47 

6.1  Algumas estatÃ­sticas descritivas ................................................................................... 47 

6.2  Confiabilidade do teste ................................................................................................ 49 

6.3  Unidimensionalidade do teste ...................................................................................... 51 

6.4  AnÃ¡lise no Ã¢mbito da TCT ........................................................................................... 52 

6.5  AnÃ¡lise no Ã¢mbito da TRI ............................................................................................ 55 

6.6  ComparaÃ§Ã£o entre os resultados na TCT e na TRI ...................................................... 60 

7  AnÃ¡lise PedagÃ³gica............................................................................................................. 63 

8 

PercepÃ§Ãµes e inquietaÃ§Ãµes do autor .................................................................................... 69 

9  ConsideraÃ§Ãµes Finais .......................................................................................................... 71 

10  ReferÃªncias ......................................................................................................................... 72 

Anexo II ...................................................................................................................................... 78 

Anexo III .................................................................................................................................... 80 

 
 
 
 
21 

1 IntroduÃ§Ã£o 

A primeira pergunta que surge ao nos depararmos com o tÃ­tulo deste trabalho Ã©: porque utilizar 

um simulado como mÃ©todo de avaliaÃ§Ã£o educacional? Pois bem, quando surge a necessidade de 

avaliar um determinado grupo de estudantes, o que se deseja Ã© obter um resultado que apresente, 

com  a  maior  proximidade  possÃ­vel  da  realidade,  as  habilidades  adquiridas  pelos  analisados. 

Portanto, uma maneira de se obter resultados Ã© submeter este grupo a uma â€œsimulaÃ§Ã£oâ€ em que as 

resoluÃ§Ãµes  exijam  certas habilidades. Esta simulaÃ§Ã£o, ou teste, pode ser  formado por dois  tipos 

diferentes  de  itens:  discursivos  ou  objetivos.  A  nossa  escolha  por  um  teste  objetivo  se  dÃ¡  pela 

fidedignidade das anÃ¡lises das respostas. Um teste com itens discursivos pode apresentar diferentes 

interpretaÃ§Ãµes  quando  analisados  por  pessoas  diferentes.  AlÃ©m  disso,  quando  a  populaÃ§Ã£o  Ã© 

consideravelmente  grande  e  os  itens  do  teste  sÃ£o  discursivos,  a  correÃ§Ã£o  se  torna  muito  mais 

trabalhosa.  

Por ser uma etapa importante no processo de avaliaÃ§Ã£o, a elaboraÃ§Ã£o de um teste pelo professor 

costuma  ser  cuidadosamente  construÃ­da  e  sofre  constante  aprimoramento.  Segundo  Klein  e 

Fontanive  (1995),  em  geral,  o  processo  de  planejamento  dos  testes  combina  os  conteÃºdos 

curriculares e as habilidades hierarquizadas em nÃ­veis de complexidade a partir do que se espera 

que o aluno saiba e seja capaz de fazer. 

A avaliaÃ§Ã£o, de maneira geral,  Ã© uma forma de  obter dados que permitam  uma anÃ¡lise dos 

objetivos a serem atingidos (LUCKESI, 2008). Apesar de termos muito a discutir sobre as formas 

de se avaliar, Ã© difÃ­cil pensar na evoluÃ§Ã£o de um trabalho sem submeter os sujeitos do mesmo a 

alguma avaliaÃ§Ã£o. Para Luckesi (2008), a avaliaÃ§Ã£o da aprendizagem Ã© uma prÃ¡tica de investigaÃ§Ã£o 

do professor, cujo sentido Ã© intervir na busca dos melhores resultados do processo de aprendizagem 

dos nossos educandos, em sala de aula. Em seu conceito, Luckesi (2008), afirma que a avaliaÃ§Ã£o Ã© 

um juÃ­zo de qualidade sobre dados relevantes para uma tomada de decisÃ£o. Elaborar uma avaliaÃ§Ã£o 

que traduza as habilidades que se deseja analisar nÃ£o Ã© uma tarefa simples, mas, sem dÃºvidas, partir 

dos resultados obtidos em avaliaÃ§Ãµes bem elaboradas, a chance de sucesso em nossas tomadas de 

decisÃµes Ã© maior. Isso ocorre porque o processo de educaÃ§Ã£o Ã© constante e uma etapa serve de prÃ©-

requisito  para  a  prÃ³xima  etapa.  Se  os  estudantes  apresentam  um  bom  desempenho  em  uma 

 
 
22 

avaliaÃ§Ã£o que foi mal elaborada, isso pode gerar problemas em etapas futuras que dependam desta, 

pois os estudantes podem, na realidade, nÃ£o possuir as habilidades necessÃ¡rias. 

Amplamente utilizada entre os professores, no momento da avaliaÃ§Ã£o, a Teoria ClÃ¡ssica dos 

Testes (TCT) consiste em atribuir a mesma pontuaÃ§Ã£o para cada questÃ£o, independente do grau de 

dificuldade e de outros parÃ¢metros envolvidos. Este tipo de avaliaÃ§Ã£o apresenta dificuldades para 

comparar  dois  respondentes  distintos  que  foram  submetidos  ao  mesmo  teste  (RABELO,  2013), 

pois  dois  indivÃ­duos  que  atingiram  a  mesma  nota  nÃ£o  necessariamente  acertaram  as  mesmas 

questÃµes e, consequentemente, nÃ£o possuem as mesmas habilidades. Por exemplo, em um teste de 

nove questÃµes que tenha sido aplicado para uma turma do 9Âº ano do Ensino Fundamental. Com 

este  teste,  deseja-se  medir  as  habilidades  dos  respondentes  em  Trigonometria  no  triÃ¢ngulo 

retÃ¢ngulo. Das nove questÃµes, trÃªs envolvem seno, trÃªs envolvem cosseno e trÃªs envolvem tangente. 

Dois  estudantes  acertaram  seis  questÃµes,  porÃ©m  um  deles  errou  as  trÃªs  que  envolem  tangente 

enquanto o outro errou uma de cada relaÃ§Ã£o trigonomÃ©trica. Se estes estudantes forem avaliados 

pela TCT terÃ£o notas iguais, porÃ©m um deles nÃ£o atingiu o conhecimento necessÃ¡rio sobre tangente. 

Para resolver estes e outros problemas em potencial, uma opÃ§Ã£o a ser utilizada como mÃ©todo de 

avaliaÃ§Ã£o Ã© a Teoria de Resposta ao Item (TRI). Andrade, Tavares e Valle (2000), afirmam que a 

TRI vem sendo progressivamente introduzida em nosso meio, e Ã© um instrumento poderoso nos 

processos quantitativos de avaliaÃ§Ã£o educacional, pelo fato de permitir, inclusive, a construÃ§Ã£o de 

escalas de habilidades calibradas. Este constante crescimento da utilizaÃ§Ã£o da TRI se dÃ¡ pelo fato 

de que as  avaliaÃ§Ãµes  em larga escala possuem, de modo  geral,  itens objetivos, o que permite  a 

aplicaÃ§Ã£o desta teoria. Dentre estas provas podemos  destacar,  aqui  no  Brasil, o ENEM (Exame 

Nacional do Ensino MÃ©dio), a OBMEP (OlimpÃ­ada Brasileira de MatemÃ¡tica das Escolas PÃºblicas 

e Privadas), o SAEB (Sistema de AvaliaÃ§Ã£o da EducaÃ§Ã£o BÃ¡sica), a Prova Brasil, alÃ©m de questÃµes 

de concursos, vestibulares, entre outros testes aplicados em larga escala. 

Uma avaliaÃ§Ã£o muito importante para a educaÃ§Ã£o nacional, aplicada bienalmente Ã© a Prova 

Brasil. Essa importÃ¢ncia estÃ¡ relacionada ao resultado dos estudantes nesta prova. A nota da Prova 

Brasil serve de base para o cÃ¡lculo do IDEB (Ãndice de Desenvolvimento da EducaÃ§Ã£o BÃ¡sica). 

Infelizmente este Ã­ndice nÃ£o Ã© completamente fidedigno, pois a taxa de aprovaÃ§Ã£o escolar Ã© levada 

em consideraÃ§Ã£o para o cÃ¡lculo da nota final. Isso significa que se a mÃ©dia geral de duas escolas 

for  a  mesma,  mas  uma  das  escolas  obtiver  um  Ã­ndice  de  aprovaÃ§Ã£o  de  100%  enquanto  a  outra 

 
23 

obtiver um Ã­ndice de aprovaÃ§Ã£o de 80%, a escola que obteve uma taxa de aprovaÃ§Ã£o maior terÃ¡ um 

IDEB maior.  

Por  gerar  um  Ã­ndice  fundamental  no  desempenho  de  uma  unidade  escolar,  a  Prova  Brasil 

motivou  o municÃ­pio de JaraguÃ¡ do Sul  a  criar  uma prova local, a ser aplicada  bienalmente no 

municÃ­pio,  denominada  a  partir  daqui  de  â€œprova  JaraguÃ¡â€.  Aplicada  desde  2015,  esta  prova  Ã© 

formada por itens objetivos e aplicada em larga escala. Por estes motivos, foi escolhida a Teoria da 

Resposta ao Item na elaboraÃ§Ã£o e anÃ¡lises desta prova. Com isso, buscamos aumentar a efetividade 

dos  testes  e,  consequentemente,  obter  resultados  que  possam  traduzir  de  maneira  mais  eficaz  a 

qualidade do trabalho que vem sendo feito.  

O  objetivo  geral  deste  trabalho  Ã©  analisar  um  simulado  de  matemÃ¡tica  utilizando  a  Teoria 

ClÃ¡ssica dos Testes (TCT) e a Teoria de Resposta ao Item (TRI). Como objetivos especÃ­ficos deste 

trabalho vamos analisar analisar os itens de acordo com a TCT utilizando os coeficientes bisseriais, 

discriminaÃ§Ã£o,  dificuldade  e  distratores;  analisar  os  itens  de  acordo  com  a  TRI  utilizando  os 

coeficientes bisseriais e a dificuldade do item, discriminaÃ§Ã£o, acerto ao acaso, Curva CaracterÃ­stica 

do Item (CCI),  e curva de informaÃ§Ã£o do item; fazer uma anÃ¡lise pedagÃ³gica das questÃµes que 

apresentam deficiÃªncias, apontando os possÃ­veis fatores que influenciaram no resultado, alÃ©m de 

propor melhorias; comparar os resultados das anÃ¡lises dos itens obtidos com as duas teorias, TCT 

e TRI; determinar a dimensionalidade e confiabilidade do teste e apontar o que pode ser melhorado 

para  que  futuras  avaliaÃ§Ãµes  similares  possam  discriminar  melhor  os  respondentes,  apresentado 

resultados mais satisfatÃ³rios. 

Este trabalho justifica-se e Ã© relevante pois irÃ¡ auxiliar a responder perguntas que aparecem 

naturalmente durante o processo de aprendizagem, como: Estamos fazendo um bom trabalho? Os 

estudantes estÃ£o em constante evoluÃ§Ã£o? Em que podemos melhorar?   

Estas foram algumas das questÃµes que motivaram o municÃ­pio de JaraguÃ¡ do Sul a criar a prova 

JaraguÃ¡. Como a prova Ã© aplicada bienalmente, existe a necessidade de que o nÃ­vel da prova e as 

habilidades  que  se  deseja  medir,  nÃ£o  se  alterem  entre  uma  ediÃ§Ã£o  e  outra.  Por  este  motivo,  na 

elaboraÃ§Ã£o e anÃ¡lise destas provas, a secretaria municipal de educaÃ§Ã£o de JaraguÃ¡ do Sul utiliza a 

Teoria  de  Resposta  ao  Item,  o  que  permite,  antes  mesmo  de  avaliar  o  desempenho  dos  alunos, 

avaliar a confiabilidade dos testes. 

 
24 

Por ser um professor do quadro efetivo dos servidores do municÃ­pio de JaraguÃ¡ do Sul e querer 

contribuir no processo de aprendizagem, surgiu a ideia de fazer este trabalho que me proporcionou 

aprofundar os conhecimentos sobre a TRI e analisar estatisticamente e pedagogicamente os itens 

de um dos simulados que jÃ¡ foi aplicado, colaborando com futuras aplicaÃ§Ãµes da prova JaraguÃ¡.   

AlÃ©m disso, os resultados e discussÃµes apresentados neste trabalho podem auxiliar o dia a dia 

do professor, fazendo-o refletir sobre o processo de elaboraÃ§Ã£o das suas provas, corrigindo as suas 

falhas e confirmando as suas certezas. 

No  capÃ­tulo  2  deste  trabalho  apresentamos  a  Teoria  ClÃ¡ssica  dos  testes,  discutindo  as  suas 

limitaÃ§Ãµes  e  definindo  os  conceitos  utilizados  para  analisar  a  prova  JaraguÃ¡.  De  maneira 

semelhante,  no  capÃ­tulo  3  apresentamos  a  Teoria  de  Resposta  ao  Item.  No  capÃ­tulo  4  estÃ£o  em 

destaque alguns trabalhos que executaram pesquisas e anÃ¡lises similares a esta, contendo alguns 

resultados obtidos. Os procedimentos metodolÃ³gicos, materiais e mÃ©todos utilizados na aplicaÃ§Ã£o 

da  prova  JaraguÃ¡  e  justificativa  para  a  aplicaÃ§Ã£o  da  mesma  se  encontram  no  capÃ­tulo  5.  Os 

resultados obtidos estÃ£o apresentados no capÃ­tulo 6, incluindo a comparaÃ§Ã£o entre os resultados 

obtidos com a TCT e com a TRI. No capÃ­tulo Ã© realizada a anÃ¡lise pedagÃ³gica dos itens, principal 

objetivo das anÃ¡lises deste trabalho. No capÃ­tulo 8 hÃ¡ uma discussÃ£o que envolve experiÃªncias da 

prÃ¡tica docente do autor. Por fim, no capÃ­tulo 9, apresentamos algumas consideraÃ§Ãµes, limitaÃ§Ãµes 

e sugestÃµes de continuidade do trabalho. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
25 

2 A Teoria ClÃ¡ssica dos Testes 

Neste capÃ­tulo vamos falar um pouco sobre os tipos de avaliaÃ§Ã£o e tambÃ©m sobre a avaliaÃ§Ã£o 

em  larga escala no  Brasil. AlÃ©m  disso,  vamos  descrever um  pouco sobre  a Teoria ClÃ¡ssica dos 

Testes.  Entre  os  principais  conceitos  que  envolvem  esta  teoria,  destacamos  o  resultado  que  Ã© 

apresentado com base nos escores brutos, ou seja, dois estudantes que fizeram a mesma prova e 

acertaram a mesma quantidade de questÃµes terÃ£o a mesma nota, mesmo que as questÃµes nÃ£o sejam 

as mesmas. AlÃ©m disso, falamos tambÃ©m das limitaÃ§Ãµes que esta teoria apresenta e como corrigir 

ou melhorar essas limitaÃ§Ãµes. 

2.1 AvaliaÃ§Ã£o 

Em todas as atividades que envolvem algum tipo de aprendizagem e deseja-se medir o nÃ­vel 

desta  aprendizagem,  deve-se  submeter  os  participantes  a  algum  tipo  de  avaliaÃ§Ã£o.  A  partir  da 

dÃ©cada de 60 a literatura sobre avaliaÃ§Ã£o aumentou consideravelmente (VIANNA, 1995). O termo 

avaliaÃ§Ã£o vem sendo discutido em vÃ¡rios trabalhos acadÃªmicos com o passar dos anos, repensando-

se estratÃ©gias e revendo-se conceitos. Segundo Luckesi (2007) a avaliaÃ§Ã£o, tanto no geral quanto 

no caso especÃ­fico da aprendizagem, nÃ£o possui uma finalidade por si sÃ³, mas estÃ¡ inserida em um 

processo que visa construir um resultado previamente definido. Isso significa que a avaliaÃ§Ã£o nÃ£o 

deve  terminar  apenas  na  aplicaÃ§Ã£o  e  obtenÃ§Ã£o  do  resultado  de  uma  prova,  mas  sim  que  este 

resultado  sirva  para  que  o  professor  possa  repensar  as  suas  estratÃ©gias,  confirmando  ou 

reformulando os processos didÃ¡ticos utilizados. 

Segundo CortesÃ£o (2002) hÃ¡ trÃªs tipos de avaliaÃ§Ã£o: avaliaÃ§Ã£o diagnÃ³stica, avaliaÃ§Ã£o formativa 

e avaliaÃ§Ã£o somativa. A avaliaÃ§Ã£o diagnÃ³stica Ã© utilizada quando se deseja identificar competÃªncias 

do pÃºblico alvo antes de se iniciar um trabalho. Em cursos de inglÃªs, por exemplo, costuma-se fazer 

uma  prova  para  identificar  em  que  nÃ­vel  se  encontra  o  estudante.  Posteriormente  o  estudante  Ã© 

encaminhado para a turma que condiz com o nÃ­vel que o mesmo se encontra. A avaliaÃ§Ã£o formativa 

tem por caracterÃ­stica contribuir constantemente com o processo de aprendizagem. As provas que 

os alunos de uma escola fazem durante o ano, por exemplo, tem carÃ¡ter formativo, desde que haja 

retomada dos pontos necessÃ¡rios. Por fim, a avaliaÃ§Ã£o somativa tem por objetivo apresentar um 

sumÃ¡rio  de  resultados  obtidos  em  uma  situaÃ§Ã£o  educativa.  Este  tipo  de  avaliaÃ§Ã£o  costuma  ser 

 
 
 
26 

aplicada, por exemplo, no final de um ano, no final de um curso, ou de qualquer perÃ­odo letivo de 

uma unidade de ensino (CORTESÃƒO, 2002).  

A  prova  JaraguÃ¡,  objeto  de  estudo  deste  trabalho,  tem  um  carÃ¡ter  tanto  de  uma  avaliaÃ§Ã£o 

diagnÃ³stica  como  de  uma  avaliaÃ§Ã£o  somativa,  visto  que  o  objetivo  da  aplicaÃ§Ã£o  desta  prova  Ã© 

avaliar as  competÃªncias  dos estudantes antes de iniciar o prÃ³ximo ano letivo  para que se possa 

trabalhar as deficiÃªncias, alÃ©m de avaliar a qualidade da educaÃ§Ã£o durante os dois anos anteriores 

a mesma.   

Quando se fala em avaliaÃ§Ã£o, a maneira mais utilizada para mensurar o domÃ­nio de um certo 

indivÃ­duo  sobre determinado conteÃºdo Ã©  a  aplicaÃ§Ã£o de provas. Para que se possa comparar tal 

domÃ­nio entre os respondentes destas provas deve-se, de alguma maneira, padronizar a anÃ¡lise dos 

resultados. A conduta do professor no processo de aferiÃ§Ã£o do aproveitamento escolar tem sido a 

nota ou coneito (LUCKESI, 2007). Como a prova JaraguÃ¡ Ã© aplicada para um nÃºmero relativamente 

grande  de  estudantes  (aproximadamente  10.000),  necessita-se  de  uma  estratÃ©gia  eficiente  de 

avaliaÃ§Ã£o em larga escala. 

No Brasil, existem alguns testes aplicados periodicamente como o Sistema de AvaliaÃ§Ã£o da 

EducaÃ§Ã£o  BÃ¡sica  (SAEB),  Exame  Nacional  do  Ensino  MÃ©dio  (ENEM)  e o  Exame  Nacional  de 

Desempenho de Estudantes (ENADE). Mas a experiÃªncia brasileira nÃ£o se restringe Ã s avaliaÃ§Ãµes 

de abrangÃªncia nacional. Segundo Rabelo (2013), Estados e municÃ­pios tÃªm criado os seus prÃ³prios 

sistemas,  sendo que muitos  deles escolhem metodologias que permitem comparar os resultados 

obtidos com os nacionalmente estabelecidos.  

A Teoria ClÃ¡ssica dos Testes foi criada para cumprir este papel de anÃ¡lise dos resultados. Esta 

teoria, largamente utilizada antes da criaÃ§Ã£o da Teoria de Resposta ao Item, baseia-se em resultados 

obtidos em provas atravÃ©s de escores brutos ou padronizados. O que Ã© levado em consideraÃ§Ã£o aqui 

Ã© o resultado final do teste de cada respondente, quem acerta mais questÃµes possui mais habilidades, 

conforme descrito por Vianna (2014). 

Segundo  Rabelo  (2013)  podemos  perceber  algumas  deficiÃªncias  na  TCT.  Em  especial, 

destacam-se a discriminaÃ§Ã£o dos itens, fidedignidade dos testes e, por fim, a impossibilidade de 

comparaÃ§Ã£o de dois indivÃ­duos que fizeram testes distintos. Digamos que queremos comparar as 

habilidades  de  dois  alunos  que  tiraram  a  mesma  nota  em  um  teste.  Basicamente,  queremos 

determinar qual dos dois possui mais competÃªncias. PorÃ©m, por mais que eles tenham atingido a 

 
27 

mesma  nota,  isso  nÃ£o  significa  que  eles  tenham  alcanÃ§ado  as  mesmas  competÃªncias,  pois  eles 

podem  ter  acertado  questÃµes  distintas  que  exigem  habilidades  diferentes  do  respondente,  por 

exemplo. 

Outro fator que impossibilita a comparaÃ§Ã£o entre indivÃ­duos atravÃ©s da TCT Ã© que para tal 

comparaÃ§Ã£o estes alunos deveriam ter feito o mesmo teste (RABELO, 2013). Portanto, para uma 

prova que seja aplicada periodicamente para um pÃºblico com o mesmo nÃ­vel de escolaridade, as 

anÃ¡lises a partir da TCT nÃ£o seriam precisas, pois nÃ£o seria possÃ­vel aplicar a mesma prova. 

Apesar das limitaÃ§Ãµes que a TCT apresenta, podemos analisar vÃ¡rios parÃ¢metros importantes 

que envolvem um teste, como confiabilidade, dificuldade e discriminaÃ§Ã£o. Antes de tudo, devemos 

analisar a unidimensionalidade do teste, isto Ã©, apenas uma dimensÃ£o estÃ¡ sendo medida pelo teste. 

Por  exemplo,  se  medirmos  a  proficiÃªncia  em  matemÃ¡tica  de  modo  geral,  provavelmente  serÃ¡ 

multidimensional, mas se medirmos a proficiÃªncia em geometria do 7Âº ano do Ensino Fundamental, 

provavelmente  serÃ¡  unidimensional.  Segundo  Junker  (2012)  fazemos  isso  por  dois  motivos: 

primeiro, estes itens aumentarÃ£o a confiabilidade do teste; e segundo, itens unidimensionais sÃ£o 

mais fÃ¡ceis de descrever e interpretar.  

2.1  DiscriminaÃ§Ã£o do Item 

O  poder  de  discriminaÃ§Ã£o  de  um  item  Ã©  a  sua  capacidade  de  diferenciar  com  clareza  os 

respondentes que possuem altas habilidades dos que possuem baixas habilidades. Na TCT, Pasquali 

(2003) diz que dentre as formas existentes para o cÃ¡lculo do Ã­ndice de discriminaÃ§Ã£o, a dos grupos-

critÃ©rio e o da correlaÃ§Ã£o item-total sÃ£o as mais utilizadas pelos psicanalistas. O mÃ©todo dos grupos-

critÃ©rio trabalha com valores de referÃªncia, utilizando como base para tais valores os resultados do 

prÃ³prio teste ou resultados externos, enquanto o mÃ©todo da correlaÃ§Ã£o item-total relaciona o escore 

total do teste com o escore obtido no item.  

[...] Quando o cÃ¡lculo do Coeficiente Bisserial Ã© efetuado para cada uma das 
alternativas, tem-se a correlaÃ§Ã£o da opÃ§Ã£o de respostas do indivÃ­duo ao item 
com o seu desempenho no teste como um todo. Assim, espera-se que alunos que 
se desempenham bem no teste, tenham feito a opÃ§Ã£o pela alternativa correta de 
um  determinado  item.  Caso  esses  alunos  tenham  sido  atraÃ­dos  a  responder 
qualquer uma das alternativas que nÃ£o a certa, o item nÃ£o Ã© discriminativo e 
nÃ£o consegue diferenciar os alunos que construÃ­ram proficiÃªncias, daqueles que 
as nÃ£o construÃ­ram. (FERREIRA, 2009, p. 23) 

 
 
 
28 

Neste trabalho, para analisar o parÃ¢metro de discriminaÃ§Ã£o dos itens por meio da TCT, vamos 

utilizar a correlaÃ§Ã£o ponto bisserial. 

O coeficiente de correlaÃ§Ã£o ponto bisserial (ğœŒğ‘ğ‘) Ã© dado por um Ã­ndice que varia no intervalo 

[âˆ’1,1].  Quanto  mais  prÃ³ximo de  1,  mais  discriminativo  serÃ¡  o  item,  consequentemente  quanto 

mais  prÃ³ximo  de  âˆ’1,  menos  discriminativo  serÃ¡  o  item  (MAIA,  2009).  Um  coeficiente  de 

correlaÃ§Ã£o ponto-bisserial negativo significa que o escore mÃ©dio dos respondentes que acertaram 

o item Ã© menor do que o escore mÃ©dio total, ou seja, os indivÃ­duos com baixas habilidades acertaram 

o item enquanto indivÃ­duos com altas habilidades erraram o item, o que Ã© indesejÃ¡vel. O coeficiente 

de correlaÃ§Ã£o ponto bisserial Ã© expresso pela EquaÃ§Ã£o 2.1. 

                                                         ğœŒğ‘ğ‘ =

ğ‘†ğ‘Ì…Ì…Ì… âˆ’ ğ‘†Ì…
ğœğ‘†

ğ‘
âˆ™ âˆš
ğ‘

,                                                            (2.1) 

em que ğ‘†ğ‘Ì…Ì…Ì… representa o escore mÃ©dio no teste para os que acertaram o item, ğ‘†Ì… Ã© o escore mÃ©dio 

para todos, ğœğ‘† Ã© o desvio padrÃ£o nÃ£o nulo dos escores obtidos no teste pelos respondentes, ğ‘ Ã© a 

proporÃ§Ã£o de indivÃ­duos que acertaram o item no teste, ou seja, o Ã­ndice de dificuldade, e ğ‘ Ã© o 

complementar de ğ‘.  

NÃ£o podemos deixar de observar que a correlaÃ§Ã£o ponto bisserial nÃ£o estÃ¡ definida para o caso 

em que todos os indivÃ­duos acertaram o item, pois terÃ­amos ğ‘ = 0. Segundo Rabelo (2013), itens 

que apresentam coeficiente de correlaÃ§Ã£o inferiores a 0,30 sÃ£o considerados de baixa discriminaÃ§Ã£o 

e devem ser rejeitados. Ensinam Leite (2003), Vianna (1982) e Arias Lloreda e Lloreda  (2006) 

que  a  escala  apresentada,  criada  por  Ebel  (1965),  Ã©  uma  boa  referÃªncia  para  a  classificaÃ§Ã£o  da 

qualidade discriminativa de um item: 

Tabela 2.1 - ClassificaÃ§Ã£o do item do teste, por nÃ­vel do Ã­ndice de discriminaÃ§Ã£o 

Ãndice de  discriminaÃ§Ã£o   ClassificaÃ§Ã£o do item 
Abaixo de 0,19 
Entre 0,20 e 0,29 
Entre 0,30 e 0,39 
Acima de 0,40 

Ineficiente, devendo ser eliminado ou revisado totalmente 
No mÃ­nimo, necessita de revisÃ£o. 
AceitÃ¡vel, nÃ£o requerendo revisÃ£o 
SatisfatÃ³rio, devendo permanecer no teste 

Fonte: INEP 2014 

 
 
  
29 

A escala apresentada na tabela 2.1 Ã© uma boa referÃªncia para analisar os resultados da prova 

JaraguÃ¡, identificando os itens que devem ser excluÃ­dos do teste. 

2.2 Dificuldade do Item 

Um parÃ¢metro importante a ser analisado Ã© a dificuldade dos itens que compÃµem o teste. Na 

TCT, o Ã­ndice de dificuldade de um  item  Ã© dado pela  razÃ£o entre o nÃºmero de candidados que 

responderam  corretamente  o  item  e  o  nÃºmero  total  de  candidatos  que  responderam  ao  teste, 

EquaÃ§Ã£o 2.2. 

                                                                           ğ¼ğ‘‘ğ‘“ =

ğ‘›ğ‘
ğ‘›ğ‘¡

                                                                  (2.2)                                                                                                                               

em  que  ğ¼ğ‘‘ğ‘“  representa  o  Ã­ndice  de  dificuldade,  ğ‘›ğ‘  representa  o  nÃºmero  de  candidatos  que 

responderam  corretamente  o  item  e  ğ‘›ğ‘¡  representa  o  nÃºmero  total  de  candidatos.  Portanto  a 

dificuldade do item no Ã¢mbito da Teoria ClÃ¡ssica dos Testes varia no intervalo [0,1], sendo 0 um 

item extremamente difÃ­cil (nenhum acerto) e 1 um item extremamente fÃ¡cil (todos os respondentes 

acertaram este item).  

Com base na tabela apresentada por alguns autores para classificar os itens no que diz respeito 

a dificuldade na TRI (ver Tabela 2.2) e observando a necessidade de uma anÃ¡lise similar utilizando 

a TCT, criamos uma tabela para classificar os itens do teste no que diz respeito ao seu nÃ­vel de 

dificuldade.  Esta  tabela  pode  ter  uma  importÃ¢ncia  significativa  em  futuras  anÃ¡lises  similares  Ã s 

apresentadas  neste  trabalho,  ampliando  as  discussÃµes  e  aumentando  a  confiabilidade  dos 

resultados. 

Tabela 2.2 - ClassificaÃ§Ã£o e percentual esperado para os Ã­ndices de dificuldade da TCT 

ClassificaÃ§Ã£o 
Muito fÃ¡ceis 
FÃ¡ceis 
Medianos 
DifÃ­ceis 
Muito difÃ­ceis 

Valor 
0,81 ou mais 
de 0,61 a 0,80 
de 0,41 a 0,60 
de 0,21 a 0,40 
atÃ© 0,20 
Fonte: do autor 

% esperado 
10% 
20% 
40% 
20% 
10% 

Esta classificaÃ§Ã£o, quando satisfeita, representa um teste equilibrado em relaÃ§Ã£o ao nÃ­vel de 

dificuldade. 

 
 
 
 
30 

3  A Teoria de Resposta ao Item 

Diferentemente  da  TCT,  que  leva  em  consideraÃ§Ã£o  o  escore  bruto  do  teste,  as  anÃ¡lises  da 

Teoria de Resposta ao Item se concentram nas respostas a cada item. Como forma de sanar algumas 

limitaÃ§Ãµes da TCT, utilizam-se atualmente tÃ©cnicas provenientes da Teoria de Resposta ao Item 

(TRI),  cujo  interesse  reside  em  entender  a  maneira  como  as  pessoas  respondem  aos  itens 

(REVELLE, 2015). Assim, por mais que duas provas sejam distintas, se os itens forem semelhantes 

no  que  diz  respeito  a  nÃ­vel  de  dificuldade  e  habilidade  especÃ­fica,  os  resultados  obtidos  pelos 

indivÃ­duos podem ser comparados. 

Apesar de ser considerada atualmente a melhor maneira de avaliar e comparar as habilidades 

dos  estudantes,  Ã©  importante  destacar  que  o  processo  de  avaliaÃ§Ã£o  Ã©  muito  complexo  para  ser 

completamente contemplado apenas com a aplicaÃ§Ã£o de uma prova. Em relaÃ§Ã£o a isso, Machado 

(1996), diz que â€œum processo de avaliaÃ§Ã£o nunca se esgota em um processo de medida, porÃ©m vai 

alÃ©m deleâ€. Mesmo sabendo que temos que aprimorar o modo de avaliar, nÃ£o podemos confundir 

essa necessidade de melhorias com frustraÃ§Ã£o por tudo o que Ã© feito.  

3.1 Modelos para itens dicotÃ´micos 

Nesta seÃ§Ã£o serÃ£o apresentados modelos utilizados para anÃ¡lise de itens dicotÃ´micos, isto Ã©, 

itens  que  possuem  duas  possibilidades  de  correÃ§Ã£o,  certo  ou  errado.  Na  prÃ¡tica,  os  modelos 

logÃ­sticos para itens dicotÃ´micos sÃ£o os modelos de resposta ao item mais utilizados, sendo que hÃ¡ 

basicamente trÃªs tipos: modelo logÃ­stico de um parÃ¢metro, modelo logÃ­stico de dois parÃ¢metros e 

modelo logÃ­stico de trÃªs parÃ¢metros (ANDRADE; TAVARES; VALLE, 2000).  

O modelo logÃ­stico de dois parÃ¢metros (dificuldade e discriminaÃ§Ã£o do item, modelo ML2) foi 

o  primeiro  a  ser  utilizado,  jÃ¡  no  final  da  dÃ©cada  de  50  do  sÃ©culo  passado.  A  equaÃ§Ã£o  para  este 

modelo Ã© dada pela EquaÃ§Ã£o 3.1.  

                                                        ğ‘ƒ(ğœƒ) =

1

1 + ğ‘’âˆ’ğ‘(ğœƒâˆ’ğ‘)  ,                                                    (3.1) 

na qual ğ‘’ Ã© o nÃºmero de Euler, cujo valor Ã© aproximadamente 2,718, ğ‘ Ã© o parÃ¢metro de dificuldade 

do item, ğ‘ Ã© o parÃ¢metro de discriminaÃ§Ã£o do item e ğœƒ Ã© o nÃ­vel de habilidade. 

 
 
31 

Na dÃ©cada de 60, surgiu o modelo logÃ­stico de um parÃ¢metro (modelo ML1), proposto pelo 

matemÃ¡tico Georg Rasch. Neste modelo, o parÃ¢metro de discriminaÃ§Ã£o tem seu valor fixado em 

ğ‘ = 1,0,  para  todos  os  itens,  enquanto  o  parÃ¢metro  de  dificuldade  assume  diferentes  valores 

dependendo do item (BAKER e KIM, 2004). O parÃ¢metro de discriminaÃ§Ã£o Ã© dado pela EquaÃ§Ã£o 

3.2. 

                                                              ğ‘ƒ(ğœƒ) =

1

1 + ğ‘’(ğ‘âˆ’ğœƒ) ,                                                     (3.2) 

em que ğ‘’ Ã© o nÃºmero de Euler, cujo valor Ã© aproximadamente 2,718, ğ‘ Ã© o parÃ¢metro de dificuldade 

do item e ğœƒ Ã© o nÃ­vel de habilidade 

Criado em 1968 por Allan Birnbaum e utilizado atÃ© os dias de hoje, o modelo logÃ­stico de trÃªs 

parÃ¢metros (modelo ML3) leva em consideraÃ§Ã£o o acerto ao acaso. Representado pela variÃ¡vel ğ‘, 

o  parÃ¢metro  que  representa  o  chamado  â€œchuteâ€,  atÃ©  entÃ£o  nÃ£o  era  considerado.  O  parÃ¢metro  ğ‘ 

representa a probabilidade de um aluno com baixa habilidade responder corretamente o item. Este 

parÃ¢metro tambÃ©m Ã© conhecido como a probabilidade de acerto ao acaso (ANDRADE; TAVARES; 

VALLE, 2000). 

A EquaÃ§Ã£o 3.3 Ã© dada para o modelo 3LP. 

                                                ğ‘ƒ(ğœƒ) = ğ‘ + (1 âˆ’ ğ‘)

1

1 + ğ‘’âˆ’ğ‘(ğ‘âˆ’ğœƒ)  ,                                            (3.3) 

em que ğ‘’ Ã© o nÃºmero de Euler, cujo valor Ã© aproximadamente 2,718, ğ‘ Ã© o parÃ¢metro de dificuldade 

do item, ğ‘ Ã© o parÃ¢metro de discriminaÃ§Ã£o do item e ğœƒ Ã© o nÃ­vel de habilidade e ğ‘ representa o 

parÃ¢metro de acerto ao acaso. 

Quando um indivÃ­duo responde aos itens de um teste gera uma sÃ©rie de valores iguais a 1 (no 

caso de acerto) ou 0 (no caso de erro). Podemos pensar nestes dados na forma de uma tabela com 

j linhas, referente a quantidade de respondentes e i colunas, referentes a quantidade de itens. No 

caso da TRI, deseja-se descobrir qual  o valor do traÃ§o latente (de habilidade) do indivÃ­duo  que 

melhor explica o acerto ou o erro em cada item individualmente (RABELO, 2013). Para fazer isso, 

a pergunta a ser respondida Ã©: qual Ã© a probabilidade o j-Ã©simo acertar o i-Ã©simo item? A resposta 

para  essa  pergunta  estÃ¡  relacionada  ao  nÃ­vel  de  habilidade  ğœƒ  que  o  indivÃ­duo  possui  e  dos 

parÃ¢metros do modelo ML3, definida pela EquaÃ§Ã£o 3.4. 

 
 
32 

                                     ğ‘ƒ(ğ‘‹ğ‘–ğ‘— = 1/ğœƒğ‘—) = ğ‘ğ‘– +

1 âˆ’ ğ‘ğ‘–
1 + exp[âˆ’ğ·ğ‘ğ‘–(ğœƒğ‘— âˆ’ ğ‘ğ‘–)]

 ,                        (3.4) 

em que ğ‘‹ğ‘—ğ‘– Ã© a resposta do indivÃ­duo j ao item i (igual a 1 se o indivÃ­duo responde corretamente   

ao  item  e,  igual  a  0,  caso  contrÃ¡rio),  ğ‘ğ‘–  > 0  Ã©  o  parÃ¢metro  de  discriminaÃ§Ã£o  do  item  i,  ğ‘ğ‘–  Ã©  o 

parÃ¢metro de dificuldade do item i, 0 < ğ‘ğ‘– < 1 Ã© o parÃ¢metro da assÃ­ntota inferior do item, ou seja, 

a chance de um respondente com baixa habilidade responder corretamente o item i, ğœƒğ‘— representa 

o traÃ§o latente (habilidade) do j-Ã©simo indivÃ­duo e ğ· Ã© um valor de escala, que Ã© igual a 1 na mÃ©trica 

logÃ­stica e igual a 1,7 na mÃ©trica normal. Segundo Klein (2013) o uso da mÃ©trica normal vem do 

fato  de  que  os  primeiros  modelos  utilizavam  a  funÃ§Ã£o  ogiva  normal  e  de  que  a  funÃ§Ã£o  de 

distribuiÃ§Ã£o  cumulativa  normal  com  mÃ©dia  0  e  desvio  padrÃ£o  1  Ã©  bem  aproximada  pela  funÃ§Ã£o 

logÃ­stica  com  parÃ¢metro  ğ‘ = 0 e parÃ¢metro  ğ‘ = 1,7, no sentido de que o mÃ¡ximo da diferenÃ§a 

pontual entre as duas funÃ§Ãµes Ã© menor do que 0,01. 

Quando estimamos os valores que a funÃ§Ã£o ğ‘ƒ(ğœƒ) assume para o i-Ã©simo item, se os resultados 

estiverem  dentro  do  esperado  para  termos  um  item  cumprindo  bem  a  sua  funÃ§Ã£o  avaliadora,  o 

grÃ¡fico Ã© uma sigmoide chamada Curva CaracterÃ­stica do Item (CCI), ilustrada na Figura 3.1. A 

funÃ§Ã£o ğ‘ƒ(ğœƒ) assume, no eixo vertical, valores no intervalo (0,1), que representam a probabilidade 

de acerto de 0% a 100%. No eixo horizontal a habilidade ğœƒ assume valores que estÃ£o em uma escala 

de mÃ©dia igual a 0 e um desvio padrÃ£o igual a 1.  

Figura 3.1 - Curva CaracterÃ­stica do Item - CCI 

Fonte: Andrade, Tavares e Valle (2000, p.11) 

 
 
33 

Vale mencionar que existem  estudos  de um  modelo  logÃ­stico de quatro parÃ¢metros (ML4). 

AlÃ©m de discriminaÃ§Ã£o, dificuldade e acerto ao acaso, o modelo logÃ­stico de quatro parÃ¢metros 

leva em consideraÃ§Ã£o as possÃ­veis falhas na elaboraÃ§Ã£o de um item diante de uma resposta errada 

de  um  respondente  com  altas  habilidades.  Segundo  MuÃ±iz  (1990)  alguns  autores  propÃµem  um 

modelo logÃ­stico de quatro parÃ¢metros, que visa controlar circunstÃ¢ncias aleatÃ³rias relacionadas 

com falhas do construtor no momento da elaboraÃ§Ã£o dos itens. Desde o final da dÃ©cada de 90 este 

modelo Ã© pouco usado, MuÃ±iz (1997) explica que o mesmo nÃ£o apresenta vantagens significativas 

comparativamente aos outros trÃªs modelos e, ademais, os problemas que trata de solucionar podem 

ser muito bem controlados durante a elaboraÃ§Ã£o dos itens. 

3.2 Dificuldade do item 

O parÃ¢metro ğ‘ (dificuldade do item) na TRI representa o nÃ­vel de conhecimento (habilidade) 

que  o  indivÃ­duo  deve  possuir  para  responder  a  um  item.  De  uma  forma  mais  especÃ­fica,  a 

dificuldade Ã© o valor da habilidade ğœƒ necessÃ¡rio para que se tenha uma probabilidade de acerto 

igual a 

(1+ğ‘)

2

. Obtemos tal resultado observando o valor de ğœƒ no ponto de interseÃ§Ã£o entre a CCI e 

a reta horizontal que passa pelo ponto 

(1+ğ‘)

.  

2

Pelo fato da dificuldade ser medida em uma escala padronizada, seus valores podem variar de 

âˆ’âˆ a +âˆ, porÃ©m, na prÃ¡tica este intervalo se reduz a  âˆ’3 (item muito fÃ¡cil) e  +3 (item muito 

difÃ­cil), pois esta escala abrange mais de 99% das ocorrÃªncias (TORRES, 2015).  

 Na Figura 3.2 temos as curvas de trÃªs itens. A probabilidade de acerto ao acaso Ã©  ğ‘ = 0,2, 

ficando a reta horizontal em 0,6. Podemos ver que a curva em verde representa um item mais fÃ¡cil 

(ğ‘ = âˆ’0,5), a curva em preto representa um item com uma dificuldade mÃ©dia (ğ‘ = 0) e a curva 

em vermelho representa um item mais difÃ­cil (ğ‘ = 0,5). 

 
 
 
 
 
34 

Figura 3.2 - ComparaÃ§Ã£o das CCIs de itens com diferentes nÃ­veis de dificuldade e mesma 
probabilidade de acerto ao acaso. 

Fonte: Torres (2015) 

Quando nÃ£o Ã© considerado o acerto ao acaso (modelo  ML2) ou simplesmente temos ğ‘ = 0 

(nÃ£o considerar acerto de item por â€œchuteâ€), a dificuldade Ã© dada pelo valor da habilidade que gera 

uma probabilidade de 50% de acerto do item (MAIA, 2009).  

A Tabela 3.1 representa a distribuiÃ§Ã£o e a classificaÃ§Ã£o adotada pela maioria dos autores da 

Ã¡rea de avaliaÃ§Ã£o e psicometria, de acordo com a dificuldade dos itens (RABELO, 2013).  

Tabela 3.1 - ClassificaÃ§Ã£o e percentual esperado para os Ã­ndices de dificuldade da TRI 

ClassificaÃ§Ã£o 
Muito fÃ¡ceis 
FÃ¡ceis 
Medianos 
DifÃ­ceis 
Muito difÃ­ceis 

Valores de b  % esperado 

atÃ© -1,28 
de -1,27 a -0,52 
de -0,51 a 0,51 
de 0,51 a 1,27 
1,28 ou mais 

10% 
20% 
40% 
20% 
10% 

Fonte: Rabelo (2013) 

Essa classificaÃ§Ã£o pode ser utilizada para determinar o equilÃ­brio entre o nÃ­vel de dificuldade 

das questÃµes, de modo que o teste nÃ£o seja muito difÃ­cil e nem muito fÃ¡cil.  

3.3 DiscriminaÃ§Ã£o do item 

Quando  falamos  da  discriminaÃ§Ã£o  de  um  item  nos  referimos  a  capacidade  do  item  de 

diferenciar  respondentes  com  alta  habilidade  de  respondentes  com  baixa  habilidade.  Na  TRI, 

 
 
  
podemos  observar  a  discriminaÃ§Ã£o  do  item  atravÃ©s  da  inclinaÃ§Ã£o  da  CCI  no  ponto  de  inflexÃ£o 

(ponto em que a curva muda de concavidade), representada pelo parÃ¢metro ğ‘. Vimos anteriormente 

35 

que para determinar o ponto de inflexÃ£o fazemos 

1+ğ‘

2

. Teoricamente, o parÃ¢metro de discriminaÃ§Ã£o 

varia no intervalo (âˆ’âˆ, +âˆ), porÃ©m na prÃ¡tica os valores de ğ‘ variam no intervalo (0,2).  Segundo 

Rabelo (2013) valores negativos da discriminaÃ§Ã£o indicam que o item se comporta de uma maneira 

estranha, pois estariam indicando que a probabilidade de acerto do item diminui com o aumento da 

aptidÃ£o  do  sujeito.  Em  geral,  sÃ£o  considerados  como  discriminativos  itens  com  valores  de  ğ‘ 

superiores a 0,70. De acordo com Rabelo (2013) podemos categorizar os itens de acordo com a 

Tabela 3.2. 

Tabela 3.2 - ClassificaÃ§Ã£o do item de acordo com a discriminaÃ§Ã£o pela TRI. 

Valores 
a = 0 
0 < a â‰¤ 0,35 
0,35 < a â‰¤ 0,65 
0,65 < a â‰¤ 1,35 
1,35 < a â‰¤ 1,70 
a > 1,70 

DiscriminaÃ§Ã£o 
nenhuma 
muito baixa 
Baixa 
moderada 
Alta 
muito alta 

Fonte: Rabelo (2013) 

A Tabela 3.2 servirÃ¡ de base para a classificaÃ§Ã£o dos itens de acordo com a sua discriminaÃ§Ã£o, 

o que serÃ¡ feito no capÃ­tulo 6. Estes resultados serÃ£o confrontados com os dados obtidos na anÃ¡lise 

de discriminaÃ§Ã£o da TCT. 

3.4 Acerto ao acaso 

Representado  pelo  parÃ¢metro  ğ‘,  o  acerto  ao  acaso  representa  as  respostas  corretas  dadas 

aleatoriamente, o chamado â€œchuteâ€. Em relaÃ§Ã£o Ã  CCI, o parÃ¢metro ğ‘ Ã© dado pelo ponto em que a 

assÃ­ntota inferior ao grÃ¡fico intercepta o eixo das probabilidades. Em uma prova em que cada item 

possua quatro alternativas, espera-se valores ligeiramente inferiores a 0,25 para o acerto ao acaso 

Rabelo (2013). Caso o valor seja muito superior a 0,25, isso indica que a resposta correta atrai tanto 

os respondentes com altas habilidades quanto os respondentes com baixas habilidades, ou seja, o 

parÃ¢metro ğ‘ Ã© o mesmo independentemente da habilidade do respondente. 

 
 
 
 
 
36 

3.5 CritÃ©rio dos distratores 

Outro componente importante a ser considerado ao avaliar um teste Ã© o estudo dos distratores. 

Esta anÃ¡lise complementa os parÃ¢metros de dificuldade e discriminaÃ§Ã£o do item. 

Conforme Urbina (2007), para que se tenha um item de mÃºltipla escolha ideal, a alternativa 

correta deste item deve ser Ã³bvia para o testando que possui as habilidades necessÃ¡rias para resolvÃª-

lo, e os distratores parecem igualmente plausÃ­veis para aqueles que nÃ£o possuem as habilidades 

necessÃ¡rias para resolver o item. Portanto elaborar um item com bons distratores nÃ£o Ã© uma tarefa 

simples,  pois  hÃ¡  uma  linha  tÃªnue  entre  um  bom  distrator  e  uma  â€œpegadinhaâ€,  ou  seja,  uma 

alternativa incorreta que atrai os testandos que possuem o conhecimento necessÃ¡rio para resolver 

o item (TORRES, 2015).  

Segundo  Urbina  (2007),  depois  da  aplicaÃ§Ã£o  de  um  teste,  deve-se  realizar  uma  anÃ¡lise  dos 

distratores, comeÃ§ando pela quantidade de testandos que selecionou cada distrator. Para a autora, 

â€œo exame cuidadoso da frequÃªncia com que os vÃ¡rios distratores foram escolhidos por testandos de 

diferentes  nÃ­veis  de  habilidade  serve  para  detectar  possÃ­veis  falhas  nos  itensâ€.  Desta  forma, 

seguindo a orientaÃ§Ã£o de Urbina, faremos um estudo dos distratores da prova JaraguÃ¡.  

3.6 Confiabilidade do Teste 

Um fator importante na elaboraÃ§Ã£o de um teste Ã© sua confiabilidade. VÃ¡rios fatores influenciam 

nos resultados de um teste, como a motivaÃ§Ã£o dos respondentes, condiÃ§Ãµes do local em que estÃ¡ 

sendo aplicado, clima, entre outros. Um teste totalmente confiÃ¡vel seria aquele que nÃ£o possui erros 

sistemÃ¡ticos, ou seja, erros que podem ser corrigidos apÃ³s serem detectados. Por exemplo: se foi 

detectado que um termÃ´metro mede 1Âº C a mais em todas as suas mediÃ§Ãµes, basta corrigir esta 

diferenÃ§a no momento de apresentar os resultados. 

Segundo Vianna (1982, p.157-160), sÃ£o vÃ¡rios os fatores que afetam a fidedignidade de um 

teste  e  podem  ser  relacionados  ao  prÃ³prio  teste  ou  ao  examinado.  Com  relaÃ§Ã£o  ao  teste,  ele 

argumenta que; 

i)  quanto maior o nÃºmero de itens, maior a fidedignidade; 

ii)  quanto menor a amplitude da dificuldade dos itens, maior a fidedignidade; 

iii) quanto maior a interdependÃªncia dos itens, menor a fidedignidade; 

iv)  quanto mais objetiva a correÃ§Ã£o, maior a fidedignidade; 

v)  quanto mais homogÃªneo o teste, maior a fidedignidade; e  

 
 
vi)  quanto maior a introduÃ§Ã£o de elementos estranhos e/ou capiciosos no teste, menor a sua 

37 

fidedignidade. 

3.7  Alfa de Cronbach 

Diante de tantos fatores influenciÃ¡veis na confiabilidade de um teste, podemos nos perguntar: 

como obter um Ã­ndice aceitÃ¡vel de confiabilidade? Uma das maneiras de responder essa pergunta 

e que tambÃ©m servirÃ¡ de base para os estudos deste trabalho Ã© calcular o alfa de Cronbach (ğ›¼).  

Para Anjos  e Andrade (2012, p. 9) o coeficiente alfa de Cronbach Ã© utilizado para medir a 

consistÃªncia  interna  do  instrumento  de  medida.  Proposto  por  Cronbach  (1951),  Ã©  o  que  gera  o 

menor  valor,  considerado  como  limite  inferior  dos  coeficientes  de  fidedignidade  de  um  teste, 

conforme Arias, Lloreda& Lloreda (2006, p. 54). Para MuÃ±iz (2003, p. 54), mais que a estabilidade 

das medidas, o coeficiente ğ›¼ reflete o grau em que covariam os itens que constituem o teste, sendo, 

portanto, um Ã³timo indicador de sua consistÃªncia interna, cuja estatÃ­stica Ã© dada pela EquaÃ§Ã£o 3.5. 

                                             ğ›¼ =

ğ‘›
ğ‘› âˆ’ 1

(1 âˆ’

ğ‘›
2 
âˆ‘ ğœğ‘–
ğ‘–=1
2
ğœğ‘‹

) , ğ‘› â‰  1 ğ‘’ ğœğ‘‹

2 â‰  0                              (3.5) 

2 representa a variÃ¢ncia do item ğ‘– (ğ‘– = 1, 2, â€¦ , ğ‘›) e, ğœğ‘‹

2, a variÃ¢ncia total dos escores do 

em que ğœğ‘–
teste.  

Conforme ğœğ‘–

2 diminui, ou seja, conforme a variÃ¢ncia entre os itens diminui, maior serÃ¡ valor 

de ğ›¼, o que implica uma maior consistÃªncia interna, aumentando a confiabilidade do teste. O valor 

de  ğ›¼  varia  no  intervalo  [0,1].  Segundo  Vianna  (1982)  uma  fidedignidade  mÃ­nima  de  0,70  Ã© 

considerada aceitÃ¡vel para fins de decisÃ£o. 

3.8   Unidimensionalidade do teste 

Analisar a unidimensionalidade do teste significa analisar se apenas uma habilidade estÃ¡ sendo 

medida  pelo  teste.  Por  exemplo,  um  teste  de  matemÃ¡tica  que  contÃ©m  alguns  itens  que  sÃ£o 

estritamente  computacionais  e  outro  que  envolve  material  verbal  provavelmente  nÃ£o  sÃ£o 

unidimensionais  (KOLEN;  BRENNAN,  2013).  Segundo  Junker  (2012)  fazemos  isso  por  dois 

motivos: primeiro, estes itens aumentam a confiabilidade do teste; e segundo, um teste composto 

por itens unidimensionais sÃ£o mais fÃ¡ceis de expor e explicar.  

 
 
 
 
38 

Existem  vÃ¡rios  mÃ©todos  para  determinar  a  dimensionalidade  de  um  teste.  Pasquali  (2003), 

comenta que os mÃ©todos que apresentam maiores propriedades estÃ£o baseados na anÃ¡lise fatorial e 

no traÃ§o latente (TRI). Para Andriola (2009), os seguintes mÃ©todos merecem destaque na literatura 

mundial: o procedimento de Bejar; o contraste de Gustaffson; o mÃ©todo de McDonald; o contraste 

Q1  e  Q2  de  Van  den  Wollenber;  a  anÃ¡lise  de  procedÃªncia  modificada;  o  mÃ©todo  Hattie  para  a 

comparaÃ§Ã£o de autovalores reais e simulados; e o mÃ©todo da equaÃ§Ã£o de regressÃ£o.  

Com  fundamento  na  anÃ¡lise  fatorial,  neste  trabalho  vamos  utilizar  o  mÃ©todo  das  cargas 

fatoriais para estudar a dimensionalidade do item. Carga fatorial Ã© a correlaÃ§Ã£o entre a variÃ¡vel e o 

fator. A carga ao quadrado Ã© a quantia de variÃ¢ncia total da variÃ¡vel explicada pelo fator (Hair et. 

al.,  2005,  p.109).  Conforme  Pasquali  (2003),  um  critÃ©rio  mÃ­nimo  para  que  um  item  seja 

unidimensional  Ã©  uma  carga  fatorial  maior  ou  igual  do  que  0,30.  TambÃ©m  analisamos  a 

dimensionalidade do teste por meio do mÃ©todo scree-plot. Idealizado por R. B. Cattel em 1996, o 

mÃ©todo  scree-plot  Ã©  utilizado  para  identificar  o  nÃºmero  de  fatores  a  ser  extraÃ­do  com  base  na 

representaÃ§Ã£o grÃ¡fica dos autovalores da matriz. Para Andriola (2009) o procedimento consiste em 

traÃ§ar uma reta paralela aos fatores que possuem autovalores mais baixos, atÃ© que a mesma â€œcorteâ€ 

o eixo das ordenadas. SÃ£o detidos tantos fatores quanto o nÃºmero de autovalores que estejam na 

parte superior da reta (Figura 3.3). 

Figura 3.3 - Exemplo da aplicaÃ§Ã£o do mÃ©todo scree-plot 

Fonte: Adaptado de Hair. et. al. (2005) 

 
 
 
39 

No exemplo da Figura  3.3 temos um  teste considerado multidimensional,  pois  hÃ¡ 3 fatores 

com  autovalores  na  parte  superior  da  reta.  Este  teste  tambÃ©m  Ã©  conhecido  como  â€œregra  do 

cotoveloâ€, o que significa que se conseguimos enxergar um â€œcotoveloâ€ ao realizar o procedimento 

de traÃ§ar a reta, isso indica que apenas um fator possui autovalor acima desta reta, ou seja, o teste 

pode ser considerado unidimensional.  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
40 

4 RevisÃ£o de Literatura 

Neste  capÃ­tulo  apresentamos  os  resultados  de  alguns  trabalhos  que  realizaram  anÃ¡lises 

similares Ã s que propomos neste trabalho, considerando a confiabilidade do teste, discriminaÃ§Ã£o 

dos itens, nÃ­vel de dificuldade dos itens, anÃ¡lise dos distratores e acerto ao acaso. Estes critÃ©rios 

vÃ£o servir de base para analisarmos a qualidade de um item e se ele deve ou nÃ£o permanecer no 

teste.  

Um dos trabalhos que nos auxiliou nas anÃ¡lises foi DiferenÃ§as nas RealizaÃ§Ãµes MatemÃ¡ticas 

de  Acordo  com  a  Oportunidade  para  Aprender  (OPA):  Um  Estudo  Utilizando  um  Modelo  de 

Quatro ParÃ¢metros da Teoria de Resposta ao Item, (BARNARD-BRAK et al, 2018). 

Neste trabalho foi analisado o desempenho dos estudantes nos itens do Programa Internacional 

de AvaliaÃ§Ã£o dos Estudantes (PISA) em 2012, nos Estados Unidos. Para este estudo foi utilizado 

um modelo de quatro parÃ¢metros em que o quarto parÃ¢metro (d) corresponde ao â€œdescuidoâ€, ou 

seja,  uma  explicaÃ§Ã£o  para  que  um  estudante  com  bom  desempenho  tenha  respondido  de  forma 

errada a um determinado item. 

O objetivo desta pesquisa Ã© saber se a probabilidade de um estudante com alta proficiÃªncia 

responder errado um determinado item estÃ¡ relacionada com o fato de este estudante ter recebido 

mais ou menos oportunidades de aprender (OPA).  

O  resultado  foi  uma  pequena,  porÃ©m  estatisticamente  significativa  relaÃ§Ã£o  entre  OPA  e  o 

desempenho  em  testes  de  matemÃ¡tica.  Com  o  aumento  da  oportunidade  para  aprender  dos 

estudantes, o seu desempenho em matemÃ¡tica aumentou tambÃ©m. 

JÃ¡ na tese de doutorado de Maia (2009), Uso da Teoria ClÃ¡ssica dos Testes â€“ TCT e da Teoria 

de Resposta ao Item â€“ TRI na AvaliaÃ§Ã£o da Qualidade MÃ©trica de Testes de SeleÃ§Ã£o, foi utilizada 

a  TCT  como  instrumento  na  avaliaÃ§Ã£o  da  qualidade  mÃ©trica  da  prova  do  concrso  vestibular  da 

Universidade  Estadual  do  CearÃ¡  â€“  UECE,  de  2007,  envolvendo  as  disciplinas  de  PortuguÃªs  e 

MatemÃ¡tica. Participaram 20.016 candidatos a 38 cursos de graduaÃ§Ã£o, que deveriam responder 14 

questÃµes de PortuguÃªs e 10 questÃµes de MatemÃ¡tica. 

De maneira geral, a prova de matemÃ¡tica que foi analisada neste trabalho apresenta um Ã­ndice 

mÃ©dio de dificuldade, tanto pela TCT quanto pela TRI. AlÃ©m disso, tanto o item considerado mais 

fÃ¡cil (item 03) quanto o item considerado mais difÃ­cil (item 06) foram os mesmos em ambas as 

teorias. 

 
 
41 

No que diz respeito a discriminaÃ§Ã£o dos itens, os resultados apresentados pela TRI foram mais 

significativos  do  que  os  ocasionados  na  TCT.  Num  intervalo  prÃ¡tico  de  0  a  3,  os  resultados  se 

mostraram variando de 1,418 para o item 06 a 2,603, para o item 04. Assim, pela TRI, foi concluÃ­do 

pelo autor que essa prova se mostrou com um Ã³timo comportamento discriminativo. 

A anÃ¡lise pedagÃ³gica dos itens considerados o mais fÃ¡cil e o mais difÃ­cil da prova, tambÃ©m 

serviu de referÃªncia para as nossas anÃ¡lises. Dentre estas anÃ¡lises destacam-se as sugestÃµes para 

mudanÃ§as no enunciado que o tornariam mais claro, e discussÃ£o das estratÃ©gias de resoluÃ§Ã£o do 

item. 

Outro trabalho com proposta similar Ã  nossa foi feito por Silva (2015), intitulado Teoria de 

Resposta ao Item â€“ TRI em AvaliaÃ§Ãµes de MatemÃ¡tica na EEM Professor Gabriel EpifÃ¢nio dos 

Reis.  

Este  trabalho  teve  como  foco  principal  a  avaliaÃ§Ã£o,  discutindo  o  ato  de  avaliar  e  os 

instrumentos que podem ser utilizados para que os resultados atingidos sejam os esperados.  De 

uma  forma  mais  especÃ­fica,  neste  trabalho  priorizou-se  como  objetivo  analisar  a  aplicaÃ§Ã£o  da 

Teoria de resposta ao Item (TRI) em avaliaÃ§Ãµes de MatemÃ¡tica do Ensino MÃ©dio da escola Gabriel 

EpifÃ¢nio. 

Para um pÃºblico de 61 estudantes da 1Âª sÃ©rie do Ensino MÃ©dio foi aplicada uma prova com 9 

itens objetivos, todos dicotÃ´micos, ou seja, com respostas classificadas em certas ou erradas. As 

notas dos estudantes foram calculadas inicialmente utilizando a TCT, proporcional ao nÃºmero de 

acertos,  tendo  cada  questÃ£o  o  mesmo  peso  e  depois  recalculada  atravÃ©s  do  modelo  logÃ­stico 

unidimensional  de  3  parÃ¢metros  (ML3)  da  TRI  em  que  foram  utilizados  os  parÃ¢metros  de 

dificuldade b, discriminaÃ§Ã£o a, e acerto ao acaso c. 

O  software  utilizado  para  estimar  os  resultados  foi  o  ICL  -  (IRT  Command  Language). 

Segundo  MendonÃ§a  (2012),  este  Ã©  um  software  criado  por  Brad  Hanson  e  que  pode  fazer 

estimativas dos parÃ¢metros dos modelos logÃ­sticos 1, 2 e 3 parÃ¢metros de itens dicotÃ´micos. 

Analisando as curvas caracterÃ­stica dos itens o autor apresenta os itens 1 e 8, considerados o 

mais  difÃ­cil  e  o  mais  fÃ¡cil,  respectivamente.  O  item  1  exigia  do  respondente  conhecimentos  de 

SemelhanÃ§a  de  TriÃ¢ngulos,  enquanto  o  item  8  exigia  conhecimentos  sobre  a  influÃªncia  dos 

coeficientes no grÃ¡fico de uma equaÃ§Ã£o do 2Âº grau.  

Observamos uma comparaÃ§Ã£o feita pelo autor entre os resultados obtidos na TCT e na TRI. 

De  modo  geral,  neste  trabalho,  as  notas  dos  estudantes  na  TRI  foram  maiores  do  que  na  TCT, 

 
42 

enquanto  que  em  outras  situaÃ§Ãµes  as  notas  na  TCT  sÃ£o  maiores.  Um  grÃ¡fico  de  dispersÃ£o  foi 

utilizado para comparar os resultados dos estudantes nas duas teorias, apontanto, por exemplo, que 

em  algumas  situaÃ§Ãµes,  dois  indivÃ­duos  atingiram  a  mesma  nota  na  TCT  (acertaram  o  mesmo 

nÃºmero de questÃµes), mas quando o mÃ©todo avaliativo foi a TRI, atingiram notas distintas. 

Na busca por trabalhos que utilizassem a aplicaÃ§Ã£o de simulados, encontramos o trabalho de  

TÃ´rres (2015): Uma aplicaÃ§Ã£o da Teoria de Resposta ao Item em um Simulado de MatemÃ¡tica no 

Modelo ENEM. AlÃ©m da TRI, a anÃ¡lise dos itens tambÃ©m foi feita utilizado a Teoria ClÃ¡ssica dos 

Testes,  com  o  objetivo  de  fornecer  um  feedback  aos  professores  elaboradores  do  simulado  e 

possibilitar a criaÃ§Ã£o de um banco de itens na escola. 

O  simulado  contendo  45  itens  da  Ã¡rea  de  MatemÃ¡tica  foi  aplicado  para  165  estudantes  do 

Ensino MÃ©dio e prÃ©-vestibular de um colÃ©gio do Distrito federal, respeitando as mesmas condiÃ§Ãµes 

de aplicaÃ§Ã£o da prova propostas pelo ENEM. Para a anÃ¡lise destes itens utilizou-se o programa R, 

apÃ³s os dados estarem tabelados no Excel. 

A anÃ¡lise dos itens foi feita em quatro subseÃ§Ãµes: anÃ¡lise dos itens deficientes, itens sujeitos a 

reelaboraÃ§Ã£o, itens sujeitos a aprimoramento e itens bons. Apresentamos algumas das principais 

informaÃ§Ãµes de cada uma dessas subseÃ§Ãµes.  

Na anÃ¡lise de itens deficientes foram descartados quatro itens, sendo trÃªs deles por nÃ£o terem 

atingido o valor mÃ­nimo de 20% no Ã­ndice de discriminaÃ§Ã£o proposto por Ebel (1965). O quarto 

item (item 145) descartado foi um pouco mais curioso. Se este item fosse avaliado apenas pela 

TRI,  teria  resultado  satisfatÃ³rio,  com  os  parÃ¢metros  ğ‘ = 1,737, ğ‘ = 2,142  e  ğ‘ = 0,179,  sendo 

considerado um item muito difÃ­cil. PorÃ©m, alÃ©m da discriminaÃ§Ã£o ter sido igual a 19% na TCT, 

duas  das  alternativas  incorretas  apresentam  um  considerÃ¡vel  bisserial  positivo,  logo  hÃ¡  um 

indicativo de que o item nÃ£o foi bem formulado, pelo fato destas alternativas serem marcadas com 

mais frequÃªncia por estudantes com bom desempenho.   

Em  relaÃ§Ã£o  aos  itens  sujeitos  a  reelaboraÃ§Ã£o  foram  classificados  7  itens.  O  autor  sugere 

mudanÃ§as no enunciado das questÃµes alÃ©m de aplicaÃ§Ãµes em um grupo maior de estudantes, para 

verificar se o comportamento dos distratores se mantÃ©m. O autor chama a atenÃ§Ã£o para o item 166 

em que uma simples diferenÃ§a no arredondamento do ğœ‹ para 3,14 ou 3 faria com que a resposta do 

estudante fosse diferente. Como este arredondamento nÃ£o foi esclarecido no enunciado da questÃ£o, 

este provavelmente foi o motivo pelo qual o item nÃ£o apresentou um resultado melhor. 

 
43 

No  grupo  dos  itens  sujeitos  a  aprimoramento  apareceram  8  questÃµes  e  no  grupo  dos  itens 

considerados bons foram classificadas 26 questÃµes. Para os itens sujeitos a aprimoramento o autor 

tambÃ©m sugere mudanÃ§as no enuciado das questÃµes alÃ©m de sugerir novas aplicaÃ§Ãµes para grupos 

maiores.  

Os trabalhos citados, juntamente com as suas referÃªncias, auxiliaram muito em nossas certezas 

provisÃ³rias e dÃºvidas temporÃ¡rias. Tanto  para o embasamento teÃ³rico quanto  para as anÃ¡lises e 

discussÃµes  dos  resultados,  estudar  o  que  foi  realizado  nestes  trabalhos,  incluindo  limitaÃ§Ãµes  e 

sugestÃµes, foi de fundamental importÃ¢ncia na realizaÃ§Ã£o da nossa pesquisa.  

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
44 

5  Metodologia 

Neste capÃ­tulo falamos sobre a cidade de JaraguÃ¡ do Sul, mencionando algumas caracterÃ­sticas 

relevantes no que diz respeito a educaÃ§Ã£o. AlÃ©m disso, apresentamos a prova JaraguÃ¡, como essa 

prova Ã© aplicada, o pÃºblico envolvido, alÃ©m dos procedimentos que serÃ£o utilizados para avalia-la. 

Situado  no  norte  do  estado  de  Santa  Catarina,  o  municÃ­pio  de  JaraguÃ¡  do  Sul,  segundo  o 

Instituto Brasileiro de Geografia EstatÃ­stica â€“ IBGE, possui 170.835 habitantes. Estes dados sÃ£o 

referentes  Ã   ultima  publicaÃ§Ã£o  do  IBGE  em  30  de  agosto  de  2017.  Segundo  o  prÃ³prio  IBGE  o 

municÃ­pio de JaraguÃ¡ do Sul possui uma taxa de escolarizaÃ§Ã£o de 98,3% entre as pessoas de 6 a 14 

anos de idade. AlÃ©m disso, no Ãºltimo IDEB, referente ao ano de 2015, o municÃ­pio atingiu a nota 

6,9 para os anos iniciais e 5,6 para os anos finais, sendo superiores aos Ã­ndices nacionais de 5,3 e 

3,8 para os anos iniciais e finais, respectivamente (INEP, 2018). A Figura 5.1 mostra a localizaÃ§Ã£o 

do municÃ­pio em relaÃ§Ã£o ao mapa do Brasil.  

Figura 5.1 - LocalizaÃ§Ã£o do municÃ­pio de JaraguÃ¡ do Sul 

JaraguÃ¡ do Sul 

Assim como existe uma preocupaÃ§Ã£o individual de cada professor, no municÃ­pio de JaraguÃ¡ 

do Sul, sempre houve uma preocupaÃ§Ã£o muito grande com a qualidade do ensino. A feira municipal 

de matemÃ¡tica e a feira municipal de ciÃªncias e tecnologia (Figura 5.2) sÃ£o exemplos de aÃ§Ãµes em 

prol de uma EducaÃ§Ã£o melhor. PorÃ©m, para elaborar aÃ§Ãµes mais pontuais nas escolas necessita-se, 

primeiramente, saber qual a real situaÃ§Ã£o de cada Unidade de Ensino e seus respectivos estudantes. 

Para isso, a rede municipal de ensino de JaraguÃ¡ do Sul iniciou em 2014 um programa de simulados 

 
 
45 

bienais com o intuito de criar, futuramente, um Ã­ndice de cada uma das disciplinas curriculares para 

o municÃ­pio. Ã‰ claro que a ideia Ã© identificar os problemas e apontar possÃ­veis soluÃ§Ãµes para estes 

problemas, de modo geral ou para determinado local especÃ­fico. 

Figura 5.2 - VI Feira Municipal de EducaÃ§Ã£o MatemÃ¡tica de JaraguÃ¡ do Sul, e Feira Municipal 
CientÃ­fica e TecnolÃ³gica (FECITEC) 2017 

Fonte: https://jdv.com.br 

Aplicada  pela  primeira  vez  em  2015,  a  prova  JaraguÃ¡  abrangeu  todas  as  27  escolas  do 

municÃ­pio de JaraguÃ¡ do Sul, para as turmas de 6Âº ao 9Âº ano da EducaÃ§Ã£o BÃ¡sica. A 2Âª ediÃ§Ã£o da 

prova estÃ¡ programada para este ano (2018). Fazem a prova aproximadamente 10.000 estudantes 

da rede pÃºblica municipal, compreendidos em uma faixa etÃ¡ria de 10 a 15 anos. A prova Ã© formada 

pelas  9  disciplinas  do  currÃ­culo  escolar:  PortuguÃªs,  MatemÃ¡tica,  CiÃªncias,  HistÃ³ria,  Geografia, 

Ensino Religioso, Artes, InglÃªs e EducaÃ§Ã£o FÃ­sica. As provas sÃ£o formadas por 10 questÃµes de cada 

disciplina. Os estudantes realizam estas provas em trÃªs dias consecutivos, sendo trÃªs disciplinas 

por  dia.  Ã‰  disponibilizado  aos  estudantes  o  perÃ­odo  de  3  horas/aula  (135  minutos)  para  que 

concluam as 30 questÃµes de cada dia. A elaboraÃ§Ã£o desta prova envolveu uma equipe de professores 

da  Secretaria  Municipal  de  EducaÃ§Ã£o  que  recebeu  um  treinamento  na  Universidade  Federal  de 

Santa Catarina com o professor Dalton Francisco de Andrade. 

Para a realizaÃ§Ã£o deste trabalho foram levadas em consideraÃ§Ã£o as respostas de 300 estudantes 

das  turmas  do  8Âº  ano  que  responderam  um  teste  com  10  questÃµes  referente  Ã   disciplina  de 

matemÃ¡tica no ano de 2015. Por ser um nÃºmero muito grande de estudantes, a Secretaria Municipal 

 
 
46 

da EducaÃ§Ã£o (SEMED) tomou esta amostra de 300 alunos para as devidas anÃ¡lises, tais como Ã­ndice 

por escola, Ã­ndice por turma, Ã­ndice do municÃ­pio, etc. Assim, com a disponibilizaÃ§Ã£o destes dados 

pela SEMED, realizamos todo o trabalho. 

A Figura 5.3 mostra um fluxograma discriminando passo a passo as anÃ¡lises que serÃ£o feitas 

neste trabalho.  

Figura 5.3 - AnÃ¡lises realizadas 
Figura 5.3 - AnÃ¡lises realizadas 

Estas  anÃ¡lises  foram  feitas  utilizando  a  TCT  e  a  TRI  aplicando  o  modelo  logÃ­stico  de  trÃªs 

parÃ¢metros. Como o INEP (2014) desconsidera a inclusÃ£o de questÃµes que possuem uma correlaÃ§Ã£o 

ponto-bisserial inferior a 0,20, adotamos este critÃ©rio para a exclusÃ£o dos ites deficientes da prova 

JaraguÃ¡, tanto das anÃ¡lises pela TCT quanto pela TRI. Em relaÃ§Ã£o a anÃ¡lise pedagÃ³gica dos itens 

tentamos  apontar  alguns  fatores  que  possam  ter  influenciado  o  baixo  nÃ­vel  de  correlaÃ§Ã£o.  A 

obtenÃ§Ã£o dos resultados se deu por meio do software versÃ£o 3.4.2 (R CORE TEAM, 2017), com 

os pacotes mirt versÃ£o 1.28 (CHALMERS, 2012), CTT versÃ£o 2.3.2 (WILLSE, 2017), psych 1.8.4 

(REVELLE, 2017) e ltm versÃ£o 1.1-1 (RIZOPOULOS, 2006). O conjunto de dados utilizado para 

as anÃ¡lises e a rotina estÃ£o nos anexos II e III, respectivamente. 

 
 
 
 
 
 
 
 
 
 
 
 
 
47 

6  Resultados e DiscussÃ£o 

Neste  capÃ­tulo  vamos  apresentar  os  resultados  referentes  Ã s  duas  teorias  de  estudo  deste 

trabalho aplicadas na prova JaraguÃ¡. Estes resultados vÃ£o servir de base para a anÃ¡lise estatÃ­stica e 

pedagÃ³gica. 

6.1  Algumas estatÃ­sticas descritivas 

Nas tabelas e figuras a seguir apresentam-se os resultados obtidos e comentados atravÃ©s das 

teorias TCT e TRI.  

Iniciamos apresentando a Tabela 6.1. Esta tabela contÃ©m os valores referentes a quantidade de 

acertos das questÃµes, ou seja, quantos estudantes acertaram apenas uma questÃ£o, quantos estudantes 

acertaram duas questÃµes, e assim sucessivamente. 

Tabela 6.1 - FrequÃªncia das pontuaÃ§Ãµes totais 

Quantidade de questÃµes 
FrequÃªncia 

0 
1 

1 
7 

3 
2 
21 
55 
Fonte: Do autor. 

4 
65 

5 
57 

6 
43 

7 
28 

8 
17 

9 
5 

10 
1 

Apenas um dos alunos respondeu corretamente todas as questÃµes. Da mesma maneira, apenas 

um dos alunos nÃ£o acertou nenhuma das questÃµes. AlÃ©m disso, a maior parte dos alunos acertou 

cinco questÃµes ou menos. 

Na Tabela 6.2 podemos ver uma representaÃ§Ã£o dos itens no que diz respeito as quantidades de 

erros e acertos.  

Tabela 6.2 - ProporÃ§Ãµes para cada nÃ­vel de resposta. 

Item 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 

Erros  Acertos 
0,7967 
0,1967 
0,5033 
0,4933 
0,6033 
0,3967 
0,3300 
0,6667 
0,2200 
0,7800 
0,2700 
0,7267 
0,7800 
0,2133 
0,6400 
0,3533 
0,3967 
0,6000 
0,1400 
0,8600 
Fonte: do autor. 

 
 
 
48 

Na Tabela 6.3 temos os valores de outras estatÃ­sticas descritivas da prova. 

Tabela 6.3 - Outras estatÃ­sticas descritivas 

FunÃ§Ã£o 
MÃ©dia 
Moda 
Mediana 
Q1 
Q3 

Valor 
4,71 
4,00 
5,00 
3,00 
6,00 
Nota MÃ¡xima  10,00 
0,00 
Nota MÃ­nima 
3,26 
VariÃ¢ncia 
1,80 
Desvio PadrÃ£o 

Fonte: Do autor. 

Como as notas variam de 0 a 10, o valor igual a 6 para o terceiro quartil (Q3) monstrou que a 

maior parte das notas altas estÃ£o mais prÃ³ximas de 5 do que de 10, o que jÃ¡ era de se esperar apÃ³s 

analisarmos os resultados da tabela de frequÃªncia (Tabela 6.1). 

Na Figura 6.1 apresentamos um histograma das notas dos alunos. 

Figura 6.1 - Histograma das notas dos alunos 

Fonte: do autor. 

 
 
49 

De acordo com o histograma (Figura 6.1) podemos ver que concentraÃ§Ã£o de notas baixas Ã© 

maior do que a concentraÃ§Ã£o de notas altas. Podemos ver tambÃ©m que grande parte dos estudantes 

atingiu notas entre 3 e 6. 

6.2  Confiabilidade do teste 

Uma das formas de avaliar a confiabilidade do teste Ã© atravÃ©s do valor do alfa de Cronbach, 

que foi igual a 0,429. Na Tabela 6.4 temos a alteraÃ§Ã£o no valor do alfa de Cronbach mediante a 

exclusÃ£o de um determinado item. 

Tabela 6.4 - ConsequÃªncia no valor do alfa de Cronbach com a exclusÃ£o de cada item do teste. 

Excluindo  Valor 
0,4040 
0,4515 
0,3582 
0,3918 
0,4353 
0,4210 
0,3906 
0,3871 
0,3845 
0,3984 

Item 1 
Item 2 
Item 3 
Item 4 
Item 5 
Item 6 
Item 7 
Item 8 
Item 9 
Item 10 
Fonte: Do autor 

Constatamos que a retirada dos itens 2 e 5 implicaria em uma pequena melhora do valor do 

alfa de Cronbach. Apesar de melhorar o coeficiente ğ›¼, o mesmo ainda nÃ£o atingiria o nÃ­vel aceitÃ¡vel 

de 0,70. 

Na Tabela 6.5 estÃ£o os resultados inerentes a confiabilidade do teste utilizado como base deste 

estudo, levando em consideraÃ§Ã£o correlaÃ§Ã£o ponto-bisserial.  

 
 
 
 
 
 
 
 
 
50 

Tabela 6.5 - CorrelaÃ§Ã£o ponto-bisserial. 

Item 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 

CorrelaÃ§Ã£o ponto-
bisserial 
0,23925079 
0,06158151 
0,35052307 
0,25559223 
0,10074721 
0,15913489 
0,28967397 
0,26803129 
0,27147925 
0,29806435 

Fonte: Do autor. 

Os itens 1, 4, 7, 8 e 9 necessitam de revisÃ£o, pois possuem correlaÃ§Ã£o ponto-bisserial inferior 

a 0,29, Ã­ndice mÃ­nimo conforme orienta Pasquali (2003). AlÃ©m disso, os itens que atingiram o valor 

mÃ­nimo  da  correlaÃ§Ã£o  ponto-bisserial  estÃ£o  muito  prÃ³ximos  do  limite,  o  que  mostra  uma  baixa 

consistÃªncia dos itens.  

Na Tabela 6.6 estÃ£o os dados referentes a correlaÃ§Ã£o Ponto Bisserial com a pontuaÃ§Ã£o total 

dos escores, o que nos permite fazer uma anÃ¡lise sobre quais itens podem ser excluÃ­dos para obter 

um teste com maior poder de discriminaÃ§Ã£o.   

Tabela 6.6 - CorrelaÃ§Ã£o Ponto Bisserial com Escores Total 

Item 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 

IncluÃ­do  ExcluÃ­do 
0,3930 
0,3304 
0,5156 
0,4421 
0,2963 
0,3581 
0,4233 
0,4665 
0,4526 
0,3765 
Fonte: Do autor 

0,184 
0,0593 
0,2773 
0,2012 
0,0721 
0,1217 
0,2115 
0,2239 
0,2024 
0,1971 

A exclusÃ£o dos ites nÃ£o implica em melhoras significativas dos coeficientes de correlaÃ§Ã£o 

ponto-bisserial, o que pode ser explicado pela pequena quantidade de itens no teste. 

 
 
 
51 

6.3  Unidimensionalidade do teste 

Vamos utilizar dois mÃ©todos para determinar a dimensionalidade do teste: o mÃ©todo das cargas 

fatoriais e o mÃ©todo scree-plot. Iniciamos com a Tabela 6.7 que apresenta as cargas fatoriais dos 

itens. 

Tabela 6.7 - Cargas fatoriais 

Item 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 

F1 
0,800 
0,364 
0,930 
0,973 
0,964 
0,659 
0,466 
0,703 
0,707 
0,589 
Fonte: Do autor 

Conforme apresentado na Tabela 6.7, percebemos que a carga fatorial dos itens 2 e 7 sÃ£o as 

mais baixas, porÃ©m ultrapassam o valor mÃ­nimo de 0,30, critÃ©rio mÃ­nimo de unidimensionalidade 

proposto por Pasquali (2003). 

Na Figura 6.2 apresentamos o grÃ¡fico scree-plot da prova JaraguÃ¡. 

Figura 6.2 - GrÃ¡fico scree-plot da prova JaraguÃ¡ 

Fonte: do autor. 

 
 
 
52 

Aplicando a â€œregra do cotoveloâ€ nÃ£o foi possÃ­vel determinar uma multidimensionalidade no 

teste,  pois  apenas  um  dos  fatores  apresentou  autovalor  acima  da  reta,  o  que  indica  um  teste 

unidimensional. Assim, o teste Ã© constituÃ­do por poucas questÃµes e, aparentemente, possui apenas 

uma dimensÃ£o.  

6.4  AnÃ¡lise no Ã¢mbito da TCT 

Como o INEP (2014) desconsidera a inclusÃ£o de questÃµes que possuem uma correlaÃ§Ã£o ponto-

bisserial inferior a 0,20, os itens 2, 5 e 6 foram excluÃ­dos, tanto das anÃ¡lises pela TCT quanto pela 

TRI. Em relaÃ§Ã£o a anÃ¡lise pedagÃ³gica dos itens tentamos apontar alguns fatores que possam ter 

influenciado o baixo nÃ­vel de correlaÃ§Ã£o. 

Iniciamos as anÃ¡lises da TCT com  a Tabela 6.8 em que consta a classificaÃ§Ã£o dos itens da 

prova JaraguÃ¡ de acordo com o nÃ­vel de dificuldade.  

Tabela 6.8 - Itens da prova JaraguÃ¡ na escala de dificuldade da TCT 

ClassificaÃ§Ã£o 
Muito fÃ¡ceis 
FÃ¡ceis 
Medianos 
DifÃ­ceis 
Muito difÃ­ceis 

Itens 
1 
3, 7 e 8 
9 
4 
10 

%   % esperado 

14,1% 
43,6% 
14,1% 
14,1% 
14,1% 

10% 
20% 
40% 
20% 
10% 

Fonte: do autor. 

De acordo com a Teoria ClÃ¡ssica dos Testes o item mais difÃ­cil da prova JaraguÃ¡ foi o item 10, 

enquanto o item mais fÃ¡cil foi o item 1. Classificando os itens de acordo com a Tabela 2.2, criada 

pelo  autor, os itens 1, 4  e 10,  considerados muito  fÃ¡cil, difÃ­cil  e muito  difÃ­cil, respectivamente, 

atingiram  uma  porcentagem  prÃ³xima  da  desejada.  PorÃ©m  os  itens  considerados  fÃ¡ceis 

compreendem uma porcentagem acima do esperado e, consequentemente, os itens considerados 

medianos compreendem uma porcentagem abaixo do esperado (negrito). Isso mostra que, de modo 

geral, o teste apresentou um nÃ­vel considerado fÃ¡cil. 

Listamos na Tabela 6.9, em ordem decrescente, os itens da prova JaraguÃ¡ de acordo com o seu 

parÃ¢metro de discriminaÃ§Ã£o na Teoria ClÃ¡ssica dos Testes. 

 
 
 
 
 
 
 
 
Tabela 6.9 - ParÃ¢metro de discriminaÃ§Ã£o dos itens da prova JaraguÃ¡ 

53 

Item 
3 
10 
7 
9 
8 
4 
1 

ParÃ¢metro de discriminaÃ§Ã£o 
0,35052307 
0,29806435 
0,28967397 
0,27147925 
0,26803129 
0,25559223 
0,23925079 

Fonte: do autor. 

Considerando os valores que constam na tabela 8 e a classificaÃ§Ã£o dos itens conforme a sua 

discriminaÃ§Ã£o, temos um item com discriminaÃ§Ã£o aceitÃ¡vel que nÃ£o precisa de revisÃ£o (item 3), e 

seis itens que necessitam de revisÃ£o (itens 10, 7, 9, 8, 4 e 1). 

Por meio da anÃ¡lise psicomÃ©trica clÃ¡ssica, de modo geral, verificamos que os itens da prova 

JaraguÃ¡  nÃ£o  apresentam  muito  poder  discriminativo.  Segundo  Oliveira  (2017)  isso  pode  ter 

ocorrido  por  conta  de  uma  quantidade  insuficiente  de  questÃµes.  Uma  quantidade  pequena  de 

questÃµes nÃ£o fornece uma medida confiÃ¡vel sobre o que se pretende medir, mesmo que esses itens 

sejam bastante correlacionados entre si (OLIVEIRA, 2017). 

Para concluir as anÃ¡lises utilizando a Teoria ClÃ¡ssica dos Testes, analisamos os distratores por 

meio dos resultados que estÃ£o apresentados no Quadro 6.1. Os itens 2, 5 e 6 foram mantidos na 

anÃ¡lise dos  distratores  para que pudÃ©ssemos apontar alguns possÃ­veis  motivos  pelos  quais  estes 

itens apresentaram resultados ruins: 

Quadro 6.1 - AnÃ¡lise de distratores 

Resposta 

A 
B 
C 
*D 

Resposta 

A 
*B 
C 
D 

Item 1  

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
1 
0 
7 
47 

0 
0 
3 
95 

7 
6 
35 
100 
Item 3 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
9 
35 
8 
3 

1 
89 
4 
4 

24 
58 
39 
27 

Resposta 

*A 
B 
C 
D 

Resposta 

*A 
B 
C 
D 

Item 2 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
72 
26 
16 
15 
6 
7 
4 
7 

55 
52 
15 
26 
Item 4 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
59 
20 
15 
14 
21 
18 
3 
3 

22 
48 
65 
13 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
54 

Item 5 

Resposta 

A 
B 
*C 
D 

Resposta 

A 
*B 
C 
D 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
4 
10 
10 
31 

7 
14 
37 
40 

27 
25 
20 
76 
Item 7 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
0 
52 
1 
2 

23 
93 
20 
12 

1 
92 
3 
2 

Resposta 

*A 
B 
C 
D 

Resposta 

A 
B 
*C 
D 

Item 6  

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
48 
11 
22 
12 
23 
17 
5 
15 

24 
39 
50 
35 
Item 8 

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
1 
12 
36 
6 

13 
29 
71 
35 

1 
2 
88 
7 

Resposta 

A 
*B 
C 
D 

Item 9  

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
21 
14 
64 
30 
3 
2 
10 
9 

69 
27 
15 
37 

Resposta 

A 
B 
C 
*D 

Item 10  

ProficiÃªncia 
Baixa  MÃ©dia  Alta 
26 
25 
26 
16 
17 
6 
29 
8 

57 
53 
32 
6 

Fonte: Do autor 

Em  todos  os  itens  que  podem  permanecer  no  teste,  um  maior  nÃºmero  de  alunos  com  alta 

proficiÃªncia obteve Ãªxito, ou seja, os alunos que se mostraram preparados para o teste, acertaram 

as  questÃµes  esperadas.  Em  destaque  no  Quadro  6.1  (negrito)  temos  os  distratores  que  atraÃ­ram 

respondentes de mÃ©dia e alta proficiÃªncia, o que aponta possÃ­veis falhas na elaboraÃ§Ã£o do item.  

VÃ¡rios  fatores  importantes  para  os  resultados  da  prova  e  para  futuros  trabalhos  similares 

podem ser observados com a anÃ¡lise que foi feita utilizando a Teoria ClÃ¡ssica dos Testes como: a 

exclusÃ£o  de  itens  que  nÃ£o  satisfazem  requisitos  mÃ­nimos,  Ãªnfase  nas  alternativas  que  atraÃ­ram 

muitos  respondentes  com  alta  proficiÃªncia  (distratores),  alÃ©m  dos  Ã­ndices  de  discriminaÃ§Ã£o  e 

dificuldade que podem ser comparados com os resultados obtidos com a TRI.  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
55 

6.5  AnÃ¡lise no Ã¢mbito da TRI 

De  maneira  semelhante  Ã   nossa  anÃ¡lise  utilizando  a  TCT,  iniciamos  a  anÃ¡lise  na  TRI 

apresentando  a  classificaÃ§Ã£o  dos  itens  levando  em  consideraÃ§Ã£o  o  seu  nÃ­vel  de  dificuldade 

(parÃ¢metro b). 

Tabela 6.10 - ParÃ¢metro de dificuldade - TRI 

Item 
1 
3 
4 
7 
8 
9 
10 

Dificuldade 
0,625 
0,269 
1,258 
-1,675 
-0,162 
1,029 
2,438 

Fonte: do autor. 

Na sequÃªncia classificamos os itens em relaÃ§Ã£o ao seu nÃ­vel de dificuldade. Na Tabela 6.11 

verifica-se o que cada Ã­ndice de dificuldade apresentado na Tabela 6.10 representa na escala que 

vai de muito fÃ¡cil a muito difÃ­cil. 

Tabela 6.11 - ClassificaÃ§Ã£o dos itens em relaÃ§Ã£o ao nÃ­vel de dificuldade â€“ TRI 

ClassificaÃ§Ã£o 
Muito fÃ¡ceis 
FÃ¡ceis 
Medianos 
DifÃ­ceis 
Muito difÃ­ceis 

Itens 
7 
8 
3 
1, 4 e 9 
10 

%   % esperado 

14,1% 
14,1% 
14,1% 
43,6% 
14,1% 

10% 
20% 
40% 
20% 
10% 

Fonte: Do autor 

Destacamos na Tabela 6.11 (negrito) as porcentagens que destoaram muito do que se espera 

para um teste equilibrado no que diz respeito a dificuldade dos itens. O item 10, considerado o mais 

difÃ­cil, e o item 7, considerado o mais fÃ¡cil, foram resultados esperados. A surpresa maior ficou 

para o item 1, o qual serÃ¡ descrito na subseÃ§Ã£o de comparaÃ§Ã£o entre TCT e TRI. 

Na  Tabela  6.12  temos  os  coeficientes  de  discriminaÃ§Ã£o  (parÃ¢metro  a)  dos  itens  da  prova 

JaraguÃ¡. 

 
 
 
 
 
 
56 

Tabela 6.12 - DiscriminaÃ§Ã£o dos itens - TRI 

Item  DiscriminaÃ§Ã£o 

1 
3 
4 
7 
8 
9 
10 

2,266 
4,304 
7,211 
0,897 
1,682 
1,699 
1,241 
Fonte: Do autor. 

Um dos itens com alto Ã­ndice de discriminaÃ§Ã£o que nÃ£o se traduz em sua curva caracterÃ­stica 

Ã© o item  1. Isso  ocorreu devido  ao alto Ã­ndice de acerto ao acaso (Tabela  6.14)  deste item  que, 

conforme  vimos  no  capÃ­tulo  3,  interfere  diretamente  no  cÃ¡lculo  do  Ã­ndice  de  discriminaÃ§Ã£o. 

Lembramos que o nÃ­vel de dificuldade deste apresentou surpresa, o que tambÃ©m pode ser explicado 

pelo alto Ã­ndice de acerto ao acaso, pois o mesmo interfere diretamente no cÃ¡lculo do parÃ¢metro b.  

Na  Tabela  6.13  sÃ£o  apresentados  os  valores  de  acerto  ao  acaso  de  todos  os  itens  da  prova 

JaraguÃ¡. 

Tabela 6.13 - Acerto ao acaso 

Item  Acerto ao acaso 

1 
3 
4 
7 
8 
9 
10 

0,715 
0,337 
0,250 
0,006 
0,223 
0,216 
0,065 
Fonte: Do autor. 

A seguir temos a Figura 6.3 que contÃ©m a curva caracterÃ­sticas de cada um dos itens da prova 

JaraguÃ¡. De modo geral, o comportamento da curva apresenta informaÃ§Ãµes sobre o item no que 

diz respeito a dificuldade, discriminaÃ§Ã£o e acerto ao acaso. 

 
Figura 6.3 - CCIs considerando V2 = item 1 e assim sucessivamente atÃ© V11 = item 10. 

57 

Fonte: Do autor. 

Novamente  mencionamos  o  item  1,  representado  na  Figura  6.3  por  V2.  Analisando  a  CCI 

podemos perceber um grande achatamento da mesma, o que indica pouco poder de discriminaÃ§Ã£o, 

ou  seja,  o  item  nÃ£o  Ã©  capaz  de  separar  os  respondentes  que  possuem  altas  habilidades  dos  que 

possuem baixas habilidades. O item 10 (V11), considerado o mais difÃ­cil do teste, tambÃ©m teve um 

bom Ã­ndice de discriminaÃ§Ã£o. Vale mencionar tambÃ©m a CCI do item 2 (V3). O grande achatamento 

desta curva mostra que o item fornece pouca informaÃ§Ã£o sobre os respondentes.  

Na Figura 6.4 apresentamos a funÃ§Ã£o de informaÃ§Ã£o de cada item do teste. A observaÃ§Ã£o da 

configuraÃ§Ã£o da curva de informaÃ§Ã£o do item representa a maneira como o item se desempenhou 

para cada nÃ­vel de habilidade no que diz respeito ao Ã­ndice de discriminaÃ§Ã£o. 

 
 
 
58 

Figura 6.4 - FunÃ§Ã£o de informaÃ§Ã£o de cada item. 

Fonte: do autor. 

A curva de informaÃ§Ã£o do item 2 (V3) reforÃ§a o que falamos anteriormente, o item realmente 

nÃ£o  apresenta  informaÃ§Ãµes  sobre  os  respondentes.  Os  itens  3  e  4  do  teste  (V4  e  V5, 

respectivamente)  sÃ£o  os  que  mais  discriminam  os  respondentes.  Estes  itens  serÃ£o  discutidos  na 

comparaÃ§Ã£o entre TCT e TRI. Observamos tambÃ©m a curva de informaÃ§Ã£o do item 10 (V11) que 

apresenta informaÃ§Ãµes sobre os respondentes com altas habilidades. 

A opÃ§Ã£o pelo valor da escala se deu pelo alto valor de discriminaÃ§Ã£o dos itens 4, 5 e 6 (V5, V6 

e V7) o que acabou interferindo na visualizaÃ§Ã£o dos outros itens. A Figura 6.5, na qual podemos 

observar todas as curvas de informaÃ§Ã£o do teste (referete aos 10 utens) complementa a Figura 6.4 

e serve tambÃ©m para justificar a mudanÃ§a na escala. 

 
 
 
 
 
Figura 6.5 - FunÃ§Ã£o de informaÃ§Ã£o dos 10 itens 

59 

Fonte: do autor. 

Em seguida temos a curva de informaÃ§Ã£o do teste, juntamente com o erro padrÃ£o. 

Figura 6.6 - Curvas de InformaÃ§Ã£o do Teste e Erro PadrÃ£o 

Fonte: Do autor. 

 
 
 
 
60 

Analisando  a  curva  de  informaÃ§Ã£o  do  teste  e  erro  padrÃ£o,  pode-se  perceber  que  o  mesmo 

apresenta maior informaÃ§Ã£o para os respondentes de proficiÃªncia em torno de 0,5 a 3,0, ou seja, 

nesse  intervalo  hÃ¡  uma  maior  precisÃ£o  na  estimativa  das  proficiÃªncias.  Isso  significa  que  a 

capacidade de discriminar os respondentes que possuem as habilidades necessÃ¡rias para resolver o 

teste  daqueles  que  nÃ£o  possuem,  Ã©  maior  para  os  respondentes  que  possuem  um  nÃ­vel  ğœƒ  de 

habilidade no intervalo (0,5;3,0). NÃ£o podemos deixar de observar uma menor informaÃ§Ã£o em duas 

regiÃµes,  prÃ³ximo  a  (+1)  e  prÃ³ximo  a  (+2)  unidades  da  habilidade  medida.  Isso  significa  que  a 

inclusÃ£o de itens que possuem estes nÃ­veis de dificuldade resultaria em uma maior confiabilidade 

no instrumento de medida. Percebe-se tambÃ©m que o erro de estimativa Ã© maior prÃ³ximo a estes 

dois  nÃ­veis  de  habilidade,  o  que  implica  uma  dificuldade  de  diferenciar  de  forma  precisa  os 

respondentes com nÃ­veis relativamente prÃ³ximos a esses. 

6.6  ComparaÃ§Ã£o entre os resultados na TCT e na TRI 

Nesta subseÃ§Ã£o vamos apresentar uma comparaÃ§Ã£o entre as duas teorias no que diz respeito a 

dificuldade dos itens e discriminaÃ§Ã£o dos itens, analisando os itens da prova JaraguÃ¡ com base nas 

escalas de dificuldade e discriminaÃ§Ã£o deste estudo. Na Figura 6.7 comparamos a classificaÃ§Ã£o dos 

itens por nÃ­veis de dificuldade. 

Figura 6.7 - ClassificaÃ§Ã£o dos itens por nÃ­vel de dificuldade 

TCT

TRI

Esperado

3

3

3

1

1

1

1

1

1

1

1

1

1

1

1

Muito fÃ¡cil

FÃ¡cil

Mediano

DifÃ­cil

Muito difÃ­cil

Fonte: do autor 

3,5

3

2,5

2

1,5

1

0,5

0

 
 
 
 
 
61 

Verifica-se que ambas as teorias nÃ£o atingiram uma quantidade desejÃ¡vel de itens medianos, 

ficando abaixo do esperado. AlÃ©m disso, percebe-se que, de acordo com a TCT, o teste se mostrou 

mais fÃ¡cil do que com a TRI. Nas faixas extremas os resultados estÃ£o dentro do esperado. 

O item mais difÃ­cil do teste considerado por ambas as teorias foi o item 10. O item considerado 

mais fÃ¡cil pela TCT foi o item 1, enquanto o item mais fÃ¡cil de acordo com a TRI foi o item 7. O 

item 1 apresentou um alto Ã­ndice de acerto ao acaso (0,715), o que interfere diretamente no cÃ¡lculo 

do parÃ¢metro de dificuldade da TRI (parÃ¢metro b). Apesar do item 7 nÃ£o ter sido considerado o 

mais fÃ¡cil pela TCT, o mesmo foi considerado um item fÃ¡cil, o que mostra que a anÃ¡lise das duas 

teorias apresentou similaridades. 

Ressaltamos a importÃ¢ncia da anÃ¡lise dos itens com a Teoria ClÃ¡ssica, o que nos fez olhar com 

mais  atenÃ§Ã£o  para  o  item  1,  percebendo  que  o  seu  alto  Ã­ndice  de  acerto  ao  acaso  interferiu  na 

classificaÃ§Ã£o dos itens de acordo com o parÃ¢metro b. 

Apesar de ter um alto Ã­ndice de discriminaÃ§Ã£o (7,211), analisando a funÃ§Ã£o de informaÃ§Ã£o do 

item  4  (Figura  6.8)  podemos  ver  que  esta  discriminaÃ§Ã£o  Ã©  particularmente  vÃ¡lida  para  os 

respondentes com aptidÃµes dentro de um pequeno intervalo prÃ³ximo a 0,8. 

Figura 6.8 - FunÃ§Ã£o de informaÃ§Ã£o do item 4

Na Figura 6.9 temos a funÃ§Ã£o de informaÃ§Ã£o do item 3. 

Fonte: do autor. 

 
 
 
 
 
62 

Figura 6.9 - FunÃ§Ã£o de informaÃ§Ã£o do item 3

Fonte: Do autor. 

O item 3, o mais discriminativo na TCT (0,35), tambÃ©m teve um bom Ã­ndice de discriminaÃ§Ã£o 

na TRI (4,304), porÃ©m, da mesma forma que aconteceu com o item 4, atravÃ©s da sua funÃ§Ã£o de 

informaÃ§Ã£o temos que esta discriminaÃ§Ã£o Ã© particularmente vÃ¡lida para os respondentes com nÃ­vel 

de aptidÃ£o em torno de 0,5. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
63 

7 AnÃ¡lise PedagÃ³gica 

Neste  capÃ­tulo  faremos  uma  anÃ¡lise  pedagÃ³gica  de  sete  itens  da  prova  JaraguÃ¡:  o  item  1, 

considerado o mais fÃ¡cil pela TCT com aproximadamente 80% de acertos, os itens 2, 5 e 6 que, 

por nÃ£o atingirem um Ã­ndice mÃ­nimo de 0,20 da correlaÃ§Ã£o ponto-bisserial devem ser excluÃ­dos do 

teste, o item 4 que apresentou distratores ruins, o item 10, considerado o mais difÃ­cil da prova em 

ambas as teorias e o item 7, considerado um item fÃ¡cil em ambas as teorias. 

Em relaÃ§Ã£o a anÃ¡lise das questÃµes pelo item 1 da prova JaraguÃ¡. Dois fatos curiosos em relaÃ§Ã£o 

a anÃ¡lise deste item estÃ£o em seus Ã­ndices de dificuldade e discriminaÃ§Ã£o. Se observarmos a CCI 

(Figura 6.3), podemos perceber que nÃ£o Ã© necessÃ¡rio possuir grandes habilidades para resolver o 

item, pois b = 0,625. Mesmo assim, de acordo com o estudo apresentado neste trabalho, o nÃ­vel de 

dificuldade deste item foi dado como mediano.  

Em relaÃ§Ã£o ao poder de discriminaÃ§Ã£o do item 1, a = 2,266, o grande achatamento da curva 

indica  que  o  item  nÃ£o  discrimina  os  respondentes  de  diferentes  nÃ­veis  de  habilidade,  o  que 

novamente vai de encontro ao seu Ã­ndice mediano de discriminaÃ§Ã£o.  

Estes fatos sÃ£o explicados pelo alto Ã­ndice de acerto ao acaso c = 0,715, ou seja, a alternativa 

mais procurada quando se desejou  â€œchutarâ€ a resposta foi justamente a alternativa correta, letra 

(D), o que dificulta interpretar se o respondente realmente possuÃ­a as habilidades necessÃ¡rias para 

resolver o item, ou se ele simplesmente â€œchutouâ€ e acertou a questÃ£o.  

QuestÃ£o 1 

Esta Ã© uma questÃ£o em que se deseja que o estudante aplique regra de trÃªs. PorÃ©m, como a 

razÃ£o Ã© igual a 2, o estudante nem precisaria aplicar a regra, pois basta dobrar o nÃºmero de pÃ¡ginas, 

assim como aconteceu com as horas. Uma possÃ­vel alteraÃ§Ã£o no enunciado que provavelmente faria 

com que o estudante aplicasse de fato a regra de trÃªs seria:  

 
 
 
64 

1) Renato levou 4 horas para digitar um texto de 22 pÃ¡ginas. Se ele trabalhar durante 10 horas, 

no mesmo ritmo, Ã© possÃ­vel que ele digite um texto de: 

(A)  50 pÃ¡ginas 

(B)  60 pÃ¡ginas 

(C)  44 pÃ¡ginas 

(D)  55 pÃ¡ginas 

Com essa mudanÃ§a no enunciado a proporÃ§Ã£o entre os valores dados nÃ£o Ã© tÃ£o direta, o que 

faz com que o respondente tente aplicar a regra de trÃªs. 

Conforme foi relatado no capÃ­tulo 6, a retirada dos itens 2, 5 e 6 ocasionariam em um teste 

mais eficiente. Agora, de forma mais detalhada, analisaremos alguns dos motivos que podem ter 

influenciado este resultado. 

QuestÃ£o 2 

      Um  detalhe  que  podemos  perceber  na  elaboraÃ§Ã£o  desta  questÃ£o  estÃ¡  relacionado  Ã   sua 

formataÃ§Ã£o. Os sinais operacionais nÃ£o sÃ£o totalmente claros, podendo haver confusÃ£o na hora de 

realizar os cÃ¡lculos. A seguir mostramos como deveria estar apresentada a expressÃ£o: âˆ’1 âˆ’ (âˆ’5) âˆ™

(âˆ’3) + (âˆ’4) âˆ™ 3 âˆ¶ (âˆ’4). 

Apesar de ter sido uma prova aplicada para o 8Âº ano, o conteÃºdo Ã© do 7Âº ano. A ideia foi aplicar 

um simulado no inÃ­cio do ano letivo com os conteÃºdos referentes ao ano anterior para diagnosticar 

as  deficiÃªncias  dos  alunos  e  trabalhar  estas  deficiÃªncias  antes  do  simulado  seguinte.  Eu,  por 

exemplo,  passei  a  trabalhar  um  pouco  mais  de  Ã¡lgebra  com  os  estudantes  do  8Âº  ano,  pois  foi 

dignosticado uma certa dificuldade neste conteÃºdo com as anÃ¡lises da prova JaraguÃ¡. 

Outro detalhe a ser observado Ã© que essa questÃ£o envolve conteÃºdos do 7Âº ano (operaÃ§Ãµes entre 

nÃºmeros  inteiros)  e  do  6Âº  ano  (expressÃµes  numÃ©ricas).  A  questÃ£o  2  foi  elaborada  para  medir  o 

conhecimento dos estudantes sobre as operaÃ§Ãµes que envolvem nÃºmeros inteiros, e os principais 

erros da questÃ£o foram na resoluÃ§Ã£o da expressÃ£o numÃ©rica, e nÃ£o das operaÃ§Ãµes em si. 

 
 
 
 
 
Em seguida apresentamos a questÃ£o 4, na qual as alternativas (B) e (C) se apresentaram como 

distratores ruins por atraÃ­rem muitos respondentes com mÃ©dia e alta habilidade. 

QuestÃ£o 4 

65 

Uma explicaÃ§Ã£o para os respondentes terem assinalado as alternativas (B) e (C) estÃ¡ no fato 

de  que  ambas  possuem  um  nÃºmero  de  quilometragem  que  Ã©  mÃºltiplo  da  quilometragem  do 

enunciado  da  questÃ£o  envolvendo  potÃªncias  de  base  10  (5 âˆ™ 103  e  5 âˆ™ 102).  Uma  mudanÃ§a  no 

enunciado  que  minimizaria  o  erro  cometido  por  estes  respondentes  seria  a  nÃ£o  utilizaÃ§Ã£o  dos 

mÃºltiplos de 5 com potÃªncias de base 10. Esta mudanÃ§a faria com que os respondentes cumprissem 

as etapas necessÃ¡rias para a resoluÃ§Ã£o da questÃ£o: transformaÃ§Ã£o de unidades (5 km em 5000 m) e 

proporÃ§Ã£o entre os nÃºmeros do problema e os nÃºmeros da resposta. 

QuestÃ£o 5 

A questÃ£o 5 tambÃ©m foi designada para ser retirada do teste. A anÃ¡lise dos distratores mostra 

que a alternativa (D) atraiu mais respondentes com altas habilidades do que a alternativa correta 

(C). Uma maneira de resolver esta questÃ£o Ã©: 

6000 = (

1

100

âˆ™ 120000) âˆ™ ğ‘¡  â†’ ğ‘¡ = 5, em que ğ‘¡ representa o tempo que Marcos levou para pagar o 

emprÃ©stimo. A maioria dos estudantes que assinalou a alternativa (D), provavelmente nÃ£o executou 

os cÃ¡lculos, tentando utilizar um raciocÃ­nio lÃ³gico ao ver relaÃ§Ã£o entre os 6 meses da resposta e os 

R$6.000,00 de juros. Dessa forma a alternativa (D) se apresentou como um distrator ruim, pois foi 

assinalada  por  aproximadamente  40%  dos  respondentes  com  nÃ­vel  alto  de  habilidade  e 

aproximadamente 56% dos respondentes com um nÃ­vel mÃ©dio de habilidade. 

 
 
 
66 

Este conteÃºdo, alÃ©m de porcentagem, envolve matemÃ¡tica financeira, conteÃºdo trabalhado por 

muitos  professores  somente  no  9Âº  ano. Portanto,  o  fato  de  muitos  alunos nÃ£o  terem  estudado  o 

conteÃºdo necessÃ¡rio para a resoluÃ§Ã£o deste problema Ã© o principal motivo para que este item seja 

excluÃ­do do teste. 

Outro fator que pode ter influenciado o desempenho ruim de alguns estudantes neste item foi 

a falta de autonomia durante o processo de aprendizagem. Essa falta de autonomia, juntamente com 

a  falta  de  persistÃªncia  na  resoluÃ§Ã£o  de  um  problema,  podem  ser  detectadas  pelos  erros  nos 

simulados. A alternativa (D) da questÃ£o 5, que atraiu mais respondentes do que a alternativa correta 

em  todos  os  trÃªs  nÃ­veis  de  habilidade,  demonstra  uma  resposta  assinalada  sem  muito  esforÃ§o, 

apresentando uma busca rÃ¡pida por uma soluÃ§Ã£o que faÃ§a algum sentido, mesmo que este sentido 

seja mÃ­nimo. Estudantes que tenham autonomia nos estudos, que tenham o costume de persistir na 

busca pela soluÃ§Ã£o do problema, de modo geral, nÃ£o cometem este tipo de erro.  

QuestÃ£o 6 

A questÃ£o 6 foi classificada como uma questÃ£o difÃ­cil (b = 2,263). De fato, a resoluÃ§Ã£o desta 

questÃ£o envolve algumas etapas: 

15% de R$1.200,00 = R$180,00 

25% de R$1.200,00 = R$300,00 

R$180,00 + R$300,00 = R$480,00 

A resposta correta Ã© a letra A (R$480,00). Como as alternativas B e C apresentam valores que 

aparecem durante a resoluÃ§Ã£o da questÃ£o (R$180,00 e R$300,00), estas duas alternativas atraÃ­ram 

vÃ¡rios  respondentes.  Por  outro  lado,  grande  parte  dos  respondentes  com  altas  habilidades 

escolheram a opÃ§Ã£o correta, o que mostra que as alternativas B e C nÃ£o foram distratores tÃ£o ruins. 

 
 
67 

Esta questÃ£o, assim como a questÃ£o 5, envolve porcentagem e foi indicada para ser retirada do 

teste. Uma sugestÃ£o para os professores Ã© que trabalhem o conteÃºdo de porcentagem com um pouco 

mais de Ãªnfase no 7Âº ano. 

QuestÃ£o 7 

O item 7 foi considerado o mais fÃ¡cil pela TRI e considerado fÃ¡cil pela TCT. Um aluno que 

tenha  lido  o  enunciado  viu  que  200  pessoas  participaram  da  pesquisa  e,  dessas  200,  100 

responderam  shopping,  ou  seja,  a  metade.  A  Ãºnica  alternativa  que  apresenta  uma  divisÃ£o  que 

contÃ©m um setor que corresponde Ã  metade Ã© a alternativa (B).        

QuestÃ£o 10 

As  trÃªs  alternativas  incorretas  (A),  (B)  e  (C)  atraÃ­ram  uma  quantidade  considerÃ¡vel  de 

respondentes com alta habilidade. As alternativas (A) e (B) tambÃ©m foram escolhidas por vÃ¡rios 

respondentes com mÃ©dia habilidade. Como este foi considerado um item muito difÃ­cil (b = 2,438), 

Ã©  esperado  que  todas  as  alternativas  pareÃ§am  corretas.  AlÃ©m  disso,  a  alternativa  que  atriu  mais 

respondentes com altas habilidades foi a alternativa correta, o que mostra que os distratores, de 

modo geral, cumpriram bem a sua funÃ§Ã£o.  

 
 
 
 
68 

Este  item  atingiu  bons  nÃ­veis  de  discriminaÃ§Ã£o.  De  fato,  o  item  foi  bem  elaborado. 

Diferentemente do que acontece com a maioria das questÃµes que pedem a resposta do problema, 

esta  questÃ£o  avalia  se  o  estudante  entendeu  o  processo,  algo  difÃ­cil  de  se  avaliar  em  questÃµes 

objetivas.  AlÃ©m  de  interpretar  a  situaÃ§Ã£o  do  problema  o  estudante  deveria  lembrar  que  1  kg 

corresponde a 1.000 g, ou seja, deve-se multiplicar 15 por 1.000. 

Podemos dizer que a Teoria ClÃ¡ssica dos Testes e a Teoria de Resposta ao Item foram muito 

Ãºteis no processo de avaliaÃ§Ã£o da prova JaraguÃ¡. Fomos capazes de apontar falhas de elaboraÃ§Ã£o, 

salientar  acertos,  discutir  os  problemas  e  as  suas  possÃ­veis  soluÃ§Ãµes,  fatores  que  interferem 

diretamente na aprendizagem dos estudantes. 

De modo geral nÃ£o foi um bom teste. A pequena quantidade de questÃµes pode ter interferido 

nos  resultados,  alÃ©m  da  amostra  de  estudantes  que  tambÃ©m  poderia  ser  maior.  Uma  das  nossas 

sugestÃµes para melhorar este teste seria o aumento do nÃºmero de questÃµes e a sua aplicaÃ§Ã£o a um 

nÃºmero maior de estudantes.  

Nas novas ediÃ§Ãµes deste teste alguns cuidados devem ser tomados em relaÃ§Ã£o a elaboraÃ§Ã£o dos 

itens  como  verificar  se  o  item  realmente  estÃ¡  avaliando  aquilo  que  se  deseja,  se  o  respondente 

necessita realmente da habilidade a ser medida para resolver o item, ou se o item pode ser resolvido 

de uma forma mais simples. 

 
 
 
 
 
 
 
 
 
 
 
 
 
69 

8 PercepÃ§Ãµes e inquietaÃ§Ãµes do autor 

No contexto geral, o foco principal deste trabalho estÃ¡ nas avaliaÃ§Ãµes, mas no meu ponto de 

vista outras questÃµes pertinentes merecem ser discutidas, em minha visÃ£o. Desde que eu comecei 

a lecionar matemÃ¡tica no municÃ­pio de JaraguÃ¡ do Sul em 2014, percebo nos estudantes, de modo 

geral, pouco tempo de dedicaÃ§Ã£o aos estudos. Ã‰ claro que a atuaÃ§Ã£o da famÃ­lia e dos professores 

tem grande influÃªncia nisso. Em relaÃ§Ã£o aos professores tenho percebido  alguns problemas que 

exigem uma atenÃ§Ã£o especial. Diferentemente do que ocorre em algumas instuiÃ§Ãµes de ensino da 

rede privada, na rede municipal de Ensino de JaraguÃ¡ do Sul os estudantes sÃ³ tÃªm aulas com um 

professor com formaÃ§Ã£o em matemÃ¡tica a partir do 6Âº ano. Antes disso, as aulas sÃ£o dadas por um 

professor formado em pedagogia que leciona a maior parte das disciplinas curriculares. A grande 

maioria dos professores das sÃ©ries iniciais (pedagogos) com os quais eu discuti sobre matemÃ¡tica 

disseram ter uma certa dificuldade em ensinar alguns conteÃºdos especÃ­ficos de matemÃ¡tica, como 

fraÃ§Ãµes e contagem.  

Com  base  em  minhas  vivÃªncias  de  sala  de  aula,  o  maior  obstÃ¡culo  que  existe  entre  os 

estudantes e o entendimento da matemÃ¡tica Ã© a falta de autonomia por parte desses estudantes. Os 

estudantes  que  apresentam  um  bom  desempenho,  de  modo  geral,  quando  se  deparam  com  um 

desafio, persistem na busca pela resposta, mesmo que tenham fracassado nas primeiras tentativas 

de  resolver  o  desafio.  Em  contrapartida,  os  estudantes  que  geralmente  nÃ£o  apresentam  bom 

desempenho em matemÃ¡tica costumam desistir logo apÃ³s as primeiras tentativas, buscando logo a 

resposta sem ter feito um grande esforÃ§o.  Pelo que conversamos com os professores da UDESC 

durante  as  disciplinas  deste  mestrado,  essa  falta  de  autonomia  acompanha  os  estudantes  atÃ©  os 

cursos de graduaÃ§Ã£o, juntamente com a falta de tempo destinado aos estudos.  

Tentando  mudar  este  cenÃ¡rio  do  Ensino  Fundamental,  pelo  menos  das  turmas  em  que  eu 

leciono, algumas estratÃ©gias fazem parte do meu trabalho. Uma dessas estratÃ©gias Ã© entregar para 

os estudantes uma lista de exercÃ­cios (algo em torno de 50 exercÃ­cios) para que eles resolvam em 

casa  e  me  entreguem  no  dia  da  prova.  A  entrega  desta  lista  consta,  para  a  nota  da  prova,  um 

acrÃ©scimo  que  varia  de  0,1  a  1,0  ponto,  dependendo  da  quantidade  de  exercÃ­cios  reolvidos, 

organizaÃ§Ã£o  e,  Ã©  claro,  exatidÃ£o.  A  qualquer  momento  os  estudantes  podem  pedir  auxÃ­lio  para 

resolver os exercÃ­cios mais difÃ­ceis, pedir dicas, ou atÃ© que eu mesmo resolva, quando estiver muito 

prÃ³ximo da prova. O que eu sempre digo Ã© que: - vocÃªs nÃ£o tÃªm a obrigaÃ§Ã£o de conseguir resolver 

 
 
70 

todos os exercÃ­cios, mas tem a obrigaÃ§Ã£o de tentar. O resultado estÃ¡ sendo bem produtivo. Se eu 

demoro  alguns  dias  para  entregar  a  lista  eles  mesmos  me  cobram,  pois  geralmente  uso  alguns 

exercÃ­cios parecidos na prova, entÃ£o eles entendem que a resoluÃ§Ã£o da lista Ã© uma boa forma de 

preparaÃ§Ã£o.  

Outra estratÃ©gia que eu utilizo, desta vez nas provas, Ã© fazer uma questÃ£o extra, valendo 1,0 

ponto. Esta questÃ£o possui um nÃ­vel bem maior do que as outras questÃµes da prova, e tem como 

objetivo motivar e desafiar os estudantes, o que geralmente acontece com os de bom desempenho. 

Entre as questÃµes utilizadas estÃ£o problemas da  segunda fase da OBMEP, problemas da  OBM, 

questÃµes de vestibulares, ou questÃµes mais aprofundadas do conteÃºdo que nÃ£o foram trabalhadas 

em sala. A figura 16 representa uma questÃ£o que eu jÃ¡ utilizei em provas.  

Figura 8.1 - QuestÃ£o aplicada em uma prova de matemÃ¡tica 

Fonte: OBMEP 

AlÃ©m de incentivar os estudantes com bom desempenho, esta questÃ£o bÃ´nus, mesmo que de 

uma forma singela, serve de preparaÃ§Ã£o para que eles tenham um melhor desempenho em outras 

avaliaÃ§Ãµes, alÃ©m da OBMEP. 

Quando  incentivamos  o  raciocÃ­nio,  a  persistÃªncia  na  busca  pela  soluÃ§Ã£o,  e  a  perseveranÃ§a, 

independente da quantidade de fracassos, os estudantes estÃ£o sendo preparados nÃ£o apenas para as 

provas de matemÃ¡tica, mas para qualquer situaÃ§Ã£o de dificuldade que encontrar na vida. 

 
 
 
 
 
71 

9 ConsideraÃ§Ãµes Finais 

O objetivo do presente trabalho Ã© analisar a qualidade de um simulado de matemÃ¡tica aplicado 

para estudantes do 8Âº ano da prefeitura municipal de JaraguÃ¡ do Sul, alÃ©m de discutir os itens do 

simulado  pedagogicamente,  contribuindo  na  elaboraÃ§Ã£o  de  futuros  testes.  Para  cumprir  este 

objetivo, foram aplicadas na pesquisa a metodologia da Teoria ClÃ¡ssica dos Testes e da Teoria de 

Resposta ao item. Estas anÃ¡lises nos levaram a discutir pedagogicamente a construÃ§Ã£o de um item, 

enriquecendo as discussÃµes sobre a TCT e a TRI e contribuindo para futuros trabalhos similares.  

AlÃ©m  da  anÃ¡lise  de  forma  individual  utilizando  as  duas  teorias,  realizamos  tambÃ©m  uma 

comparaÃ§Ã£o entre os resultados apresentados pela TCT e pela TRI, apontando algumas limitaÃ§Ãµes, 

semelhanÃ§as e diferenÃ§as nos resultados. 

A anÃ¡lise feita com o auxÃ­lio da TCT e da TRI, nos proporcionou a clareza e a confiabilidade 

dos resultados obtidos, identificando os itens que sÃ£o capazes de discriminar os  estudantes que 

possuem as habilidades necessÃ¡rias para resolver o teste daqueles que nÃ£o possuem (itens 3, 4 e 

10).  AlÃ©m  disso,  tambÃ©m  fomos  capazes  de  classificar  os  itens  de  acordo  com  o  nÃ­vel  de 

dificuldade, o que pode ser muito importante na hora de elaborar um teste. 

Os resultados e discussÃµes deste trabalho podem ser de grande valor para a aplicaÃ§Ã£o de testes 

similares,  tanto  para  a  Secretaria  Municipal  de  EducaÃ§Ã£o  de  JaraguÃ¡  do  Sul  quanto  para  outras 

instituiÃ§Ãµes que tem por objetivo avaliar a qualidade de suas provas, corrigindo e aprimorando o 

que se mostrar necessÃ¡rio 

ConcluÃ­mos  que  os  itens  2,  5  e  6  deveriam  ser  retirados  do  teste,  porÃ©m  nÃ£o  refizemos  os 

procedimentos de anÃ¡lise e discussÃ£o. Isso porque o maior objetivo deste trabalho estÃ¡ voltado para 

a anÃ¡lise pedagÃ³gica dos itens, auxiliando na elaboraÃ§Ã£o de testes futuros. 

Como sugestÃ£o para trabalhos futuros, a partir do estudo realizado, recomendamos a aplicaÃ§Ã£o 

a TCT e da TRI em simulados de outras disciplinas, alÃ©m de matemÃ¡tica, com a presenÃ§a de uma 

anÃ¡lise pedagÃ³gica dos itens, o que auxilia o processo de minimizaÃ§Ã£o dos erros na elaboraÃ§Ã£o do 

teste. Sugerimos tambÃ©m que sejam realizados os mesmos procedimentos de anÃ¡lise deste trabalho 

excluindo os itens 2, 5 e 6, alÃ©m da utilizaÃ§Ã£o dos modelos de 2 e 4 parÃ¢metros (ML2 e ML4), 

discutindo os resultados e fazendo uma comparaÃ§Ã£o paralela aos resultados discutidos no presente 

trabalho.  Sugerimos  tambÃ©m  analisar  se  os  itens  da  prova  JaraguÃ¡  satisfazem  os  requisitos 

necessÃ¡rios para serem classificados como Ã¢ncora ou quase Ã¢ncora, o que agregaria mais valor aos 

resultados do trabalho. 

 
 
72 

10 ReferÃªncias 

ANDRADE,  D.  F.  D.;  TAVARES,  H.  R.;  VALLE,  R.  D.  C.  Teoria  da  Resposta  ao  Item: 

conceitos 

e 

aplicaÃ§Ãµes. 

CearÃ¡: 

Sinape, 

2000. 

DisponÃ­vel 

em 

<http://egov.ufsc.br/portal/sites/default/files/livrotri.pdf> 

ANDRIOLA, W. B. Psicometria Moderna: caracterÃ­sticas e tendÃªncias. Estudos em AvaliaÃ§Ã£o 

Educacional, SÃ£o Paulo, v. 20, n. 43, mai/ago, 319-340, 2009. 

ANJOS,  A.; ANDRADE, D. F.  Teoria  de Resposta ao Item com o uso do R.  In:  SimpÃ³sio 

Nacional 

de 

Probabilidade 

e 

EstatÃ­stica, 

2012. 

DisponÃ­vel 

em 

<https://docs.ufpr.br/~aanjos/CE095/RTRIsinape.pdf>. Acesso em 12 de agosto de 2018. 

ARIAS, M. R. M.; LLOREDA, M. J. H.; E LLOREDA, M.V. H. Psicometria. Madrid. Alianza 

Editorial, S. A., 2006. 

BARNARD-BRAK,  Lucy;  LAN,  William  Y.;  YANG,  Zhanxia.  Differences  in  mathematics 

achievement according to opportunity to learn: A 4pL item response theory examination. Studies 

in Educational Evaluation, v. 56, p. 1-7, 2018. 

CHALMERS,  R.  P.  mirt:  A  multidimensional  Item  Response  Theory  Package  for  the  R 

Environment.  Journal  of  Statistical  Software,  v.  48,  n.  6,  p.  1-29,  2012.  Acesso  em  02  de 

setembro de 2018. 

CORTESÃƒO,  L.  Formas  de  Ensinar,  formas  de  avaliar.  Lisboa:  MinistÃ©rio  da  EducaÃ§Ã£o, 

Departamento do Ensino BÃ¡sico: [s.n.], 2002. 

FERREIRA, Francisco Fialho G. Escala de ProficiÃªncia para o ENEM: utilizando teoria da 

resposta  ao  item.  DissertaÃ§Ã£o  de  Mestrado  apresentada  ao  Programa  de  PÃ³s-graduaÃ§Ã£o  em 

MatemÃ¡tica 

e 

EstatÃ­stica, 

UFPA, 

2009. 

DisponÃ­vel 

em: 

<http://www.ppgme.ufpa.br/doc/diss/fialhoguedes.pdf>.  Acesso em 16 de julho 2018. 

HAIR,  J.  F.;  BLACK,  W.  C.;  BABIN,  J.  B.;  ANDERSON,  R.  E.;  TATHAN,  R.  L.  AnÃ¡lise 

Multivariada de Dados. 6Âª ediÃ§Ã£o. Artmed S. A. Porto Alegre. 2005. 

INEP.  Exame  Nacional  de  Desempenho  de  Estudantes  (ENADE  2014).  RelatÃ³rio  SÃ­ntese: 

MatemÃ¡tica. 

2014. 

DisponÃ­vel 

em: 

<http://download.inep.gov.br/educacao_superior/enade/relatorio_sintese/2014/2014_rel_matem

matem.pdf> Acesso em 20 de julho de 2018. 

 
 
 
73 

IBGE.  Censo  DemogrÃ¡fico.  2017.  DisponÃ­vel  em  <https://www.ibge.gov.br/estatisticas-

novoportal/por-cidade-estado-estatisticas.html?t=destaques&c=4208906>.  Acesso  em  12  de 

agosto de 2018. 

INEP. 

IDEB 

â€“ 

Resultados 

e 

Metas. 

DisponÃ­vel 

em 

<http://ideb.inep.gov.br/resultado/home.seam?cid=5721>. Acesso em 20 de julho de 2018.  

JUNKER, B. W. Some aspects of classical reliability theory & classical test theory. Carnegie 

Mellon University. Pittsburgh. 2012. 

KLEIN,  R.  Alguns  aspectos  da  Teoria  de  Resposta  ao  Item  relativos  Ã   estimaÃ§Ã£o  das 

proficiÃªncias. Ensaio: AvaliaÃ§Ã£o e PolÃ­ticas PÃºblicas em EducaÃ§Ã£o, v. 21, n. 78. 2013   

KLEIN, R.; FONTANIVE, N. S. AvaliaÃ§Ã£o em larga escala: tendÃªncias e desafios. Em aberto, 

vol. 15, n. 66, p. 29-34, abr./jun. 1995. 

KOLEN, Michael J.; BRENNAN, Robert L. Test equating: Methods and practices. Springer 

Science & Business Media, 2013. 

LUCKESI, C. C. AvaliaÃ§Ã£o da Aprendizagem escolar. 19. ed. SÃ£o Paulo: Cortez, 2008. 

LUCKESI, C. C.  VerificaÃ§Ã£o ou AvaliaÃ§Ã£o: O Que Pratica a Escola. Governo do Estado do 

CearÃ¡: CAED, 2007. 

MACHADO, N. Epistemologia e didÃ¡tica. SÃ£o Paulo. 1996. 

MAIA, J. L. O uso da Teoria ClÃ¡ssica dos Testes - TCT e da Teoria de Resposta ao Item - 

TRI na avaliaÃ§Ã£o da qualidade mÃ©trica de testes de seleÃ§Ã£o. Tese de doutorado apresentada 

ao  programa  de  pÃ³s-graduaÃ§Ã£o  em  educaÃ§Ã£o  brasileira,  UFC,  2009.  DisponÃ­vel  em: 

<http://repositorio.ufc.br/bitstream/riufc/3235/1/2009_Tese_JLMaia.pdf>.  Acesso  em  16  de 

julho de 2018. 

MENDONÃ‡A, J. AnÃ¡lise da eficiÃªncia de estimaÃ§Ã£o de parÃ¢metros da TRI pelo software 

ICL. DissertaÃ§Ã£o de Mestrado. Universidade Federal de Lavras. Lavras â€“ MG, 2012. 

MUÃ‘IZ, J. TeorÃ­a de Respuesta a los Ã­tems: un nuevo enfoque en la evoluciÃ³n psicolÃ³gica y 

educativa. Madri: PirÃ¡mide, 1990. 

MUÃ‘IZ, J. IntroducciÃ³n a la teoria de respuesta a los Ã­tems. Madri: PirÃ¡mide, 1997. 

MUÃ‘IZ, J. Teoria ClÃ¡ssica dos Testes. Madrid: PirÃ¡mide, S. A, 2003. 

PASQUALI,  L.  Psicometria:  teoria  dos  testes  na  psicologia  e  na  educaÃ§Ã£o.  PetrÃ³poles,  RJ: 

Vozes, 2003. 

 
74 

RABELO,  M.  AvaliaÃ§Ã£o  Educacional:  Fundamentos,  metodologia  e  aplicaÃ§Ã£o  no  contexto 

brasileiro. Rio de Janeiro: SBM, 2013. 

REVELLE,  W.  The  â€œNew  Psychometricsâ€  â€“  Item  Response  Theory.  DisponÃ­vel  em: 

<http://www.personality-project.org/r/book/Chapter8.pdf>. Acesso em 01 de setembro de 2018. 

REVELLE, William R. psych: Procedures for personality and psychological research. 2017. 

DisponÃ­vel  em:  <https://CRAN.R-project.org/package=psych.  Acesso  em  01  de  setembro  de 

2018. 

RIZOPOULOS,  Dimitris.  ltm:  An  R  package  for  latent  variable  modeling  and  item  response 

theory  analyses.  Journal  of  statistical  software,  v.  17,  n.  5,  p.  1-25,  2006.  DisponÃ­vel  em 

<http://www.jstatsoft.org/v17/i05/>  

SILVA, F. E. F. D. Teoria de resposta ao Item (TRI) em AvaliaÃ§Ãµes de MatemÃ¡tica na EEM 

Professor Gabriel EpifÃ¢nio dos Reis. Trabalho de conclusÃ£o de curso apresentado ao Corpo 

Docente do Mestrado Profissional em MatemÃ¡tica em Rede Nacional  - PROFMAT - UFERSA. 

MossorÃ³. 2015. DisponÃ­vel em < https://sca.profmat-sbm.org.br/sca_v2/get_tcc3.php?id=598>. 

Acesso em 01 de setembro de 2018. 

TORRES,  F.  C.  Uma  AplicaÃ§Ã£o  da  Teoria  de  Resposta  ao  Item  em  um  Simulado  de 

MatemÃ¡tica no Modelo ENEM. Trabalho de conclusÃ£o de curso apresentado ao Departamento 

de MatemÃ¡tica da Universidade de BrasÃ­lia, UNB, 2015. DisponÃ­vel em:  <https://sca.profmat-

sbm.org.br/sca_v2/get_tcc3.php?id=79363>. Acesso em 16 de julho de 2018. 

URBINA, S. Fundamentos da Testagem PsicolÃ³gica. Porto Alegre: Artmed, 2007. 

VIANNA, H. M. Testes em EducaÃ§Ã£o. 4 Ed. ed. SÃ£o Paulo : Ibrasa, 1982. 

VIANNA,  H.  M.  AvaliaÃ§Ã£o  Educacional:  Uma  perspectiva  histÃ³rica.  Estudos  em  AvaliaÃ§Ã£o 

Educacional, SÃ£o Paulo, v. 25, p. 7-24, Dez 1995. 

VIANNA, H. M. Estudos em AvaliaÃ§Ã£o Educacional. SÃ£o Paulo: [s.n.], v. 25, 2014. 

WILLSE,  J.  T.  (2017).  CTT:  Classical  Test  Theory  Functions.  R  package  version  2.3. 

<https://CRAN.R-project.org/package=CTT>  

 
 
 
 
75 

Anexo I 

Nas pÃ¡ginas seguintes encontram-se os 10 itens do simulado de MatemÃ¡tica aplicado para as 

turmas do 8Âº ano da rede municipal de educaÃ§Ã£o de JaraguÃ¡ do Sul em 2016.  

 
 
 
 
 
 
 
 
 
76 

 
 
 
 
 
 
 
 
 
77 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
78 

Anexo II 

Dados da planilha MAT8.dat 

 
 
 
 
 
 
 
 
79 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
80 

Anexo III 

Rotina no software R 

#Carregamento e conferÃªncia da planilha denominada dados 
dados = read.fwf('C:\\Users\\Marcos\\Desktop\\Dissertacao\\MAT8.dat',widths=c(3,rep(1,10)),header=F,dec=',') 

head(dados) 

tail(dados) 

View(dados) 

#ExclusÃ£o da primeira linha e da primeira coluna. Nova planilha dados2 
dados2<-dados[-1,-1] 

#InclusÃ£o do gabarito 
gabarito=c("D","A","B","A","C","A","B","C","B","D") 

#Erros e acertos, frequÃªncia, ponto-bisserial item total, alfa de Cronbach com exclusÃµes 
descript(dad.binario) 

#carregamento dos pacotes utilizados 
library(psych) 
library(CTT) 
library(mirt) 
library(ltm) 

#TransformaÃ§Ã£o da planilha dados2 em valores binÃ¡rios 
dad.binario <- key2binary(dados[2:nrow(dados),2:11],t(dados[1,2:11])) 

#Confiabilidade (Coeficiente Alfa) 
reliability(as.matrix(dad.binario,itemal=TRUE)) 

#AplicaÃ§Ã£o do modelo logÃ­stico de trÃªs parÃ¢metros  
meu.modelo.1<-mirt(dad.binario,1,"3PL") 

#Cargas Fatoriais 
summary(meu.modelo.1) 

#TRI - discriminaÃ§Ã£o, dificuldade e acerto ao acaso 
coef(meu.modelo.1,simplify=T,IRTpars=T) 

#Erros e acertos, frequÃªncia, ponto-bisserial item total, alfa de Cronbach com exclusÃµes 
descript(dad.binario) 

#moda# 
statmod<-function(dad.binario){z<-table(as.vector(dad.binario));names(z)[z==max(z)]} 
statmod(rowSums(dad.binario)) 

#mÃ­nimo, Q1, mediana, Q3, mÃ©dia, mÃ¡ximo 
summary(rowSums(dad.binario)) 

#desvio padrÃ£o 
sd(rowSums(dad.binario)) 

#variÃ¢ncia 
var(rowSums(dad.binario)) 

#Curva caracterÃ­stica do item 7 
itemplot(meu.modelo.1,7,zeros=T) 

 
 
 
 
 
 
 
 
81 

#Curva caracterÃ­stica do item 10 
itemplot(meu.modelo.1,10,zeros=T) 

#Curva caracterÃ­stica de cada item do teste 
plot(meu.modelo.1,type="trace") 

#Curva de informaÃ§Ã£o de cada item do teste 
plot(meu.modelo.1,type="infotrace", theta_lim=c(-4,4), ylim=c(0,0.5)) 

#Curva de informaÃ§Ã£o do teste e curva do erro padrÃ£o 
plot(meu.modelo.1,type="infoSE") 

#Curva de informaÃ§Ã£o do item 3 e curva do erro padrÃ£o 
itemplot(meu.modelo.1,3,type="infoSE") 

#AnÃ¡lise dos distratores 
distractor.analysis(dados2,gabarito) 

#CorrelaÃ§Ã£o ponto-bisserial 
iA <- itemAnalysis(dad.binario) 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
A aplicaÃ§Ã£o de simulados Ã© uma prÃ¡tica comum quando se deseja avaliar um 
grupo de estudantes. PorÃ©m, para que os resultados apresentados sejam vÃ¡lidos, 
Ã© necessÃ¡rio que os itens que compÃµem o simulado sejam capazes de discriminar 
os participantes que possuem as habilidades que estÃ£o sendo medidas dos 
estudantes que nÃ£o possuem. Desta forma, o presente trabalho se propÃ´s a 
analisar a qualidade dos itens de um simulado de MatemÃ¡tica aplicado na rede 
municipal de educaÃ§Ã£o de JaraguÃ¡ do Sul. Esta anÃ¡lise foi feita utilizando e 
comparando os resultados da Teoria ClÃ¡ssica dos Testes (TCT) e da Teoria de 
Resposta ao Item (TRI). Concluiu-se que a maior parte dos itens necessita de 
revisÃ£o. Os resultados obtidos com as anÃ¡lises da TCT e da TRI foram 
confrontados, garantindo uma maior fidedignidade nas conclusÃµes sobre os itens. 
Os resultados das duas teorias apresentaram divergÃªncias em relaÃ§Ã£o aos itens 
com maior poder de discriminaÃ§Ã£o. Por outro lado, o item considerado mais difÃ­cil 
do teste foi o mesmo nas duas teorias. AlÃ©m disso, foi realizada uma anÃ¡lise 
pedagÃ³gica nos itens considerados deficientes, com o intuito de contribuir com 
futuros trabalhos similares. Algumas sugestÃµes de alteraÃ§Ã£o no enunciado da 
questÃ£o e das alternativas foram feitas neste trabalho. 

Orientadora: Elisa Henning 

Joinville, 2018 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

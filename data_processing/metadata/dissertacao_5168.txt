UNIVERSIDADE DO ESTADO DE MATO GROSSO 

CAMPUS DE SINOP 

FACULDADE DE CI√äNCIAS EXATAS E TECNOL√ìGICAS 

MESTRADO PROFISSIONAL EM MATEM√ÅTICA EM REDE 

NACIONAL - PROFMAT 

R√îMULO FANGUEIRO PEREIRA 

METODOLOGIA PARA A FUS√ÉO DE IMAGENS DIGITAIS BASEADA NAS 
EQUA√á√ïES DE COLINEARIDADE 

SINOP-MT 
2021 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
R√îMULO FANGUEIRO PEREIRA 

METODOLOGIA PARA A FUS√ÉO DE IMAGENS DIGITAIS BASEADA NAS 
EQUA√á√ïES DE COLINEARIDADE 

Disserta√ß√£o apresentada ao Programa de 
Mestrado  Profissional  em  Matem√°tica  em 
do 
Rede  Nacional 
departamento 
da 
Universidade  Estadual  do  Mato  Grosso  ‚Äì 
UNEMAT,  como  requisito  parcial  para 
obten√ß√£o  do  grau  de  Mestre  em 
Matem√°tica. 

‚Äì  PROFMAT, 
de  Matem√°tica 

Prof. Dr. Giovane Maia do Vale 
Orientador 

Prof. Dr. Jo√£o Gabriel Ribeiro 
Coorientador 

Prof. Me. Diogo Albino de Queiroz 
Coorientador 

SINOP 
2021 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1 

AGRADECIMENTOS 

Em primeiro lugar, eu agrade√ßo a Deus, o Criador de tudo e de todos, raz√£o pela qual 

eu existo e estou aqui. 

Agrade√ßo tamb√©m especialmente ao meu orientador, professor Doutor Giovane Maia 

do  Vale,  que  representou  para  mim  o  grande  esteio  na  constru√ß√£o  deste  trabalho, 

sendo extremamente compreensivo comigo em um momento de dificuldade pessoal 

em minha vida. Foi gra√ßas a ele que este trabalho p√¥de ser realizado e apresentado. 

Tamb√©m agrade√ßo √† minha fam√≠lia, meu pai, minha m√£e, minhas irm√£s e meus av√≥s, 

que  me  deram  todas  as  condi√ß√µes  para  que  eu  pudesse  estudar  e  realizar  este 

trabalho, sendo eles parte fundamental da minha vida. 

Agrade√ßo tamb√©m a minha atual namorada Luc√©lia Santana Fialho, pela ajuda e apoio 

incondicional que ela tem me dado em tudo o que eu venho fazendo, sendo ela um 

porto seguro para mim. 

Por  fim,  agrade√ßo  tamb√©m  a  todos  os  professores  integrantes  do  programa  de 

Mestrado Profissional em Matem√°tica em n√≠vel nacional - PROFMAT, pelo Campus 

de  Sinop  ‚Äì  MT,  bem  como  todos  os  meus  colegas  de  mestrado,  que  foram 

fundamentais no processo de forma√ß√£o e conclus√£o deste curso. 

 
 
 
 
 
 
2 

RESUMO 

Este  trabalho  versa  sobre  a  aplica√ß√£o  da  Matem√°tica  como  a  ferramenta  que 
fundamenta o processamento de imagens capturadas por sat√©lite. Nestes termos, o 
objetivo deste trabalho foi desenvolver um software livre que efetuasse o processo de 
fus√£o de imagens via m√©todo de fus√£o IHS. Tal software, implementado em C/C++, 
se  baseou  no  algoritmo  de  retifica√ß√£o  de  imagens  que  incorpora  as  equa√ß√µes  de 
colinearidade (Geometria Projetiva). Logo, se efetuou altera√ß√µes no referido algoritmo 
e nas equa√ß√µes de colinearidade de modo a gerar o referido software. Neste caso, o 
algoritmo de retifica√ß√£o de imagens modificado foi utilizado como uma ferramenta de 
reamostragem  de 
foram 
provenientes  do  sat√©lite  sino-brasileiro  CBERS  4.  Foram  utilizadas  as  imagens 
multiespectrais (R, G e B) do sensor MUX - C√¢mera Multiespectral Regular, com 
de  resolu√ß√£o  espacial,  e  a  imagem  pancrom√°tica  do  sensor  PAN  -  C√¢mera 
20 ùëöùëö
Pancrom√°tica e Multiespectral, com resolu√ß√£o espacial de 
. Por meio do software QGIS 
foram efetuados dois recortes nas imagens CBERS 4. Os recortes foram utilizados nos testes 
e diziam respeito √†s regi√µes dos reservat√≥rios de Ilha Solteira e Engenheiro Souza Dias 
(Jupi√°),  localizados  entre  os  estados  de  S√£o  Paulo  e  Mato  Grosso  do  Sul.  Os 
resultados  (imagens  fusionadas),  ap√≥s  serem  submetidos  √†  processo  de  realce  de 
contraste, se mostraram satisfat√≥rios, indicando o sucesso da pesquisa. 

imagens  multiespectrais.  As 

imagens  de  entrada 

5 ùëöùëö

Palavras ‚Äì chave: sat√©lite, Matem√°tica, imagens, Sensoriamento Remoto, fus√£o de 
imagens. 

 
 
 
 
 
 
 
 
 
 
 
3 

ABSTRACT 

This work deals with the application of Mathematics as fundamental tool for processing 
of  images  captured  by  satellite.  In  these  terms,  the  objective  of  this  work  was  to 
develop a free software that could carry out image fusion process via the IHS fusion 
method. Such software, implemented in C / C ++, was based on image rectification 
algorithm  that  incorporates  collinearity  equations  (Projective  Geometry).  Therefore, 
changes were made in the referred algorithm and in collinearity equations in order to 
generate the referred software. In this case, the modified image rectification algorithm 
was used as a multispectral image resampling tool. The input images were from the 
Sino-Brazilian  satellite  CBERS  4.  Multispectral  images  (R,  G  and  B)  from  the  MUX 
sensor - Regular Multispectral Camera, with 20 m spatial resolution, and panchromatic 
image from the PAN sensor - Multispectral and Panchromatic Camera, with a spatial 
resolution  of  5  m,  were  used.  Using  the  QGIS  software, two  cutouts  were made  on 
CBERS 4 images. The cutouts were used in tests and related to the regions of Ilha 
Solteira and Engenheiro Souza Dias (Jupi√°) reservoirs, located between the states of 
S√£o Paulo and Mato Grosso do Sul. The results (fused images), after being submitted 
through  the  contrast  enhancement  process,  are  defined  as  satisfactory,  indicating 
research success. 

Keywords: satellite, Mathematics, images, Remote Sensing, images fusion. 

 
 
 
 
 
 
4 

√çNDICE DE FIGURAS 

Figura 1: Espectro vis√≠vel da luz. .............................................................................. 13 

Figura 2: Sistemas de cores prim√°rias: RGB e CMYK. ............................................ 14 

Figura 3: Esquema do cubo de cores RGB. ............................................................. 15 

Figura 4: Tri√¢ngulo de representa√ß√£o matiz/satura√ß√£o ............................................ 16 

Figura 5: Estrutura piramidal intensidade/matiz/satura√ß√£o ....................................... 17 

Figura 6: Esquematiza√ß√£o da disposi√ß√£o dos pixels no sistema cartesiano. ........... 20 

Figura 7: Representa√ß√£o de uma matriz P de M linhas por N colunas. .................... 21 

Figura 8: Exemplo de representa√ß√£o matricial de pixels em tons de cinza. ............. 21 

Figura 9: Exemplo de composi√ß√£o colorida. ............................................................. 22 

Figura 10: Ilustra√ß√£o de resolu√ß√µes espaciais distintas. .......................................... 24 

Figura  11:  Ilustra√ß√£o  mostrando  um  esquema  de  resolu√ß√£o  espectral.  √Ä  esquerda, 

resolu√ß√£o multiespectral; √† direita, resolu√ß√£o hiper espectral. .................................. 25 

Figura  12:  Representa√ß√£o  de  uma  mesma  imagem  em  diferentes  resolu√ß√µes 

radiom√©tricas. ............................................................................................................ 26 

Figura 13: Esquema do processo de fus√£o de imagens por m√©todo IHS. ............... 28 

Figura 14: Exemplo de fus√£o IHS: a) Imagem pancrom√°tica (tons de cinza) com alta 

resolu√ß√£o;  b)  Imagem  colorida  (RGB)  com  baixa  resolu√ß√£o;  e  c)  Resultado  final  da 

fus√£o. ........................................................................................................................ 28 

Figura 15: Esquema de distribui√ß√£o de angula√ß√µes e colinearidade em fotogrametria.

 .................................................................................................................................. 29 

Figura  16:  Etapas  do  algoritmo  de  fus√£o  de  imagens,  materializadas  no  software 

‚ÄúFusion‚Äù. .................................................................................................................... 43 

Figura 17: Interface do Fusion: Prompt de Comando de MS-DOS. ......................... 44 

Figura 18: Tabela contendo os dados e especifica√ß√µes da c√¢mera MUX, respons√°vel 

pela capta√ß√£o das bandas 

, 

 e 

. ......................................................................... 49 

Figura 19: Tabela contendo os dados e especifica√ß√µes da c√¢mera PAN, respons√°vel 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

pela capta√ß√£o da imagem pancrom√°tica. .................................................................. 49 

Figura  20:  Aloca√ß√£o  dos  reservat√≥rios  hidrel√©tricos  -  Ret√¢ngulo  Superior: 

Reservat√≥rio de Ilha Solteira; Ret√¢ngulo Inferior: Reservat√≥rio Engenheiro Souza Dias 

(Jupi√°). ...................................................................................................................... 50 

Figura 21: Usina de Ilha Solteira: (a) Composi√ß√£o colorida ‚Äì 

; (b) Componente 

vermelha; (c) Componente verde; (d) Componente azul. .......................................... 51 

20 ùëöùëö

 
 
5 

Figura  22:  Usina  de  Jupi√°:  (a)  Composi√ß√£o  colorida  ‚Äì 

;  (b)  Componente 

vermelha; (c) Componente verde; (d) Componente azul. .......................................... 51 

20 ùëöùëö

Figura 23: Imagens Pancrom√°ticas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o 

da Usina de Jupi√° ...................................................................................................... 52 

Figura 24: Composi√ß√µes coloridas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o 

da Usina de Jupi√°. ..................................................................................................... 54 

Figura  25:  Imagens  coloridas  reamostradas  relativas  √†s  regi√µes  de  Ilha  Solteira  (√† 

esquerda) e de Jupi√° (√† direita). ................................................................................ 55 

Figura 26: Imagens coloridas reamostradas com realce, relativas √†s regi√µes de Ilha 

Solteira (√† esquerda) e de Jupi√° (√† direita). .............................................................. 55 

Figura 27: Imagens fusionadas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o da 

Usina de Jupi√°. .......................................................................................................... 56 

Figura 28: Imagens fusionadas resultantes do experimento, com realce  de contraste 

linear, relativas √†s regi√µes de Ilha Solteira (√† esquerda) e de Jupi√° (√† direita). ........ 57 

Figura  29:  Imagem  fusionada  real√ßada:  (a)  Regi√£o  da  Usina  de  Ilha  Solteira;  (b) 

Regi√£o da Usina de Jupi√°. ........................................................................................ 58 

Figura  30:  Compara√ß√£o  de  detalhes  (regi√£o  de  Ilha  Solteira):  (a)  Imagem  colorida 

inicial; (b) Imagem fusionada ..................................................................................... 59 

Figura 31: Compara√ß√£o de detalhes (regi√£o de Jupi√°): (a) Imagem colorida inicial; (b) 

Imagem fusionada ..................................................................................................... 59 

 
 
 
 
 
 
 
 
6 

SUM√ÅRIO 

1 

Introdu√ß√£o ........................................................................................................... 8 

1.1  Estado da Arte e Justificativa ......................................................................... 8 

1.2  Objetivos ...................................................................................................... 10 

1.3  Estrutura do Trabalho ................................................................................... 11 

2  FUNDAMENTA√á√ÉO TE√ìRICA ......................................................................... 12 

2.1  A Luz e o Olho Humano ............................................................................... 12 

2.2  As Cores Prim√°rias ...................................................................................... 13 

2.3 

Imagens Digitais ........................................................................................... 19 

2.4  Resolu√ß√µes de Imagens ............................................................................... 23 

2.4.1  Resolu√ß√£o Espacial ..................................................................... 23 

2.4.2  Resolu√ß√£o Espectral .................................................................... 24 

2.4.3  Resolu√ß√£o Radiom√©trica .............................................................. 25 

2.4.4  Resolu√ß√£o Temporal .................................................................... 27 

2.5  Fus√£o de Imagens via M√©todo IHS .............................................................. 27 

2.6  Equa√ß√µes de Colinearidade ......................................................................... 29 

2.7  Retifica√ß√£o de imagens ................................................................................ 32 

3  Metodologia ....................................................................................................... 36 

3.1  Pre√¢mbulo .................................................................................................... 36 

3.2  Delineamento Metodol√≥gico da Pesquisa .................................................... 38 

3.2.1  Altera√ß√µes √†s equa√ß√µes de colinearidade ................................... 38 

3.2.2  O algoritmo de fus√£o de imagens ................................................ 42 

4  RESULTADOS E AN√ÅLISES ............................................................................. 48 

4.1  Dados de Entrada ........................................................................................ 48 

4.2  Resultados Experimentais e An√°lises .......................................................... 53 

4.2.1  Procedimentos preliminares ........................................................ 53 

4.2.2  A fus√£o das imagens ................................................................... 55 

 
7 

5  CONCLUS√ïES E RECOMENDA√á√ïES: ........................................................... 61 

5.1  Conclus√µes .................................................................................................. 61 

5.2  Recomenda√ß√µes .......................................................................................... 62 

REFER√äNCIAS BIBLIOGR√ÅFICAS ......................................................................... 63 

 
 
 
 
 
 
8 

1 

INTRODU√á√ÉO 

1.1  Estado da Arte e Justificativa 

No  universo  do  Sensoriamento  Remoto  e  da  Fotogrametria  s√£o  aplicadas 

t√©cnicas  e  metodologias  intimamente  ligadas  √†  Matem√°tica  e  que  envolvem,  por 

exemplo,  vetores,  equa√ß√µes,  Geometria,  ajustamento  de  observa√ß√µes  e  conceitos 

espaciais diversos (GONZALEZ e WOODS, 2010). At√© mesmo programas com fins 

cartogr√°ficos, como o Google Maps e o Google Earth, que incorporam tecnologia GPS 

(Global Positioning System) e que fazem uso das metodologias e t√©cnicas associadas 

ao  Sensoriamento  Remoto  e  √†  Fotogrametria,  possuem  em  sua  constitui√ß√£o  uma 

enorme gama de teorias matem√°ticas que os tornam operacionais. 

√â sabido ainda que, em Sensoriamento Remoto e Fotogrametria os sensores 

possibilitam  a  capta√ß√£o  de  radia√ß√£o  eletromagn√©tica  refletida  pelos  alvos  e  este 

conte√∫do d√° origem a dados (imagens digitais) que, quando processados, resultam 

em informa√ß√µes abrangentes sobre as √°reas de interesse (CR√ìSTA, 1992). Assim, 

cabe informar que, as metodologias e t√©cnicas ligadas ao Sensoriamento Remoto e √† 

Fotogrametria  encontram-se  impregnadas  de  elementos  Matem√°ticos,  pois  as 

imagens  digitais,  que  s√£o  as  principais  fontes  de  dados  destas  ci√™ncias,  est√£o 

intrinsecamente  ligadas  √†  Matem√°tica  e,  por  este  motivo,  surge  a  demanda  por 

algoritmos e modelos matem√°ticos para o seu processamento e para a subsequente 

gera√ß√£o de informa√ß√µes (CR√ìSTA, 1992). Eis a√≠ a import√¢ncia das imagens digitais, 

as quais se encontram no escopo da pesquisa aqui descrita. 

Neste contexto, ao se buscar por imagens digitais orbitais, por exemplo, no site 

do INPE ‚Äì Instituto Nacional de Pesquisas Espaciais (http://www.dgi.inpe.br/CDSR/), 

verifica-se  uma  gama  razo√°vel  de  sat√©lites  e  sensores  dispon√≠veis.  De  modo  mais 

geral,  novos  sat√©lites  destinados  ao  imageamento  s√£o  lan√ßados  regularmente, 

aumentando  consideravelmente  a  disponibilidade  de  dados  orbitais.  No  entanto, 

apesar  da  disponibilidade  de  imagens,  o  custo  de  produtos  que  oferecem  alta 

resolu√ß√£o  e  elevado  detalhamento,  por  vezes,  √©  proibitivo  para  uma  parcela  da 

comunidade das geoci√™ncias. Logo, √© comum que se busque uma alternativa vi√°vel a 

estes produtos onerosos, conforme o exposto a seguir. 

 
 
 
9 

√â comum verificar que sensores pancrom√°ticos, que imageam o espectro em 

apenas uma banda ou faixa de frequ√™ncia (imagens em tons de cinza), d√£o origem √†s 

imagens de mais alta resolu√ß√£o espacial (qualidade do detalhamento da imagem) do 

que os sensores multiespectrais (coloridos) de um mesmo sat√©lite. Assim, visando um 

melhor  aproveitamento  dos  dados  com  diferentes  resolu√ß√µes  espaciais  e,  muitas 

vezes,  provenientes  de  diferentes  sensores,  alguns  m√©todos  de  processamento  de 

imagens  t√™m  sido  propostos  (VENTURA,  2002).  Estes  m√©todos,  genericamente 

conhecidos como ‚Äúm√©todos de fus√£o de imagens‚Äù, destinam-se a combinar imagens 

de  diferentes  caracter√≠sticas  espectrais  e  espaciais  a  fim  de  se  obter  uma  nova 

imagem,  fruto  da  fus√£o  de  imagens  pancrom√°ticas,  com  boa  resolu√ß√£o  espacial,  e 

imagens multiespectrais que, diferentemente das imagens pancrom√°ticas, possuem, 

eventualmente,  pior  resolu√ß√£o  espacial  (LEONARDI  et  al.,  2005).  Ou  seja,  nos 

m√©todos de fus√£o de imagens, atribui-se cor √† uma imagem pancrom√°tica de melhor 

resolu√ß√£o  espacial,  utilizando-se  as  cores de  imagens  multiespectrais  de resolu√ß√£o 

espacial inferior (CHAVEZ e BOWELL, 1988). Logo, o resultado √© uma imagem com 

boa resolu√ß√£o espacial e informa√ß√£o de cor, a qual era anteriormente inexistente. 

Nestes termos, como a discrep√¢ncia de qualidade e de utilidade estabelecida 

entre imagens de sat√©lite, com e sem colora√ß√£o, √© significativa e considerando a busca 

que  os  interessados  das  √°reas  de  Geoprocessamento,  Geom√°tica  e  Geografia 

(usu√°rios,  pesquisadores  e  professores)  empreendem  por  imagens  com  a  melhor 

qualidade poss√≠vel, verifica-se a import√¢ncia da pesquisa te√≥rica e implementa√ß√£o de 

softwares capazes de gerar imagens digitais que possuam a qualidade almejada por 

tais interessados. 

Cabe informar que j√° existem algoritmos destinados √† fus√£o de imagens e que 

estes  s√£o  conhecidos,  aprovados  e  consolidados  pela  comunidade  cient√≠fica 

(LEONARDI et al., 2005). Por√©m, segundo Leonardi et al. (2005), dada a diferen√ßa de 

concep√ß√£o entre tais algoritmos, existe alguma diverg√™ncia entre os produtos gerados 

por eles. Logo, √© nesse contexto que a pesquisa executada se inseriu. 

Diante  do  exposto  e  considerando  a  import√¢ncia  da  Matem√°tica,  bem  como, 

das imagens digitais no √¢mbito das Geoci√™ncias, buscou-se fazer avan√ßar o estado 

da arte no tocante a estes assuntos. Logo, nesta pesquisa efetuou-se altera√ß√µes a um 

modelo matem√°tico e se criou um novo algoritmo, dando origem, consequentemente, 

a  um  programa  de  computador  destinado  √†  fus√£o  de  imagens  digitais,  baseado  no 

 
10 

processo de retifica√ß√£o de imagens, o qual incorpora em sua concep√ß√£o elementos 

de  Geometria  Projetiva  (equa√ß√µes  de  colinearidade).  Para  se  atingir  tais  metas, 

realizou-se  um  estudo  do  algoritmo  de  retifica√ß√£o  de  imagens  e  das  equa√ß√µes  de 

colinearidade  a  ele  incorporadas.  Diante  do  know-how  adquirido,  efetuou-se 

mudan√ßas  algor√≠tmicas  e  matem√°ticas  no  processo  de  modo  a  se  gerar  um 

algoritmo/software de fus√£o de imagens baseado na teoria de fus√£o de imagens via 

m√©todo IHS (Intensity-Hue-Saturation). Cabe especificar que, se optou por utilizar o 

m√©todo de fus√£o de imagens IHS, devido √† qualidade de seus resultados, preconizada 

na literatura, e pelo fato deste ser frequentemente utilizado pela comunidade cient√≠fica 

(LEONARDI et al., 2005). A an√°lise se deu de forma comparativa entre as imagens 

fusionadas geradas e as respectivas imagens simplesmente reamostradas. 

Por  fim,  especifica-se  que,  em  um  primeiro  momento,  os  resultados  desta 

pesquisa  podem  ser  utilizados  em  aplica√ß√µes  de  Sensoriamento  Remoto  e 

Fotogrametria, que necessitam de dados confi√°veis e de excelente qualidade espacial 

e espectral. Em adi√ß√£o a isso, por sua facilidade de opera√ß√£o, o sistema criado poder√° 

ser utilizado tamb√©m, tanto no √¢mbito acad√™mico, quanto na Educa√ß√£o B√°sica, e.g., 

por professores de Geografia e de Hist√≥ria. 

1.2  Objetivos 

A pesquisa objetivou o estudo e o aprofundamento te√≥rico relativo √†s equa√ß√µes 

de colinearidade e ao algoritmo fotogram√©trico de retifica√ß√£o de imagens digitais, com 

o  intuito  de  criar  uma  aplica√ß√£o  computacional  que  efetuasse  a  fus√£o  de  imagens 

digitais com base no m√©todo IHS de fus√£o. A metodologia desenvolvida encontra-se 

no  √¢mbito  da  Geometria  Projetiva  e  foi  avaliada  comparativamente  com  rela√ß√£o  √†s 

imagens reamostradas pelo pr√≥prio sistema implementado. 

A fim de alcan√ßar tal objetivo, algumas metas foram estabelecidas e ser√£o aqui 

detalhadas.  Inicialmente,  procurou-se  estudar  a  teoria  relativa  √†s  equa√ß√µes  de 

colinearidade,  com  vistas  a  entender  sua  concep√ß√£o  e  par√¢metros,  bem  como, 

analisar o algoritmo fotogram√©trico de retifica√ß√£o de imagens, objetivando vislumbrar 

sua l√≥gica de funcionamento e angariar embasamento te√≥rico para a implementa√ß√£o 

proposta.  Em  seguida,  buscou-se  estudar  a  linguagem  de  programa√ß√£o  C/C++, 

considerando  o  paradigma  procedural  de  implementa√ß√£o  computacional,  para  que, 

 
 
 
11 

com isso, se pudesse projetar e efetuar modifica√ß√µes algor√≠tmicas e matem√°ticas no 

algoritmo  de  retifica√ß√£o  de  imagens,  objetivando  assim  a  cria√ß√£o  de  um  software 

capaz  de  realizar  a  fus√£o  de  imagens.  Por  fim,  a  √∫ltima  meta  foi  efetuar  a 

experimenta√ß√£o  e  posterior  avalia√ß√£o  comparativa  entre  os  resultados  advindos  do 

novo software proposto. 

1.3  Estrutura do Trabalho 

Este trabalho foi estruturado em 5 cap√≠tulos. Ap√≥s a introdu√ß√£o, na qual o tema 

abordado foi contextualizado, chegou-se ao Cap√≠tulo 2, destinado √† apresenta√ß√£o dos 

fundamentos  te√≥ricos  que  embasam  a  metodologia  elaborada  e  executada.  Neste 

cap√≠tulo  se  explana  sobre:  a  luz  e  o  olho  humano,  as  cores  prim√°rias,  as  imagens 

digitais, os tipos de resolu√ß√µes de imagens, a fus√£o de imagens via m√©todo IHS, as 

equa√ß√µes de colinearidade e o algoritmo de retifica√ß√£o de imagens digitais. 

O  Cap√≠tulo  3  destina-se  √†  apresenta√ß√£o  do  delineamento  metodol√≥gico 

empreendido e que resultou no software implementado. Neste cap√≠tulo s√£o descritos 

os detalhes inerentes √† metodologia como, por exemplo, a especifica√ß√£o dos dados 

dos processados (imagens), as altera√ß√µes matem√°ticas e algor√≠tmicas para a gera√ß√£o 

do referido programa e os aspectos relativos √† implementa√ß√£o do software de fus√£o 

de imagens. 

No Cap√≠tulo 4 est√£o contidos os resultados obtidos e as an√°lises empreendidas 

sobre tais resultados. 

Ao  final,  tem-se  as  conclus√µes  advindas  da  pesquisa  realizada.  Ou  seja,  o 

Cap√≠tulo 5 traz as considera√ß√µes finais e as principais conclus√µes que se p√¥de inferir 

partir da realiza√ß√£o do trabalho, bem como, as recomenda√ß√µes relativas a poss√≠veis 

trabalhos futuros. 

 
 
 
 
 
12 

2  FUNDAMENTA√á√ÉO TE√ìRICA 

As  se√ß√µes  que  seguem  fundamentam  a  pesquisa  realizada.  Assim,  os 

conte√∫dos  relacionados  √†  luz  e  ao  olho  humano,  √†s  cores  prim√°rias,  √†s  imagens 

digitais, aos tipos de resolu√ß√µes de imagens, √† fus√£o de imagens via m√©todo IHS, √†s 

equa√ß√µes  de  colinearidade  e  ao  algoritmo  de  retifica√ß√£o  s√£o  apresentados  e 

brevemente  discutidos  a  fim  de  que  se  tenha  o  arcabou√ßo  te√≥rico  necess√°rio  √† 

execu√ß√£o da pesquisa de acordo com o delineamento metodol√≥gico previsto. 

2.1  A Luz e o Olho Humano 

Antes de se falar de imagens geradas por sensores embarcados em sat√©lites, 

faz-se necess√°rio realizar uma abordagem acerca das principais caracter√≠sticas das 

ondas eletromagn√©ticas, al√©m do funcionamento do olho humano, com rela√ß√£o a seu 

mecanismo de capta√ß√£o de luz. 

As ondas eletromagn√©ticas que comp√µem a luz possuem, como qualquer onda 

de  car√°ter  f√≠sico,  um  comprimento  de  onda 

  e  uma  frequ√™ncia 

,  medida  em 

oscila√ß√µes  por  segundo,  indicadas  em  hertz  (Hz),  sendo  que  estas  grandezas  s√£o 

ùúÜùúÜ

ùëìùëì

inversamente  proporcionais  entre  si.  Entre  as  ondas  eletromagn√©ticas  de  baixa 

frequ√™ncia  (e.  g.,  infravermelho),  podem  ser  citadas  as  ondas  de  r√°dio,  televis√£o  e 

micro-ondas.  A  faixa  de  frequ√™ncia  correspondente  ao  espectro  eletromagn√©tico 

vis√≠vel pelo olho humano varia entre 4.1014 Hz (luz vermelha) e 8.1014 Hz (luz violeta), 

o  que  equivale  a  um 

intervalo  de 

frequ√™ncias  relativamente  curto.  Mais 

especificamente, tal faixa corresponde √†s cores vermelho, alaranjado, amarelo, verde, 

azul,  anil,  violeta  e  suas  varia√ß√µes,  respectivamente,  que  s√£o  derivadas  da 

decomposi√ß√£o  da  luz  branca.  Acima  disso  est√£o  as  ondas  de  alta  frequ√™ncia, 

conhecidas  como  ondas  ultravioleta,  entre  as  quais  se  encontram  o  raio  X  e,  com 

frequ√™ncia ainda maior, os raios gama. (GASPAR, 2016).  

Com rela√ß√£o √†s estruturas do olho humano respons√°veis pela capta√ß√£o de luz, 

estas consistem em pequenos elementos denominados de cones e bastonetes. Os 

cones s√£o ativados pela maior presen√ßa de luz e s√£o respons√°veis pela capta√ß√£o das 

cores.  J√°  os  bastonetes,  menos  sens√≠veis  √†s  cores,  est√£o  presentes  em  uma 

 
 
 
 
13 

quantidade bastante superior √† dos cones e possuem a capacidade de captar luz em 

ambientes com baixa luminosidade. Com isso, os bastonetes s√£o √∫teis em ambientes 

de baixa luminosidade, em que o discernimento de formas dos objetos se sobrep√µe 

ao de cores (GONZALEZ e WOODS, 2010). 

Figura 1: Espectro vis√≠vel da luz. 
Fonte: Gaspar (2016) 

Basicamente,  a  luz  captada  pelo  olho  humano  pode  advir  de  duas  fontes: 

corpos emissores de luz, como o Sol e as l√¢mpadas el√©tricas, e corpos refletores de 

luz, como a maioria dos objetos vis√≠veis. Considerando esta segunda classe, chega-

se ao √¢mbito das imagens digitais produzidas por sat√©lite que, de modo geral, s√£o o 

produto da amostragem e quantiza√ß√£o da radia√ß√£o eletromagn√©tica refletida. 

A Figura 1 ilustra, em destaque, o espectro vis√≠vel que √© constitu√≠do por ondas 

com comprimento de onda percept√≠veis pelo olho humano. 

2.2  As Cores Prim√°rias 

Quando  se  fala  em  cores  prim√°rias,  se  est√°  abordando  basicamente  um 

conjunto de cores determinadas que d√° origem √†s demais cores captadas pelo olho 

humano. Neste ponto, cabe especificar que, as cores dizem respeito ao comprimento 

de  onda  da  radia√ß√£o  eletromagn√©tica  refletida  pelos  objetos  e  que  s√£o, 

posteriormente, captadas pelo olho humano. Gonzalez e Woods (2010) especificam 

que, para fins de padroniza√ß√£o, a CIE (Commission Internationale de l‚ÄôEclairage ou, 

 
 
 
 
em  portugu√™s,  Comiss√£o  Internacional  de  Ilumina√ß√£o)  determinou,  em  1931,  os 

seguintes valores espec√≠ficos como comprimentos de onda das tr√™s cores prim√°rias: 

azul  = 

,  verde  = 

  e  vermelho  = 

.  Assim,  por  exemplo,  um 

14 

objeto  que  reflita  radia√ß√£o  eletromagn√©tica  com  comprimento  de  onda  em  torno  de 

700 ùëõùëõùëõùëõ

435,8 ùëõùëõùëõùëõ
546,1 ùëõùëõùëõùëõ
 ser√° visto como vermelho. 

700 ùëõùëõùëõùëõ

Complementando  e  corroborando  com  o  acima  descrito,  Gomes  e  Queiroz 

(2001) especificam que as tr√™s cores prim√°rias da luz, considerando a percep√ß√£o do 

olho  humano,  s√£o  o  vermelho,  o  verde  e  o  azul,  e  que  estas  formam  o  sistema 

conhecido como RGB (Red-Green-Blue, em ingl√™s). Das luzes relativas √† estas tr√™s 

cores se originam todas as demais, inclusive a luz branca, quando combinadas (ou 

adicionadas). Por exemplo, o vermelho combinado com o verde, em igual propor√ß√£o, 

forma a cor amarela. De igual modo, o vermelho e o azul formam o magenta e, por 

sua  vez,  o  azul  com  o  verde  resulta  no  ciano.  A  luz  de  cor  branca  √©  resultante  da 

combina√ß√£o, em intensidade m√°xima, das tr√™s cores prim√°rias citadas anteriormente. 

Essa combina√ß√£o vale, tanto para objetos emissores de luz, quanto para os objetos 

refletores. No caso de um objeto refletor, a luz branca (combina√ß√£o de todas as cores) 

chega  at√©  ele  e  as  componentes  da  luz  s√£o  absorvidas  por  sua  superf√≠cie,  com 

exce√ß√£o de uma componente particular que ser√° refletida e que ser√° respons√°vel por 

sua colora√ß√£o, quando tal objeto for observado pelo olho humano ou imageado. Por 

exemplo, se um objeto √© de cor vermelha, significa que ele absorveu as outras faixas 

de cores e refletiu apenas a cor vermelha. 

Figura 2: Sistemas de cores prim√°rias: RGB e CMYK. 
Fonte: Confeccionado pelo pr√≥prio autor 

 
 
15 

Outro  sistema  de  cores  prim√°rias  muito  utilizado  √©  o  sistema  denominado 

CMYK 

(Cyan-Magenta-Yellow-BlacK,  em 

ingl√™s)  correspondente  √†s  cores 

secund√°rias  do  sistema  anterior,  ciano,  magenta  e  amarelo.  Esse  sistema  √© 

normalmente  utilizado  em  impress√µes  de  imagens  por  impressoras  e  m√°quinas 

gr√°ficas  de  modo  geral,  visto  que  as  tr√™s  cores  citadas  d√£o  origem,  quando  s√£o 

utilizadas tintas de impress√£o, a todas as outras, excetuando-se a cor preta, que √© 

adicionada  √†  parte.  Da√≠  o  nome  CMYK  (GOMES  e  QUEIROZ,  2001).  A  Figura  2 

esquematiza os dois sistemas de cores citados anteriormente. J√°, na Figura 3, tem-

se o cubo de cores RGB, que se baseia em um sistema de coordenadas cartesianas 

tridimensional, no qual cada eixo diz respeito a uma componente ou cor prim√°ria. 

Gonzales  e  Woods 

(2010)  explicam  que,  nesta 

representa√ß√£o,  por 

conveni√™ncia, assume-se que todos os valores de cor foram normalizados, de forma 

que o cubo mostrado na Figura 3 √© um cubo unit√°rio. Assim, assume-se os valores de 

R, G e B variem no intervalo [0, 1]. Nestes termos, afirma-se que imagens coloridas 

(RGB) s√£o constitu√≠das de pixels nos quais comparecem tr√™s componentes de cor. De 

modo geral, assume-se que uma imagem colorida seja o resultado da composi√ß√£o de 

tr√™s imagens, uma para cada cor prim√°ria. Ressalta-se que, as componentes ciano, 

magenta e amarelo tamb√©m comparecem, de forma complementar, no cubo de cores 

RGB. 

Figura 3: Esquema do cubo de cores RGB. 
Fonte: Gonzalez e Woods (2010) 

 
 
16 

Al√©m dos sistemas citados, h√° tamb√©m outros sistemas de cores, como o IHS 

(Intensity, Hue, Saturation ou, em portugu√™s, Intensidade-Matiz-Satura√ß√£o), no qual 

s√£o  consideradas,  al√©m  do  matiz  da  cor  (hue),  outras  caracter√≠sticas,  como  a 

intensidade e a satura√ß√£o. 

O modelo de cores IHS caracteriza-se por utilizar um sistema de coordenadas 

cil√≠ndricas  polares  que  representa  as  cores,  ao  inv√©s  de  coordenadas  cartesianas 

como o sistema RGB (CR√ìSTA, 1992). A satura√ß√£o diz respeito √† pureza relativa ou 

quantidade  de  luz  branca  agregada  ao  matiz.  Por  sua  vez,  o  matiz  define  a  cor 

dominante de um objeto. Ou seja, o matiz √© o fator que determina o comprimento de 

onda  dominante  que  ser√°  refletido  por  um  objeto  e  este  comprimento  de  onda 

determina  sua  cor.  Aliada  a  estas  duas  componentes  tem-se  a  intensidade,  que 

abarca a no√ß√£o de brilho da imagem. 

Conforme o apresentado anteriormente, o modelo RGB √© definido tomando-se 

como base um cubo unit√°rio que materializa um sistema cartesiano 3D. Por sua vez, 

as  componentes  do  modelo  IHS  de  cores,  matiz  e  satura√ß√£o,  podem  ser 

representadas, respectivamente, por um tri√¢ngulo de cores, de acordo com a Figura 

4. Considerando a Figura 4, Gonzalez e Woods (2010) expressam que o matiz 

 do 

ponto  de  cor 

  √©  o  √¢ngulo  do  vetor  com  rela√ß√£o  ao  eixo  vermelho.  Assim,  quando 

ùêªùêª

,  tem-se  a  cor  √©  vermelha,  quando 

ùëÉùëÉ

,  a  cor  √©  a  amarela,  e  assim  por 

diante (GONZALEZ, 2010). A satura√ß√£o do ponto 
ùêªùêª = 0¬∞
rela√ß√£o ao centro do tri√¢ngulo. 

ùêªùêª = 60¬∞

ùëÉùëÉ

 corresponde √† sua dist√¢ncia com 

Figura 4: Tri√¢ngulo de representa√ß√£o matiz/satura√ß√£o 
Fonte: Gonzalez (2000) 

 
 
17 

Em adi√ß√£o a isso, Gonzalez e Woods (2010) especificam que, no modelo IHS, 

a  intensidade  √©  medida  com  respeito  a  uma  linha  ortogonal  ao  tri√¢ngulo  (matiz  e 

satura√ß√£o), passando pelo seu centro. As intensidades de brilho, ao longo desta linha 

variam do preto absoluto, extremo inferior da linha, at√© o branco  absoluto, extremo 

superior da linha. A combina√ß√£o do matiz com a satura√ß√£o e a intensidade resultar√° 

no subespa√ßo de estrutura piramidal de tr√™s lados, conforme mostrado na Figura 5 

(GONZALEZ e WOODS, 2010). 

Figura 5: Estrutura piramidal intensidade/matiz/satura√ß√£o 
Fonte: adaptado de Gonzalez e Woods (2010) 

Pontos na superf√≠cie da estrutura apresentada na Figura 5 representam uma 

cor  saturada.  O  matiz  desta  cor  √©  definido  por  seu  √¢ngulo  com  rela√ß√£o  ao  eixo 

vermelho  e  sua  intensidade  consiste  na  dist√¢ncia  perpendicular  ao  ponto  preto. 

Considerando uma imagem RGB e presumindo-se que os respectivos valores tenham 

sido  normalizados  no  intervalo  [0,  1]  pode-se  chegar  aos  valores  de  intensidade, 

satura√ß√£o e matiz por meio das equa√ß√µes abaixo (GONZALEZ e WOODS, 2010): 

                                                        (1) 

ùëÖùëÖ+ùê∫ùê∫+ùêµùêµ

ùêºùêº =

3

 
 
18 

3

ùëÜùëÜ = 1 ‚àí ÔøΩ

ùëÖùëÖ+ùê∫ùê∫+ùêµùêµÔøΩ ‚àô [ùëõùëõ√≠ùëõùëõ(ùëÖùëÖ, ùê∫ùê∫, ùêµùêµ)]

                                         (3) 

                                   (2) 

Onde: 

ùêªùêª = ÔøΩ

ùúÉùúÉ
360¬∞ ‚àí ùúÉùúÉ

    ùë†ùë†ùë†ùë† ùêµùêµ ‚â§ ùê∫ùê∫
   ùë†ùë†ùë†ùë† ùêµùêµ > ùê∫ùê∫

‚Ä¢ 

‚Ä¢ 

, 

 e 

 s√£o as intensidades de brilho das componentes vermelho, verde e azul, 

normalizadas no intervalo [0, 1]; 
ùëÖùëÖ

ùêµùêµ

ùê∫ùê∫

1
2[(ùëÖùëÖ‚àíùê∫ùê∫)+(ùëÖùëÖ‚àíùêµùêµ)]

‚àí1

ùúÉùúÉ = cos

ÔøΩ

[(ùëÖùëÖ‚àíùê∫ùê∫)
Considerando que os valores 

2

1
2ÔøΩ
+(ùëÖùëÖ‚àíùêµùêµ).(ùê∫ùê∫‚àíùêµùêµ)]
 e 

, 

 foram, a priori, normalizados no intervalo 

[0,  1],  ent√£o  os  valores  de  sa√≠da  do  matiz  e  da  intensidade  tamb√©m  estar√£o 
ùêµùêµ
normalizados no intervalo [0, 1]. Por√©m, Gonzalez e Woods (2010) especificam que, 

ùëÖùëÖ

ùê∫ùê∫

para que a satura√ß√£o esteja normalizada no intervalo [0, 1], deve-se dividir os valores 

decorrentes da equa√ß√£o (3) por 360¬∫. 

Cabe esclarecer que, considerando os sistemas RGB e IHS, pode-se ir de um 

a outro sistema via Transforma√ß√£o IHS. Assim, para se ir do sistema IHS para RGB, 

Gonzalez  e  Woods  (2010)  especificam  que  as  equa√ß√µes  aplic√°veis  dependem  dos 

valores  de 

.  Tais  valores  de 

  determinar√£o  tr√™s  setores,  correspondentes  a 

intervalos  de  120¬∫,  que  separam  as  cores  prim√°rias  (ver  Figura  4).  Logo,  ap√≥s 

multiplicar 

ùêªùêª
 por 360¬∫, de modo que os valores de 

ùêªùêª

 voltem ao seu intervalo original, 

pode-se proceder a transforma√ß√£o como segue (GONZALEZ e WOODS, 2010): 

ùêªùêª

ùêªùêª

1)  Se 

, ent√£o fa√ßa: 

0¬∞ ‚â§ ùêªùêª < 120¬∞

                                                    (4) 

ùêµùêµ = ùêºùêº. (1 ‚àí ùëÜùëÜ)

                                            (5) 

ùëÖùëÖ = ùêºùêº. ÔøΩ1 +  

ùëÜùëÜ.ùëêùëêùëêùëêùëêùëê (ùêªùêª)
ùëêùëêùëêùëêùëêùëê (60¬∞‚àíùêªùêª)ÔøΩ

                                               (6) 

2)  Se 

, ent√£o subtraia 120¬∞ de 

ùê∫ùê∫ = 3. ùêºùêº ‚àí (ùëÖùëÖ + ùêµùêµ)

 (i. e., 

) e fa√ßa: 

120¬∞ ‚â§ ùêªùêª < 240¬∞

ùêªùêª

                                                    (7) 

ùêªùêª = ùêªùêª ‚àí 120¬∞

ùëÖùëÖ = ùêºùêº. (1 ‚àí ùëÜùëÜ)

                                            (8) 

ùê∫ùê∫ = ùêºùêº. ÔøΩ1 +  

ùëÜùëÜ.ùëêùëêùëêùëêùëêùëê (ùêªùêª)
ùëêùëêùëêùëêùëêùëê (60¬∞‚àíùêªùêª)ÔøΩ

 
 
19 

                                               (9) 

3)  Se 

, ent√£o subtraia 240¬∞ de 

ùêµùêµ = 3. ùêºùêº ‚àí (ùëÖùëÖ + ùê∫ùê∫)

 (i. e., 

) e fa√ßa: 

240¬∞ ‚â§ ùêªùêª < 360¬∞

ùêªùêª
                                                    (10) 

ùêªùêª = ùêªùêª ‚àí 240¬∞

ùê∫ùê∫ = ùêºùêº. (1 ‚àí ùëÜùëÜ)

                                            (11) 

ùêµùêµ = ùêºùêº. ÔøΩ1 +  

ùëÜùëÜ.ùëêùëêùëêùëêùëêùëê (ùêªùêª)
ùëêùëêùëêùëêùëêùëê (60¬∞‚àíùêªùêª)ÔøΩ

                                               (12) 

Por fim, ainda segundo Gonzalez e Woods (2010), para se retornar aos valores 

ùëÖùëÖ = 3. ùêºùêº ‚àí (ùê∫ùê∫ + ùêµùêµ)

originais de 

, 

 e 

, deve-se normalizar os valores obtidos no intervalo original. 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

2.3 

Imagens Digitais  

Uma  imagem  digital  √©  composta,  basicamente,  por  unidades  denominadas 

pixels  (contra√ß√£o  da  express√£o  inglesa  ‚Äúpicture  element‚Äù),  as  quais  s√£o  pequenos 

quadrados, coloridos (nas imagens coloridas) ou em tons de cinza (nas imagens em 

tons de cinza e pancrom√°ticas, popularmente conhecidas como imagens ‚Äúem preto e 

branco‚Äù)  (CR√ìSTA,  1992).  Essas  pequenas  unidades,  quando  em  conjunto  e 

organizadas em um grid (formato de disposi√ß√£o quadriculado, em linhas e colunas, 

conforme  figura  6),  formam  a  imagem  toda.  A  qualidade  de  uma  imagem  de  uma 

determinada  cena  depender√°  ent√£o  da  quantidade  de  pixels  que  a  comp√µe.  Logo, 

quanto  mais  pixels  a  imagem  da  referida  cena  contiver,  melhor  a  sua  qualidade 

pict√≥rica. Esses pixels, normalmente, s√£o dispostos em um sistema referencial (grid 

retangular) baseado no sistema referencial cartesiano plano, de modo a se facilitar a 

manipula√ß√£o da imagem em quest√£o. 

A Figura 6 apresenta o sistema referencial da imagem com origem no canto 

superior esquerdo. Neste sistema, a contagem de colunas (

) ocorre com rela√ß√£o ao 

eixo 

, da esquerda para a direita e se inicia em 0 (zero). J√° a contagem de linhas (

ùëêùëê

) 

da imagem, ocorre de cima para baixo e tamb√©m se inicia em 0 (zero). Dessa forma, 

ùë•ùë•

ùëôùëô

a  posi√ß√£o  de  um  pixel  qualquer  da  imagem  pode  ser  dada  por  meio  de  um  par 

ordenado (

), ou (

). 

ùë•ùë•, ùë¶ùë¶

ùëêùëê, ùëôùëô

 
 
 
20 

Cabe  informar  que,  para  fins  de  manipula√ß√£o  e  no  intuito  de  se  gerar  uma 

analogia com o primeiro quadrante do plano cartesiano, muitos autores se referem √† 

posi√ß√£o dos pixels das imagens considerando pares ordenados no formato (

). 

ùëôùëô, ùëêùëê

Figura 6: Esquematiza√ß√£o da disposi√ß√£o dos pixels no sistema cartesiano. 
Fonte: Elaborado pelo autor. 

Cr√≥sta (1992) especifica ainda que, cada pixel √© um quadrado que recobre uma 

determinada √°rea de uma cena do mundo real, representando-a pictoricamente. No 

caso de imagens de sat√©lite, a medida de √°rea do mundo real coberta por cada pixel 

ser√° a mesma de qualquer outro pixel pertencente √† mesma imagem. Ainda segundo 

o autor, a cada pixel √© atribu√≠do, no sistema referencial da imagem, um valor de ‚Äú

‚Äù e 

um  valor  de  ‚Äú

‚Äù,  que  correspondem  √†s  posi√ß√µes  de  linha  e  coluna  do  elemento, 

ùë•ùë•

tomadas com rela√ß√£o ao seu centro. Por conven√ß√£o, a origem do sistema referencial 

ùë¶ùë¶

da imagem se localiza no ponto superior esquerdo da imagem. Al√©m disso, um terceiro 

valor, na vari√°vel ‚Äú

‚Äù, √© atribu√≠do ao pixel, e se refere √† tonalidade de cinza desse pixel, 

a qual pode variar do branco ao preto, passando por tonalidades de cinza. Se forem 

ùëßùëß

consideradas as imagens coloridas, ent√£o, costumeiramente, se ter√°, para cada pixel, 

tr√™s valores de intensidade associados, respectivamente, √†s componentes R, G e B, 

a fim de que a cor do pixel seja gerada. Na pr√°tica, uma imagem colorida √© formada 

por  tr√™s  imagens  em  tons  de  cinza  que  cont√™m  as  contribui√ß√µes  de  bandas 

espec√≠ficas, R, G e B, do espectro eletromagn√©tico. 

 
 
21 

Uma imagem pode ser representada matricialmente. Segundo Marques Filho e 

Vieira Neto (1999), os pixels se distribuem em uma matriz de ordem M x N (M linhas 

por N colunas), de modo que a cada pixel est√° associado um n√∫mero inteiro (

), que 

varia de 0 a 2n -1, e que indica a tonalidade deste pixel. Sendo assim, quanto maior o 

ùëßùëß

valor de ‚Äú

‚Äù, maior a quantidade de tons de cinza que poder√° ser utilizada na gera√ß√£o 

de uma imagem. 

ùëõùëõ

Figura 7: Representa√ß√£o de uma matriz P de M linhas por N colunas. 
Fonte: Confeccionado pelo pr√≥prio autor. 

De  modo  mais  did√°tico,  tem-se  na  Figura  7  uma  ilustra√ß√£o  do  conceito  de 

distribui√ß√£o  matricial  de  tons  de  cinza  em  cada  pixel.  Neste  casso, 

,  com  

 e 

, representa a intensidade de brilho (ou n√≠vel de cinza) na 

ùëÉùëÉ(ùë•ùë•, ùë¶ùë¶)

posi√ß√£o (
ùë•ùë• = 1, ‚Ä¶ , ùëÄùëÄ

). 

ùë¶ùë¶ = 1, ‚Ä¶ , ùëÅùëÅ

ùë•ùë•, ùë¶ùë¶

Figura 8: Exemplo de representa√ß√£o matricial de pixels em tons de cinza. 
Fonte: Alc√¢ntara (2016) 

 
 
 
22 

Na Figura 8 √© apresentado um exemplo esquem√°tico de imagem digital. Neste 

exemplo,  efetuou-se  a  amplia√ß√£o  de  um  pequeno  recorte  de  uma  imagem  e  se 

apresenta,  ao  lado  deste  recorte,  uma  grade  com  os  n√∫meros  que  definem  as 

intensidades de brilho dos pixels presentes no recorte. 

Conforme o citado anteriormente, as imagens coloridas s√£o, conforme o pr√≥prio 

nome diz, imagens que apresentam cor. Essas imagens, em meio digital, podem se 

apresentar em diferentes formatos de representa√ß√£o, tais como o formato RGB (do 

ingl√™s: Red-Green-Blue), que apresenta este nome devido √†s cores prim√°rias da luz, 

ou o formato IHS (Intensity-Hue-Saturation) (MENESES e ALMEIDA, 2012). O formato 

RGB √© o mais usual, mas para a manipula√ß√£o de imagens de sat√©lite ser√£o utilizados 

tamb√©m outros formatos, como o citado IHS, que √© menos conhecido pelo p√∫blico de 

modo  geral.  Ressalta-se  que,  as  imagens  coloridas  s√£o  formadas  a  partir  da 

justaposi√ß√£o das componentes de cor constituintes em cada pixel. No caso de uma 

imagem  RGB,  cada  pixel  recebe  uma  contribui√ß√£o  das  tonalidades  verde,  azul  e 

vermelho,  com  intensidades  particulares,  de  modo  a  formar  a  colora√ß√£o  final  dos 

pixels e, consequentemente, da imagem como um todo. 

Na  imagem  apresentada  na  Figura  9,  pode-se  verificar  uma  composi√ß√£o 

colorida √† direita e suas componentes de cor, separadas √† esquerda. Nota-se que, 

cada  imagem  componente  constitui  uma  imagem  em  tons  de  cinza  e  que  a  sua 

composi√ß√£o d√° origem √† imagem colorida. 

Figura 9: Exemplo de composi√ß√£o colorida. 
Fonte: Gomes e Queiroz (2001). 

 
 
23 

2.4  Resolu√ß√µes de Imagens 

O termo resolu√ß√£o, no √¢mbito do Sensoriamento Remoto, diz respeito a quatro 

par√¢metros  relacionados  √†  imagem,  os  quais  s√£o:  resolu√ß√£o  espacial,  resolu√ß√£o 

espectral,  resolu√ß√£o  radiom√©trica  e  resolu√ß√£o  temporal.  Estes  par√¢metros  est√£o 

intrinsecamente  associados  √†  imagem,  definindo-a  e  determinando  sua  poss√≠vel 

utilidade. Nas subse√ß√µes que seguem, as defini√ß√µes destes par√¢metros s√£o postas. 

2.4.1  Resolu√ß√£o Espacial 

A resolu√ß√£o espacial, tamb√©m chamada de resolu√ß√£o geom√©trica, est√° ligada 

ao detalhamento do espa√ßo imageado pelo sat√©lite. Nas palavras de Cr√≥sta (1992): 

A  resolu√ß√£o  espacial  √©  definida  pela  capacidade  do  sistema  sensor  em 
"enxergar" objetos na superf√≠cie terrestre; quanto menor o objeto poss√≠vel de 
ser  visto,  maior  a  resolu√ß√£o  espacial.  A  maneira  mais  comum  de  se 
determinar a resolu√ß√£o espacial de um sensor √© pelo seu campo instant√¢neo 
de  visada  ou  IFOV.  Este  campo  √©  determinado  pelas  propriedades 
geom√©tricas do sistema sensor e define a √°rea do terreno imageado que √© 
"vista" pelo instrumento sensor de uma dada altitude e a um dado momento. 
O IFOV √© medido pelas dimens√µes da √°rea vista no terreno e, de uma forma 
simplificada, ele representa o tamanho do pixel [...] (CR√ìSTA, 1992, p. 25) 

Em  outras  palavras,  a  resolu√ß√£o  espacial  √©,  basicamente,  a  √°rea  do  terreno 

recoberta por um pixel da imagem. Normalmente, se considera um pixel quadrado e, 

por este motivo, a resolu√ß√£o espacial √© dada pelo comprimento do lado do quadrado, 

no  terreno,  recoberto  por  este  pixel.  Por  exemplo,  uma  imagem  com  resolu√ß√£o 

espacial de 1 metro ter√° cada pixel cobrindo uma √°rea equivalente a 1 metro por um 

metro do terreno (

), assim como, uma imagem de resolu√ß√£o espacial de 0,1 metro 

ter√° cada pixel cobrindo uma √°rea de 0,1 metro por 0,1 metro (

2

1 ùëõùëõ

). Deste modo, 

quanto  numericamente  menor  for  a  resolu√ß√£o  espacial  de  uma  imagem,  mais 

2

0,01 ùëõùëõ

detalhada  ela  ser√°  e,  consequentemente,  maior  ser√°  a  quantidade  de  pixels  que  a 

compor√°. A Figura 10 fornece um exemplo no qual uma mesma cena √© imageada com 

imagens de diferentes resolu√ß√µes espaciais. Pode-se perceber que, quanto menor a 

√°rea do terreno abarcada por um pixel, mais detalhada ser√° a imagem, pois pequenos 

detalhes poder√£o ser observados no plano da imagem. 

 
 
 
 
 
24 

Figura 10: Ilustra√ß√£o de resolu√ß√µes espaciais distintas. 
Fonte: Jensen (2007) apud Alc√¢ntara (2016). 

Por vezes, alguns autores se referem √† resolu√ß√£o espacial por meio da sigla 

GSD que, em ingl√™s, significa Ground Sample Distance (em portugu√™s: dist√¢ncia de 

amostra do terreno). 

2.4.2  Resolu√ß√£o Espectral 

A  resolu√ß√£o  espectral  est√°  relacionada  com  as 

faixas  do  espectro 

eletromagn√©tico que o sensor pode captar. Cr√≥sta (1992) explica: 

A resolu√ß√£o espectral √© um conceito inerente √†s imagens multiespectrais de 
Sensoriamento Remoto. Ela √© definida pelo n√∫mero de bandas espectrais de 
um  sistema  sensor  e  pela  largura  do  intervalo  de  comprimento  de  onda 
coberto por cada banda. Quanto maior o n√∫mero de bandas e menor a largura 
do  intervalo,  maior  √©  a  resolu√ß√£o  espectral  de  um  sensor.  O  conceito  de 
banda,  pode  ser  exemplificado  no  caso  de  duas  fotografias  tiradas  de  um 
mesmo objeto, uma em branco-e-preto e a outra colorida; a foto branco-e-

 
 
 
 
25 

preto representa o objeto em apenas uma banda espectral, enquanto a foto 
colorida  representa  o  mesmo  objeto  em  tr√™s  bandas  espectrais,  vermelha, 
azul e verde que, quando combinadas por superposi√ß√£o, mostram o objeto 
em cores. (CR√ìSTA, 1992, p. 25) 

A  resolu√ß√£o  espectral  √©  um  par√¢metro  que depende  do  sensor  de  capta√ß√£o. 

Em  termos  gerais,  ela  est√°  relacionada  √†  quantidade  de  intervalos  do  espectro 

eletromagn√©tico que o sensor √© capaz de captar. Por exemplo, em se considerando a 

faixa  de  luz  vis√≠vel  do  espectro  eletromagn√©tico,  que  vai  do  vermelho  ao  violeta, 

quanto mais subdivis√µes esse sensor dispuser para captar essa faixa eletromagn√©tica, 

menor  ser√°  o  intervalo  de  comprimento  de  onda  captado  por  cada  subdivis√£o,  e 

melhor ser√° a resolu√ß√£o espectral do sensor. Vale frisar que os sat√©lites normalmente 

captam tamb√©m faixas al√©m do espectro eletromagn√©tico vis√≠vel.  

Figura 11: Ilustra√ß√£o mostrando um esquema de resolu√ß√£o espectral. √Ä esquerda, resolu√ß√£o 
multiespectral; √† direita, resolu√ß√£o hiper espectral. 
Fonte: Lu e Fei (2014) apud Alc√¢ntara (2016) 

A  Figura  11  acima  ilustra  o  esquema  de  imageamento  feito  por  sensores 

espectrais,  podendo  ser  multiespectral  (menor  resolu√ß√£o)  ou  hiper  espectral  (maior 

resolu√ß√£o),  e  que  se  encontram  embarcados  em  sat√©lites.  A  ilustra√ß√£o  mostra  as 

bandas  espectrais  pass√≠veis  de  serem  capturadas  pelos  respectivos  tipos  de 

sensores. 

2.4.3  Resolu√ß√£o Radiom√©trica 

A resolu√ß√£o radiom√©trica, tamb√©m conhecida como resolu√ß√£o de intensidade, 

est√° ligada ao n√∫mero de tons de cinza que a imagem disp√µe para ser formada. Nas 

palavras de Cr√≥sta (1992): 

A  resolu√ß√£o  radiom√©trica  √©  dada  pelo  n√∫mero  de  n√≠veis  digitais, 
representando  n√≠veis  de  cinza,  usados  para  expressar  os  dados  coletados 

 
 
 
 
26 

pelo  sensor.  Quanto  maior  o  n√∫mero  de  n√≠veis,  maior  √©  a  resolu√ß√£o 
radiom√©trica. Para entender melhor esse conceito, pensemos numa imagem 
com apenas 2 n√≠veis (branco e preto) em compara√ß√£o com uma imagem com 
32  n√≠veis  de  cinza  entre  o  branco  e  o  preto;  obviamente  a  quantidade  de 
detalhes percept√≠veis na segunda ser√° maior do que na primeira e, portanto, 
a segunda imagem ter√° uma melhor resolu√ß√£o radiom√©trica. (CR√ìSTA, 1992, 
p. 26) 

Basicamente, quanto maior a quantidade de n√≠veis de cinza dispon√≠veis para 

compor a imagem, melhor ser√° sua qualidade gr√°fica. Esses tons de cinza s√£o dados 

como uma pot√™ncia de 2. Segundo Gonzalez e Woods (2010): 

Com base em algumas considera√ß√µes relativas ao hardware, o n√∫mero de 
n√≠veis de intensidade normalmente √© igual a 2k, sendo k um n√∫mero inteiro 
[...] O n√∫mero mais comum √© k=8 (8 bits), com 16 bits sendo utilizados em 
algumas  aplica√ß√µes  nas  quais  o  realce  em  determinadas  faixas  de 
intensidade √© necess√°rio. A quantiza√ß√£o de intensidade utilizando 32 bits √© 
rara. (GONZALEZ e WOODS, 2010, p. 39) 

Sendo  assim,  o  n√∫mero  de  bits  √©  o  expoente  da  pot√™ncia  2k  e  indica, 

indiretamente, o n√∫mero de tons de cinza que comp√µem a imagem. 

Figura 12: Representa√ß√£o de uma mesma imagem em diferentes resolu√ß√µes radiom√©tricas. 
Fonte: Alc√¢ntara (2016) 

Na Figura 12 √© apresentado um exemplo no qual uma mesma cena √© imageada 

com  diferentes  quantidades  de  n√≠veis  de  brilho.  Assim,  pode-se  perceber  que  a 

imagem de maior resolu√ß√£o radiom√©trica (11 bits) √© mais detalhada, ou n√≠tida, e que 

apresenta a melhor qualidade visual. 

 
 
27 

2.4.4  Resolu√ß√£o Temporal 

De acordo com Alc√¢ntara (2016), a resolu√ß√£o temporal est√° ligada ao intervalo 

de tempo com que as imagens ou informa√ß√µes s√£o captadas. Este intervalo de tempo 

correspondente ao tempo que o sat√©lite leva para voltar a cobrir a mesma √°rea. Por 

exemplo,  um  imageamento  de  uma  mesma  regi√£o,  realizado  quinzenalmente,  ter√° 

uma resolu√ß√£o temporal melhor  do que um imageamento efetuado a cada 26 dias. 

Sendo assim, a resolu√ß√£o temporal, tamb√©m chamada de tempo de revisita, √© muito 

√∫til  no  acompanhamento  da  evolu√ß√£o  geogr√°fica  de  diferentes  localidades  e  seus 

contextos,  como  o  desmatamento  de  florestas.  Cabe  especificar  que,  a  resolu√ß√£o 

temporal est√° correlacionada com a altitude em que o sat√©lite orbita e com o tipo de 

√≥rbita em que ele est√°. 

2.5  Fus√£o de Imagens via M√©todo IHS 

As imagens de sat√©lite comumente utilizadas possuem caracter√≠sticas diversas, 

principalmente  se  forem  consideradas,  por  exemplo,  as  resolu√ß√µes  vistas  nas 

subse√ß√µes anteriores. Isso ocorre devido √†s caracter√≠sticas dos sensores de capta√ß√£o 

de imagens. 

Tendo  em  vista  a  resolu√ß√£o  espectral,  verifica-se  que  existem  dois  tipos 

principais de imagens captadas por sat√©lites: as imagens pancrom√°ticas, em tons de 

cinza, e as imagens multiespectrais, que podem dar origem √†s composi√ß√µes coloridas. 

Se  forem  considerados  os  sensores  de  um  mesmo  sat√©lite,  constata-se  que, 

frequentemente,  as  imagens  pancrom√°ticas  apresentam  melhor  resolu√ß√£o  espacial 

que as respectivas imagens multiespectrais. Por√©m, se a resolu√ß√£o espacial √© uma 

desvantagem  para  as  imagens  multiespectrais,  os  dados  relativos  √†  cor  s√£o  uma 

vantagem desej√°vel para os usu√°rios. Deste modo, para que se obtenha dados com 

o melhor das caracter√≠sticas de ambos os tipos de imagens, pode-se efetuar a fus√£o 

entre imagens RGB e pancrom√°tica, relativas a uma mesma √°rea do terreno, e assim 

se obter um produto em cores e com resolu√ß√£o espacial satisfat√≥ria. 

Segundo  Cr√≥sta  (1992),  um  m√©todo  comumente  utilizado  para  isso  √© 

denominado  m√©todo  de  fus√£o  IHS.  Neste  m√©todo  considera-se  o  fato  de  que  a 

intensidade  (

)  est√°  correlacionada  √†  imagem  pancrom√°tica.  De  acordo  com  Al-

Wassai et al. (2011), este m√©todo consiste basicamente em: 

ùêºùêº

 
28 

1)  Registrar as imagens multiespectrais R, G, B e pancrom√°tica de uma mesma √°rea 

em  um  mesmo  sistema  referencial  cartogr√°fico  e  efetuar  a  reamostragem  das 

componentes R, G e B para a dimens√£o da imagem pancrom√°tica; 

2)  Efetuar a transforma√ß√£o das imagens das bandas R, G e B reamostradas para o 

sistema IHS. Nesta transforma√ß√£o s√£o utilizadas as equa√ß√µes de (1) a (3). 

3)  Considerando-se que 

 (intensidade) est√° correlacionada √† imagem pancrom√°tica, 

substituir 

 pela imagem pancrom√°tica; 

ùêºùêº

4)  Converter a imagem, do sistema IHS para o sistema RGB, obtendo o produto final. 

ùêºùêº

Para esta transforma√ß√£o s√£o utilizadas as equa√ß√µes de (4) a (12). 

Segundo  Gonzalez  e  Woods  (2010),  na  fus√£o  IHS  a  substitui√ß√£o  da 

componente  de  intensidade  pela  banda  pancrom√°tica  produz  imagens  com  melhor 

defini√ß√£o espacial. Assim, problemas relativos ao sharpening, associados √† simples 

reamostragem das bandas R, G e B, s√£o quase que totalmente eliminados. 

A Figura 13 apresenta o esquema dos passos descritos anteriormente. 

Figura 13: Esquema do processo de fus√£o de imagens por m√©todo IHS. 
Fonte: Confeccionado pelo pr√≥prio autor. 

A seguir, √© apresentado um exemplo do processo de fus√£o (INPE, 2021): 

Figura 14: Exemplo de fus√£o IHS: a) Imagem pancrom√°tica (tons de cinza) com alta resolu√ß√£o; b) 
Imagem colorida (RGB) com baixa resolu√ß√£o; e c) Resultado final da fus√£o. 
Fonte: Acervo do Instituto Nacional de Pesquisas Espaciais 

 
 
 
29 

Ao se comparar a imagem das Figuras 14(b) e 14(c), pode-se notar um ganho 

em qualidade pictorial com rela√ß√£o ao resultado da fus√£o. 

2.6  Equa√ß√µes de Colinearidade  

De modo simplificado, as equa√ß√µes se baseiam na suposta colinearidade entre 

tr√™s  elementos  relacionados  √†  tomada  das  imagens:  o  centro  √≥ptico  do  sistema  de 

lentes de capta√ß√£o, um ponto qualquer na imagem e seu ponto hom√≥logo no espa√ßo 

f√≠sico  imageado  (espa√ßo  objeto).  Assim,  as  equa√ß√µes  de  colinearidade  s√£o 

basicamente materializadas tomando-se por base as rela√ß√µes de propor√ß√£o entre as 

dist√¢ncias  referentes  a  esses  pontos,  podendo-se  tamb√©m  se  chegar  ao  mesmo 

resultado pelo uso da semelhan√ßa de tri√¢ngulos. 

Figura 15: Esquema de distribui√ß√£o de angula√ß√µes e colinearidade em fotogrametria. 
Fonte: Universidade Federal de Vi√ßosa (adaptado) 

Do esquema da figura acima pode-se depreender as seguintes rela√ß√µes: 

 
 
 
 
30 

Onde: 

                                                     (13) 

ùë•ùë•ùë•ùë•
ùëßùëßùë•ùë• =
ùë¶ùë¶ùë•ùë•
ùëßùëßùë•ùë• =

ùë•ùë•ùë•ùë•

ùëßùëßùë•ùë•
ùë¶ùë¶ùë•ùë•

ùëßùëßùë•ùë•

‚Ä¢ 

‚Ä¢ 

, 

 e 

 s√£o coordenadas do ponto 

 contido na imagem, tomando-se por base 

ùë¶ùë¶ùë•ùë•

o  sistema  cartesiano 
ùë•ùë•ùë•ùë•
fotogram√©trico); 

ùëßùëßùë•ùë•

tridimensional  da 

ùë•ùë•

imagem 

(sistema 

referencial 

, 

 e 

 s√£o as coordenadas do ponto P contido no terreno, tomando-se por 

base o sistema cartesiano da imagem (sistema referencial fotogram√©trico); 
ùë•ùë•ùë•ùë•

ùë¶ùë¶ùë•ùë•

ùëßùëßùë•ùë•

Considerando que a coordenada 

 corresponde √† dist√¢ncia focal (

) no sensor 

de capta√ß√£o, pode-se substituir 

 por 

, de modo que as equa√ß√µes acima passam a 
ùëßùëßùë•ùë•

ùëìùëì

ser escritas como: 

ùëßùëßùë•ùë•

ùëìùëì

ùë•ùë•ùë•ùë• = ‚àíùëìùëì.

ùë•ùë•ùë•ùë•
ùëßùëßùë•ùë•

(14) 

Segundo Silva (2020), levando-se em conta que tanto as coordenadas do ponto 

ùë¶ùë¶ùë•ùë• = ‚àíùëìùëì.

ùë¶ùë¶ùë•ùë•
ùëßùëßùë•ùë•

na  imagem  quanto  do  ponto  no  terreno  est√£o  contidas  em  sistemas  cartesianos 

tridimensionais  distintos,  faz-se  necess√°ria  a  convers√£o  entre  estes  sistemas,  de 

modo a se obter uma padroniza√ß√£o entre pontos no terreno e na imagem. O sistema 

cartesiano tomado como padr√£o ser√° o do terreno. Para a convers√£o entre os dois 

sistemas cartesianos tridimensionais, utiliza-se a seguinte rela√ß√£o: 

Onde: 

ÔøΩ

ùë•ùë•ùë•ùë•
ùë¶ùë¶ùë•ùë•
ùëßùëßùë•ùë•

ÔøΩ = ùúÜùúÜ . ùëÖùëÖùúîùúîùúîùúîùúîùúî ÔøΩ

ùëãùëã ‚àí ùëãùëãùëãùëã
ùëåùëå ‚àí ùëåùëåùëãùëã
ùëçùëç ‚àí ùëçùëçùëãùëã

ÔøΩ

                                      (15) 

‚Ä¢ 

‚Ä¢ 

, 

  e 

  s√£o  coordenadas  de  pontos,  considerando  o  sistema  cartesiano 

tridimensional padr√£o do terreno; 
ùëãùëã

ùëåùëå
, 

ùëçùëç
  e 

  s√£o  coordenadas  do  ponto  P  no  terreno,  considerando  o  sistema 

cartesiano tridimensional da imagem; 
ùë•ùë•ùë•ùë•

ùë¶ùë¶ùë•ùë•

ùëßùëßùë•ùë•

 
 
 
‚Ä¢  Xo,  Yo  e  Zo  s√£o  coordenadas  do  centro  perspectivo  do  sensor  no  sistema 

31 

 √© a matriz de rota√ß√£o entre os sistemas tridimensionais. Ela pode ser definida 

tridimensional padr√£o do terreno; 

 √© um dado fator de escala; 

 √© a dist√¢ncia focal da c√¢mera; 

ùúÜùúÜ

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

ùëìùëì
como o produto 
ùëÖùëÖùúîùúîùúîùúîùúîùúî

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

ùëÄùëÄùúîùúî  =   ÔøΩ

ùëÄùëÄùúîùúî  =   ÔøΩ

0
ùëêùëêùëãùëãùëêùëê ùúîùúî

0
1
0
ùëêùëêùë†ùë†ùë†ùë† ùúîùúî
0 ‚àíùëêùëêùë†ùë†ùë†ùë† ùúîùúî ùëêùëêùëãùëãùëêùëê ùúîùúî
ùëêùëêùëãùëãùëêùëê ùúîùúî 0 ‚àíùëêùëêùë†ùë†ùë†ùë† ùúîùúî
1
ùëêùëêùë†ùë†ùë†ùë† ùúîùúî 0

0
ùëêùëêùëãùëãùëêùëê ùúîùúî

0

ÔøΩ

ÔøΩ 

, onde: 

ùëÖùëÖùúîùúîùúîùúîùúîùúî  =  ùëÄùëÄùúîùúî. ùëÄùëÄùúîùúî. ùëÄùëÄùúîùúî

 √© a matriz de rota√ß√£o ao redor do eixo 

√© a matriz de rota√ß√£o ao redor do eixo 

; 

; 

ùë•ùë•

ùë¶ùë¶

. 

ùëßùëß

 √© a matriz de rota√ß√£o ao redor do eixo 

ùëêùëêùëãùëãùëêùëê ùúîùúî
ùëÄùëÄùúîùúî  =   ÔøΩ
‚àíùëêùëêùë†ùë†ùë†ùë† ùúîùúî
Logo, a matriz 
0

ùëêùëêùë†ùë†ùë†ùë† ùúîùúî 0
ùëêùëêùëãùëãùëêùëê ùúîùúî 0
1

ÔøΩ

 √© dada pela seguinte f√≥rmula: 
0

ùëÖùëÖùúîùúîùúîùúîùúîùúî

ùëÖùëÖùúîùúîùúîùúîùúîùúî =   ÔøΩ

cos ùëòùëò . cos ùúîùúî

ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. cos ùúîùúî + cos ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî ‚àí cos ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. cos ùúîùúî
‚àí cos ùúîùúî . ùëêùëêùë†ùë†ùë†ùë† ùúîùúî cos ùúîùúî. cos ùúîùúî ‚àí ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî cos ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî + ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. ùëêùëêùë†ùë†ùë†ùë† ùúîùúî. cos ùúîùúî

ùëêùëêùë†ùë†ùë†ùë† ùúîùúî

‚àí cos ùúîùúî . ùëêùëêùë†ùë†ùë†ùë† ùúîùúî

cos ùúîùúî. cos ùúîùúî

ÔøΩ
(16) 

Ao se substituir as equa√ß√µes (15) e (16) na equa√ß√£o (14), obt√©m-se as equa√ß√µes de 

colinearidade, explicitadas na seguinte rela√ß√£o (ANDRADE, 1998 apud SILVA, 2020): 

xp = ‚àíùëìùëì

ùëüùëü11(ùëãùëã ‚àí Xo) + ùëüùëü12(ùëåùëå ‚àí Yo) + ùëüùëü13(ùëçùëç ‚àí Zo)
ùëüùëü31(ùëãùëã ‚àí Xo) + ùëüùëü32(ùëåùëå ‚àí Yo) + ùëüùëü33(ùëçùëç ‚àí Zo)

(17) 

Sendo que: 

yp = ‚àíùëìùëì

ùëüùëü21(ùëãùëã ‚àí Xo) + ùëüùëü22(ùëåùëå ‚àí Yo) + ùëüùëü23(ùëçùëç ‚àí Zo)
ùëüùëü31(ùëãùëã ‚àí Xo) + ùëüùëü32(ùëåùëå ‚àí Yo) + ùëüùëü33(ùëçùëç ‚àí Zo)

Onde: 

xp = x‚Ä≤p ‚àí xf
ÔøΩ
yp = y‚Ä≤p ‚àí xf

‚Ä¢ 

, com 

, denotam os elementos da matriz 

; 

‚Ä¢  x‚Äôp e y‚Äôp s√£o coordenadas do ponto p contido na imagem, tomando-se por base o 

ùëÖùëÖùúîùúîùúîùúîùúîùúî

ùëñùëñ, ùëóùëó = 1, ‚Ä¶ ,3

ùëüùëüùëñùëñùëñùëñ
sistema referencial fiducial; 

‚Ä¢  xf  e yf √© a coordenada x do centro do plano da imagem; 

 
 
 
 
 
 
32 

Deste  modo,  tomando-se  os  elementos  de  rota√ß√£o  (œâ,  œÜ,  Œ∫)  e  os  elementos  de 

transla√ß√£o  (Xo,  Yo,  Zo),  pode-se  projetar  as  coordenadas  do  sistema  cartesiano 

tridimensional  da  imagem  para  o  sistema  tridimensional  padr√£o  do  terreno, 

considerando a coordenada Z conhecida, utilizando-se as equa√ß√µes de colinearidade 

na forma inversa. Segundo Andrade (1998), tais equa√ß√µes s√£o: 

ùëãùëã = ùëãùëãùëãùëã + (ùëçùëç ‚àí ùëçùëçùëãùëã). ( 

ùëüùëü11. xp + ùëüùëü21. yp ‚àí ùëüùëü31ùëìùëì
ùëüùëü13. xp + ùëüùëü23. yp ‚àí ùëüùëü33ùëìùëì

 )

(18) 

Por fim, Andrade (1998) especifica que as equa√ß√µes de colinearidade, tanto na 

ùëåùëå = ùëåùëåùëãùëã + (ùëçùëç ‚àí ùëçùëçùëãùëã). (

ùëüùëü12. xp + ùëüùëü22. yp ‚àí ùëüùëü32ùëìùëì
ùëüùëü13. xp + ùëüùëü23. yp ‚àí ùëüùëü33ùëìùëì

)

sua forma direta, quanto na sua forma inversa, envolvem seis par√¢metros de cunho 

geom√©trico que s√£o: duas transla√ß√µes, uma em 

 e outra em 

, tr√™s rota√ß√µes em torno, 

respectivamente, dos eixos 

, 

 e 

, e um fator de escala, associado √† dist√¢ncia focal 
ùë¶ùë¶

ùë•ùë•

. 

ùëìùëì

ùë•ùë•

ùë¶ùë¶

ùëßùëß

2.7  Retifica√ß√£o de imagens 

A retifica√ß√£o de imagens, nas palavras de Silva (2020), ‚Äú√© o processo pelo qual 

ocorre a elimina√ß√£o das distor√ß√µes causadas pelos √¢ngulos de atitude da c√¢mera que 

fez a tomada de uma imagem‚Äù, ou seja, √© a corre√ß√£o da imagem original, a qual sofre 

distor√ß√µes  devido  aos  efeitos  de  poss√≠veis  inclina√ß√µes  do  sensor  de  capta√ß√£o  em 

rela√ß√£o ao terreno ou objeto imageado. 

Segundo  Cr√≥sta  (1992),  as  principais  fontes  de  distor√ß√£o  das  imagens  de 

sat√©lite s√£o a rota√ß√£o da Terra e a instabilidade da plataforma, a qual sofre varia√ß√µes 

na altitude, na velocidade do sat√©lite em rela√ß√£o ao terreno e nos eixos de rota√ß√£o do 

sat√©lite. Sendo assim, o objetivo deste processo √© fazer com que a imagem fique em 

uma  perspectiva,  apesar  de  c√¥nica,  perfeitamente  vertical,  como  se  o  sensor  de 

capta√ß√£o estivesse posicionado ortogonalmente ao objeto, algo que √© praticamente 

imposs√≠vel  durante  o  processo  de  imageamento.  A  precis√£o  desejada  deve  ser 

compar√°vel  √†  de  um  mapa,  ou  seja,  o  processo  deve  apresentar  uma  exatid√£o 

rigorosa em rela√ß√£o ao objeto imageado. Segundo Cerqueira (2004), neste processo 

 
 
 
 
 
33 

s√£o  utilizados  modelos  matem√°ticos,  normalmente  baseados  nas  equa√ß√µes  de 

colinearidade (vistas anteriormente). 

De  modo  bem  simplificado,  pode-se  dizer  que  o  processo  de  retifica√ß√£o  de 

imagens, realizado pelos softwares especializados, consiste no  estabelecimento de 

uma rela√ß√£o entre as coordenadas da imagem original e da imagem retificada, com a 

realoca√ß√£o  de  pixels,  de  modo  a  se  corrigir  as  distor√ß√µes  da  imagem  original 

(CR√ìSTA,1992). 

Segundo  Andrade  (1998),  existe  mais  de  uma  forma  de  se  implementar  o 

algoritmo  de  retifica√ß√£o  de  imagens:  o  m√©todo  direto  e  o  m√©todo  indireto.  Por  uma 

quest√£o  de  efici√™ncia,  o  algoritmo  descrito  a  seguir  diz  respeito  ao  m√©todo  de 

retifica√ß√£o  digital  indireto,  que  utiliza  as  equa√ß√µes  de  colinearidade  na  sua  forma 

direta. Neste caso, as equa√ß√µes de colinearidade, na sua forma direta, s√£o utilizadas 

para 

relacionar 

fotocoordenadas  da 

imagem 

retificada, 

reamostrada,  com 

fotocoordenadas da imagem original, obtendo assim o tom de cinza que preencher√° 

a  respectiva  posi√ß√£o  do  grid  da  imagem  retificada.  Para  que  a  retifica√ß√£o  ocorra  a 

contento, duas outras transforma√ß√µes s√£o utilizadas para relacionar os referenciais de 

imagem e o fotogram√©trico. Tais transforma√ß√µes s√£o dadas em momento oportuno. 

Os passos que comp√µem o algoritmo de retifica√ß√£o s√£o os seguintes: 

1)  Leitura  da  imagem  de  entrada  (imagem  original):  no  processo  de  leitura, 

al√©m  das  intensidades  de  brilho  da  imagem  de  entrada,  s√£o  carregados  e 

armazenados os valores relativos √† largura e altura da imagem original. 

2)  Leitura  dos  par√¢metros  de  transforma√ß√£o:  al√©m  dos  valores  de  brilho  da 

imagem de entrada e de suas dimens√µes, s√£o lidos em arquivo ou introduzidos 

via  interface  os  valores  dos  √¢ngulos  de  orienta√ß√£o  exterior  (

, 

  e 

),  que 

fornecem  a  atitude  da  c√¢mera  no  momento  da  tomada  da  imagem,  al√©m  da 

ùúîùúî

ùúîùúî

ùúîùúî

dist√¢ncia focal da referida c√¢mera (

). 

3)  C√°lculo  da  matriz  de  rota√ß√£o:  para  o  c√°lculo  da  matriz  de  rota√ß√£o  s√£o 

ùëìùëì

necess√°rios os √¢ngulos 

, 

 e 

 (passo 2) e √© utilizada a f√≥rmula prevista na 

equa√ß√£o 16. 

ùúîùúî

ùúîùúî

ùúîùúî

4)  C√°lculo das dimens√µes da imagem retificada (reamostrada): para se ter as 

dimens√µes  (largura  e  altura)  da  imagem  reamostrada,  inicialmente  s√£o 

tomadas  as  coordenadas  dos  v√©rtices  (cantos)  da  imagem  de  entrada.  Em 

 
34 

seguida, estas coordenadas s√£o transformadas do  sistema referencial  digital 

para o sistema referencial com origem no centro da imagem. Assim, a partir do 

sistema referencial digital (

), pode-se obter as coordenadas 

 de pontos 

no sistema referencial com origem no centro da imagem. Essa transforma√ß√£o 

(ùë•ùë•, ùë¶ùë¶)

ùëêùëê, ùëôùëô

√© dada por: 

Onde: 

ùëäùëä‚àí1

                                        (19) 

ùë•ùë•
ùë¶ùë¶ÔøΩ = ÔøΩ

ùëÜùëÜùë•ùë•
0
0 ‚àíùëÜùëÜùë¶ùë¶ÔøΩ ÔøΩ

ÔøΩ

ùëêùëê ‚àí

2
ùêªùêª‚àí1

ùëôùëô ‚àí

2

ÔøΩ

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

 √© a dimens√£o do pixel na dire√ß√£o 

 √© a dimens√£o do pixel na dire√ß√£o 

ùë•ùë•

; 

; 

 representa o n√∫mero de colunas da imagem; e 

ùë¶ùë¶

ùëÜùëÜùë•ùë•
ùëÜùëÜùë¶ùë¶

 o n√∫mero de linhas da imagem. 

ùëäùëä

De posse das coordenadas expressas no sistema referencial com origem no 

ùêªùêª

centro  da  imagem  e  do  valor  negativo  da  dist√¢ncia  focal  (

),  como  terceira 

coordenada,  s√£o  utilizadas  as  equa√ß√µes  de  colinearidade  inversa  (equa√ß√£o 

‚àíùëìùëì

(18)) a fim de se ter as coordenadas dos v√©rtices da imagem retificada, dadas 

no sistema referencial com origem no centro da imagem, com rela√ß√£o √† imagem 

retificada.  Por  fim,  as  coordenadas  dos  v√©rtices  da  imagem  retificada  s√£o 

transformadas para o sistema referencial digital por meio da equa√ß√£o: 

ÔøΩùëêùëê
ùëôùëô

ÔøΩ = ÔøΩ

‚àí1
ùëÜùëÜùë•ùë•
0
‚àí1ÔøΩ ÔøΩ
0 ‚àíùëÜùëÜùë¶ùë¶

ùë•ùë•
ùë¶ùë¶ÔøΩ + ÔøΩ

ùëäùëä‚àí1
2
ùêªùêª‚àí1
2

                                            (20) 

ÔøΩ

Silva (2020) explica que, em alguns casos como, por exemplo, na retifica√ß√£o 

de imagens, 

 e 

 podem ser unit√°rios, visto que, o que se tem √© um rearranjo 

dos  pixels  da  imagem  e  n√£o  uma  rela√ß√£o  dos  pixels  com  coordenadas  de 

ùëÜùëÜùë•ùë•

ùëÜùëÜùë¶ùë¶

terreno. A partir das coordenadas dos cantos da imagem retificada, pode-se ter 

acesso √†s suas dimens√µes. Em rela√ß√£o a isso, explica Silva (2020) ainda que, 

considerando  que  a  imagem  retificada  poder√°  n√£o  ser  retangular,  com  base 

nas  novas  coordenadas  dos  cantos  calculadas,  cria-se  um  ret√¢ngulo 

envolvente que possa abarcar a imagem retificada, de modo a permitir que ela 

seja  visualizada  ao  final  do  processo.  Assim,  cria-se  uma  matriz,  com  as 

 
35 

dimens√µes  do  ret√¢ngulo  envolvente,  na  qual  ser√£o  alocados  os  valores  de 

brilho relativos √† imagem retificada. 

5)  Varredura e preenchimento da imagem retificada: neste passo, toma-se a 

matriz destinada √† aloca√ß√£o dos valores de brilho relativos √† imagem retificada 

e efetua-se a sua varredura, tomando-se, paulatinamente, as coordenadas de 

seus  pixels  (

),  transformando-os  para  coordenadas  (

),  por  meio  da 

equa√ß√£o 19, e, por meio das equa√ß√µes de colinearidade direta (equa√ß√£o 17) 

ùë•ùë•, ùë¶ùë¶

ùëêùëê, ùëôùëô

chega-se  √†s  coordenadas  (

),  relativas  √†  imagem  de  entrada.  Neste  caso, 

para se ter acesso √†s coordenadas (

ùë•ùë•, ùë¶ùë¶

 dos pixels da imagem original, deve-

se  ainda  utilizar  a  equa√ß√£o  20.  Silva  (2020)  especifica  que,  visto  que  as 
ùëêùëê, ùëôùëô)

coordenadas  (

)  geradas  geralmente  n√£o  coincidem  com  coordenadas  de 

pixel  (valores  inteiros)  da  imagem  original,  utiliza-se  algum  m√©todo  de 

ùëêùëê, ùëôùëô

interpola√ß√£o para se obter o tom de cinza que preencha o respectivo pixel da 

matriz relativa √† imagem retificada (reamostrada). 

O resultado final √© a imagem retificada, que √© salva em arquivo. 

 
 
 
 
36 

3  METODOLOGIA 

Este  cap√≠tulo  destina-se  √†  apresenta√ß√£o  dos  procedimentos  metodol√≥gicos 

efetivamente  desenvolvidos  e  realizados  na  pesquisa.  Cabe  especificar  que,  a 

metodologia executada possuiu car√°ter te√≥rico e experimental. Ou seja, ela consistiu, 

inicialmente,  na  sondagem  do  algoritmo  de  retifica√ß√£o  de  imagens  digitais  e  das 

equa√ß√µes de colinearidade que o integram, a fim de se angariar conhecimento te√≥rico 

e  algor√≠tmico  com  o  objetivo  de  projetar  e  implementar  mudan√ßas  algor√≠tmicas  e 

matem√°ticas em tais modelos de modo a gerar um novo algoritmo capaz de efetuar a 

fus√£o de imagens digitais, com base no m√©todo IHS. 

Logo,  buscando  detalhar  o  trabalho  realizado  tem-se,  na  se√ß√£o  3.1,  um 

pequeno pre√¢mbulo, destinado √† descri√ß√£o dos principais recursos computacionais e 

dos  dados  de  entrada,  utilizados  na  pesquisa.  Na  se√ß√£o  3.2  encontra-se  a 

pormenoriza√ß√£o do delineamento metodol√≥gico executado para a gera√ß√£o do produto 

final. 

3.1  Pre√¢mbulo 

Considerando que a proposta da pesquisa envolve o uso de imagens, foram 

coletadas  e  utilizadas  imagens  provenientes  do  sat√©lite  CBERS  4,  disponibilizadas 

gratuitamente no site do INPE (http://www.dgi.inpe.br/CDSR/). A escolha do produto 

se  deu  por  conta  de  sua  √≥tima  qualidade  e  pelo  fato  de  estarem  dispon√≠veis  as 

imagens multiespectrais e a pancrom√°tica, necess√°rias √† execu√ß√£o da metodologia. 

As ortoimagens multiespectrais, possuem resolu√ß√£o espacial de 

 e foram geradas 

pelo  sensor  MUX  -  C√¢mera  Multiespectral  Regular.  Por  sua  vez,  a  imagem 

20ùëöùëö
, √© proveniente do sensor PAN - C√¢mera 

pancrom√°tica, com resolu√ß√£o espacial de 

Pancrom√°tica  e  Multiespectral.  Todas  as  imagens  s√£o  do  formato  GEOTIFF e  v√™m 
5ùëöùëö
georreferenciadas  no  Sistema  Referencial  Geod√©sico  WGS84,  considerando  o 

sistema  de  proje√ß√£o  UTM  (zona  22).  O  c√≥digo  EPSG  (European  Petroleum  Survey 

Group)  que  identifica  estes  elementos  geod√©sicos  √©  o  32722,  o  qual  foi  usado  no 

sistema de informa√ß√µes geogr√°ficas QGIS. As imagens do sensor MUX e PAN s√£o do 

dia 29/04/2020 e correspondem √† orbita 160 e ao ponto 123. Estas imagens dizem 

 
 
 
 
37 

respeito ao rio Paran√° e imedia√ß√µes, na regi√£o compreendida entre Tr√™s Lagoas ‚Äì MS 

e Ilha Solteira - SP. S√£o elas: 

‚Ä¢  Banda 1 = 0,51 - 0,85 ¬µm (PAN): imagem pancrom√°tica; 

‚Ä¢  Banda 5 = 0,45 - 0,52 Œºm (B): componente azul; 

‚Ä¢  Banda 6 = 0,52 - 0,59 Œºm (G): componente verde; 

‚Ä¢  Banda 7 = 0,63 - 0,69 Œºm (R): componente vermelha. 

Cabe  especificar  que,  as  imagens  CBERS  n√£o  foram  processadas  em  sua 

totalidade,  uma  vez  que,  a  largura  da  imagem  pancrom√°tica  (60  km)  n√£o  se 

equiparava  √†  largura  das  imagens  multiespectrais  (120  km),  al√©m  do  que,  o 

processamento integral das imagens fugiria do objetivo do trabalho. Nestes termos, 

foram feitos dois recortes, relativos aos reservat√≥rios das usinas hidrel√©tricas de Ilha 

Solteira e Engenheiro Souza Dias (Jupi√°), os quais s√£o apresentados no cap√≠tulo que 

segue. 

Neste caso, os recortes foram feitos por meio do software QGIS. O QGIS √© um 

Sistema  de  Informa√ß√µes  Geogr√°ficas  (SIG)  gratuito,  criado  por  Gary  Sherman  em 

2002. No entanto, sua vers√£o inicial foi lan√ßada em somente em 2009 (MARQUES, 

2021). 

Segundo  a  p√°gina  do  pr√≥prio  SIG,  o  QGIS  √©  um  Sistema  de  Informa√ß√£o 

Geogr√°fica (SIG) de C√≥digo Aberto, licenciado segundo a Licen√ßa P√∫blica Geral GNU, 

multiplataforma,  que  permite  a  visualiza√ß√£o,  edi√ß√£o  e  an√°lise  de  dados 

georreferenciados (QGIS, 2021). Ele suporta in√∫meros formatos de vetores, rasters, 

bases de dados e funcionalidades. Al√©m das funcionalidades nativas do SIG, ele ainda 

conta  com  complementos 

(plugins),  desenvolvidos  e  disponibilizados  por 

colaboradores de todo o mundo no site do QGIS1. A vers√£o utilizada nesta pesquisa 

foi a 3.12.2 Bucure»ôti. 

Para a gera√ß√£o dos recortes, inicialmente se ajustou o projeto inicial do QGIS 

ao  sistema  referencial  cartogr√°fico  e  proje√ß√£o  das 

imagens  do  CBERS  4 

(WGS84/UTM zona 22), adotando no menu ‚ÄúPropriedades‚Äù o respectivo c√≥digo EPSG 

32722,  relativo  aos  ditos  par√¢metros  geod√©sicos.  Ap√≥s  se  carregar  as  imagens 

(camadas raster), se utilizou a ferramenta raster ‚ÄúRecortar raster pela extens√£o‚Äù para 

1 Dispon√≠vel em:< https://plugins.qgis.org/>. Acesso: 01/05/2021 

 
                                            
38 

se gerar os recortes das imagens de entrada. Os locais dos recortes foram escolhidos 

por  possu√≠rem  fei√ß√µes  significativas  e  n√£o  possu√≠rem  cobertura  de  nuvens.  Cabe 

informar que estas raz√µes tamb√©m justificaram a escolha das imagens como um todo. 

Sendo  assim,  de  posse  dos  recortes,  utilizou-se  o  QGIS,  uma  vez  mais,  para  a 

gera√ß√£o de composi√ß√µes coloridas. 

3.2  Delineamento Metodol√≥gico da Pesquisa 

O delineamento metodol√≥gico √© descrito considerando-se dois focos: 

‚Ä¢  As altera√ß√µes matem√°ticas e algor√≠tmicas associadas ao processo de retifica√ß√£o 

de imagens digitais; e 

‚Ä¢  A gera√ß√£o do algoritmo de fus√£o de imagens. 

Logo, as subse√ß√µes que seguem destinam-se √† pormenoriza√ß√£o dos referidos 

focos e expressam o cerne da pesquisa empreendida. 

3.2.1  Altera√ß√µes √†s equa√ß√µes de colinearidade 

Cabe inicialmente lembrar que, considerando uma imagem a√©rea, a retifica√ß√£o 

de  imagens  digitais  √©  o  processo  destinado,  principalmente,  √†  elimina√ß√£o  das 

distor√ß√µes presentes em tal imagem, decorrentes dos √¢ngulos de atitude da c√¢mera 

que fez a tomada. Estes √¢ngulos de rota√ß√£o podem ocorrer em torno do eixo 

 e/ou 

do eixo 

 e/ou do eixo 

. No √¢mbito da Fotogrametria, estes √¢ngulos de atitude s√£o 

ùë•ùë•

denotados, respectivamente, por œâ, œÜ e Œ∫ (√¢ngulos de orienta√ß√£o exterior). Al√©m, dos 

ùë¶ùë¶

ùëßùëß

par√¢metros  relativos  √†  atitude  do  sensor  de  imageamento,  o  modelo  possui  um 

par√¢metro associado √† escala da imagem e que tamb√©m est√° associado √† geometria 

da c√¢mera. Este par√¢metro √© a dist√¢ncia focal 

 que, em conjunto com a altitude de 

voo,  estabelece  um  fator  de  escala  para  a  imagem  gerada.  Por  fim,  pode-se  ainda 

ùëìùëì

considerar a possibilidade de se efetuar duas transla√ß√µes, uma na dire√ß√£o 

 e outra 

na dire√ß√£o 

. Estas transla√ß√µes podem se dar por meio das coordenadas do centro 

ùë•ùë•

perspectivo, que est√£o incorporadas √†s equa√ß√µes de colinearidade. Nestes termos, 

ùë¶ùë¶

 
 
 
 
 
os par√¢metros considerados na retifica√ß√£o s√£o: tr√™s rota√ß√µes (em torno dos eixos 

, 

 e 

), um fator de escala e duas transla√ß√µes (nas dire√ß√µes dos eixos 

 e 

). 

ùë•ùë•

39 

ùë¶ùë¶

ùëßùëß

Cabe lembrar que, o algoritmo de retifica√ß√£o, da forma como foi detalhado na 

ùë¶ùë¶

ùë•ùë•

se√ß√£o 2.7, destina-se a efetuar rota√ß√µes em imagens, possivelmente, em torno dos 

eixos 

, 

  e 

.  Assim,  uma  imagem  de  entrada,  tomada  com  c√¢mera  afetada  de 

varia√ß√µes angulares, possivelmente nos tr√™s eixos, pode ser corrigida de distor√ß√µes 

ùë•ùë•

ùë¶ùë¶

ùëßùëß

decorrentes de tais varia√ß√µes. Logo, uma imagem afetada pela atitude da c√¢mera no 

momento da tomada passaria, quando processada, a ser uma imagem de perspectiva 

central. 

Nestes  termos,  cabe informar  que  os  par√¢metros,  relativos  √†s  tais  corre√ß√µes 

angulares  e  que  integram  as  equa√ß√µes  de  colinearidade,  n√£o  foram  alterados. 

Buscou-se deixar essa potencialidade no modelo a fim de que ela estivesse dispon√≠vel 

e pudesse ser utilizada se necess√°rio. Segundo Al-Wassai et al. (2011), as imagens 

a  serem  fusionadas  devem  ser  registradas  num  mesmo  sistema  referencial 

geod√©sico,  a  fim  de  que  a  superposi√ß√£o  estabelecida  entre  as  imagens 

multiespectrais  e  a  imagem  pancrom√°tica  seja  efetiva.  Logo,  deixar  tais 

par√¢metros  √†  disposi√ß√£o,  implica  em  poder  se  efetuar  ajustes  angulares  que 

possam  corrigir,  a  posteriori,  poss√≠veis  discrep√¢ncias  angulares  associadas  √† 

superposi√ß√£o. 

Andrade (1998), e Wolf e Dewitt (2000) afirmam que a dist√¢ncia focal (

) est√° 

relacionada  √†  escala  da  imagem  capturada.  Tal  informa√ß√£o  foi  bastante  √∫til  na 

ùëìùëì

pesquisa empreendida, pois Al-Wassai  et  al.  (2011)  especificam  que  as  imagens 

multiespectrais  devem  ser  reamostradas  para  as  dimens√µes  da 

imagem 

pancrom√°tica. Consequentemente, esta caracter√≠stica associada √† dist√¢ncia focal 

, 

que est√° presente nas equa√ß√µes de colinearidade direta e inversa, pode ser utilizada 

ùëìùëì

para que a reamostragem preconizada por Al-Wassai et al. (2011) ocorra. 

Nestes termos, buscou-se efetuar altera√ß√µes no dito par√¢metro de modo que 

ele efetuasse o controle da escala. Ap√≥s estudos, experimenta√ß√µes, e observa√ß√µes 

de efeitos associados √† dist√¢ncia focal e suas varia√ß√µes, a exemplo do proposto em 

Silva  (2020),  decidiu-se  pelo  uso  de  dois  par√¢metros,  de  modo  que,  a  propor√ß√£o 

estabelecida entre eles expressasse um fator de escala. Assim, os dois par√¢metros, 

 e 

, passaram a substituir o valor da dist√¢ncia focal nas equa√ß√µes de colinearidade 

ùëìùëì‚Ä≤

‚Ñé

 
direta e inversa. Corroborando com Silva (2020), as equa√ß√µes de colinearidade direta 

e inversa ficaram, respectivamente: 

40 

ùë•ùë•ùëùùëù = ‚àí‚Ñé

ùëüùëü11(ùëãùëã ‚àí ùëãùëãùê∂ùê∂ùê∂ùê∂) + ùëüùëü12(ùëåùëå ‚àí ùëåùëåùê∂ùê∂ùê∂ùê∂) + ùëüùëü13(‚àíùëìùëì‚Ä≤)
ùëüùëü31(ùëãùëã ‚àí ùëãùëãùê∂ùê∂ùê∂ùê∂) + ùëüùëü32(ùëåùëå ‚àí ùëåùëåùê∂ùê∂ùê∂ùê∂) + ùëüùëü33(‚àíùëìùëì‚Ä≤)

ùë¶ùë¶ùëùùëù = ‚àí‚Ñé

ùëüùëü21(ùëãùëã ‚àí ùëãùëãùê∂ùê∂ùê∂ùê∂) + ùëüùëü22(ùëåùëå ‚àí ùëåùëåùê∂ùê∂ùê∂ùê∂) + ùëüùëü23(‚àíùëìùëì‚Ä≤)
ùëüùëü31(ùëãùëã ‚àí ùëãùëãùê∂ùê∂ùê∂ùê∂) + ùëüùëü32(ùëåùëå ‚àí ùëåùëåùê∂ùê∂ùê∂ùê∂) + ùëüùëü33(‚àíùëìùëì‚Ä≤)

ùëãùëã = ‚àíùëìùëì‚Ä≤

ùëüùëü11ùë•ùë•ùëùùëù + ùëüùëü21ùë¶ùë¶ùëùùëù + ùëüùëü31(‚àí‚Ñé)
ùëüùëü13ùë•ùë•ùëùùëù + ùëüùëü23ùë¶ùë¶ùëùùëù + ùëüùëü33(‚àí‚Ñé)

(21) 

(22) 

Onde: 

ùëåùëå = ‚àíùëìùëì‚Ä≤

ùëüùëü12ùë•ùë•ùëùùëù + ùëüùëü22ùë¶ùë¶ùëùùëù + ùëüùëü32(‚àí‚Ñé)
ùëüùëü13ùë•ùë•ùëùùëù + ùëüùëü23ùë¶ùë¶ùëùùëù ‚àí ùëüùëü33(‚àí‚Ñé)

  e 

  s√£o  coordenadas  do  ponto  na  imagem  dadas  no  sistema  referencial 

ùë¶ùë¶ùëùùëù

fotogram√©trico da imagem original; 
ùë•ùë•ùëùùëù
  √©  o  primeiro  dos  valores  associados  √†  escala  e  que  substituiu  parcialmente  a 

dist√¢ncia focal; 
‚Ñé

 √© o segundo dos valores associados √† escala e que substituiu parcialmente a 

dist√¢ncia focal; 
ùëìùëì‚Ä≤

 s√£o os elementos da matriz de rota√ß√£o; 

  s√£o  coordenadas  de  pontos  no  sistema  referencial  fotogram√©trico  da 

  e 

ùëüùëüùëñùëñùëñùëñ
, 
imagem transformada; 
ùëãùëã

ùëåùëå
, 

ùëçùëç
 e 

 s√£o coordenadas do CP no sistema referencial fotogram√©trico da 

imagem transformada; 
ùëãùëãùê∂ùê∂ùê∂ùê∂
ùëçùëçùëêùëêùëùùëù

ùëåùëåùê∂ùê∂ùê∂ùê∂

Cabe explicar que, na pr√°tica, ao se adotar dois valores, 

 e 

, em lugar da 

dist√¢ncia focal 

, significa que agora h√° dois par√¢metros correspons√°veis pela escala. 

ùëìùëì‚Ä≤

‚Ñé

Assim, 

 est√° associado √† imagem de entrada e 

ùëìùëì

 diz respeito √† imagem reamostrada 

(de sa√≠da). Dessa forma, a propor√ß√£o entre estes novos par√¢metros implicar√° em uma 

ùëìùëì‚Ä≤

‚Ñé

mudan√ßa  de  escala  quando,  por  meio  das  equa√ß√µes  de  colinearidade  direta  ou 

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

‚Ä¢ 

 
 
 
 
 
 
 
 
41 

inversa, se for de um sistema referencial fotogram√©trico para outro. Nestes termos, 

pode-se dizer que o fator de escala 

, matematicamente, √© expresso por (Silva, 2020): 

ùê∏ùê∏

ùëìùëì‚Ä≤

                                                          (23) 

Objetivando  trabalhar  com 

ùê∏ùê∏ =

‚Ñé

  de  modo  percentual,  fixou-se 

  =  100.  Nestes 

termos, cabe ao usu√°rio arbitrar o valor de 

ùê∏ùê∏
percentual de amplia√ß√£o/redu√ß√£o da imagem de sa√≠da. Por exemplo, se 

ùëìùëì‚Ä≤
ent√£o as dimens√µes da imagem de sa√≠da (largura e altura) ser√£o iguais √†s da imagem 

 estabelecer√° ent√£o um 

. A escolha de 

ùëìùëì‚Ä≤

‚Ñé

, 

‚Ä≤

ùëìùëì

= ‚Ñé = 100

de entrada, considerando que nenhuma rota√ß√£o foi empreendida. E mais, se forem 

adotados valores de 

 maiores que 100, ent√£o ocorrer√° a amplia√ß√£o percentual da 

imagem de sa√≠da. Por outro lado, adotar valores de 

ùëìùëì‚Ä≤

 menores que 100 implicar√° na 

redu√ß√£o da imagem de sa√≠da. 

ùëìùëì‚Ä≤

Em  adi√ß√£o  ao  que  foi  expresso  sobre  as  altera√ß√µes  relativas  √†  escala, 

automatizou-se a determina√ß√£o de 

. Para tanto, foram considerados os valores de 

resolu√ß√£o espacial das imagens a serem processas. Ou seja, uma vez que o algoritmo 

ùëìùëì‚Ä≤

expresso  por  Al-Wassai  et  al.  (2011)  previa  que  as  imagens  multiespectrais 

deveriam ser reamostradas para as dimens√µes da imagem pancrom√°tica, ent√£o o 

par√¢metro 

 ficou: 

f‚Ä≤

Onde: 

                                                (24) 

‚Ä≤

ùëìùëì

=

ùëÖùëÖùëÖùëÖùëÄùëÄùëÄùëÄ
ùëÖùëÖùëÖùëÖùëÉùëÉùëÉùëÉùëÉùëÉ √ó 100

 √© a resolu√ß√£o espacial das imagens multiespectrais; e 

 √© a resolu√ß√£o espacial da imagem pancrom√°tica. 

‚Ä¢ 

‚Ä¢ 

ùëÖùëÖùê∏ùê∏ùëÄùëÄùëÄùëÄ
ùëÖùëÖùê∏ùê∏ùê∂ùê∂ùëÉùëÉùëÉùëÉ

A fim de materializar o expresso acima e considerando o exposto na se√ß√£o 3.1, 

pode-se dizer que, como a resolu√ß√£o espacial das imagens multiespectrais √© de 

e a resolu√ß√£o espacial da imagem pancrom√°tica √© de 

, ent√£o tem-se: 

20 ùëöùëö

5 ùëöùëö

Assim,  considerando 

‚Ä≤

ùëìùëì

=

20
,  chega-se  √†  conclus√£o  de  que  a  imagem 
5

√ó 100 = 400

multiespectral resultante do processamento passar√° a ter 4 vezes as dimens√µes da 

‚Ä≤

ùëìùëì

= 400

imagem de entrada e uma quantidade de pixels de 16 vezes a quantidade da imagem 

original. 

 
 
 
Apesar das transla√ß√µes, nas dire√ß√µes 

 e 

, estarem dispon√≠veis para altera√ß√£o 

42 

nas equa√ß√µes de colinearidade, os par√¢metros relativos √† elas n√£o foram alterados e 

ùë•ùë• 

ùë¶ùë¶

permaneceram  fixos.  Por√©m,  verificou-se  que  se  forem  efetuadas  transla√ß√µes 

planim√©tricas no sistema referencial fotogram√©trico das imagens, ent√£o poder-se-√° ter 

imagens  resultantes  transladadas  nas  dire√ß√µes 

  e/ou 

.  Por√©m,  altera√ß√µes 

algor√≠tmicas dever√£o ocorrer a fim de se abarcar o processo de transla√ß√£o. 

ùë•ùë•

ùë¶ùë¶

3.2.2  O algoritmo de fus√£o de imagens 

Apesar do car√°ter restrito do algoritmo de retifica√ß√£o de imagens, ele √© capaz 

de  correlacionar  duas  imagens  digitais  quaisquer  (imagem  original  e  imagem 

reamostrada). Considerando as altera√ß√µes descritas na subse√ß√£o 3.2.1 e o software 

que as incorpora, pode-se afirmar que a imagem reamostrada, al√©m de poder sofrer 

rota√ß√µes, pode agora tamb√©m possuir dimens√£o distinta √† da imagem de entrada. 

Cabe especificar que, no software de fus√£o de imagens constru√≠do, o algoritmo 

de retifica√ß√£o foi definido como uma fun√ß√£o destinada √† reamostragem das imagens 

multiespectrais, conforme o estabelecido por Al-Wassai et al. (2011). Ou seja, uma 

vez que a imagem pancrom√°tica √© de melhor resolu√ß√£o espacial (

), ent√£o ela 

possui  uma  quantidade  maior  de  linhas  e  de  colunas  que  as  imagens 

5 m

multiespectrais relativas √† mesma √°rea do terreno. Assim, para que o processo de 

fus√£o  de  imagens  ocorra  a  contento,  as  imagens  multiespectrais  devem  ser 

reamostradas de modo a ficarem com as mesmas quantidades de linhas e colunas 

da imagem pancrom√°tica. 

Para  fins  de  explana√ß√£o,  ser√£o  considerados  os  passos  apresentados  no 

esquema  da  Figura  16.  Os  referidos  passos  est√£o  materializados  no  software 

‚ÄúFusion‚Äù, que foi implementado em C/C++ (aplica√ß√£o console). 

‚Ä¢  Defini√ß√£o das Imagens 

Inicialmente, ao se executar o software, uma janela do prompt de comando 

do MS-DOS (Microsoft Disk Operating System) se abre e √© apresentada uma lista 

de  imagens  de  formato  PGM,  as  quais  se  encontram  no  mesmo  diret√≥rio  do 

programa.  Assim,  o  usu√°rio  pode  ter  uma  vis√£o  geral  das  possibilidades  de 

imagens  a  serem  utilizadas  para  processamento.  Cabe  esclarecer  que,  o 

 
 
 
programa n√£o foi constru√≠do com interface no padr√£o ‚ÄúFor Windows‚Äù, por se tratar 

de uma vers√£o preliminar, destinada √† pesquisa somente. 

43 

Figura 16: Etapas do algoritmo de fus√£o de imagens, materializadas no software ‚ÄúFusion‚Äù. 
Fonte: Elaborado pelo autor. 

Na Figura 17 √© apresentada a interface do Fusion, na qual se pode ver, ao 

final, a solicita√ß√£o da primeira imagem de entrada (Componente R). Ao introduzir 

o nome da componente, deve-se pressionar ‚ÄúEnter‚Äù e o programa, paulatinamente, 

solicitar√°  a  inser√ß√£o  das  demais  imagens  (Componente  G,  Componente  B  e 

imagem  pancrom√°tica).  O  programa  possui  um  temporizador  destinado  √† 

contagem  do  tempo  de  execu√ß√£o.  Al√©m  do  processamento  propriamente  dito,  o 

temporizador computa o tempo de inser√ß√£o dos nomes das imagens. 

 
 
44 

Figura 17: Interface do Fusion: Prompt de Comando de MS-DOS. 
Fonte: Elaborado pelo autor. 

‚Ä¢  Leitura das Imagens 

Ap√≥s  a  introdu√ß√£o  do  nome  e  do  formato  da  √∫ltima  imagem,  o  programa 

efetua a leitura das imagens e armazena as suas intensidades de brilho em vetores 

do  tipo 

  (inteiro  sem  sinal  no  intervalo  [0,255]).  As  dimens√µes  das 

imagens  tamb√©m  s√£o  armazenadas  e  s√£o  alocadas  em  vari√°veis  do  tipo 

unsigned char

(inteiro). 

‚Ä¢  Leitura de Par√¢metros 

int

Considerando  que  a  rotina  relativa  √†  retifica√ß√£o  modificada  incorpora  o 

programa Fusion, os par√¢metros relativos √†s rota√ß√µes, 

, permaneceram na 

implementa√ß√£o  e  s√£o  lidos  a  partir  de  arquivo  (setup.dat),  juntamente  com  os 

Œ∫, œÜ e œâ

valores das resolu√ß√µes espaciais das imagens. 

‚Ä¢  C√°lculo de 

Uma  vez  que,  as  dimens√µes  da  imagem  tenham  sido  lidas  quando  do 

f‚Ä≤

carregamento das imagens, efetua-se, de acordo com a equa√ß√£o 28, o c√°lculo do 

par√¢metro 

. 

‚Ä¢  Reamostragem das Imagens Multiespectrais 

f‚Ä≤

Considerando que as imagens multiespectrais possuem dimens√µes (largura 

e altura) menores que as das respectivas imagens pancrom√°ticas utilizadas e que 

Al-Wassai et al. (2011) preconizam a reamostragem das imagens multiespectrais, 

s√£o enviadas √† fun√ß√£o de retifica√ß√£o modificada: 

1)  Um √∫nico vetor de imagem multiespectral, a ser reamostrado; 

 
 
 
 
45 

2)  Dimens√µes da imagem multiespectral (largura e altura); 

3)  Os valores dos √¢ngulos de rota√ß√£o, 

, que, neste caso particular 

foram tomados nulos; 

Œ∫, œÜ e œâ

4)  O valor de 

, calculado anteriormente. 

Cabe  especificar  que,  a  referida  fun√ß√£o  √©  utilizada  (chamada)  tr√™s  vezes, 

f‚Ä≤

uma para cada vetor de imagem multiespectral. 

Como sa√≠da, a fun√ß√£o de retifica√ß√£o modificada retorna o vetor da imagem 

reamostrada  e  as  suas  dimens√µes.  Ao  se  analisar  e  constatar  a  corre√ß√£o  dos 

resultados  parciais,  verificou-se  que  a  rotina  efetuou  de  modo  ex√≠mio  a 

reamostragem. Assim, a amplia√ß√£o almejada ocorreu a contento. Por√©m, verificou-

se tamb√©m que, as dimens√µes da imagem pancrom√°tica excediam as dimens√µes 

da imagem reamostrada, fato que dificultaria a gera√ß√£o da imagem fusionada. 

Diante  deste  fato,  buscou-se  efetuar  novos  e  sucessivos  recortes  das 

imagens do CBERS 4 a fim de se verificar, sistematicamente, as suas dimens√µes 

e  se efetuar  c√°lculos  comparativos. Nestes  termos,  foi  poss√≠vel  constatar  que  a 

referida  inconsist√™ncia  era  proveniente  do  algoritmo  de  recortes  do  QGIS  e  que 

este efeito indesej√°vel, quando da gera√ß√£o de imagens fusionadas por meio deste 

SIG,  poderia  ser  tratado  por  meio  do  recurso  ‚Äú

‚Äù,  que  equiparava 

coerentemente as referidas dimens√µes. 

Superimpose

O  aspecto  favor√°vel  descoberto  foi  a  presen√ßa  de  uma  certa  simetria 

sistem√°tica.  Ou  seja,  como  as  imagens  eram  registradas  no  mesmo  sistema 

referencial  geod√©sico,  verificou-se  que  as  quantidades  de  linhas  e  colunas 

excedentes  da  imagem  pancrom√°tica  diziam  respeito  √†s  bordas  (ou  quadro)  da 

imagem pancrom√°tica. Assim, optou-se por descartar, simetricamente, tal quadro 

da imagem pancrom√°tica, de modo que se chegasse √† igualdade das dimens√µes 

para todas as imagens necess√°rias ao processamento (pancrom√°tica e imagens 

multiespectrais reamostradas). 

Algo digno de nota √© que, este passo, relacionado √† reamostragem, √© o que 

torna  a  pesquisa  √∫nica.  Ou  seja,  o  processo  de  reamostragem  baseado  no 

algoritmo de retifica√ß√£o de imagens digitais e, consequentemente, nas equa√ß√µes 

de colinearidade, √© algo que n√£o se encontra na literatura. 

 
 
46 

‚Ä¢  Normaliza√ß√£o das Imagens no Intervalo [0,1] 

Seguindo  o  preconizado  na  se√ß√£o  2.2,  os  valores  de  brilho  das  imagens 

reamostradas  foram,  linearmente,  normalizados  no  intervalo  [0,1].  Para  tanto, 

foram criados vetores do tipo 

 (n√∫meros reais, ou de ponto flutuante, com 

dupla  precis√£o)  que  receberam  os  valores  de  brilho  dos  vetores  reamostrados 

double

originais  e,  a  partir  destes  novos  vetores,  se  efetuou  a  normaliza√ß√£o.  Cabe 

esclarecer  que,  a  normaliza√ß√£o  foi  implementada  como  fun√ß√£o  e  foi  utilizada 

(chamada) tr√™s vezes, uma vez para cada vetor de imagem. 

‚Ä¢  Gera√ß√£o das Componentes 

 (Matiz) e 

 (Satura√ß√£o) 

Tomando  os  vetores 

H

,  cujos  tons  de  cinza  foram  normalizados  no 

S

intervalo [0,1], e utilizando-se as equa√ß√µes 2 e 3, gerou-se vetores 

double

 relativos 

√†s  componentes 

  (Matiz)  e 

  (Satura√ß√£o).  Cabe  esclarecer  que,  como  no 

double

processo  de  fus√£o  de  imagens  IHS  a  componente 

  (Intensidade)  √©  substitu√≠da 

H

S

pela imagem pancrom√°tica, n√£o foi necess√°rio gerar um vetor relativo √† 

I

‚Ä¢  Transforma√ß√£o do Sistema IHS para RGB 

. 

I

Tomando-se os vetores 

, relativos √†s componentes 

 e 

, e √† imagem 

pancrom√°tica,  utilizou-se  as  equa√ß√µes  de  4  a  12  para  se  gerar  as  novas 

double

H

S

componentes 

, 

 e 

, que compor√£o a imagem fusionada. 

‚Ä¢  Normaliza√ß√£o das Imagens 
G

R

B

, 

 e 

 para o Intervalo [0,255] 

Segundo o descrito na se√ß√£o 2.2, os vetores 

R

G

B

, 

 e 

, resultantes do passo 

anterior,  est√£o  normalizados  no  intervalo  [0,1].  Assim,  a  fim  de  que  o  resultado 

R

G

B

possa ser adequadamente visualizado a posteriori, efetua-se a normaliza√ß√£o dos 

referidos vetores no intervalo [0,255]. 

‚Ä¢  Realce Linear e Gera√ß√£o da Composi√ß√£o Colorida Fusionada 

Cabe esclarecer que, alguns trabalhos encontrados na literatura, bem como, 

os autores Gonzalez e Woods (2010), preconizam que algum pr√©-processamento 

baseado  em  histograma  pode  ser  utilizado  na  imagem  pancrom√°tica  de  modo  a 

melhorar  o  aspecto  pict√≥rico  da  imagem  fusionada.  Por√©m,  neste  trabalho  este 

tipo  de  pr√©-processamento  n√£o 

foi  utilizado.  Com 

isso,  buscou-se  um 

conhecimento  epistemol√≥gico  acerca  do  processo  de  fus√£o  em  si,  sem  que 

 
47 

nenhum processo acess√≥rio modificasse as caracter√≠sticas das imagens a priori e 

viesse a se propagar, gerando altera√ß√µes a posteriori. 

Assim,  gerou-se,  em  cada  experimento,  uma  imagem  fusionada  de  baixo 

contraste,  sem  qualquer  tipo  de  pr√©  ou  p√≥s-processamento,  e  tamb√©m  uma 

imagem  afetada  de  realce  de  contraste  linear  (p√≥s-processamento).  Tais 

resultados s√£o apresentados no cap√≠tulo que segue. 

Informa-se ainda que, as imagens, fusionada ‚Äúin natura‚Äù  e aquela  na qual 

foi aplicado o realce de contraste linear, foram ambas geradas pelo mesmo la√ßo 

,  respons√°vel  pela  composi√ß√£o  da  imagem  de  sa√≠da.  Para  tanto,  foram  feitas 

altera√ß√µes  diretamente  no  pr√≥prio  c√≥digo,  a  fim  de  que  as  imagens  fossem 
for
geradas, uma ap√≥s outra. 

‚Ä¢  Salvamento da Imagem Fusionada 

Ap√≥s  o  processamento,  o  programa  salva  automaticamente  a  imagem  de 

sa√≠da com o nome ‚ÄúFusion.raw‚Äù. Cabe explicar que, o formato da imagem da sa√≠da 

n√£o √© o mesmo daquele requerido para a imagem de entrada (PGM). Isso se deu, 

por conta de a imagem de sa√≠da ser colorida e as imagens de entrada serem em 

tons  de  cinza.  Logo,  haveria  a  necessidade  de  adequa√ß√£o  das  rotinas  de 

salvamento. Por√©m, foi priorizada a obten√ß√£o de resultados para fins de an√°lise 

de  consist√™ncia  do  algoritmo  e  da  implementa√ß√£o  propostos,  de  modo  que  se 

considerou os formatos das imagens de entrada e de sa√≠da irrelevantes. Por outro 

lado, fixou-se como marco a necessidade de que, para ambos os casos (input e 

output), as imagens fossem matriciais (raster). 

‚Ä¢  Encerramento do Programa 

Ao 

final  do  processamento,  o  programa 

indica  o 

tempo 

total  de 

processamento  e  informa  ao  usu√°rio  que  a  imagem  de  sa√≠da  foi  salva.  Para 

encerrar o processamento, basta pressionar qualquer tecla que a janela do prompt 

de comando do MS-DOS se fechar√°. 

 
 
 
 
48 

4  RESULTADOS E AN√ÅLISES  

Considerando  a  necessidade  de  se  averiguar  a  efici√™ncia  da  metodologia 

elaborada  e  executada,  foram  feitos  experimentos  e  a  posterior  an√°lise  dos 

resultados. Nestes termos, na se√ß√£o 4.1 s√£o fornecidas algumas informa√ß√µes sobre 

as imagens digitais, que s√£o a fonte de dados para os processamentos realizados. 

Al√©m disso, na se√ß√£o 4.2 s√£o apresentados os principais resultados, provenientes dos 

experimentos, com as devidas discuss√µes e as conclus√µes que se p√¥de depreender 

destas. 

4.1  Dados de Entrada 

Conforme o relatado na se√ß√£o 3.1, as imagens adquiridas s√£o provenientes do 

sat√©lite  CBERS  4.  Estas 

imagens  ortorretificadas  s√£o  georreferenciadas, 

considerando o Sistema Referencial Geod√©sico WGS84 e o sistema de proje√ß√£o UTM 

(zona 22). As imagens s√£o relativas √† regi√£o de fronteira entre os estados de Mato 

Grosso do Sul e S√£o Paulo, onde se encontra o Rio Paran√°.  

Apesar das imagens serem provenientes de um mesmo sat√©lite, o sensor de 

capta√ß√£o  das  imagens  das  bandas 

, 

  e 

  foi  a  C√¢mera  Multiespectral  Regular 

(MUX)  e  o  sensor  que  realizou  a  captura  da  imagem  pancrom√°tica  foi  a  C√¢mera 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

Pancrom√°tica Multiespectral (PAN). Os dados relativos aos sensores MUX e PAN s√£o 

disponibilizados  pelo  site  do  INPE  e  apresentados  a  seguir,  respectivamente,  nas 

Figuras 18 e 19. 

Apesar da grande √°rea abarcada pelas imagens, para fins de experimenta√ß√£o 

se efetuou dois recortes nas respectivas imagens e com estes recortes foram feitos 

os  experimentos.  No  sentido  de  posicionar  as  √°reas  de  estudo,  logo  abaixo, 

encontram-se as coordenadas referentes √†s hidrel√©tricas abarcadas em cada um dos 

recortes, considerando a ordem em que aparecem na imagem da Figura 20: 

‚Ä¢  Ao  Norte  (mais  acima  na  imagem):  Usina  Hidrel√©trica  de  Ilha  Solteira  - 

coordenadas 20.3828¬∞ S, 51.3622¬∞ W ‚Äì Munic√≠pio de Ilha Solteira ‚Äì SP. 

‚Ä¢  Ao  Sul  (mais  abaixo  na  imagem):  Usina  Hidrel√©trica  Engenheiro  Souza  Dias  - 

Coordenadas 20¬∞46'45"S, 51¬∞37'45"W ‚Äì Munic√≠pio de Tr√™s Lagoas ‚Äì MS. 

 
 
 
 
49 

Figura 18: Tabela contendo os dados e especifica√ß√µes da c√¢mera MUX, respons√°vel pela capta√ß√£o 

das bandas 

, 

 e 

. 

Fonte: Instituto Nacional De Pesquisas Espaciais 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

Figura 19: Tabela contendo os dados e especifica√ß√µes da c√¢mera PAN, respons√°vel pela capta√ß√£o 
da imagem pancrom√°tica. 
Fonte: Instituto Nacional de Pesquisas Espaciais 

Na  imagem  da  Figura  20  encontram-se  os  dois  ret√¢ngulos  que  delimitam  os 

recortes  de  imagem  inerentes  √†s  √°reas  escolhidas.  Conforme  o  especificado,  o 

ret√¢ngulo superior demarca o reservat√≥rio da Hidrel√©trica de Ilha Solteira e o ret√¢ngulo 

inferior delimita o reservat√≥rio da hidrel√©trica Engenheiro Souza Dias (Jupi√°). 

 
 
 
50 

Figura 20: Aloca√ß√£o dos reservat√≥rios hidrel√©tricos - Ret√¢ngulo Superior: Reservat√≥rio de Ilha 
Solteira; Ret√¢ngulo Inferior: Reservat√≥rio Engenheiro Souza Dias (Jupi√°). 
Fonte: Acervo do autor 

Ainda  no  sentido  de  demarcar  as  √°reas  de  estudo,  tem-se  abaixo  as 

coordenadas  relativas  aos  cantos  superior  esquerdo  e  inferior  direito  de  cada 

ret√¢ngulo que abarca os reservat√≥rios em quest√£o. Assim, tem-se: 

‚Ä¢  Usina de Ilha Solteira: 

Canto superior esquerdo: zona 22, E 454596,2444, N 7756314,6773. 

Canto inferior direito: zona 22, E 476420,7575, N 7742748,0881. 

‚Ä¢  Usina de Jupi√°: 

Canto superior esquerdo: zona 22, E 425103,6593, N 7711780,8737. 

Canto inferior direito: zona 22, E 443978,9138, N 7699099,0621. 

Cada  uma  das  imagens  multiespectrais  (

, 

  e 

)  possui  uma  resolu√ß√£o 

espacial de 

, ou seja, cada pixel da imagem recobre uma √°rea de 20 metros por 
ùëÖùëÖ

ùêµùêµ

ùê∫ùê∫

20 metros. A resolu√ß√£o espacial da imagem pancrom√°tica √© de 

20 ùëöùëö

, o que evid√™ncia 

uma riqueza de detalhes bastante superior. As composi√ß√µes coloridas e respectivas 

5 ùëöùëö

componentes podem ser vistas nas Figuras 21 e 22. 

 
 
51 

(a)                                                               (b) 

(c)                                                              (d) 

Figura 21: Usina de Ilha Solteira: (a) Composi√ß√£o colorida ‚Äì 

; (b) Componente vermelha; 

(c) Componente verde; (d) Componente azul. 
Fonte: Acervo do autor 

20 ùëöùëö

(a)                                                               (b) 

Figura 22: Usina de Jupi√°: (a) Composi√ß√£o colorida ‚Äì 

; (b) Componente vermelha; 

(c)                                                              (d) 

(c) Componente verde; (d) Componente azul. 
Fonte: Acervo do autor 

20 ùëöùëö

 
  
 
  
 
 
  
 
  
 
52 

As  imagens  da  Figura  21  e  22  possuem  uma  tonalidade  escura  devido  a 

caracter√≠sticas  do  sensor  de  capta√ß√£o.  Assim,  por  vezes  faz-se  necess√°rio  algum 

processamento relativo ao realce do contraste a fim de melhorar seu aspecto pictorial. 

A  seguir,  est√£o  expostas  as  imagens  pancrom√°ticas  (recortes)  de  alta 

resolu√ß√£o, relativas a cada regi√£o de hidrel√©trica. Para a gera√ß√£o destes recortes foi 

utilizada a banda 01 da C√¢mera Pancrom√°tica Multiespectral (PAN). 

(a) 

(b) 
Figura 23: Imagens Pancrom√°ticas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o da Usina de 
Jupi√°  
Fonte: Acervo do autor 

 
 
 
53 

4.2  Resultados Experimentais e An√°lises  

Nas subse√ß√µes que seguem s√£o apresentados os resultados da pesquisa, bem 

como, as explana√ß√µes, elucubra√ß√µes e conclus√µes expressas sobre tais resultados. 

4.2.1  Procedimentos preliminares 

Primeiramente,  foi  realizada,  via  software  QGIS,  a  composi√ß√£o  entre  as  tr√™s 

imagens  (recortes)  relativas  √†s  bandas 

, 

  e 

,  obtendo-se  as  imagens  coloridas 

com  resolu√ß√£o  espacial  de  20  metros  para  cada  uma  das  duas  regi√µes.  Tais 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

composi√ß√µes s√£o apresentadas na Figura 24. Cada imagem colorida possui a mesma 

quantidade de linhas e de colunas que cada uma das tr√™s imagens origin√°rias, mais 

especificamente, 944X634 pixels para a imagem da regi√£o de Jupi√° e 1091X678 pixels 

para a imagem que abarca a regi√£o de ilha Solteira. 

Como  as  imagens  pancrom√°ticas  possuem  dimens√µes  (largura  e  altura) 

maiores que as das imagens relativas √†s bandas 

, 

 e 

, para que se realizasse a 

fus√£o  entre  a  imagem  colorida  e  a  pancrom√°tica,  foi  necess√°rio  fazer  uma 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

reamostragem  das  imagens  multiespectrais,  de  modo  que  estas  ficassem  com  as 

mesmas  dimens√µes  das  imagens  pancrom√°ticas  e,  assim,  se  pudesse  realizar  o 

processo de fus√£o a contento. O processo de reamostragem, que est√° incorporado ao 

software  Fusion,  desenvolvido  no  √¢mbito  deste  trabalho,  implicou  na  gera√ß√£o  de 

imagens (recortes) com maior quantidade de linhas e colunas. Por√©m, como era de 

se esperar, a reamostragem das componentes n√£o implicou na melhoria da qualidade 

pictorial  das  imagens.  Cabe  especificar  ainda  que,  a  dimens√£o  da  imagem 

pancrom√°tica  relativa  √†  regi√£o  de  Ilha  Solteira  √©  de  4361X2709,  ao  passo  que  a 

pancrom√°tica  da  regi√£o  de  Jupi√°  apresenta  dimens√£o  de  3773X2533.  As  imagens 

coloridas simplesmente reamostradas s√£o apresentadas na Figura 25. 

 
 
 
 
 
54 

(a) 

(b) 

Figura 24: Composi√ß√µes coloridas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o da Usina de 
Jupi√°. 
Fonte: Acervo do autor 

 
 
 
55 

Figura 25: Imagens coloridas reamostradas relativas √†s regi√µes de Ilha Solteira (√† esquerda) e de 
Jupi√° (√† direita). 
Fonte: Acervo do autor  

Como a tonalidade das imagens resultantes do processo de reamostragem se 

mostrou escura, visto que n√£o se submeteu as componentes a pr√©-processamento, 

foi realizado, via software IrfanView, um realce de contraste de cores, de modo que, 

se  melhorasse  a  qualidade  visual  das  imagens.  Os  resultados  s√£o  apresentados  a 

seguir. 

Figura 26: Imagens coloridas reamostradas com realce, relativas √†s regi√µes de Ilha Solteira (√† 
esquerda) e de Jupi√° (√† direita). 
Fonte: Acervo do autor  

√â  importante  frisar  que,  apesar  do  aumento  da  resolu√ß√£o  em  pixels  das 

imagens coloridas no processo de reamostragem e do realce de contraste efetuado 

via IrfanView, a qualidade pictorial da imagem se manteve baixa, o que implica em 

uma aus√™ncia de melhora na qualidade quando a simples reamostragem √© efetuada. 

4.2.2  A fus√£o das imagens 

Tendo  j√°  dispon√≠veis  a  imagem  pancrom√°tica  de  alta  resolu√ß√£o  e  a  imagem 

colorida reamostrada de cada regi√£o (recortes), reuniu-se as condi√ß√µes necess√°rias 

para  a  fus√£o  de  imagens.  O  procedimento  se  baseou  no  m√©todo  IHS,  no  qual  se 

 
  
 
   
 
 
 
substitui a componente "Intensidade" da imagem colorida pela imagem pancrom√°tica, 

conforme explicado na se√ß√£o 2.5. Na figura a seguir s√£o mostrados os resultados dos 

experimentos. 

56 

(a) 

(b) 
Figura 27: Imagens fusionadas: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o da Usina de Jupi√°. 
Fonte: Acervo do autor 

 
 
 
57 

Como se pode notar, novamente a tonalidade das imagens se mostrou escura, 

sendo necess√°rio a aplica√ß√£o de um processo de realce de contraste. Tal processo 

foi  realizado  por  dois  caminhos  distintos.  Primeiramente  foi  realizado  um  realce  de 

contraste linear, incorporado ao c√≥digo do pr√≥prio programa Fusion, e se obteve uma 

boa melhora no aspecto visual das imagens. Seguem os resultados na Figura 28. 

Figura 28: Imagens fusionadas resultantes do experimento, com realce  de contraste linear, relativas 
√†s regi√µes de Ilha Solteira (√† esquerda) e de Jupi√° (√† direita). 
Fonte: Acervo do autor 

Pode-se  verificar  que,  nos  resultados  apresentados  nas  Figuras  27,  28  e  29 

que,  apesar  das  discrep√¢ncias  relativas  ao  contraste,  a  geometria  das  imagens 

fusionadas  se  mostrou  superior  √†  das 

imagens  que 

foram  simplesmente 

reamostradas.  Segundo  Gonzalez  e  Woods  (2010)  o  acr√©scimo  na  qualidade 

geom√©trica e na nitidez da imagem √© proveniente da substitui√ß√£o da componente 

pelos n√≠veis de brilho provenientes da imagem pancrom√°tica. Em adi√ß√£o a isso, pode-
ùêºùêº
se  concluir  que  o  software  Fusion  foi  eficaz  em  gerar  imagens  fusionadas  de  alta 

qualidade, a menos do contraste final. Por√©m, como fora dito anteriormente, em um 

primeiro  momento  se  buscou  efetuar  mudan√ßas  no  algoritmo  de  retifica√ß√£o  de 

imagens  digitais  e  nas  equa√ß√µes  de  colinearidade,  de  modo  que,  estes  elementos 

fossem  agregados  ao  m√©todo  de  fus√£o  IHS  de  imagens.  Assim,  partindo-se  do 

pressuposto de que qualquer pr√©-processamento poderia falsear os resultados, optou-

se por se processar dados ‚Äúin natura‚Äù. 

Para  fins  de  compara√ß√£o,  foi  realizado  o  processo  de  realce  autom√°tico  das 

imagens  fusionadas  no  software  IrfanView  (ver  Figura  29).  Decorre  de  tal 

processamento  uma  melhora  do  aspecto  visual  das  imagens.  Deste  modo,  essas 

imagens s√£o consideradas o produto final do experimento e expressam um resultado 

bastante satisfat√≥rio. 

 
   
 
 
58 

(a) 

(b) 
Figura 29: Imagem fusionada real√ßada: (a) Regi√£o da Usina de Ilha Solteira; (b) Regi√£o da Usina de 
Jupi√°. 
Fonte: Acervo do autor  

Cabe ressaltar que, devido √† aus√™ncia de pr√©-processamento baseado em 

histograma, indicado para a imagem pancrom√°tica (GONZALEZ e WOODS, 2010), as 

 
 
 
59 

cores  passaram  a  ter  alguma  discrep√¢ncia  com  rela√ß√£o,  por  exemplo,  √†s  imagens 

simplesmente reamostradas. No entanto, este resultado se assemelha sobremaneira 

com o obtido em outros trabalhos an√°logos e que usaram softwares comerciais, como 

√© o caso de Pisani et al. (2019) e Oliveira (2018). Assim, pode-se dizer que se chegou 

a resultados totalmente pass√≠veis de serem utilizados no √¢mbito das Geoci√™ncias. 

(a)                                                                              (b) 
Figura 30: Compara√ß√£o de detalhes (regi√£o de Ilha Solteira): (a) Imagem colorida inicial; 
(b) Imagem fusionada 
Fonte: Acervo do autor 

(a)                                                                              (b) 
Figura 31: Compara√ß√£o de detalhes (regi√£o de Jupi√°): (a) Imagem colorida inicial; 
(b) Imagem fusionada 
Fonte: Acervo do autor 

 
 
 
60 

Para uma melhor compreens√£o acerca dos resultados obtidos, as Figuras 30 e 

31 trazem em destaque detalhes com √™nfase na malha urbana, visto que este tipo de 

√°rea apresenta riqueza de detalhes radiom√©tricos e geom√©tricos que podem auxiliar 

na compara√ß√£o visual do grau de qualidade das imagens. A compara√ß√£o se d√° entre 

a  imagem  gerada  inicialmente  pela  simples  composi√ß√£o  das  bandas 

, 

  e 

,  e  a 

imagem final fusionada, resultante do experimento. 

ùëÖùëÖ

ùê∫ùê∫

ùêµùêµ

Analisando  comparativamente  as 

regi√µes  hom√≥logas,  presentes  na 

composi√ß√£o  colorida  inicial,  de  baixa  resolu√ß√£o  espacial,  e  na  imagem  fusionada, 

pode-se verificar que, tanto no par de imagens apresentadas na Figura 30, quanto no 

par de imagens presentes na Figura 31, a nitidez e a qualidade geom√©trica da imagem 

fusionada  s√£o  bastante  superiores.  Ou  seja,  como  se  pode  notar,  para  ambas  as 

regi√µes, houve uma diferen√ßa significativa na qualidade dos detalhes mostrados em 

cada imagem, com a melhora na resolu√ß√£o espacial, que passou de 20 metros para 5 

metros.  

Destas  observa√ß√µes,  conclui-se  que,  com    rela√ß√£o  √†s  imagens  fusionadas 

resultantes,  houve  um  ganho  em  qualidade  geom√©trica,  visto  que  os  contornos  se 

apresentam  bem  definidos,  e  radiom√©trica,  considerando  que  as  cores  propiciam  a 

identifica√ß√£o precisa dos alvos. Sendo assim, pode-se depreender que o objetivo do 

trabalho  foi  alcan√ßado,  uma  vez  que,  as  altera√ß√µes  e  modifica√ß√µes  empreendidas 

propiciaram a gera√ß√£o de resultados satisfat√≥rios. 

 
 
 
61 

5  CONCLUS√ïES E RECOMENDA√á√ïES: 

A  seguir,  s√£o  feitas  considera√ß√µes  acerca  da  pesquisa  realizada  e  dos 

experimentos  efetuados,  com  √™nfase  nos  resultados  e  nas  conclus√µes  alcan√ßadas. 

Tamb√©m  s√£o  feitas  algumas  recomenda√ß√µes  no  sentido  de  contribuir  para  com  os 

poss√≠veis  trabalhos  relacionados  ao  software  desenvolvido,  objetivando  o  seu 

aproveitamento na constru√ß√£o de futuros trabalhos acad√™micos. 

5.1  Conclus√µes 

A pesquisa envolveu conceitos matem√°ticos aliados √†s no√ß√µes das √°reas de 

Geod√©sia,  Fotogrametria,  Sensoriamento  Remoto  e  Inform√°tica.  Ela  consistiu  no 

estudo e posteriores altera√ß√µes do algoritmo de retifica√ß√£o de imagens digitais, bem 

como, das equa√ß√µes de colinearidade, com vistas √† constru√ß√£o de um novo software 

capaz de  efetuar a fus√£o  de imagens via m√©todo IHS. O software, implementado 

em  um  contexto  experimental  acad√™mico,  apresentou 

resultados  bastante 

satisfat√≥rios. 

Assim,  da  execu√ß√£o  da  pesquisa,  p√¥de-se  tirar  algumas  conclus√µes  √∫teis  e 

robustas. Primeiramente, ficou evidente que as altera√ß√µes efetuadas nas equa√ß√µes 

de colinearidade foram condizentes e geraram os resultados satisfat√≥rios esperados, 

e, deste modo, as altera√ß√µes algor√≠tmicas relacionadas ao algoritmo de retifica√ß√£o de 

imagens  digitais  foram  efetivas  em  gerar  as  imagens  multiespectrais  reamostradas 

necess√°rias √† fus√£o de imagem via m√©todo IHS. Al√©m disso, o descarte do quadro da 

imagem  pancrom√°tica,  que  objetivava  parear  as  dimens√µes  desta  imagem  com  as 

dimens√µes relativas √†s imagens multiespectrais, funcionou a contento. Vale ressaltar 

tamb√©m  que  a  implementa√ß√£o  do  software  Fusion  gerou  os  resultados  esperados, 

sendo que da an√°lise visual depreende-se a boa qualidade destes resultados, os quais 

est√£o  em  acordo  com  trabalhos  de  mesmo  cerne.  As  manipula√ß√µes  e  dispositivos 

digitais  utilizados  atuaram  dentro  do  previsto.  Por  fim,  ressalta-se  que  o  software 

QGIS foi de grande valia ao processo de fus√£o de imagens, pois foi eficaz no registro 

das imagens e na gera√ß√£o de recortes. 

Pelas  conclus√µes  expostas  acima,  conclui-se  que  houve  um  ganho  cient√≠fico 

relacionado aos resultados obtidos e ao produto de software gerado. Por√©m, o ganho 

maior ficou por conta do know-how adquirido pela equipe executora do projeto. 

 
 
 
 
62 

5.2  Recomenda√ß√µes 

Entende-se que o produto de software, obtido como resultado deste trabalho, 

poder√° ser utilizado futuramente em outros trabalhos cujas tem√°ticas se assemelhem 

√†quela trabalhada no √¢mbito da pesquisa aqui descrita. E mais, entende-se que os 

resultados  alcan√ßados  (imagens  fusionadas)  s√£o  pass√≠veis  de  serem  utilizados  em 

aplica√ß√µes de geoprocessamento. 

Al√©m  disso,  o  software  aqui  implementado  pode  ser  tamb√©m  utilizado  no 

ambiente  universit√°rio  ou  em  ambientes  educacionais  de  modo  geral,  como 

ferramenta  did√°tica  no  aprendizado  de  disciplinas  relacionadas  ao  Sensoriamento 

Remoto e √† Geografia, al√©m da pr√≥pria Matem√°tica, servido de exemplo de aplica√ß√£o 

pr√°tica de conceitos matem√°ticos. 

Buscando  aprimorar  o  produto  cient√≠fico  e  tecnol√≥gico  gerado,  apresenta-se 

algumas  recomenda√ß√µes  para  trabalhos  futuros.  Entre  elas,  sugere-se  efetuar  a 

compara√ß√£o estat√≠stica dos resultados gerados pelo Fusion com resultados gerados 

por outros softwares como, por exemplo, o QGIS. √â interessante tamb√©m que seja 

considerada  possibilidade  de  se  introduzir,  no  software  obtido  neste  trabalho,  as 

potencialidades relativas √† manipula√ß√£o de sistemas referenciais geod√©sicos, a fim de 

que o registro das imagens possa se tornar um processo interno a ele. Al√©m disso, ao 

Fusion,  √©  poss√≠vel  acrescentar  m√©todos  eficazes  de  realce  de  contraste,  al√©m  de 

acrescentar  e  automatizar  o  pr√©-processamento  baseado  em  histograma,  relativo  √† 

imagem pancrom√°tica, preconizado por Gonzalez e Woods (2010). Em adi√ß√£o a isso, 

√©  vi√°vel  e  desej√°vel  efetuar  a  substitui√ß√£o  da  interpola√ß√£o  bilinear,  presente  no 

software  Fusion,  por  algum  outro  m√©todo  de  interpola√ß√£o,  buscando  obter, 

possivelmente, um resultado distinto ou talvez melhor do que o j√° alcan√ßado. Por fim, 

entende-se ser interessante a recomenda√ß√£o de se implementar para o Fusion uma 

interface amig√°vel (‚ÄúFor Windows‚Äù), a fim de tornar a sua utiliza√ß√£o mais agrad√°vel e 

intuitiva aos poss√≠veis usu√°rios. 

Por  fim,  conclui-se  que  este  trabalho  tenha  gerado  resultados  cient√≠ficos 

relevantes e uma ferramenta √∫til ao ambiente acad√™mico e a quem dela quiser fazer 

uso. 

 
 
 
 
63 

REFER√äNCIAS BIBLIOGR√ÅFICAS 

AL-WASSAI, F.A.; KALYANKAR, N.V.; AL-ZUKY, A.A. The IHS transformations-
based image fusion. J. Glob. Res. Comp. Sci., 2 (5), 2011. 

ANDRADE, J. B.; Fotogrametria. Curitiba: SBEE, 1998. 

CERQUEIRA,  Jorge  Dirceu  Melo  de.  Ortorretifica√ß√£o  Digital  de  Imagens  de 
Sat√©lites  de  Alta  Resolu√ß√£o  Espacial.  Recife,  2004.  Disserta√ß√£o  (Mestrado)  ‚Äì 
Centro de Tecnologia e Geoci√™ncias, Universidade Federal de Pernambuco. 

CHAVEZ, P. S. Jr.; BOWELL, J.A.. Comparison of spectral information content 
of  Landsat  thematic  mapper  and  SPOT  for  three  different  sites  in  Phoenix. 
Photogrammetric Enginnering and Remote Sensing, 54(12):1699-1708. 1988. 

CR√ìSTA,  Alvaro  Penteado.  Processamento  digital  de 
sensoriamento remoto. Ed. rev. Campinas, SP: IG/UNICAMP, 1992. 

imagens  de 

GASPAR, Alberto. Compreendendo a f√≠sica - Ondas, √≥ptica e Termodin√¢mica. 
Manual do professor, Ensino M√©dio. 3. ed. S√£o Paulo: √Åtica, 2016. 

GOMES,  Herman  M.;  QUEIROZ,  Jos√©  Eust√°quio  R. 
Introdu√ß√£o  ao 
Processamento Digital de Imagens. Universidade Federal de Campina Grande. 
em: 
e 
Departamento 
<http://www.dsc.ufcg.edu.br/~hmg/disciplinas/graduacao/vc-2016.2/Rita-Tutorial-
PDI.pdf>, acesso em 29 mar. 2021. 

Computa√ß√£o. 

Dispon√≠vel 

Sistemas 

de 

GONZALEZ,  Rafael  C.;  WOODS,  Richard  C..  Processamento  digital  de 
imagens. 3. ed. S√£o Paulo : Pearson Prentice Hall, 2010. 

INSTITUTO  NACIONAL  DE  PESQUISAS  ESPACIAIS.  C√¢meras  Imageadoras 
CBERS-3  e  4.  Dispon√≠vel  em:  <http://www.cbers.inpe.br/sobre/cameras/cbers3-
4.php>, acesso em 12 ago. 2021. 

INSTITUTO  NACIONAL  DE  PESQUISAS  ESPACIAIS.  Fus√£o  de  Imagens  do 
Sat√©lite  CBERS-2B  no  SPRING.  Por  La√©rcio  M.  Namikawa.  Dispon√≠vel  em:  
<http://wiki.dpi.inpe.br/doku.php?id=fusaohrcccdcbers2b:exemplo>, acesso em 28 
mai. 2021. 

LEONARDI,  Silvia  Shizue;  ORTIZ,  Jussara  de  Oliveira;  FONSECA,  Leila  Maria 
Garcia.  Compara√ß√£o  de  t√©cnicas  de  fus√£o  de  imagens  para  diferentes 
sensores  orbitais.  Anais  XII  Simp√≥sio  Brasileiro  de  Sensoriamento  Remoto, 
Goi√¢nia, Brasil, 16-21 abril 2005, INPE, p. 4111-4113. 2005. 

MARQUES  FILHO,  Og√™;  VIEIRA  NETO,  Hugo.  Processamento  Digital  de 
Imagens. Rio de Janeiro: Brasport, 1999. 

MENESES,  P.R.,  ALMEIDA,  T.,  Introdu√ß√£o  ao  Processamento  de  Imagens  de 
Sensoriamento Remoto. 3. ed., Bras√≠lia-DF, 2012. 

 
 
64 

OLIVEIRA,  Claudianne  Brainer  De  Souza.  An√°lise  da  integra√ß√£o  espacial  de 
m√∫ltiplos  sensores.  Disserta√ß√£o  de  Mestrado.  Programa  de  P√≥s-Gradua√ß√£o  em 
Ci√™ncias. 2018. 

PISANI,  Rodrigo,  BUENO,  Viviane,  FIUZA,  Joice,  ESTELA,  Paulo.  (2019). 
AVALIA√á√ÉO DE T√âCNICAS DE FUS√ÉO DE IMAGENS ORBITAIS UTILIZANDO 
PRODUTOS  DO  SAT√âLITE  CBERS  4  PARA  A  APA  DO  RIO  MACHADO-MG. 
Caderno de Geografia. 29. 58-71. 10.5752/p.2318-2962.2019v29nespp58. 

SILVA, E. G. Estudo das transforma√ß√µes planas: uma aplica√ß√£o baseada nas 
equa√ß√µes  de  colinearidade.  2020.  Disserta√ß√£o  (Mestrado  Profissional  em 
Matem√°tica  ‚Äì  Profmat).  UNEMAT  -  Universidade  do  Estado  de  Mato  Grosso. 
Sinop-MT. 

UNIVERSIDADE  FEDERAL  DE  VI√áOSA.  Fotogrametria  digital.  Departamento  de 
Solos.  Dispon√≠vel  em:  <https://pt.slideshare.net/guest72086/fotogrametria-digital>, 
acesso em 29 abr. 2021. 

VENTURA,  F.  N.  Fus√£o  de  imagens  de  sensores  remotos  utilizando  a 
transformada de wavelet. 2002-08-12. (INPE -TDI/). Disserta√ß√£o (Mestrado em 
Computa√ß√£o Aplicada) - Instituto Nacional de Pesquisas Espaciais, S√£o Jos√© dos 
Campos. 2002. 

WOLF,  P.;  DEWITT,  B.  Elements  of  photogrammetry  ‚Äì  with  applications  in 
GIS. 3.ed. United States of America: Mc Graw Hill, 2000. 

 
 

Universidade Federal do Triˆangulo Mineiro - UFTM

Mestrado Profissional em Matem´atica em Rede Nacional - PROFMAT

Dissertac¸˜ao de Mestrado

Classificac¸˜ao de estudantes atrav´es de ´arvores de
decis˜ao via Python e RapidMiner

Natalia Gonc¸alves Caetano

Uberaba - Minas Gerais
Julho de 2016

Classificac¸˜ao de estudantes atrav´es de ´arvores de
decis˜ao via Python e RapidMiner

Natalia Gonc¸alves Caetano

Disserta¸c˜ao de Mestrado apresentada `a Comiss˜ao

Acadˆemica Institucional do PROFMAT-UFTM

como requisito parcial para obten¸c˜ao do t´ıtulo de

Mestre em Matem´atica.

Orientador: Prof. Dr. Leandro Cruvinel Lemes.

Uberaba - Minas Gerais

Julho de 2016

                    Catalogação na fonte: Biblioteca da Universidade Federal do Triângulo Mineiro                      Caetano, Natalia Gonçalves  C131c            Classificação de estudantes através de árvores de decisão via Python e       RapidMiner  / Natalia Gonçalves Caetano. -- 2016.       71 f. : il., fig., graf., tab.   Dissertação (Mestrado Profissional em Matemática em Rede Nacional)                    -- Universidade Federal do Triângulo Mineiro, Uberaba, MG, 2016           Orientador: Prof. Dr. Leandro Cruvinel Lemes                                    1. Árvores (Teoria dos grafos). 2. Mineração de dados (Computação). 3.       Pesquisa educacional. 4. Estudantes - Avaliação. 5. Python (Linguagem de       programação de computador). 6.  RapidMiner (Programa de computador).  I.       Lemes, Leandro Cruvinel. II. Universidade Federal do Triângulo Mineiro. III.     Título.                                                                                                                                                                                                                               CDU 519.172.1 `A Deus, porque ele ´e bom.
Ao meu marido, para que o nosso futuro seja pr´ospero.

Agradecimentos

Agrade¸co a Deus, por atender aos meus desejos, por me aben¸coar e por estar

comigo em todos os momentos da minha vida.

Agrade¸co `a Universidade Federal do Triˆangulo Mineiro pela oportunidade de con-

tinuar meus estudos.

Agrade¸co ao J´unior, meu marido, pelo amor, apoio, compreens˜ao, paciˆencia e

dedica¸c˜ao durante esse tempo dif´ıcil. Ele, que tamb´em ´e meu colega de proﬁss˜ao, dedicou

muito do seu tempo a me ajudar em todas as etapas desse mestrado.

Agrade¸co `a minha m˜ae pela bondade, dedica¸c˜ao, por fazer da minha vida a raz˜ao

da dela e por me amar tanto.

Agrade¸co a todos os meus professores pelos ensinamentos, principalmente ao meu

orientador Leandro por destinar seu tempo `a minha pesquisa.

Agrade¸co aos meus colegas de classe pelo tempo de estudo e de descontra¸c˜ao, princi-

palmente aos meus companheiros Robson e Max, pelas conversas e risadas compartilhadas

durante todo esse tempo.

Agrade¸co aos meus amigos, especialmente, Larissa e Geanne, pelo apoio e por

ouvirem meus desabafos em momentos t˜ao dif´ıceis. Agrade¸co tamb´em e, principalmente,

ao Henderson, por empenhar seu tempo em me ajudar com as imagens desta pequisa.

Agrade¸co `a Escola Estadual Professor Jos´e In´acio de Souza por compreender este

momemto ´ımpar em minha vida, especialmente `a minha amiga Alessandra, n˜ao s´o pelo

apoio nos trabalhos compartilhados, mas tamb´em pelas palavras de incentivo durante

todo esse processo.

Agrade¸co a todos que, de alguma forma, contribu´ıram para que este estudo fosse

conclu´ıdo.

”Mas em todas estas coisas somos

mais que vencedores, por meio daquele

que nos amou”.

Romanos 8:37

Resumo

Minera¸c˜ao de dados educacionais ´e uma ´area de pesquisa que utiliza ferramentas

de minera¸c˜ao de dados para interpretar dados nos contextos educacionais. Neste trabalho,

utiliza-se a minera¸c˜ao de dados para classiﬁcar alunos de acordo com o n´ıvel de conhe-

cimento com base em notas e atividades anteriores. No estudo, usa-se dados reais para

contru¸c˜ao de modelos atr´aves do algoritmo de ´arvore de decis˜ao com o objetivo de avaliar

regras de classiﬁca¸c˜ao para interven¸c˜oes did´aticas e pedag´ogicas. A partir dos modelos

criados, extraiu-se informa¸c˜oes relevantes para previs˜ao de resultados ﬁnais e identiﬁca¸c˜ao

de pontos importantes no desenvolvimento do plano de ensino e aprendizagem dos alunos.
Palavras-chave: Minera¸c˜ao de dados, ´Arvore de decis˜ao, Classiﬁca¸c˜ao, Python, Rapid-
miner.

Abstract

Educational data mining - EDM is a research ﬁeld concerned with data mining

tools for data analisys over educational datasets. The purpose at this work is to use

data mining to classify students according to their knowledge level based in their past

grades and activities. We use real data to construct decision tree models with purpose of

test classiﬁcation rules for didactic and pedagogical interventions. Considering the created

models, relevant information for student’s ﬁnal result predictions and for important points

on teaching and learning process development identiﬁcations was obtained.

Keywords: Data mining, Decision Tree, Classiﬁcation, Python, Rapidminer.

Sum´ario

INTRODUC¸ ˜AO

1 TRABALHOS RELACIONADOS

1.1 Trabalhos Internacionais . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Trabalhos Nacionais

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 ´ARVORES DE DECIS ˜AO COM RAPIDMINER

1

5

5

7

10

2.1 Entendendo o Rapidminer . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.1.1 Terminologia do Rapidminer . . . . . . . . . . . . . . . . . . . . . . 10

2.1.2 Adicionando conjuntos de dados ao reposit´orio . . . . . . . . . . . . 11

2.1.3 Construindo processos

. . . . . . . . . . . . . . . . . . . . . . . . . 13

2.1.4 Transformando o conjunto de dados . . . . . . . . . . . . . . . . . . 14

2.1.5 Processo de modelagem . . . . . . . . . . . . . . . . . . . . . . . . 15

2.1.6 Validando modelos . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

2.1.7 Visualizando resultados . . . . . . . . . . . . . . . . . . . . . . . . . 19

2.1.8 Aplicando o modelo . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.1.9 Criando um operador personalizado . . . . . . . . . . . . . . . . . . 24
´Arvores de decis˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

2.2

3 APLICAC¸ ˜OES E RESULTADOS

30

3.1 Atributos irrelevantes e alta accuracy . . . . . . . . . . . . . . . . . . . . . 30

3.2

Informa¸c˜oes ´uteis e baixa accuracy

. . . . . . . . . . . . . . . . . . . . . . 38

4 CONSIDERAC¸ ˜OES FINAIS

REFERˆENCIAS BIBLIOGR ´AFICAS

APˆENDICES

A Tabelas de aplica¸c˜ao

48

49

52

53

B Classiﬁca¸c˜ao de novos estudantes via Python

xi

58

Lista de Figuras

1

Processo de Descoberta do Conhecimento em Bancos de Dados . . . . . . .

2

2.1 Adi¸c˜ao de “users” no reposit´orio . . . . . . . . . . . . . . . . . . . . . . . . 13

2.2 Processo de visualiza¸c˜ao de “users” . . . . . . . . . . . . . . . . . . . . . . 13

2.3 Processo de ﬁltragem em “users” . . . . . . . . . . . . . . . . . . . . . . . 14

2.4 Resultado do processo de ﬁltragem em “users” . . . . . . . . . . . . . . . . 15

2.5 Decision Tree aplicado ao conjunto “users” . . . . . . . . . . . . . . . . . . 15

2.6 Grafo resultante da aplica¸c˜ao de Decision Tree em “users” . . . . . . . . . 16

2.7 Valida¸c˜ao de modelo de classiﬁca¸c˜ao de tripulantes do Titanic . . . . . . . 17

2.8 Processos internos do operador X-Validation . . . . . . . . . . . . . . . . . 18

2.9 Resultado da aplica¸c˜ao de Decision Tree no conjunto “Titanic”

. . . . . . 19

2.10 Grafo da ´arvore de decis˜ao relacionada ao conjunto “Titanic” . . . . . . . . 20

2.11 Processo de aplica¸c˜ao de Decision Tree ao conjunto “Exemplo1” . . . . . . 22

2.12 Resultado da aplica¸c˜ao de Decision Tree no conjunto “Exemplo1” . . . . . 24

2.13 Processo com o operador Execute Python . . . . . . . . . . . . . . . . . . . 25

2.14 Resultado do processo com o operadorExecute Python . . . . . . . . . . . . 27

2.15 Parˆametros do operador Decision Tree . . . . . . . . . . . . . . . . . . . . 28

3.1 Grafo com maior accuracy (Student Performance Data Set)

. . . . . . . . 35

3.2 Grafo com maior accuracy (Class grades) . . . . . . . . . . . . . . . . . . . 41

3.3 Grafo com maior accuracy (Class grades com reclassiﬁca¸c˜ao) . . . . . . . . 45

3.4 Maior accuracy (Class grades com reclassiﬁca¸c˜ao e profundidade menor)

. 46

Lista de Tabelas

2.1 Portas no Rapidminer

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3.1 Comparativo entre parˆametros no conjunto de dados Student Performance

Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

3.2 Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

3.3 Resultado da valida¸c˜ao do modelo aplicado ao conjunto de dados Student

Performance Data Set

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

3.4 Comparativo entre parˆametros no conjunto de dados Class grades . . . . . 40

3.5 Resultado da aplica¸c˜ao do modelo com maior accuracy no conjunto Class

grades

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

3.6 Resultado da valida¸c˜ao do modelo aplicado ao conjunto de dados Class

grades

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

3.7 Resultado da valida¸c˜ao do modelo aplicado ao conjunto Class grades com

uma reclassiﬁca¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

A.1 Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

Data Set - parte 1

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

A.2 Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

Data Set - parte 2

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

A.3 Resultado da aplica¸c˜ao do Decision Tree no conjunto de dados Class grades

- parte 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

A.4 Resultado da aplica¸c˜ao do Decision Tree no conjunto de dados Class grades

- parte 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

INTRODUC¸ ˜AO

Atualmente, grandes volumes de dados s˜ao gerados e armazenados diariamente

pelos sistemas e transform´a-los em conhecimentos ´uteis ´e um desaﬁo. Para atender essa

necessidade, pode-se utilizar o KDD (Knowledge Discovery in Databases). Essa express˜ao

foi formalizada em 1989 em referˆencia ao conceito de procurar conhecimento a partir de

bancos de dados. Segundo Fayyad et al. (1996), KDD ´e um processo de v´arias etapas, n˜ao

trivial, para identiﬁca¸c˜ao de padr˜oes compreens´ıveis, v´alidos, novos e potencialmente ´uteis

a partir de grandes conjuntos de dados. O processo KDD ´e n˜ao trivial, pois a complexi-

dade presente na sua execu¸c˜ao n˜ao ´e um processo de computa¸c˜ao direta. J´a a express˜ao

“padr˜oes v´alidos” indica que o conhecimento deve ser verdadeiro e adequado ao contexto, e

o termo “padr˜ao novo” indica que se deve acrescentar novos conhecimentos aos existentes,

trazendo algum benef´ıcio, de acordo com Goldschmidt and Passos (2005). Para realizar o

processo de KDD, s˜ao necess´arias algumas fases como sele¸c˜ao, pr´e-processamento, trans-

forma¸c˜ao, minera¸c˜ao de dados e an´alise, coforme dito por Fayyad et al. (1996).

A fase de sele¸c˜ao de dados ´e a primeira no processo de descoberta de informa¸c˜ao,

e ´e onde dados relevantes s˜ao selecionados para a an´alise. Possui impacto signiﬁcativo

sobre a qualidade do resultado ﬁnal, uma vez que nessa fase ´e escolhido o conjunto de

dados contendo todas os poss´ıveis atributos.

O pr´e-processamento ´e importante no processo de KDD. O intuito dessa etapa ´e re-

mover dados irrelevantes, recuperar dados incompletos e avaliar poss´ıveis dados diferentes

do conjunto.

Na fase de transforma¸c˜ao, os dados preprocessados ser˜ao preparados e transforma-

dos para um formato adequado ao algoritmo de minera¸c˜ao.

A minera¸c˜ao de dados ´e uma etapa onde um m´etodo e um algoritmo s˜ao selecio-

nados e aplicados com o objetivo de identiﬁcar os padr˜oes nos dados transformados.

Na an´alise, o conhecimento obtido ´e avaliado para que as decis˜oes sejam tomadas

da melhor maneira poss´ıvel ou documentada para grupos interessados.

Na Figura 1, ´e poss´ıvel observar as fases para que os dados se transformem em

informa¸c˜ao.

Figura 1: Processo de Descoberta do Conhecimento em Bancos de Dados

2

Embora seja ideal que as etapas sejam executadas na ordem apresentada, o pro-

cesso pode ser repetido v´arias vezes, e o resultado de cada uma depende dos resultados

das anteriores. Segundo Boente et al. (2008), como os processos para descobrir conheci-

mento em bancos de dados s˜ao elaborados, deve-se planejar o processo desde o in´ıcio e

estabelecer os objetivos de acordo com a aplica¸c˜ao do KDD. O processo de KDD pode

ser aplicado em diversas ´areas, incluindo marketing, ﬁnan¸cas, detec¸c˜ao de fraudes, manu-

faturas, telecomunica¸c˜oes, educa¸c˜ao e outros.

A etapa data mining, express˜ao inglesa que surgiu na d´ecada de 90 e tamb´em

conhecida como minera¸c˜ao de dados, ´e muito importante no processo de KDD. Ela ´e

respons´avel pela busca de conhecimento v´alido dos dados, e sua funcionalidade ´e organizar

dados, buscando padr˜oes ou discrepˆancias relevantes. A minera¸c˜ao de dados pode ser uma

importante ferramenta que potencializa a inova¸c˜ao e a lucratividade no setor empresarial.

Sua utiliza¸c˜ao pode ser feita em grandes bancos de dados, e as informa¸c˜oes podem ser

exibidas atrav´es de clusterings, nuvem de tags, ´arvores de decis˜ao e outros. Segundo

Witten et al. (1999), o uso de banco de dados em atividades cotidianas traz a minera¸c˜ao

de dados para a vanguarda das novas tecnologias empresariais.

Para alguns autores como Fayyad et al. (1996), o KDD e a minera¸c˜ao de dados

s˜ao processos distintos, mas para outros, como Han et al. (2011), o termo minera¸c˜ao de

dados tornou-se mais popular para grandes quantidades de dados armazenados em bancos

de dados ou outro tipo de banco de armazenamento. Segundo Berry and Linoﬀ (1997),

minera¸c˜ao de dados ´e a explora¸c˜ao e an´alise, de forma autom´atica ou semiautom´atica, de

grandes bases de dados com objetivo de descobrir padr˜oes. Para Cabena et al. (1998),

minera¸c˜ao de dados ´e uma ´area interdisciplinar que mobiliza conhecimentos de an´alise

estat´ıstica de dados, aprendizagem de m´aquina, reconhecimento de padr˜oes e visualiza¸c˜ao

de dados. De acordo com Prass et al. (2012), a minera¸c˜ao de dados traz uma s´erie de

ideias e t´ecnicas em diversas ´areas. Estat´ısticos, pesquisadores de Inteligˆencia Artiﬁcial

e administradores de bancos de dados usam t´ecnicas diferentes para interpretar e avaliar

os resultados obtidos com a minera¸c˜ao para, no ﬁnal, chegar `a informa¸c˜ao. Atualmente,

encontram-se dispon´ıveis v´arias ferramentas de minera¸c˜ao de dados que ajudam analistas

a classiﬁcar dados, formular hip´oteses, realizar diagn´osticos, prever interesses dos clientes

3

e descobrir perﬁs de comportamento. Todas essas possibilidades tamb´em s˜ao utilizadas

na ´area da educa¸c˜ao.

A Minera¸c˜ao de Dados Educacionais (do inglˆes, Educational Data Mining, ou

EDM) utiliza m´etodos e ferramentas do campo mais amplo de minera¸c˜ao de dados, se-
gundo Witten et al. (1999). ´E uma ´area de pesquisa recente e pouco explorada no Brasil
que desenvolve m´etodos para interpretar dados em contextos educacionais com potencial

para melhorar a qualidade do ensino, pois visa entender melhor o discente no seu processo

de aprendizagem. Recentemente, muitas institui¸c˜oes de ensino precisam lidar com uma

amplia¸c˜ao de cursos, vagas e, consequentemente, com muito dados. Com o aux´ılio da

minera¸c˜ao de dados educacionais ´e poss´ıvel descobrir fatores que podem interferir, por

exemplo, na evas˜ao ou conclus˜ao dos cursos, o que possibilita identiﬁcar falhas e criar

medidas para a solu¸c˜ao do problema de cada escola ou Universidade. Problemas te´oricos

e pr´aticos podem ser solucionados com o desenvolvimento e a aplica¸c˜ao de m´etodos com-

putadorizados, para detectar padr˜oes em grandes conjuntos de dados educacionais dif´ıceis

de analisar devido ao grande volume de dados existentes, ´e o que aﬁrma Romero et al.

(2010).

O m´etodo de minera¸c˜ao de dados usado nesse trabalho ´e a ´arvore de decis˜ao.

Segundo Da Silva (2005), ´arvores de decis˜ao s˜ao modelos estat´ısticos que analisam in-

forma¸c˜oes visando a classiﬁca¸c˜ao, regress˜ao e previs˜ao de dados. Sua constru¸c˜ao ´e for-

mada por entradas e sa´ıdas chamadas classes. Para Gama et al. (2004), o intuito ´e dividir

um problema complexo em subproblemas mais simples e, recursivamente, esta t´ecnica ´e

aplicada a cada subproblema. Mitchell (1997), aﬁrma que as ´arvores de decis˜ao est˜ao

entre os mais populares algoritmos de inferˆencia e tˆem sido aplicadas em v´arias ´areas

como, por exemplo, diagn´ostico m´edico e risco de cr´edito.

A minera¸c˜ao dos dados deste estudo ´e feita com o aux´ılio do Rapidminer, uma

plataforma para an´alise preditiva que dispensa o conhecimento de qualquer linguagem

de programa¸c˜ao. Assim, o Rapidminer disponibiliza um ambiente completo para an´alise

de dados, seja ela para estudantes, professores, pequenos neg´ocios ou grandes empresas.

Qualquer an´alise produzida pelo Rapidminer, por mais simples que seja, ´e baseada num

conjunto de dados, oferecendo uma interface gr´aﬁca f´acil de utilizar, que permite a cria¸c˜ao

r´apida de processos para an´alise de dados e disponibiliza diferentes formas de visualiza¸c˜ao

dos resultados.

Utilizamos, tamb´em, Python para classiﬁcar estudantes fora da amosta e para criar

operadores personalisados. Python ´e uma linguagem de programa¸c˜ao de alto n´ıvel, isto ´e,

a linguagem de programa¸c˜ao se assemelha muito `a linguagem verbal. A escolha do Python

deve-se a dois fatores: primeiro por Python ser uma linguagem de programa¸c˜ao livre e

segundo por ser bem-aceito nas comunidades acadˆemicas. Estes dois fatores ﬁzeram com

4

que o Python tenha uma gama de bibliotecas com m´etodos interessantes para minera¸c˜ao

de dados. O Rapidminer ´e compat´ıvel com Python, ou seja, scripts escritos na linguagem

Python podem ser executados pelo Rapidminer. Este fato, faz com que o Rapidminer

tenha inﬁnitas op¸c˜oes de operadores personalizados atrav´es da linguagem Python.

Este trabalho tem como objetivo classiﬁcar alunos, utilizando ´arvore de decis˜ao,

a partir de resultados ﬁnais, e, assim, identiﬁcar grupos em risco de reprova¸c˜ao para

acompanhamento pedag´ogico e/ou grupos com potenciais para bolsas de estudo e ati-

vidades de monitorias. Geralmente, os alunos desempenham in´umeras atividades al´em

das atividades de sala de aula, portanto ´e dif´ıcil acompanhar e reconhecer as necessida-

des individuais deles. Dessa forma, a ado¸c˜ao de mecanismos semi-automatizados podem

viabilizar a detec¸c˜ao precoce de grupos de alunos com risco de desligamento, e tentar

minimizar o problema.

O trabalho est´a organizado da seguinte forma: Inicialmente, temos o Cap´ıtulo

1 (Trabalhos Relacionados) com informa¸c˜oes de trabalhos desenvolvidos na ´area de mi-

nera¸c˜ao de dados Educacionais, principalmente com o uso da ´arvore de decis˜ao, o que
possibilita melhor compreens˜ao do estudo. Na sequˆencia, temos o Cap´ıtulo 2 ( ´Arvores de
decis˜ao com Rapidminer) com o recurso tecnol´ogico utilizado no desenvolvimento desse

trabalho, assim como instru¸c˜oes de manuseios e um foco maior no operador Decision tree,

que permite gerar a ´arvore de decis˜ao. O Cap´ıtulo 3 (Aplica¸c˜oes e resultados) consiste

na descri¸c˜ao dos processos de constru¸c˜oes de dois modelos, que inclui o entendimento

dos dados, ferramentas utilizadas, pr´e-processamento, visualiza¸c˜ao de dados, constru¸c˜oes

de modelos de classiﬁca¸c˜ao, e, em seguida, as an´alises dos resultados. Finalmente, no

Cap´ıtulo 4 (Considera¸c˜oes Finais), conclu´ımos o estudo.

1 TRABALHOS RELACIONADOS

Neste cap´ıtulo, ser˜ao apresentadas duas se¸c˜oes sobre trabalhos desenvolvidos na

´area de Minera¸c˜ao de Dados Educacionais. Na Se¸c˜ao 1.1, tem-se trabalhos realizados no

exterior e na Se¸c˜ao 1.2, tabalhos feitos no Brasil.

1.1 Trabalhos Internacionais

Muitos autores realizam an´alises e prop˜oem ferramentas no contexto de Minera¸c˜ao

de Dados Educacionais. Em Al-Radaideh et al. (2011), foi constru´ıdo um modelo de

classiﬁca¸c˜ao para prever a melhor rotina de estudos para os alunos da escola. Os dados

consistem de 248 casos que foram coletados de seis escolas b´asicas na Cidade Mafraq, na

Jordˆania. A ´arvore de decis˜ao gerada com algoritmo C4.5, chegou a um total de 87% de

precis˜ao.

Em Baradwaj and Pal (2012), o desempenho dos estudantes foi analisado utilizando

o algoritmo de classiﬁca¸c˜ao chamado ID3, para prever as notas dos estudantes no ﬁnal

do semestre. Este foi aplicado no curso de aplica¸c˜oes inform´aticas de 2007 a 2010 na

Universidade de Purvanchal VBS, Uttar Pradesh. Seu estudo foi destinado a ajudar

alunos e professores a encontrarem formas de melhorar seus desempenhos. Os dados

foram coletados a partir de 50 alunos, e, em seguida, um conjunto de regras foi extra´ıdo

para an´alise.

Outro estudo que usou t´ecnicas de minera¸c˜ao de dados para melhorar o desempenho

dos alunos foi feito por El-Halees (2009). Os dados consistiram de 151 casos de um sistema

de gest˜ao de base de dados realizado na Universidade de Gaza. Os dados foram coletados

a partir de registros pessoais e acadˆemicos dos estudantes. O autor utilizou as t´ecnicas de

minera¸c˜ao de dados, a saber: regras de associa¸c˜ao, classiﬁca¸c˜ao, agrupamento e detec¸c˜ao

de outlier. Os resultados revelaram informa¸c˜oes ´uteis a partir de regras de associa¸c˜ao e

modelos de classiﬁca¸c˜ao. Al´em disso, o estudo tinha agrupado os dados dos alunos para

identiﬁcar caracter´ısticas e detectar poss´ıveis discrepˆancias. O conhecimento obtido foi

interessante para melhorar o desempenho dos alunos.

O estudo de Nandeshwar and Chaudhari (2009) teve como objetivo prever ins-

6

cri¸c˜oes de estudantes usando dados de admiss˜ao. Os pesquisadores usaram dados da Uni-

versidade da Virginia que consiste de 112390 casos. V´arios modelos de classiﬁca¸c˜ao dos

alunos foram constru´ıdos. Eles compararam os dados de diferentes alunos e identiﬁcou-se

como melhores resultados J48 e Rido.

Al´em disso, Kabakchieva (2013), analisou a matr´ıcula e os dados pessoais de alunos

da Universidade de Economia Mundial na Bulg´aria. O objetivo foi o de prever o desem-

penho dos estudantes com base nas caracter´ısticas dos pr´e-universit´arios. O pesquisador

aplicou v´arios algoritmos de classiﬁca¸c˜ao e os resultados mostraram que ´arvore de decis˜ao

com J48 teve a maior exatid˜ao global.

Em outra an´alise, Garcıa-Saiz and Zorrilla (2011) tentaram aplicar diferentes

t´ecnicas de classiﬁca¸c˜ao para um conjunto de dados educacionais estabelecidos para com-

parar seus desempenhos e escolher os melhores algoritmos para serem integrados na sua

ferramenta (E-learning Web Miner ). Esta ferramenta ´e destinada a ajudar os professores

a descobrirem o desempenho de seus alunos. Foram utilizados os dados do campo de

nome Introdu¸c˜ao aos m´etodos multim´ıdias, oferecido em trˆes anos letivos de 2007-2010

na Universidade de Cantabria. Eles usaram diferentes m´etodos de classiﬁca¸c˜ao e desco-

briram que o desempenho e a precis˜ao das t´ecnicas dependiam do tipo dos atributos e do

tamanho do conjunto de dados. Entre os achados, o J48 foi dito adequado para conjuntos

de dados com mais de 100 instˆancias e atributos nominais com dados faltantes.

Outra compara¸c˜ao de diferentes algoritmos de minera¸c˜ao de dados foi realizada

por Romero et al. (2008). A pesquisa teve como objetivo classiﬁcar os alunos com as

mesmas notas ﬁnais em diferentes grupos, dependendo das atividades realizadas em um

curso web-based. Essas atividades incluem: o n´umero de atribui¸c˜oes feitas, o n´umero de

question´arios, o tempo total usado em testes e outros. Seu conjunto de dados consiste de

438 estudantes da Universidade de C´ordoba. Eles avaliaram o desempenho dos algoritmos

com base nos tipos dos atributos: categ´oricos e num´ericos. Eles descobriram que dois

algoritmos de ´arvore de decis˜ao, CART e C4.5, foram os melhores para dados categ´oricos.

Kovacic (2010) utilizou a classiﬁca¸c˜ao para prever o sucesso dos estudantes com

base em vari´aveis s´ociodemogr´aﬁcas (idade, sexo, etnia, educa¸c˜ao, situa¸c˜ao de trabalho

e invalidez) e de ambiente de estudo (programa de curso). O conjunto de dados cont´em

dados dos alunos no curso de Sistemas de Informa¸c˜ao na Polit´ecnica da Nova Zelˆandia.

Quatro ´arvores de classiﬁca¸c˜ao, CHAID, CHAID exaustiva, QUEST e CART foram uti-

lizadas nesse estudo e CART foi a melhor com uma porcentagem de classiﬁca¸c˜ao global

de 60,5%.

Khan and Choi (2014), utilizaram a minera¸c˜ao de dados, com o m´etodo de ´arvore

de decis˜ao. Os dados foram minerados de forma a calcular as chances de obten¸c˜ao de

uma bolsa escolar. Foram utilizados os algoritmos ID3 e J48, sendo o primeiro de melhor

7

eﬁciˆencia, mesmo sendo o outro mais r´apido de classiﬁcar os dados e criar uma ´arvore

menor. De acordo com os autores, o ID3 fornece uma ´arvore com mais regras, o que

signiﬁca maior cruzamento de dados e tomada de decis˜ao mais profunda, e ´e por isso que

o resultado previsto foi mais preciso do que J48. Concluiu-se que o sistema desenvolvido

pode ser muito ´util na previs˜ao da probabilidade de o estudante ganhar bolsa de estudos.

1.2 Trabalhos Nacionais

No Brasil, as oportunidades para praticar a minera¸c˜ao de dados educacionais est´a

aumentando e os cursos de Educa¸c˜ao `a distˆancia criaram oportunidades para as pesquisas

na ´area, segundo Baker et al. (2011). Em um estudo, Gottardo et al. (2012), apresenta

uma preliminar do uso de algumas t´ecnicas de minera¸c˜ao de dados em uma base de

dados do sistema Moodle, com o objetivo de veriﬁcar a adequa¸c˜ao do conjunto de atri-

butos propostos, contendo informa¸c˜oes de estudantes em um curso realizado a distˆancia.

Escolheu-se uma disciplina com um total de 155 estudantes concluintes em quatro tur-

mas diferentes e desenvolveu-se procedimentos para extra¸c˜ao dos atributos considerados

signiﬁcativos para o trabalho. No desenvolvimento dos experimentos foram utilizados os

algoritmos de classiﬁca¸c˜ao RandomForest e MultilayerPerceptron. O principal aspecto a

ser destacado a partir dos testes refere-se aos resultados superiores obtidos de um ex-

perimento em rela¸c˜ao a outro. Este fato aponta para a viabilidade da utiliza¸c˜ao de um

conjunto amplo de atributos para representa¸c˜ao de estudantes, potencialmente genera-

liz´aveis a diversos cen´arios de cursos Educa¸c˜ao `a Distˆancia.

Fran¸ca and do Amaral (2013), apresentam o uso de t´ecnicas de minera¸c˜ao de da-

dos para a forma¸c˜ao de grupos similares de estudantes com diﬁculdades de aprendizagem

no ensino de Programa¸c˜ao. Para a realiza¸c˜ao do trabalho, utilizou-se os dados prove-

nientes de avalia¸c˜oes da aprendizagem da disciplina Programa¸c˜ao Orientada a Objetos,

ministrada no primeiro semestre de 2010, no curso de Licenciatura em Computa¸c˜ao da

Universidade de Pernambuco, onde havia 33 estudantes matriculados. Os resultados apre-

sentados conﬁrmam que t´ecnicas de clusteriza¸c˜ao s˜ao bastante ´uteis para a forma¸c˜ao de

grupos homogˆeneos de estudantes. O uso do algoritmo K-means permitiu agrupar alu-

nos pelas suas diﬁculdades de aprendizagem e identiﬁcou um grupo de aprendizes com

diﬁculdades em entender Estrutura¸c˜ao de Sistemas em Camadas e outro composto por

estudantes com problemas em criar Arrays. Ambos os grupos foram reprovados ao ﬁnal

do semestre.

Detoni et al. (2014), mostraram resultados da aplica¸c˜ao de t´ecnicas de aprendizado

de m´aquina, utilizando como atributos unicamente contagens de intera¸c˜oes ao longo do

tempo, na predi¸c˜ao de reprova¸c˜ao de estudantes. Para a realiza¸c˜ao do trabalho, foram

8

obtidos os dados anonimizados dos cursos a distˆancia de Licenciatura Educa¸c˜ao do Campo

e de Licenciatura em Pedagogia. Demonstrou-se que utilizar apenas a quantidade de

intera¸c˜oes dos alunos ´e vi´avel para gerar predi¸c˜oes razoavelmente precisas, ainda que

menos precisas do que trabalhos anteriores que utilizam atributos muito mais espec´ıﬁcos.

Santos et al. (2012), relatam um estudo sobre a aplica¸c˜ao de t´ecnicas de minera¸c˜ao

de dados que permitem, em est´agios anteriores `as avalia¸c˜oes somativas, identiﬁcar alunos

que tˆem maior risco de reprova¸c˜ao. Os dados que sustentam a abordagem s˜ao oriundos

de avalia¸c˜oes formativas aplicadas no decorrer da disciplina atrav´es do Ambiente Virtual

de Aprendizagem Moodle. Resultados preliminares mostram que os modelos criados per-

mitem a identiﬁca¸c˜ao da propens˜ao `a reprova¸c˜ao com taxa de acerto em torno de 69%.

A primeira an´alise realizada foi a respeito do coeﬁciente de correla¸c˜ao entre a nota na

avalia¸c˜ao somativa e as demais vari´aveis existentes. Na segunda an´alise, foi aplicado o

algoritmo de clusteriza¸c˜ao k-means, atrav´es da utiliza¸c˜ao da ferramenta Weka. Na ter-

ceira an´alise, a ﬁm de identiﬁcar a tendˆencia dos estudantes a terem sucesso na avalia¸c˜ao

somativa, foram aplicados algoritmos de classiﬁca¸c˜ao sobre os dados dispon´ıveis. Dentre

os algoritmos utilizados, s˜ao apresentados apenas os resultados gerados pelo REPTree

e pelo J48 que geraram ´arvores com poucos nodos e maior capacidade preditiva. To-

dos os experimentos de classiﬁca¸c˜ao realizados utilizaram a t´ecnica de valida¸c˜ao cruzada

Leave-One-Out para medir a capacidade de generaliza¸c˜ao dos modelos. Os trˆes grupos de

experimentos realizados comprovam uma realidade esperada: Quanto maior a dedica¸c˜ao

nas atividades presenciais e semipresenciais, melhor o desempenho do aluno nas avalia¸c˜oes

somativas.

No trabalho de Moro et al. (2014), apresentou-se resultados parciais de uma pes-

quisa de mestrado que identiﬁcou, por meio de t´ecnicas de Minera¸c˜ao de Dados Educaci-

onais, padr˜oes relevantes de comportamentos de alunos que interagiram com um sistema

educacional web. A DAMICORE, ferramenta de minera¸c˜ao de dados, foi aplicada aos da-

dos com os algoritmos Normalized Compression Distance, Neighbor Joining e FastNewman

e diante dos resultados obtidos, ´e poss´ıvel supor, que a an´alise pode favorecer a tomada

de decis˜ao do professor e trazer melhorias para o processo de ensino e aprendizagem.

Manh˜aes et al. (2011) apresentam um estudo que identiﬁca os alunos com risco de

evas˜ao, atrav´es do uso de t´ecnicas de minera¸c˜ao de dados. O trabalho avaliou a t´ecnica

atrav´es de trˆes experimentos onde foram aplicados dez algoritmos de classiﬁca¸c˜ao sobre

uma base de dados acadˆemicos de alunos do curso de Engenharia Civil da Universidade

Federal do Rio de Janeiro. Os algoritmos utilizados foram: OneR, JRip, DecisionTa-

ble, SimpleCart, J48, RandomForest, SimpleLogistic, MultilayerPerceptron, NaiveBayes,

BayesNet e os m´etodos de classiﬁca¸c˜ao empregados pelos algoritmos foram: aprendizado

de regras (OneR e JRip), tabela de decis˜ao (DecisionTable), ´arvore de decis˜ao (Simple-

9

Cart, J48 e RandomForest), modelos lineares de regress˜ao log´ıstica (SimpleLogistic), mo-

delo de rede neural artiﬁcial (MultilayerPerceptron), modelos probabil´ıstico (BayesNet),

classiﬁcador probabil´ıstico simples baseado na aplica¸c˜ao do teorema de Bayes (Naive-

Bayes). Os experimentos retornaram dados com acur´acia m´edia variando entre 75 a 80%.

Concluiu-se que os desempenhos obtidos pelos algoritmos de minera¸c˜ao de dados dos mais

simples aos mais soﬁsticados foram semelhantes e que, a acur´acia dos classiﬁcadores e a

taxa de erro s˜ao fortemente inﬂuenciadas pelos bancos de dados.

2 ´ARVORES DE DECIS ˜AO COM RA-

PIDMINER

Neste cap´ıtulo ´e apresentada uma vis˜ao geral da ferramenta computacional usada

nesse trabalho, o Rapidminer, com foco no operador Decision tree. Na Se¸c˜ao 2.1, apresen-

taremos um estudo, incluindo, o passo a passo de uma poss´ıvel utiliza¸c˜ao desta ferramenta.

O operador Decision Tree ´e estudado na Se¸c˜ao 2.2. As informa¸c˜oes desse cap´ıtulo foram

retiradas da documenta¸c˜ao oﬁcial do Rapidminer. Como a documenta¸c˜ao est´a toda em

inglˆes e o p´ublico-alvo s˜ao professores do ensino b´asico, optamos por fazer uma releitura

em portuguˆes de todas as fun¸c˜oes do Rapidminer que ser˜ao utilizadas nesse trabalho.

Assim, espera-se que as pr´oximas se¸c˜oes contribuam para um melhor entendimento do

Cap´ıtulo 3, mesmo para aqueles professores que possuem diﬁculdades com a l´ıngua in-

glesa.

2.1 Entendendo o Rapidminer

Esta se¸c˜ao est´a subdividida em outras nove nas quais s˜ao apresentadas a termino-

logia do Rapidminer (Subse¸c˜ao 2.1.1), a importa¸c˜ao dos dados (Subse¸c˜ao 2.1.2), a cria¸c˜ao

de processos (Subse¸c˜ao 2.1.3), a transforma¸c˜ao dos dados (Subse¸c˜ao 2.1.4), a cria¸c˜ao de

modelos (Subse¸c˜ao 2.1.5), a valida¸c˜ao de modelos (Subse¸c˜ao 2.1.6), a visualiza¸c˜ao dos

resultados (Subse¸c˜ao 2.1.7), a aplica¸c˜ao de modelos (Subse¸c˜ao 2.1.8) e a cria¸c˜ao de ope-

radores personalizados (Subse¸c˜ao 2.1.9).

2.1.1 Terminologia do Rapidminer

Alguns termos t´ecnicos e seus signiﬁcados s˜ao importantes para o entendimento do

programa Rapidminer. Apresentaremos abaixo uma lista destes, bem como a tradu¸c˜ao

para o inglˆes, como s˜ao representados no programa.

• Operadores (em inglˆes operators) s˜ao blocos de constru¸c˜ao utilizados para realizar

a¸c˜oes com conjuntos de dados (em inglˆes dataset).

11

• Reposit´orio (em inglˆes repository) ´e o local onde encontram armazenados os con-

juntos de dados e os processos do programa.

• Portas (em inglˆes port) s˜ao os pontos atrav´es dos quais os operadores se conectam.

As portas s˜ao representadas por semic´ırculos marcados nas laterais dos operadores.

Existem v´arios tipos de portas. A Tabela 2.1 resume os tipos e fun¸c˜oes de algumas

portas que ser˜ao utilizadas nesse trabalho:

Tabela 2.1: Portas no Rapidminer

Nome da

Abrevia¸c˜ao

Tradu¸c˜ao

porta

no Rapidminer

para o inglˆes

Fun¸c˜ao

Resultado

res

Result

Exemplo

exa

Example set

Treino

tra

Training

Mostra o resultado

do um processo

Retorna um exemplo

de conjunto

Retorna um conjunto

de treinamento

Retorna o modelo

Modelo

mod

Model

criado por um pro-

Sa´ıda

out

Output

N˜ao Rotulado unl

Unlabeled

cesso.

Retorna o resultado

de um processo

Aplica dados n˜ao

rotulados

Entrada

inp

Input

Fonte de entrada

• Processo (em inglˆes process) ´e um conjunto de operadores conectados atrav´es de

suas portas de forma que suas a¸c˜oes, na ordem em que est˜ao conectadas, conduzem

a um objetivo.

2.1.2 Adicionando conjuntos de dados ao reposit´orio

Para adicionar conjuntos de dados ao reposit´orio do Rapidminer, clique no bot˜ao

Add Data na janela Repository do programa. Logo em seguida escolha o arquivo que

deseja analisar. O Rapidminer ´e compat´ıvel com arquivos em formato Access, BibTeX,

CSV, Excel, Sparse, STATA, dentre outros. Neste trabalho utilizamos apenas arquivos

CSV.

12

Arquivos CSV s˜ao arquivos comuns separados por v´ırgula. Estes podem ser criados

e editados em qualquer editor de texto. O Exemplo 2.1.1 mostra o formato de um arquivo

CSV da maneira como ele ´e apresentado num editor de texto qualquer.

Exemplo 2.1.1. Nesse exemplo, com dados ﬁct´ıcios, ilustramos como ´e redigido um

arquivo CSV num editor de texto qualquer. As v´ırgulas s˜ao usadas para separar as colunas

como se fosse uma tabela:

nome,idade,sexo,profissao

ana,23,f,empresario

carlos,29,m,advogado

pedro,19,m,estudante

leticia,21,f,estudante

roberto,25,m,empresario

Os pr´oximos passos ser˜ao apresentados considerando o Exemplo 2.1.1. Ap´os clicar

em Add Data e escolher o arquivo que deseja estudar basta clicar no bot˜ao Next. A

pr´oxima etapa consiste em especiﬁcar o formato dos dados. Como nossos dados est˜ao na

forma correta, avan¸caremos clicando uma segunda vez no bot˜ao Next. Na pr´oxima etapa,

podemos conﬁgurar os atributos. Nesta etapa vocˆe pode excluir ou renomear colunas,

deﬁnir o formato dos atributos e, tamb´em, mudar a regra que rege cada um deles. Os

tipos que cada atributo possui j´a s˜ao sugeridos pelo Rapidminer. Mudaremos apenas suas

regras. Como a primeira coluna ´e de identiﬁca¸c˜ao, clique no ´ıcone de engrenagem do lado

da palavra “nome”, escolha a op¸c˜ao Change Role (que signiﬁca mudar regra em portuguˆes)

e, no campo que foi aberto, digite id (abrevia¸c˜ao para identiﬁcador). Pressione o bot˜ao

OK. Note que a coluna “nome” ´e agora de cor diferente indicando que h´a uma regra

sobre ela. Mudaremos tamb´em a coluna “proﬁssao” seguindo os passos anteriores, por´em

digitando label no lugar de id. A regra label indica que a coluna agora est´a marcada. Esta

marca¸c˜ao ´e necess´aria caso haja necessidade de nos referirmos a alguma coluna durante

algum processo. Clicando novamente no bot˜ao next, basta dar um nome para o conjunto

de dados. Trabalharemos com os dados do Exemplo 2.1.1 um pouco mais, dessa forma,

se o leitor quiser dar o nome de “users” para este conjunto de dados, ﬁcar´a mais f´acil

acompanhar as etapas que se seguem. Se tudo estiver correto, uma tabela mostrando os

dados importados aparecer´a na tela. No caso do exemplo dado nesta se¸c˜ao, a tabela que

aparecer´a ´e ilustrada pela Figura 2.1.

Figura 2.1: Adi¸c˜ao de “users” no reposit´orio

13

2.1.3 Construindo processos

Processos podem ser feitos de diversas formas conectando os v´arios tipos de ope-

radores existentes no Rapidminer. Logo, para criar um processo vocˆe precisa saber quais

operadores se conectam e como estes realizam a¸c˜oes de forma a conduzir o processo para

o resultado esperado. Nessa subse¸c˜ao, criaremos o primeiro processo com o Rapidminer.

O processo mais simples ´e formado por um s´o operador. No reposit´orio do Ra-

pidminer, escolha um conjunto de dados e arraste-o para a janela denominada Process.

Observe que um operador denominado retrieve, termo em inglˆes que signiﬁca “receber”, ´e

inserido na janela de processos. A a¸c˜ao deste operador ´e simplesmente receber o conjunto

de dados do reposit´orio. Conecte a porta out do operador retrieve na porta res da janela

de processos, esta ´ultima se encontra no canto superior direito da janela de processos.

Nesse momento, o processo deve estar como na Figura 2.2. Pronto! Vocˆe criou seu pri-

meiro processo, basta apertar a tecla F11 para ver o resultado. Caso o conjunto de dados

importado seja o mesmo da Se¸c˜ao 2.1.2, o resultado ´e o mesmo da Figura 2.1.

Figura 2.2: Processo de visualiza¸c˜ao de “users”

14

2.1.4 Transformando o conjunto de dados

Na maioria das vezes, o conjunto de dados precisa ser transformado. Um exemplo

de operador com essa fun¸c˜ao ´e o operador Filter Examples (que em portuguˆes signiﬁca

ﬁltro de exemplos). A fun¸c˜ao do operador Filter Examples ´e simplesmente ﬁltrar os

elementos do conjunto de dados. Para encontrar um operador na janela Operators, basta

digitar seu nome no campo Seach for Operators. Supondo que, ap´os adicionar o arquivo

em formato CSV do Exemplo 2.1.1 ao reposit´orio do Rapidminer com o nome de users,

desej´assemos ﬁltrar os usu´arios selecionando apenas os do sexo masculino. Deve-se realizar

algumas etapas para que o processo tenha a aparˆencia da Figura 2.3.

Figura 2.3: Processo de ﬁltragem em “users”

• Arraste o conjunto de dados users do reposit´orio do Rapidminer para a janela de

processos;

• Arraste o operador Filter Examples da janela Operators para a janela de processos;

• Clique no operador Filter Examples;

• Na janela Parameters, clique no bot˜ao Add Filters;

• No primeiro campo digite “sexo” sem aspas, no segundo selecione a op¸c˜ao equals

(em portuguˆes, igual) e no terceiro digite “m” sem as aspas. Isso faz com que o

operador ﬁltre o conjunto de dados, selecionando apenas aquelas amostras cujo sexo

´e igual a “m”;

• Voltando a janela de processos do Rapidminer, conecte a porta out do operador

Retrieve users, na porta exa do lado esquerdo do operador Filter Examples;

• Conecte a porta exa do lado direito do operador Filter Examples, na porta res no

canto superior direito da janela de processos do Rapidminer;

• Aperte a tecla F11 para executar o processo.

O resultado do processo acima ´e apresentado pela Figura 2.4. Observe que s´o as

pessoas do sexo masculino aparecem agora na tabela.

Figura 2.4: Resultado do processo de ﬁltragem em “users”

15

2.1.5 Processo de modelagem

At´e este ponto, apresentamos no¸c˜oes b´asicas sobre como adicionar dados ao repo-

sit´orio e ao processo do Rapidminer. Tamb´em explicamos como transformar o conjunto

de dados. Nos pr´oximos par´agrafos, daremos exemplo de processos de modelagem.

Em poucas palavras, modelagem ´e a representa¸c˜ao de caracter´ısticas, padr˜oes ou

rela¸c˜oes entre os elementos de um conjunto de dados. Esta representa¸c˜ao pode ser atrav´es

de diagramas, tabelas, gr´aﬁcos, grafos, etc.

Utilizaremos, neste trabalho, a modelagem atrav´es do operador Decision Tree

(´arvore de decis˜ao em portuguˆes). Nesta se¸c˜ao, apresentaremos apenas como construir o

processo utilizando este operador. Detalhes espec´ıﬁcos do processo ser˜ao dados na Se¸c˜ao

2.2.

Novamente, para ilustrar como funciona a constru¸c˜ao de um processo de modela-

gem com o operador Decision Tree no programa Rapidminer, consideraremos o conjunto

de dados do Exemplo 2.1.1 adicionado ao reposit´orio com nome de users. Para que o

operador Decision Tree funcione, ´e necess´aria a marca¸c˜ao de um atributo como label ex-

plicado na Subse¸c˜ao 2.1.2. A Figura 2.5 representa o processo em quest˜ao, e as etapas

para a sua constru¸c˜ao s˜ao:

Figura 2.5: Decision Tree aplicado ao conjunto “users”

• Arraste o conjunto de dados users do reposit´orio do Rapidminer para a janela de

16

processos;

• Arraste o operador Decision Tree da janela Operators para a janela de processos;

• Conecte a porta out do operador Retrieve users na porta tra do operador Decision

Tree;

• Conecte a porta mod do operador Decision Tree na porta res no canto superior

direito da janela de processos do Rapidminer;

• Aperte a tecla F11 para rodar o processo;

O resultado do processo ´e apresentado na Figura 2.6 em forma de grafo.

Figura 2.6: Grafo resultante da aplica¸c˜ao de Decision Tree em “users”

O grafo da Figura 2.6 diz que se a pessoa, no conjunto de dados users, tiver uma

idade maior que 24 anos, ent˜ao esta ´e do sexo masculino, caso contr´ario ´e do sexo feminino.

Note que n˜ao ´e verdade, pois Pedro tem 19 anos, portanto uma idade menor ou igual a

24 anos, e ´e do sexo masculino. No entanto, note que este modelo fornece uma regra para

decidir se a pessoa ´e do sexo masculino utilizando apenas a idade e, mesmo assim, ´e uma

regra que conseguiu classiﬁcar corretamente 4 das 5 pessoas. De fato, poder´ıamos fazer

melhor apenas observando a tabela, no entanto, quando a quantidade de elementos do

conjunto de dados ´e muito grande (o que ocorre na maioria dos casos reais), criar modelos

manualmente para classiﬁcar os dados do conjunto ´e invi´avel, e obter uma classiﬁca¸c˜ao

com 80% de acerto atrav´es de regras de decis˜ao se torna uma tarefa extremamente dif´ıcil.

Na Se¸c˜ao 2.1.6 aprenderemos processos de valida¸c˜ao de modelos.

2.1.6 Validando modelos

Neste ponto, espera-se que o leitor saiba como adicionar determinados conjun-

tos de dados e operadores `a janela de processos. Dessa forma conduziremos o texto de

17

forma sucinta utilizando de ﬁguras para representar as estruturas dos processos a serem

trabalhados. Nesta subse¸c˜ao, apresentaremos o processo de valida¸c˜ao.

O Rapidminer j´a disponibiliza v´arios conjuntos de dados para que vocˆe possa pra-

ticar a constru¸c˜ao de processos. Dessa vez utilizaremos um desses conjuntos de dados.

No reposit´orio do Rapidminer, dentro da pasta Samples (que signiﬁca exemplos em por-

tuguˆes), vocˆe encontra v´arios exemplos de conjuntos de dados e de processos prontos

para estudo. Dentro da pasta data (que signiﬁca dados em portuguˆes), vocˆe encontra

alguns conjuntos de dados prontos para serem trabalhados. Arraste aquele com o nome

de Titanic para a janela de processos.

Como o conjunto de dados “Titanic” j´a estava no reposit´orio, n˜ao tivemos a oportu-

nidade de mudar as regras que regem os atributos deste conjunto durante sua importa¸c˜ao.

Desta forma, utilizaremos o operador Set Role para dizer que a coluna “name” ´e de iden-

tiﬁca¸c˜ao e a coluna “survived” ser´a marcada para cria¸c˜ao do modelo de ´arvore de decis˜ao.

Para a constru¸c˜ao de um processo como o da Figura 2.7, siga os seguintes passos:

Figura 2.7: Valida¸c˜ao de modelo de classiﬁca¸c˜ao de tripulantes do Titanic

• Adicione o operador Set Role `a janela de processos;

• Conecte a porta out do operador Retrieve Titanic na porta exa do operador Set

Role;

• Clique no operador Set Role;

• Na janela de parˆametros, clique no bot˜ao Edit List;

• Clique no bot˜ao Add Entry para adicionar entradas at´e que tenham um total de

duas;

• No campo atribute name da primeira entrada, selecione Name;

• No campo atribute name da segunda entrada, selecione Survived ;

• No campo target role da primeira entrada, selecione id ;

18

• No campo target role da segunda entrada; selecione label ;

• Clique no bot˜ao Apply para aplicar as regras.

Para validar o modelo de ´arvore de decis˜ao obtida atrav´es do operador Decision

Tree, neste caso usada para classiﬁcar as pessoas que sobreviver˜ao ou n˜ao do famoso

naufr´agio do “Titanic”, utilizaremos o operador X-Validation. Siga os seguintes passos:

• Arraste o operador X-Validation para janela de processos;

• Conecte a porta exa do operador Set Role na porta tra do operador X-Validation;

• Clique duas vezes sobre o operador X-Validation;

Nesse momento, pode-se ver na Figura 2.8 dois subprocessos do operador X-

Validation, um para treinamento (em inglˆes training) e um para teste (em inglˆes testing).

Figura 2.8: Processos internos do operador X-Validation

• Arraste o operador Decision Tree para janela de treinamento;

• Conecte a porta tra da janela de treinamento na porta tra do operador Decision

Tree;

• Conecte a porta mod do operador Decision Tree na porta mod da janela de treina-

mento;

• Arraste o operador Apply Model para a janela de teste;

• Conecte a porta mod da janela de teste na porta mod do operador Apply Model ;

• Conecte a porta tes da janela de teste na porta unl do operador Apply Model ;

• Arraste o operador Performance (Classiﬁcation) para a janela de teste;

• Conecte a porta lab do operador Apply Model na porta lab do operador Performance

(Classiﬁcation);

• Conecte a porta per do operador Performance (Classiﬁcation) na porta ave da

janela de teste;

19

• Clique em Process para voltar para a janela de processos;

• Conecte a primeira porta ave do operador X-Validation na porta res da janela de

processos;

• Aperte F11 para rodar o processo.

Se tudo estiver correto, uma janela com a tabela apresentada na Figura 2.9 ser´a

apresentada na tela.

Figura 2.9: Resultado da aplica¸c˜ao de Decision Tree no conjunto “Titanic”

2.1.7 Visualizando resultados

Ao executar um processo, os resultados deste s˜ao apresentados pelo Rapidminer.

Nesta subse¸c˜ao trataremos de entender o que signiﬁca alguns dos resultados que utiliza-

remos neste trabalho.

A Figura 2.9 apresenta o resultado do processo de valida¸c˜ao do modelo de ´arvore

de decis˜ao obtido pelo operador Decision Tree aplicado ao conjunto de dados “Titanic”.

O objetivo deste processo ´e classiﬁcar quem sobreviveu ou n˜ao ao acidente. A matriz

apresentada na Figura 2.9 ´e denominada Confusion Matrix (que em portuguˆes signiﬁca

Matriz de Confus˜ao). Quando somado os n´umeros inteiros da coluna true Yes, obt´em-

se a quantidade de tripulantes do “Titanic” que, de fato, sobreviveram, considerando o

conjunto de dados estudado. Somando os inteiros da coluna true No obt´em-se o n´umero

de tripulantes que n˜ao sobreviveram ao naufr´agio. Em laranja mais escuro encontramos

o n´umero de classiﬁca¸c˜oes corretas realizadas pelo modelo gerado pelo operador Decision

Tree. A porcentagem 66,20% representa os sobreviventes classiﬁcados corretamente dentre

todos que sobreviveram. J´a 86,40% ´e a porcentagem de n˜ao sobreviventes classiﬁcados

corretamente dentre todos que n˜ao sobreviveram. A porcentagem 75,06% ´e obtida fazendo

o quociente do n´umero de tripulantes classiﬁcados como sobreviventes dentre os que de

fato sobreviveram, pelo n´umero classiﬁca¸c˜oes de sobreviventes (corretas ou n˜ao) geradas

pelo modelo. Por ﬁm 80,53% ´e a porcentagem obtida fazendo o quociente do n´umero de

tripulantes classiﬁcados como n˜ao sobreviventes dentre os que de fato n˜ao sobreviveram,

pelo n´umero total de classiﬁca¸c˜oes de n˜ao sobreviventes (corretas ou n˜ao) geradas pelo

modelo de ´arvore de decis˜ao.

20

O termo accuracy (que em portuguˆes signiﬁca acur´acia) ´e a porcentagem de que,

escolhida aleatoriamente uma amostra no conjunto de dados, o modelo classiﬁque corre-

tamente a amostra. Na Figura 2.9, a accuracy ´e de 78,68%. O valor 4,45% que aparece

junto `a accuracy ´e o desvio padr˜ao. Para calcular a accuracy, basta dividir o n´umero

de amostras classiﬁcadas corretamente pelo total de amostras do conjunto de dados. O

termo mikro denota a accuracy m´edia de todas confusion matrix agregadas ao conjunto

de dados estudado. Como s´o temos uma, accuracy e mikro ser˜ao os mesmos.

Figura 2.10: Grafo da ´arvore de decis˜ao relacionada ao conjunto “Titanic”

Outro resultado importante para o nosso trabalho ´e o grafo de ´arvore de decis˜ao.

Considerando o processo de valida¸c˜ao da Subse¸c˜ao 2.1.6, o operador X-Validation tem

mais trˆes portas que n˜ao utilizamos. A primeira porta ave do operador mostra como

resultado uma confusion matrix j´a explicada nos par´agrafos anteriores. Ao conectar a

porta mod deste operador `a porta res da janela de processos e, novamente executarmos

o processo atrav´es da tecla F11, obteremos o grafo da ´arvore de decis˜ao (ver Figura

2.10). Os atributos que aparecem no grafo dentro de blocos retangulares com pontas

21

arredondadas s˜ao chamados de n´os (node). Os atributos que aparecem no grafo dentro

de blocos retangulares n˜ao arredondados s˜ao chamados de folhas. Nas folhas est˜ao os

atributos regidos pela regra label. As setas ligando os n´os e folhas s˜ao chamadas de

arestas (edges). O n´o que n˜ao recebe seta alguma ´e chamado de raiz (root).

Na aba Results, considerando ainda o processo de valida¸c˜ao da Subse¸c˜ao 2.1.6,

temos outra aba chamada description. Nesta aba encontramos uma estrutura denominada

Tree (´arvore em portuguˆes). Uma Tree apresenta o n´umero exato de classiﬁca¸c˜oes que

cada regra que um modelo de ´arvore de decis˜ao tenha gerado. A seguir, apresentamos a

tree gerada pelo processo de classiﬁca¸c˜ao de sobreviventes do Titanic:

Sex = Female

|

|

|

|

|

|

|

|

|

|

|

|

No of Siblings or Spouses on Board > 4.500: No {Yes=0, No=6}

No of Siblings or Spouses on Board <= 4.500

|

|

|

|

|

|

|

|

|

|

No of Parents or Children on Board > 5.500: No {Yes=0, No=2}

No of Parents or Children on Board <= 5.500

|

|

|

|

|

|

|

|

Passenger Class = First: Yes {Yes=139, No=5}

Passenger Class = Second

|

|

|

Age = ?: Yes {Yes=2, No=1}

Age > 56: No {Yes=0, No=2}

Age <= 56: Yes {Yes=92, No=9}

Passenger Class = Third

|

|

Passenger Fare > 32.881: No {Yes=0, No=5}

Passenger Fare <= 32.881: Yes {Yes=106, No=97}

Sex = Male: No {Yes=161, No=682}

2.1.8 Aplicando o modelo

Nesta subse¸c˜ao, mostraremos um processo que aplica um modelo e fornece a pre-

vis˜ao para algum atributo selecionado. Para a melhor compreens˜ao do leitor, apresentare-

mos a imagem do processo e na sequˆencia, o passo a passo de sua constru¸c˜ao. O processo

deve ter a aparˆencia da Figura 2.11.

Figura 2.11: Processo de aplica¸c˜ao de Decision Tree ao conjunto “Exemplo1”

22

Considere o arquivo em formato CSV representado abaixo:

Prova 1,Prova 2,Prova 3,Prova 4,Bolsista,Resultado

9,3,8,1,Sim,Aprovado

6,1,3,5,Sim,Reprovado

4,7,1,1,Sim,Reprovado

9,9,2,10,Sim,

5,2,0,9,Sim,Reprovado

10,9,9,5,N~ao,Aprovado

4,3,10,3,Sim,Aprovado

9,10,5,0,Sim,Aprovado

1,6,6,7,Sim,

3,5,4,7,Sim,

10,4,8,0,Sim,Aprovado

6,0,7,4,Sim,Reprovado

8,3,7,3,Sim,Aprovado

8,0,4,1,N~ao,Reprovado

9,6,9,10,N~ao,Aprovado

5,8,5,2,Sim,Aprovado

1,1,8,1,Sim,Reprovado

4,8,5,6,Sim,

10,10,4,10,N~ao,Aprovado

2,1,10,8,Sim,Aprovado

Observe que alguns dos alunos n˜ao tˆem valor algum no atributo “Resultado”.

Faremos a previs˜ao para tal atributo. Supondo que o arquivo acima esteja no reposit´orio

do Rapidminer com o nome de “Exemplo1”, siga os passos a seguir:

23

• Arraste o conjunto de dados “Exemplo1” para a janela de processos do Rapidminer;

• Repita o passo anterior colocando um segundo conjunto de dados “Exemplo1” na

janela de processos;

• Arraste o operador Filter Examples para a janela de processos;

• Repita o passo anterior ﬁcando com dois operadores Filter Examples e Filter Exam-

ples (2) na janela de processos;

• Conecte a porta out do operador Retrieve Exemplo1 a porta exa do lado esquerdo

do operador Filter Examples;

• Conecte a porta out do operador Retrieve Exemplo1 (2) a porta exa do lado esquerdo

do operador Filter Examples (2);

• Clique no operador Filter Examples;

• Clique no bot˜ao Add Filters;

• Na janela Create Filters: ﬁlters, no primeiro campo escolha Resultado e no segundo

campo escolha is not missing (“n˜ao est´a perdido” em portuguˆes);

• Clique no bot˜ao OK ;

• Clique no operador Filter Examples (2);

• Clique no bot˜ao Add Filters;

• Na janela Create Filters: ﬁlters, no primeiro campo escolha Resultado e no segundo

campo escolha is missing (“est´a perdido” em portuguˆes);

• Clique no bot˜ao OK ;

• Arraste o operador Decision Tree para a janela de processos;

• Conecte a porta exa do lado direito do operador Filter Examples a porta tra do

operador Decision Tree;

• Arraste o operador Apply Model para a janela de processos;

• Conecte a porta mod do operador Decision Tree a porta mod do operador Apply

Model ;

• Conecte a porta exa do operador Filter Examples (2) a porta unl do operador Apply

Model ;

24

• Conecte a porta lab do operador Apply Model a porta res na janela de processos do

Rapidminer;

• Aperte F11 para executar o processo.

Ap´os a execu¸c˜ao do processo, os resultados podem ser analisados atrav´es de uma

tabela fornecida pelo Rapidminer. Para melhor compreens˜ao dos dados, interpretaremos

o exemplo representado na Figura 2.12.

Figura 2.12: Resultado da aplica¸c˜ao de Decision Tree no conjunto “Exemplo1”

Na Figura 2.12, ´e poss´ıvel notar que o atributo “Resultado” n˜ao recebe valor algum

(por isso os sinais de interroga¸c˜ao) e que h´a uma coluna, a saber Prediction (Resultado),

que exibe uma previs˜ao sobre os valores que o atributo “Resultado” poderia receber.

A Figura 2.12 tamb´em apresenta a conﬁan¸ca da predi¸c˜ao do Rapidminer nas colunas

conﬁdence(Aprovado) e conﬁdence(Reprovado). Na linha 1, por exemplo, a conﬁan¸ca de

que o valor do atributo “Resultado” ´e “Reprovado” ´e de 100%. J´a na linha 2, a conﬁan¸ca

de que o valor do atributo “Resultado” ´e “Reprovado” ´e de 9, 1% e de que o valor ´e

“Aprovado” ´e de 90, 9%.

2.1.9 Criando um operador personalizado

Nesta se¸c˜ao, apresentaremos como criar operadores personalizados utilizando o

Python. Antes de mais nada devemos instalar a extens˜ao que permite a cria¸c˜ao de scripts

em Python dentro de um operador. Siga os seguintes passos:

• No menu do Rapidminer, clique em Extensions e depois em MarketPlace;

• No campo Search digite Python. Vocˆe encontrar´a a extens˜ao chamada Python

Scripting;

• Clique na extens˜ao e depois marque a caixa Select for installation;

• Clique no bot˜ao Install 1 packages;

• Marque a caixa I accept the terms of all license agreements;

25

• Clique novamente no bot˜ao em Install 1 packages;

• O programa te perguntar´a se vocˆe deseja reiniciar o Rapidminer para concluir a

instala¸c˜ao, clique no bot˜ao Yes;

• Caso vocˆe tenha algum processo aberto que n˜ao esteja salvo, o programa perguntar´a

se vocˆe deseja salvar seu processo. Caso n˜ao tenha processos para serem salvos,

clique no bot˜ao No. Caso tenha, clique no bot˜ao Yes;

• O Rapidminer se reiniciar´a e a extens˜ao estar´a pronta para utiliza¸c˜ao.

Existem inﬁnitas possibilidades de cria¸c˜ao de operadores de preprocesso, modela-

gem, valida¸c˜ao, aplica¸c˜ao de modelos e visualiza¸c˜ao de resultados. Acreditamos que a me-

lhor maneira de aprender a constru¸c˜ao de processos ´e na pr´atica, portanto apresentaremos

nos par´agrafos que se seguem, como criar um operador personalizado de preprocessamento

dos dados. Considere o seguinte arquivo no formato CSV:

afonso,1,9,8

ana,4,5,7

bruno,1,9,7

lucas,1,3,4

mariana,4,7,9

pedro,1,2,4

tatiane,6,3,6

zenaide,7,2,8

O arquivo acima ´e um arquivo ﬁct´ıcio. Cada linha do arquivo cont´em um nome de

um aluno e a nota que o aluno tirou em trˆes provas. Acrescentaremos uma ´ultima coluna

no conjunto de dados contendo a m´edia das notas de alguns alunos. Para a constru¸c˜ao

do processo representado na Figura 2.13, siga os seguintes passos:

Figura 2.13: Processo com o operador Execute Python

• Adicione o conjunto de dados com o nome de “notas” ao reposit´orio do Rapidminer;

• Arraste o conjunto de dados “notas” para a janela de processos;

• Arraste o operador Execute Python para a janela de processos;

• Conecte a porta out do operador Retrieve notas a porta inp do operador Execute

Python;

• Conecte a porta out do operador Execute Python a porta res da janela de resultados;

• Clique no operador Execute Python e depois no bot˜ao Edit Text na janela de

26

parˆametros;

• Apague todo o script;

• Copie e cole, no lugar do script que foi apagado, o c´odigo em Python abaixo:

import pandas

def rm_main(data):

#transformando dados em dicionario

dicionario = data.to_dict()

# adicionando a chave "media" ao conjunto de dados

dicionario["media"] = {}

# calculando e acrescentando cada media de cada aluno

for i in range(8):

dicionario["media"][i] = ( dicionario["att2"][i] +

dicionario["att3"][i] +

dicionario["att4"][i] ) / 3.0

# transformando o dicionario de volta em dataframe

resultado = pandas.DataFrame(dicionario)

# retornando o conjunto de dados, agora com a media

return resultado

• Clique no bot˜ao Apply;

• Pressione a tecla F11 para executar o processo;

Figura 2.14: Resultado do processo com o operadorExecute Python

27

O resultado do processo pode ser observado na Figura 2.14. Este ´e um simples

exemplo de processo utilizando operadores constru´ıdos com scripts na linguagem Python.

Operadores muito mais elaborados podem ser criados, no entanto a inten¸c˜ao deste trabalho

´e apenas dar uma ideia de como acontece a rela¸c˜ao entre Rapidminer e Python.

2.2

´Arvores de decis˜ao

Nesta se¸c˜ao apresentaremos detalhes do operador Decision Tree. Para trabalhar

com o operador Decision Tree, o conjunto de dados pode ser num´erico ou categ´orico

(atributos que possuem valores textuais em vez de n´umeros), no entanto, a coluna que

desejamos classiﬁcar deve ser categ´orica. Mais ainda, esta mesma coluna deve ser regida

pela regra label. Na se¸c˜ao anterior, vimos como fazer um atributo ser regido pela regra label

tanto na importa¸c˜ao dos dados para o reposit´orio do Rapidminer, quanto no processo,

neste ´ultimo caso usamos o operador Set Role.

Parˆametros de um operador s˜ao simplesmente caracter´ısticas que este possui. As

possibilidades para diversiﬁca¸c˜ao dos parˆametros de um operador podem ser encontradas,

no programa Rapidminer, clicando no operador que est´a na janela de processo e olhando

para a janela Parameters. Como exemplo, a Figura 2.15 apresenta os parˆametros do

operador Decision Tree.

Figura 2.15: Parˆametros do operador Decision Tree

28

O parˆametro criterion determina como particionar o conjunto de dados de acordo

com uma determinada regra de decis˜ao. Os crit´erios dispon´ıveis no Rapidminer s˜ao:

Information gain, Gain ratio, Gini index e Accuracy. Para detalhes sobre cada um destes

crit´erios recomendamos o leitor a leitura do livro Data Mining With Decision Trees dos

autores Rokach and Maimon (2014).

Outro parˆametro que pode ser usado para modiﬁcar o modelo ´e o maximal depth

que estabelece a profundidade m´axima de uma ´arvore, que pode variar dependendo do

tamanho do conjunto de dados. Esse parˆametro ´e utilizado para restringir o tamanho

da ´arvore de decis˜ao e cria¸c˜ao de novas regras para o modelo da ´arvore ´e interrompido

quando a sua profundidade m´axima ´e atingida. Para que a profundidade seja ilimitada,

deve-se atribuir o valor de −1 para este parˆametro.

A aplica¸c˜ao de poda (apply pruning) ´e uma t´ecnica em que folhas s˜ao removidas

com o objetivo de simpliﬁcar o grafo da ´arvore de decis˜ao perdendo o m´ınimo poss´ıvel

de informa¸c˜ao relevante. Isto ´e feito a ﬁm de aumentar a capacidade de classiﬁca¸c˜ao em

conjuntos de dados gigantes. Existem v´arias t´ecnicas de poda, tais como Cost Compexity

Pruning, Reduced Error Pruning, Minimum Error Pruning (MEP), dentre outras apre-

sentadas por Rokach and Maimon (2014). Como nesse trabalho n˜ao alteraremos esses

parˆamentros, deixaremos as caixas apply prunning e apply preprunning marcadas.

29

3 APLICAC¸ ˜OES E RESULTADOS

Neste cap´ıtulo s˜ao estudados dois conjundo de dados para classiﬁca¸c˜ao de estu-

dantes a partir de resultados anteriores. Inicialmente, mostra-se um estudo com dados

coletados no ambiente escolar de duas escolas portuguesas e na sequˆencia, ´e apresentado

outro estudo, com dados coletados em uma Universidade do Canad´a. Os dados podem

ser encontrados, respectivamente no site da Machine Learning Repository com o nome de

Student Performance Data Set e no site da OpenMV.net Datasets com o nome de Class

grades.

3.1 Atributos irrelevantes e alta accuracy

Nesse estudo, usa-se dados coletados no ambiente escolar de duas escolas portu-

guesas, por meio de relat´orios e question´arios. O conjunto de dados usado nesse trabalho

´e o da disciplina de Matem´atica, e ele inclui atributos como notas e caracter´ısticas sociais,

somando 33 no total. A seguir informa¸c˜oes sobre cada um dos atributos. S˜ao eles:

• school – Escola que o aluno estuda (GP para alunos que estudam na escola Gabriel

Pereira ou MS para alunos que estudam na escola Mousinho da Silveira).

• sex - Sexo do aluno (F para aluno do sexo feminino ou M para o sexo masculino).

• age - Idade do aluno (De 15 a 22 anos).

• address - Endere¸co residencial do aluno (U para alunos residentes na zona urbana

ou R para zona rural).

• famsize - Quantidade de pessoas na fam´ılia (LE3 para quantidades menores ou igual

a 3 ou GT3 para superiores a 3).

• Pstatus - Relacionamento dos pais (T para os pais que moram juntos ou A para os

que moram separados).

• Medu - Escolaridade da m˜ae (0 - nenhuma, 1 - ensino fundamental (4a s´erie), 2 –

ensino fundamental (5a `a 9a s´erie), 3 - ensino m´edio ou 4 - ensino superior).

31

• Fedu - Escolaridade do pai (0 - nenhuma, 1 - ensino fundamental (4a s´erie), 2 –

ensino fundamental (5a `a 9a s´erie), 3 - ensino m´edio ou 4 - ensino superior).

• Mjob - Proﬁss˜ao da m˜ae (teacher para professora, health para proﬁss˜oes relacionadas

a sa´ude, services para servi¸cos p´ublicos, at home para proﬁssionais do lar ou other

para outras proﬁss˜oes).

• Fjob - Proﬁss˜ao do pai (teacher para professor, health para proﬁss˜oes relacionadas

a sa´ude, services para servi¸cos p´ublicos, at home para proﬁssionais do lar ou other

para outras proﬁss˜oes).

• reason - Motiva¸c˜ao de escolha da escola (home para alunos que escolheram a escola

devido `a proximidade de casa, reputation para alunos que escolheram a escola pela

boa reputa¸c˜ao, course para alunos que escolheram a escola pela preferˆencia de curso

ou other para outros motivos de escolha).

• guardian - Respons´avel pelo aluno (mother se for a m˜ae, father se for o pai ou other

para qualquer outro respons´avel).

• traveltime - Tempo gasto no deslocamento de casa at´e a escola (1 – menos de 15

min, 2 – de 15 a 30 minutos, 3 - de 30 minutos a 1 hora, ou 4 – mais de 1 hora).

• studytime - Tempo de estudo semanal (1 – menos de 2 horas, 2 – de 2 a 5 horas, 3

- de 5 a 10 horas, ou 4 – mais de 10 horas).

• failures – Quantidade de reprova¸c˜ao (1 – uma reprova¸c˜ao, 2 – duas reprova¸c˜oes, 3 -

trˆes reprova¸c˜oes, ou 4 – quatro ou mais reprova¸c˜oes).

• schoolsup - Apoio escolar extra (yes para os alunos que tiveram o apoio ou no para

os que n˜ao tiveram).

• famsup - Apoio educacional da fam´ılia (yes para os alunos que tiveram o apoio ou

no para os que n˜ao tiveram).

• paid - Aulas extras de matem´atica (yes para os alunos que tiveram aulas extras ou

no para os que n˜ao tiveram).

• activities - Atividades extracurriculares (yes para os alunos que ﬁzeram as atividades

ou no para os que n˜ao ﬁzeram).

• nursery - Frequentou a escola maternal (yes para os alunos que frequentaram a

escola maternal ou no para os que n˜ao frequentaram).

32

• higher – Inten¸c˜ao de cursar o ensino superior (yes para os alunos que pretendem

cursar o Ensino Superior ou no para os que n˜ao pretendem).

• internet – Acesso `a Internet em casa (yes para os alunos que possuem o acesso ou

no para os que n˜ao possuem).

• romantic – Relacionamento amoroso (yes para os alunos que possuem o relaciona-

mento ou no para os que n˜ao possuem).

• famrel - Qualidade das rela¸c˜oes familiares (intervalo inteiro de 1 a 5, onde 1 signiﬁca

rela¸c˜oes muito ruins e 5 muito boas).

• freetime - Tempo livre ap´os a escola (intervalo inteiro de 1 a 5, onde 1 signiﬁca

pouco tempo livre e 5 muito tempo livre).

• goout – Tempo para sair com os amigos (intervalo inteiro de 1 a 5, onde 1 signiﬁca

pouco tempo livre e 5 muito tempo livre).

• Dalc - Consumo de ´alcool durante a semana (intervalo inteiro de 1 a 5, onde 1

signiﬁca nenhum consumo de ´alcool e 5 consumo excessivo).

• Walc - Consumo de ´alcool no ﬁm de semana. (intervalo inteiro de 1 a 5, onde 1

signiﬁca nenhum consumo de ´alcool e 5 consumo excessivo)

• health - Estado de sa´ude atual (intervalo inteiro de 1 a 5, onde 1 signiﬁca estado de

sa´ude muito ruim e 5 muito bom).

• absences - N´umero de faltas escolares (de 0 a 93).

• G1 – Nota total obtida no primeiro per´ıodo do curso (de 0 a 20).

• G2 – Nota total obtida no segundo per´ıodo do curso (de 0 a 20).

• G3 – Nota total obtida no ´ultimo per´ıodo do curso (de 0 a 20).

O atributo escolhido para fazer a previs˜ao, foi o G3 que representa a nota ﬁnal

obtida no ´ultimo per´ıodo do curso. O objetivo do estudo em classiﬁcar os estudantes

de acordo com o desempenho nesse atributo, se deve ao fato da forte correla¸c˜ao com os

atributos G2 e G1. Isso ocorre porque G3 ´e resultado do ´ultimo ano, enquanto G1 e

G2 correspondem `as s´eries anteriores. Como a nota representada pelo atributo G3 varia

entre 0 e 20, os alunos foram classiﬁcados da seguinte maneira:

• A - Para alunos com notas maiores que 16

33

• B - Para alunos com notas acima de 12 e menores ou iguais a 16

• C - Para alunos com notas acima de 8 e menores ou iguais a 12

• D - Para alunos com notas acima de 4 e menores ou iguais a 8

• E - Para alunos com notas menores ou iguais a 4

Neste estudo s˜ao usados os resultados de 350 alunos para prever o resultado dos

outros 45 e para aplicar a minera¸c˜ao dos dados utilizamos o Decision Tree para gerar a

´arvore de decis˜ao.

Inicialmente, a ´arvore foi gerada sem altera¸c˜ao nos parˆametros, ou seja, com valores

deﬁnidos como padr˜ao pelo Rapidminer. Como o conjunto de dados usado nessa an´alise

possui v´arios atributos e muitos alunos, a ´arvore obtida possui muitas regras, o que

ocasiona a complexidade da sua an´alise. Para melhor entendimento, o parˆametro criterion

foi alterado. Para cada uma das quatro op¸c˜oes dispon´ıveis do parˆametro, uma ´arvore

diferente foi gerada. Analisando os modelos, ´e poss´ıvel perceber que o n´o raiz foi o

atributo G2 em todos os modelos.

Isso nos permite concluir que as notas obtidas no

segundo ano do curso s˜ao muito importantes para classiﬁcar os alunos.

Outro fator importante a ser considerado, ´e que dos 32 atributos utilizados para

gerar o grafo da ´arvore, 12 n˜ao apareceram, pois o algoritmo n˜ao considerou esses atributos

relevantes para a classiﬁca¸c˜ao. S˜ao eles: school, address, famsize, Pstatus, Fjob, schoolsup,

paid, activities, nursery, internet, romantic, Dalc.

Com o intuito de encontrar o modelo com a maior accuracy, as quatro op¸c˜oes para

o criterion (Gain ratio, Information gain, Gini index e Accuracy) foram testadas, e em

todas, a an´alise foi realizada com o maximal depth (na Tabela 3.1 representado por DE )

variando do valor m´ınimo ao m´aximo. Observando a Tabela 3.1, pode-se extrair algumas

informa¸c˜oes.

34

Tabela 3.1: Comparativo entre parˆametros no conjunto de dados Student Performance

Data Set

Gain ratio

Information gain

Gini index

Accuracy

DE

76.57% +/- 6.23% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 15

76.86% +/- 6.69% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 14

76.86% +/- 6.69% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 13

75.43% +/- 7.36% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 12

76.86% +/- 6.57% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 11

76.29% +/- 6.77% 77.43% +/- 5.34% 83.43% +/- 3.79% 82.57% +/- 5.78% 10

78.00% +/- 6.65% 77.14% +/- 5.11% 83.43% +/- 3.79% 82.57% +/- 5.78% 9

78.00% +/- 6.27% 78.00% +/- 5.58% 83.43% +/- 3.79% 82.57% +/- 5.78% 8

72.29% +/- 6.79% 79.14% +/- 5.72% 83.43% +/- 3.79% 82.57% +/- 5.78% 7

77.14% +/- 7.00% 78.57% +/- 6.67% 83.43% +/- 4.00% 83.14% +/- 4.51% 6

75.14% +/- 8.19% 81.14% +/- 6.15% 82.86% +/- 4.04% 82.86% +/- 4.61% 5

71.14% +/- 5.92% 77.71% +/- 6.36% 82.57% +/- 5.34% 82.57% +/- 4.86% 4

62.29% +/- 3.93% 71.14% +/- 6.93% 77.43% +/- 2.98% 77.43% +/- 2.98% 3

45.71% +/- 6.56% 61.71% +/- 3.66% 62.86% +/- 2.86% 62.86% +/- 2.86% 2

40.29% +/- 0.86% 40.29% +/- 0.86% 40.29% +/- 0.86% 40.29% +/- 0.86% 1

• Em todas as op¸c˜oes do parˆametro criterion, com a profundidade inferior ou igual

a 5, todas as accuracy decresceram, ou seja, com a profundidade baixa, a precis˜ao

diminuiu.

• Para profundidade m´ınima, todas as accuracy tiveram o mesmo valor (40.29%).

Essa porcentagem foi a menor accuracy obtida na an´alise.

• A maior accuracy conseguida foi 83.43%, usando a op¸c˜ao gini index com a profun-

didade m´axima, que nesse caso ´e 8. Essa accuracy pode ser considerada alta, j´a que,

segundo H¨am¨al¨ainen and Vinni (2010), as taxas m´edias em trabalhos relacionados

ao assunto, s˜ao de 72%.

Vale destacar que o criterion mais usado no Rapidminer ´e o gain ratio, utlizado por

76% dos usu´arios e, nesta an´alise, essa op¸c˜ao com a profundidade m´axima selecionada,

forneceu a menor accuracy dentre todos os criterion.

A ´arvore escolhida para uma an´alise mais detalhada, foi a com maior accuracy. O

grafo dela pode ser observado atrav´es da Figura 3.1

Figura 3.1: Grafo com maior accuracy (Student Performance Data Set)

35

O grafo da ´arvore conﬁrma que o n´o raiz ´e o atributo G2. Nesse caso, acredita-

mos que aulas extras, monitorias e atividades complementares nesse ano do curso pode

interferir nos resultados do ano ﬁnal do curso.

Al´em disso, ´e poss´ıvel perceber que apenas oito atributos apareceram no grafo.

S˜ao eles: G2, absences, traveltime, failures, goout, health, reason, fedu. Dessa forma, para

melhorar os resultados, sugerimos que um trabalho de conscientiza¸c˜ao com os alunos seja

feito. O intuito seria interferir no atributo absences, mostrando para o aluno a importˆancia

de comparecer `a escola todos os dias.

Outra forma que poderia modiﬁcar positivamente os resultados, ´e interferir no

atributo failures, oferecendo uma atividade de refor¸co aos alunos que j´a s˜ao repetentes.

Na sequˆencia ´e poss´ıvel observar a Tree, ou seja, a ´arvore que gerou o grafo da Figura 3.1.

Tree

G2 > 12.500

|

|

G2 > 16.500: A {D=0, C=0, B=0, A=19, E=0}

G2 <= 16.500: B {D=0, C=7, B=86, A=4, E=0}

G2 <= 12.500

36

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

G2 > 8.500: C {D=11, C=123, B=11, A=0, E=7}

G2 <= 8.500

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

|

absences > 1

|

|

|

|

|

|

traveltime > 2.500: C {D=1, C=3, B=0, A=0, E=0}

traveltime <= 2.500

|

|

|

|

failures > 1.500

|

|

goout > 2.500: D {D=4, C=0, B=0, A=0, E=1}

goout <= 2.500: C {D=0, C=3, B=0, A=0, E=0}

failures <= 1.500: D {D=33, C=2, B=0, A=0, E=0}

absences <= 1

|

|

|

|

|

|

|

|

|

G2 > 6.500

|

|

|

|

|

|

|

health > 4.500: D {D=4, C=0, B=0, A=0, E=0}

health <= 4.500

|

|

|

|

|

reason = course: C {D=0, C=2, B=0, A=0, E=1}

reason = home

|

|

Fedu > 2.500: D {D=1, C=0, B=0, A=0, E=1}

Fedu <= 2.500: E {D=0, C=0, B=0, A=0, E=5}

reason = reputation: C {D=0, C=1, B=0, A=0, E=1}

G2 <= 6.500: E {D=0, C=0, B=0, A=0, E=19}

Para uma an´alise mais detalhada, o modelo obtido foi testado com o aux´ılio do

Rapidminer em um conjunto teste com 45 alunos aleat´orios. O resultado desse teste est´a

no Apˆendice A. A seguir, tem-se a Tabela 3.2 com a previs˜ao dada pela plataforma para

cada aluno. Os dados dessa tabela foram retirados das Tabelas A.1 e A.2.

Tabela 3.2: Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

37

Data Set

Row no. Final

prediction

(Res. Final)

15

16

17

18

19

20

21

22

23

24

25

?

?

?

?

?

?

?

?

?

?

?

C

C

B

E

C

C

C

C

C

D

A

conf.(D)

conf.(C)

conf.(B)

conf.(A)

conf.(E)

0,072

0,072

0,000

0,000

0,072

0,072

0,000

0,072

0,072

0,943

0,000

0,809

0,809

0,072

0,000

0,809

0,809

1,000

0,809

0,809

0,057

0,000

0,072

0,072

0,887

0,000

0,072

0,072

0,000

0,072

0,072

0,000

0,000

0,000

0,000

0,041

0,000

0,000

0,000

0,000

0,000

0,000

0,000

1,000

0,046

0,046

0,000

1,000

0,046

0,046

0,000

0,046

0,046

0,000

0,000

Nota-se que algumas previs˜oes s˜ao dadas com 100% de precis˜ao, como nas linhas

18, 21 e 25, por exemplo. Na linha 18, o programa fornece 100% de conﬁan¸ca para que o

aluno obtenha conceito E, na Tabela 3.2 conf.(E). J´a na linha 25, a conﬁan¸ca de 100% ´e

para que o aluno obtenha conceito A, na Tabela 3.2 conf.(A). Nesse caso, sugere-se que o

professor proponha uma parceria entre os dois alunos, de forma que o aluno com previs˜ao

de conceito A, auxilie o aluno com previs˜ao de conceito E, com o intuito de melhorar seu

desempenho na disciplina.

Ap´os a execu¸c˜ao do processo de valida¸c˜ao do modelo, obtivemos a matriz de con-

fus˜ao, que pode ser observada atrav´es da Tabela 3.3.

Tabela 3.3: Resultado da valida¸c˜ao do modelo aplicado ao conjunto de dados Student

Performance Data Set

accuracy:83.43% +/- 3.79% (mikro:83.43%)

True. D True. C True. B True. A True. E Class Precision

Pred. D

Pred. C

Pred. B

Pred. A

Pred. E

38

13

0

0

3

6

124

7

0

4

0

12

85

0

0

0

0

4

19

0

1

8

0

0

26

Class Recall

70.37% 87.94% 87.63% 82.61% 74.29%

84.44%

78.98%

88.54%

100%

78.79%

38

Nota-se que a accuracy foi de 83.43% e o desvio padr˜ao de +/-3.79%. ´E poss´ıvel
perceber que na coluna True. D, tem-se 54 alunos com conceito D, dos quais, o programa

previu 38 corretamente. J´a na coluna True. C, tem-se 141 alunos com esse conceito, dos

quais, o programa previu 124 corretamente. Analogamente, na coluna True. B, h´a 85

alunos previstos corretamente, em um total de 97. Na coluna True. A, foram previstos

19 corretamente, de um total de 23 alunos j´a na coluna True E, de um total de 35 alunos,

26 foram previstos corretamente.

Uma informa¸c˜ao importante a ser considerada, ´e a previs˜ao do conceito A, que

foi de 100%. Nesse caso, podemos usar tal fato para selecionar alunos que possam ser

monitores da disciplina de Matem´atica.

3.2

Informa¸c˜oes ´uteis e baixa accuracy

Neste estudo, o objetivo ´e fornecer ao leitor informa¸c˜oes ´uteis, mesmo quando o

modelo tiver uma baixa accuracy. O conjunto de dados utilizados foi coletado em um

curso de Engenharia Qu´ımica da Universidade McMaster dispon´ıvel em Datasets (2011).

Ele possui seis atributos e dados de 99 alunos. A seguir, tem-se os atributos e seus

signiﬁcados.

• Preﬁx - Esse atributo ´e um preﬁxo que indica o ano em que o aluno fez a primeira

matr´ıcula na Universidade.

• Assignment - Esse atributo possui valores que representam a m´edia das notas de

todas as tarefas realizadas pelos alunos.

• Tutorial - Esse atributo possui valores que representam a m´edia das notas de par-

ticipa¸c˜ao em todos os tutoriais realizados.

• Midterm – Esse atributo fornece a nota obtida pelos alunos em uma avalia¸c˜ao rea-

lizada aproximadamente no meio do curso.

• TakeHome – Esse atributo fornece as notas da avalia¸c˜ao realizada em casa.

• Final – Esse atributo representa a m´edia de todas as perguntas da avalia¸c˜ao ﬁnal,

uma prova escrita.

Esse curso permite que os alunos trabalhem em grupos para tarefas, tutoriais e no

exame realizado em casa. Para isso, os grupos foram selecionados e variados durante o

semestre.

O objetivo da an´alise ´e descobrir o quanto os atributos s˜ao bons indicadores do

desempenho do aluno na avalia¸c˜ao ﬁnal, atributo escolhido para fazer a previs˜ao. Como a

nota da avalia¸c˜ao ﬁnal varia entre 28.06 e 108.9, os alunos foram classiﬁcados da seguinte

maneira:

39

• A - Para alunos com notas maiores que 100

• B - Para alunos com notas acima de 80 e menores ou iguais a 100

• C - Para alunos com notas acima de 60 e menores ou iguais a 80

• D - Para alunos com notas acima de 40 e menores ou iguais a 60

• E - Para alunos com notas menores ou iguais a 40

Nessa an´alise s˜ao usados os resultados de 79 alunos para prever o resultado dos

outros 20, e para aplicar a minera¸c˜ao dos dados utilizamos o Decision Tree para gerar a

´arvore de decis˜ao.

Na Tabela 3.4, tem-se os resultados das valida¸c˜oes dos modelos gerados, usando

as quatro op¸c˜oes do parˆametro criterion (Gain ratio, Information gain, Gini index e

accuracy) e variando o parˆametro maximal depth (representado na Tabela 3.4 por DE)

da profundidade m´axima `a m´ınima.

40

Tabela 3.4: Comparativo entre parˆametros no conjunto de dados Class grades

Gain ratio

Information gain

Gini index

Accuracy

DE

31.61% +/- 21.02% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 19

32.86% +/- 20.97% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 18

32.86% +/- 20.97% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 17

31.61% +/- 21.75% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 16

32.96% +/- 20.97% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 15

32.86% +/- 22.41% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 14

34.29% +/- 21.11% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 13

32.86% +/- 22.41% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 12

29.11% +/- 20.97% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 11

30.36% +/- 20.25% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 10

29.11% +/- 20.92% 40.54% +/- 12.24% 39.46% +/- 14.91% 50.71% +/- 16.91% 9

33.04% +/- 23.35% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 8

31.61% +/- 23.81% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 7

39.29% +/- 21.28% 39.29% +/- 11.85% 39.46% +/- 14.91% 50.71% +/- 16.91% 6

40.54% +/- 18.37% 40.71% +/- 18.88% 39.46% +/- 17.78% 46.96% +/- 16.17% 5

44.29% +/- 15.93% 41.96% +/- 17.32% 43.21% +/- 13.33% 46.96% +/- 12.95% 4

46.79% +/- 15.65% 38.04% +/- 16.85% 40.54% +/- 12.24% 45.71% +/- 13.20% 3

36.61% +/- 15.03% 46.96% +/- 10.26% 49.46% +/- 7.19% 48.21% +/- 8.03%

25.36% +/- 1.07% 25.36% +/- 1.07% 25.36% +/- 1.07% 25.36% +/- 1.07%

2

1

O modelo com a maior accuracy foi conseguido com a op¸c˜ao accuracy do parˆametro

criterion, com o maximal depth na profundidade m´axima, que no caso desse modelo ´e 6,

o que pode ser observado no grafo da ´arvore na Figura 3.2 .

Figura 3.2: Grafo com maior accuracy (Class grades)

41

Nota-se que o n´o raiz ´e o atributo Midterm e que todos os atributos foram utilizados

para a constru¸c˜ao da ´arvore. Acreditamos que uma interferˆencia positiva poderia ocorrer

adotando uma medida que melhorasse os resultados da avalia¸c˜ao realizada no meio do

curso. Sugerimos ao professor que medidas como listas complementares, trabalhos em

grupos e refor¸co extraclasse, sejam tomadas para a prepara¸c˜ao dessa prova.

Tree

Midterm > 75.625

|

|

Midterm > 100.315: A {D=0, C=0, B=1, E=0, A=3}

Midterm <= 100.315: B {D=1, C=4, B=16, E=0, A=2}

Midterm <= 75.625

|

|

|

|

|

Tutorial > 89.640

|

|

|

|

Midterm > 42.500

|

|

|

TakeHome > 31.875

|

|

TakeHome > 100.830: B {D=0, C=1, B=2, E=0, A=0}

TakeHome <= 100.830: C {D=4, C=13, B=0, E=1, A=0}

42

|

|

|

|

|

|

|

|

|

|

TakeHome <= 31.875: D {D=2, C=0, B=0, E=1, A=0}

Midterm <= 42.500: D {D=2, C=0, B=0, E=1, A=0}

Tutorial <= 89.640

|

|

|

|

Prefix > 7.500

|

|

Assignment > 79.485: D {D=3, C=1, B=0, E=1, A=0}

Assignment <= 79.485: C {D=0, C=4, B=1, E=1, A=0}

Prefix <= 7.500: D {D=12, C=2, B=0, E=0, A=0}

O modelo representado pela Tree acima ´e obtido atrav´es do operador Decision

Tree aplicado ao conjunto de dados estudado. O professor pode utilizar este modelo para

classiﬁcar novos estudantes atrav´es de operadores espec´ıﬁcos do Rapidminer (ver Subse¸c˜ao

2.1.8) e, tamb´em, com programas em Python (ver Apˆendice B).

Ainda com o aux´ılio do Rapidminer, fez-se uma aplica¸c˜ao do modelo obtido para

testar a conﬁan¸ca dos resultados. Os 99 alunos analisados foram separados em duas

partes: 79 alunos com os resultados ﬁnais obtidos e 20 com uma coluna vazia para que o
programa forne¸ca a previs˜ao do label em cada linha. ´E poss´ıvel perceber, na Tabela 3.5,
os 20 alunos que n˜ao possuem o resultado. A Tabela completa encontra-se no Apˆendice

A dividida em duas partes (Tabela A.3 e Tabela A.4).

Tabela 3.5: Resultado da aplica¸c˜ao do modelo com maior accuracy no conjunto Class

43

grades

Row no. Final

Previs˜ao(Res.

Final)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

C

C

D

C

B

C

D

C

C

B

C

B

C

D

C

C

C

C

C

C

conf.(D)

conf.(C)

conf.(B)

conf.(E)

conf.(A)

0,417

0,417

0,500

0,000

0,000

0,417

1,000

0,000

0,000

0,000

0,417

0,000

0,000

0,500

0,417

0,000

0,417

0,000

0,417

0,417

0,472

0,472

0,000

0,500

0,000

0,472

0,000

0,500

1,000

0,000

0,472

0,000

1,000

0,000

0,472

1,000

0,472

0,500

0,472

0,472

0,056

0,056

0,000

0,500

1,000

0,056

0,000

0,500

0,000

1,000

0,056

0,500

0,000

0,500

0,056

0,000

0,056

0,500

0,056

0,056

0,056

0,056

0,500

0,000

0,000

0,056

0,000

0,000

0,000

0,000

0,056

0,000

0,000

0,000

0,056

0,000

0,056

0,000

0,056

0,056

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,500

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

Nota-se que o atributo Final ainda n˜ao tem nenhum valor. Mas h´a uma nova

coluna, Previs˜ao (Res. Final), que exibe uma previs˜ao sobre a classiﬁca¸c˜ao do aluno,

de A at´e E, com base nas regras da ´arvore de decis˜ao. Al´em da previs˜ao, os resultados

tamb´em relatam a conﬁan¸ca da predi¸c˜ao do Rapidminer. Na linha 3, por exemplo, tendo

em conta os outros atributos, com base nas regras do modelo, h´a uma chance de 50%

que o aluno obtenha conceito D, na Tabela 3.5 conf.(D), e 50% de chance de que ele

tenha conceito E, na Tabela 3.5 conf.(D). Seja D ou E, o resultado desse aluno pode ser

melhorado com uma interven¸c˜ao do professor, como por exemplo, aulas de refor¸co. J´a

na linha 10, o modelo fornece 100% de conﬁan¸ca no resultado do aluno ser conceito B,

na Tabela 3.5 conf.(B). Nesse caso, o aluno pode ser selecionado para trabalhar como

monitor e auxiliar o professor a ajudar os alunos com mais diﬁculdade.

44

Na Tabela 3.6, temos o resultado da valida¸c˜ao do modelo selecionado para an´alise.

A accuracy foi de 50.71% e o desvio padr˜ao de +/- 16.91%. Percebe-se que na coluna

True. D (Tabela 3.6), tem-se 24 alunos com conceito D, dos quais, o programa previu

11 corretamente. J´a na coluna True. C, tem-se 25 alunos com esse conceito, dos quais,

o programa previu 13 corretamente. Analogamente, na coluna True. B, h´a 13 alunos

previstos corretamente, em um total de 20. Na coluna True. E, h´a um total de 5 alunos,

mas nenhum foi previsto corretamente. Na coluna True. A, de um total de 5 alunos, 3

foram previstos corretamente.

Tabela 3.6: Resultado da valida¸c˜ao do modelo aplicado ao conjunto de dados Class grades

accuracy:50.71% +/- 16.91% (mikro:50.63%)

True. D True. C True. B True. E True. A Class Precision

Pred. D

Pred. C

Pred. B

Pred. E

Pred. A

11

11

1

1

0

8

13

4

0

0

0

3

13

0

4

3

2

0

0

0

0

0

2

0

3

Class Recall

45.83% 52.00% 65.00%

0.00% 60.00%

50.00%

44.83%

65.00%

0.00%

42.86%

Um fato importante a considerar, ´e que a melhor previs˜ao apareceu no conceito

B. Tal fato, pode ser utilizado para classiﬁca¸c˜ao de alunos com possibilidades de receber

bolsas de estudo. Esses alunos tamb´em poderiam tornarem-se tutores dos grupos de

estudos propostos anteriormente, para melhorar o resultado da avalia¸c˜ao realizada no

meio do curso.

O modelo ter precis˜ao baixa ´e um fato que pode acontecer com qualquer professor e

para melhorar a accuracy sugere-se que a quantidade de dados da amostra seja aumentado,

assim como, aumentar a quantidade de atributos tamb´em pode ajudar a melhorar a

situa¸c˜ao Gottardo et al. (2012).

Com o intuito de aumentar a accuracy, classiﬁcamos os alunos de uma forma

diferente. O conjunto de dados, assim como, todos os atributos foram mantidos, por´em a

nova classiﬁca¸c˜ao foi feita da seguinte maneira:

• Aprovado - Para alunos com notas superiores ou iguais a 60% do total.

• Reprovado - Para alunos com notas inferiores a 60% do total.

Nessa nova an´alise, como na anterior, foram usados os resultados de 79 alunos

para prever o resultado dos outros 20, e utilizamos novamente o Decision Tree para gerar

45

a ´arvore. Os parˆametros criterion e maximal depth foram alterados com a inten¸c˜ao de

encontrar o modelo com a maior accuracy, que foi obtido com o criterion na op¸c˜ao Gain

ratio e o maximal depth na profundidade m´axima. O grafo da ´arvore encontrada pode

ser observado na Figura 3.3.

Figura 3.3: Grafo com maior accuracy (Class grades com reclassiﬁca¸c˜ao)

Assim como no grafo da Figura 3.2, nesse, o n´o-raiz foi o atributo Midterm e todos

os outros atributos foram utilizados para a constru¸c˜ao da ´arvore. Caso seja de interesse

do leitor analisar uma ´arvore menor, o parˆametro maximal depth pode ser alterado, e para

o conjunto de dados em quest˜ao, diminuir esse parˆametro n˜ao inﬂuenciou a accuracy. Na

Figura 3.4, apresentamos o grafo da ´arvore com profundidade 6, de tal maneira que os

atributos Take Home e Preﬁx foram omitidos, e o n´o-raiz Midterm foi mantido.

Figura 3.4: Maior accuracy (Class grades com reclassiﬁca¸c˜ao e profundidade menor)

46

Na tentativa de facilitar a interpreta¸c˜ao do modelo, mostramos que ´e poss´ıvel

reduzir o tamanho da ´arvore, sem alterar a accuracy, o que pode ser uma ferramenta ´util

para o professor. O resultado da valida¸c˜ao dos modelos pode ser observado na Tabela 3.7.

Tabela 3.7: Resultado da valida¸c˜ao do modelo aplicado ao conjunto Class grades com

uma reclassiﬁca¸c˜ao

accuracy:76.07% +/- 10.20% (mikro:75.95%)

True. Reprovado True. Aprovado Class Precision

Pred. Reprovado

Pred. Aprovado

36

1

18

24

66.67%

96.00%

Class Recall

97.30%

57.14%

Nota-se que a accuracy foi de 76% e o desvio padr˜ao de +/- 10.20%. Comparando

com a valida¸c˜ao do modelo anterior, exibida na Tabela 3.6, podemos perceber que houve

uma melhora signiﬁcativa. Assim, o objetivo de aumentar a accuracy, alterando a ma-

neira de classiﬁcar os alunos, foi atingido. Sugerimos ent˜ao, que para melhorar modelos

com baixa accuracy, o leitor modiﬁque a maneira de classiﬁcar os alunos, isso pode al-

terar a accuracy de maneira positiva. Analisando um pouco mais a tabela, nota-se que

dos 37 alunos reprovados, o programa previu 36 corretamente, o que pode favorecer `as

interven¸c˜oes para os alunos em risco de reprova¸c˜ao. Como possibilidade de interven¸c˜ao,

sugerimos que o professor utilize medidas j´a citadas anteriormente, como: monitorias,

listas complementares, acompanhamento individual e outros.

47

4 CONSIDERAC¸ ˜OES FINAIS

Neste trabalho, apresentamos dois exemplos para classiﬁca¸c˜ao de estudantes a

partir de resultados anteriores. Neles usamos o desempenho dos estudantes para detectar

precocemente as falhas e os potenciais dos alunos, e a partir desses resultados, determinar

uma a¸c˜ao que possa impactar no aprendizado do aluno. Utilizou-se ´arvores de decis˜ao

para classiﬁca¸c˜ao dos alunos de acordo com o resultado ﬁnal, com base em atributos

dispon´ıveis em bancos de dados reais. Para tal, o Rapidminer, programa usado para

cria¸c˜ao das ´arvores, apresentou simples manuseio, pois dispensa conhecimento de qualquer

linguagem de programa¸c˜ao, e f´acil acessibilidade, pois ´e um software livre. Devido ao

n´umero de informa¸c˜oes relevantes retiradas dos modelos criados, em modelos com alta

e baixa accuracy, conclui-se que as ´arvores de decis˜ao s˜ao importantes ferramentas para

aux´ılio did´atico e pedag´ogico do professor, tanto de ensino superior, como de ensino

m´edio. Sugere-se a cria¸c˜ao de projetos de apoio e interven¸c˜ao did´atica e pedag´ogica nos

grupos classiﬁcados como grupos de risco como op¸c˜ao para amenizar as diﬁculdades dos

estudantes e melhorar a qualidade do ensino.

Para um trabalho futuro, pode-se estender a experiˆencia usando-se outras t´ecnicas

de minera¸c˜ao de dados para classiﬁca¸c˜ao de alunos com altos ´ındices de reprova¸c˜ao.

Avaliar interven¸c˜oes did´aticas e pedag´ogicas em grupos classiﬁcados como de risco,

´e muito importante para solidiﬁcar o uso de ferramentas de minera¸c˜ao de dados nas escolas

e universidades brasileiras.

Referˆencias Bibliogr´aﬁcas

Qasem A Al-Radaideh, AA Ananbeh, and Emad M Al-Shawakfa. A classiﬁcation model

for predicting the suitable study track for school students. Int. J. Res. Rev. Appl. Sci,

8(2):247–252, 2011.

Ryan Baker, Seiji Isotani, and Adriana Carvalho. Minera¸cao de dados educacionais:

Oportunidades para o brasil. Revista Brasileira de Inform´atica na Educa¸c˜ao, 19(02):

03, 2011.

Brijesh Kumar Baradwaj and Saurabh Pal. Mining educational data to analyze students’

performance. arXiv preprint arXiv:1201.3417, 2012.

Michael J Berry and Gordon Linoﬀ. Data mining techniques: for marketing, sales, and

customer support. John Wiley & Sons, Inc., 1997.

Alfredo Nazareno P Boente, Ronaldo R Goldschmidt, Vˆania Vieira Estrela, and Estadual

da Zona Oeste. Uma metodologia de suporte ao processo de descoberta de conhecimento

em bases de dados. 2008.

Peter Cabena, Pablo Hadjinian, Rolf Stadler, Jaap Verhees, and Alessandro Zanasi. Dis-

covering data mining: from concept to implementation. Prentice-Hall, Inc., 1998.

Ming-Syan Chen, Jiawei Han, and Philip S. Yu. Data mining: an overview from a database

perspective.

IEEE Transactions on Knowledge and data Engineering, 8(6):866–883,

1996.

Luiza Maria Oliveira Da Silva. Uma aplica¸c˜ao de ´arvores de decis˜ao, redes neurais e KNN

para a identiﬁca¸c˜ao de modelos ARMA n˜ao-sazonais e sazonais. PhD thesis, PUC-Rio,

2005.

OpenMV.net Datasets.

Class grades, 2011.

URL http://openmv.net/info/

class-grades. Acessado em: 10/08/2016.

50

Douglas Detoni, Ricardo Matsumura Araujo, and Cristian Cechinel. Predi¸c˜ao de re-

prova¸c˜ao de alunos de educa¸c˜ao a distˆancia utilizando contagem de intera¸c˜oes.

In

Anais do Simp´osio Brasileiro de Inform´atica na Educa¸c˜ao, volume 25, page 896, 2014.

Alaa El-Halees. Mining students data to analyze e-learning behavior: A case study.

Department of Computer Science, Islamic University of Gaza PO Box, 108, 2009.

Usama Fayyad, Gregory Piatetsky-Shapiro, and Padhraic Smyth. From data mining to

knowledge discovery in databases. AI magazine, 17(3):37, 1996.

Rozelma Soares Fran¸ca and Haroldo Jos´e Costa do Amaral. Minera¸c˜ao de dados na

identiﬁca¸c˜ao de grupos de estudantes com diﬁculdades de aprendizagemno ensino de

programa¸c˜ao. RENOTE, 11(1), 2013.

Jo˜ao Gama, Pedro Medas, Pedro Rodrigues, and FEP LIACC. Concept drift in decision-

tree learning for data streams. In Proceedings of the Fourth European Symposium on

Intelligent Technologies and their implementation on Smart Adaptive Systems, Aachen,

Germany, Verlag Mainz, pages 218–225, 2004.

Diego Garcıa-Saiz and Marta Zorrilla. Comparing classiﬁcation methods for predicting

distance students’ performance. In Proceedings of the International Workshop on Ap-

plications of Pattern Analysis (to appear), 2011.

Ronaldo Goldschmidt and Emmanuel Passos. Data Mining: um guia pr´atico. Gulf Pro-

fessional Publishing, 2005.

Ernani Gottardo, Celso Kaestner, and Robinson Vida Noronha. Avalia¸c˜ao de desempenho

de estudantes em cursos de educa¸c˜ao a distˆancia utilizando minera¸c˜ao de dados. In

Anais do Workshop de Desaﬁos da Computa¸c˜ao Aplicada `a Educa¸c˜ao, pages 30–39,

2012.

Wilhelmiina H¨am¨al¨ainen and Mikko Vinni. Classiﬁers for educational data mining. Hand-

book of Educational Data Mining, Chapman & Hall/CRC Data Mining and Knowledge

Discovery Series, pages 57–71, 2010.

Jiawei Han, Jian Pei, and Micheline Kamber. Data mining: concepts and techniques.

Elsevier, 2011.

Dorina Kabakchieva. Predicting student performance by using data mining methods for

classiﬁcation. Cybernetics and information technologies, 13(1):61–72, 2013.

51

Irfan Ajmal Khan and Jin Tak Choi. An application of educational data mining (edm)

technique for scholarship prediction. International Journal of Software Engineering and

Its Applications, 8(12):31–42, 2014.

Zlatko Kovacic. Early prediction of student success: Mining students’ enrolment data.

2010.

Laci Mary Barbosa Manh˜aes, S´ergio Manuel Serra da Cruz, Raimundo J Mac´ario Costa,

Jorge Zavaleta, and Geraldo Zimbr˜ao. Previs˜ao de estudantes com risco de evas˜ao utili-

zando t´ecnicas de minera¸c˜ao de dados. In Anais do Simp´osio Brasileiro de Inform´atica

na Educa¸c˜ao, volume 1, 2011.

Tom M Mitchell. Machine learning., chapter evaluating hypotheses. WCB/McGraw-Hill,

pages 128–153, 1997.

Luis F de S Moro, Carla L Rodrigues, Fernando RH Andrade, Alexandre CB Delbem, and

Seiji Isotani. Caracteriza¸c˜ao de alunos em ambientes de ensino online: Estendendo o uso

da damicore para minerar dados educacionais. In Anais dos Workshops do Congresso

Brasileiro de Inform´atica na Educa¸c˜ao, volume 3, page 631, 2014.

Ashutosh Nandeshwar and Subodh Chaudhari. Enrollment prediction models using data

mining. Retrieved January, 10:2010, 2009.

Taiane S Prass, S´ılvia RC Lopes, Jos´e G D´orea, Rejane C Marques, and Katiane G

Brandao. Amazon forest ﬁres between 2001 and 2006 and birth weight in porto velho.

Bulletin of environmental contamination and toxicology, 89(1):1–7, 2012.

Rapidminer, 2006. URL https://rapidminer.com. Acessado em: 20/04/2016.

Machine Learning Repository.

Student performance data set,

2014.

URL

https://archive.ics.uci.edu/ml/datasets/Student+Performance#.

Acessado

em: 03/08/2016.

Lior Rokach and Oded Maimon. Data mining with decision trees - theory and applications,

volume 81. World Scientiﬁc, 2 edition, 2014.

Crist´obal Romero, Sebasti´an Ventura, Pedro G Espejo, and C´esar Herv´as. Data mining

algorithms to classify students. In Educational Data Mining 2008, 2008.

Cristobal Romero, Sebastian Ventura, Mykola Pechenizkiy, and Ryan SJD Baker. Hand-

book of educational data mining. CRC Press, 2010.

52

Henrique Santos, Fabiane Camargo, and Sandro Camargo. Minerando dados de ambientes

virtuais de aprendizagem para predi¸c˜ao de desempenho de estudantes. Conferencias

LACLO, 3(1), 2012.

Cybele T. M. Vinagre, Renata R. Del Vecchio, and Jo˜ao B. Carvalho. introdu¸c˜ao `a teoria

espectral de grafos e aplica¸c˜oes. 2004.

Ian H Witten, Eibe Frank, Leonard E Trigg, Mark A Hall, Geoﬀrey Holmes, and Sally Jo

Cunningham. Weka: Practical machine learning tools and techniques with java imple-

mentations. 1999.

A Tabelas de aplica¸c˜ao

A seguir tem-se a aplica¸c˜ao do modelo obtido para testar a conﬁan¸ca dos resultados

de 45 alunos do conjunto de dados Student Performance Data Set. Nessa aplica¸c˜ao, o

Rapidminer fornece uma tabela com 40 colunas. S˜ao elas:

• Uma coluna com a numera¸c˜ao das linhas

• Uma coluna vazia que representa o resultado ﬁnal do aluno

• Uma coluna com a previs˜ao do resultado ﬁnal do aluno

• Cinco colunas com a conﬁan¸ca da previs˜ao do Resultado Final

• Trinta e duas colunas com os valores dos atributos

A ﬁm de visualizar apenas os resultados fornecidos pelo programa, as colunas com

os atributos listados na Se¸c˜ao 3.1 do Cap´ıtulo 3 foram retiradas da tabela original. Para

uma melhor visualiza¸c˜ao a tabela foi dividida em duas partes: Tabela A.1 e Tabela A.2.

Tabela A.1: Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

54

Data Set - parte 1

Row no. Final

prediction(Res.

Final)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

C

B

D

C

C

C

B

C

C

B

B

C

C

B

C

C

B

E

C

C

conf.(D)

conf.(C)

conf.(B)

conf.(A)

conf.(E)

0,250

0,000

0,943

0,250

0,072

0,072

0,000

0,072

0,072

0,000

0,000

0,072

0,072

0,000

0,072

0,072

0,000

0,000

0,072

0,072

0,750

0,072

0,057

0,750

0,809

0,809

0,072

0,809

0,809

0,072

0,072

0,809

0,809

0,072

0,809

0,809

0,072

0,000

0,809

0,809

0,000

0,887

0,000

0,000

0,072

0,072

0,887

0,072

0,072

0,887

0,887

0,072

0,072

0,887

0,072

0,072

0,887

0,000

0,072

0,072

0,000

0,041

0,000

0,000

0,000

0,000

0,041

0,000

0,000

0,041

0,041

0,000

0,000

0,041

0,000

0,000

0,041

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,046

0,046

0,000

0,046

0,046

0,000

0,000

0,046

0,046

0,000

0,046

0,046

0,000

1,000

0,046

0,046

Tabela A.2: Resultado da aplica¸c˜ao do Decision Tree ao conjunto Student Performance

Data Set - parte 2

Row no. Final

prediction(Res.

Final)

conf.(D)

conf.(C)

conf.(B)

conf.(A)

conf.(E)

55

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

C

C

C

D

A

C

B

C

B

C

B

D

C

E

D

C

C

E

C

E

C

B

D

C

C

0,000

0,072

0,072

0,943

0,000

0,250

0,000

0,072

0,000

0,072

0,000

0,943

0,072

0,000

0,943

0,072

0,250

0,000

0,072

0,000

0,072

0,000

0,800

0,072

0,072

1,000

0,809

0,809

0,057

0,000

0,750

0,072

0,809

0,072

0,809

0,072

0,057

0,809

0,000

0,057

0,809

0,750

0,000

0,809

0,000

0,809

0,072

0,000

0,809

0,809

0,000

0,072

0,072

0,000

0,000

0,000

0,887

0,072

0,887

0,072

0,887

0,000

0,072

0,000

0,000

0,072

0,000

0,000

0,072

0,000

0,072

0,887

0,000

0,072

0,072

0,000

0,000

0,000

0,000

1,000

0,000

0,041

0,000

0,041

0,000

0,041

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,041

0,000

0,000

0,000

0,000

0,046

0,046

0,000

0,000

0,000

0,000

0,046

0,000

0,046

0,000

0,000

0,046

1,000

0,000

0,046

0,000

1,000

0,046

1,000

0,046

0,000

0,200

0,046

0,046

Na sequˆencia tem-se o resultado da aplica¸c˜ao do modelo obtido para testar a

conﬁan¸ca dos dados de 20 alunos do conjunto de dados Class grades, usado na Se¸c˜ao

3.2 do Cap´ıtulo 3. Para melhor visualiza¸c˜ao, os dados foram divididos em duas partes:

Tabela A.3 e Tabela A.4.

Tabela A.3: Resultado da aplica¸c˜ao do Decision Tree no conjunto de dados Class grades

56

- parte 1

Row no. Final

Previs˜ao(Res.

Final)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

?

C

C

D

C

B

C

D

C

C

B

C

B

C

D

C

C

C

C

C

C

conf.(D)

conf.(C)

conf.(B)

conf.(E)

conf.(A)

0,417

0,417

0,500

0,000

0,000

0,417

1,000

0,000

0,000

0,000

0,417

0,000

0,000

0,500

0,417

0,000

0,417

0,000

0,417

0,417

0,472

0,472

0,000

0,500

0,000

0,472

0,000

0,500

1,000

0,000

0,472

0,000

1,000

0,000

0,472

1,000

0,472

0,500

0,472

0,472

0,056

0,056

0,000

0,500

1,000

0,056

0,000

0,500

0,000

1,000

0,056

0,500

0,000

0,500

0,056

0,000

0,056

0,500

0,056

0,056

0,056

0,056

0,500

0,000

0,000

0,056

0,000

0,000

0,000

0,000

0,056

0,000

0,000

0,000

0,056

0,000

0,056

0,000

0,056

0,056

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,500

0,000

0,000

0,000

0,000

0,000

0,000

0,000

0,000

Tabela A.4: Resultado da aplica¸c˜ao do Decision Tree no conjunto de dados Class grades

- parte 2

Row no. Preﬁx Assignment Tutorial Midterm TakeHome

57

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

8,00

6,00

8,00

8,00

4,00

6,00

4,00

6,00

7,00

7,00

8,00

8,00

8,00

7,00

8,00

8,00

7,00

8,00

7,00

8,00

63,40

90,74

71,79

97,33

86,86

95,60

87,93

98,49

74,35

86,29

97,00

97,33

96,41

95,60

87,52

96,73

85,34

89,94

95,60

63,40

86,21

89,64

102,87

106,74

62,64

61,40

99,47

95,43

92,93

88,81

100,52

106,74

103,71

82,28

91,58

103,71

80,54

102,77

76,13

97,37

63,12

61,25

41,88

76,88

92,50

64,38

53,12

42,50

86,25

83,12

64,38

81,25

56,25

76,88

56,25

45,00

41,25

87,50

66,25

73,12

72,78

90,00

24,77

108,89

85,19

99,81

87,96

24,77

78,70

77,96

90,74

108,89

95,93

108,33

71,85

93,52

93,70

90,74

99,81

72,78

B Classiﬁca¸c˜ao de novos estudantes

via Python

Considere a seguinte Tree:

Tree

Midterm > 75.625

|

|

Midterm > 100.315: A {D=0, C=0, B=1, E=0, A=3}

Midterm <= 100.315: B {D=1, C=4, B=16, E=0, A=2}

Midterm <= 75.625

|

|

|

|

|

|

|

|

|

|

|

|

Tutorial > 89.640

|

|

|

|

|

|

Midterm > 42.500

|

|

|

|

TakeHome > 31.875

|

|

TakeHome > 100.830: B {D=0, C=1, B=2, E=0, A=0}

TakeHome <= 100.830: C {D=4, C=13, B=0, E=1, A=0}

TakeHome <= 31.875: D {D=2, C=0, B=0, E=1, A=0}

Midterm <= 42.500: D {D=2, C=0, B=0, E=1, A=0}

Tutorial <= 89.640

|

|

|

|

Prefix > 7.500

|

|

Assignment > 79.485: D {D=3, C=1, B=0, E=1, A=0}

Assignment <= 79.485: C {D=0, C=4, B=1, E=1, A=0}

Prefix <= 7.500: D {D=12, C=2, B=0, E=0, A=0}

Neste apˆendice, apresentaremos o script em Python para classiﬁca¸c˜ao de novos

estudantes. O leitor notar´a como a linguagem se adequa a Tree de maneira intuitiva

devido ao seu alto n´ıvel.

def classificarEstudante( Midterm,Tutorial,TakeHome,Prefix,Assignment):

if Midterm > 75.625:

if Midterm > 100.315: return "A"

if Midterm <= 100.315: return "B"

if Midterm <= 75.625:

59

if Tutorial > 89.640:

if Midterm > 42.500:

if TakeHome > 31.875:

if TakeHome > 100.830: return "B"

if TakeHome <= 100.830: return "C"

if TakeHome <= 31.875: return "D"

if Midterm <= 42.500: return "D"

if Tutorial <= 89.640:

if Prefix > 7.500:

if Assignment > 79.485: return "D"

if Assignment <= 79.485: return "C"

if Prefix <= 7.500: return "D"

Para classiﬁcar um novo estudante basta atribuir valores para as vari´aveis Midterm,

Tutorial, TakeHome, Preﬁx e Assignment. Por exemplo:

print(classificarEstudante( Midterm = 70.0, Tutorial=85.0, TakeHome=40.0,

Prefix=8.0, Assignment=70.0 ) )

Os c´odigos acima podem ser executados nas vers˜oes 2.7 e 3.5 do Python.


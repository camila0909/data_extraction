UNIVERSIDADE FEDERAL DO RECÔNCAVO DA BAHIA
CENTRO DE CIÊNCIAS EXATAS E TECNOLÓGICAS
MESTRADO PROFISSIONAL EM MATEMÁTICA EM
REDE NACIONAL

JOILSON DE LIMA SILVA

O Problema de Transporte sob as Perspectivas da

Programação Linear e da Teoria do Transporte Ótimo

CRUZ DAS ALMAS - BAHIA

Fevereiro de 2022

JOILSON DE LIMA SILVA

O Problema de Transporte sob as Perspectivas da

Programação Linear e da Teoria do Transporte Ótimo

Dissertação apresentada ao Mestrado Proﬁssional em
Matemática em Rede Nacional do Centro de Ciências
Exatas e Tecnológicas da Universidade Federal do
Recôncavo da Bahia como parte dos requisitos para a
obtenção do título de Mestre em Matemática.

Orientador: Prof. Dr. João Tiago Assunção Gomes

CRUZ DAS ALMAS - BAHIA

Fevereiro de 2022

                              FICHA CATALOGRÁFICA    Ficha elaborada pela Biblioteca Central de Cruz das Almas - UFRB. Responsável pela Elaboração - Antonio Marcos Sarmento das Chagas (Bibliotecário - CRB5 / 1615).  (os dados para catalogação foram enviados pelo usuário via formulário eletrônico).     S586p               Silva, Joilson de Lima.                                 O problema de transporte sob as perspectivas da programação linear e da teoria do transporte ótimo / Joilson de Lima Silva._ Cruz das Almas, Bahia, 2022.                                100f.; il.                                     Dissertação (Mestrado) – Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas, Mestrado Profissional em Matemática – PROFMAT.                                   Orientador: Prof. Dr. João Tiago Assunção Gomes.                                  1.Matemática – Estudo e ensino. 2.Modelagem matemática – Programação linear. 3.Transportes – Análise. I.Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas. II.Título.                                                                                                                                                                       CDD: 510.7  JOILSON DE LIMA SILVA

O Problema de Transporte sob as Perspectivas da
Programação Linear e da Teoria do Transporte Ótimo

Dissertação apresentada ao Mestrado Proﬁssional em
Matemática em Rede Nacional do Centro de Ciências
Exatas e Tecnológicas da Universidade Federal do
Recôncavo da Bahia como parte dos requisitos para a
obtenção do título de Mestre em Matemática.

Aprovado em: 04 de Fevereiro de 2022

BANCA EXAMINADORA:

CRUZ DAS ALMAS - BAHIA

Fevereiro de 2022

Dedico esse trabalho, em especial, à memória de nosso saudoso amigo e meu parceiro de
jornada, Luís Mário, que ao transcender desta vida carregou consigo a grandiosidade de
um cidadão do bem; dedico também, a todos que me acompanharam nessa trajetória.

Agradecimentos

Agradeço primeiramente a Deus, por ter me concebido a dádiva da vida e saúde

para trilhar esse caminho em busca dos meus objetivos.

À minha esposa Daiane Machado, aos meus ﬁlhos Jônathas Kelvin, Arthur Henrique
e Deivid Willian, aos meus pais Lelinha e José, aos meus irmãos Jean, Jocileide e Jamilson;
e a todos os outros familiares e amigos que sempre me apoiaram e me deram forças para
seguir em frente nessa jornada.

Aos meus grandiosos professores por transmitirem seus conhecimentos e lições de
vida, em especial ao meu orientador, professor Dr. João Tiago Assunção Gomes, por ter
aceitado a missão de me guiar nesse momento ﬁnal de minha jornada e ter conduzido esta
função com muito amor e dedicação de sua grande maestria.

Aos Professores Dra. Julianna Pinele Santos Porto e Dr. Cleber Fernando Colle,
membros da Banca Examinadora, por aceitarem o convite para avaliar e contribuírem com
este trabalho.

À Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) pela
grandiosíssima ajuda ﬁnanceira que tanto contribuiu em diversas etapas ao longo do curso.

Aos meus colegas de turma, especialmente os que se tornaram grandes amigos:
Renata Sande e meu companheiro de trabalho Franquilande Aragão, vocês certamente
deixaram essa longa caminhada mais suave, signiﬁcativa e divertida.

“A Matemática é o alfabeto com o
qual Deus escreveu o Universo.”

(Galileu Galilei)

Resumo

O objetivo deste trabalho é analisar os modelos matemáticos para o problema de transporte,
a partir de duas teorias distintas, como metodologia capaz de trazer situações reais para o
fazer matemática na sala de aula. A Programação Linear será o primeiro ponto de vista
para analisar certos problemas de transporte associados à distribuição de produtos. Outra
modelagem para tal problema, envolvendo probabilidades, será estudada pela Teoria de
Transporte Ótimo, a qual permitirá caracterizar noções geométricas sobre tais elementos.
Por ﬁm, destacamos algumas aplicações do problema de transporte à comparação de
histogramas associados à propagação da COVID-19 no Brasil com o intuito de reconhecer
o fenômeno de “onda” epidemiológica.

Palavras-chave: COVID-19. Distância. Método Simplex. Modelagem Matemática. Pes-
quisa Operacional. Probabilidade. Problema de Transporte. Programação Linear. Teoria
do Transporte Ótimo.

Abstract

The objective of this work is to analyze the mathematical models for the transport problem,
from two diﬀerent theories, as a methodology capable of bringing real situations to do
mathematics in the classroom. Linear Programming will be the ﬁrst point of view in
order to analyze certain transport problems associated with product distribution. Another
model for this problem, involving probabilities, will be studied by the Optimal Transport
Theory, which will allow us to characterize geometrical notions about such elements.
Finally, we highlight some applications of the transport problem to the comparison of
histograms associated with the spread of the COVID-19 in Brazil in order to recognize
the epidemiological “wave” phenomenon.

Keywords: COVID-19. Distance. Simplex Method. Mathematical Modeling. Operational
Research. Probability. Transport Problem. Linear Programming. Optimal Transport The-
ory.

Lista de ilustrações

Figura 1 – Incluindo Dados no Excel
. . . . . . . . . . . . . . . . . . . . . . . . . 28
Figura 2 – Alimentando Informações no Solver I . . . . . . . . . . . . . . . . . . . 28
Figura 3 – Alimentando Informações no Solver II
. . . . . . . . . . . . . . . . . . 29
Figura 4 – Resolvendo com o Solver . . . . . . . . . . . . . . . . . . . . . . . . . . 30
31
Figura 5 – Solução do Solver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 6 – Histograma do Lançamento de um Dado Honesto p . . . . . . . . . . . 44
. . . . . . . . . . . 45
Figura 7 – Histograma do Lançamento de um Dado Viciado q
. . . . . . . . . . . 45
Figura 8 – Histograma do Lançamento de um Dado Viciado r
Figura 9 – Histograma Associado ao Vetor a . . . . . . . . . . . . . . . . . . . . . 62
Figura 10 – Histograma Associado ao Vetor b . . . . . . . . . . . . . . . . . . . . . 62
Figura 11 – Histograma Associado ao Vetor c . . . . . . . . . . . . . . . . . . . . . 63
Figura 12 – Histograma Associado ao Vetor a . . . . . . . . . . . . . . . . . . . . . 65
Figura 13 – Histograma Associado ao Vetor b . . . . . . . . . . . . . . . . . . . . . 65
Figura 14 – Histograma dos Números de Casos da COVID-19 . . . . . . . . . . . . 69
Figura 15 – Histograma dos Números de Óbitos da COVID-19 . . . . . . . . . . . . 70
71
Figura 16 – Gráﬁco da Função Cosseno
Figura 17 – Histograma da Função Cosseno . . . . . . . . . . . . . . . . . . . . . . 72
Figura 18 – Gráﬁco da Função Cúspide Cúbica . . . . . . . . . . . . . . . . . . . . 73
Figura 19 – Histograma da Função Cúspide Cúbica . . . . . . . . . . . . . . . . . . 74
. . . . . . . . . . . . 77
Figura 20 – Recorte da Planilha de Preparação para o Solver

. . . . . . . . . . . . . . . . . . . . . . . .

Lista de quadros

Quadro 1 – Modelo Matemático do Exemplo Motivador . . . . . . . . . . . . . . . 27
Quadro 2 – Formulação Teórica . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
Quadro 3 – Modelo Algébrico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Quadro 4 – Problema de Monge . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
Quadro 5 – Problema de Kantorovich . . . . . . . . . . . . . . . . . . . . . . . . . 50
Quadro 6 – Problema de Kantorovich em Termos da Programação Linear . . . . . 54
Quadro 7 – Problema Primal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
Quadro 8 – Problema Dual . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94

Lista de tabelas

Tabela 1 – Custos de Transporte
. . . . . . . . . . . . . . . . . . . . . . . . . . . 25
Tabela 2 – Números de Casos da COVID-19 . . . . . . . . . . . . . . . . . . . . . 69
Tabela 3 – Números de Óbitos da COVID-19 . . . . . . . . . . . . . . . . . . . . . 70
Tabela 4 – Valores para Função Cosseno . . . . . . . . . . . . . . . . . . . . . . . 72
Tabela 5 – Valores para Função Cúspide Cúbica . . . . . . . . . . . . . . . . . . . 73
Tabela 6 – Divisão Intervalos dos Histogramas para Cálculo de Distâncias . . . . . 75
Tabela 7 – Distâncias de Wasserstein para o Histogramas de Casos da COVID-19
79
Tabela 8 – Distâncias Euclidianas para o Histogramas de Casos da COVID-19 . . 79
Tabela 9 – Distâncias Wasserstein para o Histogramas de Óbitos da COVID-19 . . 82
Tabela 10 – Distâncias Euclidianas para o Histogramas de Óbitos da COVID-19 . . 82

Sumário

1
1.1

2
2.1
2.2
2.3
2.4

3
3.1
3.2
3.3
3.4

4
4.1
4.2

5

INTRODUÇÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

MODELAGEM MATEMÁTICA . . . . . . . . . . . . . . . . . . . . . 17
Breve Histórico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

PROGRAMAÇÃO LINEAR . . . . . . . . . . . . . . . . . . . . . . . 21
Modelagem de uma Situação-Problema . . . . . . . . . . . . . . . . . 21
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
Exemplo Motivador
Formulação Teórica . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
Método Simplex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

TEORIA DO TRANSPORTE ÓTIMO . . . . . . . . . . . . . . . . . 40
O Problema de Monge . . . . . . . . . . . . . . . . . . . . . . . . . . 40
O Problema de Kantorovich . . . . . . . . . . . . . . . . . . . . . . . 42
Elo entre a Teoria de Transporte Ótimo e a Programação Linear . . 51
Distância de Wasserstein . . . . . . . . . . . . . . . . . . . . . . . . . 54

APLICAÇÕES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Comparação de Histogramas da COVID-19 . . . . . . . . . . . . . . 67
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Outras Aplicações

CONCLUSÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86

REFERÊNCIAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

APÊNDICES

91

APÊNDICE A – DUALIDADE . . . . . . . . . . . . . . . . . . . . . 92

APÊNDICE B – VETORES DE PROBABILIDADE DA SEÇÃO 4.1 95

Introdução

13

A modelagem matemática tem se ﬁrmado no contexto da educação matemática
como sendo uma metodologia capaz de trazer situações reais para o fazer matemática
na sala de aula. Este fato tem transformado esta ciência em um instrumento com o qual
cada aluno se torne capaz de interpretar matematicamente a realidade que lhes rodeiam,
permitindo desenvolver habilidades que lhes possibilitem melhores intervenções no mundo
em que vivem.

Através da modelagem somos capazes de melhorar a motivação dos alunos, de
forma que eles possam desenvolver atitudes críticas perante a sociedade, despertem o senso
criativo e sejam impulsionados para utilizar novas estratégias, mesmo que estas sejam
informais. Além disso, quando o ensino-aprendizagem ocorre vinculado a um contexto
próximo da realidade do aluno, a disciplina estudada ganha uma nova conotação como
matéria de aprendizagem.

A resolução de problemas via modelos matemáticos se apresenta como uma meto-
dologia de ensino de Matemática que pode ser é muito eﬁcaz, tendo em vista que exige a
mobilização de diversos saberes até que se construa uma solução satisfatória.

Um professor de matemática tem, assim, uma grande oportunidade. Se ele
preenche o tempo que lhe é concedido a exercitar seus alunos em operações
rotineiras, aniquila o interesse e tolhe o desenvolvimento intelectual dos
estudantes, desperdiçando, dessa maneira, a sua oportunidade. Mas se ele
desaﬁa a curiosidade dos alunos, apresentando-lhes problemas compatíveis
com os conhecimentos destes e auxiliando-os por meio de indagações
estimulantes, poderá incutir-lhes o gosto pelo raciocínio independente
e proporcionar-lhes certos meios para alcançar este objetivo (POLYA,
1978).

Durante a resolução de problemas, é muito importante valorizar o processo escolhido
pelo aluno para tentar chegar a uma resposta e, dessa forma, podemos abrir espaço para o
surgimento de diferentes resoluções. Além disso, deve-se estabelecer a comparação entre
tais soluções e oportunizar aos estudantes o compartilhamento dos caminhos seguidos até
à solução ﬁnal do problema.

É fundamental que a resolução de problemas seja baseada na apresentação de
situações abertas e sugestivas, que sejam capazes de extrair dos alunos participação que
desencadeia uma atitude ativa, combinada com um esforço efetivo na busca de suas próprias
respostas para culminar na produção de seu próprio conhecimento.

Introdução

Problema de Transporte

14

Bons exemplos usados no ensino de matemática do Ensino Médio e do Ensino
Técnico, para auxiliar no desenvolvimento cognitivo, visando melhorar o processo de
tomada de decisão dentro de uma perspectiva mais próxima da realidade de cada aluno,
são encontrados nas áreas de logística e de transporte.

[ . . . ]Transportes. Para a maioria das ﬁrmas, o transporte é a atividade
logística mais importante simplesmente porque ela absorve, em média,
de um a dois terços dos custos logísticos. É essencial, pois nenhuma ﬁrma
moderna pode operar sem providenciar a movimentação de suas matérias-
primas ou de seus produtos acabados de alguma forma. Sua importância
é sempre sublinhada pelos problemas ﬁnanceiros colocados para muitas
empresas quando há uma greve ferroviária nacional ou quando carreteiros
autônomos paralisam suas atividades devido a aumentos de combustí-
veis. Não é incomum denominar tais eventos de desastres nacionais. Os
mercados não podem ser atendidos e produtos permanecem no canal de
distribuição para deteriorarem-se ou tornarem-se obsoletos. “Transporte”
refere-se aos vários métodos para se movimentar produtos. Algumas das
alternativas populares são os modos rodoviário, ferroviário e aeroviário.
A administração da atividade de transporte geralmente envolve decidir-se
quanto ao método de transporte, aos roteiros e à utilização da capacidade
dos veículos. (BALLOU, 1993, p. 24)

O setor de transporte tem uma grande importância dentro dos diversos empreen-
dimentos que necessitam fazer o deslocamento de seus produtos, uma vez que os custos
do trinômio oferta-demanda-transporte incidem signiﬁcativamente sobre o valor ﬁnal dos
produtos. Trata-se de um estudo direcionado à alocação de recursos, que tem por objetivo
principal encontrar os melhores valores para uma função, que representa os menores custos
envolvidos nas possibilidades de transporte desses recursos. Por isso, são importantes o
uso de técnicas na otimização do transporte para possibilitar maior eﬁciência na tomada
de decisão, durante a elaboração do plano de escoamento de tais produtos.

Neste trabalho, interpretaremos o problema de transporte sob o ponto de vista
algébrico e algorítmico da Programação Linear e sob uma perspectiva probabilística e
geométrica da Teoria do Transporte Ótimo.

Programação Linear

A Programação Linear é um ramo da Pesquisa Operacional que se dedica na
investigação de modelos matemáticos para representar diversos problemas do cotidiano.
De tal forma que a palavra “Programação” não se refere à programação de computadores,
e sim, a um planejamento que deve ser estruturado em torno de um problema, enquanto
que o adjetivo “Linear” signiﬁca que todos os modelos encontrados serão representados
por funções lineares.

Introdução

15

Segundo Paiva (2008), Programação Linear é uma técnica da matemática aplicada
que constitui um dos ramos da investigação operacional. Envolve a pesquisa, o estudo e
desenvolvimento de modelos de otimização sobre operações, sendo aplicada a problemas
que envolvem a condução e coordenação de operações. Dentro do universo dos modelos de
otimização, existem os modelos de programação matemática que permitem determinar
em que condição é possível, ou não, otimizar um dado objetivo face a um conjunto de
limitações.

De acordo com as ideias de Passos (2008), Programação Linear é uma técnica de
otimização aplicada a sistemas de equações (ou inequações) lineares representativos de
modelos previamente elaborados.

Teoria do Transporte Ótimo

Segundo (PEYRÉ; CUTURI et al., 2019), a Teoria do Transporte Ótimo está
interessada no problema de como comparar duas distribuições de probabilidades - duas
pilhas diferentes de areia de mesmo volume. São consideradas todas as maneiras possíveis de
transformar, transportar ou remodelar a primeira pilha na segunda, usando as informações
locais de quanto custa mover um grão de areia de um lugar para outro.

A teoria do transporte ótimo pode ser descrita informalmente usando
as palavras do Matemático francês Gaspard Monge (1746-1818): Um
trabalhador com uma pá na mão tem que mover um grande monte de
areia deitado em um canteiro de obras. O objetivo do trabalhador é
erguer com toda a areia uma nova pilha com uma forma prescrita (por
exemplo, a de um castelo de areia gigante). Naturalmente, o trabalhador
deseja minimizar seu esforço total, quantiﬁcado por exemplo, como a
distância total ou o tempo gasto carregando pás cheias de areia. (PEYRÉ;
CUTURI et al., 2019, p. 1)

Para Thorpe (2018), existem duas maneiras de formular o problema de transporte
na Teoria do Transporte Ótimo: O Problema de Monge e o Problema de Kantorovich. A
formulação de Kantorovich pode ser vista como uma generalização do problema de Monge,
cuja principal vantagem é teórica. Por exemplo, a existência de solução para o problema
de Kantorovich é sempre garantida, enquanto que resultados de existência de solução para
Monge são consideravelmente mais difíceis.

Além disso, existem diversas aplicações da Teoria do Transporte Ótimo na atuali-
dade. Por exemplo, Thorpe (2018) pontua: recuperação de imagem, representação de sinal
e imagem, problemas inversos, detecção de câncer, textura e modelagem de cores, registro
de formas e imagens e aprendizado de máquina.

Introdução

Estrutura do Trabalho

16

Iniciaremos esse trabalho fazendo uma abordagem sobre Modelagem Matemática,
em seguida, realizamos um breve passeio pela evolução histórica da Pesquisa Operacional,
onde mostramos os principais marcos do desenvolvimento desta teoria, da Programação
Linear e da Teoria de Transporte Ótimo.

No Capítulo 2, detalharemos uma sequência de passos que seguiremos para nos
levar a alcançar o objetivo deﬁnido pela Programação Linear. Apresentaremos um exemplo
motivador, o qual resolveremos baseado nos passos citados anteriormente e que servirá de
base para os outros problemas e modelos investigados neste texto. Ainda nesse Capítulo,
estudaremos de forma concisa a formulação teórica de um problema de Programação
Linear e seu principal meio de resolução, o Método Simplex.

Discutiremos no Capítulo 3 um pouco sobre a Teoria do Transporte Ótimo e,
para tanto, faremos um relato histórico descrevendo o Problema de Monge e, em seguida,
o Problema de Kantorovich. Veremos uma explanação acerca de algumas propriedades
métricas do transporte ótimo, que serão úteis para introduzir (e demonstrar) a Métrica de
Wasserstein no ﬁnal do capítulo.

Por ﬁm, no capítulo 4, apresentamos algumas aplicações do problema de transporte
diretamente associado à comparação de histogramas. Para estas comparações, utilizamos a
Métrica de Wasserstein com o intuito de reconhecer o fenômeno de “onda” epidemiológica
nos histogramas associados à propagação da pandemia de COVID-19 no Brasil.

1 Modelagem Matemática

17

Ao passo que resolvemos problemas diretamente relacionados com nossa realidade
através de um modelo matemático, estamos criando saber matemático-signiﬁcativo. Muitas
vezes dizemos, dentro deste contexto, que estamos produzindo conhecimento aplicado.
Os termos “aplicações” e “modelagem” são frequentemente utilizados para apresentar
várias formas de conectar a Matemática à realidade. Por outro lado, vale ressaltar que
existe uma diferença entre estes dois termos: a modelagem matemática é entendida como o
processo de criação de um padrão ou fórmula matemática, para explicação ou compreensão
de um fenômeno natural que pode ser de qualquer área do conhecimento; enquanto que
fazer uma aplicação é utilizar a Matemática para resolver problemas do mundo real,
visando valorizar, principalmente, situações que são acessíveis a um determinado modelo
matemático preexistente e muitas vezes já explorado.

Em função de tal diferença, alguns autores apresentam divergências de concepções
em torno do uso da Modelagem Matemática em sala de aula. Tanto que, Borba, Meneghetti
e Hermini (1999, p. 76) consideram que a modelagem pode ser vista como um esforço de
descrever matematicamente um fenômeno que é escolhido pelos alunos com o auxílio do
professor. Já para Bassanezi (2002, p. 38) um fenômeno a ser modelado deve servir de
“força motivadora” para o aprendizado dos conteúdos matemáticos da mesma forma que,
segundo ele, as discussões sobre o tema a ser trabalhado em aula, favorecem a formação
do indivíduo como elemento ativo no seu contexto social. Com isso, entende-se que esta é
uma forma de agregar signiﬁcado matemático ao conteúdo trabalhado.

Dentre as principais áreas de conhecimento que respaldam a Modelagem Matemática,
destacamos a Pesquisa Operacional que se vale de métodos quantitativos para auxiliar na
busca da melhor maneira de se tomar uma decisão dentro de uma organização, levando
em conta as condições impostas por sua realidade.

Podemos usar a Pesquisa Operacional, por exemplo, quando se pretende expressar
as melhores decisões, como o custo mínimo ou lucro máximo de produção, considerando o
fato de possuir recursos limitados, ou então, apresentar as melhores rotas em um problema
de transporte de cargas, tendo que obedecer à limitação de oferta das origens e também
sempre atender no mínimo a demanda de mercadoria dos destinos.

É bem verdade que existem diversos métodos e técnicas para se resolver problemas de
Pesquisa Operacional como, por exemplo, Teoria dos Grafos, Teoria de Filas, Programação
Linear, Programação Inteira, Programação Inteira Mista, Programação Não-Linear, dentre
outras. Este trabalho dará enfase a Programação Linear como principal técnica empregada
para resolver problemas de Pesquisa Operacional, por isso, iremos focar nossas análises na

Capítulo 1. Modelagem Matemática

18

resolução de problemas cujo modelo matemático seja representado por expressões lineares.

1.1 Breve Histórico

O processo de desenvolvimento histórico da Modelagem Matemática é marcado
por uma larga colaboração entre cientistas e militares que sempre buscaram alcançar
as melhores estratégias durante as batalhas para que assim obtivessem a vitória. Nesta
seção, listamos de forma concisa importantes fatos históricos associados ao conteúdo deste
trabalho (consulte (GRANJA; RUIZ, 2006) e (VILLANI, 2009, Páginas 29 até 37)).

Muitos estudiosos consideram o início da Pesquisa Operacional no século III A.C,
durante a Segunda Guerra Púnica, tendo como base fundamentadora as propostas de
soluções de Arquimedes para defender a cidade de Siracusa, sitiada pelos romanos. Entre
suas invenções se encontravam as catapultas de guerra com as quais podiam lançar pedras
de um quarto de tonelada a um quilômetro de distância e um sistema de espelhos para
incendiar as navegações inimigas concentrando os raios do sol.

Nos séculos XVII e XVIII, Isaac Newton, Gottfried Leibniz, Joseph-Louis Lagrange
e vários membros da família Bernoulli, obtiveram, à luz de seus trabalhos, resultados
sobre máximos e mínimos de funções. Enquanto que o matemático francês Jean-Baptiste
Fourier apresentou algoritmo para resolver sistemas de inequações, uma ideia preliminar
do que hoje conhecemos como Programação Linear. Já no ﬁnal do século XVIII, Gaspard
Monge conseguiu desenvolver os primeiros passos do método gráﬁco através do avanço da
Geometria Descritiva.

Frederick Taylor, durante o século XIX, conseguiu mostrar através de seus estudos
que durante o trabalho de escavação das minas a única variável realmente signiﬁcativa era
o peso combinado da pá e sua carga, sendo assim, conseguiu maximizar o desempenho dos
mineiros. A partir disso, foi possível desenhar pás de acordo com os diferentes tipos de
materiais que seriam usados.

Dentre os especialistas, há alguns que consideram Charles Babbage como o pai
da Pesquisa Operacional, atribuição conferida por conta de seus estudos investigativos
acerca dos custos de transporte e triagens do correio feitas para o Uniform Penny Post da
Inglaterra em 1840.

Durante a Primeira Guerra Mundial, o engenheiro inglês Frederick Lanchester
estudou sobre o poder balístico das forças opositoras e conseguiu desenvolver, a partir
de um sistema de equações diferenciais, a Lei Quadrada de Lanchester. Através desta lei
era possível determinar o resultado de uma batalha militar em função da força numérica
relativa e a capacidade de fogo dos combatentes.

A primeira abordagem feita para o Problema de Transporte foi em 1781, por Gaspard

Capítulo 1. Modelagem Matemática

19

Monge, motivado por um problema de engenharia. Em 1930, o russo Lev Nikolaevitch
Tolstoi publicou o artigo “Métodos de Encontrar a Quilometragem Mínima no Transporte
de Carga no Espaço”, que foi publicado na coleção Volume de Planejamento de Transporte
I para o Comissariado Nacional de Transporte da União Soviética.

Em 1939, o matemático russo Leonid Kantorovich e o economista holandês Tjalling
Koopmans deram importantes contribuições para a logística e a economia ao sugerir uma
nova abordagem ao problema proposto por Monge. Com isso, estes tipos de problemas
passaram a serem conhecidos como “Problemas de Transporte de Kantorovich-Koopmans”.

No transcorrer da década de 1940, Kantorovich e Koopmans desenvolveram, cada
um com sua própria visão independente, o problema do transporte, iniciando áreas de
pesquisa que mais tarde viriam a ser chamadas de “Teoria de Transporte Ótimo” e de
“Programação Linear”.

Contudo, os grandes estudiosos consideram que o maior marco do desenvolvimento
da Pesquisa Operacional acontece durante a II Guerra Mundial, na batalha da Grã-
Bretanha, quando o governo britânico buscou alguma forma para melhorar a insuﬁciência
da capacidade aérea de suas forças armadas. Mesmo contando com uma grande experiência
em combate, resolveu convocar cientistas de diversas disciplinas para solucionar o problema
e extrair o máximo de benefício dos radares recém-inventados que dispunham. Com
essa força tarefa, conseguiram determinar a localização ideal das antenas para melhor
distribuição de sinal e, com isso, foi possível dobrar a eﬁcácia do sistema de defesa aérea
evitando a derrota.

No ano de 1942, a frota de submarinos alemães começou um bloqueio à Grã-
Bretanha, por meio de ataques aos comboios de navios que transportavam suprimentos dos
Estados Unidos, impedindo-os que chegassem ao seu destino. O Anti-Submarine Warfare
Operations Research Group (ASWORG)1 conseguiu apresentar modelos matemáticos
desses navios que consideravam as diversas restrições impostas pela realidade, como a
velocidade máxima atingida pelos navios, a capacidade de suprimentos a ser transportado
e o combustível necessário para chegar ao seu destino. Foram capazes também de realizar
essas representações matemáticas para frota de submarinos alemã e, com isso, conseguiram
modelar a guerra naval, chegando a desenvolver estratégias que reduziram o número de
navios americanos afundados e ainda aumentaram a destruição de submarinos alemães.

Ao passo que a Inglaterra conseguiu avaliar a interferência dessas novas estratégias,
prontamente se criaram grupos de “Pesquisa de Operações” tentando obter melhores
resultados na batalha. Em 1947, os Estados Unidos formou um grupo de trabalho dedicado
a melhorar o processo de planejamento em larga escala o projeto: Scientiﬁc Computation
Of Optimum Programs (SCOOP)2.

1 Tradução livre do autor: Grupo de Pesquisa de Operações de Guerra Anti-Submarino
2 Tradução livre do autor: Computação Cientíﬁca de Programação Otimizada

Capítulo 1. Modelagem Matemática

20

Em 1949, Dantzig apresentou um método numérico de resolução do problema de
transporte, dando os primeiros passos para o desenvolvimento da Programação Linear.
Curiosamente, alguns técnicas associadas a este método já haviam sido trabalhadas por
Kantorovich. Tanto que até hoje, ainda existem autores que divergem sobre qual destes
deve ser considerado o verdadeiro fundador da Programação Linear.

No Brasil, a Pesquisa Operacional apareceu em meados do século XX quando, no
ﬁnal da década de 50, foi introduzida em alguns trabalhos de proﬁssionais empresariais.
Apesar disso, teve seu principal berço por meio do desenvolvimento acadêmico, segundo
Lóss (1981). Em 1959, o Instituto Tecnológico de Aeronáutica (ITA) deu início ao ensino das
primeiras disciplinas de Pesquisa Operacional (tais como teoria de jogos, simulação, ﬁlas e
estatística) ministradas para o primeiro curso de Engenharia de Produção do Brasil, que teve
início em 1957. Enquanto isso a Universidade de São Paulo (USP) implantou a disciplina
de Programação Linear. Concomitantemente, a Pontifícia Universidade Católica do Rio
de Janeiro (PUC-RJ), adquiria seu primeiro computador e um grupo de pesquisadores
começaram a trabalhar com modelos e aplicações de técnicas de Pesquisa Operacional.
A partir disso o Instituto de Matemática Pura e Aplicada (IMPA) e a Escola Nacional
de Ciências Estatísticas (ENCE) mostraram maior interesse em desenvolver pesquisas
na área de Programação Linear. Na década de 60, a empresa Petróleo Brasileiro S.A.
(PETROBRAS) fundou a Sociedade Brasileira de Pesquisa Operacional (SOBRAPO),
a qual se conﬁgurou no primeiro grupo brasileiro de estudos em Pesquisa Operacional.
Segundo esta sociedade, a Pesquisa Operacional é uma ciência aplicada voltada para a
resolução de problemas reais, tendo como principal foco avaliar linhas de ação alternativas
para encontrar as soluções que melhor servem aos objetivos dos indivíduos ou organizações.

As contribuições do problema de transporte à economia foi o principal tópico do
Prêmio de Ciências Econômicas em Memória de Alfred Nobel de 1975 concedido à Leonid
Kantorovich e Tjalling Koopmans.

A partir da década de 1990, a Teoria de Transporte Ótimo foi revisitada tanto por
matemáticos teóricos, pelas aplicações ao tópico de Equações Diferencias Parciais, como
por matemáticos computacionais, devido as aplicações a área de Machine Learning3. Vale
ressaltar que pesquisadores deste tópico, como Cédric Villani (em 2010) e Alessio Figalli
(em 2018), foram agraciados com o International Medal for Outstanding Discoveries in
Mathematics4, também conhecida como Medalha Fields, que é a mais importante honraria
da Matemática da atualidade.

3 Tradução livre do autor: Aprendizagem de Máquina
4 Tradução livre do autor: Medalha Internacional de Descobrimentos Proeminentes em Matemática

2 Programação Linear

21

Neste capítulo, estudaremos o problema de transporte sob o ponto de vista da
Programação Linear. De acordo com Marins (2011) a Programação Linear tem como
objetivo obter a melhor solução para problemas cujo modelo possuam expressões lineares.
Desta forma, a otimização ocorrerá por meio do estudo de uma função linear, chamada
de função objetivo, que deverá atender à um sistema de igualdades e/ou desigualdades
lineares, às quais denominamos de restrições.

Inicialmente, discutiremos o processo de modelagem e as etapas de resolução de
um problema da Programação Linear através de um exemplo de transporte associado a
distribuição de produtos. Nas seções 2.3 e 2.4, serão apresentados os alicerce teórico da
Programação Linear que viabilizam a otimização dos problemas propostos neste texto.
Listamos as seguintes referências (MARINS, 2011; GOLDBARG; LUNA, 2005; BAZARAA;
JARVIS; SHERALI, 2008; DANTZIG; THAPA, 2006) onde podem ser encontrado todo o
conteúdo desenvolvido nesta capitulo.

2.1 Modelagem de uma Situação-Problema

Marins (2011) defende que para se resolver um problema de Programação Linear
são necessárias as etapas de observação, de formulação do problema, de construção do
modelo cientíﬁco e de resolução deste modelo por meio de método adequado, o qual pode
ser determinístico ou probabilístico por se tratar de uma abordagem cientíﬁca.

Desta forma, para resolvermos um problema de Programação Linear, primeiramente
precisamos realizar uma abordagem para encontrarmos uma modelagem matemática para
esse problema, para que tenhamos uma melhor compreensão da situação-problema e
sejamos capazes de criar modelos que representem bem tais situações, e a partir de então,
usarmos um método de resolução que nos leve à melhor solução do modelo.

Independentemente do método a ser aplicado para a análise e resolução de um
Problema de Programação Linear (PPL), será necessário seguir algumas etapas básicas
que, em linhas gerais, são apresentadas e detalhadas nesta seção.

Etapa 1. Compreensão da Situação-Problema

A deﬁnição e compreensão do problema a ser estudado trará uma visão exata dos
objetivos a serem alcançados, uma vez que a qualidade e o nível de conﬁança do resultado
ﬁnal são diretamente proporcionais à precisão da análise inicial. Vale a pena salientar

Capítulo 2. Programação Linear

22

que ao longo desse processo de entendimento inicial da situação-problema, pode haver
suposições em que as informações não são bem estruturadas, e por isso, é importante
saber que quanto mais objetivas forem as informações, melhor será o resultado ﬁnal. Além
disso, esta etapa é a principal base para deﬁnição das limitações impostas pela natureza
do problema que irá conﬁgurar as chamadas restrições que devem serem atendidas.

Etapa 2. Construção de um Modelo Matemático

Uma vez compreendido a situação-problema, devemos seguir para a construção de
um modelo, que deve ser feita através da representação da situação-problema e de suas
restrições através de modelos matemáticos para nortear a busca por uma solução.

Tal modelo deve ser composto por um conjunto de variáveis envolvidas em equações
e inequações que descrevem o problema e suas restrições. Vale a pena lembrar, que nem
sempre um modelo matemático descreve a situação real em sua totalidade, pois pode
haver variáveis que não serão incluídas por existir um número muito grande delas, o
que diﬁculta a modelagem e uma possível resolução. A quantidade de variáveis a serem
representadas matematicamente pode variar de acordo com as necessidades impostas pela
situação-problema e estas são chamadas de variáveis de decisão.

De forma resumida, apresentamos a seguir uma sequência de passos que auxiliam
na construção de um modelo matemático de Programação Linear que melhor represente a
situação-problema de forma coerente, clara e concisa:

2A. Identiﬁcar as variáveis de decisão e representá-las em simbologia algébrica;

2B. Identiﬁcar as restrições do problema e expressá-las como equações ou inequações

lineares em termos das variáveis de decisão;

2C. Identiﬁcar o objetivo de interesse no problema e representá-lo como função linear
em termos das variáveis de decisão. O objetivo deve compreender a otimização desta
função, isto é, maximizar ou minimizar tal função deﬁnida.

Em consonância com a sequência de passos apontados acima, é muito importante
que nessa fase sejam feitas e respondidas muitas perguntas, tais como: Quais são as
hipóteses que devem ser sugeridas? Quais decisões devem ser tomadas? Quais recursos
afetam tais decisões?

Etapa 3. Resolução do Modelo

Nessa etapa, buscamos uma solução do modelo de Programação Linear que foi
proposto. Esta solução é chamada de solução ótima e pode ser obtida através de técnicas

Capítulo 2. Programação Linear

23

ou ferramentas de solução numérica e computacionais, que geralmente são baseadas em
um algoritmo.

Um algoritmo bastante utilizado na Programação Linear é o Método Simplex, com
uma boa contextualização em Dantzig (1963). Outro algoritmo muito poderoso foi proposto
por Karmarkar (1984) e consiste no Método dos Pontos Interiores. Detalhes sobre ambos
podem ser obtidos em Hillier e Lieberman (2013).

Uma poderosa ferramenta computacional muito utilizada na resolução de problemas

de Programação Linear é o complemento Solver.

Gomes Júnior e Souza (2004) aﬁrmam que:

O Solver faz parte de um conjunto de programas algumas vezes chamado
de ferramentas de análise hipotética. Com o Solver você pode localizar
um valor ideal para uma fórmula em uma célula, chamada de célula de
destino, em uma planilha. O Solver trabalha com um grupo de células
relacionadas direta ou indiretamente com a fórmula na célula de destino.
O Solver ajusta os valores nas células variáveis que você especiﬁcar,
chamadas de células ajustáveis, para produzir o resultado especiﬁcado
por você na fórmula da célula de destino. Você pode aplicar restrições
para restringir os valores que o Solver poderá usar no modelo e as
restrições podem se referir a outras células que afetem a fórmula da
célula de destino.

Etapa 4. Análise da Solução

A avaliação da solução ótima tem por objetivo principal determinar se as conclusões
encontradas para o modelo proposto escolhido para representar a situação-problema, são
adequadas ou não para o problema real. Caso a solução seja julgada inadequada, ou seja,
apresente um resultado discrepante, será preciso redeﬁnir o problema ou redeﬁnir o modelo.
Caso a solução seja apropriada, teremos uma solução adequada para o problema e, então,
deve-se fazer a aplicação real da solução ótima encontrada.

Com base nesses passos, espera-se que tenhamos uma solução que seja condizente
com o ambiente real, ou no mínimo, que a solução ótima seja exequível para apreciação
dentro da realidade.

É importante frisarmos que a sequência de passos listados anteriormente é ﬂexível,
ou seja, não é necessário seguir todo o ciclo para que possamos concluir se a solução
encontrada é boa ou ruim para representar o problema real. Assim, pode ser necessário
fazer uma modiﬁcação no modelo, para que possamos encontrar uma adaptação melhor
do modelo à realidade, ou mesmo, objetivando encontrarmos uma solução mais precisa
para o problema.

Capítulo 2. Programação Linear

24

2.2 Exemplo Motivador

Iremos abordar nessa seção, um problema de transporte que tem resolução capaz de
ser facilmente entendida e que nos possibilite dialogar sobre suas restrições, o que denota
uma abordagem com entendimento claro e possível de ser aplicado no Ensino Médio. O
problema abaixo foi inspirado em (CAIXETA FILHO, 2001).

Situação-Problema. Suponha que uma empresa é responsável pela distribuição da
produção agrícola de um produtor de arroz paulista. Para isso, deve-se levar em conta todo
o custo do transporte da produção. Sabe-se que o produtor possui três locais de produção:

Fazenda Mariana,

Fazenda Braga

e

Fazenda Falcão.

Considera-se ainda que cada local de produção possui uma oferta mensal de no máximo

100,

150

e

170

toneladas de arroz,

respectivamente. Esta produção deve ser transportada até dois diferentes centros de
distribuição (CD), que se localizam em

Campinas

e

Sorocaba,

e que requerem, respectivamente, uma demanda mensal de

250

e

140

toneladas de arroz.

Como realizar esse transporte com o menor custos e atendendo às especiﬁcações do
problema?

Etapa 1. Compreensão da situação-problema

Para se obter uma melhor compreensão, iremos enumerar tanto as origens quanto
os destinos, com números naturais em ordem crescente. Assim, a Fazenda Mariana é 1, a
Fazenda Braga é 2, a Fazenda Falcão recebe 3, o centro de distribuição de Campinas será
4 e, por ﬁm, o centro de distribuição de Sorocaba é 5. Esta enumeração visa facilitar a
identiﬁcação das variáveis e a associação com as trajetórias.

Etapa 2. Construção de um Modelo Matemático

Veja que para modelar este problema deve-se considerar cada variável de decisão
como sendo a quantidade que deve ser transportada da origem i, para o destino j,
representada por xij.

Capítulo 2. Programação Linear

25

Como exemplo, seja a quantidade de arroz que sairá da Fazenda Braga (2) e
abastecerá o centro de distribuição de Sorocaba (5). Na notação proposta, será a quantidade
a ser transportada de 2 para 5. Logo, a origem será 2 e o destino será 5, obtendo a variável
deﬁnida por x25. Da mesma maneira, a quantidade de arroz que sairá da Fazenda Braga
(1) para o centro de Campinas (4), terá origem 1 e destino 4, obtendo a variável x14.

Observe que na modelagem desse problema, cada uma das três fazendas tem a
opção de levar seus produtos a dois diferentes locais, o que gera seis rotas diretas diferentes,
isto signiﬁca que estamos diante de um problema de seis variáveis.

Criamos a Tabela 1, para podermos realizar a análise dos custos de transporte
por tonelada de arroz em todas as trajetórias possíveis do problema. Essa tabela é uma
idealização baseada apenas em critérios não oﬁciais para representar o que chamamos de
matriz dos custos de transporte.

Tabela 1 – Custos de Transporte

R$ / Toneladas

CD Campinas (4) CD Sorocaba (5)

Fazenda Mariana (1)
Fazenda Braga (2)
Fazenda Falcão (3)

12,50
13,00
10,00

6,80
9,00
8,90

Fonte: Elaborada pelo autor.

Assim, por exemplo, a quantidade a ser transportada de 1 para 5, cuja variável de
decisão é x15, terá um custo de 6, 8x15, pois x15 representa a quantidade, em toneladas,
de arroz a ser transportada e 6,8 representa segundo a matriz dos custos, o valor, em
reais (R$) do transporte de uma tonelada de arroz nesse possível caminho. Seguindo esse
raciocínio teremos a função que representa o custo total do transporte (Z). Vale salientar,
que se alguma rota acima não possuir transporte o valor de sua variável de decisão será
zero; com isso, teremos a seguinte função objetivo,

Z = 12, 5 x14 + 6, 8 x15 + 13 x24 + 9 x25 + 10 x34 + 8, 9 x35.

Elaborada a função custo, iremos analisar as restrições do problema. A produção
máxima da Fazenda Mariana (1) é de 100 toneladas de arroz, logo a soma das variáveis
que começam com (1) é menor do que ou igual a 100, assim,

x14 + x15 ≤ 100.

Analogamente, a Fazenda Braga (2) tem produção máxima de 150 toneladas e a

Fazenda Falcão (3) possui produção máxima de 170 toneladas, com isso,

Capítulo 2. Programação Linear

26

x24 + x25 ≤ 150

e

x34 + x35 ≤ 170.

Atribuída as restrições de produção, analisaremos as restrições de demanda, onde

iremos analisar a capacidade total de cada centro de distribuição.

O CD Campinas (4) tem capacidade máxima para 250 toneladas de arroz, logo, o

somatório das variáveis que terminam com (4) terá que ser igual a 250, ou seja,

x14 + x24 + x34 = 250.

Da mesma forma, o CD Sorocaba (5) tem demanda máxima de 140 toneladas de

arroz, o que gera a seguinte restrição,

x15 + x25 + x35 = 140.

Finalmente, acrescentam-se as condições de não negatividade, as quais determinam
que todas as variáveis de decisão do problema não podem assumir valores negativos, vale
lembrar que essas condições podem ser implementadas a partir de um link, durante a
resolução do problema por meio do Solver que é um complemento do Excel.

Feita a análise do problema, apresentaremos abaixo o Quadro 1 com o modelo de
Programação Linear para o mesmo, contendo a função objetivo, as restrições de produção,
as restrições de demanda e as restrições de não negatividade.

Capítulo 2. Programação Linear

27

Quadro 1 – Modelo Matemático do Exemplo Motivador

Função Objetivo

Minimizar Z = 12, 5 x14 + 6, 8 x15 + 13 x24 + 9 x25 + 10 x34 + 8, 9 x35.

Sujeito às Restrições de Produção

x14 + x15 ≤ 100
x24 + x25 ≤ 150
x34 + x35 ≤ 170

Sujeito às Restrições de Demanda

x14 + x24 + x34 = 250
x15 + x25 + x35 = 140

Sujeito às Restrições de Não Negatividade

x14 ≥ 0
x24 ≥ 0
x34 ≥ 0

x15 ≥ 0
x25 ≥ 0
x35 ≥ 0

Onde

{x14, x15, x24, x15, x34, x35} são as variáveis de decisão.

Fonte: Elaborado pelo autor.

Etapa 3. Resolução do Modelo (via Solver)

Feito a modelagem do problema lançamos mão do Excel para adicionar os dados do
problema. Em nosso exemplo, precisamos calcular os totais que irão atender às restrições
do problema, esses totais estão nas células de I6 (coluna I e linha 6) a I12 (coluna I e
linha 12), para tanto, usaremos a função do Excel conhecida como [SOMARPRODUTO],
digitamos essa fórmula na célula I6, em seguida, escolhemos as células de C6 a H6, que são
onde tem os coeﬁcientes das variáveis, depois digitamos o ponto e vírgula (;) e selecionamos
às células que contém as variáveis que são de C14 a H14. No ﬁnal, apertamos a tecla F 4
para travarmos estas células e assim podermos transferir esta fórmula corretamente para
as demais células da coluna de Totais, agora basta teclarmos ENTER.

Para transferir a fórmula para as demais colunas basta selecionar a I6, clicar sobre
o quadradinho em destaque no canto inferior direito dessa célula e arrastar o cursor sobre
as demais células segurando o clique inicial, como mostra a Figura 1.

Capítulo 2. Programação Linear

28

Figura 1 – Incluindo Dados no Excel

Fonte: Elaborada pelo autor.

Nesse momento, iremos usar o suplemento do Excel conhecido como Solver. Com
esta ferramenta devidamente habilitada, iremos acessar o ícone DADOS na janela do
Excel e no canto superior direito irá aparecer a janela com o símbolo do Solver sobre o
qual iremos clicar para abrir a janela de alimentação de dados desta ferramenta, conforme
Figura 2.

Figura 2 – Alimentando Informações no Solver I

Fonte: Elaborada pelo autor.

Capítulo 2. Programação Linear

29

Com a janela do Solver aberta vamos informar os dados do problema. Aparecerá o
campo “Deﬁnir Objetivo:”. Selecionamos este campo da janela e clicamos sobre a célula
I12, que representa o total de nossa função custo. Em seguida, marcamos a forma de
otimização que queremos que o programa realize, isto é, “Min” para minimizar o problema.
Também devemos preencher a linha “Alterando Células Variáveis:”. Para isto selecionamos
esta linha da janela, clicamos e arrastamos sobre as células que representam as variáveis,
as quais são C14 até H14.

Clicamos em adicionar e irá abrir uma nova janela na qual devemos informar as

restrições do problema, ver Figura 3.

Figura 3 – Alimentando Informações no Solver II

Fonte: Elaborada pelo autor.

Colocando o cursor sobre a linha “Referência de Célula” e clicamos sobre a célula
I6 da coluna (TOTAIS). Também escolhemos o símbolo referente a essa restrição clicando
na seta da coluna central da janela “Adicionar Restrições”. Em seguida, colocamos o cursor
sobre a coluna restrição da janela e depois clicamos sobre a célula da primeira restrição
J6.

Como nosso problema tem outras restrições, clicamos em adicionar e repetimos o
procedimento anterior para as demais restrições (veja Figura 3 para facilitar a compreensão)
e, ao ﬁnal da última restrição, clicamos em OK.

Ao clicarmos em OK, seremos encaminhados para a primeira janela do Solver.

Agora, devemos clicar no botão Resolver e então abrirá uma ultima janela.

Capítulo 2. Programação Linear

30

Figura 4 – Resolvendo com o Solver

Fonte: Elaborada pelo autor.

Nesta última etapa, o Solver nos fornece algumas opções, conforme mostra a Figura
4, temos a opção de: Manter a solução por ele encontrada; exibir alguns relatórios; ou
restaurar as opções para valores iniciais. Iremos manter a solução e clicar OK. Logo em
seguida, nos será exibida a solução ótima encontrada pelo Solver.

Etapa 4. Análise da Solução

Com a solução, consegue-se analisar exatamente como se proceder o transporte dos
centros de distribuições até as respectivas fazendas, a ﬁm de que o custo seja mínimo, ou
seja, somos capazes de identiﬁcar a melhor quantidade a ser transportada de uma das
fazendas para um determinado centro de distribuição; ou até mesmo, deﬁnir se vale a pena
não fazer o trasporte em uma determinada rota.

Ao observamos os resultados (veja Figura 5) notamos que no campo correspondente
à variável de decisão x15, dado pela célula D14, aparece o valor 100. Isto signiﬁca que
a informação da quantidade ótima de arroz a ser transportada de 1 para 5, ou mais
precisamente, da fazenda Mariana para o centro de distribuição de Sorocaba, é de 100
toneladas. Da mesma forma, veriﬁcamos que o mais econômico é que não haja transporte
da fazenda Mariana para o centro de distribuição de Campinas, pois a variável de decisão
x14, na célula C14, é igual a zero.

Capítulo 2. Programação Linear

31

Figura 5 – Solução do Solver

Fonte: Elaborada pelo autor.

Outra informação importante, é o fato de que para obter o menor custo ótimo de
transporte, apenas a fazenda Braga utilizou 120 toneladas de arroz das 150 existentes,
enquanto as demais fazendas transportaram o total de arroz produzido para suprir a
capacidade total de 390 = (250+140) toneladas de arroz para os dois centros de distribuição.
Por ﬁm, obtemos a informação de que o menor custo total do transporte para atender às
condições do problema será de

Z = R$ 3.780, 00.

2.3 Formulação Teórica

Estabelecidos os procedimento práticos para resolução de um problema de trans-
porte segundo à Programação Linear, a partir desta seção, iremos estudar as técnicas e
resultados matemáticos que embasam tal teoria.

Em linhas gerais, Programação Linear pode ser entendida como uma técnica que
pressupõe a relação linear entre as características do problema, buscando a solução de
problemas que objetivam a otimização de um sistema de estudo. Essas características
do problema são representadas e relacionadas por meio de uma série de equações e/ou
inequações lineares.

Goldbarg e Luna (2005), defendem que os modelos de Programação Linear cons-
tituem um tipo especial de modelos de otimização. Para que um determinado sistema

Capítulo 2. Programação Linear

32

possa ser representado por meio de um modelo de Programação Linear, ele deve possuir
as seguintes características:

• Proporcionalidade: a quantidade de recurso consumido por uma dada atividade deve
ser proporcional ao nível dessa atividade na solução ﬁnal do problema. Além disso, o
custo de cada atividade é proporcional ao nível de operação da atividade.

• Não Negatividade: deve ser sempre possível desenvolver dada atividade em qualquer
nível não negativo, e qualquer proporção de um dado recurso deve sempre poder ser
utilizado.

• Aditividade: o custo total é a soma das parcelas associadas a cada atividade.

• Separabilidade: pode-se identiﬁcar de forma separada o custo (ou consumo de recursos)

especíﬁco das operações de cada atividade.

Com isso, a formulação geral de um problema de Programação Linear, é apresentada

no Quadro 2.

Função Objetivo

Quadro 2 – Formulação Teórica

Maximizar (ou Minimizar) Z = c1x1 + c2x2 + c3x3 + c4x4 + · · · + cnxn

Sujeita às Restrições

a11x1 + a12x2 + a13x3 + · · · + a1nxn ≤ b1
a21x1 + a22x2 + a23x3 + · · · + a2nxn ≤ b2
a31x1 + a32x2 + a33x3 + · · · + a3nxn ≤ b3

...

(ou ≥ ou =)
(ou ≥ ou =)
(ou ≥ ou =)

am1x1 + am2x2 + am3x3 + · · · + amnxn ≤ bm

(ou ≥ ou =)

Onde

{c1, c2, c3, . . . , cn} são os coeﬁcientes das variáveis na função objetivo Z;
{x1, x2, x3, . . . , xn} são as variáveis de decisão;
{a11, a12, a13, . . . , amn} são os coeﬁcientes das variáveis nas restrições;
{b1, b2, b3, . . . , bm} são os termos independentes das restrições.

Fonte: Elaborado pelo autor.

Independente do método escolhido para resolução, um problema de Programação
Linear é representado por um modelo simbólico estruturado com equações e/ou inequações
lineares, donde também podemos propor uma reformulação matricial para representá-lo,
ver Quadro 3.

Capítulo 2. Programação Linear

33

Quadro 3 – Modelo Algébrico

Função Objetivo

Maximizar (ou Minimizar) Z = CX

Sujeita às Restrições

AX ≤ B,

X ≥ 0

e B ≥ 0

(ou ≥ ou =)

Onde

C = (c1, . . . , cm) , X =







x1
...
xn







, A =







a11
...
am1







· · · a1n
...
. . .
· · · amn

, B =













b1
...
bn

Fonte: Elaborado pelo autor.

Observação. Outras formas equivalentes de enunciar um problema de Programação Linear
serão exploradas no Apêndice A por meio da noção de dualidade.

2.4 Método Simplex

De posse do modelo matemático que compreende um problema de Programação
Linear, destacando a função objetivo e as restrições, precisamos utilizar um método de
Programação Linear para encontrarmos a solução ótima. O processo que utilizamos para
tal tarefa recebe o nome de Método Simplex.

O Método Simplex foi desenvolvido por George Dantzig e Tjalling Koopmans em
1946, quando trabalhavam para United States Air Force (USAF)1. Este é considerado
por muitos como um dos principais algoritmos inventados no século XX e trata-se de
uma estratégia de manipulação interativa, utilizada para se determinar numericamente a
solução ótima de um problema de Programação Linear.

O método consiste em procurar uma solução inicial e, em seguida, buscar outra
solução que seja melhor que a anterior. Este processo se repete até se encontrar uma
solução ótima. (GOLDBARG; LUNA, 2005) pontua que,

O Simplex é um algoritmo que se utiliza de um ferramental baseado na
álgebra linear para determinar, por um método iterativo, a solução ótima
de um Problema de Programação Linear. Sua concepção básica é simples
e, por isso mesmo, eﬁciente. Em linhas bastante gerais, o algoritmo parte
de uma solução viável do sistema de equações que constituem as restrições
do Problema de Programação Linear, solução essa normalmente extrema
(vértice). A partir dessa solução inicial vai identiﬁcando novas soluções
viáveis de valor igual ou melhor que a corrente. O algoritmo, portanto,
possui um critério de escolha que permite encontrar sempre novos e

1 Tradução livre do autor: Força Aérea dos Estados Unidos

Capítulo 2. Programação Linear

34

melhores vértices da envoltória convexa do problema, e um outro critério
que consegue determinar se o vértice escolhido é ou não um vértice ótimo.

Para Ploskas e Samaras (2014) a escolha do elemento de articulação em cada
iteração é um dos passos mais críticos para o algoritmo Simplex. A ﬂexibilidade da seleção
de variáveis que entram e saem permite desenvolver várias regras de articulações. Por
este motivo, o Método Simplex é utilizado na otimização matemática sequencial para
avaliar a melhor solução possível de um problema complexo, dadas determinadas condições
operacionais e a quantidade de recursos.

Para resolver um modelo de Programação Linear usando o Método Simplex, as

seguintes etapas são necessárias:

• Formulário padrão: uma representação matemática do objetivo do problema;

• Apresentar variáveis de folga: transforma as inequações em equações;

• Criar o quadro: uma deﬁnição das variáveis envolvidas no problema;

• Variáveis dinâmicas: identiﬁcação da variável de decisão;

• Criar um novo quadro: deﬁnição dos critérios de parada;

• Veriﬁcar a otimização: realização de iterações para avaliar o comportamento das

variáveis e chegar na solução desejada;

• Identiﬁcar os valores ideais: apresentação da solução ótima.

Já vimos que a formulação padrão de um problema de Programação Linear se dá
em torno de um sistema de equações e inequações, com isso, surgem os primeiros desaﬁos
do Método Simplex. A diﬁculdade desse tipo de problema pode ser, segundo Goldbarg e
Luna (2005), dividida em dois blocos:

1) Como obter soluções factíveis básicas do sistema de equações;

2) Como evitar o teste de todas as soluções factíveis básicas possíveis para garantir a

otimização do sistema.

A partir do modelo algébrico do problema de Programação Linear, apresentado no
Quadro 3, iremos renomear alguns elementos para trabalharmos com o Método Simplex:

• A =








a11
...
am1








· · · a1n
...
. . .
· · · amn

é a matriz dos coeﬁcientes (ou matriz tecnológica);

Capítulo 2. Programação Linear

35

• C = (c1, c2, c3, . . . , cn) é o vetor de custos;

• X = (x1, x2, x3, . . . , xn)T é o vetor das variáveis ou incógnitas;

• B = (b1, b2, b3, . . . , bm)T é o vetor dos termos independentes.

Além disto, faz-se necessário apresentarmos algumas deﬁnições para o melhor entendimento
do processo realizado pelo Método Simplex.

Deﬁnição 2.1 (Partição Básica de A). Toda matriz dos coeﬁcientes A pode ser reorgani-
zada como

de modo que:

A = h ¯B | N

i

• ¯Bm×m2 representa a matriz básica que é formada por m elementos da matriz dos
coeﬁcientes Am×n. Esta matriz básica é invertível, pois possui posto m. Ela é
representada como ¯B = h
representa uma
coluna da matriz A e os índices ¯B1, ¯B2, . . . , ¯Bm são chamados de índices básicos e
indicam qual é a coluna da matriz A que faz parte de ¯B;

i, onde cada elemento a ¯Bi

a ¯B1, a ¯B2, . . . , a ¯Bm

• Nm×(n−m) representa a matriz não-básica que é formada pelas n−m colunas restantes
da matriz A. É representada por N = h
i, onde cada elemento aNi
representa uma coluna da matriz A e os índices N1, N2, . . ., Nn−m são chamados
de índices não-básicos e indicam qual é a coluna da matriz A que este elemento
pertencia.

aN1, aN2, . . . , aNn−m

Esta partição nas colunas da matriz A, por sua vez, estabelece uma partição no

vetor X, dividindo as variáveis básicas das variáveis não-básicas.

Deﬁnição 2.2 (Partição Básica de X). O vetor da variáveis pode ser reescrito como

em que



x ¯B1

x ¯B2...








x ¯Bm

• X ¯B

=

• XN =

X =


 ,





X ¯B
XN






, é o vetor das variáveis básicas com m componentes;







xN1

xN2...








xNn−m






, é o vetor das variáveis não-básicas com n − m componentes.





Capítulo 2. Programação Linear

36

A partir destas deﬁnições, o sistema que deﬁne as restrições no modelo algébrico da
, XN

Programação Linear pode ser reescrito utilizando as matrizes ¯B, N e os vetores X ¯B

AX = B

⇐⇒

h ¯B | N

i


 = B.





X ¯B
XN

Note que ¯B X ¯B

+ N XN = B, logo o vetor X ¯B

é dado por

X ¯B

= ¯B−1 B − ¯B−1 N XN .

(2.1)

Deﬁnição 2.3 (Solução Básica). Considere uma partição básica da matriz dos coeﬁcientes
A = h ¯B | N
i. A solução que se obtém ao ﬁxar todas as n − m variáveis de XN em zero é
chamada de solução básica. Esta solução pode ser melhor visualizada como

ˆX =






= ¯B−1B

ˆX ¯B
ˆXN = 0

Em particular, a solução básica é uma solução factível para o problema e será o
ponto de partida na busca da solução ótima, ou seja, a partir dela procura-se uma solução
melhor.

Analogamente aos casos anteriores, obtemos a decomposição abaixo.

Deﬁnição 2.4 (Partição Básica de C). O vetor de custos será dado por

onde,

C = h

C ¯B | CN

i
,

• C ¯B

= h
objetivo;

c ¯B1, c ¯B2,

. . . , c ¯Bm

i, são os coeﬁcientes das variáveis básicas na função

• CN = h
objetivo.

cN1, cN2,

. . . , cNn−m

i, são coeﬁcientes das variáveis não-básicas na função

Vejamos como a função objetivo também pode ser expressa utilizando a estrategia

da partição básica:

Z = C X

⇐⇒

h
C ¯B | CN

i


 = C ¯B X ¯B

+ CN XN = Z.

(2.2)





X ¯B
XN

Substituindo a equação (2.1) na equação (2.2) tem-se

Z = C ¯B

( ¯B−1 B − ¯B−1 N XN ) + CN XN = C ¯B

¯B−1 B − C ¯B

¯B−1 N XN + CN XN (2.3)

Calculando agora a função objetivo na solução básica teremos

ˆZ = C ¯B

ˆX ¯B

+ CN

ˆXN = C ¯B

¯B−1 B + CN 0 = C ¯B

¯B−1 B

(2.4)

Capítulo 2. Programação Linear

37

Em seguida, iremos apresentar a deﬁnição de um vetor auxiliar que facilitará a notação e
os cálculos desenvolvidos a seguir (além disso, é utilizado no construção da dualidade no
problema da Programação Linear, consulte Apêndice A).

Deﬁnição 2.5 (Vetor Multiplicador do Simplex). O vetor m × 1 dado por

λT = C ¯B

¯B−1

é chamado de vetor multiplicador do Simplex (ou vetor de variáveis duais).

A partir do vetor multiplicador do Simplex, realizando as seguintes manipulações
algébricas (detalhadas em (WEBER, 2018)), encontraremos a função objetivo. Primeira-
mente, substituindo a equação (2.4) na equação (2.3), obteremos

Z = ˆZ − C ¯B

¯B−1 N XN + CN XN .

Inserindo o vetor multiplicador do Simplex, da Deﬁnição 2.5, tem-se

Z = ˆZ − λT N XN + CN XN = ˆZ + (CN − λT N ) XN .

(2.5)

(2.6)

Ao expor, na equação (2.6), os elementos de CN e N com seus respectivos índices não-
básicos, em conjunto com o vetor das variáveis não-básicas XN , obteremos a seguinte
função objetivo

Z = ˆZ + (cN1 − λT aN1

)xN1

+ (cN2 − λT aN2

)xN2

+ · · · + (cNn−m − λT aNn−m

)xNn−m. (2.7)

Deﬁnição 2.6 (Custos Relativos). Os coeﬁcientes ˆcNj
custos relativos (ou custos reduzidos).

= (cNj − λT aNj

) são chamados

Dessa forma, poderemos escrever a equação (2.7) como sendo

Z = ˆZ + ˆcN1xN1

+ ˆcN2xN2

+ · · · + ˆcNn−mxNn−m.

Com a introdução do conceito de custo relativo, obtém-se todas as ferramentas
necessárias para saber se a solução é ótima. Para isso, basta procurar algum custo relativo
negativo pois, se este for o caso, tem-se uma solução melhor do que a solução básica.
Por outro lado, se nenhum custo relativo for negativo a solução básica será ótima. Isto
estabelece um importante critério para obter otimalidade.

Deﬁnição 2.7 (Critério de Otimalidade). Dada uma partição básica A = h ¯B | N
i,
considere a solução básica factível ˆX ¯B
= ¯B−1 B ≥ 0 e o vetor multiplicador do Simplex
λT = C ¯B
) ≥ 0, para todo j = 1, 2, . . . , n − m, então a solução
básica é ótima.

= (cNk − λT aNk

¯B−1. Se ˆcNj

Capítulo 2. Programação Linear

38

Esta deﬁnição nos mostra claramente que se todos os custos relativos são não-
negativos, então a solução básica é ótima, pois ao acrescentar valores positivos à função
objetivo obtém-se uma solução pior que a anterior.

De posse do critério de parada para a condição de otimalidade, busca se o processo
para encontrar sempre uma solução factível melhor que a presente; ou seja, caso a solução
básica não seja ótima, como determinar uma outra solução básica factível melhor?

Primeiramente, suponha que solução não ótima é não-degenerada, ou seja, não
apresenta nenhuma solução básica factível com uma variável básica com valor zero. Assim,
existe um custo relativo da variável não-básica xNk
que é negativo, ou seja, existe um k
tal que

ˆcNk

= (cNk − λT aNk

) < 0,

que irá diminuir o valor da função objetivo e fornecer uma solução factível melhor.

Deﬁnição 2.8 (Estratégia Simplex). Denomina-se de estratégia Simplex a perturbação
de uma solução básica factível, que altera as variáveis não-básicas, da seguinte forma






xNk
xNk

= (cid:15) ≤ 0,
= 0,

(variável com custo relativo negativo)

j = 1, 2, . . . , n − m e

j 6= k

Deﬁnição 2.9 (Direção Simplex). A direção Simplex é o vetor que fornece os coeﬁcientes
de como são alteradas as variáveis básicas pela estratégia Simplex.

Atente que a Deﬁnição 2.8 mostra que a estratégia Simplex consiste em pegar uma
variável não-básica xNk
, que possui custo relativo negativo, e atribuí-la um valor (cid:15) ≥ 0,
diminuindo assim a solução básica factível encontrada anteriormente, ao mesmo tempo
continuam igual a zero. É esta perturbação
que todas as outras variáveis não-básicas xNj
que produzirá melhor solução de minimização.

Na literatura, denomina-se regra de Dantzig a escolha da variável não-básica que
possui o menor custo relativo, pois “quanto menor o valor de ˆcNk
, mais rápido a função
objetivo decresce”. Desta forma, passa-se a determinar o maior valor possível de (cid:15) para que
a solução se mantenha factível. Esse processo é chamado de Tamanho do Passo Epsilon.

A partir disso, pode-se repetir o processo, pois se a condição de otimalidade não for
veriﬁcada, busca-se novamente uma nova partição básica, utilizando-se a estratégia Simplex
e determinada pela direção Simplex que melhore a função objetivo. Este processo pode se
repetir quantas vezes for necessário até que a condição de otimalidade seja veriﬁcada.

Ferramentas Computacionais

O Método Simplex basicamente consiste neste procedimento de desenvolvimento
das interações sequenciais para otimização em busca da melhor solução. Neste sentido,

Capítulo 2. Programação Linear

39

existem bibliotecas de linguagem de programação que possuem softwares que são capazes
de aplicar o Método Simplex, ou seja, são ferramentas digitais que já possuem o algoritmo
de resolução desse método devidamente implementado. Esse é o caso do Lindo, do Lingo,
e da ferramenta Solver, disponível por exemplo, para plataforma Windows no software
Microsoft Excel e, para Linux, via LibreOﬃce; dentre essas, e outras possibilidades, nos
limitamos a trabalhar com o Solver que é um complemento do Excel.

Como vimos anteriormente em nosso exemplo motivador, o Solver é uma ferramenta
de análise hipotética que é capaz de identiﬁcar o valor ideal para uma fórmula matemática
alocada numa determinada célula, conhecida como célula de destino dentro de uma
estrutura de planilha devidamente montada respeitando a formulação especíﬁca de um
dado Problema de Programação Linear.

3 Teoria do Transporte Ótimo

40

No presente capítulo, assumiremos a perspectiva da Teoria do Transporte Ótimo.
Discutiremos dois tipos de problemas de transporte, o Problema de Monge e o Problema
de Kantorovich, realizando um breve levantamento histórico desta teoria. Ao ﬁnal, apre-
sentamos a Métrica de Wasserstein, um importante conceito geométrico de Teoria de
Probabilidade caracterizado a partir do Problema de Kantorovich.

Toda nossa pesquisa estará restrita ao caso da Teoria do Transporte Ótimo entre
probabilidades ﬁnitas. Os principais resultados desta teoria, podem ser encontrados nas
referências (PEYRÉ; CUTURI et al., 2019; THORPE, 2018; VILLANI, 2003; VILLANI,
2009). Além disso, precisaremos de alguns pré-requisitos (Teoria de Probabilidade e Espaços
Métricos), os quais serão explorados ao longo do capítulo.

3.1 O Problema de Monge

Gaspard Monge foi um matemático francês que viveu no período de 1746 a 1818.
Desde cedo começou se destacando por apresentar uma grande diversidade de técnicas e
habilidades como desenhista e inventor. Monge já havia concluído seus estudos de ﬁlosoﬁa,
física e matemática aos dezesseis anos, quando foi convidado a trabalhar na Escola Real
de Engenharia de Mézières. Passou vinte anos de sua vida resolvendo um complicado
problema de construção de fortiﬁcações, inventando um novo método que viria a ser o
alicerce da geometria descritiva.

Acredita-se que foi justamente durante a empreitada mencionada anteriormente
que Gaspard Monge fez uma primeira abordagem a respeito de um problema que consiste
em transportar determinada quantidade de massa de uma região a outra, de tal forma
que o custo do trabalho realizado seja mínimo. Em sua versão do problema de transporte,
Monge determinou que a massa a ser transportada não pode ser dividida, ou seja, é preciso
transportar toda massa de um fornecedor para um único consumidor. Esta formulação
vem a ser um caso especíﬁco do problema de transporte da Teoria do Transporte Ótimo e,
por isso, passou a se chamar de Problema de Monge.

Descrevemos abaixo uma versão discreta e ﬁnita do problema de Monge:

• Encontram-se disponíveis em n origens (fornecedores), cada uma com capacidade de

fornecimento ai, para i = 1, 2, . . . , n;

• Serão utilizados m destinos (consumidores), que podem absorver as quantidades bj

com j = 1, 2, . . . , m;

Capítulo 3. Teoria do Transporte Ótimo

41

• Os valores das origens i serão enviados para os destinos j, com um custo de transporte
Cij, esgotando-se as disponibilidades de cada origem e satisfazendo-se as necessidades
em cada destino;

• Deve-se respeitar o fato de que cada origem (fornecedor) precisa enviar seu produto
total a um único destino (consumidor), mas cada destino (consumidor) pode receber
produto de mais de uma origem (fornecedor) para completar sua capacidade.

A partir do último item (a condição determinada por Monge), pode-se descrever

uma relação de transporte entre as n origens e m destinos dada por uma função

T : {i = 1, 2, 3, . . . , n} −→ {j = 1, 2, . . . , m}.

Para que o problema de transporte de Monge tenha uma solução ótima, primeiramente, é
necessário garantir a existência de ao menos uma função T , que realiza o transporte entre
as origens e os destinos, condicionada à seguinte relação entre a capacidade do fornecedor
(ai) e a do consumidor (bj):

bj = X

ai

T (i)=j

para todo i = 1, 2, . . . , n e j = 1, 2, . . . , m.

(3.1)

Uma função deste tipo recebe a denominação de Mapa de Transporte.

A partir disso, procurar-se minimizar a soma de todos os custos Cij, onde i é uma
das origem e j é o destino fornecido por um mapa de transporte T , isto é, T (i) = j, levando
em consideração todos mapas de transporte T que podem ser encontradas no processo de
distribuição. Esta discussão nos remete à formulação matemática dada no Quadro 4.

Quadro 4 – Problema de Monge

Função Objetivo

Sujeita às Restrições

Minimizar Z =

n
X

i=0

CiT (i)

T : {i = 1, 2, 3, . . . , n} −→ {j = 1, 2, . . . , m}

tal que

bj = X

ai

T (i)=j

para todo

i = 1, . . . , n e j = 1, . . . , m.

Onde

{C11, C12, . . . , C21, C22, . . . , Cnm} são custos de transporte;
T : {i = 1, 2, 3, . . . , n} −→ {j = 1, 2, . . . , m} é um mapa de transporte;
{a1, a2, a3, . . . , an} são as capacidades das origens;
{b1, b2, b3, . . . , bm} são as capacidades dos destinos.

Fonte: Elaborado pelo autor.

Capítulo 3. Teoria do Transporte Ótimo

42

Observação. O trabalho de Monge estudava uma versão mais complexa de tal problema,
onde cada índice i ou j seriam representados por pontos no espaço Rn, podendo ter uma
inﬁnidade de tais pontos, e o custo de transporte considerado era a distância Euclidiana
em Rn. As capacidades seriam funções de Rn a valores reais e a condição que deﬁne o
mapa de transporte teria que ser reformulado utilizando integração.

Atente que a condição (3.1) nem sempre se veriﬁca, portanto, este tipo de problema

não apresentará uma solução geral para todos os casos.

Exemplo 3.1. Dadas as origens {i = 1, 2, 3} e os destinos {j = 1, 2}, considere as
seguintes capacidades do fornecedor (ai) e a do consumidor (bj):

a1 = 100,
a2 = 150,
a3 = 170,

e

b1 = 250,
b2 = 140.

É fácil ver que a condição (3.1) não pode ser apresentada para capacidade do fornecedor
j = 2, isto é,

a1 = 100 6= b2,
a2 = 150 6= b2,
a3 = 170 6= b2,

a1 + a2 = 250 6= b2,
a2 + a3 = 320 6= b2,
a3 + a1 = 270 6= b2,

e

a1 + a2 + a3 = 420 6= b2.

(Perceba a similaridade deste problema com o exemplo dado na Seção 2.2.)

No século XIX, foi oferecido um prêmio pela solução do problema de Monge, o
qual foi faturado por Paul Émile Appell, que se mostrou capaz de apresentar algumas
propriedades geométricas acerca do Transporte Ótimo em R2 e em R3 e ainda conseguiu
retiﬁcar algumas observações feitas por Monge em sua resenha original. No entanto,
resultados de existência de solução para o problema de Monge só apareceram no ﬁnal do
século XX — por meio de Sudakov em 1979, Brenier em 1991, Ambrosio em 2003 e etc —
com um tratamento formal do problema de transporte da Teoria do Transporte Ótimo,
dado pelo Problema de Kantorovich.

3.2 O Problema de Kantorovich

Leonid Vitaliyevich Kantorovich nasceu em São Petersburgo e desde muito jovem
foi reconhecido como um estudante extremamente talentoso. Matriculou na graduação em
Matemática da Universidade Estadual de Leningrado com quatorze anos, aos vinte já des-
pontava como professor titular do Instituto de Engenharia de Construção Industrial desta
universidade e três anos depois, concluiu seu doutorado em Ciências Físico-Matemáticas.

Capítulo 3. Teoria do Transporte Ótimo

43

Kantorovich contribuiu tanto para o desenvolvimento da Matemática quanto das
Ciências Econômicas. No campo do desenvolvimento econômico, Leonid conseguiu intro-
duzir reformas ao design econômico da União Soviética, desenvolvendo ﬂexibilidade na
teoria Marxista. Já no campo da Matemática, aprimorou um método linear dos multipli-
cadores de Lagrange, o qual é bastante semelhante ao utilizado na Programação Linear
atualmente. Mas, sua principal contribuição em ambas as áreas foi ter gerado novas ideias
em torno do problema de alocação e transporte de recursos, pelas quais recebeu, em 1975,
o Prêmio de Ciências Econômicas em Memória de Alfred Nobel, em conjunto com Tjalling
Koopmans. Além desta homraria, Kantorovich também recebeu o Prêmio do Estado de
Stalin e o Prêmio Lenin, considerados duas das maiores honras para cientistas da União
das Repúblicas Socialistas Soviéticas (URSS), e foi eleito postumamente para o Hall da
Fama da Federação Internacional das Sociedades de Pesquisa Operacional em 2003.

Para que seja possível discutir o Problema de Kantorovich, que consistirá na
formulação geral do problema de transporte da Teoria do Transporte Ótimo, precisaremos
de alguns pré-requisitos.

Teoria de Probabilidade

Faremos uma abordagem concisa de alguns importantes conceitos da Teoria de
Probabilidade. Para uma apresentação mais detalhada das deﬁnições abaixo, veja a
referência (ROSS, 2009).

Deﬁnição 3.2. Dizemos que p = (p1, p2, . . . , pn)T ∈ Rn é um vetor de probabilidade se
suas coordenadas p1, p2, . . . , pn satisfazem as condições:

(P1) pi ≥ 0, para todo i ∈ {1, 2, . . . , n};

(P2) p1 + p2 + · · · + pn = 1.

Para compreendermos melhor a deﬁnição de vetor de probabilidade, começaremos

ilustrando uma situação-problema, da qual poderemos extrair tais deﬁnições.

Exemplo 3.3. Consideremos três caixas denotadas por R1, R2 e R3. Suponhamos que
existam um total de 100 pequenas bolas distribuídas dentro destas caixas. Não estamos
interessados em entender o comportamento de cada bola, mas a distribuição delas nas
caixas R1, R2 e R3.

Se temos R1 com 30 bolas, R2 com 50 bolas e R3 com 20 bolas, isto signiﬁca
que 30% das bolas estão em R1, 50% das bolas estão em R2 e 20% estão em R3. Como
não temos interesse na quantidade total de bolas, uma forma simples de representar essa
distribuição é considerar um vetor coluna com 3 coordenadas indicando os respectivos

Capítulo 3. Teoria do Transporte Ótimo

44

percentuais (em notação decimal) de cada região, ou seja,

p =








0, 3
0, 5
0, 2








.

No caso em que R1 possui 55 bolas, R2 com 45 bolas e R3 nenhuma bola, teríamos








q =








0, 55
0, 45
0

.

Com isso, a qualquer distribuição de bolas associa-se um vetor que possui três coordenadas
não negativas cuja soma resulta em 1.

Vejamos como representar graﬁcamente os vetores de probabilidade.

Deﬁnição 3.4. O histograma associado a um vetor de probabilidade p = (p1, p2, . . . , pn)T,
consiste no gráﬁco de uma função cujo domínio é dado pelos índices do vetor {1, 2, 3, . . . , n}
e os valores de cada coordenada pi fornecem a frequência (ou altura da barra) associada
ao índice i.

Exemplo 3.5 (Lançamento de um dado). Sabemos que a chance de cair um certo número
no lançamento de um dado (honesto) é de 1 em 6, ou seja, cada face deste dado tem

probabilidade
deste dado por um vetor de probabilidade de coluna com 6 coordenadas

de aparecer. Representamos a distribuição da probabilidade de cada face

1
6

p =

(cid:18) 1
6 ,

1
6 ,

1
6,

1
6,

1
6 ,

1
6

(cid:19)T

,

onde cada entrada de índice i fornece a probabilidade de cair a face i virada para cima.
Segundo a Deﬁnição 3.4, seu respectivo histograma é apresentado na Figura 6.

Figura 6 – Histograma do Lançamento de um Dado Honesto p

Fonte: Elaborada pelo autor.

Capítulo 3. Teoria do Transporte Ótimo

45

Analogamente, se o dado for viciado, o lançamento pode dar preferência para uma
ou mais faces fornecendo outros vetores de probabilidades (ou de frequências) e respectivos
histogramas:

q = (0, 1; 0, 15; 0, 2; 0, 3; 0, 15; 0, 1)T

e

r = (0, 1, 0, 0, 0, 0)T .

As Figuras 7 e 8 representam os histogramas das distribuições q e r, respectivamente.

Figura 7 – Histograma do Lançamento de um Dado Viciado q

Fonte: Elaborada pelo autor.

Figura 8 – Histograma do Lançamento de um Dado Viciado r

Fonte: Elaborada pelo autor.

O conjunto de todas as possíveis distribuições de probabilidades associadas a um
experimento aleatório ou situação-problema é um importante subconjunto de Rn. Vamos
denotar por Pn o conjunto formado por todos os vetores de probabilidade de tamanho n.

Veremos na próxima subseção que a formulação de Kantorovich para o problema
de transporte, utilizará vetores de probabilidade com o intuito de realizar um “transporte”
entre suas coordenas. Antes, vamos deﬁnir a matriz de plano de transporte.

Capítulo 3. Teoria do Transporte Ótimo

46

Deﬁnição 3.6 (Plano de Transporte). Dados vetores de probabilidade

a = (a1, a2, . . . , an)T ∈ P n

e

b = (b1, b2, . . . , bm)T ∈ P m,

denominamos uma matriz

X =








X11
...
Xn1








· · · X1m
...
. . .
· · · Xnm

∈ Rn×m
+

de plano de transporte, se obedece as condições:

(T1) A soma em cada linha da matriz X fornece a respectiva entrada do vetor de

probabilidade a, ou seja,

Xij = ai para todo i = 1, 2, . . . , n;

(T2) A soma em cada coluna da matriz X fornece a respectiva entrada do vetor de

probabilidade b, isto é,

Xij = bj para todo j = 1, 2, . . . , m.

Exemplo 3.7 (Plano de Transporte I). Dadas as probabilidade




a =

∈ P3

e

b =





0, 64
0, 36


 ∈ P2

m
X

j=1

n
X

i=1

0, 24
0, 36
0, 40











vamos veriﬁcar que a matriz



0, 24
0
0, 40
é um plano de transporte de a para b. De fato,

X =













0
0, 36
0

(T 1) :





0, 24 + 0 = 0, 24 = a1
0 + 0, 36 = 0, 36 = a2
0, 40 + 0 = 0, 40 = a3

e

(T 2) :






0, 24 + 0 + 0, 40 = 0, 64 = b1
0 + 0, 36 + 0, 40 = 0, 36 = b2

.

Analogamente, podemos identiﬁcar (T1) e (T2) no seguinte caso:

¯X =








0, 16 0, 08
0, 36
0, 12 0, 28

0






















0, 24
0, 36
0, 40

= a

b = (cid:16)0, 64 0, 36(cid:17)T

Donde,

(T 1) :





0, 16 + 0, 08 = 0, 24 = a1
0, 36 + 0 = 0, 36 = a2
0, 12 + 0, 28 = 0, 40 = a3

e

(T 2) :






0, 16 + 0, 36 + 0, 12 = 0, 64 = b1
0, 08 + 0 + 0, 28 = 0, 36 = b2

.

Capítulo 3. Teoria do Transporte Ótimo

47

Também é possível reescrever os sistemas (T1) e (T2) algebricamente, para isso,

considere o vetor coluna

1n =



1


1




...








1






n cópias,

e observe que:

X 1n =








X11
...
Xn1

· · · X1m
...
. . .
· · · Xnm
















1
...




1

=








X11 + . . . + X1m
...
Xn1 + . . . + Xnm








=








= a.








a1
...
a2

X T 1m =








· · · X1n
X11
...
...
. . .
X1m · · · Xmn
















1
...




1

=








X11 + . . . + X1n
...
Xm1 + . . . + Xmn








=








b1
...
b2








= b.

Vejamos outro exemplo de plano de transporte sob este ponto de vista algébrico.

Exemplo 3.8 (Plano de Transporte II). A matriz

X =


0

0



0

1
4
0

1
20








0 0
1
4
0 0 0
0 1
5

1
4

é um plano de transporte entre os vetores de probabilidade a =
(cid:18)

(cid:19)T

0,

3
10,

1
2 , 0,

1
5

. De fato,

(cid:19)T

(cid:18) 1
2 , 0,

1
2

e b =

X 1n =








1
20

1
4

+ 1
4
0
+ 1
4

+ 1
5








=















1
2
0

1
2

= a

e

X T 1n =



























0
+ 1
20
+ 1
4
0

1
4
1
4

1
5

=



























0

3
10
1
2
0

1
5

= b.

Apresentamos uma última deﬁnição e um ultimo resultado que serão fundamentais

para apresentar o problema de transporte da Teoria do Transporte Ótimo.

Deﬁnição 3.9. Deﬁnimos o conjunto de todos planos de transporte entre os vetores de
probabilidade a ∈ Pn e b ∈ Pm como

U (a, b) =

X ∈ Rn×m

+





= n

X ∈ Rn×n

+

m
X

:

Xij = ai

e

n
X

Xij = bj

j=1
: X 1n = a

e

i=1
X T 1m = b





o

.

Capítulo 3. Teoria do Transporte Ótimo

48

Proposição 3.10. Existe ao menos um plano de transporte entre os vetores de probabili-
dade a ∈ Pn e b ∈ Pm (ou seja, U (a, b) 6= ∅).

Demonstração. A partir dos vetores

a = (a1, a2, . . . , an)T ∈ P n

e

b = (b1, b2, . . . , bm)T ∈ P m,

deﬁna a matriz n × m

X =











a1 b1 a1 b2
a2 b1 a2 b2
...
...
an b1 an b2

· · · a1 bm
· · · a2 bm
. . .

...

· · · an bm











.

Para garantir que X = (cid:16)
condições

(cid:17)

ai bi

ij

∈ U (a, b), basta veriﬁcar que tal matriz satisfaz as

(T 1) :

(T 2) :

m
X

j=1

n
X

i=1

Xij =

Xij =

m
X

j=1

n
X

i=1

ai bj = ai





m
X



bj



= ai

ai bj = bj

j=1
{z
=1

|

  n
X

ai

}

!

i=1
{z
=1

|

}

= bj

onde as últimas igualdades seguem do fato de que a e b são vetores de probabilidade.

Observação. Nos trabalhos originais de Kantorovich, deﬁne-se a classe de planos de
transporte como sendo o conjunto de todas as medidas de probabilidades sobre o respectivo
espaço produto e com distribuições marginais ﬁxadas que representam, respectivamente,
as distribuições de massa inicial e ﬁnal.

Problema de Transporte da Teoria do Transporte Ótimo

Em 1942, Kantorovich, mesmo sem ter conhecimento do trabalho de Monge acerca
do problema de transporte, escreveu um artigo no qual apresentou uma nova formulação
que se mostrou inovadora e suscetível de solução, quando comparada com o Problema
de Monge. A formulação de Kantorovich substituía o problema de obter um mapa de
transporte pelo problema de encontrar um plano de transporte, e assim minimizar o custo
total. O grande diferencial foi permitir que a massa a ser transportada de uma origem possa
ser fragmentada entre os diversos destinos disponíveis, o que gerou maiores possibilidades
de distribuição da massa total.

Descrevemos abaixo uma versão discreta e ﬁnita da proposta de Kantorovich:

• Encontram-se disponíveis em n origens, com capacidade ai, para i = 1, 2, . . . , n;

Capítulo 3. Teoria do Transporte Ótimo

49

• Serão utilizados m destinos, que podem absorver as quantidades bj com j =

1, 2, . . . , m;

• Assumimos que as capacidade das origens e dos destinos formam vetores de probabi-

lidade (a1, a2, . . . , an) e (b1, b2, . . . , bm);

• Os valores das origens i podem ser enviados para os destinos j, com um custo de

transporte (por unidade) Cij;

• Será permitido particionar a capacidade de cada origem i e transportá-los para os
destinos j, por meio de um plano de transporte Xij, esgotando-se as disponibilidades
de cada origem e satisfazendo-se as necessidades em cada destino.

Os dois últimos item serão reescritos em termos matemático, isto é

m
X

j=1

Xij = ai

e

Já o terceiro item acima impõem as condições

n
X

i=1

ai = 1

e

n
X

i=1

m
X

j=1

Xij = bj.

bj = 1.

O Problema de Kantorovich consiste basicamente em determinar o menor custo da
distribuição de um determinado produto, de modo a minimizar o somatório de todos os
custos de transporte por quantidades transportadas Cij Xij, levando em consideração todos
os possíveis planos de transportes Πij ∈ U (a, b) envolvidos no processo de distribuição.
Dessa forma, apresentamos no Quadro 5 a formulação geral do Problema de Kantorovich.

Capítulo 3. Teoria do Transporte Ótimo

50

Quadro 5 – Problema de Kantorovich

Função Objetivo

Minimizar Z =

n
X

m
X

i=1

j=1

CijXij

Sujeita às Restrições

X ∈ U (a, b) =






X ∈ Rn×m

+

:

m
X

j=1

Xij = ai

e

n
X

i=1

Xij = bj






a ∈ Pn

ou seja,

!

ai = 1

n
X

i=1

e

b ∈ Pm


isto é,


 .

bj = 1

m
X

j=1

Onde

C denota a matriz de custos de transporte cujas entradas Cij são os custo

unitário de transporte da origem i até cada o destino j;

X denota um plano de transporte, cujas entradas Xij são as quantidades

a ser transportada de cada origem i para o destino j;

a = (a1, a2, . . . , an)T denota o vetor de probabilidade, com coordenadas ai

que são as capacidades das origens;

b = (b1, b2, . . . , bm)T denota o vetor de probabilidade, com coordenadas bj

que são as capacidades dos destinos.

Fonte: Elaborado pelo autor.

De forma concisa, podemos reduzir a uma única expressão

Z = min

X∈U (a,b)

n
X

m
X

i=1

j=1

CijXij.

A existência de um plano de transporte ótimo é veriﬁcada de forma mais simples no
formalismo de Kantorovich.

Proposição 3.11. Sempre existe plano de transporte Π ∈ U (a, b) tal que

Z = min

X∈U (a,b)

n
X

m
X

i=1

j=1

CijXij =

n
X

m
X

i=1

j=1

CijΠij.

Demonstração. Utilizaremos um resultado clássico do cálculo em várias variáveis (LIMA,
2020, Capítulo 8, Proposição 4): toda função (a valores reais) contínua deﬁnida em um
conjunto fechado e limitado (compacto) possui pontos de máximo e mínimo.

Primeiramente, estamos investigando a função (a valores reais)

Φ :

U (a, b)

X = (Xij)

−→ R
n
X

7−→

m
X

i=1

j=1

CijXij,

 
Capítulo 3. Teoria do Transporte Ótimo

51

Por ser uma função linear nas variáveis Xij, ela é uma função contínua.

Resta argumentar que o conjunto U (a, b) ⊂ Rn×m é fechado e limitado (para a
deﬁnição de tais noções, consulte (LIMA, 2020)). Perceba que as variáveis Xij estão
restritas ao intervalo [0, 1], logo U (a, b) é um subconjunto do cubo n × m-dimensional
[0, 1]n×m, o qual é um conjunto limitado. Para mostrar a propriedade fechada, considere
as seguintes funções

αi : U (a, b) −→ R
m
X

X

7−→

e

Xij

βj : U (a, b) −→ R
n
X

X

7−→

Xij

j=1

i=1

para todo 1 ≤ i ≤ n e 1 ≤ j ≤ m. Note que as restrições que deﬁnem as matrizes em
U (a, b) podem ser escritas através dos conjuntos α−1
(bj), para
1 ≤ j ≤ m. Em particular, por serem funções (lineares) contínuas, todos estes conjuntos
são fechados. Por construção, temos que

(ai), para 1 ≤ i ≤ n, e β−1

j

i

U (a, b) =

!

\

α−1
i

(ai)

  n
\

i=1


 .

(bj)

β−1
j





m
\

j=1

Como as interseções de conjuntos fechados também são conjuntos fechados, garantimos
que U (a, b) é fechado, donde segue o resultado.

Observação. Outras forma equivalente de apresentar o problema de transporte da Teoria de
Transporte Ótimo, é conhecida como Dualidade de Kantorovich. Trata-se de um resultado
clássico que pode ser encontrado nas referências (VILLANI, 2003; THORPE, 2018; PEYRÉ;
CUTURI et al., 2019).

3.3 Elo entre a Teoria de Transporte Ótimo e a Programação Linear

Para compreender a conexão entre as formulações do problema de transporte na
Teoria de Transporte Ótimo (Quadro 5) e na Programação Linear (Quadro 2 e Quadro 3),
necessitamos traduzir:

• a função objeto Z =

coluna;

n
X

m
X

i=1

j=1

CijXij em um produto de um vetor linha por um vetor

• e as restrições

m
X

j=1

Xij = ai e

n
X

i=1

Xij = bj, num sistema linear dado por.

Como teremos que transformar matrizes em vetores, introduzimos o procedimento

de vetorização de matrizes

Capítulo 3. Teoria do Transporte Ótimo

52

Deﬁnição 3.12. (Vetorização de Matrizes) A partir de uma matriz n × m

M =








x11
...
xn1








· · · x1m
...
. . .
· · · xnm

deﬁniremos um vetor coluna nm × 1, empilhando as colunas da matriz M































x1,1
...
xn,1
x1,2
...
xn,2
...
x1,m
...
xn,m































.

vet(M ) =

Para a função objetivo,

vet(C)(cid:124) vet(X) = (cid:16)

C11, · · · , Cn1 | C12, · · · , Cn2 | · · · | C1m, · · · , Cnm

(cid:17)

n
X

m
X

=

i=1

j=1

CijXij = Z.































X11
...
Xn1
X12
...
Xn2
...
X1m
...
Xnm































Por outro lado, para traduzir as restrições, utilizaremos as seguintes notações
para a matriz identidade e para o vetor linha com todas as entradas 1 em dimensão n,
respectivamente

Idn =











1 0 · · · 0
0 1 · · · 0
...
...
. . .
0 0 · · · 1

...











e

ˆ1n = (1, 1, · · · , 1)
}

|

{z
n cópias

.

Capítulo 3. Teoria do Transporte Ótimo

53

A restrição do tipo

m
X

Xij = ai realizará a soma de coordenadas de vet(X) com espaçamento

de n. Temos então que

j=1











|

1 0 · · · 0
0 1 · · · 0
...
...
. . .
0 0 · · · 1

...

Idn

· · ·

Idn

{z
m cópias































X11
...
Xn1
X12
...
Xn2
...
X1m
...
Xnm









































}

=











X11 + X12 + · · · + X1m
X21 + X22 + · · · + X2m
...
Xn1 + Xn2 + · · · + Xnm











=











= a.











a1
a2
...
an

Já a restrição do tipo

n
X

Xij = bj, a soma as m coordenadas de vet(X) em sequência,

donde utilizaremos o vetor ˆ1n, isto é,

i=1











|

1 · · · 1
0
...
0

0
ˆ1n
0

0

· · ·

0

0
· · ·
...
. . .
· · · ˆ1n

{z
m×m subdivisões











}































X11
...
Xn1
X12
...
Xn2
...
X1m
...
Xnm































=











X11 + X21 + · · · + Xn1
X12 + X22 + · · · + Xn2
...
X1m + X2m + · · · + Xnm











=





















b1
b2
...
bm

= b

Podemos agora reapresenta o problema de Kantorovich em termos do seguinte

problema de Programação Linear dado no Quadro 6.

Capítulo 3. Teoria do Transporte Ótimo

54

Quadro 6 – Problema de Kantorovich em Termos da Programação Linear

Função Objetivo

Minimizar Z = vet(C)(cid:124) vet(X)

Sujeita às Restrições

Avet(X) = B,

vet(X) ≥ 0

e B ≥ 0

Onde

vet(C)T = (cid:16)

C11, . . . , Cn1 | C12, . . . , Cn2 | . . . | C1m, . . . , Cnm

(cid:17)

,

vet(X) =


























X11
...
Xn1
X12
...
Xn2
...
X1m
...
Xnm


























,

A =












Idn
1 · · · 1
0
...
0

Idn
0
ˆ1n
0
0

· · ·
· · ·
· · ·
. . .
· · ·












Idn
0
0
...
ˆ1n

e

B =

#

"a
b

=















.















a1
...
an
b1
...
bm

Fonte: Elaborado pelo autor.

3.4 Distância de Wasserstein

Concluída a parte de apresentação do problema de transporte da Teoria do Trans-
porte Ótimo, iniciaremos uma discussão sobre as características geométricas e intrínsecas
do Problema de Kantorovich. Para que seja possível introduzir a Métrica de Wassers-
tein, que consistirá na ferramenta que fornece a estrutura geométrica a ser investigada,
precisaremos de mais alguns pré-requisitos.

Espaço Métrico

Veremos nesta subseção uma noção bastante simples acerca do conceito de uma
distância. Para mais detalhes sobre este tópico, consulte a referência (LIMA, 2020; DEZA;

Capítulo 3. Teoria do Transporte Ótimo

55

DEZA, 2009).

Intuitivamente uma distância representa a medida do espaço que separa dois objetos.
Uma métrica é um conceito que generaliza essa ideia geométrica de distância e se mostra
uma ferramenta de muita importância em vários campos da ciência e tecnologia, tais como:
Geometria, Teoria dos Grafos e Redes, Computação Gráﬁca, Probabilidade, Estatística,
Astronomia, Biologia, Física, dentre outros.

Deﬁnição 3.13. Uma métrica (ou distância) sobre um conjunto não vazio M qualquer
pode ser entendida como uma função d : M × M → R+, que deve satisfazer às seguintes
propriedades:

(M1) Ser simétrica, ou seja, d(x, y) = d(y, x) para todo x, y ∈ M ;

(M2) Ser nula para pontos coincidentes, isto é, d(x, y) = 0 se e somente se x = y;

(M3) Atender à desigualdade triangular, dada por

d(x, z) ≤ d(x, y) + d(y, z)

para todo

x, y, z ∈ M.

Essas propriedades são facilmente veriﬁcadas nos seguintes casos.

Exemplo 3.14 (Reta Real R). A métrica usual sobre o a reta real R é simplesmente
d : R × R → R+ deﬁnida por

isto é, o valor absoluto da diferença entre dois números.

d(x, y) = |x − y|,

Para estes casos particulares, a desigualdade triangular pode ser interpretada, de
maneira intuitiva, através do fato que o comprimento de qualquer um dos lados de um
triângulo não pode ser maior que a soma dos outros dois lados.

Ter um conjunto munido de uma função que atende às condições mostradas na
deﬁnição anterior, ou seja, às propriedades de uma métrica, nos garante uma estrutura
geométrica sobre este conjunto cujas características podem ser exploradas.

Deﬁnição 3.15. Deﬁniremos um espaço métrico como sendo um par ordenado (M, d) no
qual M é um conjunto não vazio e d é uma métrica em M .

Vamos ver alguns exemplos já conhecidos de espaços métricos.

Exemplo 3.16 (Plano R2). Sejam x = (x1, x2) e y = (y1, y2) elementos de R2. Deﬁniremos
a métrica d : R2 × R2 → R+ como sendo

d(x, y) = kx − yk = q(x1 − y1)2 + (x2 − y2)2.

O Plano Euclidiano (R2, d) é um espaço métrico.

Capítulo 3. Teoria do Transporte Ótimo

56

Exemplo 3.17 (Espaço Euclidiano n-dimensional Rn). Sejam x = (x1, x2, x3, x4, . . . , xn)
e y = (y1, y2, y3, y4, . . . , yn) elementos de Rn. Consideramos o espaço métrico Euclidiano
n-dimensional (Rn, d), cuja a métrica d : Rn × Rn → R+ é

d(x, y) =

v
u
u
t

n
X

i=1

(xi − yi)2.

(Vale salientar que esta não é a única métrica deﬁnida em Rn, veja (LIMA, 2020).)

Veremos abaixo uma construção mais abstrata de espaço métrico.

Exemplo 3.18 (Conjunto de três elementos). Considere um conjunto M formado por
três objetos aleatórios, por exemplo, uma cadeira, uma mesa e um sofá, denotados por c,
m e s, respectivamente. Deﬁnimos a seguinte função d : M × M → R+ tal que:

d(c, c) = 0,

d(m, m) = 0,

d(s, s) = 0,

d(c, m) = 1,

d(m, c) = 1,

d(m, s) = 1,

d(s, m) = 1,

d(s, c) = 1 e d(c, s) = 1.

O Lema 3.19 mostra que M = {c, m, s} é um espaço métrico.

Lema 3.19. O conjunto M = {c, m, s} munido da função d : M × M → R+ dada por



d(x, y) =

0,
1,

se x = y
se x 6= y



é um espaço métrico.

Demonstração. Temos que veriﬁcar a validade das propriedades da Deﬁnição 3.13. Através
da construção do exemplo, ﬁca notório a veriﬁcação da positividade da função d, pois
segue do próprio enunciado que d(x, y) = 0 ou d(x, y) = 1 > 0 para quaisquer que sejam
x, y ∈ M .

A partir do enunciado, temos

d(x, y) = 1 = d(y, x)

e d(x, x) = 0

Segue que, para quaisquer que sejam x, y ∈ M , teremos d(x, y) = d(y, x) e, assim,
veriﬁcamos a propriedade (M1). Da mesma forma, temos que d(x, x) = 0 para qualquer
x ∈ M . Logo d(x, y) = 0 se, e somente se, x = y, donde veriﬁcamos a propriedade (M2).

Para mostrarmos a propriedade (M3), que é a desigualdade triangular, iremos

dividir a análise em dois casos:

• Caso 1: Se x = z, então d(x, z) = 0. Logo 0 = d(x, z) ≤ d(x, y) + d(y, z), pois 0 é
menor ou igual que a soma de quaisquer números não negativos, inclusive o próprio
0;

Capítulo 3. Teoria do Transporte Ótimo

57

• Caso 2: Se x 6= z, então d(x, z) = 1. Observe que sem dúvidas teremos ou x 6= y ou
z 6= y, visto que, se x = y e y = z então x = z, contrariando a hipótese. Dessa forma,
d(x, z) = 1 ≤ d(x, y) + d(y, z).

Observação. De maneira geral, qualquer conjunto ﬁnito X pode se tonar um espaço métrico
usando a construção demonstrada acima. Para tanto, basta que deﬁnamos a métrica zero-
um que satisfaz d(x, x) = 0 para qualquer x ∈ X e d(x, y) = 1 para quaisquer que sejam
x, y ∈ X, com x 6= y.

Exemplo 3.20 (Distância entre Índices). O conjunto ﬁnito dos n primeiro números natu-
rais {1, 2, 3, . . . , n} se torna um espaço métrico se o munirmos da métrica d : {1, 2, . . . , n} ×
{1, 2, . . . , n} → R+ tal que

d(i, j) = |i − j|.

Trata-se da restrição da distância Euclidiana em R a um subconjunto próprio, logo satisfaz
todas as propriedades da Deﬁnição 3.13.

Propriedades Métricas do Problema de Transporte

Nesta seção, introduziremos mais um exemplo de espaço métrico, cujo conjunto
base será o espaço dos vetores de probabilidade Pn. A função distância estará intimamente
relacionada ao problema de transporte da Teoria do Transporte Ótimo e, consequentemente,
a Programação Linear.

Teorema 3.21. Considere C uma matriz de custos n × n que satisfaz:

(C1) A matriz C é simétrica, ou seja, Cij = Cji;

(C2) Cij = 0 se, e somente se, i = j;

(C3) Cik ≤ Cij + Cjk para quaisquer índices i, j, k.

Então

W (a, b) = min

X∈U (a,b)

n
X

n
X

i=1

j=1

CijXij

é uma métrica, denominada de distância (ou métrica) de Wasserstein, e o espaço dos
vetores de probabilidade munido desta distância, (Pn, W ), é um espaço métrico.

Perceba que as condições sobre a matriz de custos do problema de transporte se
assemelham com as propriedades (M1), (M2) e (M3) de uma métrica (da Deﬁnição 3.13).
Em particular, podemos aﬁrmar que d(i, j) = Cij determina uma distância sobre o conjunto
de índices {1, 2, . . . , n}.

Capítulo 3. Teoria do Transporte Ótimo

58

De forma mais geral, o resultado acima estabelece que o valor ótimo do problema
de transporte herdará as propriedades de distância de sua matriz de custos, quando esta
determina uma métrica entre as localizações investigadas no problema de transporte, ou
seja, as origens e os destinos. A demonstração desenvolvida abaixo detalha as linhas gerais
da prova apresentada em (PEYRÉ; CUTURI et al., 2019, Proposição 2.2).

Demonstração. Partindo de (C1), (C2), (C3) e das particularidades do problema de
Kantorovich, queremos provar as propriedades (M1), (M2) e (M3) da Deﬁnição 3.13 para
a métrica de Wasserstein W (a, b).

Note que, a positividade de W é consequência dos custos e planos de transportes

sempre serem valores não negativos,

Cij ≥ 0 e Xij ≥ 0

=⇒

W (a, b) = min

X∈U (a,b)

n
X

n
X

i=1

j=1

CijXij ≥ 0.

Veriﬁcaremos a primeira propriedade (M1), a simetria. Observe a reescritura

n
X

n
X

i=1

j=1

CijXij

(C1)=

n
X

n
X

j=1

i=1

CjiX T
ji.

Sabemos que sempre é possível selecionar um plano de transporte ótimo F ∈ U (a, b), isto
é, que atinge o valor mínimo do problema de transporte de a para b, logo

W (a, b) =

n
X

n
X

i=1

j=1

Cij Fij.

Deste plano de transporte, obtemos outro plano F T que transporta b até a. Veja que

W (a, b) =

n
X

n
X

i=1

j=1

CijFij

(C1)=

n
X

n
X

j=1

i=1

Cji F T

ji ≥ min

X∈U (b,a)

n
X

n
X

j=1

i=1

CjiX T
ji

= W (b, a).

Por outro lado, selecionamos o plano de transporte ótimo G ∈ U (b, a), tal que

W (b, a) =

n
X

n
X

j=1

i=1

Cji Gji,

e observamos que

W (b, a) =

n
X

n
X

j=1

i=1

CjiGji

(C1)=

n
X

n
X

j=1

i=1

Cij GT

ij ≥ min

X∈U (b,a)

n
X

n
X

i=1

j=1

CijXij = W (a, b).

Portanto, dois valores são menores e iguais entre si sempre que W (a, b) = W (b, a) e, assim,
a distância de Wasserstein é simétrica.

Para obter a segunda propriedade (M2), vamos veriﬁcar a nulidade para pontos

coincidentes.

Capítulo 3. Teoria do Transporte Ótimo

59

• a = b =⇒ W (a, b) = W (a, a) = 0:

Primeiramente, tomamos

A =











a1
0
...
0

e calculamos

n
X

n
X

i=1

j=1

Cij Aij =

Como W (·, ·) ≥ 0, temos que

0

a2
...
0

n
X

i=1











· · ·
· · ·
. . .

0
0
...
· · · an

∈ U (a, a)

Cii ai

(C2)=

n
X

n
X

i=1

j=1

0 · ai = 0.

0 ≤ W (a, a) = min

X∈U (a,a)

n
X

n
X

i=1

j=1

Cij Xij ≤

n
X

n
X

i=1

j=1

Cij Aij = 0

Logo, a matriz A é um plano de transporte ótimo e W (a, a) = 0.

• W (a, b) = 0 =⇒ a = b:

Suponha que existe um plano de transporte ótimo Π ∈ U (a, b), tal que

n
X

n
X

i=1

j=1

Cij Πij = W (a, b) = 0.

Como Cij ≥ 0 e Πij ≥ 0, temos que Cij Πij = 0 para todo 1 ≤ i, j ≤ n. Segue daí
que

Para i = j, teremos Cij = Cii

(C2)= 0;

Para i 6= j, teremos Cij

(C2)
6= 0, logo Πij = 0.

Mas recorde que Πij é um plano de transporte, que veriﬁca as condições

ai =

m
X

j=1

Πij = Πii

e

bj =

n
X

i=1

Πij = Πjj

para todo 1 ≤ i, j ≤ n, portanto

Π =











0
Π11
0 Π22
...
...
0
0

0
· · ·
0
· · ·
...
. . .
· · · Πnn











=











a1
0
...
0

0

a2
...
0











· · ·
· · ·
. . .

0
0
...
· · · an

=











b1
0
...
0

0

b2
...
0

· · ·
· · ·
. . .

· · ·











0
0
...
bn

.

Em particular, temos ak = bk, ou seja, a = b

Para obter a desigualdade triangular (M3),

W (a, c) ≤ W (a, b) + W (b, c),

consideremos:

Capítulo 3. Teoria do Transporte Ótimo

60

• P um plano de transporte ótimo entre a e b, isto é, W (a, b) =

n
X

n
X

i=1

k=1

CikPik e

P ∈ U (a, b)

⇐⇒






P 1n = a
P T 1n = b

ou






Pn

j=1 Pkj = ak
i=1 Pik = bk

Pn

.

• Q um plano de transporte ótimo entre b e c, ou seja, W (b, c) =

n
X

n
X

k=1

j=1

CkjQkj e

Q ∈ U (b, c)

⇐⇒






Q 1n = b
QT 1n = c

ou






Pn

Pn

j=1 Qkj = bk
j=1 Qjk = ck

.

Assumiremos que o vetor de probabilidade b não tenha coordenada nula, ou seja
bi 6= 0 para todo 1 ≤ i ≤ n. Caso contrário, bk = 0 para algum k, observe que não há
nada o que ser transportado das entradas de a para bk, logo a k-ésima coluna do plano P
será toda zero, e também nada será transportado de bk para as entradas de c, donde a
k-ésima linha do plano Q será toda nula. Sendo assim, os produtos envolvendo os termos
Pik = Qkj = 0 seriam ignorados nas contas que se seguem.

Deﬁniremos a matriz S da seguinte forma

S = P











1
b1
0
...
0

0

1
b2

...
0

· · ·
· · ·
. . .

· · ·











0
0
...

1
bn

Q.

Inicialmente, veriﬁcaremos que S é um plano de transporte entre a e c, isto é,

S ∈ U (a, c)

⇐⇒






S 1n = b
ST 1n = c

.

Multiplicando a equação que deﬁne S por 1n, em ambos os lados, teremos:

S 1n = P











1
b1
0
...
0

0

1
b2

...
0

· · ·
· · ·
. . .

· · ·











0
0
...

1
bn

= P

Q 1n
| {z }
=b











1
b1
0
...
0

0

1
b2

...
0

· · ·
· · ·
. . .

· · ·











0
0
...

1
bn

Analogamente, segue que











= P 1n = a.











b1
b2
...
bn

ST 1n = QT











1
b1
0
...
0

0

1
b2

...
0

· · ·
· · ·
. . .

· · ·

T











0
0
...

1
bn

= QT

P T 1n
| {z }
=b











1
b1
0
...
0

0

1
b2

...
0

· · ·
· · ·
. . .

· · ·































b1
b2
...
bn

0
0
...

1
bn

= QT 1n = c.

Capítulo 3. Teoria do Transporte Ótimo

61

Agora, vamos obter a desigualdade triangular para a métrica de Wasserstein,
utilizando o plano de transporte S como valor intermediador. isto é, vamos mostrar que

W (a, c) ≤

n
X

n
X

i=1

j=1

Cij Sij ≤ W (a, b) + W (b, c).

Pela deﬁnição da matriz S, temos que

Sij =

n
X

k=1

Pik

1

bk

Qkj.

Com isso,

W (a, c) = min

X∈U (a,c)

n
X

n
X

Cij Xij

S∈U (a,c)
≤

n
X

n
X

i=1

j=1

Cij Sij

i=1

j=1
  n
X

n
X

n
X

Cij

Pik

i=1

j=1

k=1

n
X

n
X

n
X

(cid:18)

Pik

Cij

i=1

j=1

k=1

!

Qkj

(cid:19)

Qkj

1

bk

1

bk

n
X

n
X

n
X

(C3)
≤

i=1

j=1

k=1

(Cik + Ckj)

(cid:18)

Pik

1

bk

(cid:19)

Qkj

n
X

n
X

n
X

i=1

j=1

k=1

Cik Pik

n
X

n
X

i=1

k=1

Cik Pik

1

bk

1

bk

n
X

Qkj +

n
X

n
X

n
X

i=1

j=1

k=1

Ckj Pik

Qkj

+

n
X

n
X

k=1

j=1

Ckj Qkj

1

bk

j=1
| {z }
=bk

1

bk

n
X

Qkj

Pik

i=1
| {z }
=bk

n
X

n
X

i=1

k=1

n
X

n
X

i=1

k=1

Cik Pik

(cid:18) 1

bk

(cid:19)

+

bk

n
X

n
X

k=1

j=1

Ckj Qkj

(cid:18) 1

bk

(cid:19)

bk

Cik Pik +

n
X

n
X

k=1

j=1

Ckj Qkj

=

=

=

=

=

=

= W (a, b) + W (b, c).

Por ﬁm, W (a, c) ≤ W (a, b) + W (b, c) como desejado.

Comparação de Histogramas

Finalizamos este capítulo com alguns exemplos simples, onde a métrica de Was-
serstein pode ser facilmente calculada (ou estimada), como forma de compreender as
características dos vetores de probabilidades, ou dos histogramas, que esta distância se
propõem a quantiﬁcar.

A primeira deﬁnição é sobre a matriz de custos que devemos levar em consideração.
Segundo o enunciado do Teorema 3.21, uma tal matriz deve satisfazer as condições (C1),

Capítulo 3. Teoria do Transporte Ótimo

62

(C2) e (C3). Uma escolha natural, será considerar o módulo da diferença entre os índices
da matriz, ou seja, Cij = |i − j|, que já foi introduzida no Exemplo 3.20.

Exemplo 3.22 (Deslocamento de Histograma I). Desejamos calcular a distância entre os
seguintes vetores de probabilidade em P8, dados por

a = (0, 0, 1, 0, 0, 0, 0, 0)T,

b = (0, 0, 0, 1, 0, 0, 0, 0)T

e

c = (0, 0, 0, 0, 0, 0, 0, 1)T.

Seus respectivos histogramas são as Figuras 9, 10 e 11, que são similares a menos de
deslocamento.

Figura 9 – Histograma Associado ao Vetor a

Fonte: Elaborada pelo autor.

Figura 10 – Histograma Associado ao Vetor b

Fonte: Elaborada pelo autor.

Capítulo 3. Teoria do Transporte Ótimo

63

Figura 11 – Histograma Associado ao Vetor c

Fonte: Elaborada pelo autor.

Abaixo exibimos os cálculos da métrica de Wasserstein envolvendo tais veto-
res/histogramas, para isto, analisaremos o respectivo Problema de Kantorovich cuja matriz
de custos é

C =























0 1 2 3 4 5 6 7
1 0 1 2 3 4 5 6
2 1 0 1 2 3 4 5
3 2 1 0 1 2 3 4
4 3 2 1 0 1 2 3
5 4 3 2 1 0 1 2
6 5 4 3 2 1 0 1
7 6 5 4 3 2 1 0























onde, por exemplo, para se fazer o transporte do índice 3 para o 4 teremos um custo de
transporte de |3 − 4| = 1 e para o transporte do índice 4 para o 8 teremos um custo de
|4 − 8| = 4.

• Distância de Wasserstein entre a e b (W (a, b) = W (b, a)): É fácil ver que existe único

plano de transporte, U (a, b) = {Π}, dado pela matriz

Π =























0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0























,

que também deverá ser o plano de transporte ótimo. Portanto,

W (a, b) = min

X∈U (a,b)

n
X

n
X

i=1

j=1

Cij Xij =

n
X

n
X

i=1

j=1

Cij Πij = C3,4 Π3,4 = |3 − 4| × 1 = 1;

Capítulo 3. Teoria do Transporte Ótimo

64

• Distância de Wasserstein entre b e c (W (b, c) = W (c, b)): Analogamente, U (b, c) =

{Π∗} para

Π∗ =























0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0























e a distancia é dada por

W (b, c) = min

X∈U (b,c)

n
X

n
X

i=1

j=1

Cij Xij =

n
X

n
X

i=1

j=1

Cij Π∗
ij

= C4,8 Π∗
4,8

= |4 − 8| × 1 = 4;

• Distância de Wasserstein entre c e a (W (c, a) = W (a, c)): Por ﬁm, U (b, c) = {Π∗∗}

com

Π∗∗ =























0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0























,

cuja distância é

W (c, a) = min

X∈U (c,a)

n
X

n
X

i=1

j=1

Cij Xij =

n
X

n
X

i=1

j=1

Cij Π∗∗
ij

= C8,3 Π∗∗
8,3

= |8 − 3| × 1 = 5.

A partir dos valores acima, observe que a métrica de Wasserstein é capaz de identiﬁcar e
quantiﬁcar o deslocamento de massa entre índices distintos para os vetores de probabilidade
mencionados anteriormente.

Por outro lado, este comportamento de deslocamento não é reconhecido pela
distância Euclidiana (veja Exemplo 3.17) entre os vetores a, b e c como calculada abaixo.

• Distância Euclidiana entre a e b

(cid:18)

d(a, b) = d(b, a) = qP8

i=1

(ai − bi)2

(cid:19)

:

d(a, b) = q
√

=

(0 − 0)2 + (0 − 0)2 + (1 − 0)2 + (0 − 1)2 + (0 − 0)2 + (0 − 0)2 + (0 − 0)2 + (0 − 0)2

2

Capítulo 3. Teoria do Transporte Ótimo

65

• Distância Euclidiana entre b e c

(cid:18)

d(b, c) = d(c, b) = qP8

i=1

(bi − ci)2

(cid:19)

:

d(b, c) = q
√
2

=

(0 − 0)2 + (0 − 0)2 + (0 − 0)2 + (1 − 0)2 + (0 − 0)2 + (0 − 0)2 + (0 − 0)2 + (0 − 1)2

• Distância Euclidiana entre c e a

(cid:18)
d(c, a) = d(a, c) = qP8

i=1

(ci − ai)2

(cid:19)
:

d(c, a) = q
√
2

=

(0 − 0)2 + (0 − 0)2 + (0 − 1)2 + (0 − 0)2 + (0 − 0)2 + (0 − 0)2 + (0 − 0)2 + (1 − 0)2

Exemplo 3.23 (Comparação de Histogramas II). Considere os vetores de probabilidade
em P7

(cid:18)

a =

0, 0, 0,

1
10,

2
10,

4
10,

3
10

(cid:19)T

e

b =

(cid:18) 1
10,

2
10,

4
10,

(cid:19)T

3
10, 0, 0, 0

e seus respectivos histogramas dados nas Figuras 12 e 13.

Figura 12 – Histograma Associado ao Vetor a

Fonte: Elaborada pelo autor.

Figura 13 – Histograma Associado ao Vetor b

Fonte: Elaborada pelo autor.

Capítulo 3. Teoria do Transporte Ótimo

66

Dada a matriz de custos

C =




















0 1 2 3 4 5 6
1 0 1 2 3 4 5
2 1 0 1 2 3 4
3 2 1 0 1 2 3
4 3 2 1 0 1 2
5 4 3 2 1 0 1
6 5 4 3 2 1 0




















,

apresentamos um plano de transporte Π ∈ U (a, b), dado pela matriz

Π =




















0
0
0

1
10
0
0
0

0
0
0
0

2
10
0
0

0
0
0
0
0

4
10
0

0
0
0
0
0
0

3
10

0 0 0
0 0 0
0 0 0
0 0 0
0 0 0
0 0 0
0 0 0




















,

que não necessariamente será único ou ótimo. Em particular, temos que

W (a, b) ≤

n
X

n
X

i=1

j=1

Cij Πij = |1 − 4|

1
10

+ |2 − 5|

2
10

+ |3 − 6|

4
10

+ |4 − 7|

3
10

= 3.

Pelos resultados anteriores, a distância de Wasserstein consegue assimilar e quanti-
ﬁcar o deslocamento de vetores de probabilidade que são similares. Na realidade, em vista
do problema de transporte, a Métrica de Wasserstein permite comparar as entradas dos
vetores de probabilidade em índices distintos i e j, mas para isso, prescreve um custo que
é proporcional a separação destes índices. Destacamos que tal comportamento pode ser
útil em diversas aplicações que tentaremos explorar no próximo capítulo.

4 Aplicações

67

Neste capítulo, exploraremos algumas aplicações relacionadas à comparação de

histogramas, utilizando a métrica de Wasserstein como principal ferramenta de estudo.

4.1 Comparação de Histogramas da COVID-19

Etapa 1. Compreensão da Situação-Problema:

Atualmente, os meios de comunicações veiculam frequentemente a seguinte frase:
“[ . . . ] estamos vivendo uma nova onda na pandemia causada pela COVID-19 [ . . . ]”. Tal
aﬁrmação nos leva a questionar o que é (e como reconhecer) uma “onda” no contexto da
pandemia.

No século XIX, pesquisadores (Biólogos, Epidemiologistas, etc) reconheceram
padrões regulares de um comportamento ondulatório em seus dados sobre a propagação
de uma doença/vírus, o que levou a disseminação do termo “onda” epidemiológica. As
tentativas de deﬁnição formal para este fenômeno, muitas vezes não conseguem abranger
a diversidade da doença/vírus existentes e, por este motivo, não existe um concesso do
que de fato caracteriza uma “onda” epidemiológica.

Nossa principal motivação ao desenvolver esta aplicação é o fato de que, na
Matemática, pode-se descrever diversos tipos de ondas do mundo real por meio de funções
conhecidas. Por exemplo:

• A vibração de uma corda de um violão é caracterizada pelas ondas harmônicas
(unidimensionais), cuja representação emprega a função cosseno, y = cos(x) (ou a
função seno, y = sen(x));

• As frentes de onda (unidimensional), observada em ondas oceânicas, podem ser

descritas pela função cúspide cúbica, dada por y = 1 − |x| 2
3 .

Nesta seção, iremos comparar por similaridade o histogramas obtidos a partir de
gráﬁcos da propagação da COVID-19 no Brasil com histogramas associados às funções
matemáticas que modelam este fenômeno de “onda” (função cosseno cos(x) e função
cúspide cúbica 1 − |x| 2

3 ).

Etapa 2. Construção de um Modelo Matemático:

Inicialmente, fomos em busca dos dados da evolução da COVID-19 no Brasil,
para que pudéssemos deﬁnir como abordaríamos estes dados. Consultamos o banco de

Capítulo 4. Aplicações

68

dados do Conselho Nacional de Secretários de Saúde (CONASS) — única plataforma
atualizada disponível no período da análise — e extraímos as informações necessárias para
nosso trabalho. Coletamos os dados, referentes ao período do dia 15/03/2020 até o dia
25/09/2021, organizados por semanas epidemiológicas da COVID-19. Note que a primeira
semana de incidência do vírus no Brasil, a partir do dia 15/03/2020 até 21/03/2020,
coincide com os seguintes acontecimentos: registro da primeira morte pela doença (em
18/03/2020) e declaração de transmissão comunitária no país pelo Ministério da Saúde (no
dia 21/03/2020). Vale salientar que esta primeira semana do vírus no Brasil, na realidade,
corresponde à 12a semana na escala internacional indicada pela World Health Organization
(WHO)1.

Encontramos dois conjuntos de dados que julgamos pertinentes para nossa análise:
o primeiro é referente à evolução de números de casos da doença e o segundo diz respeito ao
número de óbitos ocasionados pela COVID-19. Para melhorar o entendimento e simpliﬁcar
a apresentação das comparações que serão realizadas, agrupamos os dados a cada 4
semanas, ou seja, o primeiro dado apresentado vai da semana 12 até a semana 15, o
segundo contabiliza das semanas 16 até 19 e assim por diante até o último dado que
compreende da semana 89 a semana 91. Essa divisão propõem a apresentação dos casos de
óbitos em 20 intervalos, abrangendo um total de 79 semanas de incidência da COVID-19
no Brasil.

O primeiro conjunto de dados referente à propagação de números de casos da
COVID-19 no Brasil está apresentado na Tabela 2, onde também apresentamos uma
normalização dos mesmos, que se justiﬁca pelo fato de que temos a intenção de trabalhar
com vetores de probabilidade. Desta forma, realizamos a construção do histograma que
representa esses dados percentuais dos números de casos na Figura 14.

Analogamente, exibimos a Tabela 3 referente ao segundo conjunto de dados sobre
a evolução dos números de óbitos no Brasil e respectivo histograma dado pela Figura 15.

1 Tradução livre do autor: Organização Mundial de Saúde (OMS)

Capítulo 4. Aplicações

69

Tabela 2 – Números de Casos da COVID-19

Intervalo Semanas Número de Casos Porcentagem dos Casos

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

12 a 15
16 a19
20 a 23
24 a 27
28 a 31
32 a 35
36 a 39
40 a 43
44 a 47
48 a 51
52 a 55
56 a 59
60 a 63
64 a 67
68 a 71
72 a 75
76 a 79
80 a 83
84 a 87
88 a 91

Total

20606
135212
516907
904158
1130873
1136930
873184
671648
672151
1147922
1254351
1354695
1629181
2006071
1700873
1761546
1834600
1175830
810750
614699

21352187

0,00097
0,00633
0,02421
0,04234
0,05296
0,05325
0,04089
0,03146
0,03148
0,05376
0,05875
0,06345
0,07630
0,09395
0,07966
0,08250
0,08592
0,05507
0,03797
0,02879

1,00000

Fonte: Elaborada pelo autor.

Figura 14 – Histograma dos Números de Casos da COVID-19

Fonte: Elaborado pelo autor.

Capítulo 4. Aplicações

70

Tabela 3 – Números de Óbitos da COVID-19

Intervalo Semanas Número de Óbitos Porcentagem dos Óbitos

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

12 a 15
16 a19
20 a 23
24 a 27
28 a 31
32 a 35
36 a 39
40 a 43
44 a 47
48 a 51
52 a 55
56 a 59
60 a 63
64 a 67
68 a 71
72 a 75
76 a 79
80 a 83
84 a 87
88 a 91

Total

1124
9503
25303
28335
29298
26889
20954
15497
12086
17216
23091
29236
38559
74243
69982
51215
51056
32783
22640
15190

594200

0,00189
0,01599
0,04258
0,04769
0,04931
0,04525
0,03526
0,02608
0,02034
0,02897
0,03886
0,04920
0,06489
0,12495
0,11778
0,08619
0,08592
0,05517
0,03810
0,02556

1,00000

Fonte: Elaborada pelo autor.

Figura 15 – Histograma dos Números de Óbitos da COVID-19

Fonte: Elaborado pelo autor.

Capítulo 4. Aplicações

71

A partir de breve observação visual do comportamento dos dois histogramas
apresentados anteriormente, percebemos duas regiões com características muito próximas
de uma “onda”. A primeira região é formada pelos primeiros dez intervalos, ou seja, do
intervalo 1 (semanas de 12 a 15) até o intervalo 10 (semanas de 48 a 51). Vimos em ambos
os histogramas (Figura 15 e Figura 14) a possibilidade de similaridade desta região com
uma função que classicamente é utilizada para modelar ondas, deste modo, escolhemos a
função Cosseno

y = cos(x)

como um parâmetro de comparação. Já a segunda região vai do intervalo 11 (semanas de
52 a 55) até o intervalo 20 (semanas de 88 a 91), ou melhor, os dez últimos intervalos.
Principalmente, para o histograma que representa o número de óbitos (Figura 15), identiﬁ-
camos um comportamento de “cume” ou frente de onda e, por conta disso, escolhemos
função Cúspide Cúbica

para servir de parâmetro de nossas comparações de histogramas.

y = cusp(x) = 1 − |x|

2
3

Com esta observação nos dez primeiros e dez últimos intervalos, resolvemos modelar
os histogramas associados à função cosseno e à função cúspide cúbica com dez barras como
detalhado a seguir:

• Construímos o gráﬁco da função cosseno y = cos(x) no intervalo de −

e
dividimos esse intervalo em dez partes iguais. Desejamos construir um histograma
sobre o gráﬁco, onde cada barra incide sob o valor da função no ponto médio em cada
um destes intervalos. Daí, encontramos o valor de cada um desses pontos médios,
i, e em seguida calculamos o valor do
que denotamos por xi = − π
2
cosseno de cada xi, no Excel. Por ﬁm, normalizamos esses valores para encontrar um
vetor de probabilidade com 10 entradas e assim apresentar o histograma da função
cosseno. Veja a Figura 16, a Tabela 4 e a Figura 17.

+ h(2 × i − 1) × π

20

π
2

a π
2

Figura 16 – Gráﬁco da Função Cosseno

Fonte: Elaborada no (WOLFRAM|ALPHA, 2022).

Capítulo 4. Aplicações

72

Tabela 4 – Valores para Função Cosseno

Índice i

Fórmula xi

xi

cos(xi) Porcentagem cos(xi)

1

2

3

4

5

6

7

8

9

− π
2

+ (1 × π
20

)

− π
2

+ (3 × π
20

)

− π
2

+ (5 × π
20

)

− π
2

+ (7 × π
20

)

− π
2

+ (9 × π
20

)

− π
2

+ (11 × π
20

)

− π
2

+ (13 × π
20

)

− π
2

+ (15 × π
20

)

− π
2

+ (17 × π
20

)

-1,413717

0,156

-1,099557

0,454

-0,785398

0,707

-0,471239

0,891

-0,157080

0,988

0,157080

0,988

0,471239

0,891

0,785398

0,707

1,099557

0,454

10

− π
2

+ (19 × π
20

)

1,413717

0,156

0,02447

0,07102

0,11062

0,13938

0,15451

0,15451

0,13938

0,11062

0,07102

0,02447

Total

3,972

1,00000

Fonte: Elaborada pelo autor.

Figura 17 – Histograma da Função Cosseno

Fonte: Elaborada pelo autor.

Capítulo 4. Aplicações

73

• Consideramos o intervalo de −1 a 1 para análise do gráﬁco da função cúspide cúbica
y = cusp(x) = 1 − |x| 2
3 e, em seguida, dividimos esse intervalo em dez partes iguais.
Assim como na função cosseno, o gráﬁco da cúspide cúbica intercepta a linha superior
das barras do histograma nos respectivos pontos médios dos intervalos em questão.
Chamamos de xi = −1 + [(2 × n − 1) × 0, 1] os pontos médios dos intervalos e,
então, calculamos os valores da função para cada um dos xi encontrados. Ao ﬁm,
normalizamos esses valores de xi para obter o vetor de probabilidade e o histograma
associado a função cúspide cúbica. Elaboramos a Figura 18, a Tabela 5 e a Figura
19 dessa função conforme abaixo.

Figura 18 – Gráﬁco da Função Cúspide Cúbica

Fonte: Elaborada no (WOLFRAM|ALPHA, 2022)

Tabela 5 – Valores para Função Cúspide Cúbica

cusp(xi) Porcentagem cusp(xi)

Índice i

Fórmula xi

1

2

3

4

5

6

7

8

9

−1 + (1 × 0, 1)

−1 + (3 × 0, 1)

−1 + (5 × 0, 1)

−1 + (7 × 0, 1)

−1 + (9 × 0, 1)

−1 + (11 × 0, 1)

−1 + (13 × 0, 1)

−1 + (15 × 0, 1)

−1 + (17 × 0, 1)

10

−1 + (19 × 0, 1)

xi

-0,9

-0,7

-0,5

-0,3

-0,1

0,1

0,3

0,5

0,7

0,9

0,068

0,212

0,370

0,552

0,785

0,785

0,552

0,370

0,212

0,068

Total

3,972

Fonte: Elaborada pelo autor.

0,01708

0,05328

0,09317

0,13894

0,19753

0,19753

0,13894

0,09317

0,05328

0,01708

1,00000

Capítulo 4. Aplicações

74

Figura 19 – Histograma da Função Cúspide Cúbica

Fonte: Elaborada pelo autor.

Note que os dois histogramas que obtivemos referente à COVID-19 possuem 20
barras (logo os vetores de probabilidade possuem 20 entradas) e os histogramas das funções
cosseno e cúspide cúbica tem 10 barras (vetores de probabilidade com 10 entradas). Para
que seja possível compará-los, decidimos dividir cada histograma da COVID-19 em 11
novos histogramas, cada um com 10 barras (10 entradas).

Inicialmente, tomamos os dados referentes aos intervalos de 1 até 10 do Histograma
de Casos da COVID-19 (Tabela 2), normalizamos e geramos um vetor de probabilidade
a1−10. Em seguida, para os dados de 2 até 11, realizamos novamente a normalização e
obtemos o vetor a2−11. Repetimos esse processo ate obter o vetor de probabilidade a11−20.
Analogamente, para o Histograma de Óbitos da COVID-19 (Tabela 3) construímos os
vetores d1−10, d2−11 até d11−20.

Os respectivos vetores de probabilidade que decompõem o Histograma de Casos
da COVID-19 e o Histograma de Óbitos da COVID-19 são apresentados no Apêndice B.
Além disso, a correspondência entre o índice que referência estes vetores e o período que
ele compreende, é dado na Tabela 6

Capítulo 4. Aplicações

75

Tabela 6 – Divisão Intervalos dos Histogramas para Cálculo de Distâncias

Intervalo de Índices Semanas Iniciais Semanas Finais

1-10
2-11
3-12
4-13
5-14
6-15
7-16
8-17
9-18
10-19
11-20

12 a 15
16 a 19
20 a 23
24 a 27
28 a 31
32 a 35
36 a 39
40 a 43
44 a 47
48 a 51
52 a 55

48 a 51
52 a 55
56 a 59
60 a 63
64 a 67
68 a 71
72 a 75
76 a 79
80 a 83
84 a 87
88 a 91

Fonte: Elaborada pelo autor.

Etapa 3. Resolução do Modelo (via Solver):

Deﬁnido todos os vetores de probabilidade e respectivos histogramas que serão
utilizados como parâmetros para a comparação, vamos começar a construir as planilhas
para os cálculos de distâncias por meio da métrica de Wasserstein.

A primeira deﬁnição é a função custo unitário, que será deﬁnida como sendo a
distância de um índice a outro, ou seja, o módulo da diferença entre os índices que variam
de 1 até 10. Assim, nossos coeﬁcientes das varáveis de decisão serão representados por
Cij = |i − j| ou, mais especiﬁcamente, pela matriz 10 × 10

C =





























0 1 2 3 4 5 6 7 8 9
1 0 1 2 3 4 5 6 7 8
2 1 0 1 2 3 4 5 6 7
3 2 1 0 1 2 3 4 5 6
4 3 2 1 0 1 2 3 4 5
5 4 3 2 1 0 1 2 3 4
6 5 4 3 2 1 0 1 2 3
7 6 5 4 3 2 1 0 1 2
8 7 6 5 4 3 2 1 0 1
9 8 7 6 5 4 3 2 1 0





























.

Em particular, sua respectiva vetorização é dada pelo vetor 1 × 100

vet(C)T = (cid:16)0, 1, 2, 3, 4, 5, 6, 7, 8, 9 (cid:12)
(cid:12)
(cid:12)

1, 0, 1, 2, 3, 4, 5, 6, 7, 8 (cid:12)
(cid:12)
(cid:12) · · ·

(cid:12)
(cid:12)
(cid:12)

9, 8, 7, 6, 5, 4, 3, 2, 1, 0(cid:17)

.

Também apresentamos o plano de transporte (uma matriz 10 × 10) e sua vetorização

Capítulo 4. Aplicações

76

associada (um vetor 1 × 100), que determinaram as varáveis de decisão:


X =














x1,2
x1,1
x2,2
x2,1
...
...
x9,1
x9,2
x10,1 x10,2

x1,10
· · · x1,9
x2,10
· · · x2,9
...
...
. . .
· · · x9,9
x9,10
· · · x10,9 x10,10














e

vet(X) =



















































x1,1
...
x10,1
x1,2
...
x10,2
...
x1,10
...
x10,10

Outra deﬁnição muito importante se refere à matriz que deﬁne as restrições para
um problema de Programação Linear. Esta matriz possui tamanho 20 × 100 e dentro dela
podemos identiﬁcar várias outras matrizes, como por exemplo, Id10, a matriz identidade
10 × 10, e o vetor linha ˆ110 com todas as entradas iguais a 1. Sua representação pode ser
dada da seguinte forma:













































A =

1 0 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0
0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 1

1 1 1 1 1 1 1 1 1 1

0

0
...
0













































Id10

Id10

· · ·

Id10

0
ˆ110
0

0

0

0

0
ˆ110
0

0

· · ·

· · ·

· · ·
. . .

· · ·

0

0

0
...
ˆ110

Com esta matriz será possível traduzir as restrições do Problema de Kantorovich em termos
de seu produto com a vetorização do plano de transporte vet(X), como foi mostrado na
Seção 3.3.

Já possuímos as ferramentas necessários para realizarmos as comparações que
desejamos e, diante disso, faremos uso mais uma vez do Excel para calcularmos as distâncias
por meio da ferramenta Solver. Para tanto, utilizaremos os mesmo princípios e passos que
foram realizados no nosso exemplo motivador, na Seção 2.2.

Capítulo 4. Aplicações

77

O primeiro passo é alimentar o Excel com a matriz A que deﬁne as restrições para
um problema de Programação Linear, digitando todas as entradas dessa matriz na planilha
do Excel. Abaixo desta matriz colocamos uma linha com 100 colunas onde inserimos os
respectivos custos para cada uma das colunas. Logo abaixo desta linha, criamos outra linha
com 100 colunas onde o Solver através da fórmula [SOMARPRODUTO] irá preencher
com os valores ótimos das variáveis de decisão, ou melhor, com as entradas de um plano
de transporte ótimo. Posteriormente, criamos três colunas cada uma com 20 linhas: a da
esquerda, chamamos de (Totais) e será preenchida automaticamente pelo Solver com a
fórmula [SOMARPRODUTO]; a coluna do meio, possuirá a representação simbólica do
sinal das restrições (neste caso, sempre será o símbolo =); e na última coluna, denominada
de (Restrições), iremos preencher com a concatenação dos vetores de probabilidades
dados pelos histogramas. Por ﬁm, criamos uma célula, logo abaixo da coluna dos (Totais),
onde o Solver irá preencher com a distância total ótima de nossa comparação, também em
função da fórmula [SOMARPRODUTO].

Devido ao tamanho de nossa matriz, compartilhamos apenas um recorte da parte
ﬁnal da tela quando conﬁguramos nossa planilha para o cálculo com o Solver, conforme
Figura 20.

Figura 20 – Recorte da Planilha de Preparação para o Solver

Fonte: Elaborada pelo autor.

Para nossas comparações, iremos alimentar a coluna (Restrições) da planilha do
Excel com os dados dos vetores de probabilidade (histogramas) para os quais desejamos
calcular a distância de Wasserstein. Como os vetores possuem 10 entradas e esta coluna
possui 20 linhas, devemos proceder da seguinte forma:

• As dez primeiras linhas serão alimentadas com os dados de um dos vetores de

Capítulo 4. Aplicações

78

probabilidade referente aos histogramas de caso ou óbitos da COVID-19, neste casos,
os vetores a(·) ou d(·).

• As dez últimas possuirão dados do vetor de probabilidade associado aos histogramas
da função que utilizaremos como parâmetro de comparação, em nosso caso, ou a
função cosseno bcos ou a função cúspide cúbica bcusp.

Lembrando que todos os vetores de probabilidade mencionados acima podem ser encontra-
dos no Apêndice B.

A partir daqui executamos 44 instâncias do Solver no Excel, para realizar o cálculo
de: 11 distâncias W (a(·), bcos); 11 distâncias W (a(·), bcusp); 11 distâncias W (d(·), bcos); 11
distâncias W (d(·), bcusp). Não vamos apresentar todas as telas de cálculo destas distâncias,
principalmente, por conta dos tamanhos da matriz e dos vetores envolvidos. Caso o leitor
tenha interesse em vê-los, pode consultar a planilha no seguinte link disponibilizado pelos
autores: (GOMES; SILVA, 2022).

Etapa 4. Análise da Solução:

Realizaremos tal comparação de similaridade entre os histogramas por meio de
distâncias entre os respectivos vetores de probabilidades, ou seja, quanto mais próximo
do valor zero for o valor da distância, mais similares serão os vetores de probabilidades e
os histogramas. Para nossas analises utilizaremos a métrica de Wasserstein e a distância
Euclidiana em R10. Intuitivamente, a distância Euclidiana em R10 compara e quantiﬁca a
diferença de entrada de mesmo índice i dos vetores de probabilidade (barras em mesma
posição dos histogramas). Recorde que a métrica de Wasserstein também permite comparar
e quantiﬁcar a diferença de entrada em índices distintos i e j, colocando um custo Cij
proporcional a separação destes índices.

Etapa 4.1. Análise da Solução: Histograma de Casos da COVID-19

Devido a decomposição dos dados do Histograma de Casos da COVID-19 (Tabela 2
e Figura 14) em 11 novos vetores de probabilidade (a(·)), teremos que fazer 11 comparações
em relação ao vetor de probabilidade da função cosseno bcos (Tabela 4 e Figura 17) e mais
outras 11 em relação ao vetor de probabilidade da função cúspide cúbica bcusp (Tabela 5 e
Figura 19).

Apresentaremos abaixo as tabelas contendo todos os 22 valores de distâncias que

apuramos para os Casos da COVID-19 nas distâncias de Wasserstein e Euclidiana.

Capítulo 4. Aplicações

79

Tabela 7 – Distâncias de Wasserstein para o Histogramas de Casos da COVID-19

Hist. Casos Período em Semanas Cosseno bcos Cúspide bcusp

a1−10
a2−11
a3−12
a4−13
a5−14
a6−15
a7−16
a8−17
a9−18
a10−19
a11−20

12 a 15 - 48 a 51
16 a 19 - 52 a 55
20 a 23 - 56 a 59
24 a 27 - 60 a 63
28 a 31 - 64 a 67
32 a 35 - 68 a 71
36 a 39 - 72 a 75
40 a 43 - 76 a 79
44 a 47 - 80 a 83
48 a 51 - 84 a 87
52 a 55 - 88 a 91

Variação Total

1,01192

0,69220
0,78854
0,98304

1,12071
1,08575
1,02563
0,88056
0,57082

0,35687
0,48288

0,76384

Fonte: Elaborada pelo autor.

1,01192

0,77904
1,02478
1,21928

1,30801
1,23595
1,10281
0,97366
0,72544

0,59311
0,7149

0,69693

Tabela 8 – Distâncias Euclidianas para o Histogramas de Casos da COVID-19

Hist. Casos Período em Semanas Cosseno bcos Cúspide bcusp

a1−10
a2−11
a3−12
a4−13
a5−14
a6−15
a7−16
a8−17
a9−18
a10−19
a11−20

12 a 15 - 48 a 51
16 a 19 - 52 a 55
20 a 23 - 56 a 59
24 a 27 - 60 a 63
28 a 31 - 64 a 67
32 a 35 - 68 a 71
36 a 39 - 72 a 75
40 a 43 - 76 a 79
44 a 47 - 80 a 83
48 a 51 - 84 a 87
52 a 55 - 88 a 91

Variação Total

0,15561
0,16544
0,18707
0,21275

0,23060
0,20927
0,17907
0,15374
0,11035

0,08751
0,09073

0,14309

Fonte: Elaborada pelo autor.

0,16552
0,20231
0,24152
0,26835

0,27705
0,25153
0,22262
0,19833
0,15860

0,13953
0,14008

0,13752

Capítulo 4. Aplicações

80

Em relação à função cosseno bcos:

Primeiramente, buscamos regiões que podem caracterizar uma “onda” epidemioló-
gica. Podemos observar que a porção do Histograma de Casos da COVID-19 que mais
se mostrou similar a esta função foi no intervalo de 10 - 19, visto que a métrica de
Wasserstein obteve o menor valor W (a10−19, bcos) = 0, 35687. Este intervalo correspondente
às semanas de (48 a 51) até (84 a 87), onde reconhecemos a “segunda onda” da pandemia.
Além disso, o segundo e o terceiro menor valor da métrica de Wasserstein encontram-se
na vizinhança deste período. Ao veriﬁcar o quarto menor valor W (a2−11, bcos) = 0, 69220,
identiﬁcamos a “primeira onda” da pandemia no intervalo de 2 - 12, associado às semanas
de (16 a 19) até (52 a 55).

O intervalo do Histograma de Casos da COVID-19 que mais se mostrou diferente
da função cosseno foi a porção de 5 - 14, pois a distância de Wasserstein obteve o maior
valor W (a5−14, bcos) = 1, 12071. De fato, neste intervalo veriﬁcamos uma redução das taxas
de casos que correspondem às semanas de (28 a 31) até (64 a 67).

Note que com a distância Euclidiana, os valores máximo e mínimo coincidem com
a análise da métrica de Wasserstein. Por outro lado, a identiﬁcação da “primeira onda” da
pandemia só ocorre no sexto menor valor ||a1−10 − bcos|| = 0, 15561, isto é, no intervalo de
1 - 10 das semanas de (12 a 15) até (48 a 51).

Outra observação importante é a variação total entre as distâncias calculadas. Veja
que há uma diferença entre a maior e a menor distância de Wasserstein de 1, 12071 −
0, 35687 = 0, 76384, que é uma variabilidade muito maior que a da distância Euclidiana de
0, 23060 − 0, 08751 = 0, 14309.

Em relação à função cúspide cúbica bcusp:

Observamos um comportamento muito parecido ao da função cosseno: o menor valor
foi de W (a10−19, bcusp) = 0, 59311, que ocorreu no intervalo de 10 - 19; o quarto menor
foi de W (a2−11, bcusp) = 0, 77904, correspondente à porção de 2 - 11; e o maior valor foi
de W (a5−14, bcusp) = 1, 30801, correspondente à porção de 5 - 14. Por sua vez, a variação
total da métrica de Wasserstein é dada por uma diferença de 1, 30801 − 0, 59311 = 0, 71490,
valor um pouco menor que a variação total desta mesma distância para função cosseno,
0, 76384, e muito maior que a da distância Euclidiana para função cúspide que foi de
0, 27705 − 0, 13953 = 0, 13752.

Tais números nos mostram que a função cosseno tem uma melhor aproximação do
Histograma de Casos da COVID-19 do que a função cúspide cúbica, pois os valores da
distância de Wasserstein listados na primeira coluna das Tabelas 7 e 8 são sempre menores
que os da segunda coluna.

Capítulo 4. Aplicações

81

Por ﬁm, ambas as distâncias associam o comportamento no “cume”, presente na
função cúspide cúbica, no período 10 - 19 (semanas de (48 a 51) até (84 a 87)), identiﬁcado
como a “segunda onda” da pandemia.

Etapa 4.2. Análise da Solução: Histograma de Óbitos da COVID-19

Da mesma forma, ﬁzemos a decomposição dos dados do Histograma de Óbitos da
COVID-19 (Tabela 3 e Figura 15) em 11 vetores de probabilidade (d(·)), logo encontramos
11 distâncias em relação ao vetor de probabilidade da função cosseno bcos (Tabela 4 e
Figura 17) e outras 11 distâncias com respeito à probabilidade da função cúspide cúbica
bcusp (Tabela 5 e Figura 19). Ao total, apresentaremos duas tabelas, cada uma com 22
distâncias, com respeito as distância de Wasserstein (Tabela 9) e Euclidiana (Tabela 10).

Em relação à função cosseno bcos:

Inicialmente procuramos o fenômeno de “onda” epidemiológica. Observando os
valores apurados, vemos que a porção do Histograma de Óbitos da COVID-19 que mais
se assemelhou a função cosseno é o intervalo de 1 - 10, onde foi encontrada a menor
distância de Wasserstein W (d1−10, bcos) = 0, 24478. Claramente, tivemos números altos
de óbitos no período correspondente às semanas de (12 a 15) até (48 a 51) que pode ser
identiﬁcada como a “primeira onda” da pandemia. Além disso, para o segundo o menor
valor da métrica de Wasserstein W (d11−20, bcos) = 0, 31289, já identiﬁcamos a “segunda
onda” no intervalo de 11 - 20, associado às semanas de (52 a 55) até (88 a 91).

Já a maior distância de Wasserstein foi de W (d6−15, bcos) = 1, 64019, donde temos
que a porção que menos se assemelhou com a função cosseno foi o intervalo de 6 - 15,
correspondente às semanas de (32 a 35) até (68 a 71). De fato, notamos uma baixa nos
números de óbitos para este período.

Encontramos um intervalo de 1, 64019 − 0, 24478 = 1, 39541 entre os valores
extremos da métrica de Wasserstein para a função cosseno, o que denota uma variabilidade
muito maior que a distância Euclidiana, 0, 31496 − 0, 08751 = 0, 22674

Para a distância Euclidiana, a menor distância corresponde aos intervalos 10 - 19,
que é vizinho ao período 11 - 20 da segunda menor distância de Wasserstein. Já o período
associado ao valor de maior distância é o intervalo 5 - 14, também vizinho ao da maior
distância de Wasserstein. Por ﬁm, a segunda menor distância Euclidiana se veriﬁca em 1 -
10 que concorda com o período de menor valor da métrica de Wasserstein.

Capítulo 4. Aplicações

82

Tabela 9 – Distâncias Wasserstein para o Histogramas de Óbitos da COVID-19

Hist. Óbitos Período em Semanas Cosseno bcos Cúspide bcusp

d1−10
d2−11
d3−12
d4−13
d5−14
d6−15
d7−16
d8−17
d9−18
d10−19
d11−20

12 a 15 - 48 a 51
16 a 19 - 52 a 55
20 a 23 - 56 a 59
24 a 27 - 60 a 63
28 a 31 - 64 a 67
32 a 35 - 68 a 71
36 a 39 - 72 a 75
40 a 43 - 76 a 79
44 a 47 - 80 a 83
48 a 51 - 84 a 87
52 a 55 - 88 a 91

Variação Total

0,24478
0,61139
0,94404
1,06892
1,44842

1,64019
1,55553
1,36731
0,91489
0,35708

0,31289
1,39541

Fonte: Elaborada pelo autor.

0,38896
0,80889
1,18028
1,30516
1,63908

1,76467
1,62057
1,38571
0,93567
0,43428

0,39147
1,37571

Tabela 10 – Distâncias Euclidianas para o Histogramas de Óbitos da COVID-19

Hist. Óbitos Período em Semanas Cosseno bcos Cúspide bcusp

d1−10
d2−11
d3−12
d4−13
d5−14
d6−15
d7−16
d8−17
d9−18
d10−19
d11−20

12 a 15 - 48 a 51
16 a 19 - 52 a 55
20 a 23 - 56 a 59
24 a 27 - 60 a 63
28 a 31 - 64 a 67
32 a 35 - 68 a 71
36 a 39 - 72 a 75
40 a 43 - 76 a 79
44 a 47 - 80 a 83
48 a 51 - 84 a 87
52 a 55 - 88 a 91

Variação Total

0,08822
0,14760
0,20711
0,24229

0,31496
0,31279
0,26624
0,21318
0,14305

0,08751
0,09073

0,22674

Fonte: Elaborada pelo autor.

0,11480
0,19091
0,25663
0,29471

0,35773
0,35455
0,31039
0,25442
0,16885

0,13953
0,14008

0,24293

Capítulo 4. Aplicações

83

Em relação à função cúspide cúbica bcusp:

Mais um vez obtemos o mesmo comportamento da função cosseno: o menor valor
foi de W (a1−10, bcusp) = 0, 38896, que ocorreu no intervalo de 1 - 10; o segundo menor foi
de W (d11−20, bcusp) = 0, 39147, correspondente à porção de 11 - 20; e o maior valor foi
de W (d6−15, bcusp) = 1, 76467, correspondente à porção de 6 - 15. Novamente, todas as
distâncias calculadas com a função cúspide cúbica foram maiores de que os respectivos
valores apurados para função cosseno. Além disso, a variação total da métrica de Was-
serstein, 1, 76467 − 0, 38896 = 1, 37571, é muito maior que a da distância Euclidiana para
função cúspide, 0, 11480 − 0, 35773 = 0, 24293.

Um fato curioso é que nenhuma das distâncias associou o comportamento de
“cume”, presente na função cúspide cúbica, à “segunda onda” da pandemia. Em particular,
a distância Euclidiana aproximou a “segunda onda” à função cosseno e a “primeira onda”
à função cúspide cúbica, fornecendo assim uma resposta contrária à intuição visual que
tivemos no início.

Etapa 4.3 Análise da Solução: Comentários ﬁnais

Em linhas gerais, consideramos que obtivemos bons resultados no reconhecimento
de “ondas” epidemiológicas com ambas as distâncias Wasserstein e Euclidiana. Acreditamos
que a métrica de Wasserstein, devido a sua variabilidade, pode ser mais sensível a pequenas
diferenças no histograma.

A função cosseno foi a melhor escolha para a comparação, uma vez que, sempre
obteve valores de distância menores. Ainda assim, a função cúspide cúbica é uma boa
escolha já que os valores apurados foram próximos do da função cosseno. Por outro lado,
o comportamento de “cume”, presente na função cúspide cúbica, não foi precisamente
reconhecido no período da “segunda onda” da pandemia.

4.2 Outras Aplicações

Uma das principais aplicações relacionadas à comparação de histogramas é a
possibilidade de comparar imagens usando suas característica visuais intrínsecas (consulte
(SAPPELLI; VERBERNE; KRAAIJ, 2017; WILSON; MARTINEZ, 1997)). Por exemplo,
quando um médico radiologista manipula e interpreta imagens radiológicas com o objetivo
de ter auxílio no diagnóstico e tomada de decisão para determinados casos (ver (AKGÜL
et al., 2011)). Outra importante utilização é a detecção e o reconhecimento de sinais de
Libras utilizando a visão computacional para processar imagens e vídeos.

Segundo Liu et al. (2007), ao executar uma consulta por similaridade em imagens,

dois tipos de abordagens são amplamente consideradas na literatura:

Capítulo 4. Aplicações

84

• As Comparações por Contexto em meta-descrições como tags2, palavras-chave, rótulos
ou ontologias que são associados aos dados por processos externos, tais como, por
meio de especialistas humanos ou por estratégias automatizadas. Aplicações de
recomendação de conteúdos na web e busca em dados não estruturados, são exemplos
de aplicações que utilizam essa abordagem;

• As Comparações por Conteúdo são capazes de expressar a similaridade (ou a dissimi-
laridade) entre pares de elementos, representados em um mesmo conjunto, utilizando
a extração de características representadas internamente nos próprios objetos com-
plexos.

Em ambos os tipos, são amplamente usadas funções para medir a semelhança (ou
diferença) entre os elementos. Do ponto de vista formal, este o problema de comparações
pode ser adequadamente modelado pelas métricas introduzidas na Seção 3.4. Uma grande
diversidade de métricas podem ser encontradas na literatura (consulte (DEZA; DEZA,
2009)), e essa variedade se dá pelo fato de que diversas áreas do conhecimento fazem uso
destas funções, sendo algumas mais adequadas em determinados tópicos do que outras.
Isto se justiﬁca, pois diferentes distâncias podem reﬂetir a similaridades entre dois objetos
de maneiras distintas, dependendo muitas vezes do contexto, dos dados e da aplicação em
questão.

Finalizaremos este capítulo apresentando a ideia resumida de tradução de imagens
através de vetores de histogramas ou probabilidade. A base dessa representação de imagens
será por meio de suas características intrínsecas, concentrando-se em um recurso valioso
dado pela sua distribuição de cores.

Primeiramente, introduziremos os elementos fundamentais que modelam uma

imagem digital:

• Um pixel é o menor elemento em uma imagem onde é possível atribuir uma cor;

• Uma cor é dada por um trio ordenado (r, g, b), onde cada entrada fornece a tonalidade,

respectivamente, das cores vermelho (r), verde (g) e azul (b);

• A tonalidade de uma cor é dada por um número inteiro que varia de 0 até 255, isto
é, tons mais claros são dados por valores próximos ao 255, enquanto os tons mais
escuros são valores próximos de 0.

Deste modo, uma imagem digital pode ser apresentada por uma malha de pixels, onde
cada pixel contêm a informação de uma cor, ou seja, um vetor de três tonalidades, ou
números inteiros entre 0 e 255.

2 Tradução livre do autor: Etiquetas

Capítulo 4. Aplicações

85

Por exemplo, uma imagem Full HD3 é uma malha de 1920 × 1080 vetores tridi-
mensionais com entrada inteiras. Já as imagens em preto e branco, tem sua tradução
simpliﬁcada, pois os vetores podem ser substituídos por um único número inteiro que varia
de 0 (cor branca) até 255 (cor preta).

A partir do modelo matemático de uma imagem poderá ser construído uma
representação gráﬁca da forma como os tons de cores são distribuídos em uma imagem
digital. De acordo com Antonello (2018), um histograma de uma imagem é um gráﬁco
de colunas que representa a distribuição dos valores dos pixels, ou seja, a porcentagem
do total de pixels associada a cada valor/vetor tonal. Desta forma, temos um vetor de
probabilidade de tamanho dado pela quantidade de cores (vetores) que existem na imagem
cujas entradas fornecem a frequência desta cor (vetor) dentre todos os pixels da imagem.

Uma vez que traduzimos imagens em histogramas/vetores de probabilidade, é possí-
vel reproduzir os cálculos da seção para comparar tais imagens/histogramas/probabilidade
com a distância Euclidiana, a métrica de Wasserstein e/ou outras distâncias.

3 Tradução livre do autor: Alta Deﬁnição Total

5 Conclusão

86

Neste Trabalho, trouxemos duas propostas (equivalentes) para abordagem do
problema de transporte. A primeira análise ocorreu à luz de um importante e vasto ramo
da Matemática, a Programação Linear, onde analisamos os custos de transportes associados
à distribuição de produtos. Na segunda abordagem, lançamos mão da Teoria do Transporte
Ótimo, que se mostrou uma ferramenta muito útil para nossa proposta de analisarmos
propriedades geométricas entre histogramas (probabilidades) intrínsecamente relacionadas
ao problema de transporte.

Do ponto de vista histórico, fomos capazes de evidenciar que o surgimento da
Pesquisa Operacional veio de necessidades concretas em aplicações militares e que o seu
desenvolvimento atual e permanente é fruto de problemas colocados pelas mais diversas
áreas: Logística, Industria, Economia, Computação, Matemática, etc. A análise da evolução
histórica também nos revelou que a Programação Linear e a Teoria do Transporte Ótimo
surgiram a partir da sagacidade de estudiosos como Monge, Kantorovich, Koopmans,
Dantzing entre outros, que ﬁzeram abordagens e métodos de resolução inovadores nessas
teorias.

Vale reforçar que nossa abordagem da Programação Linear foi no âmbito do ensino
da Matemática, fazendo referência às aplicações que esta tem e a importância em utiliza-las
para estudar conceitos matemáticos. Em nosso Exemplo Motivador (Seção 2.2), ﬁcou muito
evidente a necessidade de utilizarmos a modelagem matemática para resolvermos problemas
que envolvam deslocamentos de objetos e que tenhamos o objetivo de minimizar custos
ou maximizar lucros da atividade de transporte concreta de um determinado produto.
Além disso, notamos a grande importância do desenvolvimento da lógica e do raciocínio
matemático durante a interpretação e resolução desses problemas. Ainda sobre este, foi
muito signiﬁcativo a aplicação da ferramenta Solver, através do Microsoft Excel, que se
demonstrou ser uma alternativa eﬁcaz para o tratamento dos dados na geração de soluções
para o problema de transporte e que foi a principal ferramenta para o desenvolvimento de
nossas aplicações.

Da mesma forma, trabalhamos com a Teoria de Transporte Ótimo (para probabili-
dades ﬁnitas) com a ﬁnalidade de desenvolver a capacidade de usar a Matemática como
instrumento de interpretação e intervenção no mundo real, buscando uma multiplicidade
de novas aplicações para o problema de transporte, ainda fazendo uso dos métodos de
resolução da Programação Linear. Em nossa aplicação à Comparação de Histogramas
da COVID-19 (Seção 4.1) foi possível identiﬁcar a clara similaridade existente entre as
características das ondas, que podem ser modelas por meio das funções matemáticas, e

Capítulo 5. Conclusão

87

comportamentos epidemiológicos. É evidente que não estudamos características inerentes
das ondas como, frequência, comprimento, velocidade de propagação ou amplitude, mas
comparamos o comportamento de dois histogramas de evolução da COVID-19, com funções
que tem as características principais para a modelagem das ondas. Dessa forma, podemos
dizer que o comportamento tanto da evolução do número de casos quanto do número
de óbitos da COVID-19, no período que abordamos, possuem uma grande similaridade
com o comportamento das ondas que são entendidas como sendo uma perturbação que se
propaga num meio.

Salientamos a diﬁculdade inerente que muitas vezes há na própria formalização dos
problemas, a qual advém da complexidade dos enunciados e suas interpretações. Mesmo
assim, continuações naturais deste trabalho seriam:

• Estender os cálculos da Seção 4.1 para histogramas em outros países, outras doenças

e outras funções de onda para comparação;

• Aplicar noções de Data Clustering1 aos diversos dados da pandemia utilizando a
métrica de Wasserstein, a qual acreditamos que possa fornecer importantes resultados.

• Investigar a Teoria de Transporte Ótimo para probabilidades na reta real R (caso

contínuo), cenário onde a Programação Linear não se aplica.

Ressaltamos que as nossas aplicações são exemplos simples e ingênuos da área de
Machine Learning2. Apesar de usualmente esta área explorar outros métodos (regressão
linear ou logística, gradiente descendente, etc), a Teoria de Transporte Ótimo tem começado
a despontar como ferramenta fundamental para o desenvolvimento de novas técnicas.

Em suma, atendendo a todos os aspectos aqui mencionados, acreditamos que este
texto serve como uma preciosa ferramenta de complementação aos diversos trabalhos
em Programação Linear já desenvolvidos no âmbito do PROFMAT e uma das poucas
referência na literatura acadêmica em língua portuguesa que investiga o paralelismo ente
a Programação Linear e a Teoria de Transporte Ótimo.

1 Tradução livre do autor: Agrupamento de Dados
2 Tradução livre do autor: Aprendizagem de Máquina

Referências

88

AKGÜL, C. B. et al. Recuperação de imagem baseada em conteúdo em radiologia: status
atual e direções futuras. Jornal de Imagem Digital, Springer, v. 24, n. 2, p. 208–222, 2011.

ANTONELLO, R. Introdução a Visão Computacional com Python e OpenCV. 1. ed.
Santa Catarina, 2018.

BALLOU, R. H. Logística empresarial: transportes, administração de materiais e
distribuição física. São Paulo: Atlas, 1993. ISBN 978-8522408740.

BASSANEZI, R. C. Ensino-aprendizagem com modelagem matemática: uma nova
estratégia. São Paulo: Editora Contexto, 2002. ISBN 978-8572442077.

BAZARAA, M. S.; JARVIS, J. J.; SHERALI, H. D. Linear programming and network
ﬂows. New York: John Wiley & Sons, 2008. ISBN 978-0470462720.

BORBA, M. C.; MENEGHETTI, R. C.; HERMINI, H. A. Estabelecendo critérios para
avaliação do uso de modelagem em sala de aula: estudo de um caso em um curso de
ciências biológicas. BORBA, MC Calculadoras gráﬁcas e educação matemática. Rio de
Janeiro: USU, Ed. Bureau ou In: FAINGUELERNT, E. K.; GOTTLIEB, F. C. (Org.).
Calculadoras Gráﬁcas e Educação Matemática. Rio de Janeiro: Art Bureau, p. 95–113,
1999.

CAIXETA FILHO, J. V. Pesquisa operacional: técnicas de otimização aplicadas a
sistemas agroindustriais. São Paulo: Atlas, 2001. ISBN 978-8522437344.

DANTZIG, G. B. Linear Programming and Extensions. Santa Monica: Princeton
university press, 1963.

DANTZIG, G. B.; THAPA, M. N. Linear programming 1 : introduction. New York:
Springer Science & Business Media, 2006. ISBN 978-0387948331.

DEZA, M. M.; DEZA, E. Encyclopedia of distances. In: Encyclopedia of distances. [S.l.]:
Springer, 2009. p. 1–583.

DUALIDADE. In: DICIONÁRIO Online de Português. Porto: 7Graus, 2022. Disponível
em: <https://www.dicio.com.br/dualidade/>. Acesso em: 20 fev. 2022.

GOLDBARG, M.; LUNA, H. Otimização combinatória e programação linear: modelos e
algoritmos. Rio de Janeiro: Elsevier Brasil, 2005. v. 2. ISBN 978-8535215205.

GOMES, J. T. A.; SILVA, J. d. L. Histograma-COVID-19. Repositório - GitHub, 2022.
Disponível em: <https://github.com/jtagomes/Histograma-COVID-19>. Acesso em: 20
fev. 2022.

GOMES JÚNIOR, A. d. C.; SOUZA, M. J. F. Solver (Excel): Manual de referência.
Ouro Preto, 2004. Disponível em: <http://www.decom.ufop.br/marcone/Disciplinas/
OtimizacaoCombinatoria/solver_p.pdf>. Acesso em: 12 set. 2021.

Referências

89

GRANJA, D. I.; RUIZ, J. J. História da Pesquisa Operacional. 2006. Disponível em:
<http://www.phpsimplex.com/pt/historia.htm>. Acesso em: 21 fev. 2022.

HILLIER, F. S.; LIEBERMAN, G. J. Introdução à pesquisa operacional. Porto Alegre:
McGraw Hill Brasil, 2013. ISBN 978-8580551181.

KARMARKAR, N. A new polynomial-time algorithm for linear programming.
Combinatorica, n. 4, p. 373–395, 1984.

LIMA, E. L. Espaços métricos. Rio de Janeiro: IMPA, 2020. ISBN 978-6599052873.

LIU, Y. et al. A survey of content-based image retrieval with high-level semantics. Pattern
recognition, Elsevier, v. 40, n. 1, p. 262–282, 2007.

LÓSS, Z. E. O desenvolvimento da pesquisa operacional no brasil. PTS, v. 10, p. 81,
1981.

MARINS, F. A. S. Introdução à pesquisa operacional. Cultura Acadêmica, São Paulo,
2011.

PAIVA, S. M. d. A. A programação linear no ensino secundário. Dissertação (Mestrado) —
Universidade Portucalense Infante Don Henrique, Porto, 2008.

PASSOS, E. J. P. F. d. Programação linear: como instrumento da pesquisa operacional.
São Paulo: Editora Atlas, 2008. ISBN 978-8522448395.

PEYRÉ, G.; CUTURI, M. et al. Computational optimal transport: with applications to
data science. Foundations and Trends® in Machine Learning, Now Publishers, Inc., v. 11,
n. 5-6, p. 355–607, 2019.

PLOSKAS, N.; SAMARAS, N. Gpu acelerado pivot regras para o algoritmo simplex.
v. 96, p. 1–9, 2014.

POLYA, G. A arte de resolver problemas. Rio de Janeiro: Interciência, 1978. ISBN
978-8571931367.

ROSS, S. Probabilidade: um curso moderno com aplicações. Porto Alegre: Bookman, 2009.
ISBN 978-8577806218.

SAPPELLI, M.; VERBERNE, S.; KRAAIJ, W. Avaliação de sistemas de recomendação
cientes do contexto para reencontro de informações. Jornal da Associação de Ciência e
Tecnologia da Informação, Wiley Online Library, v. 68, n. 4, p. 895–910, 2017.

THORPE, M. Introduction to optimal transport. Cambridge, 2018. Disponível em: <http:
//www.damtp.cam.ac.uk/research/cia/ﬁles/teaching/Optimal_Transport_Notes.pdf>.
Acesso em: 12 set. 2021.

VILLANI, C. Topics in optimal transportation. Providence: American Mathematical
Society, 2003. ISBN 978-0821833124.

VILLANI, C. Optimal transport: old and new. Berlin: Springer, 2009. ISBN
978-3662501801.

Referências

90

WEBER, R. F. F. Programação Linear no Ensino Médio: um estudo dos modelos
de transporte com uma proposta para deﬁcientes visuais. Dissertação (Mestrado) —
Universidade Estadual de Campinas, Campinas, 2018.

WILSON, D. R.; MARTINEZ, T. R. Funções de distância heterogênea aprimoradas.
Jornal de Pesquisa de Inteligência Artiﬁcial, v. 6, p. 1–34, 1997.

WOLFRAM|ALPHA. Champaign: Wolfram Research, Inc., 2022. Disponível em:
<https://www.wolframalpha.com/>. Acesso em: 20 fev. 2022.

Apêndices

APÊNDICE A – Dualidade

92

Etimologicamente, a palavra dualidade deriva do latim “dualitas, atis”, com o
mesmo sentido “qualidade do que é duplo”. Em (DUALIDADE, 2022), esta é deﬁnida
como sendo a qualidade do que contém em sua essência duas substâncias, dois princípios,
duas naturezas. Esse signiﬁcado amplo, gerou várias aplicações em diversos campos de
conhecimento e ganhou ocupações diferentes até dentro de uma mesma área. Vejamos
abaixo algumas aplicações desse termo:

• Na psicologia, pode ser entendida como sendo o princípio ideológico segundo o qual é
possível haver a coexistência simultânea de coisas antagônicas dentro de um mesmo
objeto (a matéria e o espírito; o corpo e a alma; o bem e o mal). Uma bem conhecida
versão é a dualidade mente–corpo, atribuída a René Descartes (1641), segundo a qual
a mente é uma substância não física identiﬁcada com a consciência, distinguindo-a
do cérebro, considerado como o assento da inteligência.

• Para a linguística, dualidade expressa a particularidade da categoria número que,
quando presente em determinadas línguas, representa duas entidades isoláveis, por
oposição a singularidade e a pluralidade;

• Em física, existe a dualidade onda-partícula, propriedade dos entes físicos possuírem
tanto comportamento de partículas como comportamento de ondas, e também é
conhecida como dualidade matéria-energia.

Este termo ocupa várias facetas em quase todos os diferentes tópicos do conheci-
mento matemático. Como de origem do próprio nome, as dualidades em teorias matemáticas
estabelecem algum tipo de relação entre objetos que correspondem a pares, por exemplo:

• Para Lógica Proposicional, os conectivos lógicos (∧) e (∨) são duais. Dadas P e Q

sentenças lógicas, destacamos as equivalências

¬(P ∧ Q) ⇐⇒ ¬P ∨ ¬Q
¬(P ∨ Q) ⇐⇒ ¬P ∧ ¬Q;

• Na Álgebra Booleana, o princípio da dualidade diz que cada expressão ou identidade
algébrica dedutível a partir dos postulados em uma Álgebra Booleana, continua
válida se todas as ocorrências dos operadores + e . e dos elementos 0 e 1 são trocados
um pelo outro;

APÊNDICE A. Dualidade

93

• A dualidade de Álgebra Linear diz respeito a análise especíﬁca da relação entre um
espaço vetorial e o seu espaço dual. A saber, se X é um espaço vetorial (sobre o corpo
K) de dimensão ﬁnita, consideremos o conjunto dos funcionais lineares l : X → K
que tem uma estrutura de espaço vetorial para as operações de soma de funções e
multiplicação por um escalar. Denotamos por X 0 = {l : X → K : l é linear} o espaço
dual de X;

• No contexto da Topologia, as noções de conjunto aberto e fechado são duais, pois vale
a seguinte equivalência: A é aberto de X, se e somente, se seu conjunto complementar
A(cid:123) é fechado em X.

Programação Linear

A noção de dualidade na programação linear signiﬁca a existência de um segundo
modelo, chamamos de problema dual, associado ao problema original, que será chamado
de problema primal.

No problema primal, de cada ponto sub-ótimo que satisfaça todas as restrições,
há uma direção ou subespaço de direções que aumentará o valor a função objetivo. Ao
mover-se em qualquer uma dessas direções, remove-se a folga entre a solução candidata e
uma ou mais restrições. Um valor inviável da solução candidata é aquele que excede uma
ou mais das restrições.

No problema dual, o vetor dual multiplica as restrições que determinam as posições
das restrições no primal. Variar o vetor dual no problema dual é equivalente a revisar os
limitantes superiores do problema primal. O limitante superior mais baixo é procurado,
ou seja, o vetor dual é minimizado para remover a folga entre as posições candidatas das
restrições e o ótimo real. Um valor inviável do vetor dual é aquele que é muito baixo, o
qual deﬁne as posições candidatas de uma ou mais restrições em uma posição que exclui o
ótimo real.

Dessa forma, a transição de um problema primal para um problema dual, ou

vice-versa, deverá seguir as seguintes regras:

• Se o primal for um problema de maximização (ou minimização), então o problema

dual será um problema de minimização (ou maximização);

• Cada variável do primal está associada a uma restrição no dual e cada restrição do

primal está associada a uma variável do dual;

• Os coeﬁcientes de custo da função objetivo do primal correspondem aos termos

independentes das restrições do dual;

APÊNDICE A. Dualidade

94

• Os termos independentes das restrições do primal correspondem aos coeﬁcientes de

custo da função objetivo do dual;

• A transposta da matriz dos coeﬁcientes tecnológicos do primal é a matriz dos

coeﬁcientes tecnológicos do dual.

Abaixo, reapresentamos o problema primal (recorte do Quadro 3) e, de acordo com

as regras descritas acima, exibimos o problema dual correspondente:

Quadro 7 – Problema Primal

Função Objetivo

Maximizar (ou Minimizar) Z = CX

Sujeita às Restrições

AX ≤ B,

X ≥ 0

e B ≥ 0

Onde

A =







a11
...
am1







· · · a1n
...
. . .
· · · amn

, X =













x1
...
xn

, B =







b1
...
bn







, C = (c1, · · · , cm)

Fonte: Elaborado pelo autor.

Quadro 8 – Problema Dual

Função Objetivo

Minimizar (ou Maximizar) D = B(cid:124)Y

Sujeita às Restrições

A(cid:124)Y ≥ C,

Y ≥ 0

e C ≥ 0

Onde

A(cid:124) =







a11
...
an1







,

· · · a1m
...
. . .
· · · anm

Y =







y1
...
ym







, B(cid:124) = (b1, · · · , bn) , C =

Fonte: Elaborado pelo autor.













c1
...
cm

APÊNDICE B – Vetores de Probabilidade
da Seção 4.1

95

Vetor de probabilidade associado ao Histograma de Casos da COVID- 19

(Tabela 2 e Figura 14):

hCasos =



























































0, 00097
0, 00633
0, 02421
0, 04234
0, 05296
0, 05325
0, 04089
0, 03146
0, 03148
0, 05376
0, 05875
0, 06345
0, 07630
0, 09395
0, 07966
0, 08250
0, 08592
0, 05507
0, 03797
0, 02879



























































APÊNDICE B. Vetores de Probabilidade da Seção 4.1

96

Vetores de probabilidade associados a decomposição do Histograma de Casos

da COVID-19 (Figura 6):

a1−10 =





























0, 00286
0, 01875
0, 0717
0, 12541
0, 15686
0, 1577
0, 12111
0, 09316
0, 09323
0, 15922





























a2−11 =





























0, 01600
0, 06122
0, 10709
0, 13394
0, 13465
0, 10342
0, 07955
0, 07961
0, 13596
0, 14856





























a4−13 =

a7−16 =





























0, 08392
0, 10495
0, 10551
0, 08104
0, 06233
0, 06238
0, 10653
0, 11641
0, 12572
0, 1513

























































0, 0668
0, 05138
0, 05142
0, 08782
0, 09596
0, 10364
0, 12463
0, 15347
0, 13012
0, 13476





























a5−14 =

a8−17 =





























0, 09522
0, 09573
0, 07352
0, 05655
0, 05659
0, 09665
0, 10561
0, 11406
0, 13717
0, 1689

























































0, 04786
0, 0479
0, 0818
0, 08939
0, 09654
0, 1161
0, 14295
0, 1212
0, 12553
0, 13073





























a3−12 =

a6−15 =

a9−18 =





















































































0, 05349
0, 09357
0, 11703
0, 11766
0, 09037
0, 06951
0, 06956
0, 1188
0, 12981
0, 1402





























0, 09134
0, 07015
0, 05396
0, 054
0, 09222
0, 10078
0, 10884
0, 13089
0, 16117
0, 13665





























0, 04624
0, 07896
0, 08629
0, 09319
0, 11207
0, 138
0, 117
0, 12117
0, 1262
0, 08088





























APÊNDICE B. Vetores de Probabilidade da Seção 4.1

97

a10−19 =





























0, 07822
0, 08547
0, 09231
0, 11101
0, 13669
0, 1159
0, 12003
0, 12501
0, 08012
0, 05524





























a11−20 =





























0, 08868
0, 09579
0, 1152
0, 14185
0, 12027
0, 12456
0, 12972
0, 08314
0, 05733
0, 04346





























Vetor de probabilidade associado ao Histograma de Óbitos da COVID-19

(Tabela 3 e Figura 15):

hÓbitos

=



























































0, 00189
0, 01599
0, 04258
0, 04769
0, 04931
0, 04525
0, 03526
0, 02608
0, 02034
0, 02897
0, 03886
0, 04920
0, 06489
0, 12495
0, 11778
0, 08619
0, 08592
0, 05517
0, 03810
0, 02556



























































APÊNDICE B. Vetores de Probabilidade da Seção 4.1

98

Vetores de probabilidade associados a decomposição do Histograma de Óbitos

da COVID-19 (Figura 6):

d1−10 =

d4−13 =

d7−16 =





























0, 00603
0, 05104
0, 13589
0, 15217
0, 15734
0, 14441
0, 11253
0, 08323
0, 06491
0, 09245

























































0, 11749
0, 12149
0, 1115
0, 08689
0, 06426
0, 05012
0, 07139
0, 09575
0, 12123
0, 15988

























































0, 05952
0, 04402
0, 03433
0, 0489
0, 06558
0, 08304
0, 10952
0, 21087
0, 19877
0, 14545





























d2−11 =

d5−14 =

d8−17 =





























0, 04565
0, 12155
0, 13611
0, 14074
0, 12917
0, 10066
0, 07444
0, 05806
0, 0827
0, 11092

























































0, 10206
0, 09367
0, 07299
0, 05398
0, 0421
0, 05997
0, 08044
0, 10184
0, 13432
0, 25863

























































0, 04055
0, 03162
0, 04505
0, 06042
0, 0765
0, 10089
0, 19426
0, 18311
0, 13401
0, 13359





























d3−12 =

d6−15 =

d9−18 =





























0, 11103
0, 12433
0, 12855
0, 11798
0, 09194
0, 068
0, 05303
0, 07554
0, 10132
0, 12828

























































0, 08204
0, 06393
0, 04728
0, 03688
0, 05253
0, 07045
0, 0892
0, 11765
0, 22652
0, 21352

























































0, 03025
0, 0431
0, 0578
0, 07319
0, 09653
0, 18586
0, 17519
0, 12821
0, 12781
0, 08206





























APÊNDICE B. Vetores de Probabilidade da Seção 4.1

99

d10−19 =





























0, 04199
0, 05632
0, 0713
0, 09404
0, 18107
0, 17068
0, 12491
0, 12452
0, 07995
0, 05522





























d11−20 =





























0, 0566
0, 07166
0, 09451
0, 18197
0, 17153
0, 12553
0, 12514
0, 08035
0, 05549
0, 03722





























Vetor de probabilidade associado ao Histograma do Cosseno (Figura 17):

bcos =





























0, 02447
0, 07102
0, 11062
0, 13938
0, 15451
0, 15451
0, 13938
0, 11062
0, 07102
0, 02447





























Vetor de probabilidade associado ao Histograma da Cúspide Cúbica (Figura 19):

bcusp =





























0, 01708
0, 05328
0, 09317
0, 13894
0, 19753
0, 19753
0, 13894
0, 09317
0, 05328
0, 01708





























APÊNDICE B. Vetores de Probabilidade da Seção 4.1

100

Observação. Com o objetivo de manter o padrão de 5 casas decimais e tendo vista
o arredondamento das entradas dos vetores acima, algumas entradas tiveram que ser
ajustadas para que todos os vetores sejam sempre vetores de probabilidade. Observamos
que tais ajustes foram pontuais e ocorreram na quinta casa decimal, desta forma, não
geram erros muito grandes nos cálculos realizados neste trabalho.


BIANCA GIOVANINI DE OLIVEIRA

O TEOREMA DA MATRIZ-ÁRVORE DE KIRCHHOFF

Santo André, 2022

UNIVERSIDADE FEDERAL DO ABC

CENTRO DE MATEMÁTICA, COMPUTAÇÃO E COGNIÇÃO

BIANCA GIOVANINI DE OLIVEIRA

O TEOREMA DA MATRIZ-ÁRVORE DE KIRCHHOFF

Orientador: Prof. Dr. Sinuê Dayan Barbero Lodovici

Dissertação de mestrado apresentada ao Centro de

Matemática, Computação e Cognição para

obtenção do título de Mestre em Matemática.

ESTE EXEMPLAR CORRESPONDE A VERSÃO FINAL DA DISSERTAÇÃO

DEFENDIDA PELA ALUNA BIANCA GIOVANINI DE OLIVEIRA,

E ORIENTADA PELO PROF. DR. SINUÊ DAYAN BARBERO LODOVICI.

SANTO ANDRÉ, 2022

Sistema de Bibliotecas da Universidade Federal do ABC
Elaborada pelo Sistema de Geração de Ficha Catalográfica da UFABC
com os dados fornecidos pelo(a) autor(a).

de Oliveira, Bianca Giovanini
     O Teorema da Matriz-Àrvore de Kirchhoff / Bianca Giovanini de
Oliveira. — 2022.

     81 fls. : il.

     Orientador: Sinuê Dayan Barbero Lodovici

     Dissertação (Mestrado) — Universidade Federal do ABC, Mestrado
Profissional em Matemática em Rede Nacional - PROFMAT, Santo
André, 2022.

     1. transformações lineares. 2. grafos. 3. matriz Laplaciana. 4. matriz
árvore. 5. Kirchhoff. I. Barbero Lodovici, Sinuê Dayan. II. Mestrado
Profissional em Matemática em Rede Nacional - PROFMAT, 2022. III.
Título.

SIGAA - Sistema Integrado de Gestão de Atividades Acadêmicas
UFABC - Fundação Universidade Federal do ABC
Programa de Pós-Graduação em Mestrado Profissional Em Matemática Em Rede Nacional
CNPJ n° 07.722.779/0001-06
Av. dos Estados, 5001 - Bairro Santa Terezinha - Santo André - SP - Brasil
profmat@ufabc.edu.br

FOLHA DE ASSINATURAS

ATA N°1

    Assinaturas dos membros da Banca Examinadora que avaliou e aprovou a Defesa de Dissertação de Mestrado
da candidata BIANCA GIOVANINI DE OLIVEIRA, realizada em 3 de Junho de 2022:

gp.fi

Dr. SINUE DAYAN BARBERO LODOVICI, UFABC

Presidente - Interno ao Programa

Dr. MARCIO FABIANO DA SILVA, UFABC

Membro Titular - Examinador(a) Interno ao Programa

/ñ

Dr. ALEXANDRE LYMBEROPOULOS, USP

Membro Titular - Examinador(a) Externo à Instituição

%pi

Dr. RAFAEL DE MATTOS GRISI, UFABC

Membro Suplente - Examinador(a) Interno ao Programa

Dr. ARMANDO TRALDI JUNIOR, IFSP

Membro Suplente - Examinador(a) Externo à Instituição

UFABC - Fundação Universidade Federal do ABC

Este exemplar foi revisado e alterado em relação à versão original, 

de acordo com as observações levantadas pela banca examinadora 

no dia da defesa, sob responsabilidade única do(a) autor(a) e com 

a anuência do(a) (co)orientador(a). 

                          Santo André  
, 

08 

de 

agosto 

de 

2022 

. 

Bianca Giovanini de Oliveira 

       Sinue Dayan Barbero Lodovici 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                                           
                                                            
 
 
 
 
 
 
Dedico este trabalho à meu marido Fabiano e

minha ﬁlha Valentina, que me apoiaram e em

muitos momentos foram privados de minha com-

panhia e de divertimentos em virtude dos meus

estudos.

iii

A G R A D E C I M E N T O S

Agradeço a Oxalá e aos orixás por terem me mantido na trilha certa durante este

projeto de pesquisa com saúde e forças para chegar até o ﬁnal. Sou grata à minha

família pelo apoio emocional que me deram durante toda minha vida. Deixo um

agradecimento especial ao meu orientador pelo incentivo e pela dedicação do seu

tempo ao meu projeto de pesquisa. Também quero agradecer à Universidade Federal do

ABC e a todos os professores do meu curso pela elevada qualidade do ensino oferecido.

O presente trabalho foi realizado com apoio da Coordenação de Aperfeiçoamento de

Pessoal de Nível Superior - Brasil (CAPES) - Código de Financiamento 001.

v

“A educação é a arma mais poderosa que você pode usar

para mudar o mundo.”

(Nelson Mandela)

vii

R E S U M O

Este trabalho apresenta conceitos básicos de Álgebra Linear, como espaços vetoriais,

transformações lineares, seus autovalores e suas representações diagonais. Também são

abordadas noções elementares sobre grafos, que nos permitem apresentar o objetivo

principal da dissertação: a demonstração do Teorema da Matriz-Árvore de Kirchhoff

para grafos.

Palavras-chave: transformações lineares; grafos; matriz Laplaciana; matriz-árvore;

Kirchhoff

ix

A B S T R A C T

This text presents fundamental concepts of Linear Algebra, such as linear spaces,

linear maps, its eigenvalues and diagonal representations. We also approach some ele-

mentary theory on graphs, which allow us to present the main topic of this dissertation:

the proof of Kirchhoff’s Matrix Tree Theorem on graphs.

Keywords: linear transformations; graphs; Laplacian matrix; tree matrix; Kirchhoff

xi

C O N T E Ú D O

Introdução

1 E S PA Ç O V E T O R I A L , S U B E S PA Ç O, B A S E S E D E P E N D Ê N C I A L I N E A R

1.1 Espaço Vetorial

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.1.1 Axiomas do espaço vetorial

. . . . . . . . . . . . . . . . . . . . .

1.2 Subespaços . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2.1 Propriedades do Subespaço . . . . . . . . . . . . . . . . . . . . .

1.3 Combinações Lineares . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.4 Dependência e Independência Linear . . . . . . . . . . . . . . . . . . . .

1.4.1 Conjunto linearmente independente . . . . . . . . . . . . . . . .

1.4.2 Conjunto linearmente dependente . . . . . . . . . . . . . . . . .

1.5 Bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 M AT R I Z E S

2.1 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

3

3

4

4

4

5

5

5

6

6

9

9

2.1.1 Matrizes especiais

. . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.1.2 Operações com Matrizes . . . . . . . . . . . . . . . . . . . . . . . 13

2.2 Determinante . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.2.1 Determinante de uma matriz de ordem n ≤ 3 . . . . . . . . . . . 20
2.2.2 Determinante de uma matriz de ordem n ≥ 4 . . . . . . . . . . . 22
2.3 Fórmula de Binet-Cauchy . . . . . . . . . . . . . . . . . . . . . . . . . . 23

2.4 Cofator

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

2.5 Matriz Adjunta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

2.6 Matriz Inversa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

3 T R A N S F O R M A Ç Õ E S L I N E A R E S

29

3.1 Imagem ou transformado de v . . . . . . . . . . . . . . . . . . . . . . . . 29

3.2 Transformações lineares representadas por matrizes diagonais . . . . . . 31

3.3 Núcleo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.4 Autovalor e Autovetor

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.4.1 Independência linear de autovetores correspondentes a autova-

lores distintos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

3.5 Matrizes semelhantes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

xiii

xiv

C O N T E Ú D O

3.5.1 Polinômios Característicos . . . . . . . . . . . . . . . . . . . . . . 37

3.5.2 Traço de uma matriz . . . . . . . . . . . . . . . . . . . . . . . . . 38

3.5.3 Método para determinar autovalores e autovetores . . . . . . . . 40

3.6 Diagonalização de matrizes

. . . . . . . . . . . . . . . . . . . . . . . . . 45

4 N O Ç Õ E S S O B R E G R A F O S

49

4.1 deﬁnições básicas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

4.1.1 Ciclo hamiltoniano . . . . . . . . . . . . . . . . . . . . . . . . . . 52

4.2 Representações de Grafos ou Multigrafos . . . . . . . . . . . . . . . . . . 54

4.2.1 Listagem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

4.2.2 Grafos expressos por Matrizes . . . . . . . . . . . . . . . . . . . . 54

4.3 Teoremas e Corolários . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

5 M AT R I Z L A P L A C I A N A

57

5.1 Conceitos básicos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.2 Teorema do Posto para Matrizes Laplacianas . . . . . . . . . . . . . . . . 64

6 T E O R E M A D A M AT R I Z - Á R V O R E

7 C O N C L U S Ã O

Bibliograﬁa

73

79

81

I N T R O D U Ç Ã O

Esse trabalho foi motivado pela curiosidade de compreender um ramo da Matemá-

tica denominado de Teoria dos Grafos, o que me conduziu ao estudo do Teorema da

Matriz-Árvore de Kirchhoff.

Como a Teoria dos Grafos não se mostrou familiar a minha rotina proﬁssional me depa-

rei com a necessidade de resgatar conhecimentos prévios de álgebra linear, essenciais

para compreensão desse tema como autovalor, autovetor, diagonalização de matrizes e

noções sobre grafos.

Dessa forma, para alcançar o principal objetivo da dissertação em apresentar a de-

monstração do Teorema da Matriz-Árvore de Kirchhoff para grafos na tentativa de

atrelar esses assuntos ao cotidiano proﬁssional em que estou inserida, foi elaborada

uma escalada de aprendizagem focada em galgar desde os conceitos básicos, ou seja, o

embasamento conceitual mais simples até a compreensão da demonstração.

Primeiramente, serão deﬁnidos conceitos básicos de espaço vetorial, assim como seus

axiomas e propriedades. Ainda neste capítulo aprofundaremos os conhecimentos sobre

as dependências lineares envolvidas.

Num segundo momento, trabalharemos com matrizes, suas operações, determinantes

além de discorrer sobre a fórmula de Binet-Cauchy.

Na terceira parte aprofundaremos os conhecimentos sobre transformações lineares,

autovalores e autovetores.

No quarto capítulo, apresentaremos as noções básicas sobre grafos, suas representações,

teoremas e corolários.

No quinto capítulo, abordaremos a matriz Laplaciana, que se mostra extremamente

necessária para realização da demonstração foco desta dissertação.

Próximo a conclusão da escalada será realizado o estudo do Teorema do Posto, parte

constituinte da demonstração objeto deste trabalho.

Finalmente, concluiremos o trabalho desenvolvendo a demonstração do Teorema da

Matriz-Árvore de Kirchhoff e por ﬁm será realizado o fechamento do trabalho abordando

todo o desenrolar dessa dissertação.

1

1

E S P A Ç O V E T O R I A L , S U B E S P A Ç O , B A S E S E

D E P E N D Ê N C I A L I N E A R

Na álgebra linear são utilizados com frequência autovalores e autovetores. Como

a dissertação foca na demonstração do Teorema da Matriz-Árvore de Kirchhoff, serão

necessários alguns conceitos básicos de álgebra linear. As referências utilizadas nesse

capítulo foram: [7], [1], [10] e [2].

1.1 E S PA Ç O V E T O R I A L

Um espaço vetorial, também chamado de espaço linear, é um conjunto de vetores

onde estão deﬁnidas as operações de adição e multiplicação. Essas operações devem

satisfazer os axiomas de espaço vetorial. Da mesma forma que, em geometria analítica,

somamos pares de vetores (do plano ou do espaço) e multiplicamos tais vetores por

escalares, o conjunto de todas as matrizes reais admite estrutura de espaço vetorial pois

somamos matrizes e multiplicamos por escalares sendo respeitados os axiomas.

Deﬁnição 1.1. Um espaço vetorial E é um conjunto não vazio de elementos, chamados
vetores, em que estão deﬁnidas duas operações: a adição em que, sendo u, v ∈ E um
par de vetores pertencentes a E, corresponde um novo vetor u + v ∈ E , denominado
soma de u e v; a multiplicação por um número real, sendo um número α ∈ R e um
vetor v ∈ E corresponde um vetor α · v ou αv , sendo que para quaisquer α, β ∈ R e u,v
e w ∈ E as operações devem satisfazer os axiomas a seguir.

3

4

E S PA Ç O V E T O R I A L , S U B E S PA Ç O, B A S E S E D E P E N D Ê N C I A L I N E A R

1.1.1 Axiomas do espaço vetorial

• comutatividade : u + v = v + u;

• associatividade : (u + v) + w = u + (v + w) e (αβ)v = α(βv);

• vetor nulo : existe um vetor 0 ∈ E, denominado vetor nulo, tal que v + 0 = 0 + v =

v para todo v ∈ E;

• inverso aditivo : para cada v ∈ E existe um vetor −v ∈ E, denominado inverso

aditivo tal que −v + v = v + (−v) = 0;

• distributividade :(α + β)v = αv + βv e α(u + v) = αu + αv;

• multiplicação por 1: 1 · v = v.

1.2 S U B E S PA Ç O S

Considerando E um espaço vetorial e F ⊂ E um subconjunto. É dito que F é

um subespaço vetorial de E se, além de ser um subconjunto, F munido das mesmas

operações de E é por si só um espaço vetorial. De fato, para decidir se um subconjunto

F é subespaço de E, não é necessário veriﬁcar todas as propriedades da deﬁnição de

espaço vetorial, basta atender as propriedades abaixo.

1.2.1 Propriedades do Subespaço

• 0 ∈ F;

• Se u, v ∈ F então u + v ∈ F;

• Se v ∈ F então, para todo α ∈ R, αv ∈ F.

Para alcançar o conceito de base é necessária abordagem de alguns conhecimentos

básicos estudados a seguir.

1.3 C O M B I N A Ç Õ E S L I N E A R E S

5

1.3 C O M B I N A Ç Õ E S L I N E A R E S

Deﬁnição 1.2. Seja E um espaço vetorial real. Um vetor x em E é uma combinação
linear dos vetores v1, v2, · · · , vm em E se existirem escalares α1, α2, · · · , αm, tais que x
pode ser expresso na forma

x = α1v1 + ... + αmvm =

m
∑
i=1

αivi

Os escalares α1, α2, · · · , αm são denominados coeﬁcientes da combinação linear.

No caso em que m = 1, a expressão da deﬁnição acima se torna x = α1v1. Desse
modo, dizer que x é uma combinação linear de v1 é o mesmo que dizer que x é um
múltiplo escalar de v1 .

Deﬁnição 1.3. Dizemos que os vetores v1, ..., vm geram um espaço (subespaço) vetorial
E se todo vetor de E puder ser escrito como combinação linear dos vetores v1, ..., vm.

1.4 D E P E N D Ê N C I A E I N D E P E N D Ê N C I A L I N E A R

Os espaços vetoriais possuem uma estrutura algébrica em que, ﬁxada uma base

num espaço vetorial de dimensão m, tem como elementos combinações lineares dos m

vetores com coeﬁcientes univocamente determinados. Torna-se muito importante, em

álgebra linear, saber se um dado vetor v de um espaço vetorial E é combinação linear

de outros vetores desse espaço.

1.4.1 Conjunto linearmente independente

Um conjunto X ⊂ E é linearmente independente quando nenhum vetor v ∈ X é combi-

nação linear de outros elementos de X, sendo E um espaço vetorial. Quando o conjunto
X é L.I (abreviação de linearmente independente) seus elementos são todos (cid:54)= 0, dado
que o vetor nulo é combinação linear de quaisquer outros: 0 = 0 · v1 + ... + 0 · vm.

Teorema 1.4. A combinação linear de vetores L.I. dando o vetor nulo é única.
Seja X um conjunto L.I, no espaço vetorial E. Se α1v1 + ... + αmvm = 0 com v1, ..., vm ∈ X

6

E S PA Ç O V E T O R I A L , S U B E S PA Ç O, B A S E S E D E P E N D Ê N C I A L I N E A R

então α1 = ... = αm = 0.
Reciprocamente , se a única combinação linear nula de vetores de X é aquela cujos

coeﬁcientes são todos iguais a zero, então X é um conjunto L.I.

Pode-se concluir facilmente que todo subconjunto de um conjunto L.I. é ainda L.I.

Corolário 1.5. Se v = α1v1 + ... + αmvm = β1v1 + · · · + βmvm e os vetores v1, · · · , vm são
L.I. então α1 = β1, · · · , αm = βm.

Neste caso teríamos (α1 − β1)v1 + ... + (αm − βm)vm = 0 portanto, pelo Teorema 1.4,

(α1 − β1) = ... = (αm − βm) = 0.

Teorema 1.6. Sejam v1, ..., vm vetores não-nulos do espaço vetorial E. Se nenhum deles é
combinação linear dos anteriores então o conjunto X = {v1, ..., vm} é L.I.

1.4.2 Conjunto linearmente dependente

Deﬁnição 1.7. Um conjunto X ⊂ E é dito linearmente dependente (abreviação L.D.)

se X não é L.I.

Do Teorema 1.4 percebemos que a deﬁnição acima é equivalente a aﬁrmar que X ⊂ E
é linearmente dependente se e somente se equação α1v1 + ... + αmvm = 0 (com incógnitas
αi, i ∈ {1, . . . , m}) admite solução com algum αi (cid:54)= 0 (solução não-trivial).

Teorema 1.8. Se os vetores v1, ..., vm geram espaço vetorial E então qualquer conjunto
com mais de m vetores em E é L.D.

1.5 B A S E S

Deﬁnição 1.9. Um conjunto B ⊂ E é uma base para E se é L.I. e se B gera E, ou seja,

todo vetor de E pode ser escrito como combinação linear dos elementos de B.

Chamamos o número dim E de elementos (ou a cardinalidade) de B de dimensão do

espaço E.

Notamos que a dimensão de E não depende da escolha da base B, ou seja, todas as

bases de E têm mesma cardinalidade. Além disso, os conceitos de base e dimensão se

estendem naturalmente a subespaços F ⊂ E, uma vez que esses são também espaços

vetoriais.

1.5 B A S E S

7

2

M AT R I Z E S

Neste capítulo abordaremos conceitos básicos de matrizes presentes no currículo do

ensino médio. Como referências utilizadas nesse capítulo temos: [7], [5], [10] e [6].

2.1 M AT R I Z E S

Denomina-se matriz m por n, M = [aij], uma lista de números reais aij, onde
1 ≤i≤ m e 1 ≤j≤ n, onde M é formada por números reais distribuídos em m linhas e n
colunas.

Deﬁnição 2.1. Seja M uma matriz qualquer em que cada elemento é indicado por

aij. Tem-se que o índice i indica a linha e o índice j indica a coluna a que o elemento
pertence. Uma matriz m × n é representada por:

M =










a11
a21
......

am1

a12
a22
......

am2

....

....

....

....










a1n
a2n
......

amn

A matriz M pode ser representada por: M = (aij) sendo i ∈ {1, 2, 3, ..., m} e j ∈
{1, 2, 3, ..., n}; ou ainda M = (aij)m×n. Note que o conjunto M(m×n) de todas as matrizes
m × n será um espaço vetorial se deﬁnidos a soma de matrizes e o produto de uma

matriz por um número real, realizando as operações coordenada a coordenada.

9

10

M AT R I Z E S

2.1.1 Matrizes especiais

Existem matrizes que recebem nomes especiais por suas características que serão

mencionadas a seguir.

Matriz linha

É denominada matriz linha toda matriz do tipo 1 × n que é composta por uma única

linha.

Matriz coluna

(cid:16)

a11

a12

....

a1n

(cid:17)

É denominada matriz coluna toda matriz do tipo m × 1 que é composta por uma

única coluna.










a11
a21
......

am1










Matriz nula

É denominada matriz nula toda matriz que é composta somente por elementos

iguais a zero. Exemplos:

(cid:16)

0 0 .... 0

(cid:17)










0

0

......

0



















0

0

0

0

......

......

0

0

....

....

....

....










0

0

......

0

2.1 M AT R I Z E S

11

Matriz quadrada de ordem n

É denominada matriz quadrada de ordem n toda matriz do tipo n × n composta

por quantidade idêntica de linhas e colunas.










a11
a21
......

an1

a12
a22
......

an2

....

....

....

....










a1n
a2n
......

ann

É necessário esclarecer que chama-se diagonal principal de uma matriz quadrada

M de ordem n a matriz linha formada pelos elementos de M que têm os índices i e j

iguais:

(cid:16)

a11

a22

a33

. . .

ann

(cid:17)

É necessário comentar também que chama-se diagonal secundária de uma matriz

quadrada M de ordem n a matriz linha formada pelos elementos de M que têm a soma

dos índices i e j igual a n + 1.
(cid:16)

a1n

a2(n−1)

a3(n−2)

. . .

an1

(cid:17)

Exemplo 2.1.







9 −7
4 −5

8

6
−1 2

3







A matriz acima é quadrada de ordem 3, tendo como diagonal principal

(cid:16)

8 4 3

(cid:17)

e

sua diagonal secundária é

(cid:16)

−7 4 −1

(cid:17)

.

Exemplo 2.2.










0

1

2

3

4

7
6
5
9 −1 −2
8
−3 −4 −5 −6










12

M AT R I Z E S

A matriz acima é quadrada de ordem 4, tendo como diagonal principal

e sua diagonal secundária é

(cid:16)

3 6 9 −3

(cid:17)

.

(cid:16)

0 5 −1 −6

(cid:17)

Matriz diagonal

É denominada matriz diagonal toda matriz quadrada cujos elementos que não

pertencem à diagonal principal são iguais a zero.










a11
0

......

0

a22
......

0

0

....

....

....

....










0

0

......

ann

Note que nada impede que a11 = a22 = ... = ann = 0.

Matriz identidade de ordem n

É denominada matriz identidade, In, a matriz diagonal cujos elementos que perten-

cem à diagonal principal são iguais a 1.










1

0

0

1

......

......

0

0

....

....

....

....










0

0

......

1

In =

Matriz transposta

Deﬁnição 2.2. Dada uma matriz A = (aij)m×n, é denominada transposta de A a matriz
At = (a(cid:48)

ji)n×m tal que aij = a(cid:48)

ji para todo i e todo j.

Exemplo 2.3. Determine a matriz transposta de A.

A =

(cid:32)

(cid:33)

a

b

c d

⇒ At =

(cid:32)

(cid:33)

a

c

b d

2.1 M AT R I Z E S

13

Exemplo 2.4. Encontre a matriz transposta de B.




B =

(cid:32)

(cid:33)

a

b

d e

c

f

a d

⇒ Bt =





b

c





e

f

Exemplo 2.5. Determine a matriz transposta de C.

(cid:16)

C =

a

b

c d

(cid:17)

⇒ Ct =












a

b

c

d








2.1.2 Operações com Matrizes

Adição de Matrizes

Deﬁnição 2.3. Dadas duas matrizes, A = (aij)m×n e B = (bij)m×n, é chamada soma de
A + B, a matriz C = (cij)m×n tal que cij = aij + bij, para todo i e j. Note que a soma
de duas matrizes A e B do tipo m × n é uma matriz C do mesmo tipo em que cada

elemento é a soma dos elementos correspondentes em A e B.

Exemplo 2.6. Dadas as matrizes a seguir foram realizadas as adições.

(a)

(cid:32)

1 2 3

4 5 6

(cid:33)

(cid:32)

+

4 −1
−4

1
0 −6

(cid:33)

(cid:32)

=

1 + 4
4 − 4

2 − 1

5 + 0

3 + 1
6 − 6

(cid:33)

(cid:32)

=

(cid:33)

5 1 4

0 5 0

14

M AT R I Z E S

(b)

(cid:32)

7 8

9 9

(cid:33)

(cid:32)

+

0 1

2 3

(cid:33)

(cid:32)

=

7 + 0 8 + 1

9 + 2 9 + 3

(cid:33)

(cid:32)

=

(cid:33)

9

7

11 12

(cid:16)

(c)

5 11 3/4

(cid:16)

(cid:17)

+

1 −2 3

(cid:16)

(cid:17)

=

5 + 1 11 − 2 3/4 + 3

(cid:16)

(cid:17)

=

6 9 15/4

(cid:17)

Propriedades da Adição de Matrizes

associativa: (A + B) + C = A + (B + C) sendo A, B e C quaisquer do tipo m × n;

Demonstração. Tome (A + B) + C = X e A + (B + C) = Y. Se A = (aij)m×n, B = (bij)m×n,
C = (cij)m×n, X = (xij)m×n e Y = (yij)m×n teremos que: xij = (aij + bij) + cij = aij + (bij +
cij) = yij para todos i ∈ {1, . . . , m} e j ∈ {1, . . . , n}.

comutativa: A + B = B + A sendo A e B quaisquer do tipo m × n;

Demonstração. Tome A + B = X e B + A = Y. Usando a mesma notação adotada na
demonstração da propriedade associativa, teremos que: xij = aij + bij = bij + aij = yij
para todos i ∈ {1, . . . , m} e j ∈ {1, . . . , n}.

elemento neutro: Qualquer que seja A do tipo m × n, existe M, elemento neutro da

soma, tal que A + M = A ;

Demonstração. Basta tomar M a matriz m × n com todas as entradas iguais a 0 e somar
coordenada a coordenada.

Note que, se A + M = A sucede: aij + mij − aij ⇒ mij = 0 ⇒ M = 0 Portanto o

elemento neutro é único, ou seja, é necessariamente a matriz nula do tipo m × n.

É usual denotar o elemento neutro da soma por 0.

elemento simétrico (oposto): Para todo A do tipo m × n existe A(cid:48), denominada
matriz oposta de A, tal que A + A(cid:48) = 0.

Demonstração. Basta tomar A(cid:48) = (a(cid:48)
da matriz A.

ij) com a(cid:48)

ij = −aij, onde aij denotam os elementos

Analogamente ao que ocorre com a matriz nula, ﬁxada A a matriz oposta é única.

2.1 M AT R I Z E S

15

Impondo A + A(cid:48) = M = 0, resulta em: aij + a(cid:48)

ij = −aij ∀i, ∀j. Ou seja, a
simétrica da matriz A para a adição é a matriz A(cid:48) de mesmo tipo que A, em que cada
elemento é simétrico do correspondente de A. É usual denotar a matriz oposta A(cid:48) por
−A.

ij = 0 ⇒ a(cid:48)

Produto de matriz por um escalar

Deﬁnição 2.4. Dado um escalar k e uma matriz A = (aij)m×n chama-se produto kA a
matriz B = (bij)m×n tal que bij = kaij para todo i e todo j. Ou seja, multiplicar uma
matriz A por um escalar k é construir uma matriz B formada pelos elementos de A

todos multiplicados por k.

Exemplo 2.7. Dadas as matrizes abaixo foi realizado o produto de uma matriz por um

escalar.
(cid:32)

(a) 3.

2
7
1
5 −1 −2

(cid:33)

(cid:32)

=

3.7

3.1
3.5 3.(−1) 3.(−2)

3.2

(cid:33)

(cid:32)

=

(cid:33)

6
21
3
15 −3 −6

(b) 1
2 .







0

2

4

8
4
6
10 12 −6













=







0 1

2

4 3
2
5 6 −3

(c) (−2).







−1
8
2 −6
−3

5







=







(−2).(−1)
(−2).2
(−2).(−3)

(−2).8
(−2).(−6)
(−2).5







=













2 −16
−4
12
6 −10

Propriedades do Produto de Matriz por um escalar

O produto de um escalar por uma matriz apresenta as seguintes propriedades que

podem ser deduzidas de maneira semelhante àquela que ﬁzemos para as propriedades
associativa e comutativa da adição, ou seja, coordenada a coordenada. Se a, b ∈ R (a, b
números reais) e A, B são matrizes com o mesmo número de linhas e colunas temos:

16

M AT R I Z E S

• associativa: a.(b.A) = (ab).A;

• distributiva do escalar: a.(A + B) = a.A + a.B;

• distributiva da matriz: (a + b).A = a.A + b.A;

• elemento neutro do produto: 1.A = A.

Decorre de todas essas propriedades o seguinte resultado:

Proposição 2.5. O espaço Mm×n das matrizes m por n munido das operações de adição e
multiplicação por escalar aqui descritas é um espaço vetorial.

Produtos de Matrizes

Deﬁnição 2.6. Dadas duas matrizes A = (aij)m×n e B = (bjk)n×p, chama-se produto AB
a matriz C = (cik)m×p tal que

cik = ai1 · b1k + ai2 · b2k + ai3 · b3k + · · · + ain · b1k =

n
∑
j=1

aijbjk

para todo i ∈ {1, 2, · · · , m} e todo k ∈ {1, 2, · · · , p}. Note que:

A deﬁnição acima garante a existência do produto AB somente se o número de colunas

de A for igual ao número de linhas de B, sendo A do tipo m × n e B do tipo n × p.

A deﬁnição acima também garante que o produto AB é uma matriz que tem o número
de linhas de A e o número de coluna de B, visto que C = AB é do tipo m × p.

Pela deﬁnição, um elemento cik da matriz AB será obtido pelo processo abaixo:

toma-se uma linha i da matriz A:

(cid:16)

ai1

ai2

....

ain

(cid:17)

toma-se a coluna k da matriz B:










b1k
b2k
......

bnk










2.1 M AT R I Z E S

17

coloca-se a linha i de A na "vertical"ao lado da coluna k de B:

(cid:16)

ai1

ai2

....

ain

(cid:17)

toma-se a coluna k da matriz B:










ai1
ai2
......

ain



















b1k
b2k
......

bnk










calculam-se os n produtos dos elementos que ﬁcaram lado a lado:










ai1 · b1k
ai2 · b2k
...
ain · bnk










somam-se esses n produtos , obtendo cik.

Exemplo 2.8. Dada as matrizes A e B, vamos calcular o produto AB.

(cid:32)

A =

(cid:33)

1 2 3

4 5 6

e B =













7

8

9

Observe que sendo A do tipo 2 × 3 e B do tipo 3 × 1 existe AB e é do tipo 2 × 1, sendo

AB = C.

C =

(cid:32)

(cid:33)

.

1 2 3

4 5 6













7

8

9

(cid:32)

=

1.7 + 2.8 + 3.9

4.7 + 5.8 + 6.9

(cid:33)

(cid:32)

=

(cid:33)

50

122

18

M AT R I Z E S

Exemplo 2.9. Calcular AB dadas as matrizes:

A =

(cid:32)

1 2

3 4

(cid:33)

(cid:32)

e B =

(cid:33)

5 6

7 8

Note que A é do tipo 2 × 2 e B do tipo 2 × 2, assim teremos:

C =

(cid:32)

1 2

3 4

(cid:33)

(cid:32)

.

5 6

7 8

(cid:33)

(cid:32)

=

1.5 + 2.7 1.6 + 2.8

3.5 + 4.7 3.6 + 4.8

(cid:33)

(cid:32)

=

(cid:33)

19 22

43 50

Propriedades do Produto de Matrizes

associativa: (AB)C = A(BC), quaisquer que sejam as matrizes A = (aij)m×n, B =
(bjk)n×p e C = (ckl)p×r;

distributiva à direita em relação a adição : (A + B)C = AC + BC, quaisquer que
sejam as matrizes A = (aij)m×n, B = (bij)m×n e C = (cjk)n×p;

distributiva à esquerda: C(A + B) = CA + CB, quaisquer que sejam as matrizes
A = (aij)m×n,B = (bij)m×n e C = (cki)p×m;

comutatividade do escalar: (kA)B = A(kB) = k(AB), quaisquer que sejam o número k
e as matrizes A = (aij)m×n,B = (bjk)n×p;

identidade: Se Im e In são , respectivamente, as matrizes diagonais m × m e n × n com
os elementos da diagonal iguais a 1, então Im A = AIn = A, qualquer que seja a matriz
A = (aij)m×n.

Note que a multiplicação de matrizes não é, em geral, comutativa, ou seja, para duas

matrizes quaisquer A e B é incorreto assumir que A.B = B.A.

Possíveis situações:

2.1 M AT R I Z E S

19

• 1) Existem casos no qual existe AB e não existe BA. Isso sucede quando A é uma
matriz m × n, B é uma matriz n × p e m (cid:54)= p com base na deﬁnição de produto
de matrizes.

Exemplo 2.10. Determine o produto de A.B e B.A.

6



(cid:32)

(cid:33)

A =

0 1 2

3 4 5

e B =









7

8

AB =

(cid:33)

(cid:32)

23

86

BA não existe pois, pela deﬁnição do produto de matrizes, o número de colunas

de B é diferente do número de linhas de A.

• 2) Há casos em que existe AB e BA, entretanto são matrizes de tipos diferentes e,

portanto, AB (cid:54)= BA.Isto ocorre quando A é m × n, B é n × m e m (cid:54)= n.

Exemplo 2.11. Determine o produto de A.B e B.A.













0 1

2 3

4 5

(cid:32)

A =

(cid:33)

5 4 3

2 1 0

e B =

AB =

BA =

(cid:32)

20 32

(cid:33)

2

2

5

1

16 11

0

6

30 21 12













• 3) Nos casos em que AB e BA são do mesmo tipo, ou seja, A e B são matrizes

quadradas e de mesma ordem, temos quase sempre AB (cid:54)= BA.

20

M AT R I Z E S

Exemplo 2.12. Determine o produto de A.B e B.A.

A =

(cid:32)

1 0

2 3

(cid:33)

(cid:32)

e B =

(cid:33)

4 5

6 0

AB =

BA =

(cid:32)

4

(cid:33)

5

(cid:32)

26 10

14 15

6

0

(cid:33)

Observe que quando A e B são tais que AB = BA, dizemos que A e B comutam. Note

que uma condição necessária para A e B comutarem é que sejam matrizes quadradas e

de mesma ordem.

2.2 D E T E R M I N A N T E

Será importante a abordagem de determinante para realização dessa dissertação

devido a dependência desse conceito para utilização da Fórmula de Binet-Cauchy que

será empregada na demonstração do Teorema da Matriz-Árvore de Kirchhoff.

2.2.1 Determinante de uma matriz de ordem n ≤ 3

Deﬁnição 2.7. Considere o conjunto das matrizes quadradas de elementos reais. Seja

A uma matriz quadrada de ordem n, chamaremos de determinante da matriz A, com

notação det(A), o número obtido indutivamente pela fórmula que alguns livros de

ensino médio trazem como o Teorema de Laplace:

• base da indução: No caso em que A é de ordem 1 (n=1), deﬁnimos o det(A)

como o único elemento de A, ou seja, se A = [a11] então det(A) = a11.

• passo de indução: Para n ≥ 2 deﬁnimos:

det(A) =

n
∑
i=1

(−1)i+j.aij.det(Aij)

ou

2.2 D E T E R M I N A N T E

21

det(A) =

n
∑
j=1

(−1)i+j.aij.det(Aij)

onde i ∈ {1, . . . , n} ou j ∈ {1, . . . , n} é ﬁxado e Aij é a matriz (n − 1) × (n − 1)
obtida de A após serem removidas sua linha i e sua coluna j.

É comum denotarmos o determinante de uma matriz escrevendo seus elementos

entre barras verticais simples, por exemplo:

det

(cid:32)

a11
a21

a12
a22

(cid:33)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

a11
a21

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

a12
a22

Notamos que o somatório não depende da escolha de utilização da linha ou coluna.

Observe que, assim, a escolha de uma linha ou coluna com a maior quantidade de zeros

se mostra como uma forma de reduzir os cálculos.

Deﬁnição 2.8. Observamos que, para matrizes de ordem 2 e 3 o cálculo do determi-

nante é simples:

1. No caso em que A é de ordem 2 (n=2), o produto dos elementos da diagonal

principal menos o produto dos elementos da diagonal secundária.

(cid:32)

A =

(cid:33)

a11
a21

a12
a22

→ det(A) = a11.a22 − a12.a21

2. No caso em que A é de ordem 3 (n=3), teremos de repetir as duas primeiras

colunas ao lado da matriz, os termos antecedidos pelo sinal positivo serão obtidos

multiplicando os elementos seguindo na mesma direção da diagonal principal

e os termos antecedidos pelo sinal negativo serão obtidos multiplicando os ele-

mentos seguindo a mesma direção da diagonal secundária. Esse procedimento é

denominado Regra e Sarrus.

A =







a11
a21
a31







a13
a23
a33

a12
a22
a32

→ det(A) =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

a11
a21
a31

a12
a22
a32

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

a13
a23
a33

a11
a21
a31

a12
a22
a32

det(A) = a11.a22.a33 + a12.a23.a31 + a13.a21.a32 − a13.a22.a31 − a11.a23.a32 − a12.a21.a33

22

M AT R I Z E S

Exemplo 2.13. Calcule os determinantes das matrizes a seguir:




(cid:32)

(cid:33)

3 1

4 2

e C =





1 3
4
5 2 −3

1 4

2





A = (21), B =

det(A) = 21

det(B) = 3.2 − 4.1 = 2

det(C) =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 3
4
5 2 −3

1 4

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 3

5 2

1 4

= 1.2.2 + 3.(−3).1 + 4.5.4 − 4.2.1 − 1.(−3).4 − 3.5.2

det(C) = 4 − 9 + 80 − 8 + 12 − 30 = 49.

2.2.2 Determinante de uma matriz de ordem n ≥ 4

Exemplo 2.14. Calcule o determinante da matriz A.










1 −2 0

3

2

3

1

0

3

1

2
3
1 −1

0

2










A =

Como a matriz A é de ordem 4, será escolhida a coluna 3, pois é a coluna que possui

a maior quantidade de zeros, temos

det(A) =

4
∑
i=1

(−1)i+3.ai3.det(A−i−3)

2.3 F Ó R M U L A D E B I N E T- C A U C H Y

23

det(A) = (−1)1+3.0.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 0
3
3 3 −1

1 1

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+ (−1)2+3.2.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3

1

1 −2

3
3 −1

1

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

+(−1)3+3.1.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 −2 3

2

1

0

1

3

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+ (−1)4+3.0.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 −2

3

2

3

3
0
3 −1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

det(A) = 1.0.20 − 1.2.21 + 1.1.5 − 1.0.(−13) = 0 − 42 + 5 − 0 = −37.

Aplicamos a Regra de Sarrus no cálculo de cada um desses determinantes, obtendo

det(A) = −37.

2.3 F Ó R M U L A D E B I N E T- C A U C H Y

A fórmula de Binet-Cauchy é integrante dos resultados da Álgebra Linear e será

necessária na demonstração do Teorema da Matriz-Árvore de Kirchhoff para grafos.

Portanto para conclusão desse trabalho mostra-se signiﬁcativa sua abordagem.

Teorema 2.9. (Fórmula de Binet-Cauchy)

Sejam A e B matrizes de ordem m × n e n × m, respectivamente. Então det(A.B) = 0,

se m > n. Se m ≤ n,

det(A.B) = ∑

det(AP)det(BP)

P

no qual a somatória será sobre todos os subconjuntos P de S = {1, 2, · · · , n} com m

elementos.

Para cada P, AP é a matriz m × m alcançada a partir de A mantendo as colunas de A
cujos índices pertencem a P; BP é a matriz m × m obtida de B mantendo as linhas de B
cujos índices pertencem a P.

24

M AT R I Z E S

Exemplo 2.15. Utilizando a Fórmula de Binet-Cauchy para obter det(A.B) quando







A=

1
2 3 6
−2 0 1 5

4

5 1 2







e B=










−2 3

1

1

0

3

2
5
4 −1

2

6










Com base no teorema 2.9 temos S = {1, 2, 3, 4} e os subconjuntos de P são:

P1 = {1, 2, 3}, P2 = {1, 2, 4}, P3 = {1, 3, 4} e P4 = {2, 3, 4}. Obtendo:

AP1=

AP3=

























1
2 3
−2 0 1

4

5 1

1
3 6
−2 1 5

4

1 2













, BP1=

, BP3=

−2 3

1

1

0

2
5
4 −1

−2 3

1
4 −1

2

6

0

3













, AP2=

, AP4=



















1
2 6
−2 0 5

4

5 2

, BP2=







−2 3 1

1

3

2 5

2 6



,











2 3 6

0 1 5

5 1 2

, BP4=







1 2
5
0 4 −1

3 2

6



.





Assim det(A.B) = det(AP1).(BP1) + det(AP2).(BP2) + det(AP3).(BP3) + det(AP4).(BP4)

det(A.B) = (−23).51 + (−37).19 + 33.(−73) + 39.(−40)

det(A.B) = −1173 − 703 − 2409 − 1560 = −5845.

Note que no teorema 2.9, se m = n, então det(A.B) = det(A).det(B), resultado do

determinante do produto de duas matrizes quadradas e de mesma ordem.

2.4 C O F AT O R

Deﬁnição 2.10. Considere a matriz A de ordem n ≥ 2, sendo aij um elemento de A.
Deﬁnimos como Dij o determinante da matriz obtida suprimindo a i-ésima linha e a
j-ésima coluna de A e denominamos de Cofator Aij do elemento aij, o número dado por

2.4 C O F AT O R

25

Aij = (−1)i+j.Dij

Exemplo 2.16. Determine os cofatores da matriz A.

(A) =







4 3 4

2 1 5

3 3 2







Eliminada a primeira linha e primeira coluna teremos:

D11 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 5

3 2

A11 = (−1)1+1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1 5

3 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)2.(1.2 − 3.5) = 2 − 15 = −13

Eliminada a primeira linha e segunda coluna teremos:

D12 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 5

3 2

A12 = (−1)1+2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 5

3 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)3.(2.2 − 3.5) = (−1)(4 − 15) = 11

Eliminada a primeira linha e terceira coluna teremos:

D13 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 1

3 3

A13 = (−1)1+3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 1

3 3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)4.(2.3 − 3.1) = (6 − 3) = 3

Eliminada a segunda linha e primeira coluna teremos:

D21 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3 4

3 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

26

M AT R I Z E S

A21 = (−1)2+1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3 4

3 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)3.(3.2 − 3.4) = (−1)(6 − 12) = 6

Eliminada a segunda linha e segunda coluna teremos:

D22 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 4

3 2

A22 = (−1)2+2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 4

3 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)4.(4.2 − 3.4) = (8 − 12) = −4

Eliminada a segunda linha e terceira coluna teremos:

D23 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 3

3 3

A23 = (−1)2+3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 3

3 3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)5.(4.3 − 3.3) = (−1)(12 − 9) = −3

Eliminada a terceira linha e primeira coluna teremos:

D31 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3 4

1 5

A31 = (−1)3+1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

3 4

1 5

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)4.(3.5 − 1.4) = (15 − 4) = 11

Eliminada a terceira linha e segunda coluna teremos:

D32 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 4

2 5

A32 = (−1)3+2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 4

2 5

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)5.(4.5 − 2.4) = (−1)(20 − 8) = −12

Eliminada a terceira linha e terceira coluna teremos:

D33 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 3

2 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

A33 = (−1)3+3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4 3

2 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (−1)6.(4.1 − 2.3) = (4 − 6) = −2

2.5 M AT R I Z A D J U N TA

27

Usando a notação deﬁnida aqui para cofatores as fórmulas de Laplace para o deter-

minante (Deﬁnição 2.7 ) podem ser simpliﬁcadas para:

det(A) =

n
∑
i=1

aij.Aij

det(A) =

n
∑
j=1

aij.Aij.

ou

2.5 M AT R I Z A D J U N TA

Deﬁnição 2.11. Dada a matriz A = [aij], a matriz adjunta de A Adj(A) é deﬁnida por:

Adj(A) = (Co f (A))t

onde (Co f (A)) é a matriz na qual os elementos são os cofatores Aij da matriz A,ou seja,
é a matriz onde cada elemento aij é igual ao cofator Aij da matriz A.

Exemplo 2.17. Determine a matriz adjunta de A dada por:

A =







4 3 4

2 1 5

3 3 2







Baseado nos resultados obtidos no exemplo 2.16 teremos:








Co f (A) =





A11 A12 A13
A21 A22 A23
A31 A32 A33





=





−13

11
3
−4 −3
6
11 −12 −2





Adj(A) = (Co f (A))t =







−13
11
6
11 −4 −12
3 −3 −2







28

M AT R I Z E S

2.6 M AT R I Z I N V E R S A

Deﬁnição 2.12. Dada uma matriz quadrada A de ordem n dizemos que A é invertível
com inversa A−1 se existe a matriz A−1 tal que:

AA−1 = A−1 A = In,

onde In é a matriz identidade de ordem n.

Pode-se mostrar que A é invertível se e somente se det(A) (cid:54)= 0. Nesse caso teremos:

A−1 =

1
det(A)

Adj(A).

3

T R A N S F O R M A Ç Õ E S L I N E A R E S

As transformações lineares, também chamadas de aplicações ou operadores, são

funções cujo domínio e contradomínio são subconjuntos de espaços vetoriais.

Serão introduzidos alguns conceitos e notações de transformações lineares e então

falaremos sobre a representação matricial de uma transformação linear, estabelecendo,

assim, um vínculo com o assunto discutido no capítulo anterior.

Explanaremos aqui alguns dos principais conceitos associados a transformações

lineares, como núcleo, imagem, autovalores e autovetores. Novamente nossas principais

referências para esse capítulo são: [7], [5], [10] e [6].

3.1 I M A G E M O U T R A N S F O R M A D O D E v

Deﬁnição 3.1. Sejam E e F espaços vetoriais. Uma transformação linear é uma função
A : E → F é uma relação que associa a cada vetor v ∈ E um vetor A(v) = A · v = Av ∈ F
de tal forma que valham, para quaisquer u, v ∈ E e α ∈ R, as relações:

A(u + v) = Au + Av,

A(α · v) = α · Av

O vetor A · v é denominado imagem ou transformado de v pela transformação A.

Teorema 3.2. Sejam E e F espaços vetoriais e B uma base de E. A cada vetor u ∈ B,
façamos corresponder de maneira arbitrária um vetor u(cid:48) ∈ F. Assim existe uma única
transformação linear A : E → F tal que A.u = u(cid:48) para cada u ∈ B.

29

30

T R A N S F O R M A Ç Õ E S L I N E A R E S

Demonstração. Todo vetor v ∈ E se apresenta, de forma única, como uma combinação
linear v = α1u1 + · · · + αmum de elementos u1, · · · , um da base B. Deﬁnimos A : E → F
pondo

A.v = α1u(cid:48)

1 + · · · + αmu(cid:48)

m

Mostremos agora que A assim deﬁnida é, de fato, uma transformação linear. Sejam

v, w ∈ E. Temos:

e

v = α1u1 + · · · + αmum

w = β1u1 + · · · + βmum

Mesmo que a base B seja inﬁnita, pode-se exprimir v e w como combinações lineares

dos mesmos elementos de B, completando com coeﬁcientes zero os múltiplos de ui que
aparecem apenas numa das duas expressões.

Então

logo

v + w =

m
∑
i=1

(αi + βi)ui

A(v + w) = ∑(αi + βi)u(cid:48)

i = ∑ αiu(cid:48)

i + ∑ βiu(cid:48)

i = A.v + A.w

De forma análoga percebe-se que A(αv) = α.Av, portanto A : E → F é uma
transformação linear, tal que A.u = u(cid:48) para todo u ∈ B. Em relação à unicidade, seja
B : E → F outra transformação linear tal que B.u = u(cid:48) para todo u ∈ B. Então , para
cada v = ∑ αiui ∈ E tem-se

B.v = B(∑ αiui) = ∑ αi.Bui = ∑ αi.u(cid:48)

i = A.v

Portanto B = A

Sejam E e F espaços vetoriais de dimensão ﬁnita e A : E → F uma transformação
linear. Fixadas bases ν = {v1, · · · , vn} ⊂ E e w = {w1, · · · , wm} ⊂ F, para cada
j = {1, · · · , n} o vetor Avj se exprime como combinação linear dos vetores de base w:

3.2 T R A N S F O R M A Ç Õ E S L I N E A R E S R E P R E S E N TA D A S P O R M AT R I Z E S D I A G O N A I S

31

Avj = a1jw1 + a2jw2 + · · · + amjwm =

m
∑
i=1

aijwj

Dessa maneira, a transformação linear A : E → F juntamente com as bases ν ⊂ E
e ω ⊂ F determinam uma matriz a = [aij] ∈ M(m × n), chamada representação
matricial (ou simplesmente a matriz) da transformação linear A relativa as bases ν, ω.

Por deﬁnição, a j-ésima coluna da matriz a é formada pelas coordenadas de Avj em

relação a base ω.

É importante destacar que os vetores nas bases ν e ω são dispostos numa ordem ﬁxa,

sem o que a matriz a não ﬁcaria bem deﬁnida.

3.2 T R A N S F O R M A Ç Õ E S L I N E A R E S R E P R E S E N TA D A S P O R M AT R I Z E S D I A G O N A I S

Para que uma transformação linear tenha uma representação matricial diagonal é

essencial deﬁnir uma condição necessária e suﬁciente.

Teorema 3.3. Seja A : F → F uma transformação linear, com dim F = n. Se A admite
uma representação matricial diagonal, então existe em F um conjunto independente de
elementos v1, · · · , vk que constituem uma base para F e um correspondente conjunto de
escalares λ1, · · · , λn tais que

para k = 1, 2, · · · , n.

A(vk) = λkvk

Inversamente, se existe um conjunto independente v1, · · · , vn de elementos de F e um
correspondente conjunto de escalares λ1, · · · , λn considerando o teorema acima teremos
então a matriz

M = diag(λ1, · · · , λn)

que é uma representação de A, relativa à base (v1, · · · , vn).

Note que os elementos vk e os escalares λk são chamados de autovetores e autovalores

de A respectivamente e serão estudados numa próxima seção.

32

T R A N S F O R M A Ç Õ E S L I N E A R E S

3.3 N Ú C L E O

Nos capítulos posteriores será necessário o conhecimento sobre os conceitos de núcleo

que mencionaremos a seguir.

Dada uma transformação linear A : E → F, o núcleo é o conjunto dos vetores v ∈ E
de tal forma que Av = 0. Será utilizada a notação N(A) como representação do núcleo

de A. Note que N(A) é um subespaço vetorial de E.

Teorema 3.4. Com o objetivo de que uma transformação linear A : E → F seja injetiva é
necessário e suﬁciente que seu núcleo N(A) contenha apenas o vetor nulo.

Demonstração. Uma transformação linear A : E → F será injetiva quando v (cid:54)= v(cid:48) em
E ⇒ Av (cid:54)= Av(cid:48) em F. De modo idêntico: Av = Av(cid:48) ⇒ v = v(cid:48).
Seja A injetiva temos v ∈ N(A) ⇒ A.v = 0 = A.0 ⇒ v = 0, portanto N(A) = {0}.
Seja N(A) = {0}, então Av = Av(cid:48) ⇒ A(v − v(cid:48)) = Av − Av(cid:48) = 0 ⇒ v − v(cid:48) ∈ N(A) ⇒
v − v(cid:48) = 0 ⇒ v = v(cid:48), portanto A é injetiva.

Teorema 3.5. Uma transformação linear é injetiva se, e somente se, leva vetores L.I. em

vetores L.I.

Demonstração. Seja A : E → F uma transformação linear injetiva. Provaremos que se os
vetores v1, · · · , vn ∈ E são linearmente independentes suas imagens Av1, · · · , Avn ∈ F
são vetores linearmente independentes.
Se α1.Av1 + · · · + αn.Avn = 0 consequentemente A(α1v1 + · · · + αnvn) = 0, logo α1v1 +
· · · + αnvn = 0 pois A é injetiva.
Como v1, · · · , vn são L.I., temos α1 = · · · = αn = 0, logo Av1, · · · , Avn são L.I.
Reciprocamente, se a transformação linear A : E → F leva vetores L.I. em vetores L.I.
então v (cid:54)= 0 em E ⇒ v L.I. ⇒ Av L.I. ⇒ Av (cid:54)= 0, portanto N(A) = 0 e A é injetiva.

3.4 A U T O VA L O R E A U T O V E T O R

Considere F um espaço linear e E um subespaço de F, sendo que os mesmos não são

necessariamente de dimensão ﬁnita.

Deﬁnição 3.6. Seja A : E → F uma transformação linear de E em F. Um escalar λ é
chamado autovalor de A se existe em E um elemento v não nulo tal que

3.4 A U T O VA L O R E A U T O V E T O R

33

Av = λv

O elemento v é denominado autovetor de A associado a λ, sendo o escalar λ chamado

autovalor de A.

Note que pedimos v não nulo, pois para toda transformação linear A e todo λ ∈ R

temos A0 = 0 = λ0.

3.4.1 Independência linear de autovetores correspondentes a autovalores distintos

Uma importante propriedade dos autovalores é relacionada no teorema a seguir,

sendo que E representa um subespaço de um espaço linear F.

Teorema 3.7. Se v1, · · · , vk são autovetores de uma transformação linear A : E → E e os
autovalores correspondentes λ1, · · · , λk são distintos, então os autovetores v1, · · · , vk são
linearmente independentes.

Demonstração. Será realizada por indução matemática.
Para k=1, v1 é linearmente independente uma vez que v1 (cid:54)= 0, pois v1 é autovetor de A.
Suponha que seja válido para k autovalores distintos de A os autovetores associados
v1, · · · , vk são L.I. Vamos mostrar que é válido para k+1 se A possui k+1 autovalores
distintos, então os k+1 autovetores associados são L.I. Considere a combinação linear

nula:

α1v1 + · · · + αkvk + αk+1vk+1 = 0

Aplicando a transformação linear A nessa equação e lembrando que Avi = λivi, pois λi
são autovalores de A associados aos autovetores vi para i = {1, · · · , k + 1}, obtendo:

α1λ1v1 + · · · + αkλkvk + αk+1λk+1vk+1 = 0

Multiplicando a primeira equação por λk+1 e subtraindo da segunda equação, tem-se:

α1(λ1 − λk+1)v1 + · · · + αk(λk − λk+1)vk = 0

Pela hipótese de indução, temos v1, · · · , vk são linearmente independentes, assim
temos que αi(λi − λk+1) = 0 para i = {1, · · · , k}. Mas αi(λi − λk+1) = 0 ⇔ αi = 0 ou

34

T R A N S F O R M A Ç Õ E S L I N E A R E S

λi − λk+1 = 0. Como os autovalores de A são distintos, ou seja, λi (cid:54)= λk+1 para i (cid:54)= k + 1
obtemos αi = 0 para i = {1, · · · , k}. Substituindo na combinação linear nula temos:

α1v1 + · · · + αkvk + αk+1vk+1 = 0 ⇒ αk+1vk+1 = 0 ⇒ αk+1 = 0

visto que vk+1 (cid:54)= 0, pois é um autovetor de A. Sendo assim, pode-se veriﬁcar que αi = 0,
para i = {1, · · · , k}, isto signiﬁca que v1, · · · , vk, vk+1 são linearmente independentes.

Note que o Teorema 3.7 não seria verdadeiro se o elemento zero fosse autovetor.

Além disso,por essa razão o 0 é excluído como autovetor.

Corolário 3.8. Se dim E = n, toda transformação linear A : E → E admite no máximo n
autovalores distintos. Se A tem precisamente n autovalores distintos, então os autovetores

correspondentes formam uma base para E e a matriz de A, em relação a esta base, é uma

matriz diagonal com os autovalores como elementos diagonais.

Demonstração. Se existisse n + 1 autovalores distintos então, pelo teorema 3.2 E com-

preenderia n + 1 elementos independentes. O que não é possível já que dim E = n. A

segunda aﬁrmação é resultado dos teoremas 3.2 e 3.3.

3.5 M AT R I Z E S S E M E L H A N T E S

Teorema 3.9. Se duas matrizes n × n, A e D, representam a mesma transformação linear,

então existe uma matriz não singular P tal que

D = P−1 AP

Além disso, se A é a matriz da transformação linear relativa à base G = [g1, · · · , gn] e
se D é a matriz da transformação relativa à base U = [u1, · · · , un], então para P pode-
se considerar a matriz não singular que relaciona as duas bases através da equação

matricial U = GP.

Note que o inverso do teorema 3.9 também é verdadeiro.

Demonstração. Considere o caso em que E = F, e admita que se considera a mesma
base ordenada (g1, · · · , gn) em E e F. Seja B = (bik) a matriz de A relativa a esta base.
Isto signiﬁca que se tem

A(gk) =

bikgi

(3.1)

n
∑
i=1

3.5 M AT R I Z E S S E M E L H A N T E S

35

para k = 1, 2, · · · , n.
Escolhendo outra base ordenada (u1, · · · , un) para E e F e seja D = dkj a matriz de A
relativa a essa nova base. Têm-se:

A(uj) =

n
∑
k=1

dkjuk

para j = 1, 2, · · · , n.
Uma vez que cada uj pertence ao espaço gerado por g1, · · · , gn pode-se escrever

uj =

n
∑
k=1

pkjgk

(3.2)

(3.3)

para j = 1, 2, · · · , n.
Para algum conjunto de escalares pkj. Desse modo a matriz P = (pkj), n × n, deﬁnida
por estes escalares é não singular pois representa uma transformação linear que aplica

uma base E sobre outra base E. Aplicando A a ambos os membros de 3.3 resultam do

mesmo modo as equações:

A(ui) =

n
∑
k=1

pkj A(gk)

(3.4)

para j = 1, 2, · · · , n.
Os sistemas de equações de 3.1 a 3.4 acima podem ser escritos de modo mais simples

na forma matricial inserindo matrizes cujos elementos sejam vetores. Sejam

G = [g1, · · · , gn]

e U = [u1, · · · , un]

matrizes linha, 1 × n cujos elementos são os das bases que se consideram. Assim o
conjunto de equações em 3.3 pode ser escrito como uma equação matricial

U = GP

(3.5)

De forma análoga introduzindo

G(cid:48) = [A(g1), · · · , A(gn)]

e U(cid:48) = [A(u1), · · · , A(un)]

as equações 3.1, 3.2 e 3.4 escrevem-se respectivamente:

G(cid:48) = GA, U(cid:48) = UD, U(cid:48) = G(cid:48)P

(3.6)

de 3.5 resulta

36

T R A N S F O R M A Ç Õ E S L I N E A R E S

.

G = UP−1

Para encontrar a relação entre A e D foi expresso U(cid:48) de duas formas diferentes em

função de U. A partir de 3.5 resulta

U(cid:48) = UD

e

U(cid:48) = G(cid:48)P = GAP = UP−1 AP

Portanto UD = UP−1 AP. Contudo cada elemento nessa equação matricial é uma
combinação linear dos vetores u1, · · · , un, pois como os ui são independentes teremos

D = P−1 AP

Teorema 3.10. Se A e D são duas matrizes n × n relacionadas pela equação da forma
D = P−1 AP, com P uma matriz n × n não singular, então A e D representam a mesma
transformação linear.

Deﬁnição 3.11. Duas matrizes n × n, A e D, são ditas semelhantes se existir uma matriz
não singular P tal que D = P−1 AP.

Observe que os teoremas 3.9 e 3.10 combinados dão origem a:

Teorema 3.12. Duas matrizes são semelhantes se e somente se representam a mesma

transformação linear.

Duas representantes matriciais distintas de uma transformação linear têm o mesmo
polinômio característico. Admitindo que A : E → F é uma aplicação de um espaço n
dimensional E num espaço m dimensional F. Sejam (g1, · · · , gn) e (w1, · · · , wm) bases
ordenadas para E e F respectivamente. A representação matricial de A relativa a esta
escolha de bases é a matriz m × n cujas colunas são as componentes de A(g1), · · · , A(gn)
relativamente à base (w1, · · · , wn). Diferentes representações matriciais são devidas a
diferentes escolhas das bases.

3.5 M AT R I Z E S S E M E L H A N T E S

37

Teorema 3.13. Matrizes semelhantes tem o mesmo polinômio característico e portanto os

mesmos autovalores.

Demonstração. Seja D = P−1 AP com P não singular.

Temos D − λI = P−1 AP − λI. Mas como P−1 IP = I segue:

D − λI = P−1(A − λI)P.

Daí:

det(D − λI) = det(P−1(A − λI)P) = (detP)−1det(A − λI)detP = det(A − λI),

onde usamos a Fórmula de Binet-Cauchy.

3.5.1 Polinômios Característicos

Se dim E = n, o problema de determinação de autovalores de uma transformação
linear A : E → E pode ser resolvido via determinantes. Pretende-se determinar os
escalares λ tais que a equação Av = λv tenha uma solução v (cid:54)= 0. A equação Av = λv
pode escrever-se na forma

λIv − Av = 0

(λI − A)v = 0

Se (λI − A) tem seu determinante diferente de zero, existe inversa e o sistema acima

tem uma única solução v = 0, dado que

(λI − A)v = 0

v = (λI − A)−10

v = 0

Como pretende-se obter soluções com v (cid:54)= 0, é necessário buscar valores de λ para os

quais a matriz (λI − A) tenha determinante igual a zero.

38

T R A N S F O R M A Ç Õ E S L I N E A R E S

det(λI − A) = 0

Essa equação é denominada equação característica.

Deﬁnição 3.14. (Polinômio Característico) Seja A uma matriz quadrada de ordem n,

tem-se que o polinômio característico de A é

det(λI − A)

Proposição 3.15. São chamados de autovalores da transformação representada pela

matriz A as raízes do polinômio característico de A. Note que o polinômio característico
pode ser deﬁnido como (A − λI) ao invés de (λI − A) obtendo um polinômio característico
com sinal trocado, entretanto as raízes adquiridas são as mesmas.

Notamos que as raízes do polinômio característico podem ser números reais (R) ou

complexos (C).

Teorema 3.16. Seja

anxn + an−1xn−1 + · · · + a1x + a0

o polinômio característico de uma matriz M. Então

an−1 = −(−1)ntrM

a0 = detM

onde trM é a soma das raízes do polinômio característico.

Chamamos trM de traço de M. Têm-se que o traço de M é igual a soma dos elementos

da diagonal de A.

3.5.2 Traço de uma matriz

Demonstração. Seja f (λ) o polinômio característico de uma matriz M, nxn e represen-
tadas as n raízes de f (λ) por λ1, · · · , λn, com cada raíz escrita de acordo com o grau de
multiplicidade.

3.5 M AT R I Z E S S E M E L H A N T E S

39

f (λ) = λn + cn−1λn−1 + · · · + c1λ + c0

Na forma fatorada tem-se

f (λ) = (λ − λ1) · · · (λ − λn)

Baseado na comparação das duas formas conclui-se que o termo constante c0 e o

coeﬁciente λn−1 são dados pelas fórmulas

e

c0 = (−1)nλ1 · · · λn

cn−1 = −(λ1 + · · · + λn)

Dado que c0 = (−1)ndetM, têm-se que

λ1 · · · λn = detM

sendo o produto das raízes do polinômio característico de M é igual ao determinante

de M. Note que o determinante de uma matriz triangular é igual ao produto dos

elementos da diagonal e assim se M é triangular:

det(M − λI) = (a11 − λ)(a22 − λ) · · · (ann − λ)

Portanto os autovalores de uma matriz triangular são iguais aos elementos da diago-

nal.

O coeﬁciente de λn−1 é dado por cn−1 = −trM. Pode-se calcular esse coeﬁciente a

partir de f (λ) na forma de determinante e obtemos

cn−1 = −(a11 + · · · + ann),

onde M = (aij).

Corolário 3.17. Uma matriz é singular, ou seja, não invertível se e somente se o seu

polinômio característico não tem termo independente.

40

T R A N S F O R M A Ç Õ E S L I N E A R E S

Deﬁnição 3.18. (Multiplicidade algébrica de autovalor)

A multiplicidade algébrica do autovalor λ é sua multiplicidade enquanto raiz do

polinômio característico de A.

Proposição 3.19. Se λ é autovalor de A : E → E então E(λ) = {v ∈ E; Av = λv} é
subespaço de E e dimE(λ) ≤ (multiplicidade algébrica de λ).

3.5.3 Método para determinar autovalores e autovetores

Para determinar os autovalores e autovetores de uma matriz A, obtenha o polinômio

característico de A, sendo as raízes deste polinômio os autovalores de A. Posteriormente

resolva Av = λv, para todos os autovalores λ, obtêm-se os autovetores de A.

Exemplo 3.1. Considere uma matriz com todos os autovalores distintos. A matriz

A =







2

1

1

2
4
3
−1 −1 −2







tem o polinômio característico det(λI − A)













λ 0

0

0 λ 0

0

0 λ













−

2

1

1

2
4
3
−1 −1 −2













det

det

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

λ − 2 −1
−2

−1
λ − 3 −4

1

1

λ + 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (λ − 1)(λ + 1)(λ − 3)

As raízes do polinômio característico de uma matriz A são os autovalores distintos:
1, −1 e 3. Para determinar os autovetores correspondentes a λ = 1, resolvemos o
sistema Av = v

3.5 M AT R I Z E S S E M E L H A N T E S

41







2

1

1

4
3
2
−1 −1 −2



















v1
v2
v3













v1
v2
v3

=

que resulta em

pode-se escrever

2v1 + v2 + v3 = v1

2v1 + 3v2 + 4v3 = v2

−v1 − v2 − 2v3 = v3

v1 + v2 + v3 = 0

2v1 + 2v2 + 4v3 = 0

−v1 − v2 − 3v3 = 0

Somando membro a membro a primeira e terceira equação encontramos v3 = 0 e as
três equações são reduzidas a v1 + v2 = 0. Assim os autovetores correspondentes a λ = 1
são múltiplos de (1, −1, 0).
Analogamente encontramos os autovetores (0, 1, −1) correspondente a λ = −1 e
(2, 3, −1) correspondente a λ = 3. Uma vez que os autovalores são distintos os corres-
pondentes autovetores (1, −1, 0), (0, 1, −1) e (2, 3, −1) são independentes. Os resultados
resumem-se como segue:

Autovalor λ

1

-1

3

Autovetores
t(1, −1, 0), t (cid:54)= 0
t(0, 1, −1), t (cid:54)= 0
t(2, 3, −1), t (cid:54)= 0

dim

1

1

1

42

T R A N S F O R M A Ç Õ E S L I N E A R E S

Exemplo 3.2. Considere uma matriz com os autovalores repetidos. A matriz







A =

0

2

2 −1

1
3 −1

1

3







corresponde o polinômio característico det(λI − A)

det













λ 0

0

0 λ 0

0

0 λ













−

0

2

2 −1

1
3 −1

1

3













det

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

λ − 2

0
−2

1
λ − 3
−1

−1

1
λ − 3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (λ − 2)(λ − 2)(λ − 4)

Os autovalores são: 2, 2 e 4, mas note que o autovalor 2 é uma raiz dupla do polinômio

característico e para determinar os autovetores correspondentes a λ = 2, resolvemos o

sistema Av = 2v







que resulta em

que se reduz a

2 −1

1
3 −1

1

3

0

2



















v1
v2
v3

= 2.













v1
v2
v3

2v1 − v2 + v3 = 2v1

3v2 − v3 = 2v2

2v1 + v2 + 3v3 = 2v3

−v2 + v3 = 0

v2 − v3 = 0

2v1 + v2 + v3 = 0

3.5 M AT R I Z E S S E M E L H A N T E S

43

Têm-se como solução v2 = v3 = −v1 em que autovetores correspondentes a λ = 2 são
t(−1, 1, 1), com t (cid:54)= 0. De forma análoga encontramos t(1, −1, 1) correspondendo ao
autovalor λ = 4. Os resultados seguem a seguir:

Autovalor λ

2,2

4

Autovetores
t(−1, 1, 1), t (cid:54)= 0
t(1, −1, 1), t (cid:54)= 0

dim

1

1

Exemplo 3.3. Tomando uma matriz com autovalores repetidos. A matriz

A =













2 1 1

2 3 2

3 3 4

tem o polinômio característico det(λI − A)

det













λ 0

0

0 λ 0

0

0 λ













−













2 1 1

2 3 2

3 3 4

det

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

λ − 2 −1
−2
−3

−1
λ − 3 −2
λ − 4
−3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (λ − 1)(λ − 1)(λ − 7),

As raízes do polinômio característico de uma matriz A são os autovalores distintos:

1, 1 e 4. Para determinar os autovetores correspondentes a λ = 7, resolvemos o sistema

Av = 7v







2 1 1

2 3 2

3 3 4



















v1
v2
v3

= 7.













v1
v2
v3

que resulta em

44

T R A N S F O R M A Ç Õ E S L I N E A R E S

pode-se escrever

2v1 + v2 + v3 = 7v1

2v1 + 3v2 + 2v3 = 7v2

3v1 + 3v2 + 4v3 = 7v3

−5v1 + v2 + v3 = 0

2v1 − 4v2 + 2v3 = 0

3v1 + 3v2 − 3v3 = 0

Esta solução admite v2 = 2.v1, v3 = 3v1; em que os autovetores correspondentes a

λ = 7 são t(1, 2, 3), com t (cid:54)= 0. Para o autovalor λ = 1, o sistema Av = v teremos:

v1 + v2 + v3 = 0

v1 + v2 + v3 = 0

v1 + v2 + v3 = 0

Para determinar a solução deste sistema pode-se considerar v1 = a, v2 = b, com a e b
arbitrários e tomar v3 = −a − b. Desse modo cada autovetor correspondente a λ = 1
tem a forma

(a, b, −a − b) = a(1, 0, −1) + b(0, 1, −1)

onde a (cid:54)= 0 e b (cid:54)= 0.Portanto os vetores (1, 0, −1) e (0, 1, −1) formam uma base para
E(1). Assim sendo dimE(λ) = 2 quando λ = 1. Os resultados podem ser resumidos a

seguir.

Autovalor λ

7

1, 1

Autovetores
t(1, 2, 3), t (cid:54)= 0
a(1, 0, −1) + b(0, 1, −1), a (cid:54)= 0 e b (cid:54)= 0

dim E(λ)

1

2

Veriﬁca-se no exemplo 3.3 que existem três autovetores independentes, mas somente

dois autovalores distintos.

3.6 D I A G O N A L I Z A Ç Ã O D E M AT R I Z E S

45

3.6 D I A G O N A L I Z A Ç Ã O D E M AT R I Z E S

A diagonalização de matrizes busca encontrar uma matriz diagonal semelhante a

uma dada matriz. Isso está diretamente ligado a encontrar uma base para um dado

espaço vetorial que torne a representação matricial de uma dada transformação linear

o mais simples possível.

Deﬁnição 3.20. Uma matriz quadrada A é diagonalizável se existe P tal que P−1 AP é
diagonal.

Proposição 3.21. Uma matriz quadrada de ordem n é diagonalizável se e somente se tem

n autovetores linearmente independentes.

Método de Diagonalização de matriz

Encontre n autovetores linearmente independentes de A denotados por v1, v2, · · · , vn.
Seja P = (v1, v2, · · · , vn) têm-se que a matriz D = P−1 AP é diagonal. Pode-se admitir
um conjunto qualquer de autovetores linearmente independentes para diagonalizar uma

matriz, note que cada conjunto resultará numa base diferente em que a transformação

pode ser redigida como matriz diagonal. Veja que a mudança de base e a decorrente

mudança das matrizes de mudança de base não altera a matriz diagonal que representa

a transformação, sendo a sua diagonal composta pelos autovalores da transformação.

Exemplo 3.4. Seja







A =

1 −1
−1

1







1
1
0 −1

0

primeiramente encontra-se o polinômio característico det = (λI − A)

det













λ 0

0

0 λ 0

0

0 λ













−

0

1 −1
−1

1
1
0 −1

1













det

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

λ − 1

1

0

1

−1
λ − 1 −1

0

λ + 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (λ − 1)(λ − 1)(λ + 1) − 1.1.(λ + 1) = (λ3 − λ2 − 2λ).

46

T R A N S F O R M A Ç Õ E S L I N E A R E S

A matriz A tem autovalores 0, −1 e 2. Para determinar os autovetores corresponden-

tes a λ = 0, resolvemos o sistema Av = 0







que resulta em

1 −1
−1

1









.











v1
v2
v3

= 0

1
1
0 −1

0

v1 − v2 + v3 = 0

−v1 + v2 + v3 = 0

−v3 = 0

Tendo assim os autovetores pertencentes a 0 na forma (x, x, 0)T. De forma análoga
obtêm-se os autovetores de −1 na forma (y, y, −y)T e os autovetores de 2 na forma
(z, −z, 0)T.
Adota-se então os autovetores para as coluna da matriz de mudança de base: (1, 1, 0)T,
(1, 1, −1)T, (1, −1, 0)T. Assim

1







P =

1
1
1 −1







, P−1 =







1/2

1/2

0

0
1/2 −1/2







1
−1

0

e P−1 AP =







0
0
0
0 −1 0

0

0

2







0

1
0 −1

Escolhendo agora autovetores diferentes para as colunas da matriz de mudança de

base:(−2, −2, 0)T, (3, 3, −3)T, (1, −1, 0)T.Têm-se dessa forma:

3 −1







Q =

−2
−2
3
0 −3







, Q−1 =







−1/4 −1/4 −1/2
−1/3

0
−1/2

0
1/2

0







e Q−1 AQ =













0
0
0
0 −1 0

0

0

2

1

0

Exemplo 3.5. Dada a matriz

A =

(cid:33)

(cid:32)

2 1

0 2

3.6 D I A G O N A L I Z A Ç Ã O D E M AT R I Z E S

47

tem como polinômio característico (2 − x)2 e duas raízes iguais; o autovalor 2 tem
multiplicidade algébrica igual a 2. Este autovalor tem somente autovetores da forma

(cid:33)

(cid:32)

a

0

e não podemos obter, portanto dois autovetores linearmente independentes para cons-

truir uma matriz de mudança de base. A matriz não é diagonalizável.

Exemplo 3.6. Seja uma matriz qualquer na forma













k 1

0 k

0

1

k

0 0
...
0 0 · · ·













· · · 0

0
...

1

k

. . .
0

com a constante k na diagonal e uns acima da diagonal terá n autovalores iguais a k,

e o autoespaço de todos terá dimensão um. Nenhuma dessas matrizes é diagonalizável.

Portanto não podemos obter dois autovetores linearmente independentes para construir

uma matriz de mudança de base. A matriz não é diagonalizável.

4

N O Ç Õ E S S O B R E G R A F O S

A teoria de grafos tem origem no século XVIII e mostra-se como uma ferramenta

inﬂuente para a modelagem de várias situações reais como pesquisa operacional,

classiﬁcação de relevância (pagerank), engenharia entre outros. Nesse capítulo serão

apresentadas algumas deﬁnições e resultados da Teoria de Grafos fundamentais para

o entendimento das demonstrações que serão apresentadas posteriormente. Foram

utilizadas como referências: [12], [9], [11].

4.1 D E F I N I Ç Õ E S B Á S I C A S

Um grafo G = (N, A) é composto por um conjunto (ﬁnito e não-vazio) N de nós e

um conjunto A de arcos. Cada arco é um par não-ordenado de nós distintos. Diz-se que i
e j são extremidades do arco se este arco corresponde ao par de nós {i, j}, dizemos que
i e j são as extremidades do arco. Será adotado, por convenção, que cada nó do grafo

será representado por um círculo e os arcos do grafo serão representados por linhas

ligando estes círculos, como mostra a Figura 1.

Deﬁnição 4.1. Os multigrafos são os grafos em que dois ou mais arcos são associados a

um mesmo par de nós

Observe que os exemplos a seguir: na Figura 2, estão associados dois arcos aos nós 1 e

3 e na Figura 3 o arco a está associado a um único nó, enquanto o arco b está associado

aos nós 1 e 2. Portanto, dois nós do par não ordenado não são necessariamente distintos,

conforme exempliﬁcado na Figura 3, em que o arco a associa o nó 1 a ele mesmo.

49

50

N O Ç Õ E S S O B R E G R A F O S

Figura 1: Grafo -N = {1, 2, 3, 4, 5} e A = {a, b, c, d}

Figura 2: Multigrafos (a)

Deﬁnição 4.2. É deﬁnido como laço o arco que associa um nó a ele mesmo.

Observe o exemplo da Figura 3, cujo arco a liga o nó 1 ao próprio nó 1.

Deﬁnição 4.3. Um arco é dito incidente nos nós ao qual está associado.

A descrição realizada acima pode ser observada na Figura 2 onde os arcos b e c são

incidentes nos nós 1 e 3 e na Figura 1 o nó 3 do grafo é incidente nos arcos {1, 3} e
{2, 3}.

Deﬁnição 4.4. É denominado nó isolado, aquele nó que não está ligado a nenhum

outro, ou seja, não existe nenhum arco incidente.

O nó isolado pode ser exempliﬁcado na Figura 1 pelo nó 5.

4.1 D E F I N I Ç Õ E S B Á S I C A S

51

Figura 3: Multigrafos (b)

Deﬁnição 4.5. São chamados arcos adjacentes dois arcos incidentes no mesmo nó.

Assim como dois nós incidentes num mesmo arco também são denominados adjacentes.

Como exemplo podemos citar a Figura 1, em que os nós 1 e 4 são adjacentes, além

dos arcos {1, 2} e {1, 3}.

Deﬁnição 4.6. O grau de um nó é deﬁnido pelo número de arcos incidentes no nó,

sendo que cada laço é computado como dois arcos.

Analisando a Figura 3, note que o nó 1 possui grau 3, pois possui arco {1, 2} e o laço
no nó 1 que deve ser contado como dois arcos.Note que observando o nó 2 da mesma

ﬁgura tem grau 1, devido ao único arco {1, 2}.

Deﬁnição 4.7. Um passeio entre dois nós i e j de um grafo ou multigrafo é determi-

nado como uma sequência alternante de nós e arcos iniciando em um dos nós i, j; e

ﬁnalizando no outro, de forma que cada arco é incidente aos nós que o circundam na

sequência.

Como exemplo podemos citar da Figura 1, o passeio entre os nós 1 e 4 será (1, {1, 3},
3, {2, 3}, 2, {1, 2}, 1,{1, 4}, 4). Note que nos casos de multigrafos que contém mais de
um arco entre o mesmo par de nós, a subsequência de nós pode gerar ambiguidade.

Analisando o caso da Figura 2 teremos os passeios (2, a, 1, b, 3) e (2, a, 1, c, 3)

que descreve a mesma sequência de nós. Ocasionalmente utiliza-se apenas uma das

subsequências para a deﬁnição de passeio, para descomplicar a notação. A subsequência

de nós será utilizada somente se não houver ambiguidade.

Deﬁnição 4.8. Um caminho é um passeio que não compreende nós repetidos.

52

N O Ç Õ E S S O B R E G R A F O S

Exempliﬁcando podemos veriﬁcar na Figura 1 entre os nós 2 e 4 os caminhos baseados

apenas nos nós: (2,1,4), (2,3,1,4).

Deﬁnição 4.9. Um circuito trata-se de um caminho fechado entre dois nós idênticos.

Deﬁnição 4.10. Um ciclo é um caminho fechado, isto é, um passeio que contém

precisamente dois nós iguais: o primeiro e o último.

4.1.1 Ciclo hamiltoniano

Um ciclo é chamado hamiltoniano quando é possível formar um ciclo que inclua

todos os nós, dado um grafo ou multigrafo. O ciclo recebe essa designação pois foi

o matemático irlandês William Rowan Hamilton que deﬁniu esse conceito. Um grafo

que compreenda esse tipo de ciclo é chamado grafo hamiltoniano. A seguir temos o

exemplo de um grafo hamiltoniano a Figura 4, em que os arcos azuis constituem um

ciclo hamiltoniano.

Figura 4: Grafo dodecaedro

As Figuras 5 e 6 exempliﬁcam um grafo não-hamiltoniano.Observe que o grafo de

Herschel não é hamiltoniano pois trata-se de um grafo bipartido com um número ímpar

de nós.

Deﬁnição 4.11. Dois nós são chamados de conectados se existe caminho entre eles. Um

grafo ou multigrafo é conexo se qualquer par de nós estão conectados.

4.1 D E F I N I Ç Õ E S B Á S I C A S

53

Figura 5: Grafo de Herschel

Figura 6: Grafo de Tutte

Podemos citar como exemplos de multigrafo conexo as Figuras 2 e 3. Note que o

grafo da Figura 1, é dito desconexo, ou seja, não é conexo.

Deﬁnição 4.12. O grafo H = (NH, AH) é um subgrafo de um grafo G = (N, A) se
NH ⊆ N e AH ⊆ A. Os componentes conexos de um grafo são os subgrafos conexos
deste grafo que não estão de forma rigorosa contidos em outros subgrafos conexos.

Observe a Figura 1, é um subgrafo conexo o subgrafo composto pelos nós 1 e 2 e

pelo arco (1,2); entretanto não se trata de um componente conexo, porque está contido

no subgrafo que contém os nós 1,2 e 3 e o arcos entre estes nós. Pode-se veriﬁcar que

no grafo da Figura 1 contém dois componentes conexos: um constituído pelo nó 5 e

outro composto pelos nós 1,2,3,4 e os arcos entre estes nós.

54

N O Ç Õ E S S O B R E G R A F O S

4.2 R E P R E S E N TA Ç Õ E S D E G R A F O S O U M U LT I G R A F O S

O desenho do grafo é bastante vantajoso, entretanto para resolver grafos maiores e

complexos torna-se fundamental outra forma de descrição para o grafo.

4.2.1 Listagem

A listagem dos elementos N e A é uma forma de descrever um grafo ou multigrafo.

Abaixo serão exibidas as listagens das Figuras 1, 2 e 3.

Grafo/Multigrafo Descrição

Figura 1

Figura 2

Figura 3

=

e A

{1, 2, 3, 4, 5}

N
{{1, 2} , {1, 3} , {1, 4} , {2, 3}}.
N = {1, 2, 3} e A = {a, b, c}, onde a
está associado aos nós 1 e 2; b e c aos

=

nós 1 e 3.

N = {1, 2} e A = {a, b}, onde a está
associado ao nó 1 e b aos nós 1 e 2.

4.2.2 Grafos expressos por Matrizes

Os grafos e multigrafos também podem ser expressos através de matrizes, o que

determina uma ligação com a álgebra. A matriz de incidência em que as linhas estão

associadas aos nós e as colunas aos arcos. Um elemento na linha i e coluna j é igual a 1

se o nó i é incidente no arco j e 0 em caso contrário. Para elucidar o que é uma matriz

de incidência será apresentado o exemplo da Figura 2.







1 1 1

1 0 0

0 1 1







A matriz de adjacência tem suas linhas e colunas associadas aos nós. O elemento na

linha i e coluna j é o número de arcos que possui i e j como extremidades.

4.3 T E O R E M A S E C O R O L Á R I O S

55

Para esclarecer o que é uma matriz de adjacência será apresentada a seguir a matriz

de adjacência da Figura 2.







0 1 2

1 0 0

2 0 0







4.3 T E O R E M A S E C O R O L Á R I O S

Teorema 4.13. A soma dos graus dos nós de um grafo é igual ao dobro do número de

arcos.

Demonstração. Observe que ao acrescentar os graus conta-se cada arco duas vezes,

sendo uma vez de cada extremidade.

Teorema 4.14. O número de nós de grau ímpar de um grafo é par.

Demonstração. Considerando o grafo G = (N, A), sendo expresso por di o grau do nó i
temos:

2|A|= ∑
i∈N

di = ∑

di + ∑

di

i∈N|di par

i∈N|diimpar

Note que o somatório foi separado em duas parcelas, uma contendo os graus pares e

a outra os ímpares. Como a primeira parcela é par e a soma das parcelas também é par

consequentemente a segunda parcela também será par. Repare que para ter um soma

de parcelas ímpares teremos como resultado um número par, para isso é necessário ter

um número par de parcelas.

5

M AT R I Z L A P L A C I A N A

A Matriz Laplaciana é de vital importância para a apresentação do Teorema da

Matriz-árvore, que determina o número de árvores geradoras de um grafo baseado nos

autovalores dessa matriz. Dessa forma esse conceito será explanado nesse capítulo e

retomado posteriormente para realização da demonstração do teorema. As referências

utilizadas foram [9] e [11].

5.1 C O N C E I T O S B Á S I C O S

Deﬁnição 5.1. A matriz de incidência de um grafo G com n vértices e m arestas,
simbolizada por B(G), será a matriz de ordem n × m com entradas:

(cid:40)

bij =

1,

se ei é uma aresta incidente no vértice vi;

0, nos outros casos.

Exemplo 5.1. Para o grafo G da Figura 7, a matriz de incidência será:

B(G)=















1 1 1 0 0 0 0

0 0 1 1 1 0 0

0 0 0 0 1 1 1

1 0 0 0 0 0 0

0 1 0 1 0 1 0

0 0 0 0 0 0 1















57

58

M AT R I Z L A P L A C I A N A

Figura 7: Grafo G

Deﬁnição 5.2. Denomina-se A como matriz de adjacência de G, tendo entradas aij = k,
onde k ∈ N é o número de arestas que conectam o vértice vi ao vértice vj de G. No
caso em que G é um grafo, temos k ∈ {0, 1}; no caso em que G é um multigrafo, k ≥ 2
para pelo menos um par de vértices.

Exemplo 5.2. O grafo da Figura 8

Figura 8: Grafo G

tem como matriz de adjacência:

A =















0 1 0 1 1 0

1 0 1 0 1 0

0 1 0 0 1 1

1 0 0 0 0 0

1 1 1 0 0 0

0 0 1 0 0 0















5.1 C O N C E I T O S B Á S I C O S

59

Exemplo 5.3. O grafo da Figura 9

Figura 9: Multigrafo G

tem como matriz de adjacência:

A =















0 1 0 1 0 0

1 0 1 0 1 0

0 1 0 0 0 2

1 0 0 0 1 0

0 1 0 1 0 1

0 0 2 0 1 0















Deﬁnição 5.3. Seja D a matriz diagonal dos graus dos vértices de um grafo G, em que o

grau do vértice vi, denotado por d(vi), é a quantidade de arestas que incide em vi e seja
A a matriz de adjacência de G. A matriz L é chamada Matriz Laplaciana

L = D − A

Exemplo 5.4. Para o grafo G da Figura 8 , temos a matriz diagonal

D =















3 0 0 0 0 0

0 3 0 0 0 0

0 0 3 0 0 0

0 0 0 1 0 0

0 0 0 0 3 0

0 0 0 0 0 1















60

M AT R I Z L A P L A C I A N A

e matriz de adjacência obtida no Exemplo 5.2, conclui-se que















3 0 0 0 0 0

0 3 0 0 0 0

0 0 3 0 0 0

0 0 0 1 0 0

0 0 0 0 3 0

















-













0 1 0 1 1 0

1 0 1 0 1 0

0 1 0 0 1 1

1 0 0 0 0 0

1 1 1 0 0 0





























=

0 0 0 0 0 1

0 0 1 0 0 0

L=

3 −1

3 −1
−1
0 −1
−1
0
0
−1 −1 −1
0 −1

3

0

0

0 −1 −1
0 −1
0
0 −1 −1

1

0

0

0

3

0

0

0

1















Deﬁnição 5.4. O espectro da matriz laplaciana L de um grafo G, expresso por ς(G), é

a matriz linha na qual todos os elementos são autovalores de L ordenados na forma
µ1 ≥ · · · ≥ µn então

ς(G) = (µ1 ≥ · · · ≥ µn)

Proposição 5.5. Dado um Grafo G e sendo µ1 ≥ · · · ≥ µn os autovalores da matriz
laplaciana (L), então

1. µn = 0 com autovetor associado 1 = [

(cid:104)

1 1 · · · 1

(cid:105)

]T;

2. A multiplicidade algébrica do autovalor 0 é igual ao número de componentes conexas

de G.

Demonstração.

1. Pode-se notar que para cada linha da matriz laplaciana temos

uma entrada que corresponde ao grau do vértice representado por essa linha e

temos nessa mesma linha a mesma quantidade de entradas com valor -1. Portanto,
(cid:105)
]T associado nota-se que a soma dos
tendo um autovalor 1 = [
elementos de uma linha qualquer de L é zero, portanto L.1 = 0 = 0.1. Assim, o

1 1 · · · 1

(cid:104)

número zero é autovalor e, todos os autovalores da matriz laplaciana são não

negativos, ou seja, todos eles serão maiores ou iguais a zero. Logo, µn = 0.

2. No caso do grafo G ser não conexo, aplica-se o resultado para cada uma das

componentes conexas de G, em que cada uma dessas componentes terá um

autovalor zero. Assim, o espectro de G possui tantos zeros quanto o número de

componentes conexas.

Pode-se concluir que a Matriz Laplaciana (L) possui todos os autovalores maiores ou

iguais a zero pela proposição 5.5.

5.1 C O N C E I T O S B Á S I C O S

61

Quando considerado um grafo G orientado é utilizada a deﬁnição a seguir.

Deﬁnição 5.6. Considere um grafo G com arestas orientadas. A matriz β de incidência

considerando a orientação terá seus elementos na forma

βij =





+1,
−1,

0,

se vi é o vértice onde chega ej;
se vi é o vértice de onde parte ej;
nos outros casos.

onde ej ∈ E e vi ∈ V.

Exemplo 5.5. Dado o grafo G orientado da ﬁgura 10

Figura 10: Grafo G Orientado

Obtemos como matriz β de incidência do grafo G orientado

−1 −1 −1

0
0
1 −1 −1















β=

0

0

1

0

0

0

0

0

1

0

0

0

0

0

0

0

1

0

0

0

0
0
1 −1

1

0
0
0 −1

0

0

0

0

1















Nota-se que o número de linhas de β é igual ao número de vértices de G e o número

de colunas de β é igual ao número de arestas de G. Portanto, a ordem da matriz β é

62

M AT R I Z L A P L A C I A N A

dada pelos vértices e arestas do grafo G sendo |V|×|E|. Pode-se observar que a soma

dos elementos de cada coluna de β é igual a zero.

Proposição 5.7. Seja um grafo G com n vértices, sua matriz laplaciana (L) e sua matriz
de incidência β com respeito a uma orientação qualquer. Então, L = ββT.

Demonstração. Seja F = ββT, vamos demonstrar que F = D − A independente da
orientação de G. Sabe-se que o número de linhas de β é igual ao número de vértices de

G e o número de colunas de β é igual ao número de arestas de G que fornece a ordem
da matriz β como n × |E|. Como F é resultado do produto ββT, que é de ordem |E|×n,
consequentemente F é uma matriz quadrada de ordem n. Pela Deﬁnição 5.6 atribuímos
valores −1, 0 ou 1 as entradas da matriz de incidência β de acordo com a orientação da
aresta. Quando o vértice vi possui aresta eij chegando nele é atribuído valor 1, quando o
vértice vi possui aresta eij saindo dele é atribuído valor −1 e nos outros casos é atribuído
valor 0. Note que a linha i da matriz β terá elementos não nulos independente da

orientação adotada no grafo G. Ao multiplicarmos β pela sua transposta, os elementos
de F representam o produto interno das linha i e j de β. Quando i = j, se vi possui
uma aresta eij saindo dele temos βij = −1 sendo adicionado o valor de (−1).(−1) = 1,
ao valor do elemento de F no produto interno. Se vi possui uma aresta eij chegando
nele temos βij = 1 sendo adicionado o valor de 1.1 = 1, ao valor do elemento de F no
produto interno e se não sair nem chegar arestas em vi então βij = 0 sendo adicionado
0 ao valor do elemento de F no produto interno. Dessa forma a diagonal da matriz F

é igual a diagonal da matriz D. Como G não possui laços a diagonal da matriz A é

composta por elementos iguais a zero. Portanto para i = j, as entradas de F são iguais
as entradas de D − A. Quando i (cid:54)= j, com 0 ≤ l ≤ |E|, se a aresta el sai de vi e chega
em vj temos que βil = −1 e βjl = 1. Deste modo sendo adicionado o valor 1.(−1) = −1
ao valor do elemento de F no produto interno. Analogamente se a aresta el saísse
de vj e chegasse em vi tem-se o mesmo resultado mencionado anteriormente. Logo,
independente da orientação do grafo G, ao produto interno entre as linha i e j de β
sempre será adicionado valor −1 quando houver uma aresta conectando os vértices vi
e vj. Diante disso temos que o elemento da matriz F, fij = −k, sendo k o número de
arestas ligando vi e vj. Com base na Deﬁnição 5.2, temos aij = k em que as entradas fora
da diagonal da matriz D são nulas, para i (cid:54)= j as entradas de F são iguais as entradas de
D − A. Portanto F = D − A e assim temos L = ββT.

5.1 C O N C E I T O S B Á S I C O S

63

Exemplo 5.6. Aplicando a proposição 5.7 ao Grafo da Figura 8, seguindo a orientação

da Figura 10 e utilizando o resultado do Exemplo 5.5 teremos

0

0

−1
−1
−1
1
0 −1
0 −1

0

0

0

0

1


















βT=

0

0

0
1
0 −1 0

1

0

0

0

0

1

0

1

0

0

0

0

0
0
0
0 −1 0

0

1

Assim, como L = ββT teremos

−1 −1 −1

0
0
1 −1 −1


















0

0

0
0
1 −1

0

0

0

0

0

0

1

0

1

0
0
0 −1

0

0

0

0

1















L=

0

0

1

0

0

0

0

0

1

0

Portanto

0

0

−1
−1
−1
1
0 −1
0 −1

0

0

0

0

1















.


















0

0

0
1
0 −1 0


















1

0

0

0

0

1

0

1

0

0

0

0

0
0
0
0 −1 0

0

1















L=

3 −1

3 −1
−1
0 −1
−1
0
0
−1 −1 −1
0 −1

0

0

0 −1 −1
0 −1
0
0 −1 −1

3

1

0

0

0

3

0

0

0

1















Esse resultado pode ser corroborado através do resultado do Exemplo 5.4.

64

M AT R I Z L A P L A C I A N A

5.2 T E O R E M A D O P O S T O PA R A M AT R I Z E S L A P L A C I A N A S

Para a demonstração do Teorema da Matriz-Árvore são necessários alguns conceitos

de Álgebra Linear entre eles: teorema do posto, núcleo, matriz adjunta, matriz singular,

entre outros. Para isso serão desenvolvidos os assuntos mencionados. Foram utilizadas

como referências [9], [7], [8], [3] e [4].

Deﬁnição 5.8. Uma matriz E de ordem m × n está na forma escada se:

• (i) O primeiro elemento não nulo de uma linha não nula deve ser igual a 1;

• (ii) A coluna que contém o primeiro elemento não nulo de alguma linha tem

todos os seus outros elementos da coluna iguais a zero;

• (iii) Toda linha nula ocorre abaixo de todas as linhas não nulas;

• (iv) Se as linha 1, 2, · · · , n são linhas não nulas, e se o primeiro elemento não

nulo da linha i ocorre na coluna ki então k1 < k2 < · · · < kn.

Exemplo 5.7. As matrizes a seguir estão na forma escada, pois atendem aos itens

mencionados na deﬁnição 5.8.

(cid:32)

(cid:33)

(cid:32)

,

(cid:33)

(cid:32)

,

(cid:33)

,

1 2

0 0

1 0

0 1

0 0

0 0













1 0 3 0

0 1 2 0

0 0 0 1

Já as matrizes abaixo não estão na forma escada, pois não atendem a algum dos itens

mencionados na deﬁnição 5.8.

A=

(cid:33)

(cid:32)

2 3

0 0

A matriz A não contempla o item (i).

(cid:32)

B=

(cid:33)

1 1

0 1

5.2 T E O R E M A D O P O S T O PA R A M AT R I Z E S L A P L A C I A N A S

65

A matriz B não contempla o item (ii).

C=

(cid:33)

(cid:32)

0 0

1 0

A matriz C não contempla o item (iii).

D=













1
0 1
1 0 −3

0 0

0

A matriz D não contempla o item (iv), pois k1 > k2.

Intuitivamente a matriz na forma escada recebe essa denominação, claramente,

devido a imagem criada após o escalonamento realizado conforme a ﬁgura 11

Figura 11: Matriz na forma escada

Isto é, o número de zeros antecedendo o primeiro elemento não nulo de uma linha

aumenta a cada linha, até restarem somente linhas nulas, quando houver.

Deﬁnição 5.9. Uma matriz é denominada singular se o seu determinante é nulo. Caso

contrário, dizemos que a matriz é não singular.

Exemplo 5.8. A matriz A=

(cid:33)

(cid:32)

1 −2
2 −4

é uma matriz singular, pois

det(A) = [1.(−4)] − [2.(−2)] = −4 + 4 = 0.

Já a matriz A=













1 0 0

0 1 0

0 0 1

não é uma matriz singular, pois

66

M AT R I Z L A P L A C I A N A

det(B) = [1.1.1] + [0.0.0] + [0.0.0] − [0.1.0] − [1.0.0] − [0.0.1] = 1 + 0 + 0 − 0 − 0 − 0 = 1.

Deﬁnição 5.10. Dada uma matriz A de ordem m × n, o posto da matriz é dado pela

ordem da maior submatriz não singular da matriz dada. Denota-se nesse trabalho por

r(A) o posto de A.

Exemplo 5.9. Encontre o posto da matriz







A=

3
1
0 −1

2
2 −4

0

5







Nesse caso pode-se encontrar as submatrizes:

Com submatrizes de ordem 1 × 1

a11 = 1, a12 = 3, a13 = 5, a21 = 0, a22 = −1, a23 = 2, a31 = 0, a32 = 2, a33 = −4.

Com submatrizes de ordem 2 × 2

A1 =

(cid:32)

1
3
0 −1

(cid:33)

(cid:32)

, A2 =

3
5
−1 2

(cid:33)

(cid:32)

, A3 =

−1
2
2 −4

(cid:33)

, A4 =

(cid:32)

0 −1

(cid:33)

0

2

Teremos como determinantes: A1 = −1, A2 = 11, A3 = 0, A4 = 0.

Com a única submatriz de ordem 3 × 3







A=

3
1
0 −1

2
2 −4

0

5







Teremos como determinante A = 0.

5.2 T E O R E M A D O P O S T O PA R A M AT R I Z E S L A P L A C I A N A S

67

Conclui-se que a maior ordem de submatriz não singular é 2, portanto r=Posto(A)=2.

Deﬁnição 5.11. Dada uma matriz A de ordem m × n, a nulidade da matriz é dada pela

diferença entre o número de colunas e o seu posto. Denota-se nul(A).

nul(A) = n − r

Exemplo 5.10. Encontre a nulidade da matriz







A=

1
3
0 −1

2
2 −4

0

5







Conforme resolução do Exemplo 5.9 temos que r = Posto(A) = 2 e a ordem da matriz

A é igual a 3, ou seja, n = 3. Portanto

nul(A) = n − r = 3 − 2 = 1

Teorema 5.12. Se A é uma matriz de ordem m × n, o posto da matriz é determinado pelo

número de linhas linearmente independentes da matriz, sendo as linhas não nulas obtidas

ao reduzir uma matriz na sua forma escada são ditas linhas linearmente independentes.

É possível concluir que se A é representação matricial de uma transformação linear

então o posto de A é exatamente a dimensão da imagem da transformação linear e a

nulidade a dimensão do núcleo dessa transformação.

Exemplo 5.11. Encontre o posto da matriz A.







A =

3
1
0 −1

2
2 −4

0

5







68

M AT R I Z L A P L A C I A N A

Efetuando as seguintes operações com matrizes será obtida a matriz escada:

5

3
1
0 −1







0

2
2 −4







−−−→
2L2+L3







5
3
1
0 −1 2

0

0

0







Para obter a terceira linha com todos os elementos nulos, foi realizada a seleção da

segunda linha da matriz A, seus elementos foram multiplicados por dois e somados

com os elementos da terceira linha obtendo:

2.L2 = 2.0 2.(−1) 2.2
L3 = 0 2 −4
2.L2 + L3 = 2.0 + 0 2.(−1) + 2 2.2 + (−4)
2.L2 + L3 = 0 0 0

Portanto teremos r(A)=2.

Exemplo 5.12. Encontre o posto da matriz B.

Efetuando as seguintes operações com matrizes será obtida a matriz escada:










B =

1
−1 1

2 −2

0 −1

0 −1

0

0

1

1

1

0
1
5 −4 −1 −2










−−−→
L1+L2










1 2 −2
0 −1
0 3 −2 −1 −1

1

0 0
1
1 5 −4 −1 −2

1










−−−−−→
L1+L2−L4










1 2 −2
0 −1
0 3 −2 −1 −1

0 0

0 0

1

0

1

0

1

0










Para obter a matriz na forma escada será necessário que o primeiro elemento da

segunda linha seja nulo, para isso foi selecionada a primeira linha da matriz B e somada

com a segunda linha.

L1 + L2 = 1 + (−1) 2 + 3 (−2) + 0 0 + (−1)
L1 + L2 = 0 3 −2 −1 −1
Para obter a matriz na forma escada será fundamental que o primeiro e o segundo

(−1) + 0

elemento da segunda linha sejam nulos, nesse caso não foi preciso realizar nenhuma

operação, pois já atende ao solicitado.

5.2 T E O R E M A D O P O S T O PA R A M AT R I Z E S L A P L A C I A N A S

69

Para obter a matriz na forma escada será preciso que os três primeiros elementos da

quarta linha sejam nulos, para isso foi selecionada a primeira linha, e somada com a

segunda linha e subtraída a quarta linha.
L1 + L2 − L4 = 1 + 0 − 1 2 + 3 − 5 (−2) + (−2) − (−4) 0 + (−1) − (−1)
L1 + L2 − L4 = 0 0 0 0 0

(−1) + (−1) − (−2)

Assim,

r(B) = 3 e nul(B) = r − n = 5 − 3 = 2

Note que as linhas não nulas obtidas ao reduzir uma matriz na forma escada são

linhas linearmente independentes.

Observamos que a cada passo de simpliﬁcação de uma matriz estamos multiplicando

a mesma por uma matriz não singular. No caso de matrizes quadradas o processo de

simpliﬁcação é análogo àquele de encontrar uma matriz semelhante.

Teorema 5.13. Se A é uma matriz de ordem m × n, o posto da matriz é determinado

pelo número de linhas linearmente independentes da matriz.

Exemplo 5.13. Considere as matrizes na forma escada a seguir:

(cid:32)

A=

0 1 0

0 0 0

(cid:33)

, B=










0

0
1 1
0 1 −1 0

0 0

0 0

0

0

0

0










e C=







1 0 0

0 1 2

0 0 1







Como as linhas não nulas são linearmente independentes teremos que seus postos

são r(A) = 1, r(B) = 2 e r(C) = 3, pois as mesmas já se encontram na forma de matriz

escada.

Propriedade

Se A é uma matriz de ordem m × n, então

r(A) ≤ min {m, n}

70

M AT R I Z L A P L A C I A N A

Lema 5.14. Seja G um grafo com n vértices e seja β a matriz de incidência de G com
uma orientação dada. Logo o posto r(β) de β é n − ω, onde ω é o número de componentes
conexas de G.

Demonstração. Cada componente conexa de G possui uma matriz de incidência, respei-

tando uma orientação atribuída. Dessa forma, escrevemos β como:













β(1)

0
...
0

0

β =

0
β(2)
...
· · ·

· · ·

0

0
. . .
0

0

· · ·

· · ·
...
β(ω−1)
0













0

0
...
0
β(ω)

Onde β(i) corresponde à componente conexa G(i), sendo 1 ≤ i ≤ ω.

) = ni − 1.

), mostraremos que r(β(i)T

), sendo N o núcleo de β(i)T

Teremos r(β(i)) ≤ ni − 1 pois a soma dos elementos de cada coluna de β(i) é igual a zero,
ou seja, o posto dessa matriz será no máximo ni − 1 e sendo ni o número de vértices de
G(i).
Como o posto de uma matriz e o posto de sua matriz transposta são iguais temos que
r(β(i)) = r(β(i)T
Seja x ∈ N(β(i)T
quaisquer e relacionadas aos vértices vl e vk de G(i).
Como G(i) é conexo, existe um caminho formado por q arestas ligando os dois vértices
relacionados a xl e xk. Para cada uma dessas q arestas, encontramos uma coluna cs
sendo que 1 ≤ s ≤ q. Como β(i) possui uma entrada igual a 1, outra entrada igual a −1
e as entradas restantes iguais a zero, dessa maneira xT β(i) = 0 e xTcs = 0.
Visto que esse resultado é válido para qualquer aresta, também valerá para xl = xk e
assim x será o produto entre 1 e qualquer escalar. Logo, 1 criará o subespaço N(β(i)T
)
com dimensão 1.

. Considere duas coordenadas xl e xk

(cid:104)

(cid:105)

1 1 · · · 1

Pode-se concluir que 1 = [
).
Note que como 1T.β(i) = 0, em que zero é a matriz nula, conclui-se que 1 pertence ao
subespaço.
Portanto, r(β(i)T

) = ni − 1, conclui-se r(β(i)) = ni − 1 e logo r(β) = n − ω.

]T, ni vezes, é a base do subespaço N(β(i)T

5.2 T E O R E M A D O P O S T O PA R A M AT R I Z E S L A P L A C I A N A S

71

Proposição 5.15. O posto r(L) da matriz Laplaciana L de um grafo G com n vértices,

onde ω é o número de componentes conexas de G é dado por:

r(L) = n − ω

Demonstração. Com base no lema 5.14 o posto da matriz laplaciana é igual ao posto

da matriz de incidência β respeitando uma orientação considerada sobre G, uma vez
que L = ββT conforme demostração da proposição 5.7.

Exemplo 5.14. Para o grafo da ﬁgura 8 temos ς(G) = (
√

3, 2 −
2, 0). Observe que a multiplicidade do autovalor 0 corresponde a quantidade de

2 + 2, 3 −

3 + 3, 4,

√

√

√

componentes conexas do grafo G com base no lema 5.14 e proposição 5.15.

6

T E O R E M A D A M AT R I Z - Á R V O R E

O Teorema da Matriz-Árvore ou Teorema de Kirchhoff determina o número de árvores

geradoras de um grafo, problema consagrado da Teoria de Grafos que foi provado

por Kirchhoff. Observe que o Teorema da Matriz-Árvore é reconhecido como um dos

primeiros resultados da Teoria Espectral de Grafos. Neste capítulo será apresentada a

demonstração desse teorema, em que foram utilizados conceitos básicos de Álgebra

Linear, matrizes e grafos. Foram utilizados como referências [9], [8] e [11].

Deﬁnição 6.1. Uma árvore geradora de um grafo G é um subgrafo que possui os

mesmos vértices de G e é uma árvore.

Exemplo 6.1. Observe o grafo G e suas árvores geradoras na ﬁgura 12.

Lema 6.2. A matriz adjunta de L, denominada adj(L), é um múltiplo de J. Considerando

J a matriz quadrada de ordem n cujas entradas são todas iguais a 1.

Demonstração. Baseado na proposição 5.15 e considerando G conexo tem-se que r(L) =
n − 1 e fundamentado no lema 5.14 sabe-se que o núcleo de L tem dimensão 1 e é
gerado por 1 = [

]T, n vezes.

1 1 · · · 1

(cid:104)

(cid:105)

Note que por outro prisma teremos que L.adj(L) = det(L).I = 0.I = 0, onde I é a matriz

identidade. Somando todas as linhas de L, obtêm-se uma linha nula. Note que a soma

das linhas de uma matriz não altera seu determinante e portanto temos o det(L) = 0,

onde 0 é a matriz nula de ordem n. Conclui-se que as colunas da adj(L) pertencem
ao núcleo de L e são múltiplas de 1T. Dessa forma como a matriz L é simétrica,

73

74

T E O R E M A D A M AT R I Z - Á R V O R E

Figura 12: Grafo G e suas árvores geradoras

consequentemente, a matriz adj(L) também é simétrica. Logo constatamos que todas as

entradas da adj(L) são iguais, então adj(L) é um múltiplo de J.

Lema 6.3. Qualquer submatriz quadrada de β tem determinantes 0, 1 ou −1.

Demonstração. Seja β(cid:48) uma submatriz de β, sendo que β(cid:48) possui somente duas entradas
não nulas em cada coluna, então essas entradas serão 1 e −1, por isso conclui-se que
cada coluna tem soma igual a zero. Consequentemente β(cid:48) é singular e det(β(cid:48)) = 0.
Agora supondo que no mínimo uma coluna de β(cid:48) tenha precisamente uma entrada
não nula. Nesse contexto se separarmos o determinante de β(cid:48) em termos dessa coluna
obtemos det(β(cid:48)) = ±det(β(cid:48)(cid:48)), em que β(cid:48)(cid:48) é a matriz com uma linha e uma coluna a menos
que β(cid:48). Prosseguindo nesse processo chegaremos a última submatriz de ordem 1, assim
se a entrada dessa submatriz for igual a zero obtemos det(β(cid:48)) = 0. Caso contrário essa
entrada será igual a 1 ou −1 obtendo det(β(cid:48)) = 1 ou −1.

Lema 6.4. Considere qualquer submatriz de β obtida tomando-se n − 1 de suas colunas.
Esta matriz de ordem n × (n − 1) corresponde a um subgrafo H de G contendo todos
os seus vértices. Assim, removida qualquer linha da submatriz, a matriz resultante β(cid:48) é
quadrada de ordem n − 1 e tem |det(β(cid:48))|= 1 ou 0, de acordo com o subgrafo H ser ou não
uma árvore (se for árvore, H será uma árvore geradora de G).

Demonstração. Sem perda de generalidade, será removida a n-ésima linha da submatriz
β originando a submatriz β(cid:48) de ordem n − 1.Aplicando o lema 6.3 temos que |det(β(cid:48))|= 1
ou 0.

T E O R E M A D A M AT R I Z - Á R V O R E

75

Supondo que H não é árvore geradora de G e composto por n vértices e n − 1 arestas
teremos que H é desconexo. Portanto existe uma componente que não possui o vértice
vn, à vista disso a soma das colunas de β(cid:48) correspondentes a essa componente decorrem
em uma coluna nula, as linhas de β(cid:48) são linearmente independentes, dessa forma
det(β(cid:48)) = 0.
Supondo agora que H é árvore geradora de G e renomeando os vértices e arestas,
chamaremos de u1 (cid:54)= vn um vértice de grau 1 de H e de y1 a aresta que incide em u1,
pois uma árvore tem no mínimo dois vértices de grau 1.
Seja β(cid:48) = β − {u1, y1} a árvore H sem o vértice u1 e sem a aresta y1. Selecionando um
vértice de β(cid:48), com exceção de vn, que seja de grau 1 e chamando esse vértice de u2 e
sendo y2 a aresta exclusiva incidente em u2. Repetindo continuamente esse processo,
sempre excluindo o vértice renomeado e sua aresta incidente, pode-se notar que cada
aresta yi incide no vértice vi e vértice vj com j > i. Observe ainda que a renomeação
dos vértices de H fornece uma matriz β(cid:48)(cid:48), vista como resultado da permutação das
linhas de β(cid:48). Dessa forma |det(β(cid:48)(cid:48))|= |det(β(cid:48))|. Como β(cid:48)(cid:48) é uma matriz triangular inferior
que possui como entradas na diagonal principal 1 ou −1 teremos que |det(β(cid:48)(cid:48))|= 1
e |det(β(cid:48))|= 1. Consequentemente teremos |det(β(cid:48))|= 1 somente se H é uma árvore
geradora de G; em caso contrário teremos |det(β(cid:48))|= 0.

Teorema 6.5. O Teorema da matriz-árvore garante que o número de árvores geradoras

de G é igual a qualquer cofator de L, ou seja

adj(L) = τ(G).J

onde τ(G) indica o número de árvores geradoras.

Demonstração. Considere que G possui n vértices e e arestas; fundamentado no lema

6.2, temos que adj(L) é um múltiplo de J. Assim basta provar que o número de árvores

geradoras de G é igual ao valor de qualquer cofator de L.

Seja β0 a matriz resultante da retirada da última linha da matriz β. Note que removendo
a última linha e a última coluna de L é obtida uma submatriz igual a β0βT
0 , sendo assim
o cofator do elemento lnn de L é o det(β0βT

0 ). Pela Fórmula de Binet-Cauchy teremos:

det(β0βT

0 ) = ∑

det(βU)det(βt

U)

U

onde a somatória é considerada sobre todos os subconjuntos U de {1, 2, · · · , n} com n −
1 elementos. Logo βU expressa a submatriz quadrada de β0 cujas colunas correspondem

76

T E O R E M A D A M AT R I Z - Á R V O R E

precisamente aos elementos de U. Baseados nos lemas 6.3 e 6.4 teremos det(βU) (cid:54)= 0,
se e somente se, o subgrafo cujas arestas estão em U e possui todos os vértices de G é
uma árvore geradora de G, assim det(βU) = 1 ou −1.
Note que como det(βU) = det(βt

0) = τ(G). Portanto adj(L) = τ(G).J.

U) e que det(β0βt

Exemplo 6.2. Observe o grafo a seguir e seu determine o número de árvores geradoras.

Figura 13: Grafo G

Baseado no Teorema da Matriz-Árvore teremos que adj(L) = τ(G).J e no resultado

obtido no exemplo 5.4 teremos















L=

3 −1

3 −1
−1
0 −1
−1
0
0
−1 −1 −1
0 −1

0

0

0 −1 −1
0 −1
0
0 −1 −1

3

1

0

0

0

3

0

0

0

1















Fundamentado na deﬁnição 2.11 em que Adj(L) = (Co f (L))t e aplicando as deﬁnições

2.7 e 2.9 podemos obter

T E O R E M A D A M AT R I Z - Á R V O R E

77

Co f (L) =















8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8















Adj(L) = Co f (L)t =















8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8















Como adj(L) = τ(G).J temos















8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8

8 8 8 8 8 8















= τ(G).















1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1

1 1 1 1 1 1















Utilizando a deﬁnição 2.4 encontraremos que

τ(G) = 8

Dessa forma conclui-se que o número de árvores geradoras do gra f oG é 8. Note que

esse resultado corrobora com a resposta obtida no exemplo 6.1.

7

C O N C L U S Ã O

Nesta dissertação, foi desenvolvido o conceito de espaço vetorial onde foram estuda-

dos seus axiomas, além da ideia de subespaço e suas propriedades. Foram abordados

também temas como base, combinação linear e dependência linear.

O desenvolvimento de matrizes; sua deﬁnição, seus tipos, operações, propriedades,

cofatores e determinantes; fundamentam o estudo desse trabalho já que se mostram

presentes na explicação da demonstração do Teorema da Matriz Árvore de Kirchhoff.

Dentro do tópico de transformações lineares foram discutidos conceitos como autovalor

e autovetor; este tópico, diante dos conteúdo abordados na grade curricular da rede

estadual de ensino, não se mostrou presente ao meu contexto proﬁssional o que tornou

necessário um maior empenho e dedicação para apropriação desses conhecimentos.

Seguindo a sequência de assuntos também foram abordados polinômio característico e

diagonalização de matrizes, seus teoremas e deﬁnições. Reconheço que torna-se impor-

tante minha dedicação em relação as demonstrações, pois foi um ponto de atenção e

diﬁculdade no desdobramento deste trabalho.

Os grafos mostraram-se como um assunto interessante, que não foi abordado durante

a minha graduação, e surgiu durante as aulas de Recursos Computacionais no Ensino

da Matemática. Baseado no estudo desse conteúdo compreendi a importância e as

possíveis aplicações em tarefas e rotinas do cotidiano, sua composição, características,

representações entre outros conhecimentos.

Como a matriz laplaciana é parte constituinte da demostração do teorema foco dessa

dissertação, foi dedicado um capítulo a esse conteúdo relacionando a matriz laplaciana,

matriz diagonal e matriz de adjacência. Ainda foi estudado o teorema do posto que

aborda as componentes conexas de um grafo.

No Capítulo 6, foi apresentada a demonstração do Teorema da Matriz Árvore de Kir-

chhoff, embasada nos conhecimentos adquiridos em capítulos anteriores nos resultados

79

80

C O N C L U S Ã O

da Álgebra Linear. O teorema em questão aﬁrma que o número de árvores geradoras

de grafos e multigrafos não orientados é igual ao valor de qualquer cofator da matriz

adjunta da matriz laplaciana do grafo ou multigrafo.

Acredito que torna-se interessante a continuidade desse trabalho, por meio do apro-

fundamento nos conceitos de grafos buscando desenvolver o estudo de conectividade

algébrica e sua aplicação na vulnerabilidade de redes, além do estudo das aplicações

do espectro de um grafo.

B I B L I O G R A F I A

[1] Tom M Apostol, Cálculo: Cálculo com funções de uma variável, com uma introdução

á Álgebra linear, Reverté, 1988.

[2]

, Cálculo: Cálculo com funções de várias variáveis e Álgebra linear, com

aplicações ás equações diferenciais e ás probabilidades, Reverté, 1993.

[3] Sonia Elena Palomino Castro Bean e Daniel Norberto Kozakevich, Álgebra Linear I,

Universidade Federal de Santa Catarina (2011).

[4] José Luiz Boldrini, Sueli IR Costa, VL Figueredo e Henry G Wetzler, Álgebra linear,

1986.

[5] Iezzi Gelson, Fundamentos da Matemática Elementar: Volume IV. 7ª edição, São

Paulo: Atual (1993).

[6] José Vitor Oliveira de Jesus, Introdução à teoria espectral de grafos, Tese de

Doutoramento, 2018.

[7] Elon Lages Lima, Álgebra linear, 2a. ediçao, IMPA, Rio de Janeiro (1996).

[8] Gregorio Malajovich, Álgebra linear, (2021).

[9] Cybele Tavares Maia Vinagre Nair Maria Maia de Abreu, Renata Raposo Del-

Vecchio, Introdução á Teoria Espectral de Grafos com Aplicações, (2012).

[10] Jerônimo C Pellegrini, Álgebra Linear, (2019).

[11] Maurício Policarpo et al., Grafos e multigrafos: o teorema da matriz-árvore, (2017).

[12] José Plínio O SANTOS, Margarida P MELLO e Idani TC MURARI, Introdução à

Análise Combinatória. Rio de Janeiro, Ed, Ciencia Moderna (2007).

81


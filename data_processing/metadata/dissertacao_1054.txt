Universidade Federal de Mato Grosso
Instituto de Ciˆencias Exatas e da Terra

Departamento de Matem´atica

An´alise de varia¸c˜ao de pre¸cos utilizando Cadeias de
Markov e L´ogica Fuzzy

Priscila Gabriele Pacheco

Mestrado Proﬁssional em Matem´atica: PROFMAT/SBM

Orientador: Prof. Dr. Mois´eis dos Santos Cecconello

Trabalho ﬁnanciado pela Capes

Cuiab´a - MT

Agosto de 2019

An´alise de varia¸c˜ao de pre¸cos utilizando Cadeias de
Markov e L´ogica Fuzzy

Este exemplar corresponde `a reda¸c˜ao ﬁnal da dis-
serta¸c˜ao, devidamente corrigida e defendida por
Priscila Gabriele Pacheco e aprovada pela co-
miss˜ao julgadora.

Cuiab´a, 27 de agosto de 2019.

Prof. Dr. Mois´eis dos Santos Cecconello
Orientador

Banca examinadora:

Prof. Dr. Mois´eis dos Santos Cecconello
Prof. Dr. Andr´e Krindges
Prof. Dr. Edgar Nascimento

Disserta¸c˜ao apresentada ao curso de Mestrado
Proﬁssional em Matem´atica – PROFMAT, da Uni-
versidade Federal de Mato Grosso, como requisito
parcial para obten¸c˜ao do t´ıtulo de Mestre em
Matem´atica.

ii

Dados Internacionais de Catalogação na Fonte.  Ficha catalográfica elaborada automaticamente de acordo com os dados fornecidos pelo(a)autor(a). Permitida a reprodução parcial ou total, desde que citada a fonte.P116a    Pacheco, Priscila Gabriele.Análise de variação de preços utilizando Cadeias de Markov eLógica Fuzzy / Priscila Gabriele Pacheco. -- 2019xii, 61 f. : il. ; 30 cm.Orientador: Moiséis dos Santos Cecconello.Dissertação (mestrado profissional) – Universidade Federal deMato Grosso, Instituto de Ciências Exatas e da Terra, Programa dePós-Graduação Profissional em Matemática, Cuiabá, 2019.Inclui bibliografia.1. incerteza. 2. matriz de transição. 3. séries temporais. I. Título.iii

Aos meus amores de sempre.

iv

Agradecimentos

Agrade¸co, primeiramente a minha fam´ılia, Marlene, Luiz e Let´ıcia, pela paciˆencia

ao suportar dois (quase trˆes) anos de estresse, falhas e ausˆencia. A Let´ıcia, por ser meu

suporte, um po¸co sem ﬁm de incentivo e irmandade.

Ao Marcus, em especial, por ser algu´em com quem contar, pelo suporte que me

deu e por ser meu motorista particular desde o exame de acesso at´e a ´ultima confrater-

niza¸c˜ao.

Ao meu orientador, prof. Mois´eis, a quem s´o tenho a agradecer pela paciˆencia e

compreens˜ao.

Aos meus colegas de mestrado, por me darem motivos para divertir muita gente.

Por serem motivo de tanta divers˜ao, obrigada!

`A minha equipe de trabalho, por segurarem as pontas todas as sextas-feiras para

que eu pudesse adquirir o t´ıtulo. Em especial, agrade¸co Iza e Cris pelo apoio e incentivo,

sem elas esse momento n˜ao existiria.

Muito obrigada a todos.

v

N˜ao sou nada.

Nunca serei nada.

N˜ao posso querer ser nada.
`A parte isso, tenho em mim todos os

sonhos do mundo.

Fernando Pessoa.

vi

Resumo

Os conceitos de cadeias de Markov e l´ogica Fuzzy s˜ao importantes teorias cujo foco est´a

no tratamento de incertezas, onde pode-se aplicar a previs˜ao de varia¸c˜ao de pre¸cos de

produtos negociados em bolsa. Este trabalho tem como objetivo apresentar um estudo

de aplica¸c˜ao para os conceitos de cadeias de Markov e l´ogica Fuzzy. Os dados presentes

neste trabalho foram coletados no site do Centro de Estudos Avan¸cados em Economia

Aplicada, departamento integrante da Universidade de S˜ao Paulo, referentes a toda base

de preciﬁca¸c˜ao das commodities soja e frango. Aborda raz˜oes pelas quais as duas teorias

s˜ao consideradas importantes, como podem ser associadas ao estudo de s´eries temporais,

bem como algumas de suas caracter´ısticas e deﬁni¸c˜oes mais interessantes para o modelo

apresentado. Tamb´em pode servir de suporte a outros trabalhos interessados em outros

tipos de varia¸c˜oes de pre¸cos em ativos diversos negociados em bolsa ou balc˜ao. Consi-

derando o tamanho da exporta¸c˜ao para o mercado brasileiro, informa¸c˜oes como an´alise

de varia¸c˜ao do pre¸co s˜ao ´uteis para o gerenciamento dos neg´ocios. Os modelos Fuzzy e

determin´ıstico apresentaram resultados muito parecidos para a varia¸c˜ao de pre¸cos da soja,

mostrando com clareza a tendˆencia positiva desta s´erie temporal. Quanto a varia¸c˜ao de

pre¸cos do frango, os modelos variaram um pouco, apresentando outras possibilidades de

an´alise.

Palavras chave: incerteza, matriz de transi¸c˜ao, s´eries temporais.

vii

Abstract

Concepts of Markov chains and Fuzzy logic are important theories that focus on dealing

with uncertainties, it can be applied the forecast of price variation of exchange traded

products. This paper aims to present an application to the concepts of Markov chains

and Fuzzy logic. The data presented in this paper were collected on the Center for

Advanced Studies in Applied Economics, University of S˜ao Paulo, for the entire soybean

and chicken commodity pricing basis. It discusses how the both theories are considered

important, as they may be associated with the study of time series, as well as some of

their most interesting characteristics and deﬁnitions for the model presented.

It may

also support other work that is interested in other types of price ﬂuctuations in various

exchange or over the counter assets. Considering the size of the export to the Brazilian

market, information such as price change analysis is useful for business management.

The described models presented very similar results for soybean price variation, clearly

presenting the positive trend of this time series. Regarding the variation of chicken prices,

the models varied slightly, presenting other possibilities of analysis.

Keywords: uncertainty, transition matrix, time series.

viii

Sum´ario

Agradecimentos

Resumo

Abstract

Lista de ﬁguras

Lista de tabelas

Introdu¸c˜ao

1 Cadeias de Markov

1.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Cadeias de Markov . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

v

vii

viii

xi

xii

1

3

3

4

1.3 An´alise Assint´otica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2 Teoria Fuzzy

29

2.1 Conjuntos e Eventos Fuzzy . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

2.2 Cadeias de Markov com estados Fuzzy . . . . . . . . . . . . . . . . . . . . 33

3 O Modelo

37

3.1 A proposta

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

3.2 Aplica¸c˜ao Cadeias de Markov . . . . . . . . . . . . . . . . . . . . . . . . . 40

3.3 Aplica¸c˜ao Fuzzy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

3.4 Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

Considera¸c˜oes ﬁnais

54

ix

Referˆencias Bibliogr´aﬁcas

Apˆendice: Scripts R

Apˆendice: Scripts Matlab

56

57

59

x

Lista de Figuras

3.1 Base de dados completa da Soja.

. . . . . . . . . . . . . . . . . . . . . . . 41

3.2 Base de dados completa do Frango.

. . . . . . . . . . . . . . . . . . . . . . 41

3.3 Gr´aﬁco da Varia¸c˜ao do pre¸co da Soja. . . . . . . . . . . . . . . . . . . . . . 43

3.4 Gr´aﬁco da Varia¸c˜ao do pre¸co da carne de Frango.

. . . . . . . . . . . . . . 43

3.5 Histograma dos intervalos da varia¸c˜ao dos pre¸cos de Soja. . . . . . . . . . . 44

3.6 Histograma dos intervalos da varia¸c˜ao dos pre¸cos da carne de Frango.

. . . 44

3.7 Fun¸c˜oes de pertinˆencias do sistema fuzzy. . . . . . . . . . . . . . . . . . . . 50

xi

Lista de Tabelas

1.1 Resumo das propriedades dos estados da Cadeia de Markov . . . . . . . . . 27

3.1 Estat´ıstica descritiva dos dados

. . . . . . . . . . . . . . . . . . . . . . . . 42

3.2

Intervalo das varia¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

3.3

Intervalo das varia¸c˜oes - Soja . . . . . . . . . . . . . . . . . . . . . . . . . 47

3.4 Resultados - Soja . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

3.5

Intervalo das varia¸c˜oes - Frango . . . . . . . . . . . . . . . . . . . . . . . . 49

3.6 Resultados - Frango . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

3.7 Resultados (Fuzzy) - Soja . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

3.8 Resultados (Fuzzy) - Frango . . . . . . . . . . . . . . . . . . . . . . . . . . 53

xii

Introdu¸c˜ao

A matem´atica esteve presente durante o desenvolvimento intelectual humano e

como consequˆencia da hist´oria das civiliza¸c˜oes. O uso da matem´atica como forma de

analisar ˆambitos econˆomicos e sociais data de meados do s´eculo XVII, entretanto a ma-

tematiza¸c˜ao da economia s´o come¸cou de fato no s´eculo XIX. Tal acontecimento foi im-

pulsionado pela industrializa¸c˜ao e as ciˆencias econˆomicas sofreram forte inﬂuˆencia pelos

m´etodos de modelagem matem´atica inspiradas nas ciˆencias naturais, em particular na

f´ısica.

Atrav´es da matem´atica ´e poss´ıvel desenvolver modelos econˆomicos com o prop´osito

de construir uma teoria econˆomica rigorosa e uniﬁcada. Desta forma, a matem´atica per-

mite aos economistas formular proposi¸c˜oes signiﬁcativas e test´aveis sobre muitos assuntos

complexos e abrangentes que n˜ao poderiam ser adequadamente expressas informalmente.

Para analisar a varia¸c˜ao de pre¸cos foram explorados conceitos de Cadeias de

Markov e L´ogica Fuzzy. No primeiro capitulo s˜ao apresentados os conceitos te´oricos de

Cadeias de Markov.

O capitulo dois apresenta a l´ogica Fuzzy, desenvolvida por Lofti A. Zadeh, a qual

se fundamenta em determinar um grau de pertinˆencia que indicar´a quanto um elemento

pertence a um determinado conjunto.

J´a o capitulo trˆes apresenta o modelo de previs˜ao da varia¸c˜ao de pre¸cos, primeiro

atrav´es do modelo cl´assico de Cadeias de Markov com matriz de transi¸c˜ao calculada

atrav´es de probabilidade condicional convencional. Em um momento seguinte apresenta-

se o modelo baseado em estados e probabilidade condicional fuzzy e a discuss˜ao dos

resultados.

O objetivo do trabalho ´e calcular a probabilidade de varia¸c˜ao de pre¸cos de commo-

dities, utilizando cadeias de markov e l´ogica fuzzy, al´em do tempo de recorrˆencia esperado,

a ﬁm de ser uma informa¸c˜ao ´util para gestores do agroneg´ocio.

1

Informa¸c˜oes como varia¸c˜ao do pre¸co de ativos em geral, n˜ao apenas de com-

modities, podem ser muito ´uteis para gestores de carteiras, especuladores e equipes de

gerenciamento de riscos.

2

Cap´ıtulo 1

Cadeias de Markov

1.1

Introdu¸c˜ao

A incerteza se caracteriza como um ambiente naturalmente encontrado em qual-

quer sistema real, principalmente quando a¸c˜oes humanas imprevis´ıveis atuam sobre o
mesmo. ´E poss´ıvel modelar fenˆomenos ou experimentos aleat´orios onde o acaso repre-

senta um papel fundamental, chamados de n˜ao determin´ısticos, est˜ao inseridos na teoria

da probabilidade, ramo da Matem´atica que cria, desenvolve e pesquisa modelos como esse

(Morgado et al. (2016)).

A no¸c˜ao de acaso ´e quase t˜ao antiga quanto a pr´opria humanidade, no entanto,

seu entendimento como fenˆomeno natural demorou para ser aceito, porque era comumente

creditado a divindades. As primeiras manifesta¸c˜oes probabil´ısticas se deram atrav´es de

jogos, mais precisamente o Tali (jogo de osso), considerado o ancestral do dado. E assim,

com o desenvolvimento do com´ercio e uma quantidade cada vez maior de jogos de azar,

a teoria da probabilidade surgiu como disciplina matem´atica baseada nas tentativas de

quantiﬁcar riscos associados a sinistros e possibilidades de ganho (Viali (2008)).

Desde ent˜ao, v´arios matem´aticos dedicaram parte de seus estudos para o desen-

volvimento da teoria da probabilidade. E as contribui¸c˜oes se tornaram maiores a partir

de Laplace, entre eles alguns nomes de destaque s˜ao Chebyshev, Markov, von Mises, e o

atualmente considerado pai da probabilidade moderna, Andrei Kolmogorov.

Um desses nomes de destaque, o russo Andrei Andreyevich Markov (1856-1922)

aplicou o m´etodo das fra¸c˜oes cont´ınuas, inicialmente utilizado por seu professor Pafnuty

Lvovich Chebyshev (1821-1894) `a teoria da probabilidade. Tamb´em estudou sequˆencias de

3

vari´aveis mutuamente independentes esperando estabelecer as leis probabil´ısticas em for-

mas mais gerais. Conhecido pelas sequˆencias de vari´aveis aleat´orias na qual uma vari´avel

´e determinada pelo valor da anterior, mas independente no sentido de que o estado pre-

sente depende apenas da sua anterior, foi este trabalho que lan¸cou a teoria dos processos

estoc´asticos.

1.2 Cadeias de Markov

O processo estoc´astico ´e uma extens˜ao do conceito de vari´avel aleat´oria. A

vari´avel aleat´oria como fun¸c˜ao do tempo ´e chamada de processo estoc´astico (ou processo

aleat´orio).

Em outras palavras, um processo estoc´astico {Xn, n = 0, 1, 2, 3, ...} ´e uma fam´ılia

de vari´aveis aleat´orias parametrizadas pelo inteiro n, assumimos que cada uma destas

vari´aveis aleat´orias Xn toma seus valores em um conjunto ﬁnito T (Rousseau e Saint-

Aubin (2015)).

J´a o processo estoc´astico X(t) ´e de tempo discreto se X(t) ´e deﬁnido apenas para

um conjunto de instantes de tempo tn = nT , onde T ´e uma constante e n ´e um inteiro;

caso contr´ario, X(t) ´e um processo de tempo cont´ınuo.

Segundo Privault (2013), o processo estoc´astico ´e dito ”processo de Markov”, ou

tem a propriedade markoviana se, para todo n ≥ 1 a probabilidade de distribui¸c˜ao de

Xn+1 est´a determinada pelo estado Xn no tempo n, e n˜ao depende dos valores de Xk,

para k ≤ n − 1. Em outras palavras, para todo n ≥ 1 e i0, i1, ..., in, j ∈ T tem-se

P(Xn+1 = j|Xn = in, Xn−1 = in−1, ..., X0 = i0) = P(Xn+1 = j|Xn = in)

Em particular,

P(Xn+1 = j|Xn = in, Xn−1 = in−1) = P(Xn+1 = j|Xn = in),

e

P(X2 = j|X1 = i1, X0 = i0) = P(X2 = j|X1 = i1).

Por outro lado, a primeira ordem de probabilidades de transi¸c˜ao pode ser usada

4

para entender o processo como

P(Xn = in, Xn−1 = in−1, ..., X0 = i0)

= P(Xn = in|Xn−1 = in−1, ..., X0 = i0)

×P(Xn−1 = in−1, ..., X0 = i0)

= P(Xn = in|Xn−1 = in−1)P(Xn−1 = in−1|Xn−2 = in−2, ..., X0 = i0)

×P(Xn−2 = in−2, ..., X0 = i0)

= P(Xn = in|Xn−1 = in−1)P(Xn−1 = in−1|Xn−2 = in−2)

×P(Xn−2 = in−2|Xn−3 = in−3, ..., X0 = i0)

Por indu¸c˜ao ﬁnita, tem-se que

P(Xn = in, Xn−1 = in−1, ..., X0 = i0)

= P(Xn = in|Xn−1 = in−1) ... P(X1 = i1|X0 = i0) P(X0 = i0)

(1.1)

i0, i1, . . . , in ∈ T . Ent˜ao

P =

(cid:88)

j∈T

P(X1 = i, X0 = j)

=

(cid:88)

j∈T

P(X1 = i, X0 = j)P(X0 = j), i ∈ T

(1.2)

Segue uma deﬁni¸c˜ao mais formal descrita por Privault (2013).

Deﬁni¸c˜ao 1. Seja {Xn, n = 0, 1, 2, 3, ...} um processo estoc´astico tomando seus valores

num conjunto T = {A, B, C, ...}. Dizemos que {Xn} ´e uma cadeia de Markov se a proba-

bilidade P (Xn = i), i ∈ T , depender somente do valor do processo no anterior, Xn−1, e

n˜ao em qualquer dos passos anteriores Xn−2, Xn−3, .... Deﬁnimos N < ∞ como o n´umero

de elementos em T .

Essa possibilidade de calcular P (Xn) usando apenas P (Xn−1) ´e a propriedade que

deﬁne as cadeias de Markov. Ou seja, essas estruturas n˜ao possuem mem´oria de estados

passados, e o estado futuro ´e determinado completamente pelo atual.

Por exemplo, considerando o caminho aleat´orio de n´umeros inteiros, onde (Xn)n≥1

5

´e uma sequˆencia independente de valores aleatoriamente incrementados, ´e uma cadeia de

Markov de tempo discreto com T = Z = {. . . , −2, −1, 0, 1, 2, . . . }.

De fato, para todo j, in, . . . , i1 ∈ Z, neste caso T0 = 0, tem-se

P(Tn+1 = j|Tn = in, Tn−1 = in−1, . . . , T1 = i1) =

=

=

P(Tn+1 = j, Tn = in, Tn−1 = in−1, . . . , T1 = i1)
P(Tn = in, Tn−1 = in−1, . . . , T1 = i1)
P(Tn+1 − Tn = j − in, Tn − Tn−1 = in − in−1, . . . , T2 − T1 = i2 − i1, T1 = i1)
P(Tn − Tn−1 = in − in−1, . . . , T2 − T1 = i2 − i1, T1 = i1)
P(Xn+1 = j − in, Xn = in − in−1, . . . , X2 = i2 − i1, X1 = i1)
P(Xn = in − in−1, . . . , X2 = i2 − i1, X1 = i1)
P(Xn+1 = j − in)P(Xn = in − in−1, . . . , X2 = i2 − i1, X1 = i1)
P(Xn = in − in−1, . . . , X2 = i2 − i1, X1 = i1)

=

=

= P(Xn+1 = j − in)

=

P(Xn+1 = j − in)P(Xn + · · · + X1 = in)
P(Xn + · · · + X1 = in)
P(Xn+1 = j − in, Xn + · · · + X1 = in)
P(X1 + · · · + Xn = in)

=

=

P(Xn+1 = j − in, Tn = in)
P(Tn = in)

=

P(Xn+1 = j, Tn = in)
P(Tn = in)

= P(Tn+1 = j|Tn = in)

Em geral, todo processo com incrementos independentes s˜ao processos markovi-

anos. No entanto, nem toda cadeia de Markov tem incrementos independentes. De fato,

cadeias de Markov que n˜ao possuem incrementos independentes s˜ao as de maior interesse.

Rousseau e Saint-Aubin (2015), indicam que Cadeias de Markov s˜ao ´unicas por

seu comportamento ser completamente caracterizado por seu estado inicial e uma matriz

de transi¸c˜ao dada por

P (Xn = i|Xn−1 = j) = pij

(1.3)

Em outras palavras, a evolu¸c˜ao aleat´oria de uma Cadeia de Markov (Xn)n∈N ´e

determinada por

Pi,j := P(Xa = j|X0 = i), i, j ∈ T.

Que coincide com a probabilidade P(Xn+1 = j|Xn = i) que ´e independente de

n ∈ N. Neste caso, a cadeia (Xn)n∈N ´e dita homogˆenea em rela¸c˜ao ao tempo.

6

Ent˜ao, esses dados podem ser organizados em uma matriz T 2 = T × T , chamada

Matriz de Transi¸c˜ao. Logo, uma matriz P ´e de transi¸c˜ao de uma cadeia de Markov se, e

somente se, pij ∈ [0, 1], para todo i, j ∈ T e

(cid:88)

i∈T

pij = 1 para todo j ∈ T .

[Pi,j]i,j∈T = [P(T1 = j|T0 = i)]i,j∈T

Tamb´em escrita como

[Pi,j]i,j∈T =




















· · ·

...

...

...

...

...

· · · P−2,−2 P−2,−1 P−2,0 P−2,1 P−2,2

· · · P−1,−2 P−1,−1 P−1,0 P−1,1 P−1,2

· · ·

· · ·

· · ·

· · ·

P0,−2

P1,−2

P2,−2
...

P0,−1

P1,−1

P2,−1
...

P0,0

P1,0

P2,0
...

P0,1

P1,1

P2,1
...

P0,2

P1,2

P2,2
...




















· · ·

· · ·

· · ·

· · ·

· · ·

· · ·

· · ·

Vale a pena ressaltar a invers˜ao da ordem dos ´ındices (i, j) entre P(Xn+1 = j|Xn =

i) e Pij. Em particular, o estado inicial i ´e uma linha na matriz, enquanto o estado ﬁnal

j corresponde a uma coluna da matriz.

Devido a rela¸c˜ao

P(X1 = j|X0 = i) = 1, i ∈ N

(cid:88)

j∈T

as linhas da matriz de transi¸c˜ao satisfazem condi¸c˜ao

(cid:88)

j∈T

Pi,j = 1,

para todo i ∈ T .

Usando a nota¸c˜ao de matriz P = (Pi,j)i,j∈T e a rela¸c˜ao 1.1 encontra-se

P(Xn = in, Xn−1 = in−1, . . . , X0 = i0) = Pin−1,in. . . . .Pi0,i1

P(X0 = i0)

(1.4)

(1.5)

7

i0, i1, . . . , in ∈ T e reescrevemos 1.2 como

P(X1 = i) =

(cid:88)

j∈T

P(X1 = 1|X0 = j)P(X0 = j) =

(cid:88)

j∈T

Pj,iP(X0 = j), i ∈ T.

(1.6)

Deﬁni¸c˜ao 2. Diz-se que um estado ´e estacion´ario se Pk,k = 1.

Considerando T = N = {0, 1, 2, . . . } e cadeias de Markov tomando valores no
conjunto dos n´umeros naturais, em que a matriz de transi¸c˜ao [P(Xn+1 = j|Xn = i)]i,j∈N ´e

escrita como

[Pi,j]i,j∈N =











P0,0 P0,1 P0,2

P1,0 P1,1 P1,2

P2,0 P2,1 P2,2
...
...
...

· · ·

· · ·

· · ·











De 1.4 temos

∞
(cid:88)

j=0

Pi,j = 1 para todo i ∈ N. Os elementos pij da matriz de

transi¸c˜ao P representam as probabilidades de encontrar-se no estado i ∈ T quando vindo

do estado j ∈ T .

A express˜ao

(cid:88)

i∈T

pij =

(cid:88)

i∈T

P (Xn = i|Xn−1 = j) = 1,

pode ser lida de forma que ao passo n−1, o sistema est´a no estado j, ent˜ao, a probabilidade

de estar em algum estado poss´ıvel no estado n ´e 1.

No caso da cadeia de Markov (Xk)k∈N em que se toma valores no espa¸co ﬁnito

de estados T = {0, 1, . . . , N } a matriz de transi¸c˜ao simpliﬁcada (N + 1) × (N + 1) tem a

forma

[Pi,j]0≤i,j≥N =














P0,0 P0,1 P0,2

. . . P0,N

P1,0 P1,1 P1,2

. . . P1,N

P2,0 P2,1 P2,2
...
...
...
PN,0 PN,1 PN,2

. . . P2,N
...
. . .
. . . PN,N














Ainda que no espa¸co de estado ﬁnito T = {0, 1, . . . , N }, a rela¸c˜ao 1.6 pode ser

8

reescrita usando nota¸c˜ao de matrizes e vetores como

η = Π.P

onde

Π = [Π0, . . . , ΠN ] = [P(X0 = 0), . . . , P(X0 = N )] ∈ RN +1

´e o vetor, ou linha, distribui¸c˜ao de X0 e

η = [η0, . . . , ηN ] = [P(X1 = 0), . . . , P(X1 = N )] ∈ RN +1

´e o vetor, ou linha, distribui¸c˜ao de X1.

Assim, conforme notado, a matriz de transi¸c˜ao P ´e uma forma conveniente de

guardar P(Xn+1 = j|Xn = i), i, j ∈ T , em um vetor de dados.

Mas ´e muito mais que isso. Suponha, por exemplo, que o interesse esteja em uma

probabilidade de transi¸c˜ao de dois passos

P(Xn+2 = j|Xn = i)

Essa probabilidade n˜ao aparece na matriz de transi¸c˜ao P , mas pode ser calculada

atrav´es da an´alise do primeiro passo, como segue

P(Xn+2 = j|Xn = i) =

(cid:88)

l∈T

P(Xn+2 = j, Xn+1 = l|Xn = i)

(cid:88)

=

l∈T

P(Xn+2 = j, Xn+1 = l, Xn = i)
P(Xn = i)

(cid:88)

=

l∈T

P(Xn+2 = j, Xn+1 = l, Xn = i)
P(Xn+1 = l, Xn = i)

P(Xn+1 = l, Xn = i)
P(Xn = i)

(cid:88)

=

l∈T

P(Xn+2 = j|Xn+1 = l, Xn = i)P(Xn+1 = l|Xn = i)

(cid:88)

=

l∈T

P(Xn+2 = j|Xn+1 = l)P(Xn+1 = l|Xn = i)

(cid:88)

=

l∈T

Pi,lPl,j = [P 2]i,j, i, j ∈ T

9

Em geral, para todo k ∈ N temos

P(Xn+k+1 = j|Xn = i) =

(cid:88)

l∈T

P(Xn+k+1 = j, Xn+k = l|Xn = i)

(cid:88)

=

l∈T

P(Xn+k+1 = j, Xn+k = l, Xn = i)
P(Xn = i)

(cid:88)

=

l∈T

P(Xn+k+1 = j, Xn+k = l, Xn = i)
P(Xn+k = l, Xn = i)

P(Xn+k = l, Xn = i)
P(Xn = i)

(cid:88)

=

l∈T

P(Xn+k+1 = j|Xn+k = l, Xn = i)P(Xn+k = l|Xn = i)

(cid:88)

=

l∈T

P(Xn+k+1 = j|Xn+k = l)P(Xn+k = l|Xn = i)

(cid:88)

=

l∈T

P(Xn+k = l|Xn = i)Pi,j

´E poss´ıvel veriﬁcar que a fam´ılia de matrizes

[P(Xn+k = j|Xn = i)]i,j∈T , k ≥ 1

satisfaz a mesma rela¸c˜ao de indu¸c˜ao como a matriz P k, isto ´e,

[P k+1]i,j =

[P k]i,lPl,j,

(cid:88)

l∈T

ent˜ao por indu¸c˜ao em k ≥ 0 a igualdade

[P(Xn+k = j|Xn = i)]i,j∈T = [[P k]i,j]i,j∈T = P k

n˜ao apenas para k = 0 e k = 1, mas para todo k ∈ N.

A rela¸c˜ao de produto de matriz

P m+n = P mP n

que se lˆe

[P m+n]i,j =

(cid:88)

l∈T

[P m]i,l[P n]l,j, i, j ∈ T,

10

que agora pode ser interpretada como

P(Xn+m = j|X0 = i) =

(cid:88)

l∈T

P(Xm = j|X0 = l)P(Xn = l|X0 = i),

i, j ∈ T , que, de acordo com Privault (2013), ´e chamada de equa¸c˜ao de Chapman-

Kolmogorov.

Desta forma, para calcular o vetor probabilidade ap´os qualquer n´umero de passos

´e feito pn = P pn−1 ou, alternativamente,

pn = P pn−1 = P (P pn−2) = · · · = P P . . . P
(cid:125)
(cid:123)(cid:122)
(cid:124)
n vezes

p0 = P np.

(1.7)

1.3 An´alise Assint´otica

Considerando a cadeia de Markov (Xn)n∈N, com espa¸co de estados T e seja A ⊂ T .

Estamos interessados no primeiro tempo TA que a cadeia alcan¸ca o subconjunto A, com

TA = inf {n ≥ 0; Xn ∈ A},

(1.8)

com TA = 0 se X0 ∈ A e TA = +∞ se {n ≥ 0; Xn ∈ A} (cid:54)= ∅, isto ´e, se Xn /∈ A para todo
n ∈ N. o interesse ´e calcular as probabilidades

gl(k) = P(XTA = l|X0 = k)

acertando o conjunto A ⊂ T atrav´es do estado l ∈ A come¸cando de k ∈ T .

Esse c´alculo pode ser realizado atrav´es da an´alise do primeiro passo. Para todo

k ∈ T A tem-se TA ≥ 1 dado que X0 = k, ent˜ao pode-se escrever

gl(k) = P(XTA = l|X0 = k)

=

(cid:88)

m∈T

P(XTA = l|Z1 = m)P(X1 = m|X0 = k)

=

=

(cid:88)

m∈T

(cid:88)

m∈T

Pk,mP(XTA = l|X1 = m)

Pk,mP(XTA = l|X0 = m)

11

=

(cid:88)

m∈T

Pk,mgl(m), k ∈ S A, l ∈ A.

ou seja,

gl(k) =

(cid:88)

m∈T

Pk,mgl(m), k ∈ T, l ∈ A

(1.9)

sob condi¸c˜oes de contorno, gl(k) = P(XTA = l|X0 = k) = 1{k=l}, k ∈ A, l ∈ T , desde que
TA = 0 comece sempre com X0 ∈ A.

A equa¸c˜ao 1.9 pode ser reescrita na forma matricial

gl = P gl, l ∈ A,

(1.10)

onde g ´e um vetor coluna, sob condi¸c˜ao de contorno

gl(k) = P(XTA = l|X0 = k) = 1{l}(k) =






1, k = l

0, k (cid:54)= l

para todo k ∈ A e l ∈ T .

No caso, a matriz de transi¸c˜ao P satisfaz

Pk,l = 1{k=l}

para todo k, l ∈ A, o conjunto A ´e dito ser absorvente. E mais, as probabilidades gl =
P(XTA = l|X0 = k) satisfazem a condi¸c˜ao abaixo para todo k ∈ T .

1 = P(TA = +∞|X0 = k) +

P(XTA = l|X0 = k)

(cid:88)

l∈A

= P(TA = +∞|X0 = k) +

(cid:88)

l∈A

gl(k)

(1.11)

Assuma agora que o espa¸co de estados ´e T = {0, 1, . . . , N } e a matriz de transi¸c˜ao

P tem a forma

P =





Q R

0

I





12

onde Q ´e uma matriz quadrada (r + 1) × (r + 1), R ´e uma matriz (r + 1) × (N − r) e Id

´e a matriz identidade (N − r) × (N − r), em cada caso os estados em {r + 1, . . . , N } s˜ao

absorventes.

Se o conjunto A := {r +1, . . . , N } ´e feito de estados absorventes da cadeia, tem-se

as condi¸c˜oes de contorno gl(m) = 1{m=l}, 0 ≤ l ≤ N , r + 1 ≤ m ≤ N , ent˜ao a equa¸c˜ao

1.9 pode ser reescrita como

gl(k) =

N
(cid:88)

m=0

Pk,mgl(m)

gl(k) =

r
(cid:88)

m=0

Pk,mgl(m) +

N
(cid:88)

m=r+1

Pk,mgl(m)

gl(k) =

r
(cid:88)

m=0

Qk,mgl(m) + Rk,l, 0 ≤ k ≤ r, r + 1 ≤ l ≤ N.

Geralmente, tem-se interesse no tempo m´edio que a cadeia leva para atingir o
conjunto A ⊂ T come¸cando pelo estado k ∈ T , ou seja, hA(k) := E[TA|X0 = k]. E

claramente tem-se hA(k) = 0, para todo k ∈ A.

E para todo k ∈ T A, usando a an´alise do primeiro passo tem-se

hA(k) = E[TA|X0 = k]

(cid:88)

=

l∈T

P(X1 = l|X0 = k)(1 + E[TA|X0 = l])

(cid:88)

=

l∈T

P(X1 = l|X0 = k) +

(cid:88)

l∈T

P(X1 = l|X0 = k)E[TA|X0 = l]

= 1 +

(cid:88)

l∈T

P(X1 = l|X0 = k)E[TA|X0 = l]

= 1 +

(cid:88)

l∈T

Pk,lhA(l), k ∈ T A

ou seja,

hA(k) = 1 +

(cid:88)

l∈T

Pk,lhA(l), k ∈ T A,

(1.12)

Sob as condi¸c˜oes de contorno

hA(l) = E[TA|X0 = l], l ∈ A.

(1.13)

13

A condi¸c˜ao 1.13 implica que a 1.12 torna-se

hA(k) = 1 +

(cid:88)

l∈T A

Pk,lhA(l), k ∈ T A

Essa equa¸c˜ao pode ser reescrita na forma de matriz como

P =















1
...
1

+ P hA.

Considerando apenas as linhas com ´ındice k ∈ T A, sob as condi¸c˜oes de contorno

hA(k) = 0, k ∈ A.

Quando a matriz de transi¸c˜ao P tem a forma 1.3 e A = {r + 1, . . . , N }, a equa¸c˜ao

1.12 ´e reescrita como

hA(k) = 1 +

N
(cid:88)

l=0

Pk,lhA(l)

= 1 +

r
(cid:88)

l=0

Pk,lhA(l) +

N
(cid:88)

l=r+1

Pk,lhA(l)

= 1 +

r
(cid:88)

l=0

Pk,l(l), 0 ≤ k ≤ r,

desde que hA(l) = 0, l = r + 1, . . . , N , isto ´e,

hA(k) = 1 +

r
(cid:88)

l=0

Pk,lhA(l), 0 ≤ k ≤ r,

com hA(k) = 0, r + 1 ≤ k ≤ n.

O que foi descrito acima pode ser generalizado e chegar a uma equa¸c˜ao para uma

expectativa da forma

hA(k) := E[

TA−1
(cid:88)

i=0

f (Xi)|X0 = k], 0 ≤ k ≤ N,

onde f (· ) ´e uma fun¸c˜ao utilidade.

Temos

hA(k) = f (k) +

r
(cid:88)

m=0

Pk,mhA(m), 0 ≤ k ≤ r,

14

com

hA(k) = 0, r + 1 ≤ k ≤ n.

Quando f ´e a fun¸c˜ao indicadora f = 1{l}, isto ´e,

f (Zi) = 1{l}(Zi) =






1, Zi = l

0, Zi (cid:54)= l

A vari´avel hA(k) produzir´a a m´edia do n´umero de visitas ao estado l partindo

do estado k antes de entrar no conjunto A. Quando A = {m} encontra-se h{m}(k) =

1 +

(cid:88)

l∈S,
l(cid:54)=m

Pk,lh{m}(l), k ∈ T {m} e h{m}(m) = 0, ainda de acordo com Privault (2013).

Considere agora o primeiro tempo de retorno T r

j para o estado j ∈ T , deﬁnido

por T r

j := inf {n ≤ 1 : Xn = j}, com T r

j = +∞ se Xn (cid:54)= j para todo n ≤ 1.

Em contraste com a deﬁni¸c˜ao 1.8 do tempo que bate Tj, o ´ınﬁmo ´e pego aqui

para n ≥ 1 como uma demora de pelo menos um passo do estado inicial para o retorno

ao estado j. Mesmo assim, Tj = T r

j se a cadeia come¸cou em um estado i diferente de j.

Denota por

µj(i) = E[T r

j |X0 = i] ≥ 1

o tempo m´edio de retorno ao estado j ∈ T come¸cando pelo estado i ∈ T . O tempo m´edio

de retorno tamb´em pode ser calculado pela an´alise do primeiro passo.

µj(i) = E[T r

j |X0 = i]

= 1 × P(X1 = j|X0 = i) +

(cid:88)

l∈T,
l(cid:54)=j

P(X1 = l|X0 = i)(1 + E[T r

j |X0 = l])

= Pi,j +

(cid:88)

l∈T,
l(cid:54)=j

Pi,j(1 + µj(l))

= Pi,j +

Pi,j +

(cid:88)

l∈T,
l(cid:54)=j

(cid:88)

l∈T,
l(cid:54)=j

Pi,lµj(l)

(cid:88)

=

Pi,l +

l∈T

(cid:88)

l∈T,
l(cid:54)=j

Pi,lµj(l)

15

= 1 +

(cid:88)

l∈T,
l(cid:54)=j

Pi,lµj(l),

ent˜ao

µj(i) = 1 +

(cid:88)

l∈T,
l(cid:54)=j

Pi,lµj(l), i, j ∈ T.

(1.14)

Para calcular a probabilidade de retorno em 1.14 n˜ao foi trabalhada qualquer

condi¸c˜ao de contorno. Enquanto que o tempo de retorno T r

i est´a a pelo menos um passo,

ou seja, µi(i) ≥ 1 n˜ao pode ser nulo, sempre ter´a hi(i) = 0, i ∈ T . Por outro lado, por

deﬁni¸c˜ao tem-se

hi(j) = E[T r

i |X0 = j] = E[Ti|X0 = j] = µi(j)

para todo i (cid:54)= j, e para i = j o tempo m´edio de retorno µj(j) pode ser calculado pelo

tempo de alcance hj(l), l (cid:54)= j, atrav´es da an´alise do primeiro passo como

µj(j) =

= Pj,j +

(cid:88)

l∈T

(cid:88)

l(cid:54)=j

Pj,l(1 + hj(l))

Pj,l(1 + hj(l))

(cid:88)

=

Pj,l +

l∈T

(cid:88)

l(cid:54)=l

Pj,lhj(l)

µj(j) = 1 +

(cid:88)

l(cid:54)=j

Pj,lhj(l), j ∈ T

(1.15)

Por ﬁm, ´e prefer´ıvel calcular primeiro o tempo de alcance hi(i) = 0 sob as

condi¸c˜oes de contorno hi(i) = 0, e ent˜ao encontrar o tempo de retorno µi(i) para 1.15,

i, j ∈ T .

Na sequˆencia considere

pij = P(T r

j < ∞|X0 = i) = P(Xn = j para algum n ≥ 1|X0 = i)

e denote a probabilidade de retorno ao estado j em tempo ﬁnito come¸cando do estado i.

A probabilidade pii de retorno ao estado i com um tempo ﬁnito come¸cando pelo estado i

16

pode ser calculada por

pii = P(Xn = i para algum n ≥ 1|X0 = i)

=

∞
(cid:88)

n=1

P(Xn = i, Xn−1 (cid:54)= i, . . . , Xi (cid:54)= i|X0 = i)

=

∞
(cid:88)

n=1

f (n)
i,i

:= P(T r

onde, f (n)
i,j
distribui¸c˜ao de T r

Tem-se f (1)

j = n|X0 = i) = P(Xn = j, Xn−1 (cid:54)= j, . . . , X1 (cid:54)= j|X0 = i), i, j ∈ T ´e a
j dado que X0 = i, com f (0)
i,i = P(X1 = i|X0 = i) = Pi,i, i ∈ T e decompondo de acordo com o

i |X0 = i) = 0.

i,i = P(T r

tempo do primeiro retorno k ≥ 1, a probabilidade f (k)

i,i satisfaz a rela¸c˜ao

[P n]i,i = P(Xn = i|X0 = i)

=

n
(cid:88)

k=1

P(Xk = i, Xk−1 (cid:54)= i, . . . , X1 (cid:54)= 1|X0 = i)P(Xn = i|Xk = i)

=

n
(cid:88)

k=1

P(Xk = i, Xk−1 (cid:54)= i, . . . , X1 (cid:54)= 1|X0 = i)P(Xn−k = i|X0 = i)

=

n
(cid:88)

k=1

f (k)
i,i P n−k

i,i

Assim, as probabilidades de retorno pij ser˜ao usadas para calcular a m´edia do

n´umero de retornos a um dado estado.

Ent˜ao, a no¸c˜ao de n´umero m´edio de retornos ser´a necess´aria para classiﬁcar os

estados das cadeias de Markov. Seja Ri =

1{Xn=i} o n´umero de visitas ao estado i

pela cadeia (Xn)n∈N. Se Rj = 0 come¸cando por X0 = i a cadeia nunca visita o estado j e
isso acontece com probabilidade 1 − pij, ent˜ao P(Rj = 0|X0 = i) = 1 − pij.

n=1

Por outro lado, quando a cadeia (Xn)n∈N faz um n´umero Rj = m ≥ 1 de visitas ao

estado j come¸cando pelo estado i, ele faz a primeira visita ao estado j com probabilidade

pij e ent˜ao faz m − 1 retornos ao estado j, cada um com probabilidade pjj.

Depois destas m visitas ele nunca mais retorna ao estado j, e esse evento ocorre

com probabilidade 1 − pjj.

17

∞
(cid:88)

Logo, dado que {X0 = i} tem-se

P(Rj = m|X0 = i) =






pij × (pjj)m−1 × (1 − pjj), m ≥ 1,

(1.16)

1 − pij, m = 0

No caso i = j, Ri ´e simplesmente o n´umero de retornos ao estado i come¸cando

do estado i, ´e encontrada a distribui¸c˜ao geom´etrica

P(Ri = m|X0 = i) = (pii)m × (1 − pii), m ≥ 0

Considerando,

e

P(Ri < ∞|X0 = i) =

P(Ri = ∞|X0 = i) =











0, se pii = 1,

1, se pii < 1.

1, se pii = 1,

0, se pii < 1.

Ainda, caso pjj = 1 tem-se

P(Rj = ∞|X0 = i) = pij

E tamb´em, usando a identidade

∞
(cid:88)

krk−1 = (1 − r)−2 tem-se

E[Rj|X0 = i] =

k=1

∞
(cid:88)

m=0

mP(Rj = m|X0 = i)

= (1 − pjj)pij

∞
(cid:88)

m=1

m(pjj)m−1 =

pij
1 − pjj

(1.17)

(1.18)

(1.19)

ao qual ´e ﬁnita se pjj < 1.

Um estado j ∈ T est´a acess´ıvel par i ∈ T e escreve-se (i) −→ (j) se existir um

inteiro ﬁnito n ≥ 0 tal que

[P n]i,j = P(Xn = j|X0 = i) > 0.

18

Em outras palavras, ´e poss´ıvel ir de i para j com probabilidade n˜ao-nula em

um certo n´umero de passos aleat´orios. Al´em disso, desde que P 0 = Id, a deﬁni¸c˜ao de

acessibilidade dos estados i e j ´e assegurado para todo i ∈ T , exceto se Pii = 0.

No caso de i −→ j e j −→ i diz-se que i e j se comunicam entre si e resume-se

como i ←→ j.

A rela¸c˜ao bin´aria ”←→”satisfaz as seguintes propriedades:

(cid:136) Reﬂexiva - para todo i ∈ T tem-se i ←→ i;

(cid:136) Simetria - para todo i, j ∈ T tem-se que i ←→ j ´e equivalente a j ←→ i;

(cid:136) Transitiva - para todo i, j, k ∈ T tal que i ←→ j e j ←→ k, tem-se que i ←→ k.

Assim, ”←→”´e chamada rela¸c˜ao de equivalˆencia e isso induz uma parti¸c˜ao de T

em subconjuntos disjuntos A1, . . . , Am tal que T = A1 ∪ · · · ∪ Am, e

(cid:136) tem-se i ←→ k para todo i, k ∈ Aq; e

(cid:136) tem-se i (cid:61) k sempre que i ∈ Ap e k ∈ Aq com p (cid:54)= q.

Os conjuntos A1, . . . , Am s˜ao classes comunicantes da cadeia.

Deﬁni¸c˜ao 3. Uma cadeia de Markov cujo espa¸co de estados ´e formado de uma ´unica

classe comunicante ´e dito ser irredut´ıvel, do contr´ario a cadeia ´e dita redut´ıvel.

Todos os estados em T se comunicam quando (Xn)n∈N ´e irredut´ıvel. No caso, a

i-´esima coluna da matriz de transi¸c˜ao P desaparece, isto ´e, Pk,i = 0, i ∈ T , ent˜ao o estado

i n˜ao pode ser alcan¸cado por qualquer outro estado e i torna-se uma classe comunicante

dele mesmo. Isso tamb´em ´e verdade para estados absorventes. Contudo, tendo um retorno

com probabilidade estritamente inferior a um n˜ao ´e suﬁciente para tornar um dado estado

sozinho em uma classe comunicante.

Deﬁni¸c˜ao 4. Um estado i ∈ T ´e recorrente se, come¸cando pelo estado i a cadeia retornar´a

a esse estado dentro de um tempo ﬁnito, com probabilidade 1.

Em outras palavras, o estado i ∈ T ´e recorrente se

pi,i := P(T r

i |X0 = i) = P(Xn = i para algum n ≥ 1|X0 = i) = 1

(1.20)

19

A partir de 1.19 e 1.20 que o estado i ´e recorrente se, e somente se

E[Ri|X0 = i] = ∞

(1.21)

Al´em disso, por 1.18 e 1.20 o estado i ´e recorrente, se e somente se P(Ri =

+∞|X0 = i) = 1.

Teorema 1. Um estado i ∈ T ´e recorrente se, e somente se

∞
(cid:88)

[P n]i,i = +∞

n=1

isto ´e, a s´erie acima diverge.

O teorema 1 admite o seguinte corol´ario que mostra que se um estado j ∈ T que

se comunica com um estado recorrente i, ent˜ao j tamb´em ´e recorrente.

Corol´ario 1. Seja i ∈ T um estado recorrente, ent˜ao qualquer estado j ∈ T que se

comunica com i ´e recorrente.

Logo, uma classe comunicante A ⊂ T ´e recorrente se qualquer desses estados for

recorrente.

Um estado i ∈ T ´e dito transiente quando n˜ao ´e recorrente, isto ´e, P(Ri =
+∞|X0 = i) < 1, que ´e equivalente a P(Ri = +∞|X0 = i) = 0, por 1.18. Tamb´em
pode-se escrever que i ∈ T ´e transiente quando P(Ri < ∞|X0 = i) > 0, que ´e equivalente
a P(Ri < ∞|X0 = i) = 1 por 1.17, isto ´e, o n´umero de retornos ao estado i ∈ T ´e ﬁnito

com uma probabilidade n˜ao-nula que ´e necessariamente igual a um.

Em outras palavras, pelo Teorema 1.20, o estado i ∈ T ´e transiente se, e somente

se

ou

pi,i = P(T r

i = ∞|X0 = i) = P(Xn = i para algum n ≥ 1|X0 = i) < 1,

(1.22)

P(T r

i = ∞|X0 = i) > 0.

De novo, por 1.19 e 1.20 ou diretamente por 1.21, um estado i ´e transiente se, e

somente se

E[Ri|X0 = i] < ∞

20

Como uma consequˆencia do Teorema 1, um estado i ∈ T ´e transiente se, e somente

se

∞
(cid:88)

n=1

[P n]i,i < ∞,

isto ´e, a s´erie acima converge.

Al´em disso, como consequˆencia do Corol´ario 5, se um estado i ∈ T se comunica

com um estado transiente j ent˜ao i tamb´em ´e transiente, de outra forma o estado j seria

recorrente pelo mesmo corol´ario.

Teorema 2. Seja (Xn)n∈N uma cadeia de Markov com espa¸co de estados ﬁnito T. Ent˜ao

(Xn)n∈N possui pelo menos um estado recorrente.

O tempo esperado de retorno ao estado i ∈ T , tamb´em chamado tempo m´edio

de recorrˆencia de i, ´e dado por

µi(i) := E[T r

i |X0 = i]

=

∞
(cid:88)

n=1

nP(T r

i = n|X0 = i)

=

∞
(cid:88)

n=1

nf (n)
i,i .

Deﬁni¸c˜ao 5. Um estado recorrente i ∈ T ´e recorrente positivo se

e recorrente nulo se

µi(i) = E[T r

i |X0 = i] < ∞

µi(i) = E[T r

i |X0 = i] = +∞

Como deﬁnido anteriormente, quando o estado i ´e recorrente tem-se P(T r

i <

∞|X0 = i) = 1,

isto ´e, o tempo de retorno aleat´orio T r

i ´e quase certamente ﬁnito

come¸cando pelo estado i, mesmo assim esses n˜ao produzem informa¸c˜ao na ﬁnitude da
sua expectativa µi(i) = E[T r

i |X0 = i].

Teorema 3. Assuma que o espa¸co de estados T de uma cadeia de Markov (Xn)n∈N ´e

ﬁnito. Ent˜ao todo estado recorrente em T s˜ao recorrentes positivo.

Como consequˆencia tem-se o seguinte Corol´ario.

21

Corol´ario 2. Seja (Xn)n∈N uma cadeia de Markov irredut´ıvel com espa¸co de estados T .

Ent˜ao todo estado de (Xn)n∈N ´e recorrente positivo.

Dado um estado i ∈ T , considere o conjunto de inteiros

{n ≥ 1 : [P n]i,i > 0}

O per´ıodo do estado i ∈ T ´e o m´aximo divisor comum de

{n ≥ 1 : [P n]i,i > 0}

Um estado com per´ıodo 1 ´e aperi´odico se Pi,i > 0. Um estado recorrente i ∈ T ´e

erg´otico se ´e positivo recorrente e aperi´odico.

Se [P n]i,i = 0 para todo n ≥ 1 ent˜ao o conjunto {n ≥ 1 : [P n]i,i > 0} ´e vazio e

por conven¸c˜ao o per´ıodo do estado i ´e deﬁnido como 0. Neste caso, o estado i tamb´em ´e

transiente.

Vale notar que {n ≥ 1 : [P n]i,i > 0} cont´em dois n´umeros distintos que s˜ao

relativamente primos para cada um, ou seja, o m´aximo divisor comum ´e 1, ent˜ao o estado

i ´e aperi´odico. Uma cadeia de Markov ´e considerada aperi´odica quando todos os estados

s˜ao aperi´odicos. Em particular, qualquer estado absorvente ´e aperi´odico e recorrente.

Teorema 4. Considere uma cadeia de Markov (Xn)n∈N satisfazendo as seguintes trˆes

condi¸c˜oes:

(cid:136) recorrente;

(cid:136) aperi´odica; e

(cid:136) irredut´ıvel.

Ent˜ao tem-se

onde

lim
n→∞

P(Xn)n∈N(Xn = i|X0 = j) =

1
µi(i)

, i, j ∈ T

µi(i) = E[T r

i |X0 = i] ≥ 1

´e a m´edia do tempo de retorno para o estado i ∈ T .

22

Esse resultado ´e consistente no caso de uma cadeia com dois estados.

Uma distribui¸c˜ao de probabilidade em T , isto ´e, uma fam´ılia Π = (Πi)i∈T em

[0, 1] tal que

(cid:88)

i∈T

Πi = 1

´e dito ser estacion´ario se, come¸cando em X0 o tempo 0 com a distribui¸c˜ao (Πi)i∈T , acontece

que a distribui¸c˜ao de X1 ainda ´e (Xi)i∈T no tempo 1.

Em outras palavras, (Πi)i∈T ´e estacion´ario para a cadeia de Markov com matriz

de transi¸c˜ao P, se

no tempo 0, implica

P(X0 = i) := Πi, i ∈ T,

P(X1 = i) = P(X0 = i) = Πi, i ∈ T

no tempo 1. Isso tamb´em na medida que

Πj = P(X1 = j) =

(cid:88)

i∈T

P(X1 = j|X0 = i)P(X0 = i)

(cid:88)

=

i∈T

ΠiPi,j, j ∈ T,

isto ´e, a distribui¸c˜ao Π ´e estacion´aria se, e somente se, ela ´e invariante pela matriz P , que

signiﬁca

Π = ΠP.

(1.23)

Em contraste com 1.10, a multiplica¸c˜ao por P em 1.23 est´a a direita e n˜ao a

esquerda. Considerando que distribui¸c˜oes estacion´arias e limitadas s˜ao conceitos bastante

diferentes, uma cadeia que se inicia com distribui¸c˜ao estacion´aria permanecer´a com a

mesma distribui¸c˜ao qualquer passo de tempo subsequente. Por outro lado, a ﬁm de

alcan¸car a distribui¸c˜ao limitada a cadeia pode come¸car de qualquer dado inicial para

qualquer estado ﬁxado e se converter´a a distribui¸c˜ao limitada se esta existir. Mesmo

assim, a distribui¸c˜ao limitada e estacion´aria podem coincidir em algumas situa¸c˜oes.

Mais geral, assumindo que Xn esta na distribui¸c˜ao estacion´aria Π no tempo n,

23

tem-se

P(Xn+1 = j) =

(cid:88)

i∈T

P(Xn+1 = j|Xn = i)P(Xn = i)

(cid:88)

=

i∈T

Pi,jP(Xn = i) =

(cid:88)

i∈T

Pi,jΠi

= [ΠP ]j = Πj, j ∈ T,

desde que a matriz de transi¸c˜ao de (Xn)n∈N ´e tempo homogˆeneo, ent˜ao

P(Xn = j) = Πj, j ∈ T ⇒ P(Xn+1 = j) = Πj, j ∈ T

e por indu¸c˜ao em n ≥ 0

P(Xn = j) = Πj, j ∈ T, n ≥ 1,

isto ´e, a cadeia (Xn)n∈N permanece na mesma distribui¸c˜ao Π em todos os tempos n ≥ 1,

se tiver come¸cado pela distribui¸c˜ao estacion´aria Π no tempo n = 0.

Propriedade 1. Assuma que T = {0, 1, . . . , N } ´e ﬁnito e que a distribui¸c˜ao

Πj := lim
n→∞

P(Xn = j|X0 = i), i, j ∈ T,

existe e ´e independente de i ∈ T , isto ´e, tem-se

P n =

lim
n→∞








Π0
...
Π0








. . . ΠN
...
. . .
. . . ΠN

Ent˜ao, Π = (Πj)j∈{0,1,...,N } ´e uma distribui¸c˜ao estacion´aria e

Π = ΠP,

(1.24)

isto ´e, Π ´e invariante para P .

Em particular, tem-se o seguinte resultado.

Teorema 5. Assuma que a cadeia de Markov (Xn)n∈N satisfaz as trˆes condi¸c˜oes a seguir:

(cid:136) recorrˆencia positiva;

24

(cid:136) aperi´odica; e

(cid:136) irredut´ıvel.

Ent˜ao a cadeia (Xn)n∈N admite uma distribui¸c˜ao

Πi := lim
n→∞

P(Xn = i|X0 = j) = lim
n→∞

[P n]j,i =

1
µi(i)

, i, j ∈ T,

ao qual tamb´em forma uma distribui¸c˜ao estacion´aria (Πi)i∈T = (

determinada pela equa¸c˜ao Π = ΠP .

1
µi(i)

)i∈T , unicamente

A partir do Teorema 3 temos o seguinte corol´ario do Teorema 5

Corol´ario 3. Considere uma cadeia de Markov irredut´ıvel aperi´odica com espa¸co de es-

tados ﬁnito. Ent˜ao as probabilidades

Πi := lim
n→∞

P(Xn = i|X0 = j) =

1
µi(i)

, i, j ∈ T,

forma uma distribui¸c˜ao estacion´aria a qual ´e unicamente determinada pela equa¸c˜ao

Π = ΠP

O seguinte teorema d´a condi¸c˜oes suﬁcientes para a existˆencia de uma distribui¸c˜ao

estacion´aria, sem requerer aperiodicidade ou ﬁnitude do espa¸co de estados. Como notado,

a distribui¸c˜ao limitante n˜ao pode n˜ao existir neste caso.

Teorema 6. Considere a cadeia de Markov (Xn)n∈|mathbbN satisfazendo as seguintes

condi¸c˜oes:

(cid:136) recorrente positiva; e

(cid:136) irredut´ıvel.

Ent˜ao a probabilidade

Πi =

1
µi(i)

, i ∈ T,

forma uma distribui¸c˜ao estacion´aria que ´e unicamente determinada pela equa¸c˜ao Π = ΠP.

Como uma consequˆencia do Corol´ario 2 tem-se o teorema acima, que n˜ao requere

aperiodicidade para a distribui¸c˜ao estacion´aria existir.

25

Corol´ario 4. Seja (Xn)n∈N um cadeia de Markov irredut´ıvel com espa¸co de estados ﬁnito

T . Ent˜ao as probabilidades

Πi =

1
µi(i)

, i ∈ T,

formam uma distribui¸c˜ao estacion´aria que ´e unicamente determinada pela equa¸c˜ao

Π = ΠP.

Note que a distribui¸c˜ao estacion´aria de uma cadeia de Markov pode n˜ao existir

para todos, conforme a observa¸c˜ao anterior.

Sob as suposi¸c˜oes do Teorema 5, se a distribui¸c˜ao estacion´aria e limitante existi-

rem ent˜ao elas s˜ao iguais e neste caso n´os s´o precisamos calcular uma delas. O principal

problema em algumas situa¸c˜oes ´e que pode existir apenas a distribui¸c˜ao estacion´aria. Da´ı,

de acordo com o Corol´ario 4, a distribui¸c˜ao limitante pode n˜ao existir se a cadeia n˜ao ´e

aperi´odica.

Assim, pelo Corol´ario 3, a distribui¸c˜ao limitante e a distribui¸c˜ao estacion´aria

existem - e coincidem - quando a cadeia ´e irredut´ıvel aperi´odica com espa¸co de estados

ﬁnito. Quando a cadeia ´e irredut´ıvel ´e normalmente mais f´acil s´o calcular a distribui¸c˜ao

estacion´aria e dar a distribui¸c˜ao limitante. No caso a cadeia ´e n˜ao irredut´ıvel precisa-se

tentar dividir, ou separ´a-la, em subcadeias e considerar seus subproblemas separadamente.

Em resumo, normalmente tenta-se calcular a distribui¸c˜ao estacion´aria sempre que

poss´ıvel, e a distribui¸c˜ao limitante quando existe. De outra forma n´os podemos tentar

calcular a distribui¸c˜ao limitante exponenciando a matriz de transi¸c˜ao e fazendo o limite,

mas isto ´e normalmente muito mais complicado e feito somente em casos excepcionais.

Resumindo, nota-se pelo Teorema 4 que

(cid:136) uma cadeia irredut´ıvel, recorrente e aperi´odica implica na existˆencia de uma distri-

bui¸c˜ao limitante.

Pelo Teorema 5

(cid:136) uma cadeia irredut´ıvel, recorrente positiva e aperi´odica implica na existˆencia de uma

distribui¸c˜ao limitante a qual ´e tamb´em estacion´aria.

E pelo Teorema 6

26

(cid:136) uma cadeia irredut´ıvel e recorrente positiva implica na existˆencia de uma distribui¸c˜ao

estacion´aria.

Al´em disso, a distribui¸c˜ao limitante ou estacion´aria Π = (Πi)i∈T satisfaz

Πi =

1
µi(i)

, i ∈ T,

em todos os casos destacados.

A tabela 1.1 resume as deﬁni¸c˜oes introduzidas.

Tabela 1.1: Resumo das propriedades dos estados da Cadeia de Markov

Propriedade
Absorvente - estado
Recorrente - estado
Transiente - estado
Recorrente positivo - estado
Recorrente nulo - estado
Aperi´odico - estado ou cadeia
Erg´odico - estado ou cadeia
Irredut´ıvel - cadeia
Regular - cadeira

Deﬁni¸c˜ao
Pi,i = 1

P(T r
P(T r

i < ∞|X0 = i) = 1
i < ∞|X0 = i) < 1

Recorrente e E[T r
Recorrente e E[T r

i |X0 = i] < ∞
i |X0 = i] = +∞

Per´ıodo(T ) = 1
Recorrente positivo e aperi´odico
Todos os estados s˜ao comunicantes
Todos os coeﬁcientes de P n s˜ao > 0 para algum n ≥ 1.

As restri¸c˜oes na matriz de transi¸c˜ao P resultam em v´arias propriedades das ca-

deias de Markov.

Se P ´e uma matriz n × n, dizemos que

(cid:136) P ≥ 0 se pij ≥ 0 para todo 1 ≤ i, j ≤ n;

(cid:136) P > 0 se P ≥ 0 e pelo menos um dos pij ´e positivo;

(cid:136) P (cid:29) 0 se pij > 0 para todo 1 ≥ i, j ≥ n.

Quando P ≥ 0, podemos deﬁnir um conjunto ∆ ⊂ R dos n´umeros λ que tˆem a

seguinte propriedade: existe um vetor x = (x1, x2, . . . , xn) tal que

(cid:88)

i≥j≥n

xj = 1, x > 0 e P x ≥ λx

Propriedade 2. Seja λ0 = sup∆. Ent˜ao, λ0 < ∞. Al´em disso, se P (cid:29) 0, ent˜ao, λ0 > 0.

Teorema 7 (Frobenius). Seja P > 0 e λ0 como deﬁnido acima

27

(cid:136) λ0 ´e um autovalor de P e ´e poss´ıvel escolher um autovetor associado x0 tal que

x0 > 0;

(cid:136) se λ ´e outro autovalor de P , ent˜ao, |λ| ≥ λ0.

Corol´ario 5. Se P ´e uma matriz de transi¸c˜ao de uma cadeia de Markov, λ0 = 1.

Propriedade 3. Se λ ´e um autovalor de uma matriz de transi¸c˜ao n × n P , |λ| ≤ 1.

Al´em disso, existe um autovetor associado ao autovalor λ = 1 com todas as entradas n˜ao

negativas.

Para a pr´oxima propriedade ´e preciso levantar as seguintes hip´oteses:

(a) Primeiramente, sup˜oe-se que exista exatamente um autovalor tal que |λ| = 1, e

portanto, este autovalor ´e 1.

(b) A seguir, sup˜oe-se que esse autovalor n˜ao ´e degenerado, o que equivale a dizer que

seu autoespa¸co associado tem dimens˜ao 1.

(c) Finalmente, toma-se como dado que a matriz de transi¸c˜ao P , representando a rede,

´e diagonaliz´avel, signiﬁcando que seus autovetores formam uma base.

Propriedade 4. 1 Se a matriz de transi¸c˜ao P de uma cadeia de Markov satisfaz as trˆes

hip´oteses acima, ent˜ao existe um ´unico vetor Π tal que as entradas Πi = P (Xn = i),

i ∈ T satisfazem

Πi ≥ 0, Πi =

(cid:88)

j∈T

pijΠj e

(cid:88)

i∈T

Πi = 1

Chamaremos o vetor Π o regime estacion´ario da cadeia de Markov.

2 Independentemente do ponto inicial p0

i = P (X0 = i) (onde

(cid:88)

p0
i = 1), a distribui¸c˜ao

das propriedades P (Xn = i) convergir´a ao regime estacion´ario Π, quando n → ∞.

i

Esse ponto ser´a de extrema importˆancia para a aplica¸c˜ao pretendida nos pr´oximos

cap´ıtulos.

28

Cap´ıtulo 2

Teoria Fuzzy

Questionamentos a respeito de incertezas sempre preocuparam pensadores ao

longo do tempo e atualmente a incerteza proveniente da aleatoriedade de eventos est´a

bem desenvolvida e ocupa lugar de destaque nos estudos matem´aticos, Barros e Bassanezi

(2006). A F´ısica Quˆantica tem se utilizado das teorias estoc´asticas e uma das mais

difundidas e conhecidas est´a denominada de ”Princ´ıpio da Incerteza”, devida ao f´ısico W.

Heisenberg (1927), que relaciona a posi¸c˜ao e a velocidade de uma part´ıcula.

E para descrever certos fenˆomenos tem-se utilizado graus que representam qua-
lidades ou verdades parciais. ´E precisamente neste tipo de incerteza que a L´ogica Fuzzy

tem dado suas principais contribui¸c˜oes. A palavra ”fuzzy”, de origem inglesa, signiﬁca

incerto, vago, impreciso, subjetivo, nebuloso ou difuso.

A teoria dos Conjuntos Fuzzy foi introduzida em 1965 pelo matem´atico Lofti

Asker Zadeh com a principal inten¸c˜ao de dar um tratamento matem´atico a certos termos

como aproximadamente, ou ”em torno de”, dentre outros. E esse seria um primeiro

passo para tornar poss´ıvel a produ¸c˜ao de c´alculos com informa¸c˜oes imprecisas. Al´em de

contrapor modelos determin´ısticos por modelos mais ﬂex´ıveis, que contemplem certo grau

de incerteza.

2.1 Conjuntos e Eventos Fuzzy

Para obter a formaliza¸c˜ao matem´atica de um conjunto fuzzy, Zadeh baseou-se no

fato de que qualquer conjunto cl´assico pode ser caracterizado por sua fun¸c˜ao caracter´ıstica.

29

Deﬁni¸c˜ao 6 (Zadeh). Seja U um conjunto e A um subconjunto de U. A fun¸c˜ao carac-

ter´ıstica de A ´e dada por

χA(x) =






1

0

se x ∈ A

se x /∈ A

Desta forma, χA ´e uma fun¸c˜ao cujo dom´ınio ´e U e a imagem est´a contida no conjunto

0, 1, com χA(x) = 1 indicando que o elemento x est´a em A, enquanto χA(x) = 0 indica

que x n˜ao ´e elemento de A. Assim, a fun¸c˜ao caracter´ıstica descreve completamente o

conjunto A j´a que indica quais elementos do conjunto universo U s˜ao elementos tamb´em

de A.

Deﬁni¸c˜ao 7. Seja U um conjunto cl´assico, um subconjunto fuzzy F de U ´e caracterizado

por uma fun¸c˜ao

ϕF → [0, 1]

pr´e-ﬁxada, chamada fun¸c˜ao de pertinˆencia do subconjunto fuzzy F . O ´ındice F na fun¸c˜ao

de pertinˆencia ´e usado em analogia a fun¸c˜ao caracter´ıstica de um subconjunto cl´assico.

Logo, a no¸c˜ao de subconjunto fuzzy ´e baseada na extens˜ao da fun¸c˜ao carac-

ter´ıstica, ou indicadora, de um subconjunto cl´assico. Para cada fun¸c˜ao ϕF : Ω → [0, 1],

considere a fam´ılia de α−n´ıveis

[F ]α = {ω ∈ Ω/ϕF (ω) ≥ α} para 0 ≤ α ≤ 1.

Do ponto de vista da modelagem, a teoria fuzzy veio para descrever a fronteira,

enquanto que a probabilidade apresenta uma medida de sua ocorrˆencia. Ou seja, o interes-

sante n˜ao ´e optar por uma teoria ou outra, mas sim combinar as duas com a sobreposi¸c˜ao

de incertezas.

A no¸c˜ao de eventos fuzzy, introduzida por Zadeh, ilustra o potencial da com-

bina¸c˜ao das duas teorias, a fuzzy, tratando da identiﬁca¸c˜ao do evento e a probabil´ıstica,

lidando com a medida do mesmo.

Deﬁni¸c˜ao 8. Seja (Ω, P, A) um espa¸co de probabilidades. Um evento fuzzy em Ω ´e

simplesmente um subconjunto fuzzy de Ω cujos α-n´ıveis est˜ao na σ-´algebra A.

Suponha Ω = {ω1, ω2, . . . , ωn}, e que todos os pontos tenham a mesma probabi-
1
. ´E sabido que se A for um evento com m elementos, ent˜ao P (A) =
n

deﬁne

m
n

lidade

uma probabilidade em Ω.

30

Dado o evento A, sua fun¸c˜ao indicadora χA : Ω → {0, 1} ´e conhecida e o n´umero

de casos favor´aveis ´e m =

(cid:88)

i

χA(ωi). Portanto

P (A) =

(cid:80)n

i=1 χA(ωi)
n

Por extens˜ao, se A for fuzzy, e conhecendo-se ϕA : Ω → [0, 1], o ”n´umero de casos

favor´aveis”´e m =

ϕA(ωi), de modo que

n
(cid:88)

i=1

P (A) =

(cid:80)n

i=1 ϕA(ωi)
n

Nesse caso, m pode n˜ao ser inteiro.

Deﬁni¸c˜ao 9. Seja (Ω, P, A) um espa¸co de probabilidades e A um evento fuzzy. Ent˜ao,

sua fun¸c˜ao de pertinˆencia ϕA : Ω → [0, 1] ´e uma vari´avel e, por deﬁni¸c˜ao, P (A) = E(ϕA).

Suponha que X seja uma vari´avel aleat´oria e A um evento fuzzy real com fun¸c˜ao

de pertinˆencia ϕA : R → [0, 1]. Ent˜ao, a probabilidade de A ´e dada por

P (A) = E(ϕA(X)) =

n
(cid:88)

i=1

ϕA(xi)P (X = xi)

se X for discreta, e

P (A) = E(ϕA) = E(ϕA(X)) =

(cid:90)

R

ϕA(x)f (x)dx =

(cid:90)

suppA

ϕAf (x)dx

onde f ´e a fun¸c˜ao densidade de probabilidades de X.

O conceito de independˆencia entre eventos fuzzy passa necessariamente pelo de

probabilidade condicional.

Para o evento cl´assico, a ocorrˆencia simultˆanea ´e dada pela interse¸c˜ao A∩B. Para

estender ao caso fuzzy, deve-se passar pela fun¸c˜ao indicadora χA∩B. Para o caso cl´assico,

valem χA∩B(x) = χA(x).χB(x) e χA∩B(x) = χA(x) ∧ χB(x), de modo que, poderia se

adotar tanto ”.”como ”∧”para representar a conjun¸c˜ao.

Para o caso cl´assico, se A e B forem eventos de Ω com P (B) > 0, ent˜ao

P (A|B) =

P (AB)
P (B)

=

E(χA.χB)
χB

31

A ´e dito independente de B se a ocorrˆencia de B n˜ao interferir na probabilidade

de A, isto ´e, se P (A|B) = P (A). A nota¸c˜ao AB no lugar de A ∩ B n˜ao ´e por acaso. Ela

´e proveniente do fato de optar-se por χAχB para representar χA∩B.

Portanto, A independente de B se, e somente, se

ou

E(χA.χB)
E(χB)

= E(χA.χB) = E(χA)E(χB)

P (AB) = P (A)P (B)

Considere A e B dois eventos fuzzy de R, com P (B) > 0, se, e somente, se

E(ϕB) > 0, a probabilidade condicional de A dado B ´e deﬁnida por

P (A|B) =

P (AB)
P (B)

=

E(ϕA.ϕB)
E(ϕB)

Assim, como no caso cl´assico, A ´e dito independente de B se a ocorrˆencia de B

s˜ao interferir na probabilidade de A, isto ´e, se P (A|B) = P (A). Assim, A independe de

B se, e somente, se

E(ϕA.ϕB)
E(ϕB)

= E(ϕA) ⇔ E(ϕA.ϕB) = E(ϕA)E(ϕB)

Portanto, desde que as probabilidades n˜ao se anulem, A e B s˜ao independentes

se, e somente se, as vari´aveis ϕA e ϕB s˜ao n˜ao correlacionadas.

Considere uma vari´avel aleat´oria X e a proposi¸c˜ao P (XserA), onde A representa

um termo lingu´ıstico, por exemplo, alto, baixo, muito alto, muito baixo, modelado por

um evento fuzzy real A. Uma vari´avel aleat´oria fuzzy ´e simplesmente uma fun¸c˜ao X :

Ω → F(R), em que Ω ´e espa¸co amostral.

E esse conceito estende o de vari´avel aleat´oria uma vez que R ⊂ F(R).

Outras deﬁni¸c˜oes interessantes para o tema s˜ao as descritas abaixo, apontadas

por Uzun e ErsinKiral (2017).

Deﬁni¸c˜ao 10. Um n´umero fuzzy ´e um conjunto fuzzy na reta real que satisfaz as condi¸c˜oes

de normalidade e convexidade.

32

Deﬁni¸c˜ao 11. Um n´umero fuzzy que ´e representado por trˆes pontos da forma F =

(a1, a2, a3), (a1 < a2 < a3) cuja fun¸c˜ao ´e dada por

ϕF (x) =






x − a1
a2 − a1
a3 − x
a2 − a3

,

,

se a1 ≤ x ≤ a2

se a2 ≤ x ≤ a3

0,

qualquer outro caso

´e chamado de n´umero fuzzy triangular.

2.2 Cadeias de Markov com estados Fuzzy

Considere (Ω, Λ, P ) um espa¸co de probabilidades, onde Ω ´e o espa¸co amostral, Λ

o σ-´algebra em Ω e P uma medida de probabilidade. Sendo F em Ω ´e um evento fuzzy e

µF (ω), ω ∈ Ω, µF (ω) → [0, 1] uma fun¸c˜ao caracter´ıstica do evento fuzzy F .

Ent˜ao, a probabilidade de um evento fuzzy F ´e deﬁnida usando a integral de

Lebesgue-Stieljes usadas por Zadeh (1965) como o valor esperado da fun¸c˜ao caracter´ıstica

do evento fuzzy com rela¸c˜ao a distribui¸c˜ao de probabilidade P:

e em um conjunto ﬁnito ´e

P (F ) =

(cid:90)

Ω

µF (ω)dP = E(µF )

P (F ) =

(cid:88)

Ω

µF (ω)pω

E a probabilidade condicional do evento fuzzy F dado o evento fuzzy G ´e:

P (F |G) =

P (F (cid:84) G)
P (G)

, P (G) > 0

Al´em disso, o produto de dois eventos fuzzy F e G ´e dado por:

F.G ↔ µF G = µF µG

(2.1)

(2.2)

(2.3)

(2.4)

Seja, X = {x1, x2, . . . , xn} um conjunto dado, uma parti¸c˜ao fuzzy de X ´e uma

fam´ılia de subconjuntos fuzzy de X denotada por F = {F1, F2, . . . , FN }, ∀i = {1, 2, . . . , N },

Fi (cid:54)= ∅, Fi (cid:54)= X, com as fun¸c˜oes caracter´ısticas correspondentes a µF1, . . . , µFr, que satis-

33

fazem

N
(cid:88)

i=1

µFi(xr) = 1, ∀xr ∈ X, r = {1, . . . , N }

O conceito de parti¸c˜ao fuzzy ´e utilizado principalmente para deﬁnir os estados

fuzzy para decis˜oes em um processo markoviano (Pardo e de la Fuente (2010)).

Considere os estados de um sistema e deﬁna uma parti¸c˜ao fuzzy, de modo que

cada subconjunto fuzzy Fi, i ∈ {1, 2, . . . , n} represente um estado ou evento fuzzy na

cadeia de Markov inicial.

Deﬁni¸c˜ao 12. A probabilidade do estado inicial fuzzy P(Fi) = P(X0 = Fi) ´e deﬁnida

usando a probabilidade do evento fuzzy por meio da equa¸c˜ao

P(Fi) = P{X0 = Fi} =

N
(cid:88)

s=0

P{X0 = s}µFi(s) =

N
(cid:88)

s=0

psµFi(s)

A partir da´ı ´e poss´ıvel calcular a probabilidade condicional para chegar a matriz

de transi¸c˜ao.

Propriedade 5. A probabilidade condicional do estado fuzzy Fj dado o estado inicial m,

com j ∈ {1, 2, . . . , n} e m ∈ {0, 1, . . . , N }, pode ser calculada por

P(Fj|m) = P{X1 = Fj|X0 = m} =

N
(cid:88)

s=0

pmsµFj (s)

e representa a probabilidade de transi¸c˜ao para um estado fuzzy em um passo.

Deﬁni¸c˜ao 13. A cadeia de Markov do estado fuzzy ﬁnal ´e deﬁnida pela matriz











P =

P (F1|0) P (F2|0)

. . . P (Fn|0)

P (F1|1) P (F2|1)

...

...

. . . P (Fn|1)
. . .

...

P (F1|N ) P (F2|N )

. . . P (Fn|N )











Esta matriz resulta na probabilidade de transi¸c˜ao do estado inicial m, m ∈

{0, 1, . . . , N }, para o estado ﬁnal Fj, j ∈ {1, 2, . . . , n}.

Propriedade 6. A probabilidade condicional do evento fuzzy Fj dado o evento fuzzy Fi,

com i, j ∈ {1, . . . , n} ´e uma fun¸c˜ao resultante de uma combina¸c˜ao linear de probabilidades

34

P(Fj|m) da forma

P(Fj|Fi) = P{X1 = Fj|X0 = Fi} =

N
(cid:88)

m=0

P(Fj|m)

pmµFi(m)
P(Fi)

e representa a probabilidade de transi¸c˜ao do estado fuzzy para outro estado fuzzy em um

passo.

Deﬁni¸c˜ao 14. A cadeia de Markov com estados inicial e ﬁnal fuzzy ´e deﬁnida pela matriz











(cid:101)P =

P (F1|F1) P (F2|F1)

. . . P (Fn|F1)

P (F1|F2) P (F2|F2)

...

...

. . . P (Fn|F2)
. . .

...

P (F1|Fn) P (F2|Fn)

. . . P (Fn|Fn)











Esta matriz resulta na probabilidade de transi¸c˜ao de um estado inicial fuzzy Fi

para um estado ﬁnal fuzzy Fj, com i, j ∈ {1, 2, . . . , n}.

As matrizes P e (cid:101)P s˜ao estoc´asticas, dado que a soma de cada uma de suas linhas

´e 1:

1. A m-´esima linha da matriz P s˜ao os termos P(F1|m), P(F2|m), . . . , P(Fn|m), ent˜ao

n
(cid:88)

j=1

P(Fj|m) =

n
(cid:88)

N
(cid:88)

j=1

s=0

pmsµFj (s) =

N
(cid:88)

s=0

n
(cid:88)

pms(

j=1

µFj ) = 1.

2. A i-´esima linha da matriz (cid:101)P s˜ao os termos P(F1|Fi), P(F2|Fi), . . . , P(Fn|Fi), ent˜ao

n
(cid:88)

j=1

P(Fj|Fi) =

n
(cid:88)

N
(cid:88)

j=1

m=0

P(Fj|m)

pmµFi(m)
P(Fi)

=

1
P(Fi)

(

N
(cid:88)

m=0

n
(cid:88)

pmµFi(m)(

j=1

P(Fj|m))) =

N
(cid:88)

m=0

pmµFi(m)
P(Fi)

= 1

Finalmente, para realizar os c´alculos deﬁne-se as matrizes Q e S.

35











Q =

µF1(0)

µF2(0)

µF1(1)
...

µF2(1)
...

. . .

. . .
. . .

µFn(0)

µFn(1)
...

µF1(N ) µF2(N )

. . . µFn(N )











S =














p0µF1(0)
P(F1)
p0µF2(0)
P(F2)
...
p0µFn(0)
P(Fn)

p1µF1(1)
P(F1)
p1µF2(1)
P(F2)
...
p1µFn(1)
P(Fn)

. . .

. . .
. . .

. . .

pN µF1(N )
P(F1)
pN µF2(N )
P(F2)
...
pN µFn(N )
P(Fn)














A matriz Q cont´em os valores da fun¸c˜ao caracter´ıstica da parti¸c˜ao fuzzy que determina

os estados fuzzy do sistema {F1, F2, . . . , Fn}.

Com as matrizes Q e S, deriva-se:

P = P Q

(cid:101)P = SP = SP Q

36

Cap´ıtulo 3

O Modelo

Ser´a apresentado a seguir dois modelos para s´eries temporais baseadas em va-

ria¸c˜ao de pre¸cos de commodities. Foram escolhidos os produtos Soja e Frango, devido a

quantidade de observa¸c˜oes dispon´ıveis na p´agina do CEPEA (2019), aos quais pretende-

se criar modelos determin´ısticos e fuzzy a ﬁm de encontrar seus estados estacion´arios

conjunto ao seu tempo m´edio de retorno.

De modo geral, h´a trˆes tipos de dados dispon´ıveis para an´alise; a primeira ´e

quando os dados s˜ao observados em diferentes instantes do tempo, pode ser diariamente,

semanalmente, mensalmente, trimestralmente e assim por diante, esse tipo ´e chamado de

s´erie temporal; tamb´em pode-se analisar o corte transversal que ocorre quando os dados

observados foram coletados no mesmo ponto do tempo, s˜ao exemplos as pesquisas de

opini˜ao e dados como os de censo e, por ´ultimo, tem-se os dados em painel, neste caso

uma unidade em corte transversal ´e pesquisada ao longo do tempo, por exemplo, o PIB

de cada pa´ıs sul-americano para o per´ıodo dos ´ultimos vinte anos (Wooldridge (2006)).

Como dito anteriormente, uma s´erie temporal pode ser deﬁnida como um conjunto

de observa¸c˜oes ordenadas em um per´ıodo de tempo. Os modelos mais utilizados para

descrever s´eries temporais s˜ao os processos estoc´asticos, ou seja, podem ser modelados

atrav´es de leis probabil´ısticas. Segundo Ehlers (2007), uma s´erie temporal ´e estacion´aria

quando se desenvolve aleatoriamente ao redor de uma m´edia constante, reﬂetindo alguma

forma de equil´ıbrio est´avel.

A maioria dos m´etodos de previs˜ao analisam valores passados para prever futu-

ros, que at´e o in´ıcio do s´eculo passado eram realizadas com a extrapola¸c˜ao simples de

um valor global, ajustado em fun¸c˜ao do tempo. Uma importante contribui¸c˜ao para o

37

desenvolvimento de ferramentas e m´etodos para an´alise de s´eries temporais deve-se aos

trabalhos de George Udny Yule (Esc´ocia, 1871 - Cambridge, 1951), em que o autor refere

que uma s´erie temporal deveria ser vista simplesmente como a realiza¸c˜ao de um pro-

cesso estoc´astico, assim, ele criou o modelo auto-regressivo (AR), em que o valor previsto

depende dos valores passados.

Nos anos seguintes, peritos em estat´ıstica realizaram seus trabalhos e estudos

com base no comportamento das s´eries e o quanto ele dependia de modelos lineares e do

ru´ıdo. No entanto, modelos lineares s˜ao pouco eﬁcientes para analisar s´eries temporais,

pois a maioria das s´eries reais apresentam tendˆencias n˜ao lineares.

E com o aparecimento dos computadores se iniciou uma evolu¸c˜ao acentuada

nos m´etodos de previs˜ao, principalmente naqueles baseados em simula¸c˜ao, j´a que a pro-

grama¸c˜ao ajudou a tornar mais r´apido qualquer processo de itera¸c˜ao. O prop´osito inicial

da an´alise de s´eries temporais ´e tirar inferˆencias sobre as propriedades ou caracter´ısticas

b´asicas do mecanismo gerador do processo estoc´astico das observa¸c˜oes da s´erie, Granger

(1980).

Ao analisar uma s´erie temporal, se espera que exista nela uma causa relacionada

com o tempo, alguma inﬂuˆencia nos dados que possam continuar inﬂuenciando futura-

mente. Para muitos estudiosos, apenas com a abstra¸c˜ao das regularidades presentes nos

fenˆomenos observados nas s´eries temporais que est´a a possibilidade de construir um mo-

delo matem´atico como representa¸c˜ao simpliﬁcada da realidade.

De acordo com Morettin e Toloi (2006), os principais objetivos de se analisar uma

s´erie temporal s˜ao os itens a seguir:

(cid:136) descrever propriedades da s´erie temporal;

(cid:136) explica¸c˜ao e modelagem de determinada ocorrˆencia, que posteriormente pode ser

usada para explicar outra;

(cid:136) predizer valores futuros com base em valores passados;

(cid:136) possibilidade de controle em processos ou tomadas de decis˜ao, ou seja, medir a

qualidade de um processo.

Em sua maioria, as s´eries temporais s˜ao estoc´asticas e o futuro ´e apenas par-

cialmente inﬂuenciado por valores passados. Para Morettin e Toloi (2006), uma s´erie

38

temporal estoc´astica ´e estacion´aria se a sua m´edia, variˆancia e autovariˆancia permane-

cem as mesmas, mesmo em diferentes fases. Logo, essas caracter´ıstica se veriﬁcariam em

qualquer per´ıodo, ou seja, n˜ao variam com o tempo. J´a uma s´erie temporal ´e dita n˜ao esta-

cion´aria quando a sua m´edia e/ou variˆancia varia com o tempo, nestas s´eries s´o ´e poss´ıvel

determinar uma parte dos dados, pois geram piores previs˜oes que s´eries estacion´arias.

Uma s´erie pode ser estacion´aria por per´ıodos curtos ou longos de tempo, o que

pode indicar alternˆancias de n´ıveis ou inclina¸c˜oes.

Isso explica porque em muitos ca-

sos utilizar base de dados muito grandes n˜ao signiﬁca resultados melhores, em algumas

situa¸c˜oes oscila¸c˜oes no regime estacion´ario dos dados pode provocar uma distor¸c˜ao no

resultado ﬁnal da an´alise.

S´eries temporais que n˜ao apresentam comportamento explosivo s˜ao chamadas de

homogˆeneas, e de acordo com Ehlers (2007), esse tipo de s´erie pode ser estacion´aria,

ﬂutuando ao redor de um n´ıvel, por certo per´ıodo de tempo, depois mudar de n´ıvel e

permanecer ao redor de um novo n´ıvel e assim por diante.

A maioria dos procedimentos de an´alise estat´ıstica em s´eries temporais sup˜oe

que estas sejam estacion´arias, portanto, se os dados originais n˜ao formam uma s´erie

estacion´aria ser´a necess´ario transform´a-los. A transforma¸c˜ao mais comum consiste em

fazer diferen¸cas sucessivas da s´erie original, at´e se obter uma s´erie estacion´aria.

Ainda segundo Ehlers (2007), uma propriedade importante dos processos esta-

cion´arios ´e que os processos obtidos de combina¸c˜oes lineares de processos estacion´arios s˜ao

tamb´em estacion´arios. Ou seja, se uma s´erie temporal {zt} = z1, z2, . . . , zt ´e estacion´aria

ent˜ao o processo wt = zt − zt−1 tamb´em ´e estacion´ario.

O resultado ao aplicar o operador diferen¸ca a uma s´erie zt com t observa¸c˜oes ´e

obter uma nova s´erie com um n´umero de t − 1 observa¸c˜oes.

A estacionariedade ´e uma suposi¸c˜ao muito forte para um processo estoc´astico,

nela se concentram a ideia de que as leis de probabilidade que atuam no processo n˜ao

mudam com o tempo, isto ´e, o processo mant´em o equil´ıbrio estat´ıstico.

3.1 A proposta

Uma s´erie temporal pode ser notada como uma cole¸c˜ao de observa¸c˜oes feitas

sequencialmente ao longo de um per´ıodo de tempo. Pode-se dizer que a caracter´ıstica

39

mais importante e interessante deste tipo de dado ´e o quanto as observa¸c˜oes vizinhas s˜ao

dependentes umas das outras. Enquanto modelos de regress˜ao conduzem que a ordem

das observa¸c˜oes ´e irrelevante para an´alise, em s´eries temporais a ordem dos dados ´e

crucial. Essa ideia traz conceitos importantes, como ´e o caso da sazonalidade, muitas

s´eries temporais exibem comportamentos quem tendem a se repetir em determinados t

per´ıodos de tempo.

A fam´ılia de vari´aveis aleat´orias {Xtn = {x1, . . . , xn}}, que descreve o estado do

sistema em pontos discretos no tempo t, forma um processo estoc´astico. Como vimos

em um cap´ıtulo anterior, uma cadeia de Markov se a probabilidade de ocorrˆencia de um

estado futuro depender apenas do estado presente, ou seja, se ´e independente dos eventos

passados,

pij = P {Xt+1 = j|Xt = i}

pn
ij = P {Xt+n = j|Xt = i}

(3.1)

(3.2)

Em que Xn representa o estado do processo no tempo n e pn

ij como sendo a

probabilidade de que um processo passe do estado i para j em n passos no tempo t.

3.2 Aplica¸c˜ao Cadeias de Markov

A base de dados utilizada foi o hist´orico do indicador de pre¸cos da soja ESALQ

/ BM&F BOVESPA, produto comercializado no porto de Paranagu´a e o hist´orico do

indicador de pre¸cos da carne de frango congelada negociada no atacado no estado de S˜ao

Paulo, ambos os indicadores com responsabilidade de execu¸c˜ao do Centro de Estudos

Avan¸cados em Economia Aplicada (Cepea) que ´e parte integrante do Departamento de

Economia, Administra¸c˜ao e Sociologia da Escola Superior de Agricultura Luiz de Queiroz

(ESALQ) que integra a Universidade de S˜ao Paulo (USP), campus Piracicaba, S˜ao Paulo.

O primeiro indicador ´e uma m´edia aritm´etica dos pre¸cos da soja comercializada

no porto de Paranagu´a e representa soja brasileira em gr˜ao a granel tipo exporta¸c˜ao. O

pre¸co ´e o valor em reais e em valor presente pago em neg´ocios realizados de soja ou ofertas

de venda/compra relatadas por agente colaborador do Cepea, por saca de 60 Kg, livre

de quaisquer encargos, tribut´arios ou n˜ao tribut´arios. O segundo s˜ao as m´edias regionais

40

que incluem o valor mais recente de cada colaborador, reportados nos ´ultimos sete dias

´uteis.

A ﬁguras 3.1 e 3.2 apresentam gr´aﬁcos de linhas com a periodicidade di´aria do

indicador, onde a linha ´e a uni˜ao dos pre¸cos de fechamento de cada dia de negocia¸c˜ao.

Deve-se observar que muitas s´eries temporais exibem um comportamento que tende a se

repetir a cada determinado per´ıodo de tempo, ou seja, caracter´ısticas sazonais, que neste

caso podem ser explicadas por per´ıodos de safra, altera¸c˜ao clim´atica, entre outros fatores.

Figura 3.1: Base de dados completa da Soja.

Figura 3.2: Base de dados completa do Frango.

Uma s´erie temporal estacion´aria ´e uma s´erie cujas m´edia, variˆancia e fun¸c˜ao

autocorrela¸c˜ao n˜ao variam com o tempo, Hill et al. (1999). Essa condi¸c˜ao ´e violada

por dados que apresentam tendˆencia ascendente ou descendente ao longo do tempo e

41

conforme ´e poss´ıvel observar graﬁcamente esse ´e o caso da base de dados em quest˜ao, a

s´erie apresenta claramente uma tendˆencia positiva, com o que parecem ser picos sazonais.

A tabela 3.1 possui a estat´ıstica descritiva dos dados.

Tabela 3.1: Estat´ıstica descritiva dos dados

Medida
M´edia
Moda
Mediana
M´aximo
M´ınimo
Amplitude
Variˆancia
Desvio Padr˜ao
Coeﬁciente de varia¸c˜ao
Tamanho da Amostra

Soja
60,32
61,17
61,98
97,61
26,57
71,04
310,51
17,62
0,2921
3313

Frango
2,994
2,6
2,87
4,89
1,31
3,58
0,628
0,793
0,265
3873

Como dados com tendˆencia s˜ao extremamente comuns em economia, encontra-se

frequentemente o que as pesquisas bibliogr´aﬁcas chamam de uma s´erie temporal n˜ao-

estacion´aria, Hill et al. (1999). Por´em, muitas s´eries temporais n˜ao-estacion´arias podem

ser transformadas em s´eries temporais estacion´arias tomando-se diferen¸cas uma ou mais

vezes. Tais s´eries temporais s˜ao chamadas em econometria de processos integrados n˜ao-

estacion´arios. E o n´umero d de vezes que um processo integrado deve ser submetido a

diferen¸cas para ser tornar estacion´ario ´e chamado ordem do processo integrado. Em geral,

as diferen¸cas ajudam a eliminar tendˆencias e sazonalidades.

Seguindo o modelo apresentado por Cechin e Corso (2017), foi realizado o c´alculo

abaixo para a varia¸c˜ao dos pre¸cos

δ =

Pt+1 − Pt
Pt

(3.3)

Onde, Pt ´e o pre¸co no tempo t e Pt+1 ´e o pre¸co no tempo t + 1.

42

Figura 3.3: Gr´aﬁco da Varia¸c˜ao do pre¸co da Soja.

Figura 3.4: Gr´aﬁco da Varia¸c˜ao do pre¸co da carne de Frango.

Como ´e poss´ıvel veriﬁcar nos gr´aﬁcos 3.3 e 3.4, bases de vari¸c˜oes possuem mais

possibilidades de ser estacion´arias, os valores ﬂutuam em torno de um intervalo menor.

Para calcular a matriz de transi¸c˜ao, foi deﬁnida a tabela abaixo.

Tabela 3.2: Intervalo das varia¸c˜oes
Intervalo das varia¸c˜oes
menor que -2,01%
de -2 a -1,01%
de -1 a -0,01%
de 0 a 0,99%
de 1 a 1,99%
maior que 2%

43

Desta forma foi poss´ıvel analisar a frequˆencia e o percentual acumulativo que

ocorriam as varia¸c˜oes em cada um destes intervalos, apresentados nos histogramas 3.5 e

3.6.

Figura 3.5: Histograma dos intervalos da varia¸c˜ao dos pre¸cos de Soja.

Figura 3.6: Histograma dos intervalos da varia¸c˜ao dos pre¸cos da carne de Frango.

O teste de autocorrela¸c˜ao foi aplicado as duas bases tratadas nas diferen¸cas e n˜ao

apresentam correla¸c˜oes signiﬁcativas em lags superiores ao primeiro, o que indica algum

termo de m´edia m´ovel nos dados que n˜ao foi identiﬁcado via fun¸c˜ao de autocorrela¸c˜ao

parcial.

Para construir a matriz de transi¸c˜ao da cadeia apontada, considere que o valor

base xi pertence a um dos intervalos delimitados na tabela 3.2, sendo eles

(cid:136) I1 =] − ∞; −0, 02[

44

(cid:136) I2 = [−0, 02; −0, 01[

(cid:136) I3 = [−0, 01; 0[

(cid:136) I4 = [0; 0, 01[

(cid:136) I5 = [0, 01; 0, 02[

(cid:136) I6 = [0, 02; +∞[

Em outras palavras, se xi ∈ (Xn)n∈N ent˜ao xi pertence a algum It, t ∈ {1, 2, 3, 4, 5, 6}.

Ent˜ao, seja at,q o n´umero de vezes em que a vari´avel xi ∈ It e xi+1 ∈ Iq, com t, q ∈

{1, 2, 3, 4, 5, 6}, a partir da´ı ´e poss´ıvel realizar uma contagem de ocorrˆencias na cadeia da

seguinte forma:

at,q =

n
(cid:88)

i=1

xIq (xk+1
i

) onde (xk+1

i

) =






1, se (xk+1

i

) ∈ It

0, se (xk+1

i

) /∈ It

Logo, para calcular cada probabilidade pi,j da matriz de transi¸c˜ao usou-se

pt,q =

at,q
n

onde n ´e o n´umero total de observa¸c˜oes presentes no estado t.

Segue a matriz de transi¸c˜ao para o primeiro modelo apresentado.

















P =

0, 19411765 0, 17647059 0, 3294118 0, 2000000 0, 05882353 0, 04117647

0, 08747515 0, 16302187 0, 3618290 0, 2823062 0, 08349901 0, 02186879

0, 02668760 0, 10884354 0, 4186290 0, 3490319 0, 07430665 0, 02250131

0, 01111648 0, 06573224 0, 3301112 0, 4562591 0, 10681489 0, 02996617

0, 01981982 0, 05765766 0, 2702703 0, 4144144 0, 17657658 0, 06126126

0, 04324324 0, 08108108 0, 2108108 0, 2864865 0, 22702703 0, 15135135

















Como o estado est´avel ´e calculando usando a equa¸c˜ao Πj =

1, 2, . . . , n, e

n
(cid:88)

j=1

Πj = 1, tem-se

45

n
(cid:88)

i=1

Πipij, com i, j =

















































π1

π2

π3

π4

π5

π6

=

















π1

π2

π3

π4

π5

π6

















e

0, 1941 0, 1764 0, 3294 0, 2000 0, 0588 0, 0411

0, 0874 0, 1630 0, 3618 0, 2823 0, 0834 0, 0218

0, 0266 0, 1088 0, 4186 0, 3490 0, 0743 0, 0225

0, 0111 0, 0657 0, 3301 0, 4562 0, 1068 0, 0299

0, 0198 0, 0576 0, 2702 0, 4144 0, 1765 0, 0612

0, 0432 0, 0810 0, 2108 0, 2864 0, 2270 0, 1513

















π1 + π2 + π3 + π4 + π5 + π6 = 1

(3.4)

Resulta no sistema a ser resolvido






π1 = 0, 1941π1 + 0, 0874π2 + 0, 0266π3 + 0, 0111π4 + 0, 0198π5 + 0, 0432π6

π2 = 0, 1764π1 + 0, 1630π2 + 0, 1088π3 + 0, 0657π4 + 0, 0576π5 + 0, 0810π6

π3 = 0, 3294π1 + 0, 3618π2 + 0, 4186π3 + 0, 3301π4 + 0, 2702π5 + 0, 2108π6

π4 = 0, 2000π1 + 0, 2823π2 + 0, 3490π3 + 0, 4562π4 + 0, 4144π5 + 0, 2864π6

π5 = 0, 0588π1 + 0, 0834π2 + 0, 0743π3 + 0, 1068π4 + 0, 1765π5 + 0, 2270π6

π6 = 0, 0411π1 + 0, 0218π2 + 0, 0225π3 + 0, 0299π4 + 0, 0612π5 + 0, 1513π6

π1 + π2 + π3 + π4 + π5 + π6 = 1

Resolvendo o sistema, tem-se que:

































π1

π2

π3

π4

π5

π6

































0, 031461

0, 093207

0, 354087

0, 383811

0, 102923

0, 034511

=

Resumindo o que foi encontrado

46

Tabela 3.3: Intervalo das varia¸c˜oes - Soja

Intervalo
menor que -2,01%
de -2 a -1,01%
de -1 a -0,01%
de 0 a 0,99%
de 1 a 1,99%
maior que 2%

Probabilidade
3,1461 %
9,3207 %
35,4087 %
38,3811 %
10,2923 %
3,4511 %

´E poss´ıvel agora calcular o tempo de recorrˆencia esperado para cada probabilidade

apresentada.

Tabela 3.4: Resultados - Soja
Probabilidade de estado est´avel πj Tempo de recorrˆencia esperado µii

π1
π2
π3
π4
π5
π6

31, 79 dias
10, 73 dias
2, 82 dias
2, 62 dias
9, 72 dias
28, 98 dias

Atrav´es da tabela 3.4 note que uma varia¸c˜ao de 0 `a 0, 99% pode ser esperada a

cada 2, 62 dias, enquanto que uma varia¸c˜ao maior do que 2% ´e esperada apenas a cada

28, 98 dias.

Segue a matriz de transi¸c˜ao para o segundo modelo apresentado.

















P =

0.09022556 0.12781955 0.2406015 0.4360902 0.06015038 0.04511278

0.05109489 0.08394161 0.2591241 0.5291971 0.05109489 0.02554745

0.03689065 0.06851120 0.2424242 0.5797101 0.05533597 0.01712780

0.03053097 0.07079646 0.1814159 0.6026549 0.07522124 0.03938053

0.02047782 0.05119454 0.1501706 0.5665529 0.12286689 0.08873720

0.02614379 0.04575163 0.1176471 0.5882353 0.14379085 0.07843137

















Como o estado est´avel ´e calculando usando a equa¸c˜ao Πj =

1, 2, . . . , n, e

n
(cid:88)

j=1

Πj = 1, tem-se

n
(cid:88)

i=1

Πipij, com i, j =

47

















π1

π2

π3

π4

π5

π6

















































π1

π2

π3

π4

π5

π6

=

0.0902 0.1278 0.2406 0.4361 0.0601 0.0451

0.0511 0.0839 0.2591 0.5292 0.0511 0.0255

0.0369 0.0685 0.2424 0.5797 0.0553 0.0171

0.0305 0.0708 0.1814 0.6026 0.0752 0.0394

0.0205 0.0512 0.1502 0.5665 0.1229 0.0887

0.0261 0.0457 0.1176 0.5882 0.1438 0.0784

































e

π1 + π2 + π3 + π4 + π5 + π6 = 1

(3.5)

Resulta no sistema a ser resolvido






π1 = 0.0902π1 + 0.0511π2 + 0.0369π3 + 0.0305π4 + 0.0205π5 + 0.0261π6

π2 = 0, 1278π1 + 0, 0839π2 + 0, 0685π3 + 0, 0708π4 + 0, 0512π5 + 0, 0457π6

π3 = 0, 2406π1 + 0, 2591π2 + 0, 2424π3 + 0, 1814π4 + 0, 1502π5 + 0, 1176π6

π4 = 0, 4361π1 + 0, 5292π2 + 0, 5797π3 + 0, 6026π4 + 0, 5665π5 + 0, 5882π6

π5 = 0, 0601π1 + 0, 0511π2 + 0, 0553π3 + 0, 0752π4 + 0, 1229π5 + 0, 1438π6

π6 = 0, 0451π1 + 0, 0255π2 + 0, 0171π3 + 0, 0394π4 + 0, 0887π5 + 0, 0784π6

π1 + π2 + π3 + π4 + π5 + π6 = 1

Resolvendo o sistema, tem-se que:

































π1

π2

π3

π4

π5

π6

































0.034352

0.070770

0.196033

0.583945

0.075399

0.039500

=

Resumindo o que foi encontrado

48

Tabela 3.5: Intervalo das varia¸c˜oes - Frango

Intervalo
menor que -2,01%
de -2 a -1,01%
de -1 a -0,01%
de 0 a 0,99%
de 1 a 1,99%
maior que 2%

Probabilidade
3,4352 %
7,0770 %
19,6033 %
58,3945 %
7,5399 %
3,95 %

´E poss´ıvel agora calcular o tempo de recorrˆencia esperado para cada probabilidade

apresentada.

Tabela 3.6: Resultados - Frango
Probabilidade de estado est´avel πj Tempo de recorrˆencia esperado µii

π1
π2
π3
π4
π5
π6

29, 1 dias
14, 1 dias
5, 1 dias
1, 7 dias
13, 3 dias
25, 3 dias

Atrav´es da tabela 3.4 note que uma varia¸c˜ao de 0 `a 0, 99% pode ser esperada a

cada 1, 7 dias, enquanto que uma varia¸c˜ao maior do que 2% ´e esperada apenas a cada

25, 3 dias.

3.3 Aplica¸c˜ao Fuzzy

Primeiramente, vale lembrar que enquanto a l´ogica convencional ou, como alguns

autores chamam, cl´assica usa distin¸c˜oes muito bem deﬁnidas para separar conjuntos, a

l´ogica fuzzy tenta modelar conceitos considerados imprecisos.

Em outras palavras, a l´ogica fuzzy se utiliza da ideia de pertinˆencia gradual,

onde considera que um elemento pertence ou n˜ao a um conjunto com diferentes graus

de pertinˆencia, um exemplo cl´assico ´e o conceito de alto ou baixo, gordo ou magro, em

que as possibilidades de permanˆencia aos grupos s˜ao subjetivas e podem inclusive serem

classiﬁcadas entre elas mesmas.

Ser˜ao usadas as mesmas bases descritas anteriormente para o modelo, ambos

acessados da p´agina virtual do CEPEA

49

(cid:136) Soja - valores de fechamento di´ario compreendidos entre 13 de mar¸co de 2006 a 17

de julho de 2019;

(cid:136) Frango - valores de fechamento di´ario compreendidos entre 08 de dezembro de 2003

`a 17 de julho de 2019.

Os retornos foram calculados da forma

δ =

Pt+1 − Pt
Pt

(3.6)

Agora, associa-se cada mudan¸ca de varia¸c˜ao de pre¸cos em seis estados fuzzy, que

ser˜ao denotados por {F1, F2, F3, F4, F5, F6}. Os estados ser˜ao classiﬁcados como n´umeros

triangulares fuzzy para obter uma associa¸c˜ao dos graus de pertinˆencia do retorno em

quest˜ao.

Figura 3.7: Fun¸c˜oes de pertinˆencias do sistema fuzzy.

Esses valores fuzzy, ou estados fuzzy, formam uma parti¸c˜ao da base de dados.

Usando a nota¸c˜ao padr˜ao para um n´umero fuzzy de um conjunto discreto F = {i, µF (i)|i =

0, . . . , N }, tem-se que os valores fuzzy para a base de preciﬁca¸c˜ao da Soja s˜ao

(cid:136) F1 = (−0, 0300/ − 0, 0200/ − 0, 0100)

(cid:136) F2 = (−0, 0200/ − 0, 0100/0, 0000)

(cid:136) F3 = (−0, 0100/0, 0000/0, 0000)

(cid:136) F4 = (0, 0000/0, 0000/0, 0100)

50

(cid:136) F5 = (0, 0000/0, 0100/0, 0200)

(cid:136) F6 = (0, 0100/0, 0200/0, 0300)

Comparado ao modelo de cadeias de Markov, o novo modelo fornece uma des-

cri¸c˜ao mais realista aos estados, pois utilizar´a probabilidade condicional fuzzy para calcu-

lar a matriz de transi¸c˜ao. Desta forma, considerando os seis estados do sistema, a matriz

de transi¸c˜ao para os estados fuzzy ´e

















P =

0.0805 0.2308 0.2389 0.1849 0.1911 0.0737

0.0500 0.1796 0.2616 0.2651 0.1805 0.0633

0.0439 0.1692 0.2677 0.2795 0.1784 0.0612

0.0473 0.1544 0.2702 0.2649 0.2098 0.0533

0.0473 0.1608 0.2578 0.2568 0.2213 0.0559

0.0529 0.1877 0.2069 0.2269 0.2615 0.0641

















O que resulta em uma distribui¸c˜ao de probabilidade para o retorno da varia¸c˜ao

do pre¸co, calculada da mesma forma que o estado estacion´ario, ou seja,

































π1

π2

π3

π4

π5

π6

































0.0488

0.1695

0.2603

0.2610

0.2011

0.0592

=

Que resultar´a em um tempo m´edio de retorno, listado na tabela 3.7, onde ´e

poss´ıvel analisar se os dias de ganho ou perda podem ser classiﬁcados entre curto, m´edio

ou longo prazo.

Tabela 3.7: Resultados (Fuzzy) - Soja
Probabilidade de estado est´avel πj Tempo de recorrˆencia esperado µii

π1
π2
π3
π4
π5
π6

20, 5 dias
5, 9 dias
3, 84 dias
3, 83 dias
4, 97 dias
16, 9 dias

51

Para a base de preciﬁca¸c˜ao do Frango, os valores fuzzy para a base de preciﬁca¸c˜ao

s˜ao

(cid:136) F1 = (−0, 0300/ − 0, 0200/ − 0, 0100)

(cid:136) F2 = (−0, 0200/ − 0, 0100/0, 0000)

(cid:136) F3 = (−0, 0100/0, 0000/0, 0000)

(cid:136) F4 = (0, 0000/0, 0000/0, 0100)

(cid:136) F5 = (0, 0000/0, 0100/0, 0200)

(cid:136) F6 = (0, 0100/0, 0200/0, 0300)

Considerando os seis estados do sistema, a matriz de transi¸c˜ao para os estados

fuzzy ´e

















P =

0.0682 0.2141 0.3336 0.2480 0.0917 0.0445

0.0426 0.1681 0.3286 0.3012 0.1277 0.0317

0.0400 0.1606 0.3304 0.3054 0.1332 0.0305

0.0381 0.1374 0.3136 0.3118 0.1477 0.0514

0.0362 0.1340 0.3121 0.3048 0.1572 0.0557

0.0264 0.1145 0.2930 0.2743 0.2175 0.0742

















O que resulta em uma distribui¸c˜ao de probabilidade para o retorno da varia¸c˜ao

do pre¸co, calculada da mesma forma que o estado estacion´ario, ou seja,

































π1

π2

π3

π4

π5

π6

































0.0398

0.1510

0.3243

0.2996

0.1422

0.0431

=

Que resultar´a em um tempo m´edio de retorno, listado na tabela 3.8, onde ´e

poss´ıvel analisar se os dias de ganho ou perda podem ser classiﬁcados entre curto, m´edio

ou longo prazo.

52

Tabela 3.8: Resultados (Fuzzy) - Frango
Probabilidade de estado est´avel πj Tempo de recorrˆencia esperado µii

π1
π2
π3
π4
π5
π6

25, 12 dias
6, 62 dias
3, 08 dias
3, 34 dias
7, 03 dias
23, 20 dias

As categorias dos estados e as matrizes de probabilidade de transi¸c˜ao condicional

foram calculadas via Matlab.

3.4 Resultados

Analisando o comportamento dos dois modelos apresentados ´e poss´ıvel veriﬁcar

que eles geram resultados muito parecidos entre si. Fornecendo informa¸c˜oes a especula-

dores e investidores em potencial sobre oportunidades futuras para estrat´egias de compra

e venda de curto, m´edio e longo prazo.

Para a soja os dois modelos apresentaram resultados muito pr´oximos, com um

tempo menor de retorno no quarto intervalo. Demonstrando a tendˆencia positiva da s´erie

e indicando uma oportunidade de ganho a curto prazo.

Quanto ao frango, os modelos n˜ao apresentaram resultados t˜ao pr´oximos quanto

a soja, enquanto no primeiro modelo a s´erie apresentou seu menor tempo de retorno

ao intervalo quatro o segundo mostrou o intervalo trˆes. Apesar de nivelar as varia¸c˜oes

centrais, uma diferen¸ca entre os modelos chama aten¸c˜ao, no primeiro modelo tem-se um

tempo de retorno predominantemente menor entre os trˆes ´ultimos intervalos, enquanto que

no segundo modelo essa l´ogica ´e invertida, comportamento esse que pode ser justiﬁcado

pelo fato de a l´ogica fuzzy interpretar melhor incertezas e portanto medir o risco de

maneira mais precisa, sendo mais conservadora em seus resultados.

53

Considera¸c˜oes ﬁnais

Este trabalho estudou Cadeias de Markov e L´ogica Fuzzy com uma aplica¸c˜ao

para analisar varia¸c˜oes de pre¸cos.

Os c´alculos foram realizados nos softwares R Core Team (2017) e Matlab, devido a

rapidez e precis˜ao dos resultados. Foram utilizadas bases de preciﬁca¸c˜ao das commodities

soja e frango congelado disponibilizadas na p´agina virtual do CEPEA - USP.

Tais informa¸c˜oes s˜ao consideradas vantajosas quanto a estrat´egias de neg´ocios e

crit´erios de tomada de decis˜ao. Tamb´em pode ajudar produtores a realizarem um processo

de prote¸c˜ao de custos e pre¸cos de forma eﬁcaz.

No caso da soja, os resultados encontrados foram bem parecidos seguindo as duas

metodologias. No caso do frango, o resultado aplicando probabilidade fuzzy pareceu mais

conservadora, invertendo a posi¸c˜ao encontrada utilizando cadeias de markov. Deixando

claro que para trabalhos futuros a sugest˜ao seria explorar, estressando mais os modelos

e suas diferen¸cas, considerando varia¸c˜oes cambiais, inﬂa¸c˜ao e pol´ıticas monet´arias. De

modo a tentar limpar a base de dados e proporcionar novas an´alises, inclusive em bases

de dados que n˜ao sejam em mercados `a vista, estendendo os m´etodos a ativos futuros ou

negociados em balc˜ao.

Por ﬁm, este trabalho ´e fruto de uma inspira¸c˜ao presente em uma das disciplinas

do Profmat. Claro que a maioria das disciplinas n˜ao possuem muitos exemplos de mo-

delos imediatamente aplic´aveis, por´em todo conhecimento adquirido durante o curso de

mestrado resulta certamente em possibilidades reais de criar novos modelos e aplica¸c˜oes

dentro ou fora do ambiente escolar.

54

Referˆencias Bibliogr´aﬁcas

Barros, L. C. e Bassanezi, R. C. (2006). T´opicos de l´ogica Fuzzy e biomatem´atica.

UNICAMP–IMEEC, Campinas–SP.

Cechin, R. B. e Corso, L. L. (2017). Previs˜ao da varia¸c˜ao do pre¸co da soja, utilizando

Cadeia de Markov. VII Congresso Basileiro de engenharia de produ¸c˜ao.

CEPEA (2019).

Centro de estudos avan¸cados em economia aplicada.

URL:

https://www.cepea.esalq.usp.br Acesso em: 01/08/2019.

Ehlers,

R.

S.

(2007).

An´alise

de

s´eries

temporais.

URL:

http://www.each.usp.br/rvicente/AnaliseDeSeriesTemporais.pdf

Acesso

em:

01/02/2019.

Granger, C. W. J. (1980). Forecasting in business and economics. Academic Press: New

York, San Francisco, London.

Hill, C., Griﬃths, W., e Judge, G. (1999). Econometria. Editora Saraiva, S.Paulo.

Morettin, P. A. e Toloi, C. M. (2006). Modelos para previs˜ao de s´eries Temporais. Edgard

Blucher, S.Paulo.

Morgado, A. C., Carvalho, J. B. P., de Carvalho, P. C. P., e Fernandez, P. (2016). An´alise

Combinat´oria e Probabilidade. Sociedade Brasileira de Matem´atica, Rio de Janeiro–RJ.

Pardo, M. J. e de la Fuente, D. (2010). Fuzzy Markovian decision processes: Application

to queueing systems. Elsevier.

Privault, N. (2013). Understanding Markov Chains - Examples and Applications. Springer,

Singapore.

55

R Core Team (2017). R: A Language and Environment for Statistical Computing. R

Foundation for Statistical Computing, Vienna, Austria.

Rousseau, C. e Saint-Aubin, Y. (2015). Matem´atica e Atualidade–Volume 1. Sociedade

Brasileira de Matem´atica, Rio de Janeiro–RJ.

Uzun, B. e ErsinKiral (2017). Application of markov chains-fuzzy states to gold price. In

Procedia Computer Sciense of 9th ICSCCW, Ago 24-25, volume 120, p´aginas 365–371,

Budapeste, Hungria. Elsevier.

Viali, L. (2008). Algumas considera¸c˜oes sobre a origem da teoria da probabilidade. Revista

Brasileira de Hist´oria da Matem´atica, 8(16):143–153.

Wooldridge, J. M. (2006). Introdu¸c˜ao ´a Econometria. Thomson, S.Paulo.

Zadeh, L. A. (1965). Fuzzy sets. Information and Control, 8:338–353.

56

Apˆendice: Scripts

R - Matriz de Transi¸c˜ao com probabilidade condicional

convencional

Para carregar as bases no programa:

base < − read.table(”FrangoSoja.csv”, head=T, sep=”:”, dec=”,”,stringsAsFactors =

FALSE)

as.data.frame(base)

Calculando a base de diferen¸cas:

difbase < − array(c(0:0),dim=c(length(base$Reais),1))

i < −1

while (i<length(base$Reais))

difbase[i,1] < − ((base[i+1,1] - base[i,1])/base[i,1])

i < − i+1

Para calcular a matriz de transi¸c˜ao

while (i<length(difbase))

difbase[i,1] < − ((base[i+1,1] - base[i,1])/base[i,1])

if (difbase[i,1] < -0.02)

a < − a+1

A[j] < − i+1

j < − j+1

if (difbase[i,1] >= -0.02 && difbase[i,1] < -0.01)

b < − b+1

B[g] < − i+1

g < − g+1

57

if (difbase[i,1] >= -0.01 && difbase[i,1] < 0)

c < − c+1

C[k] < − i+1

k < − k+1

if (difbase[i,1] >= 0 && difbase[i,1] < 0.01)

d < − d+1

D[l] < − i+1

l < − l+1

if (difbase[i,1] >= 0.01 && difbase[i,1] <= 0.02)

e < − e+1

E[m] < − i+1

m < − m+1

if (difbase[i,1] > 0.02 )

f < − f+1

F[n] < − i+1

n < − n+1

i < − i+1

i < − 1

cont[i] < − c(0,0,0,0,0,0)

while (i<=length(A))

if (difbase[A[i]] < -0.02)

cont[1] < − cont[1]+1

if (difbase[A[i]] >= -0.02 && difbase[A[i]] < -0.01)

cont[2] < − cont[2]+1

if (difbase[A[i]] >= -0.01 && difbase[A[i]] < 0)

cont[3] < − cont[3]+1

if (difbase[A[i]] >= 0 && difbase[A[i]] < 0.01)

cont[4] < − cont[4]+1

if (difbase[A[i]] >= 0.01 && difbase[A[i]] <= 0.02)

cont[5] < − cont[5]+1

if (difbase[A[i]] > 0.02)

58

cont[6] < − cont[6]+1

i < − i+1

P[1] < − c(cont[1]/a, cont[2]/a, cont[3]/a, cont[4]/a, cont[5]/a, cont[6]/a)

O passo acima deve ser repetido para cada intervalo, gerando a matriz de transi¸c˜ao.

Cada P [i] ´e uma linha da cadeia.

P < − c(P1, P2, P3, P4, P5, P6)

t(matrix(P,6,6))

A an´alise de autocorrela¸c˜ao da base foi feita da forma

acf(base)

pacf(base)

acf(difbase)

pacf(difbase)

require(urca)

lsoj.df < − ur.df(y=difbase, lag=3, type=’trend’)

summary(lsoj.df)

kpss.ur < − ur.kpss(difbase, type=’tau’, lags=”short”)

summary(kpss.ur)

Matlab - Matriz de Transi¸c˜ao com probabilidade con-

dicional Fuzzy

Para carregar as bases no programa:

T = readtable(’Sojamod.csv’);

M = table2array(T);

C0 = [];

Pontos do n´umero triangular fuzzy (a/b/c)

bxp = [-0.02 -0.01 0 0 0.01 0.02];

bxp = [-0.03 -0.02 -0.01 0 0 0.01 0.02 0.03];

for i = 1:length(M)-1

Varia¸c˜ao relativa

DP = (M(i+1)-M(i))./M(i)+(1-2*rand(1))*eps;

C = [];

59

C´alculo da matriz e resolu¸c˜ao do sistema de autovetor associado ao autovalor 1.

for j = 2:length(bxp)-1

trfn1 = trimf(DP,[bxp(j-1) bxp(j) bxp(j+1)]);

C = [C trfn1];

end

C0 = [C0;C];

end

I = zeros(length(bxp)-2);

for i = 1:(length(bxp)-2)

vaux1 = ﬁnd(C0(1:end-1,i)¿0);

I(i,:) = sum(C0(vaux1+1,:));

end

TR = diag(1./sum(I,2))*I;

[CA,DA] = eig(TR’);

EE = CA(:,1)/sum(CA(:,1))

TEMR = 1./(CA(:,1)/sum(CA(:,1)))

disp(’ ’)

for i = 0:length(TR)

if(i==0)

str=string();

for j=1:length(TR)

str(j)= [’A’ num2str(j)];

end

disp([sprintf(’%s ’,’ ’) sprintf(’ %s ’,str)])

else

str = string();

for j=1:length(TR)

str(j)= num2str(TR(i,j),’%1.4f’);

end

disp([sprintf(’%s ’,[’A’ num2str(i)]) sprintf(’%s ’,str)])

end

end

60

disp(’ ’)

for i=1:length(bxp)-2

disp([sprintf(’%s%i ’,’A’, i) ’ => (’ num2str(bxp(i),’%1.4f/’) num2str(bxp(i+1),’%1.4f/’)

num2str(bxp(i+2),’%1.4f)’)])

end

disp(’ ’)

61


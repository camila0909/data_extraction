Programa¸c˜ao Linear e suas Aplica¸c˜oes:
Deﬁni¸c˜ao e M´etodos de Solu¸c˜oes

Goiˆania
2013

1

TERMO DE CIÊNCIA E DE AUTORIZAÇÃO PARA DISPONIBILIZAR ELETRONICAMENTE 
OS TRABALHOS DE CONCLUSÃO DE CURSO NA BIBLIOTECA DIGITAL DA UFG 

Na qualidade de titular dos direitos de autor, autorizo a Universidade Federal de Goiás 
(UFG)  a  disponibilizar,  gratuitamente,  por  meio  da  Biblioteca Digital  de  Teses  e  Dissertações 
(BDTD/UFG), sem ressarcimento dos direitos autorais, de acordo com a Lei nº 9610/98, o do-
cumento conforme permissões assinaladas  abaixo, para fins de leitura, impressão e/ou  down-
load, a título de divulgação da produção científica brasileira, a partir desta data. 

1. Identificação do material bibliográfico:           Trabalho de Conclusão de Curso de  
                                                                                Mestrado Profissional 
2. Identificação do Trabalho  

Autor (a):  Pedro Felippe da Silva Araújo 
Pedrinho21_09@hotmail.com 
E-mail: 
Seu e-mail pode ser disponibilizado na página?   [x]Sim            [  ] Não 

Vínculo empregatício do autor 
Agência de fomento: 
País: 
Título: 

Brasil 

Servidor Público 
Secretaria de Educação 
UF:  DF 

CNPJ:  00.394.676/0001-07 

Sigla:  SEEDF 

Programação Linear e suas Aplicações: Definição e Métodos de Soluções 

Palavras-chave:  Conjuntos Convexos, Programação Linear, Método Simplex 
Título em outra língua: 

Linear  Programming  and  its  Applications:  Definition  and  Me-
thods of Solutions 

Palavras-chave em outra língua:  Convex Sets, Linear Programming, Simplex Method 

Área de concentração:  Matemática do Ensino Básico 
Data defesa: (dd/mm/aaaa) 
Programa de Pós-Graduação: 
Orientador (a):  José Yunier Bello Cruz 
E-mail: 
Co-orientador(a):* 
E-mail: 

18/03/2013           
PROFMAT 

yunier@impa.br 

*Necessita do CPF quando não constar no SisPG 

3. Informações de acesso ao documento:  

Concorda com a liberação total do documento [x] SIM          [   ] NÃO1 

Havendo concordância  com  a  disponibilização  eletrônica,  torna-se imprescindível  o  en-

vio do(s) arquivo(s) em formato digital PDF ou DOC do trabalho de conclusão de curso. 

O sistema da Biblioteca Digital de Teses e Dissertações garante aos autores, que os ar-
quivos  contendo  eletronicamente  as  teses,  dissertações  ou  trabalhos  de  conclusão  de  curso, 
antes  de  sua  disponibilização,  receberão  procedimentos  de  segurança,  criptografia  (para  não 
permitir cópia e  extração  de conteúdo,  permitindo  apenas impressão  fraca)  usando  o  padrão 
do Acrobat.  

_________________________                                                           Data: 08 / 04 / 2013 
       Assinatura do autor 

 Neste caso o documento será embargado por até um ano a partir da data de defesa. A extensão deste prazo 

1 
suscita justificativa junto à coordenação do curso. Os dados do documento não serão disponibilizados durante o período 
de embargo.  

                                                                                                     
     
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                   
Pedro Felippe da Silva Ara´ujo

Programa¸c˜ao Linear e suas Aplica¸c˜oes

Deﬁni¸c˜ao e M´etodos de Solu¸c˜oes

Trabalho de Conclus˜ao de Curso apresentado
ao programa de P´os-gradua¸c˜ao do Instituto de
Matem´atica e Estat´ıstica da Universidade Federal
de Goi´as, como requisito parcial para obten¸c˜ao do
t´ıtulo de Mestre em Matem´atica.
´Area de concentra¸c˜ao: Matem´atica do Ensino
B´asico
Orientador: Prof. Jos´e Yunier Bello Cruz

Bras´ılia
2013

3

Dados Internacionais de Catalogação na Publicação (CIP) 
GPT/BC/UFG 

Araújo, Pedro Felippe da Silva. 

A663p 

Programação  linear e suas aplicações [manuscrito]: definição 

e métodos de soluções / Pedro Felippe da Silva Araújo. – 2012. 

xv, 74 f. : il., figs, tabs. 

Orientador: Prof. Dr. José Yunier Bello Cruz. 
Dissertação  (Mestrado)  –  Universidade  Federal  de  Goiás, 

Instituto de Matemática e Estatística, 2012. 
       Bibliografia. 

Inclui lista de figuras, abreviaturas, siglas e tabelas. 
Apêndices. 

1.  Conjuntos Convexos. 2. Programação Linear. 3. 

Método Simplex. I. Título. 

CDU: 514.172 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
Todos os direitos reservados. ´E proibida a reprodu¸c˜ao total ou parcial do trabalho

sem autoriza¸c˜ao da universidade, do autor e do orientador.

Pedro Felippe da Silva Ara´ujo

Graduou-se em Matem´atica na Universidade de Bras´ılia (UnB); durante a gra-
dua¸c˜ao, participou do Programa de Ensino e Tutorial de Matem´atica (PETMAT); foi
congressista do 10o Encontro Nacional de Educa¸c˜ao Matem´atica (X ENEM); foi moni-
tor das disciplinas C´alculo e Vari´aveis Complexas do Departamento de Matem´atica da
UnB; atualmente, ´e professor de Educa¸c˜ao B´asica da Secretaria de Educa¸c˜ao do Distrito
Federal, Bras´ılia.

5

Aos meus pais Ribamar e Natalina, ao meu irm˜ao Brunno, `a minha amada Juliane
e aos meus amigos Carlos, Helder, Walter, Ronan, resumindo, `a turma PROFMAT do
p´olo An´apolis que me incentivou e me deu for¸ca para concluir o mestrado com ˆexito.

6

Agradecimentos

Aos professores do PROFMAT que passaram o conhecimento necess´ario para o
desenvolvimento deste trabalho, principalmente ao professor Dr. Jos´e Yunier Bello Cruz
quem sugeriu e ajudou no desenvolvimento do tema.

7

“A matem´atica, quando a compreendemos bem, possui n˜ao somente a verdade,

mas tamb´em a suprema beleza.”

Bertrand Russel

8

Resumo

Ara´ujo, P. F. da S.. Programa¸c˜ao Linear, Bras´ılia, 2012. Dis-
serta¸c˜ao de Mestrado. Departamento de Matem´atica, Instituto de
Matem´atica e Estat´ıstica, Universidade Federal de Goi´as.

Problemas que envolvem a ideia de otimiza¸c˜ao est˜ao presentes em v´arios cam-
pos de estudo como, por exemplo, na Economia se busca a minimiza¸c˜ao de custos e
a maximiza¸c˜ao do lucro em uma ﬁrma ou pa´ıs, a partir do or¸camento dispon´ıvel; na
Nutri¸c˜ao se procura suprir os nutrientes essenciais di´arios com o menor custo poss´ıvel,
considerando a capacidade ﬁnanceira do indiv´ıduo; na Qu´ımica se estuda a press˜ao e a
temperatura m´ınimas necess´arias para realizar uma rea¸c˜ao qu´ımica espec´ıﬁca no menor
tempo poss´ıvel; na Engenharia se busca o menor custo para a confec¸c˜ao de uma liga
de alum´ınio misturando v´arias mat´erias-primas e obedencendo `as restri¸c˜oes m´ınimas e
m´aximas dos respectivos elementos presentes na liga.

Todos os exemplos citados, al´em de uma inﬁnidade de outras situa¸c˜oes, buscam
sua solu¸c˜ao atrav´es da Programa¸c˜ao Linear. S˜ao problemas de minimizar ou maximi-
zar uma fun¸c˜ao linear sujeito a Desigualdades ou Igualdades Lineares, com o intuito de
encontrar a melhor solu¸c˜ao deste problema.

Para isso, mostram-se neste trabalho os m´etodos de solu¸c˜ao de problemas de
Programa¸c˜ao Linear. H´a ˆenfase nas solu¸c˜oes geom´etricas e no M´etodo Simplex, a forma
alg´ebrica de solu¸c˜ao. Procuram-se mostrar v´arias situa¸c˜oes as quais podem se encaixar
alguns desses problemas, dos casos gerais a alguns casos mais espec´ıﬁcos.

Antes de chegar, eventualmente, em como solucionar problemas de Programa¸c˜ao
Linear, constr´oi-se o campo de trabalho deste tipo de otimiza¸c˜ao, os Conjuntos Convexos.
H´a apresenta¸c˜oes das deﬁni¸c˜oes e teoremas essenciais para a compreens˜ao e o desenvolvi-
mento destes problemas; al´em de discuss˜oes sobre a eﬁciˆencia dos m´etodos aplicados.

Durante o trabalho, mostra-se que h´a casos os quais n˜ao se aplicam as solu¸c˜oes
apresentadas, por´em, em sua maioria, se enquadram de maneira eﬁciente, mesmo como
uma boa aproxima¸c˜ao.

Palavras-chave

<Conjuntos Convexos, Programa¸c˜ao Linear, M´etodo Simplex>

9

Abstract

Ara´ujo, P. F. da S.. Linear Programming, Bras´ılia, 2012. Mas-
ters Dissertation. Departamento de Matem´atica, Instituto de Ma-
tem´atica e Estat´ıstica, Universidade Federal de Goi´as.

Problems involving the idea of optimization are found in various ﬁelds of study,
such as, in Economy is in search of cost minimization and proﬁt maximization in a ﬁrm
or country, from the available budget; in Nutrition is seeking to redress the essential
nutrients daily with the lowest possible cost, considering the ﬁnancial capacity of the
individual; in Chemistry studies the pressure and temperature minimum necessary to
accomplish a speciﬁc chemical reaction in the shortest possible time; in Engineering seeks
the lowest cost for the construction of an aluminium alloy mixing various raw materials
and restrictions obeying minimum and maximum of the respective elements in the alloy.
All examples cited, plus a multitude of other situations, seek their Remedy by
Linear Programming. They are problems of minimizing or maximizing a linear function
subject to linear inequalities or Equalities, in order to ﬁnd the best solution to this
problem.

For this show in this paper methods of problem solving Linear Programming.
There is an emphasis on geometric solutions and Simplex Method, to form algebraic
solution. Wanted to show various situations which may ﬁt some of these problems, some
general cases more speciﬁc cases.

Before arriving eventually in solving linear programming problems, builds up the
ﬁeld work of this type of optimization, Convex Sets. There are presentations of deﬁnitions
and theorems essential to the understanding and development of these problems, besides
discussions on the eﬃciency of the methods applied.

During the work, it is shown that there are cases which do not apply the solutions

presented, but mostly ﬁt eﬃciently, even as a good approximation.

Keywords

<Convex Sets, Linear Programming, Simplex Method>

10

Sum´ario

1 Introdu¸c˜ao

12
1.1 Preliminares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.2 Objetivos
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.3 O Desenvolvimento Hist´orico da Programa¸c˜ao Linear . . . . . . . . . . . . 13
. . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.4 Apresenta¸c˜ao dos Cap´ıtulos

2 Conjuntos Convexos

15
2.1 Conceitos de Topologia em Rn . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.2 Convexidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3 Desigualdades e Sistemas de Inequa¸c˜oes Lineares

29
3.1 Desigualdades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2 Sistemas de Desigualdades Lineares . . . . . . . . . . . . . . . . . . . . . . 32
3.3 O valor m´aximo e m´ınimo da forma linear no poliedro . . . . . . . . . . . . 34
3.4 Redu¸c˜ao de Desigualdades Lineares a Igualdades Lineares . . . . . . . . . . 36

4 Programa¸c˜ao Linear

40
4.1 Modelos de Programa¸c˜ao Linear . . . . . . . . . . . . . . . . . . . . . . . . 40
4.2 Solu¸c˜ao Gr´aﬁca . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
. . . . . . . . . . . . . . . . . . . . . . 55
4.3 Limita¸c˜oes da Programa¸c˜ao Linear

5 M´etodo Simplex

57
5.1 Rela¸c˜ao entre o m´etodo gr´aﬁco e o alg´ebrico . . . . . . . . . . . . . . . . . 57
5.2 O M´etodo Simplex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
5.3 Casos Especiais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
. . . . . . . . . . . . . . . . . . . . . . . . . . 75
5.4 Obten¸c˜ao da solu¸c˜ao inicial
5.4.1 Casos de Diﬁculdades . . . . . . . . . . . . . . . . . . . . . . . . . . 75
5.4.2 Processo do “M Grande” . . . . . . . . . . . . . . . . . . . . . . . . 76
. . . . . . . . . . . . . . . . 77
5.4.3 Processo da Fun¸c˜ao Objetiva Artiﬁcial

6 Considera¸c˜oes Finais

83

A ´Algebra Linear

84
A.1 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
A.2 Sistemas de Equa¸c˜oes Lineares . . . . . . . . . . . . . . . . . . . . . . . . . 89
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
A.3 Espa¸co Vetorial

11

Cap´ıtulo 1

Introdu¸c˜ao

1.1 Preliminares

Um Programa Linear ´e um problema de otimiza¸c˜ao no qual h´a uma fun¸c˜ao obje-
tiva linear e restri¸c˜oes que consistem de equa¸c˜oes ou inequa¸c˜oes lineares. A forma exata
dessas restri¸c˜oes podem ser diferentes dependendo do problema estudado, mas, como mos-
tra abaixo, qualquer Programa Linear pode ser transformado em um Sistema de Equa¸c˜oes
Lineares chamado forma “standard”.

maximizar

c1x1 + c2x2 + ... + cnxn

sujeito a






...

...

a11x1 + a12x2 + ... + a1jxj + ... + a1nxn = b1
a21x1 + a22x2 + ... + a2jxj + ... + a2nxn = b2
...
...
ai1x1 + ai2x2 + ... + aijxj + ... + ainxn = bi
...
...
am1x1 + am2x2 + ... + amjxj + ... + amnxn = bm
x1, x2, ..., xn (cid:62) 0,

...

...

...

...

onde bi , ci e aij s˜ao constantes reais ﬁxas, e os xj s˜ao n´umeros reais a serem deter-
minados. Assume-se que cada equa¸c˜ao pode ser multiplicada por −1, quando necess´ario,
para que cada bi seja n˜ao negativo.

Em uma nota¸c˜ao vetorial, este problema na forma “standard” pode ser reescrito

como:

maximizar

Ax = b

cT x sujeito a
e x (cid:62) 0.

Aqui x ´e um vetor coluna n-dimensional, cT ´e um vetor linha n-dimensional, A
´e a matriz dos coeﬁcientes de ordem m × n e b ´e um vetor coluna m-dimensional. A
desigualdade vetorial x (cid:62) 0 indica que cada componente de x ´e n˜ao-negativo.

12

1.2 Objetivos

Os objetivos deste trabalho s˜ao:

(i) Desenvolver a teoria dos conjuntos convexos;

(ii) Apresentar as propriedades alg´ebricas e geom´etricas das desigualdades lineares e dos

sistemas de desigualdades lineares;

(iii) Explicar alguns modelos cl´assicos da Programa¸c˜ao Linear;

(iv) Apresentar o m´etodo gr´aﬁco para a resolu¸c˜ao de um modelo de Programa¸c˜ao Linear,

com alguns casos particulares;

(v) Desenvolver o M´etodo Simplex, o qual ´e a forma alg´ebrica de resolu¸c˜ao de um modelo

de Programa¸c˜ao Linear, com alguns casos especiais.

Como objetivo principal, procurou-se esclarecer as ideias te´oricas de forma a con-
tribuir na utiliza¸c˜ao adequada das t´ecnicas. Assim, percebe-se o detalhamento ao desen-
volver os problemas propostos no tabalho.

1.3 O Desenvolvimento Hist´orico da Programa¸c˜ao Li-

near

A hist´oria da Programa¸c˜ao Linear ´e de 1830 a 1947. Neste per´ıodo, houve per-

cursores iniciais que desenvolveram estudos sobre:

(i) igualdades e desigualdades lineares como Fourrier e Gauss em 1826, Gordan em 1873

e Pareto em 1906, bem como a contribui¸c˜ao deste na Teoria dos Jogos; veja [20];

(ii) Solu¸c˜oes de Sistemas Lineares por Motzkin em 1936; veja [20];

(iii) matriz de insumo e produto de Leontief; veja [19];

(iv) atribui¸c˜oes de produ¸c˜ao de Kantorovich em 1939; veja [18];

(v) o problema do transporte de Hitchcock em 1941; veja [14].

O problema do Transporte foi um dos problemas que mais impulsionou a Pro-
grama¸c˜ao Linear. As principais contribui¸c˜oes foram modeloar, quantiﬁcar e resolver pro-
blemas pr´aticos que seriam reduzidos a Sistemas de Equa¸c˜oes Lineares.

Foi em 1947 que Dantzig concebeu uma t´ecnica automatizada, a qual permitiu que
problemas de otimiza¸c˜ao com fun¸c˜ao objetivo linear e restri¸c˜oes lineares fossem resolvidos,
chamada M´etodo Simplex; veja [12].

Depois da constru¸c˜ao da base de desenvolvimento da Programa¸c˜ao Linear, surgi-
ram melhorias para os m´etodos existentes; novas estruturas matem´aticas foram encontra-
das e descritas; e novos campos foram descobertos e desenvolvidos como, por exemplo:

13

(i) Manne, em 1953, e Orchand, em 1955, trataram sobre Programa¸c˜ao Param´etrica;

veja [21];

(ii) Charnes, em 1952, tratou sobre Degenera¸c˜ao e uma aplica¸c˜ao de Programa¸c˜ao Linear

sobre a mistura de combust´ıveis na avia¸c˜ao; veja [11];

(iii) Lemke, em 1954, desenvolveu o M´etodo Simplex Dual; veja [17];

(iv) Ford e Fulkerson, em 1954, descreveu um problema de Programa¸c˜ao Linear que
permitiria tra¸car uma rota para enviar tanto ﬂuxo quanto for poss´ıvel, a partir de
uma origem a um destino, atrav´es de uma rede; veja [13];

(v) Koopmans e Bechmann, em 1957, foram os primeiros a descrever o problema da

Atribui¸c˜ao Quadr´atica, o qual ´e uma estrutura n˜ao-linear; veja [16];

(vi) Karmarkar, em 1984, desenvolveu o M´etodo dos Pontos Interiores, que tem a propri-
edade de exigir um esfor¸co computacional ligeiramente maior a partir do aumento
do trabalho; veja [15].

Continua, atualmente, a melhoria de m´etodos da classe dos Pontos Interiores e se

procuram implementa¸c˜oes mais eﬁcientes deste m´etodo.

Outros avan¸cos tˆem sido a prolifera¸c˜ao de softwares e o uso de planilhas na oti-
miza¸c˜ao, cujo aumento da velocidade e da mem´oria acompanhado de baixos custos, me-
lhorou o uso de t´ecnicas na Programa¸c˜ao Linear.

1.4 Apresenta¸c˜ao dos Cap´ıtulos

O Cap´ıtulo 2 trata sobre conjuntos convexos, que ´e utilizado nas estruturas das
solu¸c˜oes de um Programa Linear. Mostram-se as principais deﬁni¸c˜oes e teoremas para
explicar o desenvolvimento dos modelos de Programa¸c˜ao Linear propostos.

O Cap´ıtulo 3 aborda as desigualdades lineares, com suas propriedades alg´ebricas
e geom´etricas; trata sobre sistemas de desigualdades lineares, como reduzi-los a Sistemas
de Equa¸c˜oes Lineares e como encontrar a sua solu¸c˜ao m´axima ou m´ınima.

O Cap´ıtulo 4 trata sobre o tema deste trabalho, a Programa¸c˜ao Linear, mostrando-
se alguns modelos cl´assicos que, como visto no resumo hist´orico, motivaram seu desenvol-
vimento; Resolu¸c˜ao de modelos de Programa¸c˜ao Linear a partir do m´etodo gr´aﬁco com
alguns casos particulares; e aborda as limita¸c˜oes de modelos espec´ıﬁcos de Programa¸c˜ao
Linear.

O Cap´ıtulo 5 trata sobre o m´etodo alg´ebrico utilizado para resolver modelos de
Programa¸c˜ao Linear, o M´etodo Simplex, mostrando-se seu desenvolvimento por sistemas
de desigualdades lineares e por quadros; e casos especiais ao resolver alguns modelos de
Programa¸c˜ao Linear;

O Apˆendice apresenta t´opicos de ´Algebra Linear como pr´e-requisito ao bom en-
tendimento deste trabalho. Apresentam-se as deﬁni¸c˜oes e os teoremas principais sobre
Matrizes, Sistemas Lineares e Espa¸co Vetorial.

14

Cap´ıtulo 2

Conjuntos Convexos

Neste cap´ıtulo se aborda os conceitos essenciais para a constru¸c˜ao do campo de de-
ﬁni¸c˜ao da Programa¸c˜ao Linear, sendo primordial o conhecimento dos principais teoremas
da ´Algebra Linear.

2.1 Conceitos de Topologia em Rn

Abaixo, introduz-se algumas terminologias de topologia em Rn importantes sobre

conjuntos.

Deﬁni¸c˜ao 1. Seja V ∈ Rn um espa¸co vetorial, ai, bi ∈ V tal que ai representa um vetor
linha e bi um vetor coluna de n´umeros reais; o conjunto dos pontos {x ∈ V |aix = bi}
representa o hiperplano e as desigualdades {x ∈ V |aix (cid:54) bi} e {x ∈ V |aix = bi} os
semi-espa¸cos correspondentes no Rn.

Exemplo 1.

a) x ∈ R : x = a ´e um hiperplano; x ∈ R : x (cid:54) a e x ∈ R : x (cid:62) a s ao semi-espa¸cos

chamados semirretas.

b) Para n = 2, tem-se que:

(i) o hiperplano ´e deﬁnido por uma reta;

(ii) os semi-espa¸cos s˜ao deﬁnidos pelos semiplanos.

c) Para n = 3, tem-se que:

(i) o hiperplano ´e deﬁnido por um plano;

(ii) os semi-espa¸cos correspondentes recebem este mesmo nome.

Deﬁni¸c˜ao 2. Seja x0 ∈ Rn; uma bola de raio c centrada em x0 ´e chamada vizinhan¸ca de
x0.

Deﬁni¸c˜ao 3. Se S ∈ Rn cont´em uma vizinhan¸ca de x0, ent˜ao S ´e uma vizinhan¸ca de x0
e x0 ´e um ponto interior de S.

15

Deﬁni¸c˜ao 4. O conjunto dos pontos interiores de S ´e chamado interior de S e denotado
por int(S).

Deﬁni¸c˜ao 5. Se todo ponto de S ´e um ponto interior, isto ´e, se S = int(S), ent˜ao S ´e
aberto; S ´e fechado se o complementar de S ´e aberto.

Figura 2.1: Representa¸c˜ao de um conjunto fechado

Figura 2.2: Representa¸c˜ao de um conjunto aberto

Na Programa¸c˜ao Linear se lida, exclusivamente, com conjuntos fechados, portanto

consideramos somente semi-espa¸cos fechados.

Exemplo 2. Como uma ilustra¸c˜ao, considere o sistema de desigualdades lineares abaixo:

(cid:26) 3x1 + 2x2 (cid:54) 6
2x1 − x2 (cid:62) 1.

5

(2.1)

A Figura 2.3 ilustra as retas I e II representando as rela¸c˜oes de (2.1), enquanto as
abas representam os semi-espa¸cos deﬁnidos pelas rela¸c˜oes. Estes semi-espa¸cos dividem o
plano bidimensional em quatro conjuntos A, B, C e D. Todos os pontos do conjunto A
contradizem a restri¸c˜ao da rela¸c˜ao I e satisfaz a restri¸c˜ao II, C contradizem a restri¸c˜ao
da rela¸c˜ao II e n ao satisfaz a restri¸c˜ao I, B contradiz ambas as restri¸c˜oes e D, incluindo
seu bordo, satisfaz ambas as rela¸c˜oes, sendo chamado de conjunto poss´ıvel ou conjunto
solu¸c˜ao poss´ıvel.

16

Figura 2.3: conjunto solu¸c˜ao poss´ıvel

Deﬁni¸c˜ao 6. O octante n˜ao-negativo Rn
em Rn, isto ´e

+ ´e o conjunto de todos os pontos n˜ao-negativos

Exemplo 3.

{x ∈ Rn|xi (cid:62) 0, i = 1, ..., n}.

a) Em R2, o ortante n˜ao-negativo equivale ao primeiro quadrante, incluindo-se os eixos

positivos e a origem.

b) Acrescentando-se as rela¸c˜oes III: x1 (cid:62) 0 e x2 (cid:62) 0 ao sistema do exemplo anterior,
5, 0), (2, 0) e

ent˜ao o conjunto solu¸c˜ao do sistema equivale ao triˆangulo de v´ertices ( 2
(1, 3
2) dado pela interse¸c˜ao do conjunto D com o primeiro quadrante.

Figura 2.4: conjunto solu¸c˜ao com restri¸c˜ao de inc´ognitas n˜ao – negativas

Deﬁni¸c˜ao 7. Um conjunto S ∈ Rn ´e dito limitado se existe uma bola de raio c ∈ R tal
que ele est´a contido nessa bola; um conjunto que n˜ao ´e limitado ´e chamado ilimitado;
quando um conjunto ´e fechado e limitado, ele ´e chamado de compacto.

Exemplo 4.

a) O conjunto da Figura 2.1, de fato, ´e compacto;

b) O conjunto D da Figura 2.3 ´e ilimitado;

17

c) O conjunto solu¸c˜ao hachurado na Figura 2.4 ´e compacto.

Deﬁni¸c˜ao 8. A interse¸c˜ao de um n´umero ﬁnito de hiperplanos e/ou semi-espa¸cos fechados
em Rn ´e chamado politopo; um politopo limitado ´e chamado poliedro.

Exemplo 5.

a) O conjunto D da Figura 2.3 ´e um politopo, mas n˜ao ´e um poliedro;

b) O conjunto solu¸c˜ao hachurado na Figura 2.4 ´e um poliedro.

Mostrar-se-´a no cap´ıtulo 4 que todo conjunto solu¸c˜ao de um problema de Pro-

grama¸c˜ao Linear forma um politopo.

Nota¸c˜ao Hi denota o conjunto dos pontos que satisfaz

n
(cid:80)
j=1

aijxj (cid:54) bi, i = 1, 2, ..., m,

que ´e a i-´esima rela¸c˜ao linear ; ent˜ao S =

simultaneamente, todas as m rela¸c˜oes.

m
(cid:84)
i=1

Hi ´e o conjunto dos pontos que satisfaz,

Deﬁni¸c˜ao 9. A k -´esima rela¸c˜ao ´e chamada redundante se S =

rela¸c˜ao n˜ao ´e redundante, ent˜ao ela ´e chamada essencial.

m
(cid:84)

i = 1
i (cid:54)= k

Hi. Se a k -´esima

Deﬁni¸c˜ao 10. Seja V um espa¸co vetorial e ai, bi, ˜x ∈ V ; se algum ponto ˜x ∈ S satisfaz
a i -´esima rela¸c˜ao linear como uma equa¸c˜ao, isto ´e, se ai ˜x = bi, ent˜ao a i -´esima rela¸c˜ao ´e
dita vinculada a ˜x.

Exemplo 6.

Figura 2.5:

Figura 2.6:

18

a) Na Figura 2.5, o poliedro gerado pelos semi-espa¸cos I, II, ..., VII ´e a ´area hachurada
com extremos nos pontos O, A, B, C e D. Claramente, a desigualdade II ´e redun-
dante, aﬁnal sua inclus˜ao ou remo¸c˜ao n˜ao altera a regi˜ao do politopo. O mesmo
argumento pode ser aplicado `a desigualdade IV, a qual tamb´em ´e redundante. Note,
contudo, que a desigualdade IV possui o ponto B e a desigualdade II n˜ao passa por
ponto algum do politopo, com isso, diz-se que a restri¸c˜ao II ´e uma redundˆancia forte
e IV uma redundˆancia fraca. Ao ponto C as rela¸c˜oes I e III est˜ao vinculadas, da
mesma forma ao ponto O as rela¸c˜oes VI e VII est˜ao vinculadas, enquanto o ponto
E n˜ao possui rela¸c˜ao de vincula¸c˜ao.

b) Na Figura 2.6, as rela¸c˜oes I e II s˜ao desigualdades enquanto a rela¸c˜ao III ´e uma
equa¸c˜ao, logo o politopo deﬁnido ´e um segmento de reta com extremos em A e B.
Isto implica que as rela¸c˜oes I e V s˜ao redundantes e poderiam ser deletadas sem
alterar o poliedro.

2.2 Convexidade

Deﬁni¸c˜ao 11. Seja V ∈ Rn um espa¸co vetorial, x ∈ V e ai ∈ R, i = 1, ..., r; a combina¸c˜ao
linear y =

aixi, ´e chamada:

r
(cid:80)
i=1

(i) combina¸c˜ao linear n˜ao-negativa se ai (cid:62) 0, ∀i = 1, ..., r;

(ii) combina¸c˜ao linear aﬁm se

r
(cid:80)
i=1

ai = 1;

(iii) combina¸c˜ao linear convexa se valem os ´ıtens (i) e (ii).

Exemplo 7.

Considere os pontos x1 = (0, 0), x2 = (3, 0), x3 = (0, 2), x4 = (3, 2) e y = ( 3

2).
Por inspe¸c˜ao, note que a combina¸c˜ao linear dos pontos x1, x2, x3, x4 com as respectivas
constantes a1 = 0, a2 = 1
4 e a4 = 0 geram o ponto y, logo, tem-se uma combina¸c˜ao
linear n˜ao negativa.

2, a3 = 1

2, 1

Para encontrar uma combina¸c˜ao linear aﬁm ou convexa, basta encontrar o con-

junto solu¸c˜ao do sistema






0a1 + 3a2 + 0a3 + 3a4 = 3
2
0a1 + 0a2 + 2a3 + 2a4 = 1
2
a1 + a2 + a3 + a4 = 1.

Ignorando as condi¸c˜oes n˜ao-negativas ao iniciar e resolvendo o sistema por esca-

lonamento, tem-se que:






0a1 + 3a2 + 0a3 + 3a4 = 3
2
0a1 + 0a2 + 2a3 + 2a4 = 1
2
a1 + a2 + a3 + a4 = 1

Aplicando-se opera¸c oes elementares, chega-se em um sistema o qual possui o
mesmo conjunto solu¸c˜ao, como se explica no Apˆendice. Com isso, tem-se o seguinte
sistema:

19






a2 + a4 = 1
2
−a2 + a3 = − 1
4
a1 + a2 = 3
4.

Uma das solu¸c˜oes do sistema ´e a1 = 3

4, a2 = 0, a3 = 1

4 e a4 = 0, indicando que,

de fato, y ´e uma combina¸c˜ao linear aﬁm dos vetores dados.

Finalmente, Para que y seja uma combina¸c˜ao convexa, todos os parˆametros devem
ser n˜ao-negativos, satisfazendo as restri¸c˜oes do sistema escalonado obtido. Com isso, ´e
2], resultando que a1, a2, a3 (cid:62) 0, logo y tamb´em ´e uma combina¸c˜ao
f´acil ver que a2 ∈ [ 1
convexa dos pontos dados.

4, 1

Proposi¸c˜ao 2.2.1. Qualquer ponto situado no segmento de reta que liga dois pontos
contidos no Rn pode ser expresso como uma combina¸c˜ao convexa desses dois pontos.

Demonstra¸c˜ao.

Sejam A1 e A2 pertencentes a Rn; Considere a Figura 2.7, onde A3 ´e um ponto

qualquer entre A1 e A2.

Como A3 est´a entre A1 e A2, ent˜ao, para algum 0 (cid:54) α (cid:54) 1, tem-se, por constru¸c˜ao:

α(A1 − A2) = A3 − A2
A3 = αA1 + (1 − α)A2.

Como os coeﬁcientes α e (1 − α) de A3 s˜ao n˜ao-negativos e a soma deles ´e igual

a 1, ent˜ao tem-se que A3, pela deﬁni¸c˜ao 8, ´e uma combina¸c˜ao convexa de A1 e A2.

Figura 2.7:

(cid:4)

Corol´ario 2.2.2. Qualquer ponto que for expresso como uma combina¸c˜ao convexa de dois
pontos ﬁca contido no segmento de reta que os une.

Demonstra¸c˜ao.

Seja A3 a combina¸c˜ao convexa:

20

A3 = αA1 + (1 − α)A2, ∀ 0 (cid:54) α (cid:54) 1.

Note que se α = 0, A3 = A2 e se α = 1, A3 = A1.

Suponha que A3 n˜ao pertence ao segmento com extremos em A1 e A2, conforme mostra

a Figura 2.8.

Figura 2.8:

Logo, tem – se que:

A3 = αA1 + A2 − αA2
= α(A1 − A2) + A2

A3 − A2 = α(A1 − A2).

Logo tem-se que os vetores A3 − A2 e (A1 − A2) devem ter a mesma dire¸c˜ao. Isso
s´o poderia acontecer se A3 pertence ao segmento de reta com extremos em A1 e A2. (cid:4)

Considere agora trˆes pontos A1, A2 e A3 pertencentes a Rn, conforme mostra a

Figura 2.9.

Figura 2.9:

21

Veja que, tamb´em, qualquer ponto do triˆangulo A1A2A3 pode ser obtido como

uma combina¸c˜ao convexa dos pontos A1, A2 e A3.

Sabe-se que A4 = αA1 + (1 − α)A3 para 0 (cid:54) α (cid:54) 1 pertence ao segmento de reta
com extremos em A1 e A3. Ent˜ao A5 = kA4 + (1 − k)A2, para 0 (cid:54) k (cid:54) 1 representa um
ponto qualquer dentro do triˆangulo. Tem-se que:

A5 = k[αA1 + (1 − α)A3] + (1 − k)A2
= kαA1 + (1 − k)A2 + k(1 − α)A3.

Note que os coeﬁcientes de A1, A2 e A3 s˜ao n˜ao-negativos e soma deles ´e:

kα + (1 − k) + (k − kα) = 1.

Portanto, A5 ´e uma combina¸c˜ao convexa de A1, A2 e A3.

Ao se considerar quatro vetores A1, A2, A3 e A4 pode-se obter a Figura 2.10

Figura 2.10:

Note que qualquer ponto do tetraedro da Figura 2.10 pode ser obtido com uma
combina¸c˜ao convexa de A1, A2, A3 e A4. Essa propriedade pode ser veriﬁcada pelo leitor
de modo an´alogo ao do triˆangulo. Essa propriedade ser´a v´alida qualquer que seja o n´umero
de pontos.

Demonstrar-se-´a no cap´ıtulo 4 que, se dois v´ertices de um segmento pertence
`a solu¸c˜ao ´otima do modelo de programa¸c˜ao linear, ent˜ao qualquer combina¸c˜ao convexa
destes tamb´em ser´a uma solu¸c˜ao ´otima.

Deﬁni¸c˜ao 12 (Conjunto Convexo). Um conjunto S ´e dito convexo se uma combina¸c˜ao
convexa de quaisquer dois elementos de S ´e um elemento de S, isto ´e, para todo x1, x2 ∈ S
e para todo numero real α ∈ [0, 1], o ponto αx1 + (1 − α)x2 ∈ S.

Geometricamente, um conjunto ´e convexo se todos os pontos de um segmento de

reta, com extremos que s˜ao elementos de S, s˜ao elementos de S.

22

Exemplo 8.

a) A Figura 2.11 mostra um disco descrito pela equa¸c˜ao x2

1 + x2

2 − 2x1 (cid:54) 0. Note que ele

´e um conjunto convexo.

Figura 2.11:

Mostrando-se algebricamente, considere que ˜x, ˆx ∈ R2, tais que ˜x = (˜x1, ˜x2) e

ˆx = (ˆx1, ˆx2), sejam dois pontos que satisfa¸cam a rela¸c˜ao, isto ´e

˜x2
1 + ˜x2

2 − 2˜x1 (cid:54) 0 e

ˆx2
1 + ˆx2

2 − 2ˆx1 (cid:54) 0.

Considere tamb´em que ¯x ∈ R2, onde ¯x = (¯x1, ¯x2), ´e uma combina¸c˜ao convexa

qualquer de ˜x e ˆx, isto ´e

¯xj = λ˜xj + (1 − λ)ˆxj, j = 1, 2 com λ ∈ [0, 1].

Portanto, tem-se que

1 + ¯x2
¯x2

2 − 2¯x1 = [λ˜x1 + (1 − λ)ˆx1]2 + [λ˜x2 + (1 − λ)ˆx2]2 − 2[λ˜x1 + (1 − λ)ˆx1]2

(cid:124)

= (˜x1 − ˆx1)2
(cid:125)

λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0
(cid:123)(cid:122)
(cid:62)0
1 + ˆx2
+ (ˆx2
2 − 2ˆx1)
(cid:124)
(cid:123)(cid:122)
(cid:125)
(cid:54)0

(λ − 1)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:54)0

+

(cid:124)

+ (˜x2 − ˆx2)2
λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0
(cid:125)
(cid:123)(cid:122)
(cid:62)0
1 + ˜x2
+ (˜x2
2 − 2˜x1)
(cid:124)
(cid:123)(cid:122)
(cid:125)
(cid:54)0

(λ − 1)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:54)0
λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0

(1 − λ)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:62)0

(cid:54) 0.

Logo, o conjunto {(x1, x2) ∈ R2|x2

1 + x2

2 − 2x1 (cid:54) 0} ´e convexo.

23

Figura 2.12:

b) A Figura 2.12 mostra a regi˜ao hachurada no interior da par´abola ´e descrita pela

desigualdade x2

1 − x2 (cid:54) 0. Note que ela tamb´em ´e um conjunto convexo.
Mostrando-se algebricamente, considere que ˜x, ˆx ∈ R2, tais que ˜x = (˜x1, ˜x2) e

ˆx = (ˆx1, ˆx2), sejam dois pontos que satisfa¸cam a rela¸c˜ao, isto ´e

1 − ˜x2 (cid:54) 0 e
˜x2

1 − ˆx2 (cid:54) 0.
ˆx2

Considere tamb´em que ¯x ∈ R2, onde ¯x = (¯x1, ¯x2), ´e uma combina¸c˜ao convexa

qualquer de ˜x e ˆx, isto ´e

¯xj = λ˜xj + (1 − λ)ˆxj, j = 1, 2 com λ ∈ [0, 1].

Portanto, tem-se que

1 + ¯x2 = [λ˜x1 + (1 − λ)ˆx1]2 − [λ˜x2 + (1 − λ)ˆx2]2
¯x2
(1 − λ)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:62)0

+ (˜x1 − ˆx1)2
(cid:123)(cid:122)
(cid:125)
(cid:62)0

1 − ˆx2)
(cid:123)(cid:122)
(cid:125)
(cid:54)0

λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0

(λ − 1)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:54)0

(cid:124)

= (ˆx2
(cid:124)
(cid:54) 0.

+ (˜x2
(cid:124)

1 − ˜x2)
(cid:123)(cid:122)
(cid:125)
(cid:54)0

λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0

Logo, o conjunto {(x1, x2) ∈ R2|x2

1 − x2 (cid:54) 0} ´e convexo.

Lema 2.2.3. Toda rela¸c˜ao linear deﬁne um conjunto convexo.

Demonstra¸c˜ao.

Seja V um espa¸co vetorial e a, b, x ∈ V ; considere a rela¸c˜ao linear ax R b e suponha

que x1, x2 ∈ V resolvem esta rela¸c˜ao, isto ´e

24

Considere, agora, ¯x uma combina¸c˜ao convexa de x1 e x2, isto ´e

ax1 − b R 0 e ax2 − b R 0.

Ent˜ao, tem-se que

¯x = λx1 + (1 − λ)x2 ∀ λ ∈ [0, 1]

a¯x − b = a[λx1 + (1 − λ)x2] − b

= λ
(cid:124)(cid:123)(cid:122)(cid:125)(cid:62)0

+ (1 − λ)
(ax1 − b)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:62)0
(cid:123)(cid:122)
(cid:125)
(cid:124)
R 0
R 0, para R ∈ {(cid:54), =, (cid:62)}.

(ax2 − b)
(cid:125)
(cid:123)(cid:122)
(cid:124)
R 0

De forma an´aloga poder-se-ia aplicar aos casos os quais R ∈ {<, >}.

(cid:4)

Lema 2.2.4. A interse¸c˜ao de um n´umero ﬁnito de conjuntos convexos ´e um conjunto
convexo.

Demonstra¸c˜ao.

Primeiramente, considere dois conjuntos convexos A e B e deﬁna C = A∩B. Para
quaisquer dois pontos x, y ∈ C, pode-se concluir que, como C ´e subconjunto tanto de A
quanto de B, x, y ∈ A e x, y ∈ B. Deﬁna agora um ponto z = λx + (1 − λ)y, λ ∈ [0, 1],
ent˜ao, por hip´otese, o conjunto A ´e convexo, logo z ∈ A, e o conjunto B tamb´em, logo
z ∈ B, portanto z ∈ C.

O mesmo vale para um n´umero ﬁnito de conjuntos convexos.

(cid:4)

Corol´ario 2.2.5. Todo politopo ´e um conjunto convexo.

Demonstra¸c˜ao.

Basta lembrar que um politopo ´e, por deﬁni¸c˜ao, a interse¸c˜ao de hiperplanos e/ou
(cid:4)

semi-espa¸cos.

Deﬁni¸c˜ao 13. Um ponto b´asico no Rn ´e a interse¸c˜ao de pelo menos n hiperplanos em
um ponto singular; um ponto b´asico poss´ıvel, tamb´em chamado de ponto extremo, ´e um
ponto b´asico que satisfaz todas as rela¸c˜oes lineares dadas.

Exemplo 9. A ´area hachurada na Figura 2.13 ´e um politopo; os pontos O, A, B, C, D,
E, F, G e H s˜ao pontos b´asicos, os quais somente O, A, C e F s˜ao pontos extremos do
politopo.

Deﬁni¸c˜ao 14. Um ponto x que pertence a um conjunto convexo C ´e chamado ponto
extremo de C se n˜ao existem dois pontos distintos x1 e x2 em C tais que

x = αx1 + (1 − α)x2,

∀α ∈ (0, 1).

Um ponto extremo ´e, portanto, um ponto que n˜ao se encontra, estritamente,
dentro de um segmento de reta formado por dois outros pontos do conjunto. Os pontos
extremos de um triˆangulo, por exemplo, s˜ao os trˆes v´ertices.

25

Figura 2.13:

Lema 2.2.6. Um ponto extremo n˜ao pode ser expresso como uma combina¸c˜ao convexa de
outros pontos do politopo; no poliedro, cada ponto pode ser expresso como uma combina¸c˜ao
convexa de pontos extremos. Esta propriedade n˜ao ´e v´alida para politopos que n˜ao s˜ao
poli´edricos.

Demonstrar-se-´a no Cap´ıtulo 4 que todo conjunto solu¸c˜ao de um modelo de pro-

grama¸c˜ao linear ´e um conjunto convexo.

Exemplo 10. Considere o espa¸co bidimensional; os politopos que n˜ao tem pontos extre-
mos consistem de conjunto vazio, hiperplano ou semi-espa¸co, ou a interse¸c˜ao de qualquer
n´umero de semi-espa¸cos paralelos, cujos gradientes pentencem a um hiperplano ´unico. Po-
litopos com um ´unico ponto extremo, ou est˜ao em um ponto, ou em um cone poli´edrico,
como mensionado na proposi¸c˜ao a seguir. Nenhum destes politopos s˜ao poliedros e em
nenhum desses casos ser´a poss´ıvel gerar qualquer ponto a partir dos pontos extremos
existentes que n˜ao seja o pr´oprio ponto extremo.

Deﬁni¸c˜ao 15. O conjunto de todos os pontos que podem ser expressos como combina¸c˜ao
convexa de pontos extremos ´e chamado de envolt´oria convexa dos pontos extremos dados.

Proposi¸c˜ao 2.2.7. Um poliedro ´e a envolt´oria convexa de pontos extremos.

Deﬁni¸c˜ao 16. Um cone poliedral convexo ´e a interse¸c˜ao de um n´umero qualquer de semi-
espa¸cos fechados que s˜ao limitados por hiperplanos intersectados em um mesmo ponto
chamado v´ertice o qual se encontra no 0.

Exemplo 11. S˜ao cones poliedrais:

a) Um semi-espa¸co;

b) A interse¸c˜ao de dois semi-espa¸cos;

26

c) Um plano;

d) Um semi-plano;

e) Uma reta;

f ) Semirretas de mesma origem formando um ˆangulo menor que 180o em um plano cen-

trado em 0;

g) A interse¸c˜ao de uma reta com um semi-espa¸co;

h) Uma pirˆamide convexa ilimitada com v´ertice em 0.

Figura 2.14: Cone poliedral formado por semirretas com origem em 0.

Teorema 2.2.8. Qualquer cone poli´edrico convexo com v´ertice na origem pode ser gerado
como o conjunto de todas as combina¸c˜oes lineares n˜ao – negativas de um n´umero ﬁnito
de pontos dados.

Demonstra¸c˜ao.

Far-se-´a uma demonstra¸c˜ao apenas no caso que K seja uma pirˆamide.
Supondo K ser uma pirˆamide, seleciona-se um ponto em cada uma de suas arestas.
Com isso, obt´em-se um sistema de pontos A1,..., Ar. Aﬁrma-se que o conjunto dos vetores
{A1, ..., Ar} gera K.

Examinando um plano qualquer que corta todas as arestas da pirˆamide K, obt´em-

se os pontos A(cid:48)

1, ..., A(cid:48)

r. ´E evidente que

A(cid:48)

1 = k1A1, ..., A(cid:48)

r = krAr; k1, ..., kr (cid:62) 0.

Suponha, agora, que A ´e qualquer ponto da pirˆamide diferente do v´ertice O.
A semirreta OA intercepta o plano em um certo ponto A(cid:48). ´E evidente que A(cid:48) ´e uma
combina¸c˜ao convexa do sistema A(cid:48)

1 = k1A1, ..., A(cid:48)

r e, portanto

A(cid:48) = p1A(cid:48)

1 + ... + prA(cid:48)
r,

r
(cid:88)

i=1

pi = 1.

27

Substituindo, na ´utima rela¸c˜ao, as igualdades da primeira rela¸c˜ao da demonstra¸c˜ao,

tem-se que:

levando em considera¸c˜ao que A(cid:48) = kA, tem-se que:

A(cid:48) = k1p1A1 + ... + krprAr,

A = s1A1 + ... + srAr; si =

kipi
k

, i = 1, ..., r.

Portanto, qualquer ponto A da pirˆamide K pertence ao conjunto gerado por {A1, ..., Ar}.
Nos casos em que K equivale a um dos itens do Exemplo 11, pode ser feito de
(cid:4)

modo an´alogo.

Deﬁni¸c˜ao 17. Um Simplex S ∈ Rn ´e a envolt´oria convexa de n + 1 pontos dados, tais
que n˜ao h´a hiperplanos em Rn que inclui todos estes n + 1 pontos.

Exemplo 12.

a) Um Simplex no R2 ´e um triˆangulo;

b) Um Simplex no R3 ´e um tetraedro.

28

Cap´ıtulo 3

Desigualdades e Sistemas de
Inequa¸c˜oes Lineares

Nos problemas de programa¸c˜ao linear s˜ao de interesse solu¸c˜oes de sistemas de desi-
gualdades Lineares que satisfa¸cam as restri¸c˜oes x1 (cid:62) 0,...,xn (cid:62) 0, isto ´e, solu¸c˜oes n˜ao-
negativas, as quais, neste cap´ıtulo, ver-se-´a como reduz´ı-las em um sistema equivalente
de equa¸c˜oes alg´ebricas, uma das tarefas mais importantes da programa¸c˜ao linear.

3.1 Desigualdades

Nesta se¸c˜ao, estudar-se-´a as rela¸c˜oes R = {<, >, (cid:54), (cid:62)} mensionadas nos cap´ıtulos

anteriores.

Primeiramente, veja as propriedades das desigualdades no espa¸co unidimensional

R, o qual correspondente `a reta real.

Sejam a, b, c, x, y ∈ R; ent˜ao tem-se que:

(i) a (cid:62) b ⇒ a + c (cid:62) b + c;

(ii) x (cid:62) y, a (cid:62) b ⇒ x + a (cid:62) y + b;

(iii) a (cid:62) b, λ (cid:62) 0 ⇒ λa (cid:62) λb;

(iv) a > b, λ < 0 ⇒ λa < λb;

(v) x (cid:62) y, a (cid:54) b ⇒ x − a (cid:62) y − b;

(vi) a (cid:62) b, b (cid:54) a ⇔ a = b.

Agora, analisando o espa¸co bidimensional R2, o qual corresponde ao plano, possui a

seguinte equa¸c˜ao linear:

ax + by = c; a, b, c ∈ R,

a qual o conjunto de pontos que a satisfaz equivale a uma reta, cujo vetor normal ´e

(a, b), como conhecido na geometria anal´ıtica.

29

Figura 3.1:

Tomando-se b = 0, obt´em-se uma equa¸c˜ao da forma

x = k,

Figura 3.2:

a qual determina uma reta paralela ao eixo das ordenadas, como na Figura 3.2.
Agora, tomando a = 0, obt´em-se uma equa¸c˜ao da forma

a qual determina uma reta paralela ao eixo das abscissas, como na Figura 3.3.
Analisando as desigualdades da equa¸c˜ao linear, n˜ao ´e dif´ıcil observar que:

y = k(cid:48),

30

Figura 3.3:

(i) com ax + by > c e ax + by < c tem-se os pontos acima e abaixo, respectivamente, da

reta ax + by = c. Veja a Figura 3.4;

(ii) com x < k e x > k tem-se os pontos `a esquerda e `a direita, respectivamente, da reta

x = k. Veja a Figura 3.5;

(iii) com y < k(cid:48) e y > k(cid:48) tem-se os pontos abaixo e acima, respectivamente, da reta

y = k(cid:48). Veja a Figura 3.6.

Figura 3.4:

Figura 3.5:

Figura 3.6:

Todas as desigualdades acima equivalem ao semi-espa¸co do R2, neste caso cha-

mado de semi-plano, em rela¸c˜ao ao hiperplano ax + by = c.

Analisando o espac¸co tridimensional R3, que corresponde ao espa¸co, tem-se a

seguinte equa¸c˜ao linear:

ax + by + cz = d; a, b, c, d ∈ R,

a qual o conjunto de pontos que a satisfaz equivale a um plano, cujo vetor normal ´e

(a, b, c), como conhecido da geometria anal´ıtica e como ilustrado na Figura 3.7.

Analisando as desigualdades da equa¸c˜ao linear, tem-se que

ax + by + cz > d e ax + by + cz < d,

que determinam os semi-espa¸cos correspondentes em rela¸c˜ao a ax + by + cz = d.

31

Figura 3.7:

Analogamente, no espa¸co n-dimensional Rn, a equa¸c˜ao linear ´e

a1x1 + ... + anxn = B; a1, ..., an, B ∈ R,

onde o conjunto de pontos que a satisfaz equivale ao hiperplano do espa¸co n-dimensional,

cujo vetor normal ´e (a1, ..., an) e as desigualdades

a1x1 + ... + anxn > B e a1x1 + ... + anxn < B

equivalem aos semi-espa¸cos em rela¸c˜ao ao hiperplano mensionado.

3.2 Sistemas de Desigualdades Lineares

Suponha que em um espa¸co bidimensional h´a n desigualdades da forma

ai1x1 + ai2x2 (cid:54) bi; i = 1, ..., n.1

Cada uma das desigualdades determina um dos dois semi-planos com limite na

reta ai1x1 + ai2x2 = bi com vetor normal (ai1, ai2).

Como no Cap´ıtulo 2, chama-se solu¸c˜ao do sistema qualquer par ordenado (x1, x2)

que satisfaz todas as desigualdades do sistema.

Exemplo 13.

a) A desigualdade

2x1 + 3x2 (cid:54) 6

determina um semi-plano, a qual satisfaz qualquer ponto que esteja na parte hachu-
rada como na Figura 3.8.

1Qualquer desigualdade da forma ai1x1 + ai2x2 (cid:62) bi, multiplicando seus termos por −1, equivalem a

esta equa¸c˜ao.

32

b) O sistema

(cid:26) 2x1 + 3x2 (cid:54) 6
−x1 + x2 (cid:54) 2

determina uma parte do plano como na Figura 3.9.

c) O sistema






2x1 + 3x2 (cid:54) 6
−x1 + x2 (cid:54) 2
−x1 − 3x2 (cid:54) 3

determina um conjunto de pontos na forma de um triˆangulo como na Figura 3.10.

d) O sistema





2x1 + 3x2 (cid:54) 6
−x1 + x2 (cid:54) 2
−x1 − 3x2 (cid:54) 3
x1 (cid:54) 3
2

determina um conjunto de pontos na forma de um quadril´atero como na Figura
3.11.

Figura 3.8:

Figura 3.9:

Figura 3.10:

Figura 3.11:

Quando existe um ponto que pertence a todos os semi-planos determinados pelo
sistema, diz-se que ele ´e uma solu¸c˜ao compat´ıvel. O conjunto de todos esses pontos pode

33

ser um semi-plano, um pol´ıgono limitado ou ilimitado, uma reta ou um segmento de reta,
ou um ponto, formando-se um conjunto convexo.

Quando n˜ao h´a pontos que satisfa¸cam todas as desigualdades, diz-que o sistema

´e incompat´ıvel.

Em um espa¸co tridimensional, um sistema de n desigualdades se pode escrever

da forma

ai1x1 + ai2x2 + ai3x3 (cid:54) bi; i = 1, ..., n.

Como dito, cada desigualdade determina um semi-espa¸co com plano limite

ai1x1 + ai2x2 + ai3x3 = bi.

O conjunto de desigualdades sendo compat´ıvel, existe um conjunto convexo que
satisfaz ao sistema de desigualdades, podendo ser representado da forma de um semi-
espa¸co, um poliedro, um plano, um pol´ıgono, uma reta ou um ponto.

Analogamente, suponha que em um espa¸co n-dimensional se tenha o sistema de

desigualdades

ai1x1 + ai2x2 + ... + ainxn (cid:54) bi; i = 1, ..., n,

o qual cada uma das desigualdades deﬁne um semi-espa¸co com o hiperplano limite

ai1x1 + ai2x2 + ... + ainxn = bi.

Sendo o sistema compat´ıvel, chama-se o conjunto de pontos que o satisfaz poliedro

das solu¸c˜oes.

3.3 O valor m´aximo e m´ınimo da forma linear no

poliedro

O estudo desta se¸c˜ao ´e o ponto-chave da programa¸c˜ao linear: o objetivo de ma-

ximizar ou minimizar certo problema da programa¸c˜ao linear.

Primeiramente, considere um sistema compat´ıvel com equa¸c˜oes lineares de duas
vari´aveis e suponha que, al´em disso, tem-se a fun¸c˜ao linear, posteriormente chamada de
fun¸c˜ao objetiva, de duas vari´aveis

f (x1, x2) = c1x1 + c2x2.

Tem-se como objetivo encontrar o conjunto de pontos (x1, x2) do pol´ıgono das
solu¸c˜oes que leva a fun¸c˜ao linear ao valor m´aximo ou m´ınimo. Examinando o conjunto de
pontos (x1, x2) do plano em cada um dos quais a fun¸c˜ao f toma um valor ﬁxo f = f1. O
conjunto de tais pontos ´e a reta c1x1 + c2x2 = f1. Esta reta ´e normal ao vetor (c1, c2) que
sai da origem das coordenadas. Tra¸cando-se uma reta F normal ao vetor (c1, c2), como na
Figura 3.12, e a deslocando paralelamente a si na dire¸c˜ao do vetor (c1, c2). Suponha que
em seu deslocamente, a reta F intersecta o pol´ıgono pela primeira vez no ponto A. Nesta
posi¸c˜ao F (cid:48) a reta F se faz suporte. Ao continuar o deslocamento na mesma dire¸c˜ao, a

34

reta F passar´a pelo ponto D, fazendo-se tamb´em reta suporte. Sabendo-se que no sentido
do vetor (c1, c2) se tem a dire¸c˜ao do m´aximo incremento da fun¸c˜ao linear f , ent˜ao todos
os valores que toma a fun¸c˜ao f no pol´ıgono das solu¸c˜oes, ter-se-´a valor m´ınimo na reta
suporte F (cid:48) e valor m´aximo na reta suporte F (cid:48)(cid:48).

Figura 3.12:

Logo, os valores m´aximo e m´ınimo da fun¸c˜ao f no conjunto solu¸c˜ao alcancar-se-´a
nos pontos de interse¸c˜ao deste pol´ıgono com as retas suportes normais ao vetor (c1, c2),
podendo-se gerar um ponto, no caso o v´ertice do pol´ıgono, ou um conjunto enumer´avel
de pontos, no caso o lado do pol´ıgono.

Na Figura 3.13 tem-se o caso da fun¸c˜ao f alcan¸car seu valor m´ınimo nos pontos
do segmento CD, ao mesmo tempo que seu valor m´aximo s˜ao nos pontos do pol´ıgono que
est˜ao inﬁnitamente distantes.

Figura 3.13:

Analogamente, uma fun¸c˜ao linear de trˆes vari´aveis

f = c1x1 + c2x2 + c3x3

35

toma um valor constante no plano normal ao vetor (c1, c2, c3). O sentido do vetor
(c1, c2, c3) ´e a dire¸cˆao do m´aximo incremento da fun¸c˜ao f . Os valores m´aximo e m´ınimo
desta fun¸c˜ao no poliedro das solu¸c˜oes tamb´em dar-se-˜ao nos pontos de interse¸c˜ao deste
poliedro com os planos-suportes normais ao vetor (c1, c2, c3), onde a fun¸c˜ao atinge em
um dos planos-suportes o valor m´ınimo e em outro o valor m´aximo. A interse¸c˜ao de um
poliedro com um plano-suporte pode ser um ponto, isto ´e, o v´ertice do poliedro, ou um
conjunto enumer´avel de pontos, isto ´e, uma aresta ou uma face do poliedro.
A generaliza¸c˜ao do conteito das fun¸c˜oes lineares ´e a fun¸c˜ao

f = c1x1 + c2x2 + ... + cnxn,

de n vari´aveis reais x1, x2, ..., xn chamada forma real, onde c1, c2, ..., cn ∈ R. Fixando
valores da forma linear f1, f2, ..., fq, deﬁnem-se no espa¸co n-dimensional os hiperplanos

f1 = c1x1 + c2x2 + ... + cnxn
f2 = c1x1 + c2x2 + ... + cnxn
...
...
...
fq = c1x1 + c2x2 + ... + cnxn,

...

que s˜ao normais ao vetor (c1, c2, ..., cn).

Denotando por fmin e fmax como os valores m´aximo e m´ınimo, respectivamente,
da fun¸c˜ao f no poliedro de solu¸c˜oes. Lembrando que o vetor (c1, c2, ..., cn) determina
a dire¸c˜ao do incremento m´aximo da fun¸c˜ao f , ent˜ao quando as fun¸c˜oes f (cid:48) < fmin e
f (cid:48) > fmax, os hiperplanos correspondentes n˜ao tˆem interse¸c˜ao com o poliedro de solu¸c˜oes.
Por outro lado, cada hiperplano f (cid:48)(cid:48) para o qual fmin (cid:54) f (cid:48)(cid:48) (cid:54) fmax tem pontos em comum
com o poliedro de solu¸c˜oes.

O conjunto de pontos no quais f alcan¸ca o valor m´ınimo ´e a interse¸c˜ao do poliedro
de solu¸c˜oes com o hiperplano-suporte fmin normal ao vetor (c1, c2, ..., cn); analogamente,
o conjunto de pontos no quais f alcan¸ca o valor m´aximo ´e a interse¸c˜ao do poliedro de
solu¸c˜oes com o hiperplano-suporte fmax normal ao vetor (c1, c2, ..., cn). Tal interse¸c˜ao
pode ser um v´ertice, uma aresta ou uma face do poliedro.

Logo o valor ´otimo da forma linear f no poliedro de solu¸c˜oes se atinge nos pontos
sempre se encontra, mesmo que seja um v´ertice. Por isso, para calcular a solu¸c˜ao ´otima
´e suﬁciente econtrar o v´ertice do poliedro no qual a forma linear f atinge o valor m´aximo
ou m´ınimo, resultado que ser´a demonstrado no cap´ıtulo 5 sobre M´etodo Simplex.

3.4 Redu¸c˜ao de Desigualdades Lineares a Igualdades

Lineares

S˜ao v´alidas neste tema os mesmos teoremas e deﬁni¸c˜oes estudados no APˆENDICE

para sistemas de equa¸c˜oes lineares.

Seja um sistema de m desigualdades lineares com n vari´aveis:

36





a11x1 + a12x2 + ... + a1nxn (cid:54) b1
a21x1 + a22x2 + ... + a2nxn (cid:54) b2
...
am1x1 + am2x2 + ... + amnxn (cid:54) bm,

...

...

...

que determina em um espa¸co n-dimensional um poliedro de solu¸c˜oes.
O sistema dado ainda possui a seguinte representa¸c˜ao alg´ebrica:

n
(cid:80)
j=1

aijxj (cid:54) bi; i = 1, 2, ..., m

ou

ax (cid:54) b.

Considerando, ent˜ao, a inequa¸c˜ao linear dada por

n
(cid:88)

j=1

aijxj (cid:54) bi,

de acordo com as propriedades das desigualdades em R, pode-se aﬁrmar que:

n
(cid:88)

j=1

aijxj = bi ⇔

n
(cid:88)

j=1

aijxj (cid:54) bi

e

n
(cid:88)

j=1

aijxj (cid:62) bi.

Para se resolver o sistema de inequa¸c˜oes lineares, ser´a necess´ario transform´a-lo
num sistema de equa¸c˜oes lineares equivalente. Para explanar como isso pode ser feito,
note que valem as seguintes equivalˆencias:

e

n
(cid:80)
j=1

n
(cid:80)
j=1

aijxj (cid:54) bi ⇔

aijxj (cid:62) bi ⇔

n
(cid:80)
j=1

n
(cid:80)
j=1

aijxj + xn+i = bi, xn+i (cid:62) 0

aijxj − xn+i = bi, xn+i (cid:62) 0.

A vari´avel xn+i ´e conhecida como vari´avel de folga da inequa¸c˜ao i.
Note que, mesmo inserindo as vari´aveis de folga, continua-se com o mesmo con-
n solu¸c˜ao do sistema de

2, ..., x(cid:48)

1, x(cid:48)

junto solu¸c˜ao do sistema. Aﬁnal, considerando x(cid:48)
desigualdades lineares





a11x1 + a12x2 + ... + a1nxn (cid:54) b1
a21x1 + a22x2 + ... + a2nxn (cid:54) b2
...
am1x1 + am2x2 + ... + amnxn (cid:54) bm.

...

...

...

Com isso, pode-se escrever





a11x(cid:48)
a21x(cid:48)
...
am1x(cid:48)

1 + a12x(cid:48)
1 + a22x(cid:48)
...

2 + ... + a1nx(cid:48)
n
2 + ... + a2nx(cid:48)
n
...

1 + am2x(cid:48)

2 + ... + amnx(cid:48)
n

(cid:54) b1
(cid:54) b2
...
(cid:54) bm.

37

1, x(cid:48)




Denotando





µ(cid:48)
1 = b1 − (a11x1 + a12x2 + ... + a1nxn)
µ(cid:48)
2 = b2 − (a21x1 + a22x2 + ... + a2nxn)
...
µ(cid:48)
m = bm − (am1x1 + am2x2 + ... + amnxn),

...

...

...

...

ent˜ao, em primeiro lugar, µ(cid:48)
1

(cid:62) 0, µ(cid:48)
2

deduz do sistema acima, o sistema de n´umeros x(cid:48)
do sistema de equa¸c˜oes lineares.

(cid:62) 0, ..., µm (cid:62) 0; em segundo lugar, como se
1, µ(cid:48)
m ´e a solu¸c˜ao

2, ..., µ(cid:48)

2, ..., x(cid:48)

n, µ(cid:48)

1, x(cid:48)

Reciprocamente, qualquer solu¸c˜ao x(cid:48)

1, x(cid:48)
m do sistema de
(cid:62) 0, ..., µm (cid:62) 0, lhe corres-
equa¸c˜oes formado, que satisfa¸ca a condi¸c˜ao µ(cid:48)
1
ponde uma solu¸c˜ao determinada do sistema de desigualdades. De fato, como o sistema
de n´umeros x(cid:48)

m ´e solu¸c˜ao do sistema, pode-se aﬁrmar que:

n, µ(cid:48)
2, ..., x(cid:48)
(cid:62) 0, µ(cid:48)
2

2, ..., µ(cid:48)

2, ..., µ(cid:48)

2, ..., x(cid:48)

1, µ(cid:48)

n, µ(cid:48)

1, µ(cid:48)

µ(cid:48)
1 + a11x1 + a12x2 + ... + a1nxn = b1
µ(cid:48)
2 + a21x1 + a22x2 + ... + a2nxn = b2
...
...
µ(cid:48)
m + am1x1 + am2x2 + ... + amnxn = bm.
(cid:62) 0, µ(cid:48)
2

...

...

...

De acordo com a suposi¸c˜ao de que µ(cid:48)
1

(cid:62) 0, ..., µm (cid:62) 0, ent˜ao as desigualdades

s˜ao cumpridas:





a11x(cid:48)
a21x(cid:48)
...
am1x(cid:48)

1 + a12x(cid:48)
1 + a22x(cid:48)
...

2 + ... + a1nx(cid:48)
n
2 + ... + a2nx(cid:48)
n
...

1 + am2x(cid:48)

2 + ... + amnx(cid:48)
n

(cid:54) b1
(cid:54) b2
...
(cid:54) bm,

ou seja, o sistema de n´umeros ´e solu¸c˜ao do sistema de desigualdades.

Deste modo, foi estabelecido a existˆencia de uma relacc˜ao rec´ıproca entre o con-
junto de todas as solu¸c˜oes x(cid:48)
2, ..., x(cid:48)
n,
2, ..., µ(cid:48)
1, µ(cid:48)
µ(cid:48)
m do novo sistema, nos quais se encontram os mesmos valores. Observando
(cid:62) 0, ..., µm (cid:62) 0, o problema da resolu¸c˜ao de um sistema de desigualdades
(cid:62) 0, µ(cid:48)
que µ(cid:48)
2
1
lineares se reduz a resolu¸c˜ao de um sistema correspondente de equa¸c˜oes lineares.

n do sistema e o conjunto das solu¸c˜oes x(cid:48)

2, ..., x(cid:48)

1, x(cid:48)

1, x(cid:48)

Exemplo 14.

a) Para o c´alculo das solu¸c˜oes n˜ao-negativas do sistema






2x1 + 3x2 (cid:54) 6
−x1 + x2 (cid:54) 2
−x1 − 3x2 (cid:54) 3,

primeiramente se introduz as vari´aveis de folga x3 (cid:62) 0, x4 (cid:62) 0 e x5 (cid:62) 0, obt´em se o
sistema:






2x1 + 3x2 +x3
−x1 + x2
−x1 − 3x2

+x4

= 6
= 2
+x5 = 3.

38

A qualquer solu¸c˜ao n˜ao-negativa deste sistema de equa¸c˜oes lhe corresponde

uma solu¸c˜ao n˜ao-negativa do sistema inicial.

b) Para o c´alculo das solu¸c˜oes do sistema






x1 + 2x2 + x3 + x4 (cid:54) 8
3x1 + x2 − x3 − x4 (cid:62) 12
4x1 + 3x2 + 3x3 + x4 (cid:54) 10

; x1 (cid:62) 0, x3 (cid:62) 0, x4 (cid:62) 0, x2 ∈ R.

Introduzindo as vari´aveis de folga x5 (cid:62) 0, x6 (cid:62) 0 e x7 (cid:62) 0, obt´em-se o sistema:






x1 + 2x2 + x3 + x4 +x5
3x1 + x2 − x3 − x4
4x1 + 3x2 + 3x3 + x4

−x6

= 8
= 12
+x7 = 10,

sendo

x1 (cid:62) 0, x3 (cid:62) 0, x4 (cid:62) 0, x5 (cid:62) 0, x6 (cid:62) 0, x7 (cid:62) 0 e x2 ∈ R.

Para resolver o problema da vari´avel x2, basta saber que qualqer n´umero pode
ser obtido pela diferen¸ca de dois n´umeros n˜ao-negativos, isto ´e, x2 sem restri¸c˜ao
pode ser escrito como

x2 = x(cid:48)

2 − x(cid:48)(cid:48)

2; x(cid:48)
2

(cid:62) 0, x(cid:48)(cid:48)
2

(cid:62) 0.

Portanto, obt´em-se o novo sistema:






sendo

x1 + 2x(cid:48)
3x1 + x(cid:48)
4x1 + 3x(cid:48)

2 − 2x(cid:48)(cid:48)
2 − x(cid:48)(cid:48)
2 − 3x(cid:48)(cid:48)

2 + x3 + x4 +x5
2 − x3 − x4
2 + 3x3 + x4

−x6

= 8
= 12
+x7 = 10,

x1 (cid:62) 0, x(cid:48)
2

(cid:62) 0, x(cid:48)(cid:48)
2

(cid:62) 0, x3 (cid:62) 0, x4 (cid:62) 0, x5 (cid:62) 0, x6 (cid:62) 0 e x7 (cid:62) 0.

A qualquer solu¸c˜ao n˜ao-negativa deste sistema de equa¸c˜oes lhe corresponde

uma solu¸c˜ao n˜ao-negativa do sistema inicial.

Sempre que n˜ao houver restri¸c˜ao de sinal para qualquer vari´avel xj, basta utilizar

as vari´aveis de folga x(cid:48)
j

(cid:62) 0 e x(cid:48)(cid:48)
j

(cid:62) 0 e fazer xj = x(cid:48)

j − x(cid:48)(cid:48)
j .

Quando se anula o n´umero de inc´ognitas excedentes em rela¸c˜ao ao n´umero de

equa¸c˜oes, a solu¸c˜ao encontrada ´e chamada compat´ıvel b´asica.

39

Cap´ıtulo 4

Programa¸c˜ao Linear

Os problemas de Programa¸c˜ao Linear se referem `a distribui¸c˜ao eﬁciente de recur-
sos limitados entre atividades competitivas, com a ﬁnalidade de atender a um determinado
objetivo, por exemplo, maximiza¸c˜ao de lucros ou minimiza¸c˜ao de custos. Em se tratando
de Programa¸c˜ao Linear, esse objetivo ser´a expresso por uma fun¸c˜ao linear, `a qual se d´a o
nome de fun¸c˜ao objetiva; os recursos equivalem as restri¸c˜oes do problema, tamb´em cha-
mado, em economia, de restri¸c˜ao or¸cament´aria; as atividades equivalem `as inc´ognitas do
problema; e o consumo equivale a propor¸c˜ao desta atividade em cada restri¸c˜ao.

´E claro que ´e necess´ario dizer quais as atividades que consomem cada recurso, e
em que propor¸c˜ao ´e feita esse consumo. Essas informa¸c˜oes ser˜ao fornecidas por equa¸c˜oes
ou inequa¸c˜oes lineares, uma para cada recurso. Ao conjunto dessas equa¸c˜oes ou inequa¸c˜oes
lineares se d´a o nome de restri¸c˜oes do modelo.

Geralmente existem in´umeras maneiras de distribuir os escassos recursos entre as
atividades, bastando para isso que essas distribui¸c˜oes sejam coerentes com as equa¸c˜oes
de consumo de cada recurso, ou seja, que elas satisfa¸cam as restri¸c˜oes do problema.
Entretanto, deseja-se achar aquela distribui¸c˜ao que satisfa¸ca as condi¸c˜oes do problema e
que alcance o objetivo desejado, isto ´e, que maximize o lucro ou minimize o custo, A essa
solu¸c˜ao se d´a o nome de solu¸c˜ao ´otima.

Uma vez obtido o modelo linear, constitu´ıdo pela fun¸c˜ao objetiva e pelas res-
tri¸c˜oes, a Programa¸c˜ao Linear se preocupa em achar a solu¸c˜ao ´otima. Nesse cap´ıtulo
ver-se-´a como isso pode ser obtido, graﬁcamente, quando o modelo apresentar duas ativi-
dades. Se o n´umero de atividades for maior que dois, como acontece na maioria dos casos
reais, s´o ser´a poss´ıvel determinar a solu¸c˜ao ´otima com as t´ecnicas que ser˜ao desenvolvidas
no Cap´ıtulo 5.

4.1 Modelos de Programa¸c˜ao Linear

Veja abaixo dois dos modelos mais conhecidos de Programa¸c˜ao Linear:

(i) Problema da An´alise de Atividades.

Esse problema consiste em encontrar x1, x2, ..., xn que maximize a fun¸c˜ao

linear, isto ´e, a fun¸c˜ao objetiva:

40

f (x1, x2, ..., xn) = c1x1 + c2x2 + ... + cnxn,

sabendo-se que x1, x2, ..., xn devem satisfazer o seguinte sistema de inequa¸c˜oes
lineares, isto ´e, as restri¸c˜oes:





e que

a11x1 + a12x2 + ... + a1nxn (cid:54) b1
a21x1 + a22x2 + ... + a2nxn (cid:54) b2
...
am1x1 + am2x2 + ... + amnxn (cid:54) bm

...

...

...

x1 (cid:62) 0, x2 (cid:62) 0, ..., xn (cid:62) 0.

Pode-se representar esse modelo de forma mais compacta, isto ´e:

max f (x1, x2, ..., xn) =

n
(cid:80)
j=1

cjxj

sujeito `as restri¸c˜oes

n
(cid:80)
j=1

aijxj (cid:54) bi;

i = 1, 2, ..., m

e

xj (cid:62) 0;

j = 1, 2, ..., n.

Este modelo pode ser associado a uma empresa que tem m recursos dispon´ıveis
para a realiza¸c˜ao de n atividades. Suponha-se que as atividades representem a
fabrica¸c˜ao de produtos.

Tem-se, ent˜ao, para j = 1, 2, ..., n e i = 1, 2, ..., m:

(i) bi ´e a quantidade de recurso i dispon´ıvel para as n atividades (bi (cid:62) 0);
(ii) xj ´e o n´ıvel de produ¸c˜ao da ativadade j ; os xj’s s˜ao as inc´ognitas do problema;
(iii) cj ´e o lucro unit´ario do produto j ;
(iv) aij ´e a quantidade de recurso i consumida na produ¸c˜ao de uma unidade do

produto j.

Veriﬁca-se ent˜ao que a fun¸c˜ao objetiva a ser maximizada representa o lucro
total da empresa nessas n atividades, as m restri¸c˜oes bi informam que o total gasto
do recurso i nas n atividades tem de ser menor ou no m´aximo igual a quantidade
bi dispon´ıvel daquele recurso e as restri¸c˜oes xj (cid:62) 0 eliminaram a possibilidade de
n´ıveis negativos para as diversas atividades.

A nota¸c˜ao matricial desse modelo ´e:

41

A =








a11
a12
a21
a22
...
...
am1 am2

· · · a1n
· · · a2n
...
· · · amn








, X =















x1
x2
...
xn

, B =















b1
b2
...
bm

ent˜ao o modelo toma o seguinte aspecto:

, C = (cid:2) c1

c2

· · · cn

(cid:3) ,

max CX sujeito a

AX (cid:54) B
e
X (cid:62) 0.

Exemplo 15. Uma determinada empresa est´a interessada em maximizar o lucro
mensal proveniente de quatro de seus produtos designados por I, II, III e IV. Para
fabricar esses quatro produtos, ele utiliza dois tipos de m´aquinas, M1 e M2, e dois
tipos de m˜ao-de-obra, MO1 e MO2, as quais tˆem as seguintes disponibilidades:

M´aquinas

M1
M2

Tempo Dispon´ıvel
(m´aquina-hora/mˆes)
80
20

M˜ao-de-obra Tempo Dispon´ıvel
(homem-hora/mˆes)
120
160

MO1
MO2

O setor t´ecnico da empresa fornece os seguintes quadros de produtividades:

a) N´umero de m´aquinas-hora para produzir uma unidade de cada produto:

M´aquinas

M1
M2

I
5
2

Produtos
II
4
6

III
8
–

IV
9
8

b) N´umero de homem-hora para produzir uma m´aquina de cada produto:

M˜ao-de-obra

MO1
MO2

I
2
7

Produtos
II
4
3

III
2
–

IV
8
7

O setor comercial da empresa fornece as seguintes informa¸c˜oes:

42

Produtos Potencial de Vendas Lucro Unit´ario
(R$/unidade)
10,00
8,00
9,00
7,00

(unidades/mˆes)
70
60
40
20

I
II
III
IV

Deseja-se saber a produ¸c˜ao mensal dos produtos I, II, III e IV para que
o lucro mensal da empresa, proveniente desses quatro produtos, seja m´aximo.
Formulando um modelo de programa¸c˜ao linear que expresse o objetivo e as
restri¸c˜oes da empresa, tem-se que:

max f (x1, x2, x3, x4) = 10x1 + 8x2 + 9x3 + 7x4

sujeito a

x1

x2

x3

(cid:54) 70
(cid:54) 60
(cid:54) 40
x4 (cid:54) 20





5x1 + 4x2+ 8x3 +9x4 (cid:54) 80
+8x4 (cid:54) 20
2x1 + 6x2
2x1 + 4x2+ 2x3 +8x4 (cid:54) 120
+7x4 (cid:54) 160
7x1 + 3x2
para xj (cid:62) 0;

j = 1, 2, 3, 4,

onde xj, para j = 1, 2, 3, 4, equivalem `as produ¸c˜oes mensais dos produtos I, II,
III e IV, respectivamente.

(ii) Problema da Dieta.

O problema consiste em achar x1, x2, ..., xn que minimize a fun¸c˜ao objetiva

f (x1, x2, ..., xn) = c1x1 + c2x2 + ... + cnxn,

sabendo-se que x1, x2, ..., xn devem satisfazer `as restri¸c˜oes





e que

a11x1 + a12x2 + ... + a1nxn (cid:62) b1
a21x1 + a22x2 + ... + a2nxn (cid:62) b2
...
am1x1 + am2x2 + ... + amnxn (cid:62) bm

...

...

...

x1 (cid:62) 0, x2 (cid:62) 0, ..., xn (cid:62) 0.

Pode-se representar esse modelo de forma mais compacta, isto ´e:

43

min f (x1, x2, ..., xn) =

n
(cid:80)
j=1

cjxj

sujeito a

n
(cid:80)
j=1

aijxj (cid:62) bi; i = 1, 2, ..., m

e

xj (cid:62) 0; j = 1, 2, ..., n.

Este modelo pode ser associado a uma pessoa que deseja minimizar o custo da
sua dieta di´aria. As atividades apresentam os consumos dos alimentos que poder˜ao
entrar na dieta e os recursos s˜ao as vitaminas que n˜ao podem deixar de ser supridas
pela dieta.

Tem-se, ent˜ao, para j = 1, 2, ..., n e i = 1, 2, ..., m:

(i) bi ´e a quantidade m´ınima de vitamina i que deve ser obtida nos n alimentos

(bi (cid:62) 0);

(ii) xj ´e a quantidade de alimento j na dieta; os xj’s s˜ao as inc´ognitas do problema;
(iii) cj ´e o custo unit´ario do alimento j ;
(iv) aij ´e a quantidade da vitamina i fornecida por uma unidade do alimento j.

Veriﬁca-se ent˜ao que a fun¸c˜ao objetiva a ser minimizada representa o custo total
da dieta a ser realizada com os n alimentos, as m restri¸c˜oes indicam que o total de
vitamina i obtida nos n alimentos tem de ser maior ou igual que a quantidade
m´ınima bi daquela vitamina.

A nota¸c˜ao matricial desse modelo ´e:

A =








a11
a12
a21
a22
...
...
am1 am2

· · · a1n
· · · a2n
...
· · · amn








, X =















x1
x2
...
xn

, B =















b1
b2
...
bm

ent˜ao o modelo toma o seguinte aspecto:

min CX sujeito `as restri¸c˜oes

, C = (cid:2) c1

c2

· · · cn

(cid:3) ,

AX (cid:62) B
e
X (cid:62) 0.

Exemplo 16. Uma determinada pessoa ´e for¸cada pelo seu m´edico a fazer uma
dieta alimentar que forne¸ca, diariamente, pelo menos as seguintes quantidades de
vitaminas A, B, C e D:

44

Vitaminas Quantidade m´ınima

A
B
C
D

Di´aria (mg)
80
70
100
60

A dieta dever´a incluir leite, arroz, feij˜ao e carne, que cont´em os seguintes mili-

gramas de vitaminas em cada uma de suas unidades de medida:

Vitaminas

Alimentos
Leite (L) Arroz (Kg) Feij˜ao (Kg) Carne (Kg)

A
B
C
D

10
8
15
20

5
7
3
2

9
6
4
3

10
6
7
9

Os custos unit´arios desses alimentos s˜ao os seguintes:

Alimento Custo unit´ario

Leite
Arroz
Feij˜ao
Carne

(R$)
2,00/L
1,60/Kg
3,00/Kg
10,00/Kg

Deseja-se saber o consumo di´ario de cada um desses alimentos de tal maneira

que a dieta satisfa¸ca as prescri¸c˜oes m´edicas e seja a de menor custo poss´ıvel.

Sejam xj, com j = 1, 2, 3, 4, as quantidades de leite, arroz, feij˜ao e carne,
medidas nas unidades acima, que dever˜ao entrar, diariamente, na citada dieta. O
modelo ent˜ao ser´a:

min 2x1 + 1, 6x2 + 3x3 + 10x4

sujeito a






10x1 + 5x2 + 9x3 + 10x4 (cid:62) 80
8x1 + 7x2 + 6x3 + 6x4 (cid:62) 70
15x1 + 3x2 + 4x3 + 7x4 (cid:62) 100
20x1 + 2x2 + 3x3 + 9x4 (cid:62) 60
para xj (cid:62) 0;
j = 1, 2, 3, 4.

(iii) Problema do transporte.

O modelo dos transportes tem por objetivo minimizar o custo total do trans-
porte necess´ario para abastecer n centros consumidores, chamados destinos, a partir
de m centros fornecedores, chamados origens. Pode ser assim esquematizado:

45

a1

a2

aij

b1

b2

bj

1

2

...

i

...

ci1

xi1

cij
xij

cin

xin

1

2

...

j

...

am

m

n

bn

Para i = 1, 2, ..., m e j = 1, 2, ..., n, tem-se:

(i) cij ´e o custo unit´ario de transporte da origem i para o destino j ;
(ii) ai ´e a quantidade dispon´ıvel na origem i ;
(iii) bj ´e a quantidade requerida no destino j ;
(iv) xij ´e a quantidade a ser transportada da origem i para o destino j, as quais

s˜ao as inc´ognitas do problema.

O problema consiste em encontrar os valores de xij que minimize o custo total

de transporte:

f =

m
(cid:88)

n
(cid:88)

i=1

j=1

cijxij,

sabendo-se que os x(cid:48)

ij devem satisfazer `as seguintes restri¸c˜oes de oferta e demanda:

n
(cid:88)

j=1

m
(cid:88)

i=1

xij = ai,

i = 1, 2, ..., m;

xij = bj,

i = 1, 2, ..., n;

x (cid:62) 0.

As m restri¸c˜oes de oferta, uma para cada origem, indicam que a quantidade
que sai da origem i tem de ser igual `a quantidade ai dispon´ıvel, assim como as n
restri¸c˜oes de demanda, uma para cada destino, indicam que a quantidade que chega
a cada destino j tem de ser igual `a quantidade bj requerida por aquele destino.

46

(cid:70)
(cid:70)
(cid:47)
(cid:47)
(cid:28)
(cid:28)
Os exemplos deste modelo ser˜ao feitos no pr´oximo cap´ıtulo por apresentar uma
particularidade especial, al´em disso, todos esses modelos apresentados ser˜ao resol-
vidos no pr´oximo cap´ıtulo com a utiliza¸c˜ao do M´etodo Simplex.

4.2 Solu¸c˜ao Gr´aﬁca

Para o desenvolvimento desta se¸c˜ao e do cap´ıtulo 5 ´e necess´ario enunciar e de-
monstrar os teoremas nos quais o m´etodo gr´aﬁco e o M´etodo Simplex se baseiam para se
entender, perfeitamente, seus funcionamentos. Tais teoremas foram provados por Dantzig
em 1951.

Teorema 4.2.1. O conjunto de todas as solu¸c˜oes compat´ıveis do modelo de programa¸c˜ao
linear ´e um conjunto convexo.

Demonstra¸c˜ao.

Considere um modelo de programa¸c˜ao linear com a seguinte nota¸c˜ao matricial:

max CX sujeito a

AX (cid:54) B
e
X (cid:62) 0.

Seja S o conjunto formado por AX (cid:54) B e x (cid:62) 0. Tem-se de provar que o conjunto

S ´e convexo. Para isso, basta demonstrar que

X1 ∈ S
X2 ∈ S
X1 (cid:54)= X2






que equivale a

(cid:26) X = αX1 + (1 − α)X2 ∈ S
0 (cid:54) α (cid:54) 1.

Sejam X1 e X2 duas solu¸c˜oes compat´ıveis quaisquer, ent˜ao:

AX1 (cid:54) B
X1 (cid:62) 0
(cid:27)

AX2 (cid:54) B
X2 (cid:62) 0

(cid:27)

αAX1 (cid:54) αB,

(1 − α)AX2 (cid:54) (1 − α)B.

Considere-se o vetor

Tem-se de provar que

X = αX1 + (1 − α)X2
0 (cid:54) α (cid:54) 1.

X (cid:62) 0
AX (cid:54) B.
Como X1 (cid:62) 0, X2 (cid:62) 0 e 0 (cid:54) α (cid:54) 1, ent˜ao X (cid:62) 0, al´em disso tem-se que:

47

AX = A[αX1 + (1 − α)]X2
= αAX1 + (1 − α)AX2
(cid:54) αB + (1 − α)B
(cid:54) B.

De modo an´alogo, pode-se demonstrar nos casos em que

AX = B ou AX (cid:62) B.

Teorema 4.2.2. Toda solu¸c˜ao compat´ıvel b´asica do sistema AX = B ´e um ponto extremo
do conjunto das solu¸c˜oes compat´ıveis, isto ´e, do conjunto convexo S.

(cid:4)

Demonstra¸c˜ao.

Considere o conjunto convexo formado por

De maneira expl´ıcita tem-se

AX = B
x (cid:62) 0.








a11
a21
...
am1

· · · a1m a1 m+1
· · · a2m a2 m+1
...

...

· · · amm am m+1

· · · a1n
· · · a2n
...
· · · amn






















x1
x2
...
xn








.








b1
b2
...
bm

=

Considere-se a solu¸c˜ao compat´ıvel b´asica formada pelo vetor X, de dimens˜ao n,

abaixo:

X =























x1
...
xm
0
...
0

,

com todos os xi (cid:62) 0, i = m + 1, ..., n.

Suponha-se que X n˜ao seja um ponto extremo do conjunto S. Ent˜ao X pode
ser obtido como uma combina¸c˜ao convexa de outros dois pontos distintos do conjunto S.
Sendo Y e Z esses dois pontos, pode-se ter

X = αY + (1 − α)Z
0 (cid:54) α (cid:54) 1.
Como Y e Z pertencem ao conjunto C, as seguintes rela¸c˜oes s˜ao v´alidas:

AY = B
Y (cid:62) 0

AZ = B
Z (cid:62) 0.

e

48

Se X for um ponto extremo de S, ent˜ao n˜ao existem Y e Z, distintos de X que

satisfa¸cam a combina¸c˜ao convexa.

A combina¸c˜ao convexa colocada em termos das coordenadas de cada um dos trˆes

vetores, fornece as seguintes rela¸c˜oes:






αy1 + (1 − α)z1
αy2 + (1 − α)z2
...
αym + (1 − α)zm

x1 =
x2 =
...
xm =
0 = αym+1 + (1 − α)zm+1
...
0 =

...
αyn + (1 − α)zn.
Devido `as rela¸c˜oes 0 (cid:54) α (cid:54) 1, Y (cid:62) 0 e Z (cid:62) 0, as ´ultimas n − m rela¸c˜oes s´o podem

ser satisfeitas nos seguintes casos:

(i) 0 < α < 1 e ym+i = zm+i = 0 para i = 1, 2, ..., n − m.

Neste caso, ter-se-ia X = Y = Z pois as trˆes solu¸c˜oes apresentam uma coin-
cidˆencia nas vari´aveis n˜ao-b´asicas do sistema, consequentemente, os valores das
vari´aveis b´asicas ser˜ao os mesmos para essas trˆes solu¸c˜oes.

(ii) α = 0 e zm+i = 0, para i = 1, 2, ..., n − m.

Neste caso ter-se-ia X = Z pelas mesmas raz˜oes anterioires.

(iii) α = 1 e ym+i = 0, para i = 1, 2, ..., n − m.

Neste caso ter-se-ia X = Y pelas mesmas raz˜oes anteriores.

Portanto, n˜ao existem solu¸c˜oes compat´ıveis Y e Z, distintas da solu¸c˜ao compat´ıvel
b´asica X, que satisfa¸cam a combina¸c˜ao convexa, logo o ponto X ´e um ponto extremo do
conjunto convexo.

(cid:4)

Teorema 4.2.3.

(i) Se a fun¸c˜ao objetiva possui um m´aximo ou m´ınimo ﬁnito, ent˜ao pelo menos uma

solu¸c˜ao ´otima ´e um ponto extremo do conjunto convexo S;

(ii) Se a fun¸c˜ao objetiva assume o m´aximo ou m´ınimo em mais de um ponto extremo,
ent˜ao ela toma o mesmo valor para qualquer combina¸c˜ao convexa desses pontos
extremos.

Demonstra¸c˜ao.

(i) Seja S o conjunto convexo deﬁnido por

AX = B
X (cid:62) 0.

49

e seja f (x) a fun¸c˜ao objetiva que toma o valor m´aximo M no ponto x0, ent˜ao pode-se
aﬁrmar que

f (x0) (cid:62) f (x),

para todo x ∈ S.

Sejam ¯x1, ¯x2, ..., ¯xp os pontos extremos do conjunto S. Tem-se de provar que

x0 ´e um desses pontos extremos.

Suponha-se que x0 n˜ao seja um ponto extremo de S. Ent˜ao ele pode ser obtido

pela combina¸c˜ao convexa abaixo:

sendo

x0 =

p
(cid:88)

i=1

αi ¯xi,

αi (cid:62) 0,
p
(cid:88)

i=1

i = 1, ..., p

αi = 1.

Usando-se essas rela¸c˜oes, tem-se que:

f (x0) = f

(cid:33)

α¯xi

(cid:32) p

(cid:88)

i=1

= f (α1 ¯x1 + α2 ¯x2 + ... + αp ¯xp)
= α1f (¯x1) + α2f (¯x2) + ... + αpf (¯xp)
= M.

Considere-se agora que o ponto extremo ¯xM deﬁnido pela rela¸c˜ao abaixo

f (¯xM ) = max f (¯xi); i = 1, ..., p.

Portanto, pode-se aﬁrmar que:

f (x0) (cid:54) α1f (¯x1) + α2f (¯x2) + ... + αpf (¯xp)

(cid:54) f (¯xM )

p
(cid:88)

i=1

αi

(cid:54) f (¯xM ).

Como, pela hip´otese da demonstra¸c˜ao, f (x0) (cid:62) f (x) para todo x ∈ S, ent˜ao ´e
necess´ario ter

50

f (x0) = M = f (¯xM ),

e ﬁca provado que a solu¸c˜ao ´otima x0 ´e um ponto extremo do conjunto S.

(ii) Sejam ¯x1, ¯x2, ..., ¯xp os pontos extremos do conjunto convexo S, nos quais se assume

que

f (¯x1) = f (¯x2) = ... = f (¯xp) = M.

Considerando a combina¸c˜ao convexa

x =

q
(cid:88)

i=1

αi ¯xi,

αi (cid:62) 0,
q
(cid:88)

i=1

i = 1, ..., q;

αi = 1,

sendo

tem-se que:

f (x) = f

(cid:33)

αi ¯xi

(cid:32) q

(cid:88)

i=1

= f (α1 ¯x1 + α2 ¯x2 + ... + αq ¯xq)
= α1f (¯x1) + α2f (¯x2) + ... + αqf (¯xq)

= M

q
(cid:88)

i=1

αi

= M.

Teorema 4.2.4. Se existe uma solu¸c˜ao compat´ıvel, ent˜ao existe tamb´em uma solu¸c˜ao
compat´ıvel b´asica.

A necessidade do Teorema 4.24 ´e devida ao fato de um modelo de programa¸c˜ao

linear poder n˜ao apresentar nenhuma solu¸c˜ao compat´ıvel.

Exemplo 17.

(cid:4)

51

a) Considere o seguinte modelo de Programa¸c˜ao Linear:

max f = 2x1 + x2

sujeito a






x1 + x2 (cid:62) 1
3x1 + 4x2 (cid:62) 12
x1 − x2 (cid:54) 2
−2x1 + x2 (cid:54) 2
x1 (cid:62) 0, x2 (cid:62) 0.

Como este modelo s´o possui duas vari´aveis, ele pode ser resolvido graﬁcamente.
Marcando-se as restri¸c˜oes do problema tem-se a seguinte representa¸c˜ao segundo a
Figura 4.1:

Figura 4.1:

Qualquer ponto do pol´ıgono ABCDEF satisfaz todas as restri¸c˜oes do modelo e
se diz que ele ´e o conjunto das solu¸c˜oes compat´ıveis do modelo. Para encontrar a
solu¸c˜ao ´otima, marca-se a reta 2x1 + x2 = 0 e depois se desenha suas paralelas nos
v´ertices do pol´ıgono ABCDEF. O maior valor encontrado corresponde ao m´aximo
de f , que neste caso foi 46/7.

b) Considere o conjunto de restri¸c˜oes:






x1

(cid:54) 2
(cid:54) 1
x2
2x1 +5x2 (cid:62) 10
x1 (cid:62) 0, x2 (cid:62) 0.

Como este modelo s´o possui duas vari´aveis, ele pode ser resolvido graﬁcamente.
Marcando-se as restri¸c˜oes do problema tem-se a seguinte representa¸c˜ao segundo a
Figura 4.2:

52

Figura 4.2:

Note que a interse¸c˜ao dos semi-planos ´e vazia, isto ´e, n˜ao existe a interse¸c˜ao
das restri¸c˜oes simultaneamente. Quando isso ocorre, diz-se que n˜ao h´a solu¸c˜oes
poss´ıveis.

c) Considere o politopo dado pelas restri¸c˜oes:

(cid:26) −2x1 + x2 (cid:54) 2
x1 − 3x2 (cid:54) 3
x1 (cid:62) 0, x2 (cid:62) 0.

Como este modelo s´o possui duas vari´aveis, ele pode ser resolvido graﬁcamente.
Marcando-se as restri¸c˜oes do problema tem-se a seguinte representa¸c˜ao segundo a
Figura 4.3:

Figura 4.3:

Toda fun¸c˜ao objetiva entre as duas retas traz uma solu¸c˜ao dita solu¸c˜ao ´otima

ilimitada.

d) Considere o problema de programa¸c˜ao linear:

max f = x1 + x2

sujeito a




x1 + x2 (cid:62) 1
x1 + x2 (cid:54) 2
x1 − x2 (cid:54) 2

x1 (cid:62) 0, x2 (cid:62) 0.

53

Como este modelo s´o possui duas vari´aveis, ele pode ser resolvido graﬁcamente.
Marcando-se as restri¸c˜oes do problema tem-se a seguinte representa¸c˜ao segundo a
Figura 4.4:

Figura 4.4:

Note que B e C s˜ao ambos pontos extremos e, al´em disso, solu¸c˜oes ´otimas. Na
verdade, todos os pontos do segmento BC s˜ao pontos ´otimos. Diz-se que se tem
uma dupla degenera¸c˜ao.

e) Considere o politopo deﬁnido pelas restri¸c˜oes:






4x1 + 2x2 (cid:54) 9
2x1 + 3x2 (cid:54) 6
6x1 + 5x2 (cid:54) 15
x1 (cid:62) 0, x2 (cid:62) 0.

Como este modelo s´o possui duas vari´aveis, ele pode ser resolvido graﬁcamente.
Marcando-se as restri¸c˜oes do problema tem-se a seguinte representa¸c˜ao segundo a
Figura 4.5:

Figura 4.5:

Note que as trˆes retas se intersectam no ponto A e independe da fun¸c˜ao objetiva.

Neste caso, diz-se que se tem uma degenera¸c˜ao prim´aria.

54

4.3 Limita¸c˜oes da Programa¸c˜ao Linear

Uma vez estudados os modelos de Programa¸c˜ao Linear, conv´em fazer uma ressalva

sobre as suas hip´oteses e limita¸c˜oes.

(i) Coeﬁcientes Constantes.

Nos modelos de Programa¸c˜ao Linear os coeﬁcientes aij, bi e cj s˜ao considerados

como constantes conhecidas.

A an´alise de sensibilidade do modelo permite fornecer a melhor aproxima¸c˜ao

desses coeﬁcientes, para os quais a solu¸c˜ao ´otima continua a mesma.

(ii) Divisibilidade.

As solu¸c˜oes ´otimas dos modelos de Programa¸c˜ao Linear estudados nesta dis-
serta¸c˜ao poder˜ao apresentar valores fracion´arios para qualquer uma de suas vari´aveis.
Assim, por exemplo, se uma vari´avel representar o n´umero de cadeiras a serem pro-
duzidas por uma empresa, ela poderia tomar um valor fracion´ario na solu¸c˜ao ´otima,
o que n˜ao ´e nada desej´avel. O arredondamento de valores fracion´arios para valores
inteiros mais pr´oximos pode conduzir a erros bastantes grosseiros.

Quando as vari´aveis do modelo de Programa¸c˜ao Linear s´o puderem tomar va-
lores inteiros, devem-se impor essas condi¸c˜oes no pr´oprio modelo. Passa-se ent˜ao a
lidar com um modelo de Programa¸c˜ao Inteira, que n˜ao poder´a ser resolvido com as
t´ecnicas desenvolvidas nesta disserta¸c˜ao.

(iii) Proporcionalidade.

Nos modelos de Programa¸c˜ao Linear se assumem, por exemplo, que o lucro de
cada atividade ´e proporcional ao n´ıvel de produ¸c˜ao xj, sendo o lucro unit´ario cj o
coeﬁciente de proporcionalidade. Essa hip´otese diz que o lucro unit´ario cj independe
do n´ıvel de produ¸c˜ao xj e n˜ao considera a chamada economia de escala, n˜ao sendo
v´alida na maioria dos problemas reais. Para atenu´a-la, pode-se considerar intervalos
de produ¸c˜ao nos quais essa proporcionalidade ´e, aproximadamente, veriﬁcada.

Para o caso dos coeﬁcientes aij tamb´em se assume que eles s˜ao independentes

do n´ıvel de produ¸c˜ao xj, qualquer que seja o recurso bi.

(iv) Aditividade.

A condi¸c˜ao de aditividade, existente em todos os modelos de Programa¸c˜ao
Linear, consiste em considerar as atividades do modelo como entidades totalmente
independentes, n˜ao permitindo que haja interdependˆencia entre as mesmas.

Assim, por exemplo, o lucro total de uma empresa ser´a sempre igual a soma
dos lucros parciais de cada atividade. Para mostrar que isso nem sempre ´e verdade,
considere uma empresa que deseja produzir dois produtos, bastante similares, como
por exemplo, manteiga e magarina. Se tal empresa produzir apenas manteiga, o seu
lucro ser´a c1x1, sendo c1 o lucro unit´ario da manteiga e x1 o seu n´ıvel de produ¸c˜ao.
Se a mesma empresa produzir apenas margarina, o seu lucro ser´a c2x2, sendo c2 o
lucro unit´ario da margarina e x2 o seu n´ıvel de produ¸c˜ao. Caso a empresa resolva

55

produzir tanto manteiga como margarina e colocar no mercado os dois produtos, o
modelo de Programa¸c˜ao Linear garante que o lucro total desses dois produtos ser´a
igual a c1x1 + c2x2. O que n˜ao foi levado em considera¸c˜ao ´e que os valores de c1
e c2 n˜ao dever˜ao ser iguais aos anteriores, pois ´e poss´ıvel que o pre¸co de venda da
margarina interﬁra no pre¸co de venda da manteiga, desde que tais produtos sejam
competitivos.

Racioc´ınio an´alogo pode ser feito para o caso dos coeﬁcientes aij do modelo de

Programa¸c˜ao Linear.

Apesar de todas essas limita¸c˜oes, a Programa¸c˜ao Linear ainda ´e a ferramenta
mais utilizada na resolu¸c˜ao de problemas reais que envolvam formula¸c˜ao de modelos ma-
tem´aticos. Isso se deve n˜ao somente `a sua simplicidade, como tamb´em ao fato de o modelo
sempre poder ser resolvido com as t´ecnicas que ser˜ao vistas no Cap´ıtulo 5. Conv´em res-
saltar que os problemas reais, na maioria das vezes, ter˜ao de ser solucionados mediante o
uso de computadores, pois o n´umero de equa¸c˜oes e vari´aveis, normalmente, impossibilita
os c´alculos manuais.

56

Cap´ıtulo 5

M´etodo Simplex

Neste cap´ıtulo, desenvolver-se-´a uma das principais t´ecnicas utilizadas para achar,
algebricamente, a solu¸c˜ao ´otima de um problema de programa¸c˜ao linear. O processo que
ser´a utilizado para realizar tal tarefa ´e chamado M´etodo Simplex.

Desde que exista uma solu¸c˜ao ´otima para um modelo de Programa¸c˜ao Linear, o

M´etodo Simplex sempre conseguir´a obtˆe-la.

Utilizar-se-´a, no desenvolvimento deste cap´ıtulo, um modelo de duas vari´aveis
de f´acil resolu¸c˜ao para se comparar, passo a passo, o m´etodo alg´ebrico com o gr´aﬁco,
estudado na se¸c˜ao anterior.

5.1 Rela¸c˜ao entre o m´etodo gr´aﬁco e o alg´ebrico

Nesta se¸c˜ao, percebe-se a forte rela¸c˜ao que h´a entre os m´etodos de solu¸c˜ao geom´etrico

e alg´ebrico. Primeiramente, considere o seguinte modelo de programa¸c˜ao linear:

Figura 5.1:

57

max f = 5x1 + 2x2

sujeito a






x1

(cid:54) 3
x2 (cid:54) 4
x1 +2x2 (cid:54) 9
x1 (cid:62) 0, x2 (cid:62) 0.

Como este modelo possui somente duas vari´aveis, ele pode ser resolvido graﬁca-
mente. Marcando-se as restri¸c˜oes do problema tem-se a representa¸c˜ao segundo a Figura
5.1.

Portanto, o valor m´aximo de f ´e 21, que corresponde ao v´ertice C.
Resolvendo algebricamente, acrescenta-se as vari´aveis de folga x3, x4 e x5, transformando-

se o sistema de inequa¸c˜oes no sistema de equa¸c˜oes lineares, com todas as vari´aveis n˜ao-
negativas:






x1

x2
x1 +2x2

+x3

+x4

= 3
= 4
+x5 = 9

x1, x2, x3, x4, x5 (cid:62) 0.

Espera-se que o conjunto das solu¸c˜oes compat´ıveis dos dois sistemas sejam idˆenticos
ao trape´ezio ABCDE. Para se comprovar tal fato, precisa-se representar graﬁcamente o
novo sistema. Primeiramente, transformando-se as restri¸c˜oes para:






x1

= 3 − x3
x2 = 4 − x4
x1 +2x2 = 9 − x5
x1, x2, x3, x4, x5 (cid:62) 0.

Pode-se veriﬁcar que as restri¸c˜oes s˜ao idˆenticas, aﬁnal, note, por exemplo, que as
restri¸c˜oes x1 (cid:54) 3 e x1 (cid:62) 0 s˜ao equivalentes as restri¸c˜oes x1 = 3 − x3 e x1, x3 (cid:62) 0, pois
representam a mesma fam´ılia de retas perpendiculares ao eixo x1, e o mesmo pode se
concluir para as demais restri¸c˜oes, concluindo-se que realmente ambas as desigualdades
representam o mesmo conjunto de solu¸c˜oes compat´ıveis equivalente ao trap´ezio ABCDE.
Sendo ambos os sistemas equivalentes, para se obter os v´ertices A, B, C, D e E a

partir do sistema de equa¸c˜oes lineares, basta proceder da seguinte maneira:

V´ertice A = (0,0):

Fazendo x1 = 0 e x2 = 0, tem-se que:

x3 = 3,

x4 = 4 e x5 = 9.

V´ertice B = (3,0):

Fazendo x1 = 3 e x2 = 0, tem-se que:

x3 = 0,

x4 = 4 e x5 = 6.

58

V´ertice C = (3,3):

Fazendo x1 = 3 e x2 = 3, tem-se que:

x3 = 0,

x4 = 1 e x5 = 0.

V´ertice D = (1,4):

Fazendo x1 = 1 e x2 = 4, tem-se que:

x3 = 2,

x4 = 0 e x5 = 0.

V´ertice E = (0,4):

Fazendo x1 = 0 e x2 = 4, tem-se que:

Pode-se, ent˜ao, associar esses v´ertices aos seguintes vetores:

x3 = 3,

x4 = 0 e x5 = 1.

A =

















0
0
3
4
9

, B =

















3
0
0
4
6

, C =

















3
3
0
1
0

, D =

















1
4
2
0
0

e E =









.









0
4
3
0
1

Note que cada v´ertice do trap´ezio, isto ´e, cada ponto extremo do conjunto das
solu¸c˜oes compat´ıveis do sistema de inequa¸c˜oes ´e uma solu¸c˜ao compat´ıvel b´asica do sistema
de equa¸c˜oes, como foi provado no Cap´ıtulo 4.

5.2 O M´etodo Simplex

Primeiramente, ter-se-´a um estudo mais sistem´atico do M´etodo Simplex, deﬁnindo-
se os principais conceitos e demonstrando teoremas importantes para seu desenvolvimento.

Deﬁni¸c˜ao 18. Um conjunto B = {1, ..., n} de n elementos ´e chamado uma base para a
programa¸c˜ao linear se, e somente se, a submatriz AB de A tem posto n. Neste caso, diz-se
que AB ´e uma matriz b´asica para a programa¸c˜ao linear.

Exemplo 18. Seja a matriz

1
de ordem 2 × 4 e posto m´aximo igual a 2.

A =

(cid:20) 1 −1 1 0
0 1
0

(cid:21)

,

Se B = {1, 3}, est´a-se elegendo as colunas 1 e 3, respectivamente, e, com isso,

tem-se que:

que ´e uma matriz b´asica, aﬁnal o posto de AB ´e igual a 2.

AB =

(cid:20) 1 −1
0
1

(cid:21)

,

59

Deﬁni¸c˜ao 19. Um vetor x ∈ Rn ´e um vetor b´asico, se existe uma matriz b´asica AB tal
que xB = A−1
B b e os outros componentes de x s˜ao iguais a zero. Se um vetor b´asico ´e n˜ao
negativo, ent˜ao ele ´e chamado de vetor b´asico compat´ıvel.

Exemplo 19. Tomando o Exemplo 18, considerando-se o vetor

b =

(cid:20) 1
1

(cid:21)

,

tem-se que, para {1, 2}, {1, 3}, {1, 4}, {2, 4} e {3, 4} s˜ao bases e, portanto, as correspon-
dentes matrizes s˜ao b´asicas.

Ap´os fazer os c´alculos, pode-se observar que todas as matrizes s˜ao compat´ıveis,

exceto para B = {2, 4}.

Teorema 5.2.1. Um vetor ¯x ´e um vetor b´asico compat´ıvel se, e somente se, existe um
vetor d ∈ Rn n˜ao-nulo tal que ¯x ´e a ´unica solu¸c˜ao de

Demonstra¸c˜ao.

(i) Condi¸c˜ao suﬁciente:

Seja ¯x a solu¸c˜ao ´unica de

dT x.

min
x∈F

dT x.

min
x∈F

Deﬁnindo-se I = {i ∈ {1, ..., n} : ¯xi > 0}, tem-se que:

Caso 1: Se I = ∅, ent˜ao ¯x = 0 e b = 0. Como o posto de A ´e igual a m, tem-se

que existe uma base B, para a qual se tem que:

0 = ¯xB = A−1

B b = A−1

B 0.

Com isso, tem-se que ¯x ´e um vetor compat´ıvel.

Caso 2: Se I (cid:54)= ∅, suponha que os vetores {Ai}i∈I s˜ao linearmente dependentes,

ent˜ao existe y ∈ Rn n˜ao-nulo tal que:

Com isso, tem-se que:

Al´em disso:

portanto:

−¯x (cid:54) y (cid:54) ¯x.

¯x ± y (cid:62) 0.

A(¯x ± y) = A¯x = b,

60

cT ¯x < cT (¯x ± y).

Somando-se as duas ´utimas desigualdades, tem-se que cT ¯x < cT ¯x, que ´e um
absurdo.
Logo, os vetores {Ai}i∈I s˜ao linearmente independentes. Mas como o posto de
A ´e igual a m, ent˜ao I ´e uma base se I tem m elementos, caso contr´ario se
completa I at´e que se obtenha uma base compat´ıvel B. Portanto:

(cid:88)

i∈B

¯xiAi =

(cid:88)

i∈I

¯xiAi = b,

pois ¯xi = 0, ∀ i /∈ I. Isto implica que ¯x ´e um vetor b´asico compat´ıvel.

(ii) Condi¸c˜ao necess´aria:

Seja ¯x um vetor b´asico compat´ıvel cuja base ´e B. Deﬁnindo-se I = {i ∈ {1, ..., n} :
¯xi > 0} e d ∈ Rn tal que di = 0 se i ∈ I e di = 1 se i /∈ I. Portanto, d tem
componentes inteiras n˜ao-negativas e dT ¯x = 0. Como d (cid:62) 0 e x (cid:62) 0, ∀ x ∈ F , ent˜ao
dT x (cid:62) 0, ∀ x ∈ F . Isto implica que ¯x ´e uma solu¸c˜ao de

dT x,

min
x∈F

onde F ´e um poliedro.
Tomando-se qualquer y ∈ F tal que dT y = 0, por deﬁni¸c˜ao de d, tem-se que yi =
0, ∀ i /∈ I, em particular, yi = 0, ∀ i /∈ B. Portanto:

(cid:88)

i∈B

¯xiAi −

(cid:88)

i∈B

yiai = A¯x − Ay = b − b = 0.

Como {Ai}i∈B sˆao linearmente independentes e (cid:80)
¯xi = yi, ∀ i ∈ B. Portanto, ¯x = y, o qual prova que ¯x ´e a ´unica solu¸c˜ao de:

(¯xi − yi)Ai = 0, implicam que

i∈B

dT x.

min
x∈F

(cid:4)

Teorema 5.2.2. ¯x ´e um vetor b´asico fact´ıvel se, e somente se, ¯x ´e um vetor extremo do
poliedro F .

Demonstra¸c˜ao.

Seja ¯x um vetor b´asico compat´ıvel; ent˜ao existe um vetor d ∈ Rn n˜ao-nulo que ¯x ´e

solu¸c˜ao ´unica de:

Tomando-se α = dT ¯x, tem-se que o hiperplano

dT x.

min
x∈F

61

H = {x ∈ Rn : dT x = α}

intersecta F em um ´unico ponto e F ⊂ H +. Portanto, tem-se que ¯x ´e um ponto

extremo de F .

Agora, seja ¯x um vetor extremo de F ; ent˜ao F \ {¯x} ´e um conjunto convexo, portanto
existe um hiperplano H que separa ¯x de F , isto ´e, existe d ∈ Rn \ {0} tal que ¯x ´e o ´unico
(cid:4)
minimizador de min
x∈F

dT x, logo ¯x ´e um vetor b´asico compat´ıvel.

A consequˆencia do Teorema 5.2.2 e da deﬁni¸c˜ao de base ´e que F tem um n´umero
ﬁnito de vetores extremos, dada as formas que se podem construir as bases a partir das
escolhas de m n´umeros dentre n poss´ıveis, tornando-se um problema combinat´orio.

Teorema 5.2.3.

(i) Se F (cid:54)= ∅, ent˜ao existe pelo menos um vetor b´asico compat´ıvel;

(ii) Se o problema de programa¸c˜ao linear tem solu¸c˜ao, ent˜ao existe um vetor compat´ıvel

que ´e solu¸c˜ao deste problema.

Demonstra¸c˜ao.

Prova de (i):

Seja x ∈ F e deﬁna I = {i ∈ N : xi > 0}, onde N = {1, ..., n}. Considere o seguinte
processo iterativo com o objetivo de construir uma base compat´ıvel a partir de I,
sabendo-se que {Ai}i∈I s˜ao vetores linearmente dependentes:

1. Elija y ∈ Rn n˜ao-nulo tal que:

(cid:88)

i∈I

yiAi = 0 e yj = 0, ∀ j /∈ I.

Note que tal y existe pois os vetores {Ai}i∈I s˜ao vetores linearmente depen-
dentes.

2. Calcule:

xr
yr

= min

(cid:26) xj
yj

(cid:27)

: yj > 0

.

Isto ´e poss´ıvel, pois se pode considerar, sem perda de generalidade, que h´a
componente positiva, caso contr´ario, considere −y em vez de y.

3. Deﬁna z ∈ Rn tal que:

Note que zi (cid:62) 0.

zi = xi −

xy
yr

yi, ∀ i ∈ N.

62

4. Fa¸ca:

J = {i ∈ N : zi > 0}.

Note que J ⊂ I \ {r}.

5. Atualize x = z, I = J e retorne ao passo 1.

Observe que este processo termina com vetores {Ai}i∈I linearmente independentes.
Portanto, se necess´ario, completa-se I at´e que se obtenha uma base B, pois:

(cid:88)

i∈I

xiAi =

(cid:88)

i∈B

xiAi = ABxB = b,

logo xB = A−1

B b (cid:62) 0, portanto x ´e um vetor b´asico compat´ıvel.

Prova de (ii):

Seja ¯x uma solu¸c˜ao de um problema de programa¸c˜ao linear; sabe-se que:

min
x∈F

cT x = min
x∈E

cT x,

onde E ´e o conjunto de vetores extremos do poliedro F . Portanto, ¯x ∈ E e, ent˜ao,

¯x =

k
(cid:80)
i=1

λixi onde

k
(cid:80)
i=1

λi = 1, λi > 0 e xi ∈ E, que implica:

0 (cid:54) λicT xi − λicT ¯x (cid:54)

k
(cid:88)

i=1

cT (λixi) +

k
(cid:88)

i=1

cT (λi ¯x) = cT ¯x − cT ¯x = 0.

Logo cT xi = cT ¯x o qual implica que xi ´e uma solu¸c˜ao do problema de programa¸c˜ao
linear para cada i = 1, ..., k.
Pelo Teorema 5.2.2, tem-se que os vetores xi s˜ao vetores b´asicos admiss´ıveis.

(cid:4)

O Teorema 5.2.3 diz que basta se preocupar com os vetores extremos e seus
valores funcionais para resolver um problema de programa¸c˜ao linear na forma “standard ”
e calcular aquele cuja fun¸c˜ao objetiva assume o valor m´ınimo ou m´aximo.

Com isso, o algoritmo do M´etodo Simplex ´e dado por:

Dados de entrada: Sejam m, n ∈ N, c ∈ Rn, b ∈ Rm e A ∈ Rm×n uma matriz de posto

m.

Passo 1: Encontrar uma base B tal que AB seja uma matriz b´asica compat´ıvel. Se n˜ao
existe, ent˜ao pare pois o problema n˜ao possui solu¸c˜ao; caso contr´ario, calcule:

B , ¯b = A−1
A−1

B b e cB.

63

Passo 2: Calcule

¯cT = cT − cT

BA−1

B A.

Se ¯c (cid:62) 0, ent˜ao pare, pois ¯x ´e tal que ¯x = ¯b e ¯xR = 0 ´e solu¸c˜ao; caso contr´ario,
escolha j ∈ {k ∈ {1, ..., n} : ¯ck < 0}.

Passo 3: Calcule

Yj = A−1

B Aj.

Se Yj (cid:54) 0, ent˜ao pare, pois o problema de programa¸c˜ao linear n˜ao tem solu¸c˜ao; caso
contr´ario, calcule r ∈ {1, ..., m} tal que

Passo 4: Atualize

e calcular

¯br
yrj

= min

(cid:26) ¯bi
yij

(cid:27)

: yij > 0

.

B = {B \ {B(r)}} ∪ {j},

B , ¯b = A−1
A−1

B b e cB.

Note que, dada uma base B ⊂ {1, ..., n}, B pode ser considerado como um vetor

de Rm, onde as componentes de B s˜ao os ´ındices da base B.

Exemplo 20. Se

n = 5, m = 3 e B =



 ,





4
2
5

ent˜ao a matriz b´asica est´a formada pelas colunas 4, 2 e 5 respectivamente.

Com isso, provamos que o Simplex ´e um algoritmo que vai de vetor extremo a
vetor extremo at´e que se encontra aquele que minimiza ou maximiza a fun¸c˜ao objetiva
quando h´a solu¸c˜ao.

Os resultados dos lemas a seguir garantir˜ao que cada passo do M´etodo Simplex

est´a bem deﬁnido.

Lema 5.2.4. Seja um vetor b´asico compat´ıvel correspondente `a base B; se cT −cT
0, ent˜ao ¯x ´e solu¸c˜ao do problema de programa¸c˜ao linear.

BA−1

B A (cid:62)

64

Demonstra¸c˜ao. Pode-se veriﬁcar facilmente que:

cT − cT

BA−1

B A (cid:62) 0 ⇔ cT

R − cT

BA−1

B AR (cid:62) 0.

Seja x ∈ F qualquer. Logo, tem-se que:

b = Ax = ABxB + ARxR
B b − A−1

xB = A−1

B ARxR.

Por outro lado, tem-se que:

cT x = cT
= cT
= cT
(cid:62) cT

RxR
B b − cT
B b + (cT

BxB + cT
BA−1
BA−1
B ¯xB = cT ¯x, ∀ x ∈ F.

BA−1
R − cT

B ARxR + cT
BA−1

RxR
B AR)xR

(i) cj − cT

Lema 5.2.5. Seja B uma base tal que AB ´e uma matriz b´asica compat´ıvel; se existe
j ∈ {1, ..., n} \ B tal que:
BA−1
B Aj (cid:54) 0,
ent˜ao o problema de programa¸c˜ao linear n˜ao tem solu¸c˜ao.

B Aj < 0,

(ii) A−1

Demonstra¸c˜ao. Para cada λ (cid:62) 0, deﬁne-se x(λ) ∈ Rn como:

(cid:4)

xB(λ) = A−1

B b − λA−1

B Aj, xj(λ) = λ, xi(λ) = 0, ∀ i /∈ B \ B ∪ {j}.

Logo, x(λ) (cid:62) 0, ∀ λ (cid:62) 0. Por outro lado:

Ax(λ) = ABxB(λ) + ARxR(λ)

B b − λA−1

= AB(A−1
= b − λAj + λAj
= b,

B Aj) + Ajxj

portanto x(λ) ∈ F, ∀ λ (cid:62) 0, logo:

cT x(λ) = cT
= cT
= cT

BxB(λ) + ARxR(λ)
B b − λA−1
B(A−1
BA−1
B b + λ(cj − cT

B Aj) + cjxj
BA−1

B Aj) → −∞.

65

(cid:4)

Lema 5.2.6. Seja B uma base tal que AB ´e uma matriz b´asica compat´ıvel; se existe
j ∈ {1, ..., n} \ B tal que:

(i) cj − cT

BA−1

B Aj < 0,


(ii) Yj = A−1

B Aj =









(cid:10) 0,

y1j
...
ymj

ent˜ao para r = {1, ..., m} tal que:

¯br
yrj
e o conjunto B(cid:48) = {B \ {B(r)}} ∪ {j} ´e uma base tal que:

: yij > 0

(cid:26) ¯bi
yij

= min

(cid:27)

,

a) AB(cid:48) ´e uma matriz b´asica compat´ıvel,

b) cT

B(cid:48)A−1

B(cid:48) b (cid:54) cT

BA−1

B b.

Demonstra¸c˜ao. Tem-se que:

AB(cid:48) = [AB(cid:48)(1), ..., AB(cid:48)(r), ..., AB(cid:48)(m)]
= [AB(1), ..., Aj, ..., AB(m)]
= AB + [0, ..., 0, Aj − AB(r), 0, ..., 0]
= AB + Aj[0, ..., 0, 1, 0, ..., 0] − AB(r)[0, ..., 0, 1, 0, ..., 0]
= AB + (Aj − AB(r))[0, ..., 0, 1, 0, ..., 0].

Logo:

1 + [0, ..., 0, 1, 0, ..., 0]A−1
= 1 + [0, ..., 0, 1, 0, ..., 0]A−1
= 1 + yrj − 1
= yrj > 0.

B (Aj − AB(r))
B Aj − [0, ..., 0, 1, 0, ..., 0]A−1

B AB(r)

Isto implica que AB(cid:48) ´e uma matriz de posto m. Portanto, tem-se que:

A−1

B(cid:48) b = A−1

B b −

B ((Aj − AB(r))[0, ..., 0, 1, 0, ..., 0]A−1
A−1
B b
1 + [0, ..., 0, 1, 0, ..., 0]A−1
B ((Aj − AB(r))

= A−1

B b − (Yj − [0, ..., 0, 1, 0, ..., 0]T )

¯br
yrj

(cid:62) 0

66

o qual implica que AB(cid:48) ´e uma base compat´ıvel. Por outro lado:

B(cid:48) = cT
cT

B + (cj − cB(r))[0, ..., 0, 1, 0, ..., 0],

e isto implica, depois de alguns c´alculos, que:

B(cid:48)A−1
cT

B(cid:48) b = cT

BA−1

B b +

¯br
yrj

(cT

BA−1

B b − cj)

(cid:54) cT

BA−1

B b.

(cid:4)

Como consequˆencia dos Lemas 5.2.4, 5.2.5 e 5.2.6, mostrou-se que o algoritmo do

M´etodo Simplex est´a bem deﬁnido, podendo-se enunciar o pr´oximo teorema.

Teorema 5.2.7. O algoritmo Simplex est´a bem deﬁnido e termina em um n´umero ﬁnito
de itera¸c˜oes.

Depois de deﬁnir os componentes principais do m´etodo Simplex, pode-se aﬁrmar
que a solu¸c˜ao ´otima do modelo estudado na se¸c˜ao anterior ´e uma solu¸c˜ao compat´ıvel
b´asica do sistema de equa¸c˜oes obtido, isto ´e, um ponto extremo do trap´ezio ABCDE.

O M´etodo Simplex, para ser iniciado, necessita do conhecimento de uma solu¸c˜ao
compat´ıvel b´asica do sistema, chamada de solu¸c˜ao inicial, isto ´e, um dos pontos A, B, C,
D ou E do trap´ezio. Suponha que esta solu¸c˜ao seja, por exemplo, o ponto A.

O M´etodo Simplex veriﬁca se a presente solu¸c˜ao ´e ´otima. Se for, o processo ´e
encerrado; se n˜ao for, ´e porque um dos pontos extremos adjacentes ao ponto A fornece `a
fun¸c˜ao objetiva um valor maior que o atual. No caso, tanto B como E s˜ao melhores que
A.

O M´etodo Simplex faz ent˜ao a mudan¸ca do ponto A para o ponto extremo adja-

cente que mais aumente o valor da fun¸c˜ao objetiva, no caso, o ponto B.

Agora, tudo que foi feito no ponto A ser´a feito ao ponto B. O processo ﬁnaliza
quando, estando num ponto extremo, todos os pontos a ele adjacentes, fornecerem valores
menores para a fun¸c˜ao objetiva. ´E o que acontece com o ponto extremo C. ´E nessa hora
a importˆancia do fato do conjunto das solu¸c˜oes compat´ıveis ser convexo, como foi visto
anteriormente.

Para a mudan¸ca de um ponto extremo para outro a ele adjacente, note que um
ponto extremo adjacente ´e uma solu¸c˜ao compat´ıvel b´asica incluindo todas as vari´aveis
b´asicas anteriores, com exce¸c˜ao de apenas uma delas. Encontrar, portanto, a pr´oxima
solu¸c˜ao compat´ıvel b´asica, exige a escolha de uma vari´avel b´asica para deixar a base
atual, tornando-se n˜ao-b´asica, e a escolha de uma vari´avel n˜ao-b´asica para entrar na base
em sua substitui¸c˜ao.

Resumindo, o m´etodo simplex compreender´a os seguintes passos:

(i) Encontrar uma solu¸c˜ao compat´ıvel b´asica inicial;

(ii) Veriﬁcar se a solu¸c˜ao atual ´e ´otima. Se for, pare, caso contr´ario, siga para o passo

(iii);

67

(iii) Determinar a vari´avel n˜ao-b´asica que deve entrar na base;

(iv) Determinar a vari´avel b´asica que deve sair da base;

(v) Encontrar a nova solu¸c˜ao compat´ıvel b´asica e voltar ao passo (ii).

Exemplo 21. Ser´a resolvido, algebricamente, o modelo de programa¸c˜ao linear:

max f = 5x1 + 2x2

sujeito a






x1

(cid:54) 3
x2 (cid:54) 4
x1 +2x2 (cid:54) 9
x1 (cid:62) 0, x2 (cid:62) 0.

Com a introdu¸c˜ao das vari´aveis de folga x3, x4 e x5, obt´em-se o sistema:






x1

x2
x1 +2x2

+x3

+x4

= 3
= 4
+x5 = 9

x1, x2, x3, x4, x5 (cid:62) 0.

Note que o sistema apresenta uma solu¸c˜ao compat´ıvel b´asica ´obvia, com os se-

guintes valores para as vari´aveis:

Vari´aveis n˜ao-b´asicas: x1 = x2 = 0.

Vari´aveis b´asicas: x3 = 3, x4 = 4 e x5 = 9.

Quando todas as restri¸c˜oes forem do tipo (cid:54) e os bi n˜ao-negativos, sempre ter-se-´a

uma base ´obvia formada pelas vari´aveis de folga.

Diz-se que o sistema est´a na forma canˆonica, pois apresenta as seguintes carac-

ter´ısticas:

(i) Todas as vari´aveis s˜ao n˜ao-negativas;

(ii) Todos os bi s˜ao n˜ao-negativos;

(iii) Possui uma base ´obvia.

Quando um sistema possui apenas as caracter´ısticas (i) e (ii), diz-se que ele est´a
na forma “standard”. Como foi visto no cap´ıtulo 3, sempre ´e poss´ıvel transformar um
modelo de Programa¸c˜ao Linear num sistema de equa¸c˜oes na forma “standard”.

A solu¸c˜ao compat´ıvel b´asica ´obvia corresponde ao ponto extremo A = (0, 0) do
trap´ezio ABCDE. Note que a presente solu¸c˜ao n˜ao ´e ´otima, aﬁnal o valor da fun¸c˜ao
objetiva f ´e zero, pois x1 = x2 = 0 e qualquer uma dessas vari´aveis n˜ao-b´asicas que
entrar na base, tomar´a algum valor positivo, aumentando o valor de f . Concluindo que
ainda n˜ao foi alcan¸cada a solu¸c˜ao ´otima.

Para saber qual vari´avel n˜ao-b´asica dever´a entrar na base, basta tomar aquela que
tiver o maior coeﬁciente na fun¸c˜ao objetiva, estando a fun¸c˜ao expressa apenas em termos

68

das vari´aveis n˜ao-b´asicas, visando crescer o valor de f o mais r´apido poss´ıvel. Neste caso,
toma-se x1 que possui coeﬁciente igual a 5.

Para se determinar a vari´avel que sai da base se deve, primeiramente, colocar

todas as vari´aveis b´asicas em fun¸c˜ao das n˜ao-b´asicas:






x3 = 3 − x1
x4 = 4 − x2
x5 = 9 − x1,

onde x1 (cid:54) 3 pela primeira equa¸c˜ao e x1 (cid:54) 9 pela terceira equa¸c˜ao.

Note como x1 inﬂuencia o valor das demais vari´aveis. A vari´avel x2 continuar´a
fora da base com o valor nulo. Al´em disso, conclui-se que quando x1 entra na base, as
vari´aveis x3 e x5 diminuir˜ao de valor enquanto x4 ﬁca inalterada. Deseja-se aumentar o
m´aximo poss´ıvel x1 de tal modo que nenhuma vari´avel do sistema ﬁque negativa. Tem-se,
ent˜ao, de retirar da base `aquela que se anula mais rapidamente quando se aumenta o valor
de x1, neste caso, x3.

Portanto, a nova base ser´a formada por x1, x4 e x5. ´E necess´ario tranformar o
sistema em uma nova forma canˆonica tal que a nova base seja formada por essas vari´aveis.
Logo, tem-se que:






x1

x2
x1 +2x2

+x3

+x4

= 3
= 4
+x5 = 9





⇔

1 0 1 0 0 3
0 1 0 1 0 4
1 2 0 0 1 9





−→
L3 → L3 − L1





1
0

0 0 3
1 0
0 1
1 0 4
0 2 −1 0 1 6

x1



 ⇔






+x3

x2
2x2 −x3

+x4

= 3
= 4
+x5 = 6.

A solu¸c˜ao compat´ıvel b´asica ´obvia ´e:

Vari´aveis n˜ao-b´asicas: x2 = x3 = 0.

Vari´aveis b´asicas: x1 = 3, x4 = 4 e x5 = 6.

Esta solu¸c˜ao corresponde ao v´ertice b = (3, 0), adjacente ao ponto A. Note que

x5 diminuiu de valor ao se passar do ponto A para o ponto B.

Testando-se a presente solu¸c˜ao ´otima ´e neces´ario modiﬁcar a fun¸c˜ao f em termos
das vari´aveis n˜ao-b´asicas x2 e x3, pois n˜ao se pode avaliar a inﬂuˆencia da vari´avel n˜ao-
b´asica x3 no comportamento de f , assim, x3 n˜ao teria chance de entrar na base pelo
M´etodo Simplex e, al´em disso, n˜ao se pode aﬁrmar que f aumentar´a de valor com a
entrada de x2 na base pois x1 poder´a diminuir de valor assim como x5. Logo, tem-se que:

f = 5x1 + 2x2

= 5(3 − x3) + 2x2
= 15 + 2x2 − 5x3.

Pode-se aﬁrmar, portanto, que a presente solu¸c˜ao n˜ao ´e ´otima, pois, se x2 entrar

na base, aumentar´a o valor de f .

69

Repetindo-se o processo anterior, colocando-se as vari´aveis b´asicas em fun¸c˜ao das

n˜ao b´asicas, tem-se que:


onde x2 (cid:54) 4 pela segunda equa¸c˜ao e x2 (cid:54) 3 pela terceira equa¸c˜ao.




−x3

x1 = 3
x4 = 4 −x2
x5 = 6 −2x2 +x3,

Como a vari´avel x5 ´e a que se anula mais rapidamente, ela deve sair da base.

Deve-se transformar o sistema para uma nova forma canˆonica tal que a nova base

seja formada pelas vari´aveis x1, x2 e x4. Logo, tem-se que:

x1






+x3

x2
2x2 −x3

+x4

= 3
= 4
+x5 = 6





⇔

1
0

0 0 3
1 0
1 0 4
0 1
0 2 −1 0 1 6





−→
L3 → 1

2L3

−→
L2 → L2 − L3









0 0 3
1
1 0
1 0 4
0
0 1
2 0 1
0 1 − 1
2 3

x1


2 0
= 3
1/2x3 +x4 −1/2x5 = 1
+1/2x5 = 3.
x2 −1/2x3
Esta solu¸c˜ao possui a seguinte solu¸c˜ao compat´ıvel ´obvia:

+x3







1 0
1
1
0 0
2
0 1 − 1



 ⇔

0
0
3
1 − 1
2 1
1
3
2

Vari´aveis n˜ao-b´asicas: x∗

3 = x∗

5 = 0.

Vari´aveis b´asicas: x∗

1 = 3, x∗

2 = 3 e x∗

4 = 1.

A qual corresponde ao v´ertice C, adjacente a B, do conjunto solu¸c˜ao.
Colocando-se f em fun¸c˜ao das vari´aveis n˜ao-b´asicas, tem-se que:

f = 15 + 2x2 − 5x3

= 15 + 2 (3 + 1/2x3 − 1/2x5) − 5x3
= 21 − 4x3 − x5.

Baseando-se na situa¸c˜ao acima, pode-se aﬁrmar que se est´a diante da solu¸c˜ao ´otima,

pois se x3 ou x5 entrarem na base, diminuir˜ao o valor de f . Com isso, obt´em:

f ∗ = 21 − 4x∗
= 21,

3 − x∗
5

a qual tamb´em poderia ser obtida com:

f ∗ = 5x∗
= 21.

1 + 2x∗
2

Para diferenciar a solu¸c˜ao ´otima das demais, convenciona-se represent´a-la por f ∗,

1, x∗
x∗

2, etc.

Com os novos conceitos apresentados no exemplo, pode-se reescrever os cinco

passos do M´etodo Simplex, para o caso de maximiza¸c˜ao, da seguinte maneira:

70

(i) Encontrar uma forma canˆonica inicial para o sistema de equa¸c˜oes, isto ´e, achar uma

solu¸c˜ao compat´ıvel b´asica;

(ii) Colocar a fun¸c˜ao objetiva somente em termos das vari´aveis n˜ao-b´asicas; se todos os
coeﬁcientes dessas vari´aveis forem menores ou iguais a zero a presente solu¸c˜ao ´e
´otima, caso contr´ario, siga para o passo (iii);

(iii) Colocar na base a vari´avel n˜ao-b´asica que tiver o maior coeﬁciente positivo na fun¸c˜ao

objetiva obtida em (ii);

(iv) Tirar da base a vari´avel b´asica que se anular mais rapidamente, quando a vari´avel

que entrar for aumentada de valor;

(v) Encontrar uma outra forma canˆonica para o sistema de equa¸c˜oes, levando em consi-

dera¸c˜ao os passos (iii) e (iv); voltar ao passo (ii).

A utiliza¸c˜ao de tabelas para o do M´etodo Simplex em modelos de Programa¸c˜ao

Linear visa simpliﬁcar os c´alculos do item anterior.

Exemplo 22.

a) Resolvendo o exemplo anterior com a utiliza¸c˜ao de tabelas, primeiramente, reescreve-se

o sistema da seguinte maneira:





f −5x1 −2x2
x1

+x3

x2
x1 +2x2

+x4

= 0
= 3
= 4
+x5 = 9.

Pode-se representar o sistema da maneira esquem´atica abaixo:

f x1 x2 x3 x4 x5
0
1
0
0
0
0
1
0

-5
1
0
1

-2
0
1
2

0
1
0
0

0
0
1
0

b
0 L0
3 L1
4 L2
9 L3

Base
x3
x4
x5

Note que, como x3 = x4 = x5 = 0, f j´a est´a em termos de x1 e x2. Pode-se
aﬁrmar que a presente solu¸c˜ao ´e compat´ıvel e que a vari´avel a entrar na base ´e x1
(vari´avel com maior coeﬁciente em valor absoluto).

Para a determina¸c˜ao da vari´avel que sai, pelo exemplo anterior, note que s´o ´e
necess´ario se preocupar com a raz˜ao dos coeﬁcientes do vetor b com os coeﬁcientes
de x1 que s˜ao positivos, isto ´e:

linha (1): x1 (cid:54) 3
linha (3): x1 (cid:54) 9

1 = 3.
1 = 9.

Portanto, dever´a sair da base a vari´avel associada `a linha (1), ou seja, x3 que ´e

a vari´avel que se anula mais rapidamente, obt´endo-se o seguinte quadro:

71

b

f x1 x2 x3 x4 x5
0
1
0
0
0
0
1
0

0
1
0
0

0
0
1
0

Base
x1
x4
x5

Note que x1 = x4 = x5 = 0, aﬁnal f deve ﬁcar em termos somente de x2 e
x3. Para completar o quadro, perceba que apenas as colunas x1 s˜ao distintas em
ambos os quadros. A linha (1) ser´a a linha pivˆo das transforma¸c˜oes por ser a linha
associada `a vari´avel que sai da base. Portanto, tem-se que:

L0 → L0 + 5L1;
L1 ↔ L1;
L2 ↔ L2;
L3 → L3 − L1;

obtendo-se, ent˜ao:

Base
x1
x4
x5

f x1 x2 x3 x4 x5
0
1
0
0
0
0
1
0

-2
0
1
2

5
1
0
-1

0
0
1
0

0
1
0
0

b
15
3
4
6

Da linha (0), tem-se que f = 15 + 2x2 − 5x3, coincidindo com a rela¸c˜ao obtida

anteriormente.

Pelo coeﬁciente −2 na linha (0), pode-se aﬁrmar que a solu¸c˜ao n˜ao ´e ´otima,

portanto a vari´avel que entra na base ´e x2 e, al´em disso:

linha (2): x2 (cid:54) 4
linha (3): x2 (cid:54) 6

1 = 4;
2 = 3;

a vari´avel x5, correspondente a linha (3), deve sair da base. Ent˜ao, fazendo-se:

L0 → L0 + L3;
L1 ↔ L1;
L2 → L2 − 1
L3 → 1
2L3;

2L3;

obtendo-se, ent˜ao:

f ∗ x1 x2
0
0
1
0
1
0
0
0
0
1
0
0

x3
4
1
1/2
-1/2

x4
0
0
1
0

x5
1
0
-1/2
1/2

b
21
3
1
3

Base
x∗
1
x∗
4
x∗
2

72

Portanto, a presente solu¸c˜ao ´e ´otima, pois n˜ao existe algum coeﬁciente negativo
na linha (0) e a fun¸c˜ao objetiva f = 21 − 4x∗
5 coincide com a rela¸c˜ao obtida
anteriormente.

3 − x∗

b) Seja o seguinte modelo de programa¸c˜ao linear:

max f = 7x1 + 9x2

sujeito a






x1 −x2 (cid:62) −2
3x1 +5x2 (cid:54) 15
5x1 +4x2 (cid:54) 20
x1 (cid:62) 0, x2 (cid:62) 0.

Reescrevendo o problema como um sistema de equa¸c˜oes lineares, tem-se que:





f −7x1 −9x2

−x1 +x2 +x3
3x1 +5x2
5x1 +4x2

+x4

= 0
= 2
= 15
+x5 = 20

.

Resolvendo por tabelas, tem-se que:

f x1 x2 x3 x4 x5
0
1
0
0
0
0
1
0

-9
1
5
4

-7
-1
3
5

0
1
0
0

0
0
1
0

b
0 L0 → L0 + 9L1
2
15 L2 → L2 − 5L1
20 L3 → L3 − 4L1

L1 ↔ L1

Base
x3
x4
x5

Como a base que deve sair possui a menor raz˜ao positiva entre os coeﬁcientes de b e
de x2, a qual ´e a base negativa de maior valor absoluto, isto ´e, a vari´avel que entra
na base, ent˜ao x3 deve sair da base.

f
1
0
0
0

x1
-16
-1
8
9

Base
x2
x4
x5

x2 x3 x4 x5
0
0
0
1
0
0
1
0

9
1
-5
-4

0
0
1
0

b
18 L0 → L0 + 2L2
2 L1 ↔ L1 + 1
8L2
5
8L2
12 L3 → L3 − 9

L2 → 1

8L2

Como a base que deve sair possui a menor raz˜ao positiva entre os coeﬁcientes de b e
de x1, a qual ´e a base negativa de maior valor absoluto, isto ´e, a vari´avel que entra
na base, ent˜ao x4 deve sair da base.

f x1 x2
0
0
1
1
0
0
0
1
0
0
0
0

x3
-1
3/8
-5/8
13/8

Base
x2
x1
x5

x4
2
1/8
1/8
-9/8

73

x5
0
0
0
1

b
28
L0 → L0 + 8/13L3
21/3 L1 ↔ L1 − 3/13L3
5/8 L2 → L2 + 5/13L3
51/8

L3 → 8/13L3

Como a base que deve sair possui a menor raz˜ao positiva entre os coeﬁcientes de b e
de x3, a qual ´e a base negativa de maior valor absoluto, isto ´e, a vari´avel que entra
na base, ent˜ao x5 deve sair da base.

f ∗ x1 x2 x3
0
1
0
0
0
0
1
0

0
1
0
0

0
0
1
0

x4
17/13
5/13
-4/13
-9/13

x5
8/13
-3/13
5/13
8/13

b
415/13
15/13
40/13
51/13

Base
x∗
2
x∗
1
x∗
3

O valor ´otimo se localiza extamente abaixo do coeﬁciente b, portanto o valor m´aximo
de f ´e 415/13.

5.3 Casos Especiais

H´a algumas situa¸c˜oes que podem ocorrer nos modelos de Programa¸c˜ao lLinear
que n˜ao foram vistos na se¸c˜ao anterior. S˜ao situa¸c˜oes que podem exigir uma considera¸c˜ao
ou manipula¸c˜ao diferenciada.

(i) Problema de Minimiza¸c˜ao:

Quando a fun¸c˜ao objetiva tiver de ser minimizada, podem-se fazer dois proce-

dimentos:

(i) Mudar o teste para saber se a solu¸c˜ao ´e ´otima e o crit´erio de entrada de base;

(ii) Transformar o problema de minimiza¸c˜ao num problema de maximiza¸c˜ao, sabendo-

se que encontrar o m´ınimo de uma fun¸c˜ao ´e equivalente a encontrar o m´aximo
do sim´etrico desta, isto ´e:

max f ⇔ −min (−f ).

(ii) Empate na Entrada:

Quando houver empate na escolha da vari´avel que entra na base, deve-se tomar
a decis˜ao arbitrariamente. A ´unica implica¸c˜ao envolvida ´e que se pode tomar um
caminho mais longo ou mais curto para chegar `a solu¸c˜ao ´otima.

(iii) Empate na Sa´ıda - Degenera¸c˜ao:

Como no caso anterior, a decis˜ao tamb´em deve ser tomada de forma arbitr´aria.
Neste caso, sempre ocorrer´a de pelo menos duas vari´aveis se anularem ao mesmo
tempo, anulando-se assim a vari´avel que ﬁcar na base. Quando isso ocorre, diz-se
que a solu¸c˜ao compat´ıvel b´asica ´e degenerada.

Tamb´em pode ocorrer o caso de se chegar `a solu¸c˜ao ´otima com um menor
n´umero de itera¸c˜oes, ou seja, pode-se entrar em circuitos fechados intermin´aveis `a
procura da solu¸c˜ao ´otima.

74

(iv) Solu¸c˜oes M´ultiplas:

Eventualmente, um modelo de Programa¸c˜ao Linear pode apresentar mais de
uma solu¸c˜ao ´otima. Quando isso ocorre, o pr´oprio M´etodo Simplex ´e capaz de acu-
sar, anulando vari´aveis que pertencem `a fun¸c˜ao objetiva. Note que, pelos teoremas
vistos no cap´ıtulo 4, pode-se aﬁrmar que qualquer combina¸c˜ao convexa de duas
dessas solu¸c˜oes descobertas, tamb´em ser´a solu¸c˜ao ´otima para o modelo em quest˜ao.

5.4 Obten¸c˜ao da solu¸c˜ao inicial

Sempre ´e poss´ıvel transformar um modelo de programa¸c˜ao linear num sistema
de equa¸c˜oes na forma “standard”. Acontece que, para se iniciar o M´etodo Simplex, ´e
necess´ario tˆe-lo sob a forma canˆonica, ou seja, apresentando uma solu¸c˜ao compat´ıvel
b´asica ´obvia.

O modelo desenvolvido at´e agora tem todas as suas restri¸c˜oes do tipo (cid:54) e todos
os bi’s maiores ou iguais a zero. Assim, sempre se tem uma base inicial ´obvia formada
pelas vari´aveis de folga.

Ver-se-´a neste se¸c˜ao como ´e poss´ıvel encontrar uma solu¸c˜ao compat´ıvel b´asica

inicial quando a mesma n˜ao for ´obvia.

5.4.1 Casos de Diﬁculdades

Suponha que todos os bi’s sejam maiores ou igual a zero. Se algum deles for
negativo, pode-se multiplicar toda a restri¸c˜ao correspondente por −1 para o transformar
em positivo.

Baseado nessa hip´otese, estar-se-´a em diﬁculdades desde que o modelo apresente

uma restri¸c˜ao do tipo (cid:62) ou do tipo =.

Para exempliﬁcar, considere um modelo de programa¸c˜ao linear:

sujeito a

max f = 5x1 + 2x2
x1






(cid:54) 3
x2 (cid:54) 4
x1 +2x2 (cid:62) 9
x1 (cid:62) 0, x2 (cid:62) 0.

Pela solu¸c˜ao gr´aﬁca, conclui-se que a solu¸c˜ao ´otima ´e o ponto B = (3, 4) do

triˆangulo ABC.

Colocando-se as vari´aveis de folga se obt´em:





f −5x1 −2x2
x1

+x3

x2
x1 +2x2

+x4

= 0
= 3
= 4
−x5 = 9.

O sistema, apesar de estar na forma “standard”, n˜ao est´a na forma canˆonica. A

solu¸c˜ao b´asica formada por:

75

Figura 5.2:

Vari´aveis n˜ao-b´asicas: x1 = x2 = 0,

Vari´aveis b´asicas: x3 = 3, x4 = 4 e x5 = −9,

n˜ao ´e compat´ıvel, pois x5 < 0.

Para se obter uma forma canˆonica para o sistema, pode-se acrescentar uma
vari´avel artiﬁcial x6 na 4a equa¸c˜ao. A vari´avel x6 tomar´a o lugar de x5 na base inicial.
Assim, obt´em-se:





f −5x1 −2x2
x1

+x3

x2
x1 +2x2

+x4

x1, ..., x6 (cid:62) 0,

= 0
= 3
= 4
−x5 + x6 = 9

e a solu¸c˜ao compat´ıvel b´asica ´e:

Vari´aveis n˜ao-b´asicas: x1 = x2 = x5 = 0.

Vari´aveis b´asicas: x3 = 3, x4 = 4 e x6 = 9.

Os sistemas s´o ser˜ao equivalentes se a vari´avel artiﬁcial x6 for nula. Ao se conseguir
uma base que n˜ao inclua x6, esta ser´a considerada satisfeita. Dois processos para alcan¸car
esse objetivo s˜ao explicados a seguir.

5.4.2 Processo do “M Grande”

Para se for¸car a vari´avel artiﬁcial a n˜ao pertencer `a base ´otima, pode – se trans-

formar a fun¸c˜ao objetiva para:

f =

n
(cid:88)

i=1

cixi − M xk,

76

onde, xk representa a vari´avel artiﬁcial e M um n´umero t˜ao grande quanto desej´avel.

Assim, o valor m´aximo de f s´o ser´a alcan¸cado se x6 = 0, conforme desejado.

Voltando ao exemplo da subse¸c˜ao anterior, obt´em-se o seguinte sistema de equa¸c˜oes

lineares:






f −5x1 −2x2
x1

+x3

x2
x1 +2x2

+x4

−x5

+M x6 = 0
= 3
= 4
+x6 = 9

x1, ..., x6 (cid:62) 0.
Resolvendo pelo m´etodo de tabelas, tem-se:

Base
x3
x4
x5

Base
x1
x4
x5

b

f x1 x2 x3 x4 x5 x6
0
1
1
0
0
0
0
0

-5
1
0
1

-2
0
1
2

0
0
1
0

0 M 0 L0 → L0 + 5L1
0
0
-1

3
4
9 L3 → L3 − L1

L1 ↔ L1
L2 ↔ L2

0
0
1

b

f x1 x2 x3 x4 x5 x6
5
1
1
0
0
0
-1
0

-2
0
1
2

0
0
1
0

0
1
0
0

0 M 15 L0 → L0 + L3
0
0
-1

L1 ↔ L1
3
4 L2 → L2 − 1
2L3
6

L3 → 1

0
0
1

2L3

f x1 x2
0
0
1
0
1
0
0
0
0
1
0
0

x3
4
1
1/2
-1/2

x4
0
0
1
0

Base
x1
x4
x2

x6

x5
-1 M+1
0
1/2
-1/2

0
-1/2
1/2

b
21 L0 → L0 + 2L1
3
1
3

L1 ↔ L1
L2 → 2L2
L3 → L3 + L2

f ∗ x1 x2 x3 x4 x5 x6
5
1
1
0
1
0
0
0

b
0 M 23
3
0
0
2
-1
1
4
0
0

0
1
0
0

2
0
2
1

0
0
0
1

Base
x∗
1
x∗
5
x∗
2

5.4.3 Processo da Fun¸c˜ao Objetiva Artiﬁcial

Este processo consiste em, inicialmente, abandonar a fun¸c˜ao objetiva original,
colocando no sistema uma fun¸c˜ao objetiva artiﬁcial, formada pela vari´avel artiﬁcial co-
locada. Como a nova vari´avel n˜ao pode ser negativa, o seu valor m´ınimo ser´a igual a
zero, assim, encontrando-se o m´ınimo da nova fun¸c˜ao objetiva igual a zero, ter-se-´a ex-
clu´ıdo da base a vari´avel artiﬁcial, lembrando-se que minimizar uma fun¸c˜ao ´e o mesmo
que maximizar o seu sim´etrico.

Se um modelo requer mais de uma vari´avel artiﬁcial para completar a base inicial,
a fun¸c˜ao objetiva artiﬁcial ser´a igual `a soma dessas vari´aveis artiﬁciais. Para o m´ınimo

77

daquela ser zero, todas essas dever˜ao ser nulas. Se o m´ınimo for diferente de zero, ´e porque
o sistema de equa¸c˜oes original n˜ao tem solu¸c˜ao compat´ıvel.

Retomando o exemplo anterior, tem-se:

min W = x6

sujeito a






x1

x2
x1 +2x2

+x3

+x4

= 3
= 4
−x5 + x6 = 9

x1, ..., x6 (cid:62) 0.

Lembrando-se que o m´ınimo de W ´e o mesmo que o m´aximo de −W , obt´em-se a

seguinte tabela:

−W x1 x2 x3 x4 x5 x6
1
0
0
1
0
0
1
0

0
0
0
-1

0
1
0
1

0
0
1
2

0
0
1
0

1
0
0
0

b
0
3
4
9

Base
x3
x4
x5

Eliminando da fun¸c˜ao objetiva a vari´avel b´asica x6 a partir da opera¸c˜ao L0 →

L0 − L3, tem-se:

−W x1 x2 x3 x4 x5 x6
0
0
0
1
0
0
1
0

1
0
0
-1

-2
0
1
2

-1
1
0
1

0
0
1
0

1
0
0
0

b
-9
3
4
9

Base
x3
x4
x6

Resolvendo a maximiza¸c˜ao de −W pelo M´etodo Simplex, tem-se:

−W x1 x2 x3 x4 x5 x6
0
0
0
1
0
0
1
0

-2
0
1
2

-1
1
0
1

1
0
0
-1

0
0
1
0

1
0
0
0

−W x1 x2 x3 x4 x5 x6
0
0
0
1
0
0
1
0

-1
1
0
1

2
0
1
-2

1
0
0
-1

0
0
1
0

1
0
0
0

b
-9 L0 → L0 + 2L2
3
4
9 L3 → L3 − 2L2

L1 ↔ L1
L2 ↔ L2

b
-1 L0 → L0 + L3
3 L1 → L1 − L3
4
1

L2 ↔ L2
L3 ↔ L3

Base
x3
x4
x6

Base
x3
x2
x6

−W ∗ x1 x2 x3 x4 x5 x6
1
-1
0
1

0
2
1
-2

0
1
0
-1

0
1
0
0

0
0
1
0

0
0
0
1

1
0
0
0

b
0
2
4
1

Base
x∗
3
x∗
2
x∗
1

78

Note que o valor m´ınimo de W foi igual a 0. Desprezando-se a vari´avel artiﬁcial

x6, o quadro fornece a seguinte solu¸c˜ao compat´ıvel b´asica para o sistema:

Vari´aveis n˜ao-b´asicas: x4 = x5 = 0,

Vari´aveis b´asicas: x1 = 1, x2 = 4 e x3 = 2.

Esta solu¸c˜ao compat´ıvel b´asica corresponde ao ponto extremo C = (1, 4) do
triˆangulo ABC. Os coeﬁcientes nulos de x4 e x5 na fun¸c˜ao objetiva indicam que exis-
tem mais duas solu¸c˜oes compat´ıveis b´asicas para o sistema, correspondentes aos pontos
extremos A = (3, 3) e B = (3, 4).

Obtida a solu¸c˜ao compat´ıvel b´asica para o sistema, devem-se fazer as seguintes

altera¸c˜oes no quadro:

(i) Colocar a fun¸c˜ao objetiva original;

(ii) Eliminar a fun¸c˜ao W e a vari´avel articial x6.

Ent˜ao, tem-se:

f x1 x2 x3 x4 x5
0
1
1
0
0
0
-1
0

-2
0
1
0

0
2
1
-2

-5
0
0
1

0
1
0
0

b
0 L0 → L0 + 5L3 + 2L2
2
4
1

f x1 x2 x3 x4 x5
-5
1
1
0
0
0
-1
0

-8
2
1
-2

0
0
0
1

0
0
1
0

0
1
0
0

b
13 L0 → L0 + 4L1
L1 → 1
2
2L1
4 L2 → L2 − 1
1

2L1
L3 → L3 + L1

Base
x3
x2
x1

Base
x3
x2
x1

f x1 x2
0
0
1
0
0
0
1
0
0
0
1
0

x3
4
1/2
-1/2
1

x4
0
1
0
0

x5
-1
1/2
-1/2
0

b
21 L0 → L0 + 2L1
1
3
3

L1 → 2L1
L2 → L2 + L1
L3 ↔ L3

Base
x4
x2
x1

Base
x∗
5
x∗
2
x∗
1

Exemplo 23.

f ∗ x1 x2 x3 x4 x5
0
1
1
0
0
0
0
0

5
1
0
1

0
0
1
0

0
0
0
1

2
2
1
0

b
23
2
4
3

79

a) Seja o sistema de equa¸c˜oes lineares abaixo:

(cid:26) 3x1 + 2x2 − 5x3 = 6
4x1 + 7x2 + 4x3 = 9
x1, x2, x3 (cid:62) 0.

Para encontrar todas as solu¸c˜oes compat´ıveis b´asicas do sistema pelo processo

da fun¸c˜ao artiﬁcial, considere as vari´aveis artiﬁciais x4 e x5; com isso, tem-se:

min W = x4 + x5
(cid:26) 3x1 + 2x2 − 5x3 +x4
4x1 + 7x2 + 4x3

sujeito a

= 6
+x5 = 9

x1, x2, x3, x4, x5 (cid:62) 0.

Transformando a fun¸c˜ao W para maximiza¸c˜ao, ter-se-´a:

Com isso, tem-se:

max − W = −x4 − x5.

Base
x4
x5

Base
x4
x5

−W x1 x2 x3 x4 x5
1
0
0
2
1
7

0
-5
4

1
1
0

0
3
4

1
0
0

−W x1 x2 x3 x4 x5
0
-9
0
2
1
7

1
-5
4

-7
3
4

0
1
0

1
0
0

b
0 L0 → L0 − L1 − L2
6
9

b
-15 L0 → L0 + 9
L1 → L1 − 2
6
L2 → 1
7L2
9

7L2
7L2

−W x1

1
0
0

-13/7
13/7
4/7

x2
0
0
1

x3
43/7
-43/7
4/7

x4
0
1
0

x5
9/7
-2/7
1/7

b
-24/7
24/7
9/7

Base
x4
x2

L0 → L0 + L1
L1 → 7/13L1
L2 → L2 − 7/13L1

−W ∗ x1 x2
0
0
1

0
1
0

1
0
0

x4 x5
1
1

x3
0
-43/13
32/13

b
0
24/13
3/13

Base
x∗
1
x∗
2

Note que o m´ınimo de W ´e zero, indicando que se obteve uma solu¸c˜ao com-

pat´ıvel b´asica para o sistema.

80

b) Considere o seguinte modelo de Programa¸c˜ao Linear:

min f = 3x1 + 2x2

sujeito a

(cid:26) x1 + x2 (cid:62) 5
2x1 + x2 (cid:62) 7
x1, x2 (cid:62) 0.

Colocando as vari´avei de folga, obt´em-se:

min f = 3x1 + 2x2
(cid:26) x1 + x2 −x3
2x1 + x2

sujeito a

= 5
−x4 = 7

.

x1, x2, x3, x4 (cid:62) 0.

Para encontrar uma solu¸c˜ao inicial, pode-se colocar as vari´aveis artiﬁciais x5 e

x6, acompanhadas da fun¸c˜ao objetiva W , obtendo-se:

W





f −3x1 − 2x2

x1 + x2 −x3
2x1 + x2
x1, x2, x3, x4, x5, x6 (cid:62) 0.

−x4

−x5 −x6 = 0
= 0
= 5
+x6 = 7

+x5

Transformando as fun¸c˜oes f e W para maximiza¸c˜ao, chegar-se-´a ao quadro

abaixo:

−W −f x1 x2 x3 x4 x5 x6
1
0
0
2
0
1
0
1

0
0
0
-1

0
0
-1
0

1
0
1
1

0
1
0
0

0
3
1
2

1
0
0
0

b
0
0
5
7

Base

x5
x6

Eliminando-se x5 e x6 da fun¸c˜ao W , tem-se:

Base

x5
x6

Base

x5
x6

−W −f x1 x2 x3 x4 x5 x6
1
0
0
2
0
1
0
1

0
0
-1
0

0
0
0
-1

1
0
1
1

1
0
0
0

0
1
0
0

0
3
1
2

−W −f x1 x2 x3 x4 x5 x6
0
-2
0
2
0
1
0
1

-3
3
1
2

1
0
0
-1

1
0
-1
0

0
0
1
1

1
0
0
0

0
1
0
0

81

b
0 L0 → L0 − L2 − L3
0
5
7

b
-12 L0 → L0 + 3
L1 → L1 − 3
0
L2 → L2 − 1
5
L3 → 1
2L3
7

2L3
2L3
2L3

−W −f x1
0
0
0
1
0
0
1
0

1
0
0
0

x2
-1/2
1/2
1/2
1/2

x3
1
0
-1
0

x4
-1/2
3/2
1/2
-1/2

x5
0
0
1
0

x6
3/2
-3/2
-1/2
1/2

b
-3/2
L0 → L0 + L2
-21/2 L1 → L1 − 3L2
3/2
7/2

L2 → 2L2
L3 → L3 + L2

Base

x5
x6

−W −f x1 x2 x3 x4 x5 x6
1
0
0
-1
-1
1
0
1

1
-3
2
1

0
3
-2
-1

0
0
1
0

0
1
0
0

0
0
0
1

1
0
0
0

b
0
-15
3
5

Base

x5
x6

A fun¸c˜ao W chegou ao seu valor m´ınimo que, sendo nulo, indica a existˆencia
de solu¸c˜ao compat´ıvel para o problema, podendo-se eliminar a linha da fun¸c˜ao W e
as duas vari´aveis artiﬁciais., obtendo-se:

−W −f x1 x2 x3 x4 x5 x6

b

1
0
0

0
0
1

-1
1
1

3
-2
-1

0
1
0

-15
3
5

Base

x5
x6

O quadro acima mostra uma solu¸c˜ao compat´ıvel b´asica para o sistema, inclusive

a fun¸c˜ao f j´a est´a em termos das vari´aveis n˜ao-b´asicas. Ent˜ao, tem-se:

−W −f x1 x2 x3 x4 x5 x6

b

Base

x5
x6

1
0
0

0
0
1

-1
1
1

3
-2
-1

0
1
0

-15 L1 → L1 + L2
3
5

L2 ↔ L2
L3 → L3 − L2

−W −f ∗ x1 x2 x3 x4 x5 x6

b

1
0
0

0
0
1

0
1
0

1
-2
1

1
1
-1

-12
3
2

Base

x∗
5
x∗
6

Que ´e a solu¸c˜ao ´otima.

Com isso, at´e aqui foram estudadas algumas das t´ecnicas necess´arias para encon-
trar a solu¸c˜ao ´otima de um modelo de Programa¸c˜ao Linear. Se tal modelo apresentar
um n´umero reduzido de vari´aveis, poder-se-´a aplicar o M´etodo Simplex manualmente e
resolver o problema. Se o n´umero de vari´aveis for grande, como acontece na maioria
dos problemas reais, ´e necess´ario a utiliza¸c˜ao de recursos computacionais para se obter a
solu¸c˜ao ´otima do problema.

82

Cap´ıtulo 6

Considera¸c˜oes Finais

Mostrou-se nesta disserta¸c˜ao uma algumas das formas de se resolver problemas
de Programa¸c˜ao Linear, al´em do estudo de conjuntos convexos e desigualdades. Ap´os
a modelagem de algum problema, pode-se resolver muitos deles a partir dos m´etodos
apresentados.

O M´etodo Gr´aﬁco se mostra eﬁciente, por´em se limita aos problemas no R2 e no
R3, sendo que em R3 ´e dif´ıcil a visualiza¸c˜ao dos pontos extremos para obter a solu¸c˜ao
´otima do problema de Programa¸c˜ao Linear.

O M´etodo Simplex ´e uma ferramenta de grande utilidade para resolver quaisquer
dos problemas propostos, mas, `a medida que se acrescenta mais vari´aveis, ele se torna um
m´etodo com processo de solu¸c˜ao prolongado. A utiliza¸c˜ao de ferramentas computacionais
resolvem de forma satisfat´oria esse problema.

Por ﬁm, apesar das limita¸c˜oes para resolver os problemas de Programa¸c˜ao Linear,
isto ´e, considerando-se os coeﬁcientes constantes, a divisibilidade e a proporcionalidade,
ainda se pode aplicar os m´etodos vistos neste trabalho a maioria dos problemas existentes.
Para algum problema mais espec´ıﬁco, h´a m´etodos para resolvˆe-los mais rebuscados, os
quais se encontram em textos mais avan¸cados para a solu¸c˜ao de problemas mais espec´ıﬁcos
n˜ao encontrados nesta disserta¸c˜ao..

83

Apˆendice A

´Algebra Linear

Aqui se mostra apenas os conceitos indispens´aveis para o desenvolvimento do
assunto, dando-se maior ˆenfase `as Matrizes e aos Sistemas de Equa¸c˜oes Lineares. Apenas
os teoremas mais importantes foram demonstrados.

A.1 Matrizes

Nesta se¸c˜ao se apresenta os conceitos b´asicos sobre matrizes. S˜ao conceitos que
aparecem na resolu¸c˜ao de muitos problemas, n˜ao somente para organiz´a-los e simpliﬁc´a-
los, mas por trazer novos m´etodos de solu¸c˜ao.

Deﬁni¸c˜ao 20 (Matrizes). ´E um conjunto de n´umeros dispostos em linhas e colunas em
forma de uma tabela com a seguinte representa¸c˜ao:

A = Am×n = (aij)m×n =












a11
a12
a21
a22
...
...
ai1
ai2
...
...
am1 am2

. . . a1j
. . . a2j
...
. . . aij
...
. . . amj

. . . a1n
. . . a2n
...
. . . ain
...
. . . amn












m×n

; aij ∈ R, m, n ∈ N∗.

onde m e n o n´umero de linhas e colunas da matriz, respectivamente; m × n ´e a

ordem da matriz e aij a entrada da matriz.

Nota¸c˜ao: M(m, n) representa o conjunto de todas as matrizes de ordem m × n.

Tipos especiais de matrizes

Seja a matriz A = (aij)m×n; tem-se que:

84

1. Matriz Nula: tal que aij = 0, ∀i, j.

Exemplo 24.





0 0 0 0 0
0 0 0 0 0
0 0 0 0 0





.

3×5

2. Matriz Coluna: tal que n = 1.

Exemplo 25.







1
−2
3
−4







.

4×1

3. Matriz Linha: tal que m = 1.

Exemplo 26.

(cid:2) 1 −2 3 −4 (cid:3)

1×4 .

4. Matriz Quadrada: tal que m = n.

Exemplo 27.





2
1
1
8
5
3
13 21 34





.

3×3

Os elementos tais que i = j formam a diagonal principal de A.

5. Matriz Identidade: tal que m = n, aij = 1, ∀i = j e aij = 0, ∀i (cid:54)= j.

Exemplo 28.

I =





1 0 0
0 1 0
0 0 1





.

3×3

onde I representa a matriz identidade.

6. Matriz Diagonal: tal que m = n e aij = 0, ∀i (cid:54)= j.

Exemplo 29.







0

0 0
3
0 −2 0 0
0 0
0
0 5
0

0
0







.

4×4

7. Matriz Triangular Superior: tal que m = n e aij = 0, ∀i > j.

85

Exemplo 30.







3
0 −2
0
0
0
0

7 −5 11
13
6
0
0
5
0







.

4×4

8. Matriz Triangular Inferior: tal que m = n e aij = 0, ∀i < j.

Exemplo 31.







3
0 0
0
7 −2 0 0
6
−5
0 0
13 0 5
11







.

4×4

9. Matriz Transposta (AT ): tal que aT

ij = aji, ∀i, j.

Exemplo 32.

A =

(cid:20) 1 2 3
4 5 6

(cid:21)

2×3

, AT =





1 4
2 5
3 6





.

3×2

10. Matriz Sim´etrica: tal que m = n e aij = aji, isto ´e, A = AT .

Exemplo 33.







3
7 −2
−5
6
13
11

7 −5 11
13
6
0
0
5
0







.

4×4

11. Matriz Antissim´etrica tal que m = n e aij = −aji, ∀i (cid:54)= j, isto ´e, A = −AT .

Exemplo 34.







7 −5 11
3
−7 −2 −6 13
0
5
5

−11 −13

0
0

6







.

4×4

12. Matriz em blocos: a matriz subdividida em matrizes menores a partir de linhas

verticais e/ou horizontais.

Exemplo 35.









7

3

2
11
5
13 17 19 23 29
31 37 41 43 47
43 47 53 59 61
67 71 73 79 83

|
|
|

3
17
37

5
19
41

7
23
43

2
11
13
29
47
31
−− −− −− | −− −−
61
43
83
67

59
79

53
73

47
71

|
|











.









=











86

Opera¸c˜oes com Matrizes

1. Igualdade: Sejam as matrizes A = (aij)m×n e B = (bij)m×n tal que A = B, ent˜ao

aij = bij, ∀i, j.

2. Adi¸c˜ao: Sejam as matrizes A = (aij)m×n, B = (bij)m×n e C = (cij)m×n tal que

C = A + B, ent˜ao

cij = aij + bij, ∀i, j.

3. Multiplica¸c˜ao por um escalar: Seja λ ∈ R e as matrizes A = (aij)m×n e B =

(bij)m×n tal que B = λA, ent˜ao

bij = λaij, ∀i, j.

Proposi¸c˜ao A.1.1. Sejam α, λ ∈ R e as matrizes A = (aij)m×n, B = (bij)m×n e
C = (cij)m×n; ent˜ao tem-se que:

(i) (A + B) + C = A + (B + C) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (associatividade);

(ii) α(λA) = (αλ)A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (associatividade);

(iii) A + B = B + A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (comutatividade);

(iv) A(λB) = (λA)B = λ(AB) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (comutatividade);

(v) (α + λ)A = αA + λA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .(distributividade);

(vi) λ(A + B) = λA + λB . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (distributividade);

(vii) A + 0 = A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (elemento neutro);

(viii) A + (−A) = 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (inverso aditivo).

Note que 0 em vii e viii representa a matriz nula.

4. Multiplica¸c˜ao de Matrizes: Sejam as matrizes A = (aik)m×n, B = (bkj)n×p e

C = (cij)m×p tal que C = A × B = AB, ent˜ao

cij =

n
(cid:88)

k=1

(aik × bkj), ∀i, j.

87

Geralmente, AB (cid:54)= BA. Quando ocorre a igualdade, diz-se que A comuta com

B.

Proposi¸c˜ao A.1.2. Sejam A, B e C matrizes com ordens adequadas para efetuar
as respectivas opera¸c˜oes. Ent˜ao, tem-se que:

(i) AI = IA = A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .(elemento neutro);

(ii) A(BC) = (AB)C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (associatividade);

(iii) A(B + C) = AB + AC . . . . . . . . . . . . . . . . . . . . . . . (distributividade `a esquerda);

(iv) (A + B)C = AC + BC . . . . . . . . . . . . . . . . . . . . . . . . . (distributividade `a direita).

Deﬁni¸c˜ao 21 (Matriz Inversa). Dada uma matriz A quadrada de ordem n; chama-se
Inversa de A a matriz A−1 de ordem n tal que:

A · A−1 = A−1 · A = In.

Quando existe A−1, diz-que A ´e invert´ıvel.

Proposi¸c˜ao A.1.3. Sejam A e B matrizes quadradas de ordem n. Com isso, tem-se que:

(i) Se A ´e invert´ıvel, ent˜ao sua inversa ´e ´unica;

(ii) Se A ´e invert´ıvel, ent˜ao A−1 tamb´em ´e invert´ıvel e (A−1)−1 = A;

(iii) Se A e B s˜ao invert´ıveis, ent˜ao AB tamb´em ´e invert´ıvel e (AB)−1 = B−1A−1.

Corol´ario A.1.4.

(i) Se A tem uma linha nula, ent˜ao AB tem uma linha nula;

(ii) Se B tem uma coluna nula, ent˜ao AB tem uma coluna nula;

(iii) Qualquer matriz quadrada com uma linha ou uma coluna nula n˜ao ´e invert´ıvel.

Demonstra¸c˜ao.

(i): Seja i a linha nula da matriz A; ent˜ao analizando somente o produto efetuado

dela linha da matriz A pela matriz B, tem-se que, o produto da linha i ser´a dado por:

(AB)ij =

(cid:88)

k = 1naik × bkj = 0.

Logo, AB tem uma linha nula.

(ii): Seja j a coluna nula da matriz B; ent˜ao analizando somente o produto efetuado
dela pela coluna da matriz B pela matriz A, tem-se que, o produto da coluna j ser´a dado
por:

(AB)ij =

(cid:88)

k = 1naik × bkj = 0.

88

Logo, AB tem uma coluna nula.

(iii): Supondo A invert´ıvel, ent˜ao A.A−1 = A−1.A = I.

a) Supondo A com uma linha nula, ent˜ao, por (i), A.A−1 possui uma linha nula, o que

´e absurdo, aﬁnal A.A−1 = I.

b) Supondo A com uma coluna nula, ent˜ao, por (ii), A−1.A possui uma coluna nula,

o que ´e absurdo, aﬁnal A−1.A = I.

Logo A n˜ao ´e invert´ıvel.

(cid:4)

A.2 Sistemas de Equa¸c˜oes Lineares

Deﬁni¸c˜ao 22 (Sistemas de Equa¸c˜oes Lineares). Um sistema de m equa¸c˜oes lineares e n
inc´ognitas tem a seguinte representa¸c˜ao alg´ebrica:





a11x1 + a12x2 + . . . + a1nxn = b1
a21x1 + a22x2 + . . . + a2nxn = b2
...
am1x1 + am2x2 + . . . + amnxn = bm,

...

...

...

(A.1)

onde aij s˜ao os coeﬁcientes, xj as inc´ognitas e bm os termos independentes.

Uma equa¸c˜ao gen´erica i do sistema poderia ser representada da seguinte maneira:

n
(cid:88)

j=1

aij × xj = bi.

Para representar todas as equa¸c˜oes, tem-se:

n
(cid:88)

j=1

aij × xj = bi, para i = 1, 2, ..., m.

Al´em da nota¸c˜ao de somat´orio, pode-se tamb´em utilizar a nota¸c˜ao matricial,

aﬁnal, tem-se que:





a11x1 + a12x2 + . . . + a1nxn = b1
a21x1 + a22x2 + . . . + a2nxn = b2
...
am1x1 + am2x2 + . . . + amnxn = bm

...

...

...

89








(cid:124)

a11
a12
a21
a22
...
...
am1 am2

. . . a1n
. . . a2n
...
. . . amn

(cid:123)(cid:122)
A

·








(cid:125)















x1
x2
...
xn
(cid:124) (cid:123)(cid:122) (cid:125)
X

=















b1
b2
...
bm
(cid:124) (cid:123)(cid:122) (cid:125)
B

.

Onde A ´e a matriz dos coeﬁcientes, X a matriz das inc´ognitas e B a matriz dos

termos independentes.
Seja

S = {(c1, c2, ..., cn) ∈ Rn; ai1c1 + ai2c2 + ... + aincn = bi, para i = 1, 2, ..., m}.

Esse subconjunto do Rn ´e chamado Conjunto Solu¸c˜ao do sistema (A.1).

Deﬁni¸c˜ao 23 (Transforma¸c˜oes Lineares). Seja a matriz A = (aij)m×n; para cada 1 (cid:54)
i (cid:54) m, denota-se por Li a i-´esima linha de A. Ent˜ao as Transforma¸c˜oes Elementares de
linhas na matriz A s˜ao tais que:

(i) Li ↔ Lj indica a permuta¸c˜ao das linhas Li e Lj;

(ii) Li → Li + cLj indica a substitui¸c˜ao da linha Li pela adi¸c˜ao desta por c vezes a linha

Lj;

(iii) Li → cLi indica o produto da linha Li por um n´umero real c.

Exemplo 36.

a)

b)

c)









1 2 3
4 5 6
7 8 9

−→
L1 ↔ L3





7 8 9
4 5 6
1 2 3



 .









1 2 3
4 5 6
7 8 9

−→
L1 → L1 + 2L2





9 12 15
6
5
4
9
8
7



 .









1 2 3
4 5 6
7 8 9

−→
L1 → 3L1





3 6 9
4 5 6
7 8 9



 .

90

Nota¸c˜ao:

e(A) indica uma tranforma¸c˜ao elementar na matriz A.

Sejam A e B matrizes de ordem m × n; a matriz A ´e dita equivalente por linhas `a
matriz B se B pode ser obtida de A pela aplica¸c˜ao sucessiva de transforma¸c˜oes elementares
sobre linhas.

Observe que a no¸c˜ao de equivalˆencia de matrizes por linhas corresponde `a no¸c˜ao
de equivalˆencia de sistemas de equa¸c˜oes lineares quando se efetuam as respectivas trans-
forma¸c˜oes sobre as equa¸c˜oes. De fato, `a sistemas equivalentes correspondem matrizes
associadas equivalentes e vice-versa.

Proposi¸c˜ao A.2.1. Toda transforma¸c˜ao elementar nas linhas de matrizes e(A) ´e re-
vers´ıvel, tal que existe uma transforma¸c˜ao elementar e(cid:48), onde e(cid:48)(e(A)) = e(e(cid:48)(A)) = A
para toda matriz A ∈ M(m, n).

Deﬁni¸c˜ao 24 (Forma Escalonada de uma matriz). Uma matriz m × n ser´a dita na forma
escalonada se for nula ou se:

(i) o primeiro elemento n˜ao nulo de cada linha n˜ao nula ´e 1;

(ii) cada coluna que cont´em o primeiro elemento n˜ao nulo de alguma linha tem todos os

outros elementos nulos;

(iii) Toda linha nula ocorre abaixo de todas as linhas n˜ao nulas;

(iv) se L1, L2, ..., Lp s˜ao as linhas n˜ao nulas e se o primeiro elemento n˜ao nulo da linha

Li ocorre na coluna ki, ent˜ao k1 < k2 < ... < kp.

Exemplo 37. Est˜ao escalonadas as matrizes (a) e (b) a seguir por satisfazerem a deﬁni¸c˜ao
e n˜ao est˜ao escalonadas as matrizes (c) e (d) por n˜ao satisfazerem as condi¸c˜oes (i) e (ii),
respectivamente:

(a)

(b)

(c)

(d)

















0 0 0 0
0 0 0 0
0 0 0 0

1 0 0 3
0 1 0 0
0 0 1 0

1 0 0 5
0 3 0 0
0 0 1 0

1 0 7 0
0 1 0 2
0 0 1 0



 ;



 ;



 ;



 .

91

Corol´ario A.2.2. Seja A uma matriz quadrada na forma escalonada; s˜ao equivalentes
as seguintes informa¸c˜oes:

(i) A matriz A n˜ao tem linhas nulas;

(ii) A ´e a matriz identidade;

(iii) A ´e invert´ıvel.

Demonstra¸c˜ao.

(i) ⇒ (ii) :

Como A ´e uma matriz quadrada, n˜ao tem linhas nulas e est´a na forma escalonada,
ent˜ao ela deve satisfazer as condi¸c˜oes da deﬁni¸c˜ao de matriz escalonada, logo, para
isso:

A = In.

(ii) ⇒ (iii) :

Seja A = In e B uma matriz de mesma ordem tal que:

ent˜ao tem-se que:

e

AB = BA = In,

InB = In ⇒ B = In,

InB = In ⇒ B = In.

Logo existe uma matriz B que satisfaz a primeira equa¸c˜ao, logo A ´e invert´ıvel.

(iii) ⇒ (i) :

Pela contra-positiva do Corol´ario A.1.4, se uma matriz ´e invert´ıvel, ent˜ao ela n˜ao
possui uma linha nula.

(cid:4)

Deﬁni¸c˜ao 25 (Matrizes Elementares). ´E uma matriz quadrada de ordem n obtida da
matriz identidade In a partir da aplica¸c˜ao de uma transforma¸c˜ao elementar.

92

Nota¸c˜ao: E = e(In) ´e a transforma¸c˜ao elementar aplicada na matriz identidade In.

Exemplo 38.

(a)

(b)

(c)









1 0 0
0 1 0
0 0 1

−→
L1 ↔ L3





0 0 1
0 1 0
1 0 0



 ;









1 0 0
0 1 0
0 0 1

−→
L1 → L1 + 2L2





1 2 0
0 1 0
0 0 1



 ;









1 0 0
0 1 0
0 0 1

−→
L1 → 3L1





3 0 0
0 1 0
0 0 1



 .

Teorema A.2.3. Seja e uma transforma¸c˜ao elementar sobre A ∈ M(m, n) e E = e(Im),
ent˜ao

e(A) = EA.

Demonstra¸c˜ao.

Sem perda de generalidade, considere as transforma¸c˜oes elementares e sob a matriz A

a seguir:

(i)L1 ↔ L2:

Seja A = (aij); com isso, tem-se que e(A) = A, para todo j e i (cid:54)= 1, 2 e que:

e(A)2j = a1j

e

e(A)1j = a2j.

Como as linhas da matriz elementar e(Im) e da matriz identidade Im coincidem,

exceto a 1a. e a 2a. , tem – se que:

(e(I)A)ij = e(A), ∀j, i (cid:54)= 1, 2.

Para a linha 1, tem-se que:

(e(I)A)1j =

=

j
(cid:88)

k=1
j
(cid:88)

e(I)1k × akj

e(I)2k × akj

k=1
= a2j

(e(I)A)1j = e(A)1j.

93

Analogamente, para a linha 2, tem-se que:

(e(I)A)2j = e(a2j).

(ii)L1 → cL1:

Seja A = (aij); com isso, tem-se que e(A) = A, para todo j e i (cid:54)= 1 e que:

e(A)1j = c × a1j.

Como as linhas da matriz elementar e(Im) e da matriz identidade Im coincidem,

exceto a 1a. , tem-se que:

(e(I)A)ij = e(A), ∀j, i (cid:54)= 1.

Para a linha 1, tem-se que:

(e(I)A)1j =

=

j
(cid:88)

k=1
j
(cid:88)

k=1

e(I)1k × akj

c × e(I)1k × akj

= c ×

j
(cid:88)

k=1

e(I)1k × akj

= c × A1j ⇒

(e(I)A)1j = e(A)1j.

(iii)L2 → L2 + cL1:

Seja A = (aij); com isso, tem-se que e(A) = A, para todo j e i (cid:54)= 2 e que:

e(A)2j = a2j + c × a1j.

Como as linhas da matriz elementar e(Im) e da matriz identidade Im coincidem,

exceto a 2a. , tem-se que:

(e(I)A)ij = e(A), ∀j, i (cid:54)= 1.

Para a linha 2, tem-se que:

(e(I)A)2j =

j
(cid:88)

k=1

e(I)2k × akj

94

=

=

j
(cid:88)

k=1
j
(cid:88)

k=1

(e(I)2k + c × e(I)1k) × akj

e(I)2k × akj + c ×

j
(cid:88)

k=1

e(I)1k × akj

= a2j + c × a1j

(e(I)A)2j = e(A)2j.

Corol´ario A.2.4. Sejam A, B ∈ M(m, n); ent˜ao A ´e equivalente a B se, e somente se,
existem matrizes elementares E1, E2, ..., Es de ordem m tais que:

Es × ... × E2 × E1 × A = B.

(cid:4)

Demonstra¸c˜ao.

A ´e equivalente a B quando existem transforma¸c˜oes elementares e1, e2, ..., es tais que:

Pelo Teorema A.2.3, tem-se que:

es(...(e2(e1(A)))...) = B.

Es × ... × E2 × E1 × A = B.

Corol´ario A.2.5. Toda matriz elementar ´e invert´ıvel e sua inversa tamb´em ´e uma matriz
elementar.

Demonstra¸c˜ao.

Seja E uma matriz elementar e e uma transforma¸c˜ao elementar tal que E = e(I); se
e(cid:48) ´e a transforma¸c˜ao elementar inversa de e e E(cid:48) = e(cid:48)(I), pelo Teorema A.2.3 tem-se que:

(cid:4)

I = e(cid:48)(e(I)) = e(cid:48)(E) = e(cid:48)(E)I = E(cid:48)EI = e(e(cid:48)(I)) = e(E(cid:48)) = e(I)E(cid:48) = EE(cid:48)

Logo E ´e invert´ıvel e E−1 = E(cid:48).

(cid:4)

Teorema A.2.6. Para uma matriz quadrada A de ordem n, s˜ao equivalentes as seguintes
informa¸c˜oes:

(i) A ´e invert´ıvel;

(ii) Se B ´e na forma escalonada equivalente `a matriz A, ent˜ao B = In;

(iii) A ´e uma matriz elementar ou um produto de matrizes elementares.

95

Demonstra¸c˜ao.

(i) ⇒ (ii) :

Como a matriz B ´e equivalente a matriz A, existem matrizes elementares E1,

E2, ..., Es tais que:

Es...E2E1A = B.

Como, pelo Corol´ario A.2.5, Ei ´e invert´ıvel e A, por hip´otese, tamb´em o ´e,

ent˜ao B ´e invert´ıvel e tem-se que B = In.

(ii) ⇒ (iii) :

Se Es...E2E1A = B, ent˜ao:

A = E−1

1 E−1

2 ...E−1

s B,

onde B = In e E−1

i

´e uma matriz elementar pelo mesmo corol´ario.

(iii) ⇒ (i) :

Como A ´e um produto de matrizes elementares e toda matriz elementar ´e
invert´ıvel, tem-se que, pela proposi¸c˜ao A.1.3, o produto de matrizes invert´ıveis ´e
uma matriz invert´ıvel.

(cid:4)

Observe pelo Teorema A.2.6, que uma matriz ´e equivalente a uma ´unica matriz
na forma escalonada, a matriz identidade, mostrando-se a unicidade da forma escalonada.

Teorema A.2.7. Seja A uma matriz invert´ıvel e e1, e2, ..., es uma sequˆencia de trans-
forma¸c˜oes elementares tais que es(...(e2(e1(A)))...) = I; tem -que essa mesma sequˆencia
de transforma¸c˜oes elementares aplicadas a I produz a matriz inversa A−1, isto ´e:

es(...(e2(e1(I)))...) = A−1.

Demonstra¸c˜ao.

Seja Ei, para 1 (cid:54) i (cid:54) s, uma matriz elementar correspondente a transforma¸c˜ao

elementar ei sobre a matriz identidade I; ent˜ao:

Es...E2E1A = I
Es...E2E1AA−1 = IA−1
Es...E2E1I = A−1.

Deﬁni¸c˜ao 26 (Classiﬁca¸c˜ao de Sistemas Lineares). Quanto as suas solu¸c˜oes, um sistema
pode se classiﬁcar em:

(cid:4)

96

(i) Poss´ıvel e Determinado: com uma ´unica solu¸c˜ao;

(ii) Poss´ıvel e Indeterminado: com inﬁnitas solu¸c˜oes;

(iii) Imposs´ıvel: sem solu¸c˜ao.

Para resolver um sistema linear, utilizam-se os conhecimentos desenvolvidos no

estudo de transforma¸c˜oes elementares.

Diz-se que dois sistemas lineares s˜ao equivalentes se ´e poss´ıvel obter um sistema
do outro a partir de uma sequˆencia ﬁnita de transforma¸c˜oes elementares. Com isso, pode-
se aﬁrmar que sistemas de equa¸c˜oes lineares equivalentes possuem o mesmo conjunto
solu¸c˜ao.

Deﬁni¸c˜ao 27 (Sistemas Lineares Homogˆeneos). S˜ao sistemas de equa¸c˜oes lineares tais
que os termos independentes s˜ao nulos, isto ´e:





Note que:

a11x1 + a12x2 + . . . + a1nxn = 0
a21x1 + a22x2 + . . . + a2nxn = 0
...
am1x1 + am2x2 + . . . + amnxn = 0.

...

...

...

(A.2)

(i) O conjunto S = (0, 0, ..., 0) pertence ao conjunto de solu¸c˜oes do sistema linear;

(ii) Se u = (c1, c2, ..., cn) e v = (c(cid:48)

1, c(cid:48)

2, ..., c(cid:48)

n) s˜ao solu¸c˜oes do sistema linear e se a ∈ R,

ent˜ao

e

u + v = (c1 + c(cid:48)

1, c2 + c(cid:48)

2, ..., cn + c(cid:48)
n)

tamb´em s˜ao solu¸c˜oes do sistema linear.

au = (ac1, ac2, ..., acn)

O que h´a de essencial em um sistema de equa¸c˜oes lineares s˜ao os coeﬁcientes e os
termos independentes. A partir disto, o sistema (A.1) pode ser organizado como linhas
de uma matriz ampliada, isto ´e:





a11x1 + a12x2 + . . . + a1nxn = b1
a21x1 + a22x2 + . . . + a2nxn = b2
...
am1x1 + am2x2 + . . . + amnxn = bm

...

...

...








⇔

a12
a11
a22
a21
...
...
am1 am2

. . . a1j
. . . a2j
...
. . . amj

. . . a1n
. . . a2n
...
. . . amn








.

b1
b2
...
bm

Para o sistema linear homogˆeneo (A.2), pode-se excluir a coluna de zero corres-

pondente aos termos independentes, isto ´e:

97

a11x1 + a12x2 + . . . + a1nxn = 0
a21x1 + a22x2 + . . . + a2nxn = 0
...
am1x1 + am2x2 + . . . + amnxn = 0




Exemplo 39. Classiﬁque os sistemas lineares abaixo e encontre suas solu¸c˜oes, se poss´ıvel.

a11
a12
a21
a22
...
...
am1 am2

. . . a1n
. . . a2n
...
. . . amn

. . . a1j
. . . a2j
...
. . . amj











⇔





...

...

...

.

a)

solu¸c˜ao:






x + y + 2z = 9
2x + 4y − 3z = 1
3x + 6y − 5z = 0.






x + y + 2z = 9
2x + 4y − 3z = 1
3x + 6y − 5z = 0





⇔

1 1
2 9
2 4 −3 1
3 6 −5 0





−→
L2 ↔ L2 − 2L1
L3 ↔ L3 − 3L1

−→
L3 ↔ L3 − L2









2

1 1
9
0 2 −7 −17
0 3 −11 −27





−→
L2 ↔ 1
L3 ↔ 1

2L2
3L3

9
2
1 1
2 − 17
0 1 − 7
6 − 1
0 0 − 1

2

2





−→
L3 ↔ −6L3









2
1 1
9
2 − 17
0 1 − 7
2
0 1 − 11
3 −9

9
2
1 1
2 − 17
0 1 − 7
2
3
1
0 0









−→
L1 ↔ L1 − 2L3
L2 ↔ L2 + 7
2L3





1 1 0 3
0 1 0 2
0 0 1 3





−→
L1 ↔ L1 − L2





1 0 0 1
0 1 0 2
0 0 1 3



 ;

S = {(x.y.z) ∈ R3|x = 1, y = 2, z = 3}.

Logo o sistema ´e S.P.D.

b)

solu¸c˜ao:






x + y + z = 1
2x + 2y + 2z = 2
3x + 3y + 3z = 4.






x + y + z = 1
2x + 2y + 2z = 2
3x + 3y + 3z = 4





⇔

1 1 1 1
2 2 2 2
3 3 3 4





98

−→
L2 ↔ L2 − 2L1
L3 ↔ L3 − 3L1





1 1 1 1
0 0 0 0
0 0 0 1





−→
L2 ↔ L3





1 1 1 1
0 0 0 1
0 0 0 0



 .

Logo o sistema ´e S.I.

c)

(cid:26) x + y + z = 4

2x + 5y − 2z = 3.

solu¸c˜ao:

(cid:26) x + y + z = 4

2x + 5y − 2z = 3

⇔

(cid:20) 1 1

1 4
2 5 −2 3

(cid:21)

−→
L2 ↔ L2 − 2L1

(cid:20) 1 1 | −1
0 3 |

4
4 −5

(cid:21)

−→
L2 ↔ 1

3L2

(cid:20) 1 1 | −1
0 1 |

4
3

(cid:21)

4
−5
3

−→
L1 ↔ L1 − L2

(cid:20) 1 0 | − 7
3
0 1 | − 4

17
3

(cid:21)

;

3 − 5

3

S = {(x, y, z) ∈ R3|x = −

7
3

α +

17
3

, y =

4
3

α −

5
3

, z = α, α ∈ R}.

Logo o sistema ´e S.P.I.

Lema A.2.8. Seja uma matriz A = [A(cid:48)|A(cid:48)(cid:48)] na forma escalonada, onde A(cid:48) ´e uma matriz
m×(n−1) e A(cid:48)(cid:48) ´e uma matriz m×1; Sejam k1, k2, ...,ks as posi¸c˜oes das colunas de A que
ocorrem os primeiros elementos n˜ao nulos das linhas n˜ao nulas L1,..., Ls respectivamente.
O sistema A(cid:48)X = A(cid:48)(cid:48) admite solu¸c˜ao se, e somente se, ks (cid:54)= n.

Demonstra¸c˜ao.

Observe que, como A est´a na forma escalonada, a matriz A(cid:48) tamb´em est´a.

1a parte:

Se kp = n, ent˜ao a p-´esima linha da matriz A ´e (cid:0) 0 0 ... 0 1 (cid:1). Assim, o sistema
A(cid:48)X = A(cid:48)(cid:48) tem uma equa¸c˜ao na forma 0x1 + ... + 0xn = 1, que n˜ao tem solu¸c˜ao.

2a parte:

Se kp (cid:54)= n, tem-se que p (cid:54) kp (cid:54) n. Assim, se os ai s˜ao as entradas de A(cid:48)(cid:48), tem-se
que ap+1 = ... = am = 0. Denotando-se por Ai a i-´esima coluna da matriz A, tem-se
que:

99

A(cid:48)

k1 = Ak1 =























1
0
...
0
...
0

, A(cid:48)

k2 = Ak2 =























0
1
...
0
...
0

, · · · , A(cid:48)

kp = Akp =












,












0
0
...
1
...
0

onde cada matriz acima tem as ´ultimas m − r entradas nulas. O sistema A(cid:48)X = A(cid:48)(cid:48)
se escreve, em blocos, da seguinte forma:

a = [A1|A2|...|An−1]X = A1x1 + A2x2 + ... + An−1xn−1.

Para achar a solu¸c˜ao do sistema basta tomar xki = ai e xj = 0, se j (cid:54)= ki, para

todo i = 1, ..., p.

(cid:4)

Deﬁni¸c˜ao 28 (posto). O posto p de uma matriz equivale ao n´umero de linhas n˜ao nulas
de sua forma escalonada.

Exemplo 40.

a) Seja a matriz





A =

2 9
1 1
2 4 −3 1
3 6 −5 0



 .

Tem-se que sua forma escalonada ´e a matriz

Logo a matriz A tem posto 3.

b) Seja a matriz





˜A =

1 0 0 1
0 1 0 2
0 0 1 3



 .

B =





1 1 1 1
2 2 2 2
3 3 3 4



 .

Tem-se que sua forma escalonada ´e a matriz

Logo a matriz B tem posto 2.





˜B =

1 1 1 1
0 0 0 1
0 0 0 0



 .

100

c) Seja a matriz

C =

(cid:20) 1 1

1 4
2 5 −2 3

(cid:21)

.

Tem-se que sua forma escalonada ´e a matriz

˜C =

Logo a matriz C tem posto 2.

(cid:20) 1 0 − 7
3
0 1 − 4

17
3

(cid:21)

.

3 − 5

3

Corol´ario A.2.9. Uma matriz quadrada de ordem n ´e invert´ıvel se, e somente se, ela
tem posto n.

Demonstra¸c˜ao.

Se a matriz ´e invert´ıvel, ent˜ao pelo Teorema A.2.6, sua forma escalonada ´e In,

logo tem posto n.

Reciprocamente, seja dada uma matriz quadrada de ordem n e seja ˜A sua forma
escalonada; se A tem posto n, ent˜ao ˜A n˜ao tem linhas nulas, logo, pelo Corol´ario A.2.2,
˜A = In.

Pelo Corol´ario A.2.4, tem-se que:

A = Es...E1

˜A = Es...E1,

onde E1, ..., Es s˜ao matrizes elementares, ent˜ao, pelo Corol´ario A.2.5, s˜ao invert´ıveis e,
consequentemente, pela Proposi¸c˜ao A.1.3 , A ´e invert´ıvel por ser um produto de matrizes
(cid:4)
invert´ıveis.

Teorema A.2.10 (teorema do posto). Seja um sistema de equa¸c˜oes lineares com m
equa¸c˜oes e n inc´ognitas AX = B; sejam pAB o posto da matriz ampliada do sistema e pA
o posto da matriz dos coeﬁcientes do sistema, ent˜ao o sistema ´e:

(i) O sistema ´e poss´ıvel se, e somente se, pAB = pA;

(ii) S.P.D. ⇔ pAB = pA = n;

(iii) S.P.I. ⇔ pAB = pA < n; neste caso, o sistema possui n − pA inc´ognitas livres, isto

´e, inc´ognitas que podem assumir qualquer valor real.

Demonstra¸c˜ao.

Seja AX = B um sistema linear de n inc´ognitas, C = [A|B] a matriz ampliada do
sistema e ˜C = [ ˜A| ˜B] a forma escalonada de C; denotando-se ˜A = [˜aij] e ˜B = [˜bi], tem-se,
claramente que ˜A ´e a forma escalonada de A e como ˜A ´e um bloco de ˜C, tem-se que:

pA = p ˜A < p ˜C = pAB ou pA = p ˜A = p ˜C = pAB.

1o caso:

Se pA < pAB, ent˜ao ˜C tem uma linha do tipo (cid:0) 0 ... 0 0 1 (cid:1).
Portanto, o sistema ˜AX = ˜B ´e imposs´ıvel e, ent˜ao, AX = B ´e imposs´ıvel.

101

2o caso:

Se pA = pAB, ent˜ao ˜C e ˜A tˆem o mesmo n´umero de linhas n˜ao nulas.

(i) pAB = pA = n:

Sendo ˜A uma matriz com n colunas, com p ˜A = pA = n, e estando ˜A na

forma escalonada, ela ´e uma matriz em blocos da forma

˜A =

(cid:20) In
0

(cid:21)

.

Como pAB = pA = n, segue que ˜B ´e tal que bn+1 = ... = bm = 0.
Portanto, ˜AX = ˜B ´e poss´ıvel e determinado com a ´unica solu¸c˜ao x1 =
˜b1, ..., xn = ˜bn. Consequentemente, AX = B tamb´em ´e poss´ıvel e determinado
com a mesma solu¸c˜ao.

(ii) pAB = pA < n:

Suponhamos p = pA = pAB. Neste caso, ˜A, assim como ˜C, tem p linhas
n˜ao nulas L1, ..., Lp, tais que o primeiro elemento n˜ao nulo de Li est´a na coluna
ki e k1 < ... < kp. Al’em disso, tem-se ˜bp+1 = ... = ˜bm = 0.

Tem-se ent˜ao que a equa¸c˜ao ˜AX = ˜B juntamente com o fato da matriz ˜A
estar na forma escalonada, nos fornece um sistema de equa¸c˜oes que nos mostra
a possibilidade da escolha arbitr´aria de valores para as inc´ognitas no conjunto

{x1, ..., xn} − {xk1, ..., xkp},

e com esses determinar valores para xk1, ..., xkp.

Como o conjunto acima tem n − p elementos, o sistema ˜AX = ˜B tem
n − p inc´ognitas livres e, consequentemente, o mesmo ocorre para o sistema
AX = B.

(cid:4)

Exemplo 41. Retomando os sistemas do Exemplo 16, tem-se que:

a) A matriz das inc´ognitas e a matriz ampliada da matriz escalonada s˜ao, respectiva-

mente:

˜A =





1 0 0
0 1 0
0 0 1





 e (cid:103)AB =



1 0 0 1
0 1 0 2
0 0 1 3



 .

Logo tem-se que:

Portanto o sistema ´e S.P.D.

pA = pAB = n = 3.

102

b) A matriz das inc´ognitas e a matriz ampliada da matriz escalonada s˜ao, respectiva-

mente:

˜A =





1 1 1
0 0 0
0 0 0





 e (cid:103)AB =



1 1 1 1
0 0 0 1
0 0 0 0



 .

Logo tem-se que:

Portanto o sistema ´e S.I.

1 = pA < pAB = 2.

c) A matriz das inc´ognitas e a matriz ampliada da matriz escalonada s˜ao, respectiva-

mente:

˜A =

(cid:21)

(cid:20) 1 0 − 7
3
0 1 − 4
3

e (cid:103)AB =

Logo tem-se que:

(cid:20) 1 0 − 7
3
0 1 − 4

17
3

(cid:21)

.

3 − 5

3

Portanto o sistema ´e S.P.I.

2 = pA = pAB < n = 3.

Corol´ario A.2.11. Seja um sistema de equa¸c˜oes lineares homogˆeneo com m equa¸c˜oes e
n inc´ognitas AX = 0, ent˜ao:

(i) Se A tem posto n, ent˜ao o sistema possui apenas a solu¸c˜ao nula, isto ´e, quando m = n

e A ´e invert´ıvel;

(ii) Se A tem posto menor que n, ent˜ao o sistema ´e S.P.I., isto ´e, quando m < n.

A.3 Espa¸co Vetorial

Deﬁni¸c˜ao 29. Um conjunto V ser´a dito um Espa¸co Vetorial se for munido das opera¸c˜oes
de um corpo K veriﬁcando as condi¸c˜oes a seguir para a ado¸c˜ao e multiplica¸c˜ao por escalar:

A1 (u + v) + w = u + (v + w), ∀u, v, w ∈ V . . . . . . . . . . . . . . . . . . . . . . . . . (associatividade);

A2 u + v = v + u, ∀u, v ∈ V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (comutatividade);

A3 v + 0 = v, ∀v ∈ V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (elemento neutro);

A4 v + (−v) = 0, ∀v ∈ V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (inverso aditivo);

M E1 a(u + v) = au + av, ∀u, v ∈ V, a ∈ R . . . . . . . . . . . . . . . . . . . . . . . . . . (distributividade);

M E2 (a + b)v = av + bv, ∀v ∈ V, a, b ∈ R . . . . . . . . . . . . . . . . . . . . . . . . . . . (distributividade);

M E3 (ab)v = a(bv), ∀v ∈ V, a, b ∈ R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (associatividade);

M E4 1v = v, ∀v ∈ V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (elemento neutro).

103

Nota¸c˜ao

(i) Os elementos de V ser˜ao chamados de vetores e os de K escalares;

(ii) 0 de V ´e chamado vetor nulo, isto ´e:

(iii) −v ´e chamado de vetor oposto de v, isto ´e:

0 = (0, 0, ..., 0) ∈ Rn;

v = (x1, ..., xn) ⇒ −v = (−x1, ..., −xn).

Exemplo 42.

a) Adi¸c˜ao e produto por um escalar de matrizes.

b) Conjunto das fun¸c˜oes de um conjunto n˜ao vazio A em R.

Deﬁni¸c˜ao 30 (Subespa¸co Vetorial). Sejam V um espa¸co vetorial e W um subconjunto
n˜ao vazio de V ; diz-se que W ´e um subespa¸co vetorial de V , ou subespa¸co de V , com as
opera¸c˜oes de adi¸c˜ao em V e de multiplica¸c˜ao de vetores de V por escalares.

Proposi¸c˜ao A.3.1. Sejam V um espa¸co vetorial e W um subconjunto n˜ao vazio de V ;
ent˜ao W ´e um subespa¸co de V se, e somente se:

(i) se u, v ∈ W , ent˜ao u + v ∈ W ;

(ii) se au ∈ W , com u ∈ W, a ∈ R, ent˜ao au ∈ W .

Demonstra¸c˜ao.

Se W ´e um subespa¸co de V , ent˜ao claramente as condi¸c˜oes (i) e (ii) s˜ao satisfeitas.
Reciprocamente, suponha que W possua as propriedades (i) e (ii). Para mostrar
que W ´e um subespa¸co de V , precisa-se somente veriﬁcar que os elementos de W possuem
as propriedades A3 e A4.

Tomando-se um elemento qualquer u de W , aﬁnal W (cid:54)= ∅. Pela condi¸c˜ao (ii),

au ∈ W para todo a ∈ R.

Tomando a = 0, segue-se que 0u = 0 ∈ W e, tomando, a = −1, segue-se que
(cid:4)

(−1)u = −u ∈ W .

Corol´ario A.3.2. Sejam V um espa¸co vetorial e W um subconjunto n˜ao vazio de V ;
tem-se que W ´e um subespa¸co de V se, e somente se, u + av ∈ W, ∀a ∈ R e u, v ∈ W .

Exemplo 43.

a) Seja V um espa¸co vetorial; o conjunto 0 ´e subespa¸co de V , tamb´em chamado de

espac¸co vetorial nulo, e todo o espa¸co V ´e subespa¸co de V ;

b) o plano yOz dado por W1 = {((0, y, z)| y, ∈ R} e o eixo y dado por W2 = {(0, y, 0)| y ∈

R} s˜ao subespa¸cos de R3 ;

104

c) O conjunto solu¸c˜ao de um sistema de equa¸c˜oes lineares homogˆeneas em n inc´ognitas

forma um subespa¸co de Rn;

d) No espa¸co vetorial das matrizes M(n, n), s˜ao subespa¸cos os conjuntos das matrizes

triangulares superiores, inferiores e diagonais.

Proposi¸c˜ao A.3.3. A interse¸c˜ao de dois subespa¸cos de um espa¸co vetorial V ´e um su-
bespa¸co vetorial de V .

Deﬁni¸c˜ao 31. Dados U e W subespa¸cos de um espa¸co vetorial V ; deﬁne-se a soma de U
e W , denotada por U + W , como o conjunto:

U + W = {u + w; u ∈ U, w ∈ W }.

Deﬁni¸c˜ao 32. Sejam U e W subespa¸cos de um espa¸co vetorial V ; o espa¸co vetorial V ´e
dito a soma direta de U e W e representado por V = U (cid:76) V , se V = U + W e U ∩ W = 0.

Teorema A.3.4. Sejam U e W subespa¸cos de um espa¸co vetorial V ; tem-se que V =
U (cid:76) W se, e somente se, todo vetor v ∈ V se escreve de modo ´unico como v = u+w, u ∈ U
e w ∈ W .

Demonstra¸c˜ao.

Suponha que V = U (cid:76) W e toma-se v ∈ V ; como V = U + W , pela deﬁni¸c˜ao da

soma de subespa¸cos, existem u ∈ U e w ∈ W tais que

Note que a decomposi¸c˜ao acima ´e ´unica no sentido de que se v = u(cid:48) + w(cid:48), com

u(cid:48) ∈ U e w(cid:48) ∈ W , ent˜ao u = u(cid:48) e w = w(cid:48), aﬁnal, como v = u + w e v = u(cid:48) + w(cid:48), ent˜ao:

v = u + w.

u − u(cid:48) = −(w − w(cid:48)).

Como o lado esquerdo pertence a U e o lado direito a W , da igualdade anterior

decorre que

u − u(cid:48), w − w(cid:48) ∈ U ∩ W.

como U ∩ W = 0, segue ent˜ao que u = u(cid:48) e w = w(cid:48).
Reciprocamente, suponha que todo vetor de V se escreve de modo ´unico como a

soma de um vetor de U e de um vetor de W ; ent˜ao V = U + W .

Se U ∩ W (cid:54)= 0, existiria um vetor n˜ao nulo v em U ∩ W . como v ∈ W e W ´e um
subespa¸co, ent˜ao −v ∈ W tamb´em. Consequentemente, ter-se-ia 0 = 0 + 0, com 0 ∈ U ,
0 ∈ W e 0 = v + (−v), com v ∈ U e −v ∈ W .

Como v (cid:54)= 0, ter-se-iam duas escritas distintas para um mesmo vetor de V . Como

isto n˜ao ocorre, tem-se que U ∩ W = 0.

(cid:4)

Deﬁni¸c˜ao 33 (Combina¸c˜ao Linear). Seja V um espa¸co vetorial e sejam v1, ..., vr ∈ V ; diz
– se que v ∈ V ´e uma combina¸c˜ao linear de v1, ..., vr se existem a1, ..., ar ∈ R, tais que:

v =

r
(cid:88)

i=1

aivi = a1v1 + ... + arvr.

105

Exemplo 44. Seja o vetor (1, 6, 0) ∈ R3; note que ele ´e uma combina¸c˜ao linear dos
vetores v1 = (1, 2, 0) e v2 = (−1, 2, 0), aﬁnal tem-se que:

(1, 6, 0) = 2(1, 2, 0) + 1(−1, 2, 0)

v = 2v1 + 1v2.

Deﬁni¸c˜ao 34 (vetores linearmente independentes). Sejam v1, ..., vr vetores em um espa¸co
vetorial V ; diz-se que v1, ..., vr s˜ao Linearmente Independentes ou L.I. se a equa¸c˜ao:

´e satisfeita somente quando a1 = ... = ar = 0.

a1v1 + ... + arvr = 0

Deﬁni¸c˜ao 35 (vetores linearmente dependentes). Sejam v1, ..., vr vetores em um espa¸co
vetorial V ; diz-se que v1, ..., vr s˜ao Linearmente Dependentes L.D. se a equa¸c˜ao:

a1v1 + ... + arvr = 0

´e satisfeita com algum ai (cid:54)= 0.

Exemplo 45.

a) Os vetores e1 = (1, 0) e e2 = (0, 1) s˜ao L.I., pois tem-se que:

a1e1 + a2e2 = 0
a1(1, 0) + a2(0, 1) = (0, 0)

a1 = a2 = 0.

b) Os vetores v1 = (1, −3, 4), v2 = (3, 2, 1) e v3 = (1, −1, 2) s˜ao L.D., pois tem-se que:

a1(1, −3, 4) + a2(3, 2, 1) + a3(1, −1, 2) = (0, 0)

a1v1 + a2v2a3v3 = 0






a1 + 3a2 + a3 = 0
−3a1 + 2a2 − a3 = 0
4a1 + a2 + 2a3 = 0.

Resolvendo o sistema linear homogˆeneo por escalonamento, tem-se que:






a1 + 3a2 + a3 = 0
−3a1 + 2a2 − a3 = 0
4a1 + a2 + 2a3 = 0





⇔

1 3

1
−3 2 −1
2

4 1





 ⇔



1 3

1
−3 2 −1
0

0 0



 .

O qual n˜ao ´e uma matriz invert´ıvel, logo o sistema ´e S.P.I.

106

Proposi¸c˜ao A.3.5. Sejam v1, ..., vr vetores em Rn, onde, para cada i, com 1 (cid:54) i (cid:54) n,
vi = (ai1, ..., ain) e A = (aij); tem-se que {v1, ..., vn} ´e L.I. se, e somente se, A ´e invert´ıvel.

Teorema A.3.6. Sejam v1, ..., vr vetores em Rn; se r > n, ent˜ao os vetores v1, ..., vr s˜ao
L.D..

Demonstra¸c˜ao.

Suponha que, para cada 1 (cid:54) i (cid:54) r, vi = (ai1, ..., ain) e considere a equa¸c˜ao:

k1v1 + k2v2 + ...krvr = 0.

Esta equa¸c˜ao ´e equivalente ao sistema linear homogˆeneo





a11k1 + a21k2 + ... + ar1kr = 0
a12k1 + a22k2 + ... + ar2kr = 0
...
a1nk1 + a2nk2 + ... + arnkr = 0.

...

...

...

O sistema obtido possui n equa¸c˜oes nas r inc´ognitas k1, k2, ..., kr. Como r > n,
(cid:4)

segue que o sistema tem solu¸c˜oes n˜ao triviais, logo v1, v2, ..., vr s˜ao L.D..

Teorema A.3.7. Um conjunto ﬁnito α com dois ou mais vetores de um espa¸co vetorial V
´e LD se, e somente se, pelo menos um dos vetores de α pode ser escrito como combina¸c˜ao
linear dos outros vetores.

Demonstra¸c˜ao.

Seja α = {v1, ..., vr} um subconjunto do espa¸co de V ; se α ´e L.D., ent˜ao existem
n´umeros reais a1, ..., ar, n˜ao todos nulos, tais que a1v1 + ... + arvr = 0. Suponha que
aj (cid:54)= 0. Ent˜ao:

vj = −

a1
aj

v1 − ... −

aj−1
aj

vj−1 −

aj+1
aj

VJ+1 − ... −

ar
aj

vr,

mostrando que vj ´e uma combina¸c˜ao linear dos demais vetores de α.

Reciprocamente, suponha que α tem a propriedade de que um de seus vetores,
por exemplo vi, pode ser escrito como uma combina¸c˜ao linear dos outros vetores de α,
isto ´e, que existem n´umeros reais b1, ..., bi−1, bi+1, ..., br tais que

vi = b1v1 + ... + bi−1vi−1 + bi+1vi+1 + ... + brvr.

A equa¸c˜ao anterior equivale a

b1v1 + ... + bi−1vi−1 − 1vi + bi+1vi+1 + ... + brvr = 0.

Logo α ´e L.D..

(cid:4)

Deﬁni¸c˜ao 36 (Base de um espa¸co vetorial:). Seja α = {v1, ..., vn} um conjunto ordenado
de vetores de um espa¸co vetorial V ; diz-se que α ´e uma base de V se:

(i) α ´e L.I.;

107

(ii) Os vetores de V podem ser escritos como combina¸c˜ao linear dos vetores de α, isto

´e, α gera o espa¸co vetorial V .

Exemplo 46.

a) Como o conjunto α = {e1, e2} ´e L.I. e gera R2 aﬁnal

(x, y) ∈ R2 ⇒ (x, y) = xe1 + ye2,

logo α, com a ordena¸c˜ao dada pelos ´ındices, ´e uma base de R2 chamada de base
canˆonica de R2.

b) Como o conjunto α = {e1, e2, e3} ´e L.I. e gera R3 aﬁnal

(x, y, z) ∈ R3 ⇒ (x, y, z) = xe1 + ye2 + ze3,

logo α, com a ordena¸c˜ao dada pelos ´ındices, ´e uma base de R3 chamada de base
canˆonica de R3.

c) Deﬁne-se o S´ımbolo de Kronecker, δij, para (i, j) ∈ N2, como

δij =

(cid:26) 1,
0,

se
se

i = j
i (cid:54)= j.

Seja n ∈ N − 0. Para cada 1 (cid:54) i (cid:54) n, denotando-se por ei ∈ Rn o vetor

(δi1, δi2, ..., δij, ..., δin) = (0, ..., 0, 1, 0, ..., 0),

onde a componente 1 se encontra na i -´esima posi¸c˜ao. O conjunto α = {e1, e2, ..., en}
´e L.I. e gera Rn, com a ordena¸c˜ao dos ´ındices, equivalendo `a base canˆonica de Rn.

d) Sejam

M1 =

(cid:21)

(cid:20) 1 0
0 0

, M2 =

(cid:21)

(cid:20) 0 1
0 0

, M3 =

(cid:21)

(cid:20) 0 0
1 0

e M4 =

(cid:20) 0 0
0 1

(cid:21)

.

O conjunto α = {M1, M2, M3, M4} ´e uma base de M(2, 2), aﬁnal os vetores de

α s˜ao L.I. e α gera M(2, 2), aﬁnal

M =

(cid:21)

(cid:20) a b
c d

M = aM1 + bM2 + cM3 + dM4.

108

Com isso, tem-se que:

a1M1 + a2M2 + a3M3 + a4M4 = 0

(cid:21)

(cid:20) 1 0
0 0

a1

+ a2

(cid:21)

(cid:20) 0 1
0 0

+ a3

(cid:21)

(cid:20) 0 0
1 0

+ a4

(cid:20) 0 0
0 1

(cid:21)

= 0

a1 = a2 = a3 = a4 = 0.

Teorema A.3.8. Seja α = {v1, ..., vn} um conjunto ordenado de vetores de um espa¸co
vetorial V ; as seguintes aﬁrma¸c˜oes s˜ao equivalentes:

(i) α ´e uma base de V ;

(ii) cada vetor v em V pode ser escrito de modo ´unico como combina¸c˜ao linear dos

vetores de α.

Demonstra¸c˜ao.

(i) ⇒ (ii):

Suponha que α ´e uma base de V e tome v ∈ V ; como α gera V , existem n´umeros

reais a1, ..., an tais que

v = a1v1 + ... + anvn.

(A.3)

Para mostrar que a combina¸c˜ao linear em (A.4) ´e ´unica, suponha que existem

b1, ..., bn ∈ R tais que

De (A.4) e (A.5) segue que

v = b1v1 + ... + bnvn.

(a1 − b1)v1 + ... + (an − bn)vn = 0.

(A.4)

(A.5)

Como α ´e L.I., a equa¸c˜ao (A.6) ´e satisfeita somente se aj − bj = 0 para todo
1 (cid:54) j (cid:54) n, isto ´e, se bj = aj, para todo 1 (cid:54) j (cid:54) n. Como v ∈ V foi tomado de
modo arbitr´ario, (ii) ´e satisfeito.

(ii) ⇒ (i):

Suponha que α tem a propriedade de que cada vetor v ∈ V pode ser escrito de
modo ´unico como combina¸c˜ao linear dos elementos de α. Pela deﬁni¸c˜ao de espa¸co
gerado, α gera V . Para mostrar que α ´e L.I., considere a equa¸c˜ao

k1v1 + ... + knvn = 0.

Como 0 = 0v1 + ... + 0vn e esta escrita ´e ´unica, segue que k1 = ... = kn = 0.

(cid:4)

Os n´umeros reais a1, ..., an que aparecem na demonstra¸c˜ao s˜ao chamados coor-

denadas de v na base α.

109

Nota¸c˜ao:

[v]α =




 ,






a1
...
an

onde [v]α ´e chamada de matriz das coordenadas de v na base α.

Exemplo 47.

a) Seja α a base canˆonica de R3 e v = (1, 2, 1); ent˜ao

[v]α =



 .





1
2
1

b) Seja β = {(1, 0, 0), (0, 1, 0), (1, 1, 1)}, que ´e uma base de R3, e v = (1, 2, 1); ent˜ao

[v]β =



 ,





0
1
1

aﬁnal

(1, 2, 1) = 0(1, 0, 0) + 1(0, 1, 0) + 1(1, 1, 1).

Teorema A.3.9. Seja v1, ..., vn vetores n˜ao nulos que geram um espa¸co vetorial V ; ent˜ao,
dentre esses vetores, pode-se extrair uma base de V .

Teorema A.3.10. Seja V um espa¸co vetorial gerado por um conjunto ﬁnito de vetores
v1, ..., vn; ent˜ao qualquer conjunto com mais de n vetores de V ´e L.D., consequentemente,
qualquer conjunto de vetores de V L.I. tem, no m´aximo, n vetores.

Teorema A.3.11. Sejam α = {v1, ..., vn} e β = {w1, ..., wn} duas bases de um espa¸co
vetorial V ; ent˜ao r = s e, al´em disso, se A = (aij) e B = (bij) s˜ao as matrizes com
coeﬁcientes reais tais que:

vi =

r
(cid:88)

j=1

aijwj

e wj =

r
(cid:88)

k=1

bjkvk,

ent˜ao AB = I.

Demonstra¸c˜ao.

Como α gera V e β ´e um conjunto L.I., segue que s (cid:54) r. Por outro lado, como β

gera V e α ´e um conjunto L.I., segue que r (cid:54) s. Portanto, r = s.

Sejam A e B tais que

vi =

r
(cid:88)

j=1

aijwj

e wj =

r
(cid:88)

k=1

ajkvk.

110

Logo

vi =

r
(cid:88)

j=1

aijwj =

=

r
(cid:88)

j=1

r
(cid:88)

aij

(cid:32) r

(cid:88)

k=1

(cid:32) r

(cid:88)

(cid:33)

ajkvk

(cid:33)

aijbjk

vk.

Como os v(cid:48)

is, para i = 1, ..., r, formam um conjunto L.I., isto acarreta que

k=1

j=1

r
(cid:88)

j=1

aijbjk = δik,

logo AB = I.

(cid:4)

Deﬁni¸c˜ao 37 (Dimens˜ao de um espa¸co vetorial:). O n´umero de elementos de uma base
de um espa¸co vetorial V de dimens˜ao ﬁnita ´e chamado de dimens˜ao de V .

Nota¸c˜ao:

(i) dimV : dimens˜ao de V ;

(ii) se V ´e o espa¸co vetorial nulo, ent˜ao dimV = 0.

Exemplo 48.

a) dim(R2) = 2, pois a base canˆonica de R2 tem n elementos. R2 ´e usualmente chamado

de espa¸co bidimensional;

b) dim(R3) = 3, pois a base canˆonica de R3 tem n elementos. R3 ´e usualmente chamado

de espa¸co tridimensional;

c) dim(Rn) = n, pois a base canˆonica de Rn tem n elementos;

d) dim(M(m, n)) = m × n;

e) dim(Pn) = n + 1, onde Pn ´e o espa¸co vetorial dos polinˆomios da forma a0 + a1x + ... +
anxn, sabendo-se que a base canˆonica deste ´e o conjunto α = {1, x, ..., xn}, a qual
possui n vetores.

Teorema A.3.12. Qualquer subconjunto L.I. de um espa¸co vetorial V de dimens˜ao ﬁnita
pode ser completado de modo a formar uma base de V .

Teorema A.3.13. Seja V um espa¸co vetorial de dimens˜ao ﬁnita; se W ´e um subespa¸co
de V , ent˜ao W tamb´em tem dimens˜ao ﬁnita e

al´em disso, se dimW = dimV , ent˜ao W = V .

dimW (cid:54) dimV,

111

Referˆencias Bibliogr´aﬁcas

[1] Anton, Howard; Chris Rorres; ´Algebra Linear com Aplica¸c˜oes: Porto Alegre,

Bookman, 2001.

[2] Boldrini, Jos´e Lu´ıs; ´Algebra Linear: S˜ao Paulo, Harper & Row do Brasil, 1980.

[3] Hefez, Abramo; Fernandez, Cec´ılia S.; Introdu¸c˜ao `a ´Agebra Linear: Rio de Ja-

neiro, SBM, 2012.

[4] Elseit, H.A.; Sandblom, C.–L.; Linear Programming and its applications:

Springer – Verlag Berlin Heidelberg, 2007.

[5] Webster, Roger; Convexity: Oxford University Press, 1994.

[6] B´arsov, A. S.; Qu´e es la programaci´on Lineal: Editorial MIR, Traducci´on al

espa˜nol: 1977.

[7] Solod´ovnikov, A. S.; Sistemas de Desigualdades Lineales: Editorial MIR, Tra-

ducci´on al espa˜nol: 1980.

[8] Barbosa, Ruy Madsen; Programa¸c˜ao Linear: S˜ao Paulo, Nobel, 1973.

[9] Puccini, Abelardo de Lima; Introdu¸c˜ao `a Programa¸c˜ao Linear: Rio de Janeiro,

Livros T´ecnicos e Cient´ıﬁcos Editora S. A., 1978.

[10] Beckman, F. S., The Solution of Linear Equations by the Conjugate Gradi-
ent Method, in Mathmatical Methods for Digital Computers 1, A. Ralston and H.
S. Wilf (editors), John Wiley, New York, 1960.

[11] Charnes, A., Optimality and Degeneracy in Linear Programming, Econome-

trica 20, 1952.

[12] Dantzig, G. B., Activity Analysis of Production and Allocation, T. C. Koop-

mans, John Wiley, New York, 1951.

[13] Ford, L. K. Jr., and Fulkerson, D. K., Flows in Networks, Princeton University

Press, Princeton, New Jersey, 1962.

[14] Hitchcock, F. L., The Distribution of a product from Several Sources to

Numerous Localities, J. Math. Phys. 20, 1941.

[15] Karmarkar, N. K., A New Polinomial-time Algorithm for Linear Program-

ming, Combinatorica 4, 1984.

112

[16] Koopmans, T. C., Optimum Utilization of the Transportation System, Pro-
ceedings of the International Statistical Conference, Washington, D. C., 1947.

[17] Lemke, C. E., The Dual Method of Solving the Linear Programming Pro-

blem, Naval Research Logistics Quarterly 1, 1, 1954.

[18] Kantorovich, L.V. The best use of economic resources, Moscow, 1959.

[19] Leontief, Wassily W., Input-Output Economics, 2nd ed., New York, Oxford Uni-

versity Press, 1986.

[20] Christodoulos A. Floudas and Panos M. Pardalos, Encyclopedia of Optimization,

second edition, Springer, 2009.

[21] Manne, A. S., Notes on Parametric Linear Programming, Rand Paper p. 468,

The Rand Corporation, Santa Monica, CA, 1953.

113


Universidade Federal de Goiás
Instituto de Matemática e Estatística
Programa de Mestrado Proﬁssional em
Matemática em Rede Nacional

Teoria de Resposta ao Item aplicada no ENEM

Sidney Tadeu Santiago Costa

Goiânia

2017

                                                                                                           TERMO DE CIÊNCIA E DE AUTORIZAÇÃO PARA DISPONIBILIZAR AS TESES E DISSERTAÇÕES ELETRÔNICAS NA BIBLIOTECA DIGITAL DA UFG  Na qualidade de titular dos direitos de autor, autorizo a Universidade Federal de Goiás (UFG) a disponibilizar, gratuitamente, por meio da Biblioteca Digital de Teses e Dissertações (BDTD/UFG), regulamentada pela Resolução CEPEC nº 832/2007, sem ressarcimento dos direi-tos autorais, de acordo com a Lei nº 9610/98, o documento conforme permissões assinaladas abaixo, para fins de leitura, impressão e/ou download, a título de divulgação da produção cien-tífica brasileira, a partir desta data.   1 1. Identificação do material bibliográfico:      [ X ] Dissertação         [  ] Tese   1 2. Identificação da Tese ou Dissertação 2  Nome completo do autor: Sidney Tadeu Santiago Costa  Título do trabalho: Teoria de Resposta ao Item Aplicada no ENEM   3. Informações de acesso ao documento:   Concorda com a liberação total do documento [ X  ] SIM          [   ] NÃO1  Havendo concordância com a disponibilização eletrônica, torna-se imprescindível o en-vio do(s) arquivo(s) em formato digital PDF da tese ou dissertação.      _______________________________________             Data: 03 / 03 / 2017                Assinatura do (a) autor (a) ²                                                  1  Neste caso o documento será embargado por até um ano a partir da data de defesa. A extensão deste prazo suscita justificativa junto à coordenação do curso. Os dados do documento não serão disponibilizados durante o período de embargo.    ²A assinatura deve ser escaneada.  Sidney Tadeu Santiago Costa

Teoria de Resposta ao Item aplicada no
ENEM

Trabalho de Conclusão de Curso apresentado ao Instituto de Matemática e Estatística
da Universidade Federal de Goiás, como parte dos requisitos para obtenção do grau de

Mestre em Matemática.

Área de Concentração: Estatística

Goiânia

2017

Ficha de identificação da obra elaborada pelo autor, através doPrograma de Geração Automática do Sistema de Bibliotecas da UFG.CDU 519.2COSTA, SIDNEY TADEU SANTIAGO      Teoria de Resposta ao Item aplicada no ENEM [manuscrito]  /SIDNEY TADEU SANTIAGO COSTA. - 2017.       72 f.: il.      Orientador: Prof. Fabiano Fortunato Teixeira dos Santos; coorientador José Waldemar da Silva.      Trabalho de Conclusão de Curso Stricto Sensu (Stricto Sensu) -Universidade Federal de Goiás, Instituto de Matemática e Estatística(IME), Programa de Pós-Graduação em Matemática, Goiânia, 2017.     Bibliografia. Apêndice.      Inclui símbolos, gráfico, tabelas, algoritmos, lista de figuras, listade tabelas.      1. Teoria de Resposta ao Item. 2. Método da MáximaVerossimilhança. I. dos Santos, Fabiano Fortunato Teixeira, orient. II.Título. Todos os direitos reservados. É proibida a reprodução total ou parcial deste trabalho

sem a autorização da universidade, do autor e do orientador.

Sidney Tadeu Santiago Costa é bacharel em Ciência da Computação e licenciado

em Matemática, concluiu a pós graduação latu senso em matemática aplicada e atua
desde 1995 como professor de matemática no ensino médio e pré vestibulares. Ministrou

aulas no ensino superior nos cursos de engenharia e administração por 5 anos.

Dedico esse trabalho a minha esposa Jaqueline Ferreira

Fernandes que me apoiou em todos os momentos e aos

meus ﬁlhos Ana Júlia e Heitor que dão sentido em tudo

na minha vida.

Lista de Figuras

1.1 Curva característica do item . . . . . . . . . . . . . . . . . . . . . . . .

18

2.1 Gráﬁco da probabilidade de sucesso em função da habilidade . . . . . .

2.2 Alteração da constante de proporção . . . . . . . . . . . . . . . . . . .

2.3 Variações do parâmetro de diﬁculdade
. . . . . . . . . . . . . . . . . .
2.4 Variações do parâmetro de discriminação . . . . . . . . . . . . . . . . .

2.5 Escala de transformação do acerto casual . . . . . . . . . . . . . . . . .

2.6 Curva característica ideal para o parâmetro de discriminação . . . . . .

3.1 Algoritmo de Newton-Raphson . . . . . . . . . . . . . . . . . . . . . .

3.2 Estimação dos parâmetros e das habilidades

. . . . . . . . . . . . . . .

3.3 Quantidade de iterações realizadas na estimação . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . .
3.4 Planilha com 10 itens e 16 respondentes

3.5 Planilha com os valores estimados . . . . . . . . . . . . . . . . . . . . .

4.1 Resultados para ciências humanas - software R . . . . . . . . . . . . . .
4.2 Resultados para ciências humanas - planilha eletrônica . . . . . . . . .

4.3 Comparação entre resultados para ciências humanas - faixa de 36 até 41

25

26

27
28

29

31

41

42

43
44

46

49
50

acertos

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

52

4.4 Comparação entre resultados para ciências humanas - faixa de 14 até 21
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

acertos

53

4.5 Comparação entre resultados para ciências humanas - faixa de 3 até 16

acertos

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

54

8

Sumário

1 Introdução

1.1 Teoria clássica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Visão geral da TRI . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.3 A curva característica do item - CCI

. . . . . . . . . . . . . . . . . . .

2 Referencial Teórico

2.1 Evolução histórica dos modelos

. . . . . . . . . . . . . . . . . . . . . .

Suposições da TRI

2.1.1
. . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 Modelagem matemática . . . . . . . . . . . . . . . . . . . . . .

2.2 Características gerais dos parâmetros . . . . . . . . . . . . . . . . . . .

3 Estimação dos Parâmetros

3.1 Método da máxima verossimilhança . . . . . . . . . . . . . . . . . . . .

3.2 Aplicação das fórmulas . . . . . . . . . . . . . . . . . . . . . . . . . . .
Implementação do processo de estimação . . . . . . . . . . . . . . . . .
3.3

4 Resultados e Discussões

4.1 Tratamento dos dados no software R . . . . . . . . . . . . . . . . . . .

4.2 Tratamento dos dados nos algoritmos implementados . . . . . . . . . .

5 Conclusão

13

14
15

18

20

20

20
22

30

33

34

39
43

48

48

50

56

9

Agradecimentos

Agradeço aos amigos que me apoiaram no desenvolvimento da pesquisa, ao orientador
professor Dr. Fabiano que, apesar da distância, possibilitou a realização do trabalho.

Um agradecimento especial ao professor Dr. José Waldemar da Universidade Federal

de Uberlândia, que se propôs, de forma atenciosa e prestativa, ajudar nessa pesquisa.

Agradeço aos alunos que contribuiram com dúvidas durante as oﬁcinas sobre a Teoria

de Resposta ao Item no ENEM.

10

Resumo

Com a nota obtida no Exame Nacional do Ensino Médio - ENEM os estudantes
podem se candidatar a vagas em diversas instituições públicas de ensino superior e

programas do governo, por exemplo, o programa Universidade para Todos (Prouni)

e o Fundo de Financiamento Estudantil (Fies). O ENEM utiliza uma metodologia

de correção das questões objetivas denominada Teoria de Resposta ao Item - TRI,
que possui vários aspectos que são diferentes da Teoria Clássica dos Testes - TCT.

O principal fator que determina o resultado de um sujeito em um processo avaliativo

onde se utiliza a TCT, é o número de respostas corretas, enquanto na TRI, além da

quantidade de acertos é fundamental se analisar quais respostas estão corretas. O
objetivo deste trabalho é explicar o que é a TRI e como se aplica essa metodologia em

avaliações de larga escala.

Será feita uma abordagem histórica dos modelos logísticos utilizados pela TRI e

a justiﬁcativa da existência de cada parâmetro que compõe a equação principal da
modelagem. Para determinar cada parâmetro que compõe o modelo da TRI e cal-

cular a nota ﬁnal de cada candidato, será utilizado um procedimento de otimização

denominado Método da Máxima Verossimilhança - MMV.

As ferramentas computacionais no trabalho foram o software R, com pacotes de-
senvolvidos para aplicação da TRI e a linguagem de programação Visual Basic para

programar funções, denominadas como macros, em planilhas eletrônicas.

Palavras-Chaves: Teoria de Resposta ao Item, Método da Máxima Verossimi-

lhança.

11

Abstract

With the note gotten in the Exame Nacional do Ensino Médio - ENEM the students
can applay the vacant in diverse public institutions of superior education and programs

of the government, for example, the program Universidade para Todos(Prouni) and

the Fundo de Financiamento Estudantil (Fies). The ENEM uses a methodology of

correction of the objective questions called Theory of Reply to the Item - TRI, that
has some aspects that are diﬀerent of the Classic Theory of the Tests - TCT. The

main factor that determines the result of a citizen in a avaliativo process where if uses

the TCT, is the number of correct answers, while in the TRI, beyond the amount of

rightnesss is basic if to analyze which answers they are correct. The objective of this
work is to explain what it is the TRI and as if it applies this methodology in evaluations

of wide scale.

A historical boarding of the logistic models used by the TRI and the justiﬁcation

of the existence of each parameter will be made that composes the main equation of
the modeling. To determine each parameter that composes the model of the TRI and

to calculate the ﬁnal note of each candidate, a procedure of called optimization will be

used Method of Maximum Probability - MMV.

The computational tools in the work had been software R, with packages developed
for application of the TRI and the Visual programming language beginner’s all-purpose

symbolic instruction code to program functions, called as macros, in electronic spread

sheets.

Key Works:

Item Response Theory - IRT, Maximum Likelihood Method - MMV.

12

Capítulo 1

Introdução

Este trabalho sobre a Teoria de Resposta ao Item (TRI) tem como foco a avaliação no

sistema educacional para processos em que são envolvidos vários indivíduos, conhecidos

como avaliações em larga escala. O Exame Nacional do Ensino Médio será o referencial

prático de toda a pesquisa e a aplicação das modelagens será com simulados aplicados
aos alunos do ensino básico em várias unidades de uma escola de ensino médio.

A TRI surgiu em meados dos anos 50, segundo Thurstone (1959), para resolver

o problema clássico de pisicometria relacionado a testes de inteligência; como propor

um teste de inteligência cujos resultados não variem de acordo com os instrumentos
utilizados? Imagine um problema análogo: o que aconteceria se o “metro” variasse na

medição de uma largura e altura de um prédio? Pois bem, para criar um instrumento

independente do objeto a ser avaliado, a TRI utiliza modelos e algoritmos matemáticos

de complexa operacionalidade, razão esta que justiﬁca a utilização dessa modelagem a
partir da evolução da computação.

O ENEM é uma prova aplicada uma vez ao ano e propõe uma avaliação por compe-

tências e habilidades ao ﬁnal do ensino básico e também confere a cada participante um

parâmetro para a auto-avaliação e orientação de seu processo de formação continuada.
Segundo Rabelo (2011), a partir de 2009, agregou-se novas funcionalidades ao exame,

ampliando-se o caráter de processo seletivo para o acesso às instituições de educação

superior, além de incorporar funções anteriormente atribuídas ao Exame Nacional para

Certiﬁcação de Competências de Jovens e Adultos (ENCCEJA) do ensino médio. Para
implantar essas mudanças, foi necessário recorrer às técnicas oriundas da TRI. A utili-

zação dessa teoria no ENEM abriu a possibilidade de se construir uma série histórica

13

do desempenho dos estudantes e dos egressos do ensino médio brasileiro, como é feito

com os resultados do SAEB e da Prova Brasil, segundo Silva Carvalho (2001).

Este trabalho será dividido em cinco partes. O primeiro capítulo é a introdução, que

possui a motivação e justiﬁcativa do tema escolhido bem como fundamentações teóricas

para a utilização da Teoria de Resposta ao Item. No segundo capítulo, apresentaremos

toda a evolução teórica dos modelos matemáticos da TRI. No terceiro, uma abordagem
das metodologias de estimação dos parâmetros e da habilidade de cada respondente

serão expostas. No quarto, será feita uma aplicação de todas as modelagens através do

software R e com algoritmos implementados do Visual Basic.

1.1 Teoria clássica

Quando os processos de avaliação e/ou processos de seleção utilizam escores bru-

tos ou padronizados obtidos com a análise direta dos acertos, quanto maior sua nota

(número de acertos) maior será sua classiﬁcação. Estatisticamente, esse procedimento
caracteriza análises e interpretações sempre associadas à prova como um todo e não

se aprofunda nas características de cada item. Essa é a vertente da Teoria Clássica

dos Testes - TCT, conforme descrito por Vianna (2014). Considere, por exemplo, um

teste com 45 itens aplicado para 1000 indivíduos, onde vários acertaram 30 itens, mas
ninguém acertou os mesmos exercícios. Será que todos que acertam o mesmo número

de itens, têm o mesmo conhecimento sobre tais assuntos? Provavelmente não, mas a

TCT não difere sujeitos que têm o mesmo número de acertos.

Para diferir cada sujeito dentro do teste, é necessário que se analise cada item que o
compõe. Essa é a pricipal diretriz da Teoria de Resposta ao Item: considerar caracte-

rísticas psicométricas de cada item, capazes de diferenciar os indivíduos que realizaram

um teste. Em muitas situações de medidas sociológicas, psicológicas ou educacionais, a

variável de interesse é de entendimento intuitivo para todos, no caso de uma avaliação
educacional como o ENEM, a variável é o conhecimento necessário para resolver um

problema. Porém, na maioria das vezes, ela não é observável diretamente. É isto que

a psicometria deﬁne como variáveis não observáveis ou habilidades ou traços latentes.

Embora essas variáveis possam ser facilmente descritas e listadas, por exemplo, a inte-
ligência, a habilidade em executar uma tarefa, ansiedade, o nível de entendimento de

texto etc, elas não podem ser medidas diretamente como o peso ou altura de uma pes-

soa. Apesar de todas serem características implícitas a cada ser humano. A meta das

14

medidas educacionais e psicológicas é determinar como os traços latentes se processam

na pessoa.

A TRI, de acordo com Lord (1968), se divide em duas etapas: a primeira é mensu-

rar parâmetros psicométricos como diﬁculdade, discriminação e probabilidade de acerto

casual, a partir das respostas de todos os sujeitos; em seguida, utiliza-se o conjunto

de respostas de cada respondente e um modelo matemático que depende de tais parâ-
metros para calcular o traço latente de cada participante do teste. Em linhas gerais,

a metodologia consiste em utilizar as respostas de todos os sujeitos para caracterizar

cada item do teste através de uma função e, com todas as funções dos itens, calcula-se

a habilidade de cada respondente para o padrão de respostas dicotômicas realizado no
teste, ou seja, quais itens acertou e quais errou.

No caso de processos de avaliação, cria-se uma escala de proﬁciência para atribuir

uma nota para cada habilidade. Para medir altura e comprimento que são observadas

diretamente, pode se utilizar o metro. A escala de proﬁciência é uma unidade análoga
ao metro, destinada ao processo de medir habilidades. No caso do ENEM, faz-se

uso de uma métrica com referência central igual a 500 (nota mínima média obtida

para conclusão do ensino médio em 2009) e desvio padrão 100, conforme proposto por

Pasquali (2007).

1.2 Visão geral da TRI

As avaliações fazem parte do processo de ensino e aprendizagem, elas envolvem troca

entre pessoas e devem sempre ser construtivas, como ressalta Perrenoud (1999), “antes
de regular as aprendizagens, a avaliação regula o trabalho, as atividades, as relações

de autoridade e a cooperação em aula (. . . ) ”

Quando se cria um teste, o objetivo principal é medir um traço latente: o nível de

conhecimento que o sujeito tem sobre determinado assunto, ou seja, qual conhecimento
que ele possui para resolver as situações problemas. Os testes podem ser compostos por

itens discursivos e itens objetivos. A prova discursiva é extremamente frágil à presença

de erros e difícil conﬁabilidade (ﬁdedignidade), pois dois avaliadores podem fazer lei-

turas antagônicas de um mesmo contexto ocasionando resultados discrepantes em uma
mesma avaliação. Entre pesquisadores da área de avaliação, o teste de resposta livre

(discursivo) e o teste objetivo devem ser utilizados para qualquer processo educacional;

entretanto, quando o número de examinados é muito grande, existe a necessidade de

15

resultados precisos e altamente ﬁdedignos, imparciais, justos e válidos. O teste objetivo

representa uma opção interessante, pois a correção ﬁca livre de erros de julgamentos
por parte dos examinadores, elimina-se a possibilidade de que um examinador valorize

testes com boa apresentação e com características que não são relevantes no processo

pretendido, e principalmente, tem-se rapidez na correção, conforme ressalta Vianna

(2014).

Para que se tenha uma visão geral de como funciona a TRI, considere um teste

composto por 10 itens com 5 alternativas e apenas uma correta, que foi aplicado para

16 sujeitos. As respostas foram organizadas em uma tabela conforme a Tabela 1.1. As

respostas são dicotômicas, ou seja, 1 indica acerto e 0 erro. Após uma soma dos acertos,
surgem dúvidas fundamentais para o processo de avaliação. Como diferir os respon-

dentes que acertaram a mesma quantidade de itens? Será possível que um sujeito que

acertou menos itens, tenha um conhecimento maior que outro que acertou mais? Por

que muitas pessoas acertaram o item 01 enquanto poucas o item 10? Todos os itens têm
o mesmo peso, no propósito de medir o nível de conhecimento do sujeito? Para que seja

possível determinar o grau de conhecimento (habilidade) dos indivíduos que realizam

o teste, a TRI propõe uma análise individual de cada item, mensurando característas

como discriminação, diﬁculdade e acerto casual e em seguida determinando a probabili-
dade de sucesso de um sujeito j, com habilidade θj, em um item i, denota-se por Pi(θj).
A habilidade de um sujeito é um valor real que varia no espectro de ] − ∞, ∞]. Todo o

processo é estruturado por um modelo matemático que será apresentado no Capítulo 2.

16

Tabela 1.1: Respostas após a aplicação do teste

No Sujeitos

I-01

I-02

I-03

I-04

I-05

I-06

I-07

I-08

I-09

I-10 Total

1

2

3

Ana

Bia

Carlos

4 Débora

5

6

7

8

9

10

11

12

Érica

Fábio

Gil

Heitor

Igor

Júlia

Kelly

Leo

13 Mário

14 Nubia

15 Otávio

16

Paulo

1

1

1

1

1

1

1

1

1

0

1

0

1

1

0

0

1

1

1

1

1

1

1

1

0

0

1

0

1

1

0

0

1

1

1

1

1

1

1

0

0

0

1

0

1

0

0

1

Total

12

11

10

1

1

1

1

1

1

0

0

0

0

1

0

0

0

1

1

9

1

1

1

1

1

0

0

0

0

0

1

0

0

0

1

1

8

1

1

1

1

0

0

0

0

0

0

0

1

0

0

1

1

7

1

1

1

0

0

0

0

0

0

0

0

1

0

0

1

1

6

1

1

0

0

0

0

0

0

0

0

0

1

0

1

1

0

5

1

0

0

0

0

0

0

0

0

0

0

1

1

1

0

0

4

0

0

0

0

0

0

0

0

0

1

0

1

1

1

0

0

4

9

8

7

6

5

4

3

2

1

1

5

5

5

5

5

5

A representação gráﬁca do modelo matemático utilizado na TRI é denominada

Curva Característica do Item - CCI. É possível compreender o que signiﬁca probabili-

dade de sucesso com este gráﬁco.

17

1.3 A curva característica do item - CCI

Competência é a capacidade de mobilização de recursos cognitivos, socioafetivos
ou psicomotores, estruturados em rede, com vistas a estabelecer relações com e entre

objetos, situações, fenômenos e pessoas para resolver, encaminhar e enfrentar situações

complexas. Segundo Perrenoud (1999), uma das características importantes da noção

de competência é desaﬁar o sujeito a mobilizar os recursos no contexto de situação-
problema para tomar decisões favoráveis a seu objetivo ou a suas metas. As habilidades

decorrem das competências adquiridas e referem-se ao plano imediato do saber fazer.

Por maior que seja a habilidade de uma pessoa na resolução de um item, ela pode não

ter sucesso e, por menor que seja sua habilidade, no caso do ENEM, ela pode fazer
uma escolha aleatória da resposta e acertá-la. É claro que o conceito de probabilidade

de acerto torna-se instríseco nesse processo. O gráﬁco da probabilidade de acerto em

função da habilidade é uma curva chamada de sigmóide, conforme a ﬁgura abaixo.

Figura 1.1: Curva característica do item

A proﬁciência do sujeito j é a habilidade θj que ele tem para resolver o item i,
representado no eixo horizontal. A métrica teórica desta variável vai de −∞ a +∞

mas, na prática, os valores estão aproximadamente de 0 a 1000, segundo Pasquali

18

(2007). A probabilidade de sucesso Pi(θj) é uma função que depende da habilidade
do respondente (θj) cujo gráﬁco é denominado de curva característica do item - CCI,
apresentado na ﬁgura 1.1. Nesta função, quanto maior a habilidade respondente, maior

será a probabilidade de sucesso no item, assim o gráﬁco é sempre crescente. A curva

possui uma assíntota superior igual a 1 e uma inferior igual ao valor do parâmetro

de acerto casual. Na prática, interpretamos que, quando uma pessoa sabe resolver
o item, a probabilidade de acertar tende a 100% e, caso contrário, ela deve escolher

a resposta aleatoriamente, ou seja, a probabilidade de sucesso é igual ao valor do

parâmetro de acerto casual, denotado pela letra c. A CCI possui um ponto de inﬂexão

onde a inclinação da reta tangente representa o parâmetro de discriminação do item. A
derivada da função em cada ponto mostra que antes do ponto de inﬂexão, o crescimento

da probabilidade de acerto é maior e depois menor.

Para justiﬁcar e aplicar toda a modelagem matemática da TRI, existe uma evolução

histórica de cada modelo que foi apoiado em fatos e teoremas que serão explicados e
aplicados com exemplos no próximo capítulo deste trabalho.

19

Capítulo 2

Referencial Teórico

A Teoria de Resposta ao Item é uma metodologia que mensura o nível de conhe-

cimento sobre determinado conteúdo que uma pessoa tem ao realizar um teste. Para

compreender todo o processo matemático existente nessa teoria, este capítulo apresenta

os postulados da TRI e contextualiza a evolução histórica dos modelos matemáticos
compostos por equações diferenciais ordinárias - EDO’s.

2.1 Evolução histórica dos modelos

A proposta da TRI é expressar, por funções, a relação existente entre variáveis ob-

servadas e variáveis hipotéticas, chamadas de habilidade, traço latente ou proﬁciência.
Assim, se conhecemos as características das variáveis observadas (parâmetros dos itens

de um teste), estas se tornam constantes na equação, passam a ser denotadas como

parâmetros e a equação torna-se solucionável, permitindo que se estime então o nível

de aptidão do sujeito e vice-versa; isto é, se for conhecido o nível do traço latente do
sujeito, é possível estimar as características do itens respondidos por este sujeito. A

seguir tem-se os dois postulados da Teoria de Resposta ao Item.

2.1.1 Suposições da TRI

A teoria do traço latente possui dois princípios especiais ou básicos: a unidimen-

sionalidade e a independência local. São suposições fundamentais que são ditas

20

hipóteses e não podem ser demonstradas e sim testadas, logo são aceitas ou não. Note

que um modelo matemático para funcionar e ser útil precisa de algumas suposições en-
tre o modelo e os dados, estabelecendo relações entre variáveis observáveis e empíricas.

Mesmo não sendo demonstradas previamente, as suposições de forma indireta através

de resultados podem levar a modelos práticos satisfatórios.

A unidimensionalidade

As teorias dos traços latentes mostram que por de trás de um desempenho com-

portamental qualquer, existe um conjunto de variáveis que podem ser observadas e
determinadas. Assim, um sujeito que se situa em um espaço de n dimensões, pos-

sui uma proﬁciência que pode ser expressa como função de um vetor de habilidades
(θ1, θ2, θ3, . . . , θn), ou seja:

Proﬁciência = f (θ1, θ2, θ3, . . . , θn)

É razoável aceitar que o pensamento humano seja multideterminado, ou seja, um
grupo de traços latentes são executados na resolução de um problema. Fazendo uma

análise superﬁcial, esse fato compromete o princípio em questão, todavia, é suﬁciente

assumir que na execução de uma tarefa, há uma aptidão dominante responsável pelo

desempenho do respondente. Muitas pesquisas buscam soluções para modelos multidi-
mensionais, entretanto, a TRI não possui modelos satisfatórios para esse caso, segundo

Pasquali (2007). Resumindo, embora um sujeito possua um conjunto de habilidades
(θ1, θ2, θ3, . . . , θn) necessárias para resolver um item, este postulado assume que existe
um θ = θj, para algum j, que será dominante, ou seja,

Proﬁciência = f (θ).

A independência local

Considerando que exista uma aptidão dominante responsável pela resposta de um

indivíduo, assume-se o fato de que as respostas fornecidas a dois itens diferentes são

eventos independentes. Esse é o axioma da Independência Local. Assim, este princípio

decorre que a sequência de respostas do sujeito a uma série de itens é igual ao produto
das probabilidades de sucesso ou fracasso de cada item separadamente.

Seja a probabilidade do sujeito j, com habilidade θj que deu a resposta dicotômica
uji no o item i, denotada por P (uji|θj). A proposta matemática do princípio da

21

independência local, considerando que a probabilidade de sucesso em cada item do

teste é um evento independente, é representada da seguinte forma:

P (uj1, uj2, uj3, . . . , ujI|θj) = P1(uj1|θj) · P2(uj2|θj) · . . . · PI(ujI|θj) ,

onde o número total de sujeitos é N , o número total de itens é I, i ∈ {1, 2, . . . , I} e

j ∈ {1, 2, . . . , N }. A habilidade do sujeito j é considerada aptidão dominante para
a resolução do item i e é denotada por θj. A resposta do sujeito j dada ao item i
é dicotômica, ou seja, uji = 1 resposta correta e caso contrário, uji = 0. Por ﬁm, a
probabilidade de sucesso é Pi(ui = 1|θj) e a probabilidade de fracasso é Pi(ui = 0|θj).
De acordo com a independência local, se houver alguma relação entre as respostas de

um sujeito em vários itens, a justiﬁcativa não será por causa da habilidade dominante;

logo, mantendo constantes tais fatores, é possível concluir que a única fonte de variação
de resposta será em função da aptidão, assim as respostas tornam-se independentes e

inﬂuenciadas apenas pelo teta dominante. Em resumo, a independência local implica

na unidimensionalidade; então, se a última for comprovada a primeira também será.

Outra informação relevante é que a independência local propõe a independência das
respostas do sujeito, isto não signiﬁca que os itens não possam ser relacionados. Quando

existe uma relação entre os itens, ela será deﬁnida pelo grupo de respondentes que

possuem traços latentes próximos, logo respondem de forma semelhante.

Quando um indivíduo responde a uma série de itens, ele produz um padrão de
respostas, composto pelos produtos das probabilidades (Pi para acerto e Qi = 1 − Pi
para erro). Como exemplo, para três itens e uma probabilidade individual de acerto
igual a 1
5, um padrão de resposta com acerto nas duas primeiras e erro na última é
dado por: P1 · P2 · Q3 = 0, 2 · 0, 2 · 0, 8 = 0, 032.
Na próxima seção, tem-se a dedução da equação que determina a probabilidade de
sucesso em função de habilidade do sujeito.

2.1.2 Modelagem matemática

Vários fenômenos envolvem a variação de uma grandeza em função de outra, levando

naturalmente a modelos baseados em equações diferenciais. Pode-se ter variações tem-
porais da posição de um objeto, temperatura de um material, concentração de um

agente químico, nutriente ou poluente em um meio, umidade do ar, quantidade de

habitantes de uma cidade, densidade de bactérias, massa de um gás, valor de uma

mercadoria, câmbio entre moedas, produto interno bruto e outras. Existem também as

22

variações em relação a outras grandezas como temperatura e posição, densidade e tem-

peratura, a probabilidade de sucesso em um item e a habilidade de quem o respondeu,
entre outras, segundo Kent (2012). As equações diferenciais representam diversas leis

fundamentais. Podem ser empíricas, como em reações químicas, ou heurísticas, como

em dinâmica populacional, modelo que foi aplicado na TRI, segundo Baker (2001), em

meados de 1950. O ajuste da função utilizada na TRI é análogo ao processo utilizado
no crescimento populacional e passou por duas propostas. Inicialmente, a proposta de

Malthus, onde a taxa de variação do número de indivíduos no instante t é proporcional

à quantidade de indivíduos presentes no ambiente neste instante. Seja N o número de

indivíduos em um tempo t e k uma constante de proporção; assim a EDO é

dN
dt = kN .

Supondo N (0) = N0, a solução é dada por:

N (t) = N0ekt.

Para k < 0 a população decresce e, caso contrário, a população cresce sem limites.

Como existem limitações do ambiente como a falta de alimentos para toda a popula-

ção, doenças, predadores, alterações climáticas e outras, este modelo torna-se pouco
satisfatório para um longo prazo.

A segunda modelagem, denominada Modelo de Verhulst-Pearl, considera que a

taxa de variação do número de indivíduos é proporcional à quantidade de indivíduos

presentes no ambiente (N ) e quantidade de indivíduos que completaria a capacidade
do ambiente (L) . Neste caso a EDO é escrita assim

dN

dt = kN (cid:0)1 − L

N

(cid:1),

onde k é uma constante de proporção, com N (0) = N0 tem solução particular dada
por:

N (t) =

L
−1

(cid:17)

e−kt

.

1+

(cid:16) L
N0

Neste caso, o número de indivíduos ﬁcará sempre entre a quantidade existente no
tempo zero e a capacidade do ambiente, podendo ser determinada mesmo quando

o tempo é grande. Para a TRI, tem-se que a variável que representa o número de

indivíduos na dinâmica populacional passa ser a probabilidade de acerto em um item, de

acordo com Fletcher (1994). A equação diferencial será apresentada adiante. Considere

23

uma pessoa com habilidade θ; ao resolver um item, sua probabilidade de sucesso será

P e fracasso, 1 − P . Para uma habilidade nula (θ = 0) a probabilidade de sucesso e
fracasso são iguais, ou seja, θ = 0 e P = 1
2. Assim a taxa de variação da probabilidade
é proporcional à probabilidade de sucesso e fracasso. Ressaltando que a probabilidade

de sucesso P é uma função que depende da habilidade θ, ou seja, P = f (θ), a EDO é

dP
dθ

= kP (1 − P )·

(2.1)

Considere k uma constante de proporção. Utilizando o método da separação de

variáveis proposto no estudo de equações diferenciais, tem-se:

Como

1
P (1 − P )

=

1
P

(cid:90)

dP
P (1 − P )

(cid:90)

=

kdθ.

+

1
1 − P
(cid:90) (cid:18) 1
P

, segue que

(cid:19)

+

1
1 − P

(cid:90)

dP =

kdθ.

Logo,

Segue que

ln(P ) − ln(1 − P ) = kθ + C ⇒ ln

(cid:18) P

(cid:19)

1 − P

= kθ + C.

ekθeC =

P
1 − P

.

Como θ = 0 e P = 1

2, fazendo as substituições devidas chega-se em C = 1. Fina-
lizando a resolução da EDO, chega-se na equação que determina a probabilidade de

sucesso em função da habilidade de um sujeito

ou seja,

ekθ =

P
1 − P

;

P = P (θ) =

1
1 + e−kθ ·

24

(2.2)

Adotando no eixo das abscissas a escala de proﬁciência denominada habilidade θ

e no eixo das ordenadas a probabilidade de acerto P (θ), o gráﬁco da função (2.2), é
representado pela ﬁgura adiante.

Figura 2.1: Gráﬁco da probabilidade de sucesso em função da habilidade

Nota-se que o gráﬁco é uma curva crescente. Para habilidades muito pequenas,
a probabilidade de sucesso tende a zero e, em caso oposto, a probabilidade tende

a um. Existe um ponto de inﬂexão em θ = 0 e para valores do domínio θ < −3 ou

θ > 3, a variação na probabilidade torna-se muito pequena, fato que pode ser veriﬁcado

calculando-se a derivada em tais pontos. Com relação à constante de proporção k,
segundo Rabelo (2011), para k = 1, 7 a função (2.2), possui o gráﬁco semelhante ao

gráﬁco da função de distribuição de uma Gaussiana. A ﬁgura 2.2 mostra a variação da

constante, de k = 1 para k = 1, 7.

25

Figura 2.2: Alteração da constante de proporção

Para k < 0, a função não tem representatividade, pois é decrescente (a habilidade

aumenta e a probabilidade diminui) e para k = 0 não existe variação de probabilidade,
tem-se uma função constante que não se aplica na TRI. Por ﬁm, para simpliﬁcar as

demonstrações dos modelos que introduziram os parâmetros psicométricos de discri-

minação, diﬁculdade e acerto casual, adota-se k = 1, como estabelecido em Pasquali

(2007).

O modelo logístico com um parâmetro surge pela translação horizontal do gráﬁco da

função (2.2) denotado por b. Se b < 0 gráﬁco desloca para a direita e caso contrário

para a esquerda. Para b = 0 o ponto de infexão será θ = 0. Este parâmetro está

na mesma escala da habilidade. O modelo apresentado na função (2.2) sofre uma
modiﬁcação determinando o modelo logístico - ML1, representado pela lei:

P (θ) =

1
1 + e−(θ−b) ·

(2.3)

A ﬁgura 2.3 representa as translações deﬁnidas pelas modiﬁcações do parâmetro de

diﬁculdade aplicado na função (2.3).

26

Figura 2.3: Variações do parâmetro de diﬁculdade

Considere um valor ﬁxo para a probabilidade de sucesso em um item, o desloca-

mento para a direita do gráﬁco (2.3) signiﬁca que a habilidade para acertar o item
deve aumentar, conclui-se que a diﬁculdade do item aumenta. Quando o deslocamento

ocorre para a esquerda, a diﬁculdade diminui.

Para o modelo logístico de dois parâmetros - ML2, surge um parâmetro capaz

de diferenciar sujeitos com habilidades muito próximas, chamado discriminação (a).
Retomando a equação diferencial apresentada na equação 2.1 e considerando que a

taxa de probabilidade de sucesso seja proporcional à probabilidade de sucesso, fracasso

e ao valor do parâmetro de discriminação do item, chega-se na seguinte EDO

dP
dθ

= kP (1 − P )a·

(2.4)

Note que o parâmetro discriminação (a) no processo de resolução das integrais é uma

constante, pois os diferenciais são dP e dθ . Assim, utilizando a mesma técnica para

resolver equações diferencias separáveis apresentado anteriormente, o modelo logístico

de dois parâmetros é modelado por

P (θ) =

1
1 + e−a(θ−b) ·

27

(2.5)

Aumentando o parâmetro de discriminação, a curva sigmóide torna-se bem abau-

lada, determinando valores diferentes para habilidades bem próximas, conforme apre-
sentado na ﬁgura adiante.

Figura 2.4: Variações do parâmetro de discriminação

Por ﬁm, tem-se o modelo logístico com três parâmetros - ML3, com o parâmetro
de acerto casual denotado por c. No Enem, assim como qualquer avaliação objetiva,

a escolha de uma resposta para um item pode ser feita de forma aleatória e, com

cinco alternativas (apenas uma correta) a probabilidade mínima de sucesso, passa de

0 para 0.2. Para introduzir esta propriedade na função 2.5 é necessário realizar uma
tranformação linear. A ﬁgura 2.5 mostra os valores de referência utilizados para a

transformação dos valores de probabilidade.

28

Figura 2.5: Escala de transformação do acerto casual

Para ﬁnalizar a função a ser utilizada na TRI, falta apenas considerar a escolha

aleatória da resposta do item, ou seja, o chute. Por se tratar de itens objetivos, a
menor probabilidade de acerto no item deixa de ser zero (assíntota inferior) e passa para

20% (cada item tem cinco alternativas sendo apenas uma correta). Esta característica

desloca a parte inferior da CCI para cima. O deslocamento do limite inferior é feito

por uma mudança de escala que utiliza os valores extremos como referência. Note
que a probabilidade mínima na escala do modelo de dois parâmetros é zero, e no

novo modelo é igual ao valor parâmetro de acerto casual (c = 20%), já os valores

máximos continuam sendo um, assim, a ideia do modelo de três parâmetros é criar

uma correspondência de cada probabilidade do ML2, no intervalo de 0 a 1, com um
único valor de probabilidade no intervalo de c até 1. Essa correspondência é feita de

forma proporcional, cada variação de probabilidades em um modelo é proporcional à

variação de porbabilidades do outro. Seja x o valor da probabilidade na função (2.5) e

y a nova probabilidade no ML3, a proporção entre as variações de probabilidades será

ou seja,

x − 0
y − c

=

1 − 0
1 − c

,

y = c + (1 − c)x.

Assim o modelo com três parâmetros ﬁca:

P (θ) = c + (1 − c)

1
1 + e−a(θ−b)

29

(2.6)

Esta função representa a modelagem fundamental da TRI, o modelo matemático

que, uma vez determinados os parâmetros de diﬁculdade (b), a discriminação (a) e o
acerto casual (c); é possível calcular a probabilidade de um sujeito acertar o item de

um teste.

Para reescrever a igualdade 2.6 , considera-se que o teste é composto por I itens que

serão resolvidos por N de indivíduos com i ∈ {1, 2, . . . , I} e j ∈ {1, 2, . . . , N }.
Segue que:

Pi(θj) = ci +

1 − ci
1 + e−ai.(θj −bi) ,

(2.7)

onde θj é a habilidade do indivíduo j, Pi(θj) probabilidade do indivíduo j acertar o
item i, ai é a discriminação do item i, bi é a diﬁculdade do item i e ci é o acerto casual
do item i.

A próxima seção aborda as principais características dos parâmetros e os valores

esperados para que a função 2.7 possa representar a probabilidade de acerto em um

item.

2.2 Características gerais dos parâmetros

No ML3 existe uma habilidade latente que justiﬁca o acerto ou erro de um sujeito

em cada item isoladamente. O modelo matemático proposto na função 2.7 deﬁne que,

para cada item, existe um nível de discriminação (a), a diﬁculdade do item (b) e acerto
casual (c). Os valores de cada parâmetro estão em uma escala contínua e possuem

interpretações especíﬁcas. No próximo capítulo será feita uma abordagem de como os

valores de cada um dos parâmetros são calculados.

A discriminação deve ser concebida como a capacidade do item em diferenciar in-
divíduos com habilidades diferentes. Na TRI, a discriminação é o parâmetro capaz

de diferenciar os sujeitos com traços latentes próximos na competência a ser aferida.

Na curva característica de cada item, a discriminação é dada pelo coeﬁciente angular

da reta tangente no ponto de inﬂexão (ponto onde o gráﬁco muda a concavidade).
Quanto maior o valor do parâmetro de discrimanação (a), mais íngrime será a curva

e mais discriminativo será o item. Valores próximos de zero indicam que o item tem

baixo poder de diferenciar os respondendes que sabem dos que não têm o conhecimento

necessário para responder a questão, assim não cumpre os propósitos de uma avalia-
ção educacional. Valores negativos para o parâmetro de discriminação indicam que o

30

item se comporta de maneira incoerente, pois o aumento da habilidade implicaria na

diminuição da probabilidade de acerto, assim considera-se apenas os valores positivos
(a > 0).

Para o parâmetro de discriminação, espera-se valores entre 0 e 2, sendo que os valores

mais apropriados são aqueles maiores que um, de acordo com Rabelo (2011). Diante

disso, o gráﬁco ideal é dado pela ﬁgura abaixo.

Figura 2.6: Curva característica ideal para o parâmetro de discriminação

A diﬁculdade é o valor da aptidão θ necessário para se obter uma probabilidade
de acerto igual a 1+c
2 , ou seja, quando a habilidade é igual a diﬁculdade (θ − b = 0)
na função 2.7. Quando não é permitido a escolha aleatória, a diﬁculdade é o valor da
habilidade que produz a probabilidade de 0.5 de sucesso para o item. Quanto maior for

o nível de aptidão necessário para que o sujeito acerte o item, maior será a diﬁculdade

do mesmo. A diﬁculdade é representada em uma escala contínua que varia no intervalo

(−∞, ∞) . Itens com valores de b menores que −3 são considerados muito fáceis, entre
−3 e −1 fáceis, entre −1 e 1 intermediários, entre 1 e 3 difíceis e os valores maiores

que 3 muito difíceis. O nível de diﬁculdade ideal para os itens de um teste depende

da sua ﬁnalidade. Em avaliações educacionais, recomenda-se uma distribuição dentro

de uma curva normal: 10% dos itens em cada uma das faixas extremas (muito fácil

31

e muito difícil), 20% em cada uma das faixas seguintes (fácil e difícil) e 40% na faixa

média (intermediária), segundo Pasquali (2007). A seguir tem-se a tabela dos níveis
de diﬁculdade esperados para um item.

Tabela 2.1: Níveis para o parâmetro diﬁculdade

Classiﬁcação Valores para o parâmetro

Muito Fácil

b ≤ −3

Fácil

−3 < b < −1

Itermédiário

−1 ≤ b < 1

Difícil

1 ≤ b < 3

Muito Difícil

b ≥ 3

O Parâmetro de acerto casual aumenta a probabiliade de acerto no item, deslocando
para cima a assíntota inferior; no caso do Enem, esse valor é 20%. Nota-se que esse

parâmetro aumenta a probabilidade de sucesso, veja o exemplo a seguir. Para θ = 2,

a = b = 1 e c = 0, a probabilidade de sucesso, aplicando a equação 2.5 resulta em

P (θ = 2) =

1

1 + 2 · 7−1·(2−1) = 0, 73

e no ML3 da equação 2.6 o resultado ﬁca

P (θ = 2) = 0, 2 + 0, 8 ·

1

1 + 2 · 7−1·(2−1) = 0, 78.

Isto é, com o acerto casual, o item torna-se hipoteticamente mais fácil, subindo sua

probabilidade de acerto de 73% para 78%.

Cada item possui seus parâmetros com valores especíﬁcos que são calculados por

estimação. Este procedimento matemático será explicado no próximo capítulo. A ha-

bilidade de cada respondente também será estimada da mesma forma. A estimação

supõe um valor inicial para cada parâmetro e para a habilidade, em seguida, aplica-se
várias regras e os valores são atualizados veriﬁcando se houve uma convergência dos

valores calculados nas iterações anteriores, tornando tais valores constantes, denomi-

nados os parâmetros dos itens. Os parâmetros calculados deﬁnem uma função para

cada item e com as funções de todos os itens é possível calcular a habilidade que cada
sujeito possui. Com a habilidade ou proﬁciência, tem-se a nota ﬁnal obtida no teste.

32

Capítulo 3

Estimação dos Parâmetros

A estimação de parâmetros trabalha com probabilidades de eventos independentes.

De fato, a independência das respostas dos respondentes é um postulado na teoria

(independência local). Dois ou mais eventos consideram-se independentes entre si se

a ocorrência ou a não-ocorrência de um não inﬂuencia a ocorrência do(s) outro(s),
segundo Stevenso (1981). Se dois ou mais eventos são independentes, então a proba-

bilidade de ocorrência simultânea de todos é igual ao produto de suas probabilidades
individuais. Para n eventos A1, A2, . . . , An, temos:

P (A1 e A2 e . . . e An) = P (A1) · P (A2) · . . . · P (An)

Quando os eventos são mutuamente excludentes, a probabilidade de ocorrência de

qualquer deles (por deﬁnição, não podem ocorrem dois ou mais conjuntamente) é a
soma das probabilidades individuais. Generalizando, temos:

P (A1 ou A2 ou . . . ou An) = P (A1) + P (A2) + . . . + P (An)

Para estimar os parâmetros e a habilidade, utiliza-se um padrão de respostas con-

forme apresentado na seção 2.1.1.

Uma das etapas mais importantes da TRI é a estimação dos parâmetros dos itens e

das habilidades dos respondentes. A probabilidade de uma resposta correta a um de-

terminado item depende da habilidade do indivíduo e dos parâmetros que caracterizam
o item. Mas, em geral, ambos são desconhecidos. Apenas as respostas dos indivíduos

aos itens do teste são conhecidas.

Tem-se um problema bastante complicado cujo objetivo é calcular os parâmetros

(discriminação, diﬁculdade e acerto casual) e em seguida determinar a proﬁciência

33

(habilidade) de um sujeito. Para resolver o problema, a TRI utiliza o método da

máxima verossimilhança. Este método é um processo matemático que otimiza uma
função (chamada função de verossimilhança) através de algoritmos iterativos. Neste

trabalho utilizaremos o algoritmo de Newton-Raphson.

Na próxima seção serão apresentadas todos os modelos matemáticos utilizados na

aplicação do método da máxima verrossimilhança para estimar os parâmetros de todos
os itens e as habilidades de todos os respondentes que realizaram um teste.

3.1 Método da máxima verossimilhança

Considere um teste composto por I itens respondidos por N sujeitos (i ∈ {1, 2, . . . , I}
e j ∈ {1, 2, . . . , N }) de forma que cada resposta, dada pela pessoa j ao item i, seja de-
terminada pela função uji de forma que para uji = 1 a resposta do sujeito está correta
e para uji = 0 a resposta está errada. A probabilidade de sucesso do sujeito j no item
i é calculada pela função 2.7 e será expressa por Pi(θj) ou simplesmente Pi. Por ﬁm,
tem-se o evento complementar deﬁnido pelo fracasso no item e denotado por Qi = 1−Pi.

Pelo princípio da independência local, deﬁne-se uma função l, como produto das

probabilidades para um padrão de respostas dadas pelo sujeito j a todos os I itens. A

função l é deﬁnida por:

l =

I
(cid:89)

i=1

Pi(θj)uji · Qi(θj)1−uji.

(3.1)

O objetivo é calcular o valor de cada parâmetro ai, bi e ci de todos os itens e
a habilidade θj de cada respondente, que determinam o maior valor para a função
l. Para isso, a TRI utiliza o método da máxima verossimilhança. A função (3.1)
será chamada de função de verossimilhança. Em linhas gerais, o processo consiste em

calcular uma raiz da derivada da função l. Sabe-se que a derivada de um produto de

funções é bem mais complicada que a derivada da soma, dessa forma uma técnica útil,

consiste em tormar o logaritmo em ambos os membros de (3.1). Assim, chamando de
L = ln(l), obtemos:

34

L = ln

(cid:32) I

(cid:89)

i=1

Pi(θj)uji · Qi(θj)1−uji

(cid:33)

=

=

I
(cid:88)

i=1
I
(cid:88)

i=1

ln(Pi(θj)uji · Qi(θj)1−uji)

uji · ln(Pi(θj)) + (1 − uji) · ln(Qi(θj)).

(3.2)

Para veriﬁcar se existe, e em caso positivo determinar a raiz da derivada implícita

da função (3.2) em relação a cada parâmetro e em seguida em relação à habilidade,

utilizaremos o método iterativo de Newton-Raphson. Este método foi inicialmente

introduzido por Isaac Newton para determinar as raízes de uma função por meio de
sucessivas iterações. Neste método, começa-se com um valor arbitrário para x e, em

seguida, em repetidas iterações, vão se fazendo pequenas mudanças para melhorar a

aproximação à solução. Mais tarde, Joseph Raphson melhorou o método de Newton,

introduzindo as derivadas nas repetidas iterações para resolver equações lineares e não-
lineares.

Para compreender melhor o algoritmo, considere uma função f (x) real, de variável

real que possui uma raiz. Para encontrar o valor desta raiz, devemos encontrar um

valor de x tal que f (x) = 0. Utilizando o método de Newton-Raphson, fazemos uma
atribuição inicial xn = x0, com n ∈ N, calculamos a derivada da função no ponto com
abscissa x0 e aplicamos, para n = 0, a fórmula :

xn+1 = xn −

f (xn)
f (cid:48)(xn)

,

(3.3)

onde xn é valor para x, xn+1 é um valor obtido com a aplicação da fórmula (3.5), f (xn)
é o valor da função f em xn e f (cid:48)(xn) é o valor da primeira derivada da função f em xn.
Com o valor obtido com a aplicação da fórmula (3.5), calcula-se a diferença entre x1
e x0, caso a diferença seja tão pequena quanto se queira, a raiz foi encontrada, caso
contrário, atualizamos o valor de xn e realizamos uma nova iteração.

Para aplicar Newton-Raphson na função (3.2) a função f (x) será a primeira derivada
de L porque o objetivo é encontrar o valor máximo da função L, ou seja, L(cid:48) = 0
e f (cid:48)(x) será a segunda derivada da função L. Sem perda de generalidade, adota-se

35

Pji(uji = 1|θj) = P , Pji(uji = 0|θj) = Q, θj = θ , ai = a , bi = b, ci = c, uji = u e as
representações de derivadas implícitas como ∂L
∂a2 = L(cid:48)(cid:48)
a,
∂L
∂c = L(cid:48)
∂b = L(cid:48)

∂c2 = L(cid:48)(cid:48)
c .

∂θ2 = L(cid:48)(cid:48)

∂b2 = L(cid:48)(cid:48)

∂a = L(cid:48)

∂θ = L(cid:48)

c e ∂2L

a , ∂2L

θ , ∂2L

b , ∂2L

θ, ∂L

b , ∂L

A seguir tem-se o algorítmo de Newton-Raphson para calcular cada um dos parâ-

metros e a habilidade de cada sujeito.






θn+1 = θn −

an+1 = an −

bn+1 = bn −

cn+1 = cn −

L(cid:48)
θ(θn)
L(cid:48)(cid:48)
θ(θn)
L(cid:48)
a(an)
L(cid:48)(cid:48)
a(an)
L(cid:48)
b(bn)
L(cid:48)(cid:48)
b (bn)
L(cid:48)
c(cn)
L(cid:48)(cid:48)
c (cn)

(3.4)

Para que o método da máxima verossimilhança seja executado faltam as derivadas

da função (3.2) que serão determinadas adiante.

Para determinar os parâmetros, o somatório refere-se ao conjunto de sujeitos j ∈

{1, 2, . . . , N } e para a habilidade, ao conjunto de itens i ∈ {1, 2, . . . , I}. Cada aplicação

de Newnton-Raphson é feita separadamente, assim adotamos a notação sem os conta-
dores i e j para o conjunto de itens. Neste momento as derivadas serão realizadas para

a equação (2.7) do ML3, assim, sem perdas de generalidades, deixaremos as variações

do somatório, considerando que a derivada da soma é a soma das derivadas de uma

função. Reescrevendo a igualdade (3.2), tem-se:

L = ulnP + (1 − u)lnQ.

A seguir utilizaremos a regra da cadeia para derivada de funções compostas. Vamos

derivar a função (3.2) em relação à função 2.7, em seguida faremos as derivadas da

função (2.7) em relação aos parâmetros (a, b e c) e em relação a habilidade (θ).

Agora vamos determinar a primeira derivada da função de verossimilhança L:

L(cid:48) = u

Q(cid:48)

1
Q

P (cid:48) + (1 − u)

1
P
Q P (cid:48)u + Q(cid:48)P − Q(cid:48)P u
P Q
QP (cid:48)u + Q(cid:48)P − Q(cid:48)P u
P Q

.

=

=

36

(3.5)

Lembrando que Q(cid:48) = −P (cid:48), obtemos

L(cid:48) =

=

QP (cid:48)u − P (cid:48)P + P (cid:48)P u
P Q

.

P (cid:48)u(Q + P ) − P (cid:48)P
P Q

.

Como Q + P = 1, segue que

L(cid:48) =

P (cid:48)u − P (cid:48)P
P Q

=

(u − P )
P Q

P (cid:48).

Fazendo a substituição T =

u − P
P Q

, chegamos a primeira derivada da função L

L(cid:48) = T P (cid:48).

A última etapa é calcular a derivada de segunda ordem da função de máxima ve-

rossimilhança. Primeiramente vamos calcular a derivada de T

T (cid:48) =

(u − P )(cid:48)P Q − (u − P )(P Q)(cid:48)
(P Q)2

=

=

=

=

=

=

=

−P (cid:48)P Q − (u − P )(P (cid:48)Q + P Q(cid:48))
(P Q)2

−P (cid:48)P Q − (uP (cid:48)Q + uP Q(cid:48) − P P (cid:48)Q − P 2Q(cid:48))
(P Q)2
−P (cid:48)P Q − uP (cid:48)Q − uP Q(cid:48) + P P (cid:48)Q + P 2Q(cid:48))
(P Q)2

−uP (cid:48)(1 − P ) − uP (−P (cid:48)) + P 2(−P (cid:48))
(P Q)2

−uP (cid:48) + uP (cid:48)P + uP P (cid:48) − P 2P (cid:48)
(P Q)2

−uP (cid:48) + 2uP (cid:48)P − P 2P (cid:48)
(P Q)2

−P (cid:48)(u − 2uP + P 2)
(P Q)2

.

37

Sabe-se que u = 0 ou u = 1, o que permite utilizar u2 = u. Segue então, que

T (cid:48) =

−P (cid:48)(u − P )2
(P Q)2

= −P (cid:48)T 2.

Agora a segunda derivada de L será:

L(cid:48)(cid:48) = T (cid:48)P (cid:48) + T P (cid:48)(cid:48)

= −P (cid:48)T 2P (cid:48) + T P (cid:48)(cid:48)

= −(P (cid:48)T )2 + T P (cid:48)(cid:48).

(3.6)

(3.7)

Lembrando que: L(cid:48) = T P (cid:48), ﬁnalizamos a segunda derivada

L(cid:48)(cid:48) = T P (cid:48)(cid:48) − (L(cid:48))2.

Retomando as notações para um conjunto de itens (e quando necessário, conjunto de

sujeitos), tem-se:

L(cid:48)

j =

I
(cid:88)

i=1

uji − Pi
PiQi

· P (cid:48)
i

L(cid:48)(cid:48)

j =

I
(cid:88)

i=1

uji − Pi
PiQi

· P (cid:48)(cid:48)

i − (L(cid:48)

j)2.

(3.8)

(3.9)

Para ﬁnalizar o método da máxima verossimilhança temos que calcular as derivadas

da função (2.7) em relação a cada parâmetro e a habilidade. Como

P = ci +

1 − ci
1 + e−ai(θj −bi) ,

a primeira derivada em relação a habilidade é

P (cid:48)

θ =

ai(1 − ci)e−ai(θ−bi)
(1 + e−ai(θ−bi))2

38

e a segunda derivada é

P (cid:48)(cid:48)

θ =

2a2

i (1 − ci)e−2ai(θ−bi)
(1 + e−ai(θ−bi))3 −

i (1 − ci)e−ai(θ−bi)
a2
(1 + e−ai(θ−bi))2

.

Agora, derivando em relação ao parâmetro de discriminação obtemos

P (cid:48)

a = −

(1 − ci)(1 − bi)e−ai(θ−bi)
(1 + e−ai(θ−bi))2

e a segunda derivada é

P (cid:48)(cid:48)

a =

2(1 − ci)(bi − θ)2e−2ai(θ−bi)
(1 + e−ai(θ−bi))3

−

(1 − ci)(bi − θ)2e−ai(θ−bi)
(1 + e−ai(θ−bi))2

.

Em relação ao parâmetro diﬁculdade, a primeira derivada é

P (cid:48)

b = −

ai(1 − ci)(1 − bi)e−ai(θ−bi)
(1 + e−ai(θ−bi))2

e a segunda derivada é

i (1 − ci)e−2ai(θ−bi)
(1 + e−ai(θ−bi))3 −
Finalmente, a primeira derivada em relação ao parâmetro de acerto casual é

i (1 − ci)e−ai(θ−bi)
a2
(1 + e−ai(θ−bi))2

b =

2a2

P (cid:48)(cid:48)

.

e a segunda derivada é

P (cid:48)

c = 1 −

1
1 + e−ai(θ−bi)

P (cid:48)(cid:48)

c = 0.

Todas as derivadas foram calculadas para a aplicação do algoritmo de Newton-

Raphson na função de máxima verossimilhança para estimar os parâmetros de cada
item i (ai, bi e ci) e a habilidade θj de cada sujeito j que realizou o teste.

Na próxima seção, vamos organizar a utilização de todas as fórmulas que foram

deduzidas para a aplicação do método da máxima verossimilhança.

3.2 Aplicação das fórmulas

Para a estimação dos parâmetros e das habilidades o algoritmo de Newton-Raphson

(N-R) será aplicado várias vezes. Na primeira etapa, o algoritmo é utilizado para

calcular os parâmetros e depois para determinar as habilidades.

39

Cada iteração do algoritmo consiste em fazer uma atribuição inicial para a incógnita

que se deseja estimar (parâmetro ou habilidade), em seguida, as funções (3.5) e (3.6)
são utilizadas para o grupo de sujeitos, quando se pretende calcular os parâmetros e,

para o grupo de itens, quando o objetivo é calcular o traço latente. Para ﬁnalizar a

iteração, atualiza-se o valor procurado e, caso a variação entre o valor anterior e o atual,
seja menor que um valor ﬁxado, por exemplo 10−6, ﬁnaliza-se o processo determinando
o valor para a icógnita. Se o valor ainda for maior que o esperado, reinicia-se os

procedimentos com uma nova iteração.

Em resumo, o algoritmo de N-R será mostrado na ﬁgura a seguir.

40

Figura 3.1: Algoritmo de Newton-Raphson

A rotina apresentada na ﬁgura (3.1) será aplicada para cada item determinando

os parâmetros e para cada sujeito calculando a traço latente. Considerando um teste

com I itens e N sujeitos, o algoritmo N-R será executado 3I vezes para calcular os

41

parâmetros e depois mais N vezes para calcular as habilidades, ou seja, 3I + N vezes

para cada etapa da estimação. No exemplo da tabela (1.1), o algoritmo será executado
30 vezes para determinar os parâmetros e mais 16 vezes para determinar as habilidades

dos sujeitos, logo N-R será executado 46 vezes.

Para completar o processo de estimação devemos repetir a proposta da ﬁgura (3.1)

por várias vezes, até que os valores dos parâmetros e das habilidades não tenham
variações consideráveis. Para esse procedimento, não foi estabelecido um critério de

parada, mas sim um numero ﬁxo de repetições (chamaremos de T ). Esse fato se

justiﬁca pela complexidade de programação necessária para comparar 3I parâmetros e

N habilidades simultaneamente.

Na próxima ﬁgura será apresentada a estrutura de repetição para o processo de

estimação.

Figura 3.2: Estimação dos parâmetros e das habilidades

No processo de estimação dos parâmetros e das habilidades cada rotina deve ser

executada várias vezes. Sendo assim, sem programação, seria extremamente exaustivo

os procedimentos matemáticos estabelecidos na TRI. Como exemplo, o cálculo da pro-
babilidade de sucesso, proposto na função (2.7) no exemplo da tabela (1.1), para uma

42

repetição é realizado 3.084 vezes e para 100 repetições, onde ocorre a convergência dos

valores, a fórmula foi utilizada 56.284 vezes. A ﬁgura a seguir mostra essa simulação.

Figura 3.3: Quantidade de iterações realizadas na estimação

Na próxima seção, serão implementados todos os algoritmos apresentados para a

estimação dos parâmetros e das habilidades.

3.3

Implementação do processo de estimação

Para implementar os algoritmos apresentados nas seções anteriores, foi criada uma

planilha eletrônica e as todas as funções do método da máxima verossimilhança foram
desenvolvidos em uma liguagem de programação chamada de Visual Basic, que permite

interações entre as células da planilha e rotinas de programação. A planilha permite

uma visualização didática dos resultados obtidos. As respostas da tabela 1.1 com 10

itens e 16 respondentes foram inseridas nesta planilha, conforme apresenta a ﬁgura
(3.4).

43

Figura 3.4: Planilha com 10 itens e 16 respondentes
44

A parte superior esquerda apresenta os botões com os principais comandos, seguidos

das curvas características dos 45 itens que deﬁnem o traço latente. Logo abaixo, a
primeira coluna apresenta a identiﬁcação dos sujeitos (1, 2, 3, . . . , N ), a nota e as demais

colunas tem as respostas binárias dos N sujeitos aos 45 itens. Esta planilha possui as

estimatvas iniciais para a discriminação de cada item igual a um (a = 1), recomendado

por Pasquali (2007), a diﬁculdade de cada item determinada pela razão entre erros no

4
16

item e total de itens (por exemplo, o item 01 tem 12 acertos logo, b =

= 0, 25) e o

acerto casual igual a 20% para todos os itens, pois cada item possui cinco alternativas

e apenas uma correta.

Foram implementados os algoritmos para a estimação de cada parâmetro e a ha-

bilidade, indicados pelos botões rotulados por Discriminação, Diﬁculdade, Acaso e

Habilidade. Foi desenvolvida uma rotina (indicada pelo rótulo Iterações) que realiza

chamadas consecutivas das rotinas de estimação para discriminação, diﬁculdade, acaso
e habilidade, respectivamente, para que se veriﬁque a convergência dos valores.

Segundo o guia do estudante criado pelo Instituto Nacional de Estudos e Pesquisas

Educacionais Anísio Teixeira - INEP, o cálculo da nota é realizado em uma escala que

depende de dois valores: valor de posição ou de referência, para o qual foi atribuído o
valor 500, que representa o desempenho médio dos concluintes do ensino médio da rede

pública de 2009 (primeiro ano de aplicação da TRI) que realizaram o exame naquele

ano e, valor de dispersão, para o qual foi atribuído o valor 100, que representa uma

medida de variabilidade média das notas desses concluintes em relação ao desempenho
médio 500. Esse valor é conhecido como desvio padrão. Resumindo, com a estimação

das habilidades, o cálculo da nota é feito pela equação N = 100θ + 500.

Após a realização das estimativas os resultados foram apresentados na tabela a se-

guir.

45

Figura 3.5: Planilha com os valores estimados
46

Na primeira coluna da planilha apresentada na ﬁgura (3.5) está a classiﬁcação ﬁnal

após uma ordenação. Por exemplo, o quinto colocado foi o sujeito de identiﬁcação
igual a 16, na tabela 1.1, o Paulo. Nota-se que todas as estimações atendem ao padrão

esperado, o item mais difícil (Item 10) teve a menor quantidade de acertos, vários

sujeitos acertaram 5 itens: o que teve a melhor nota (561.555) acertou os itens mais

fáceis e errou os mais difíceis enquanto o respondente que teve a menor nota (362.963),
acertou os itens mais difíceis e errou os mais fáceis, isso é uma incoerência pedagógica.

O único empate ocorreu porque os dois sujeitos tiveram as mesmas respostas, logo tem

o mesmo traço latente. Resumindo, a TRI é uma modelagem matemática que permite

gerar uma proﬁciência (nota) onde além do número de acertos, é fundamental que exista
uma coerência pedagógica nos acertos. Todos os cálculos são feitos com procedimentos

matemáticos aplicados das respostas dos sujeitos e não por uma avaliação de quem

elaborou o item. Note que em um processo de avaliação educacional, é comum que dois

professores façam avaliações diferentes para as características pedagógicas de um item
(o que é muito fácil para um, pode não ser para outro), gerando resultados distintos

e subjetivos em uma correção. Isso não ocorre em nenhum momento da aplicação da

TRI, todos os cálculos foram realizados com base em equações, conforme foi demostrado

neste trabalho.

No Apêndice 1 estão todos os códigos implementados na linguagem de programação

Visual Basic e foram aplicados nas planilhas apresentadas neste capítulo. O resultados

obtidos com as simulações de 10 itens e 16 sujeitos, apresentados na tabela da ﬁgura 3.2,

convergiram gerando valores satisfatórios. Entretanto, a aplicação da TRI no ENEM
é realizada para 45 itens por área do conhecimento, produzindo uma proﬁciência, por

área, para cada estudante que realiza o exame. Para uma avaliação em larga escala,

várias técnicas são utilizadas para tratamento da informação, caso não haja conver-

gência dos valores na aplicação dos algoritmos. Atualmente, existem vários softwares
estatísticos, com diversos pacotes desenvolvidos para realizar o tratamento de dados,

na aplicação da TRI; alguns com um custo elevado, como exemplo o BILOG (Analysis

of binary response data) e outros denominados softwares livres, como o Software R,

que será utilizado na próxima etapa deste trabalho para aplicar a TRI em um teste
simulado ao ENEM, com quatro áreas do conhecimento e 45 itens cada uma, realizado

com alunos no ensino médio e pré-vestibulares de Uberlândia.

No próximo capítulo, será realizada uma comparação entre as notas obtidas com

as rotinas programadas para aplicação da TRI no software R e as notas determinadas
pelos algoritmos desenvolvidos neste capítulo.

47

Capítulo 4

Resultados e Discussões

Para aplicar a metodologia proposta nos capítulos anteriores, foi realizado um teste

com 180 itens, sendo 45 itens para cada traço latente: Matemática e suas Tecnologias;

Linguagens, Códigos e suas Tecnologias; Ciências da Natureza e suas Tecnologias e

Ciências Humanas e suas Tecnologias. Este teste foi aplicado em dois dias; no primeiro,
para um total de 811 alunos e no segundo, 668. Foi uma simulação ao que ocorre no

ENEM: mesmos horários e itens seguindo recomendações pedagógicas direcionadas

pelas diretrizes no INEP. A respostas foram inseridas em um planilha eletrônica e

em seguida foram realizados dois procedimentos: o primeiro foi criar a rotina para a
utilização da TRI através do software R e o segundo, aplicar os algoritmos desenvolvidos

para estimar os parâmetros e a habilidade apresentados no capítulo anterior. Para

concluir, foi feita uma comparação entre os resultados obtidos em ambas simulações.

Na próxima seção será apresentado os resultados analisados no software R.

4.1 Tratamento dos dados no software R

Os comandos utiizados nos aplicativos desenvolvidos estão no Apêndice 2. Adiante

tem-se uma explicação das funções utilizadas. Para aplicação a TRI no simulado, o

primeiro passo é corrigir as respostas com o gabarito, ou seja, criar a tabela com acerto
(1) e erro (0). O segundo passo, é realizar a estimação dos parâmetros através da função

tpm (three parameter model) do pacote ltm (Latent Trait Model). O terceiro passo é

estimar as habilidades pelo comando factore.scores. O quarto passo é a transformação

48

das habilidades calculadas para a métrica estabelecida pelo INEP (N = 100θ + 500).

Com a notas, criou-se uma classiﬁcação para os participantes. Por ﬁm, foi feita a cons-
trução da curva característica de cada item, com a função plot, mostrada na ﬁgura a

seguir.

Figura 4.1: Resultados para ciências humanas - software R

Os procedimentos foram criados para determinar a proﬁciência das quatro áreas,

mas por uma questão de simplicação, a análise relatada neste trabalho foi apenas

para os 45 primeiros itens do banco de respostas, a saber, Ciências Humanas e suas

Tecnologias. Os resultados de todas a áreas foram processados e divulgados para todos
os participantes do teste.

Na próxima seção estão os resultados obtidos com o processamento das respostas

através dos algoritmos implementados na planilha eletrônica apresentada no capítulo

anterior.

49

4.2 Tratamento dos dados nos algoritmos implemen-

tados

Os resultados obtidos com a estimação dos parâmetros pelo método da máxima

verossimilhança apresentaram as curvas características dos itens apresentados na ﬁgura
a seguir.

Figura 4.2: Resultados para ciências humanas - planilha eletrônica

Nota-se que diversos itens tem gráﬁcos semelhantes em ambas simulações (Figura
4.1 e 4.2). O método da máxima verossimilhança, contudo, tem alguns problemas, em

especial o que Lord (1968) chama de efeito teto e efeito piso. Quando um sujeito acerta

quase todos os itens, a estimação de sua aptidão por meio da máxima verossimilhança

vai produzir um teta inﬁnito positivo, ou seja, θ = +∞. Este é o efeito teto, assim
não há convergência para os valores procurados e para que o algoritmo encerre a rotina

foi deﬁnido um critério de parada baseado nos valores esperados, conforme exposto na

seção 2.2. Por outro lado, quando o sujeito erra muitos itens, novamente a estimação

da sua aptidão vai produzir teta inﬁnito, desta vez, negativo, isto é, θ = −∞. Este é

50

o efeito piso e o procedimento de ﬁnalização do algoritmo foi o mesmo.

Para superar estas diﬁculdades na estimação dos parâmetros por meio da máxima
verossimilhança, são utilizados outros métodos de estimação, tais como, o método

Bayesiano, o método de Máximo a Posteriori - MAP, o A Posteriori Esperado - EAP,

a Máxima Verossimilhança Marginal - MML. Entretanto, estes serão estudos para

projetos futuros e não serão abordados neste trabalho de conclusão.

É claro que para o intervalo mediano, onde os padrões de resposta geram a conver-

gência do método, os resultados são muitos próximos. Este fato ﬁca exposto na taxa de

aproximação (diferença percentual entre a nota obtida no software R e os algoritmos

implementados) calculada na última coluna da ﬁgura 4.3. Para os exemplos, na faixa
entre 24 e 30 acertos, este percentual não chega a 1%. É importante relatar que, a

quantidade de sujeitos, com essa propriedade, no banco de respostas completo, é bem

maior do que o exposto.

Ao ﬁnal da aplicação da TRI no simulado, foi enviado para os alunos participantes,
um relatório com a nota estimada em cada uma das quatro áreas do conhecimento,

junto com a quantidade de acertos obtidos. Foi realizada uma explicação sobre a

metodologia para viabilizar a interpretação dos resultados.

As ﬁguras abaixo mostram os resultados das notas ﬁnais no software R e nos algoritmos
desenvolvidos no Visual Basic. Temos duas tabelas, a primeira obtida com o algoritmos

desenvolvidos para o Visual Basic e a segunda com os comandos executados no software

R. Em ambas, a primeira coluna indica uma identiﬁcação do sujeito, a segunda coluna,

o número de acertos e a terceira coluna, a nota ﬁnal com a TRI. A segunda tabela possui
uma coluna a mais que indica a variação percentual entre as duas notas calculadas.

Apresentaremos três faixas de acertos escolhidas dentre os 811 candidatos que ﬁze-

ram o simulado.

51

Figura 4.3: Comparação entre resultados para ciências humanas - faixa de 36 até 41

acertos

No Visual Basic, o indivíduo de identiﬁcação 550 ﬁcou em primeiro lugar enquanto

o número 396 em segundo. No software R, ocorreu a inversão destas posições. As

variações percentuais são pequenas, entretanto podemos notar que várias pessoas com

o mesmo número de acertos tiveram notas diferentes, fato justiﬁcado pelo padrão de
respostas de cada sujeito, conforme propõe a TRI.

52

Figura 4.4: Comparação entre resultados para ciências humanas - faixa de 14 até 21

acertos

Para a faixa de acertos apresentada na ﬁgura 4.4, podemos perceber que a diferença

entre as notas obtidas pela rotina implementada para o software R e os algoritmos

desenvolvidos no Visual Basic, diminui para um valor absoluto menor que 1%. Na
faixa anterior, mostrada na ﬁgura 4.3, a diferença não atingiu o valor, em módulo, de

53

7%. Quanto mais próximos dos extremos forem os padrões de respostas, maior será a

diferenças entre resultados obtidos no algoritmo e o software R.

Um fato considerável é que essa diferença vai interferir na colocação do candidato,

por exemplo, o candidato com identiﬁcação 97, acertou 22 itens e teve a nota 496, 042

no Visual Basic e 496, 800 no software R, gerando uma diferença de posições na classi-

ﬁcação geral do traço latente de Ciências Humanas e suas Tecnologias. A justiﬁcativa
será abordada no ﬁnal deste capítulo.

Figura 4.5: Comparação entre resultados para ciências humanas - faixa de 3 até 16

acertos

54

Para estes sujeitos a diferença percentual foi maior devido ao padrão de respostas

ser composto por poucos itens corretos, diﬁcultando a convergência dos valores calcu-
lados nas iterações executadas nos algoritmos. Apesar de não haver convergência para

padrões de respostas extremos (acertar ou errar quase todos), as aproximações foram

consideradas satisfatórias, ressaltando que o objetivo do trabalho é a compreensão da

metodologia aplicada na TRI.

Para superar estas diﬁculdades da estimação de parâmetros por meio da máxima

verossimilhança, são utilizados outros métodos de estimação, tais como, o método

Bayesiano, o método de Máximo a Posteriori (MAP, maximum a posteriori), o A

Posteriori Esperado (EAP, expected a posteriori) e a Máxima Verossimilhança Marginal
(MML). O EAP é utilizado pelas bibliotecas do software R enquanto o método utilizado

do Visual Basic foi o MMV, justiﬁcando as diferenças encontradas.

No próximo capítulo, teremos a conclusão do trabalho.

55

Capítulo 5

Conclusão

O processo de ensino e aprendizagem é dinâmico e precisa de constantes mudanças

para se adaptar às diversas realidades nos quais ele se insere. A avaliação torna-se uma

etapa fundamental para a melhoria na qualidade da educação. A Teoria de Resposta

ao Item mostra que um teste composto por vários itens, pode ser analisado sob um
perpectiva muito mais eﬁciente e ﬁdedigna do que a proposta na Teoria Clássica dos

Testes. Com o uso de ferramentas computacionais, a metodologia fundamentada na

determinação de um traço latente se mostra uma excelente ferramenta pedagógica para

avaliar o processo educacional.

Compreender a teoria que estrutura a TRI é uma tarefa difícil e complexa. Difundir

tal proposta revela-se ainda mais desaﬁador. A tarefa pode ser árdua mas deve ser feita,

pois ela propõe um nota fundamentada em um coerência pedagógica e não apenas no

número de acertos, algo muito sensato no processo de ensino aprendizagem. Apresentar,
com dados concretos para os estudantes do ensino médio, o resultado da execução dos

procedimentos da TRI, causou sentimentos variados: indagações de como esse processo

pode ser tão preciso ao ponto de detectar um chute; despertou a necessidade de uma

estratégia de resolução de provas buscando um padrão de respostas mais eﬁciente; e o
mais o importante, a conﬁança no processo de avaliação em que eles estão inseridos;

com a TRI eles perceberam que é possível calcular o nível de competência que um

participante possui para resolver situações problema propostas nos itens.

Implementar cada um dos algoritmos foi muito importante para entender como
funciona a TRI, e principalmente, para pensar em novos projetos para a divulgação da

metodologia nas avaliações educacionais.

56

Apendice1

Os códigos apresentados foram desenlvolvidos em Visual Basic, uma linguagem de

programação que permite criar funcionalidade especíﬁcas para planilhas eletrônicas.

Rotina para estimar o traço latente dos sujeitos.

Sub e s t i m a H a b i l i d a d e ( )

Dim pr ( 3 , 180 )

Dim h ( 1 0 0 0 0 )

Dim r ( 1 0 0 0 0 , 1 8 0)

D = C e l l s ( 7 , 5 )

t o t a l I t e n s = C e l l s ( 3 , 6 )

’LEITURAS INCIAIS :

t o t a l I n d i v i d u o s = C e l l s ( 4 , 6 ) ’ − TOTAL DE ITENS

’%%%%%%%%%%%%%%%%%%%%%%%%

’ − TOTAL DE SUJEITOS

For

i = 1 To t o t a l I t e n s

’ − PARÂMETROS INICIAIS

pr ( 1 ,

i ) = C e l l s ( 5 , 7 + i )

’ − RESPOSTAS DOS SUJEITOS

pr ( 2 ,

i ) = C e l l s ( 6 , 7 + i )

pr ( 3 ,

i ) = C e l l s ( 7 , 7 + i )

Next

i

For

j = 1 To t o t a l I n d i v i d u o s

a c e r t o s = 0

For

i = 1 To t o t a l I t e n s

r ( j ,

i ) = C e l l s ( 8 + j , 7 + i )

I f C e l l s ( 8 + j , 7 + i ) = 1 Then a c e r t o s = a c e r t o s + 1

Next

i

C e l l s ( 8 + j , 4 ) = a c e r t o s

57

Next

j

’%%%%%%%%%%%%%%%%%%%%%%%%% ’ ALGORITMO DE

’NEWTON−RAPHSON PARA TODOS SUJEITOS

For

j = 1 To t o t a l I n d i v i d u o s

h ( j ) = C e l l s ( 8 + j , 5 )

dr1 = 0

dr2 = 0

E = 1

While ( Abs (E) > 0 . 0 0 0 0 0 0 0 1 )

dr1 = 0

dr2 = 0

For

i = 1 To t o t a l I t e n s

P = pr ( 3 ,

i ) + ( 1 − pr ( 3 ,

i ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) )

T = ( r ( j ,

i ) − P) / (P ∗ ( 1 − P) )

D1P = pr ( 1 ,

i ) ∗ ( 1 − pr ( 3 ,

i ) ) ∗ D ∗ Exp(−D ∗ pr ( 1 ,

i ) ∗

( h ( j ) − pr ( 2 ,

i ) ) ) / ( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗

( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

D2P = 2 ∗ pr ( 1 ,

i ) ^ 2 ∗ ( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗

Exp(−2 ∗ D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) )

/ ( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 3

− pr ( 1 ,

i ) ^ 2 ∗ ( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗

Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) )

/ ( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

dr1 = dr1 + T ∗ D1P

58

dr2 = dr2 + T ∗ D2P − (T ∗ D1P) ^ 2

Next

i

E = dr1 / dr2

h ( j ) = h ( j ) − E

h A n t e r i o r = h ( j )

I f h ( j ) > 3 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

’ PARADA PARA CASO DE DIVERGENCIA

h ( j ) = h A n t e r i o r

End I f

I f h ( j ) < −3 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

h ( j ) = h A n t e r i o r

End I f

Wend

C e l l s ( 8 + j , 5 ) = h ( j )

C e l l s ( 8 + j , 6 ) = 100 ∗ h ( j ) + 500

Next

j

End Sub

Rotina para estimar a discriminação.

Sub e s t i m a D i s c r i m i n a c a o ( )

Dim pr ( 3 , 18 0 )

Dim h ( 1 0 0 0 0 )

Dim r ( 1 0 0 0 0 , 1 80)

D = C e l l s ( 7 , 5 )

’%%%%%%%%%%%%%%%%%%%%%%%%%%%%

59

t o t a l I t e n s = C e l l s ( 3 , 6 )

’ LEITURAS INICIAIS :

t o t a l I n d i v i d u o s = C e l l s ( 4 , 6 ) ’

− TOTAL DE ITENS

’

’

− TOTAL DE SUJEITOS

− PARÂMETROS INCIAIS

For

i = 1 To t o t a l I t e n s

pr ( 1 ,

i ) = C e l l s ( 5 , 7 + i )

pr ( 2 ,

i ) = C e l l s ( 6 , 7 + i )

pr ( 3 ,

i ) = C e l l s ( 7 , 7 + i )

Next

i

For

j = 1 To t o t a l I n d i v i d u o s

For

i = 1 To t o t a l I t e n s

r ( j ,

i ) = C e l l s ( 8 + j , 7 + i )

Next

Next

i

j

’%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For

i = 1 To t o t a l I t e n s

’NEWTON−RAPHSON PARA CADA ITEM

dr1 = 0

dr2 = 0

E = 1

While ( Abs (E) > 0 . 0 0 0 0 0 0 0 1 )

dr1 = 0

dr2 = 0

For

j = 1 To t o t a l I n d i v i d u o s

h ( j ) = C e l l s ( 8 + j , 5 )

P = pr ( 3 ,

i ) + ( 1 − pr ( 3 ,

i ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) )

T = ( r ( j ,

i ) − P) / (P ∗ ( 1 − P) )

60

D1P = −(1 − pr ( 3 ,

i ) ) ∗ ( pr ( 2 ,

i ) − h ( j ) ) ∗ D ∗

Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

D2P = 2 ∗ ( pr ( 2 ,

i ) − h ( j ) ) ^ 2 ∗ ( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗

Exp(−2 ∗ D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 3 −

( pr ( 2 ,

i ) − h ( j ) ) ^ 2 ∗ ( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗

Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

dr1 = dr1 + T ∗ D1P

dr2 = dr2 + T ∗ D2P − (T ∗ D1P) ^ 2

Next

j

E = dr1 / dr2

a A n t e r i o r = pr ( 1 ,

i )

pr ( 1 ,

i ) = pr ( 1 ,

i ) − E

I f pr ( 1 ,

i ) > 2 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

’ PARADA PARA CASO DE DIVERGENCIA

pr ( 1 ,

i ) = a A n t e r i o r

End I f

I f pr ( 1 ,

i ) < 0 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

pr ( 1 ,

i ) = a A n t e r i o r

End I f

Wend

With S h e e t s ( " Parametros " )

61

. C e l l s ( 1 + i , 4 ) = pr ( 1 ,

i )

End With

Next

i

End Sub

Rotina para estimar a diﬁculdade de cada item.

Sub e s t i m a D i f i c u l d a d e ( )

Dim pr ( 3 , 180 )

Dim h ( 1 0 0 0 0 )

Dim r ( 1 0 0 0 0 , 1 8 0)

D = C e l l s ( 7 , 5 )

’%%%%%%%%%%%%%%%%%%%%%%

t o t a l I t e n s = C e l l s ( 3 , 6 )

’ LEITURAS INICIAIS :

t o t a l I n d i v i d u o s = C e l l s ( 4 , 6 ) ’

− TOTAL DE ITENS

’

’

− TOTAL DE SUJEITOS

− PARÂMETROS INCIAIS

For

i = 1 To t o t a l I t e n s

pr ( 1 ,

i ) = C e l l s ( 5 , 7 + i )

pr ( 2 ,

i ) = C e l l s ( 6 , 7 + i )

pr ( 3 ,

i ) = C e l l s ( 7 , 7 + i )

Next

i

For

j = 1 To t o t a l I n d i v i d u o s

For

i = 1 To t o t a l I t e n s

r ( j ,

i ) = C e l l s ( 8 + j , 7 + i )

Next

Next

i

j

’%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For

i = 1 To t o t a l I t e n s

’NEWTON−RAPHSON PARA CADA ITEM

62

dr1 = 0

dr2 = 0

E = 1

While ( Abs (E) > 0 . 0 0 0 0 0 0 0 1 )

dr1 = 0

dr2 = 0

For

j = 1 To t o t a l I n d i v i d u o s

h ( j ) = C e l l s ( 8 + j , 5 )

P = pr ( 3 ,

i ) + ( 1 − pr ( 3 ,

i ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) )

T = ( r ( j ,

i ) − P) / (P ∗ ( 1 − P) )

D1P = −pr ( 1 ,

i ) ∗ ( 1 − pr ( 3 ,

i ) ) ∗ D ∗

Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

D2P = 2 ∗ pr ( 1 ,

i ) ^ 2 ∗ ( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗

Exp(−2 ∗ D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 3 − pr ( 1 ,

i ) ^ 2 ∗

( 1 − pr ( 3 ,

i ) ) ∗ (D ^ 2 ) ∗ Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) )

/ ( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) ) ^ 2

dr1 = dr1 + T ∗ D1P

dr2 = dr2 + T ∗ D2P − (T ∗ D1P) ^ 2

Next

j

E = dr1 / dr2

b A n t e r i o r = pr ( 2 ,

i )

pr ( 2 ,

i ) = pr ( 2 ,

i ) − E

63

I f pr ( 2 ,

i ) > 3 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

’ PARADA PARA CASO DE DIVERGENCIA

pr ( 2 ,

i ) = b A n t e r i o r

End I f

I f pr ( 2 ,

i ) < −3 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

pr ( 2 ,

i ) = b A n t e r i o r

End I f

Wend

With S h e e t s ( " Parametros " )

. C e l l s ( 1 + i , 3 ) = pr ( 2 ,

i )

End With

Next

i

End Sub

Rotina para estimar o acerto casual.

Sub estimaAcaso ( )

Dim pr ( 3 , 180 )

Dim h ( 1 0 0 0 0 )

Dim r ( 1 0 0 0 0 , 1 8 0)

D = C e l l s ( 7 , 5 )

’%%%%%%%%%%%%%%%%%%%

t o t a l I t e n s = C e l l s ( 3 , 6 )

’ LEITURAS INICIAIS :

t o t a l I n d i v i d u o s = C e l l s ( 4 , 6 ) ’

− TOTAL DE ITENS

For

i = 1 To t o t a l I t e n s

pr ( 1 ,

i ) = C e l l s ( 5 , 7 + i )

− TOTAL DE SUJEITOS

− PARÂMETROS INCIAIS

’

’

64

pr ( 2 ,

i ) = C e l l s ( 6 , 7 + i )

pr ( 3 ,

i ) = C e l l s ( 7 , 7 + i )

Next

i

For

j = 1 To t o t a l I n d i v i d u o s

For

i = 1 To t o t a l I t e n s

r ( j ,

i ) = C e l l s ( 8 + j , 7 + i )

Next

Next

i

j

For

i = 1 To t o t a l I t e n s

’NEWTON−RAPHSON PARA CADA ITEM

dr1 = 0

dr2 = 0

E = 1

While ( Abs (E) > 0 . 0 0 0 0 0 0 0 1 )

dr1 = 0

dr2 = 0

For

j = 1 To t o t a l I n d i v i d u o s

h ( j ) = C e l l s ( 8 + j , 5 )

P = pr ( 3 ,

i ) + ( 1 − pr ( 3 ,

i ) ) /

( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) )

T = ( r ( j ,

i ) − P) / (P ∗ ( 1 − P) )

D1P = 1 − 1 / ( 1 + Exp(−D ∗ pr ( 1 ,

i ) ∗ ( h ( j ) − pr ( 2 ,

i ) ) ) )

D2P = 0

dr1 = dr1 + T ∗ D1P

dr2 = dr2 + T ∗ D2P − (T ∗ D1P) ^ 2

Next

j

65

E = dr1 / dr2

c A n t e r i o r = pr ( 3 ,

i )

pr ( 3 ,

i ) = pr ( 3 ,

i ) − E

I f pr ( 3 ,

i ) > 1 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

’ PARADA PARA CASO DE DIVERGENCIA

pr ( 3 ,

i ) = c A n t e r i o r

End I f

I f pr ( 3 ,

i ) < 0 Then

E = 0 . 0 0 0 0 0 0 0 0 0 1

pr ( 3 ,

i ) = c A n t e r i o r

End I f

Wend

With S h e e t s ( " Parametros " )

. C e l l s ( 1 + i , 2 ) = pr ( 3 ,

i )

End With

Next

i

End Sub

66

Apêndice 2

Os códigos apresentados foram desenvolvidos para o software R. As etapas do pro-

cesso de aplicação da TRI estão descritas adiante.

Inicilamente foi feita uma correção das respostas dos estudantes criando uma planilha

eletrônica do tipo "xlsx"com as respostas binárias (”1” acerto e ”0"erro). Em seguida
foram desenvolvidas as rotinas para:

Importar as respostas para o software R:

## ENTRADA COM AS RESPOSTAS DOS ESTUDANTES

##

QUE PARTICIPARAM DO SIMULADO

p r i m e i r o D i a = r ead . x l s x ( " P r i m e i r o D i a . x l s x " , sheetName = " t o d o s " )

segundoDia = rea d . x l s x ( " SegundoDia . x l s x " , sheetName = " t o d o s " )

CH = p r i m e i r o D i a [ , c ( 2 : 4 6 ) ]

CN = p r i m e i r o D i a [ , c ( 4 7 : 9 1 ) ]

LC = segundoDia [ , c ( 2 : 4 6 ) ]

MA = segundoDia [ , c ( 4 7 : 9 1 ) ]

colnames (CH) = c ( p a s t e ( " i " , 1 : 4 5 ) )

colnames (CN) = c ( p a s t e ( " i " , 1 : 4 5 ) )

colnames (LC) = c ( p a s t e ( " i " , 1 : 4 5 ) )

colnames (MA) = c ( p a s t e ( " i " , 1 : 4 5 ) )

Estimar os parâmetros de todos os itens:

# ESTIMAÇÃO DOS PARAMETROS

parametros .CH = tpm (CH)

parametros .CN = tpm (CN)

parametros . LC = tpm (LC)

parametros .MA = tpm (MA)

67

w r i t e . x l s x ( c o e f ( parametros .CH) ,

f i l e = "/ parametrosCH . x l s x " )

w r i t e . x l s x ( c o e f ( parametros .CN) ,

f i l e = "/ parametrosCN . x l s x " )

w r i t e . x l s x ( c o e f ( parametros . LC) ,

f i l e = "/ parametrosCL . x l s x " )

w r i t e . x l s x ( c o e f ( parametros .MA) ,

f i l e = "/ parametrosMA . x l s x " )

Estimar cada traço latente: Ciencias Humanas, Ciências da Natureza, Liguagens e

Códigos e Matemática.

# DETERMINAÇÃO DO ESCORE DE CADA PADRÃO DE RESPOSTAS

t h e t a . p .CH = f a c t o r . s c o r e s ( parametros .CH,

method = "EAP" ,

r e s p . p a t t e r n s = CH)

t h e t a . p .CN = f a c t o r . s c o r e s ( parametros .CN,

method = "EAP" ,

r e s p . p a t t e r n s = CN)

t h e t a . p . LC = f a c t o r . s c o r e s ( parametros . LC,

t h e t a . p .MA = f a c t o r . s c o r e s ( parametros .MA,

method = "EAP" ,

r e s p . p a t t e r n s = LC)

method = "EAP" ,

r e s p . p a t t e r n s = MA)

Determinação da escala de proﬁciência e classiﬁcação geral.

n o t a s .CH = NA

n o t a s .CN = NA

n o t a s . LC = NA

n o t a s .MA = NA

f o r

( i

i n 1 :NROW( t h e t a . p . CH$score . d at$z1 ) ) {

n o t a s .CH[ i ] = 100∗ t h e t a . p . CH$score . dat$z1 [ i ]+500

n o t a s .CN[ i ] = 100∗ t h e t a . p . CN$score . dat$z1 [ i ]+500

}

68

f o r

( i

i n 1 :NROW( t h e t a . p . LC$score . d at$z1 ) ) {

n o t a s . LC [ i ] = 100∗ t h e t a . p . LC$score . dat$z1 [ i ]+500

n o t a s .MA[ i ] = 100∗ t h e t a . p . MA$score . dat$z1 [ i ]+500

}

# CLASSIFICAO GERAL

c l a s s i f i c a c a o .CH = s o r t . l i s t ( t h e t a . p . CH$score . dat$z1 ,

d e c r e a s i n g = T)

c l a s s i f i c a c a o .CN = s o r t . l i s t ( t h e t a . p . CN$score . dat$z1 ,

d e c r e a s i n g = T)

c l a s s i f i c a c a o . LC = s o r t . l i s t ( t h e t a . p . LC$score . dat$z1 ,

c l a s s i f i c a c a o .MA = s o r t . l i s t ( t h e t a . p . MA$score . dat$z1 ,

d e c r e a s i n g = T)

d e c r e a s i n g = T)

p o s i c a o .CH =NA

p o s i c a o .CN =NA

p o s i c a o . LC =NA

p o s i c a o .MA =NA

f o r

( i

i n 1 :NROW( c l a s s i f i c a c a o .CH) ) {

p o s i c a o .CH[ c l a s s i f i c a c a o .CH[ i ] ] = i

p o s i c a o .CN[ c l a s s i f i c a c a o .CN[ i ] ] = i

}

f o r

( i

i n 1 :NROW( c l a s s i f i c a c a o . LC) ) {

p o s i c a o . LC [ c l a s s i f i c a c a o . LC [ i ] ] = i

p o s i c a o .MA[ c l a s s i f i c a c a o .MA[ i ] ] = i

69

}

g e r a l .CH = data . frame ( " A c e r t o s CH" = a c e r t o s .CH,

" P o s i ç ã o CH" = p o s i c a o .CH , "Nota F i n a l CH" = n o t a s .CH)

g e r a l .CN = data . frame ( " A c e r t o s CN" = a c e r t o s .CN,

" P o s i ç ã o CN" = p o s i c a o .CN , "Nota F i n a l CN" = n o t a s .CN)

g e r a l . LC = data . frame ( " A c e r t o s LC" = a c e r t o s . LC,

" P o s i ç ã o LC" = p o s i c a o . LC , " Nota F i n a l LC" = n o t a s . LC)

g e r a l .MA = data . frame ( " A c e r t o s MA" = a c e r t o s .MA,

" P o s i ç ã o MA" = p o s i c a o .MA , "Nota F i n a l MA" = n o t a s .MA)

w r i t e . x l s x ( g e r a l .CH ,

f i l e = "/ R e s u l t a d o G e r a l .CH. x l s x " )

w r i t e . x l s x ( g e r a l .CN ,

f i l e = "/ R e s u l t a d o G e r a l .CN. x l s x " )

w r i t e . x l s x ( g e r a l . LC ,

f i l e = "/ R e s u l t a d o G e r a l . LC . x l s x " )

w r i t e . x l s x ( g e r a l .MA ,

f i l e = "/ R e s u l t a d o G e r a l .MA. x l s x " )

70

Referências Bibliográﬁcas

Baker, F. B. (2001). The basics of item response theory.

Fletcher, P. R. (1994). A Teoria da Resposta ao Item: medidas invariantes do desem-

penho escolar. revista da Fundação Cesgranrio Rio de Janeiro.

Kent, N. (2012). Equações Diferenciais.

Lord, F. M. (1968). Statistical theories of mental test scores. Addison-Wesley.

Pasquali, L. (2007). Teoria de resposta ao Item Procedimentos e Aplicações.

Perrenoud, P. (1999). Avaliação: da excelência à regulação das aprendizagens-entre

duas lógicas.

Rabelo, M. (2011). Análise comparativa dos processos de avaliação educacional em

larga escala.

Silva Carvalho, E. (2001). A concepção de educação proﬁssional no exame nacional de

cursos.

Stevenso, J. (1981). Estatística.

Thurstone, L. (1959). The measurement of values. Chicago University Press.

Vianna, H. M. (2014). Estudos em avaliação educacional.

71


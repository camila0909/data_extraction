FERNANDO LUIZ DE SOUZA JUNIOR

CADEIAS DE MARKOV E O JOGO Monopoly

Santo André, 2016

UNIVERSIDADE FEDERAL DO ABC

CENTRO DE MATEMÁTICA, COMPUTAÇÃO E COGNIÇÃO

FERNANDO LUIZ DE SOUZA JUNIOR

CADEIAS DE MARKOV E O JOGO Monopoly

Orientador: Prof. Dr. Rafael de Mattos Grisi

Dissertação de mestrado apresentada ao Centro de

Matemática, Computação e Cognição para

obtenção do título de Mestre

ESTE EXEMPLAR CORRESPONDE A VERSÃO FINAL DA DISSERTAÇÃO

DEFENDIDA PELO ALUNO FERNANDO LUIZ DE SOUZA JUNIOR,

E ORIENTADA PELO PROF. DR. RAFAEL DE MATTOS GRISI.

SANTO ANDRÉ, 2016

Ficha	Catalográfica	elaborada	pela	Biblioteca	da	Universidade	Federal	do	ABC	

SOUZA	JUNIOR,	Fernando	Luiz	de	

Cadeias	de	Markov	e	o	Jogo	Monopoly	/	Fernando	Luiz	de	Souza	Junior		–		Santo	André:	
Universidade	Federal	do	ABC,	2016.	

94	fls.	:	il	

Orientador:	Prof.	Dr.	Rafael	de	Mattos	Grisi	

Dissertação	 (Mestrado)	 –	 Universidade	 Federal	 do	 ABC.	 Mestrado	 Profissional	 em	
Matemática	em	Rede	Nacional	–	PROFMAT,	Santo	André,	2016.	

1.	 Princípios	 de	 probabilidade	 2.	 Cadeias	 de	 Markov	 3.	 Medida	 invariante	 4.	
Ergodicidade	 5.	 Jogo	 Monopoly	 I.	 SOUZA	 JUNIOR,	 Fernando	 Luiz	 de	 II.	 Mestrado	
Profissional	em	Matemática	em	Rede	Nacional	–	PROFMAT,	2016	III.	Cadeias	de	Markov	
e	o	Jogo	Monopoly	

	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
Dedico este trabalho à minha esposa Jânia, que

sempre esteve ao meu lado, lembrando-me que

nada é impossível para aquele que crê em si

mesmo.

iii

A G R A D E C I M E N T O S

Agradeço a Deus, por ter conservado minhas forças nesta caminhada.

Agradeço a meus pais, Elza e Fernando, por não medirem esforços em me ajudar na

busca pelo conhecimento.

Agradeço à Universidade Federal do ABC por ter me proporcionado tal riquíssima

experiência de voltar a estudar Matemática, aprendendo com os melhores.

Agradeço aos caríssimos amigos Erik, Jairo e Kléber, pelo auxílio nas horas difíceis,

pelo companheirismo, pela união.

Agradeço a todos os professores do PROFMAT, pelas excelentes aulas e pela paciên-

cia com os alunos.

E agradeço especialmente ao Professor Rafael Grisi, pela sua competência, seriedade

e sabedoria.

v

“All we have to decide is what to do with the time that is

given us.”

(J.R.R. Tolkien, The Fellowship of the Ring)

vii

R E S U M O

Neste trabalho analisamos uma versão simpliﬁcada do jogo Monopoly utilizando um

modelo de Cadeia de Markov com parâmetro de tempo discreto. No primeiro capítulo

discorremos sobre a Teoria Clássica das Probabilidades, trazendo os resultados mais

importantes para este estudo, precedida por uma breve introdução acerca das ideias

sobre o acaso ao longo da história da humanidade e os principais pensadores envolvi-

dos no desenvolvimento dessa Teoria. No segundo capítulo fazemos uma introdução

histórica aos processos estocásticos e às Cadeias de Markov; em seguida, explicamos os

conceitos fundamentais sobre Cadeias de Markov, colocando alguns exemplos e por ﬁm

discutindo a ergodicidade de uma Cadeia de Markov. No terceiro capítulo, após uma

breve explicação sobre o surgimento e posterior evolução do jogo Monopoly ao longo

do século XX, analisamos a dinâmica do jogo pelo modelo de uma Cadeia de Markov,

utilizando como objeto de estudo uma versão mais simples do jogo em questão.

Palavras-chave: Cadeias de Markov, medida invariante, ergodicidade

ix

A B S T R A C T

In this work we analyze a simpliﬁed version of the Monopoly game using a Markov

chain model with discrete time parameter. In the ﬁrst chapter we discuss on the Classi-

cal Theory of Probability, bringing the most important results for this study, preceded

by a brief introduction about the ideas of chance throughout the history of mankind

and leading thinkers involved in the development of this theory. In the second chap-

ter we make a historical introduction to stochastic processes and Markov chains; then

we explain the fundamental concepts of Markov Chains, putting some examples and

ﬁnally discussing the ergodicity of a Markov chain. In the third chapter, after a brief ex-

planation of the emergence and subsequent evolution of the Monopoly game through-

out the twentieth century, we analyze the dynamics of the game by the model of a

Markov chain, using as an object of study a simpler version of the game in question.

Keywords: Markov chains, invariant measure, ergodicity

xi

C O N T E Ú D O

Introdução

1 P R I N C Í P I O S D E P R O B A B I L I D A D E

1.1 Preâmbulo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.1.1 Sobre as Ideias . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

7

7

7

1.1.2 Um pouco de História . . . . . . . . . . . . . . . . . . . . . . . . 10

1.2 Elementos da Teoria da Probabilidade . . . . . . . . . . . . . . . . . . . 14

1.3 Deﬁnindo Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

1.3.1 Propriedades de uma Probabilidade . . . . . . . . . . . . . . . . . 24

1.4 Probabilidade Condicional e Independência . . . . . . . . . . . . . . . . 27

1.4.1 Independência . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

2 C A D E I A S D E M A R K O V

37

2.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

2.2 Conceitos Iniciais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

2.3 A Transição em n Passos e a Equação de Chapman-Kolmogorov . . . . . 44
2.3.1 Tentando Interpretar Pn . . . . . . . . . . . . . . . . . . . . . . . 47
2.4 Classiﬁcando Estados de uma Cadeia . . . . . . . . . . . . . . . . . . . . 51
2.5 Considerações Sobre a Convergência de Pn . . . . . . . . . . . . . . . . . 61
2.5.1 Convergência, Recorrência e Irredutibilidade . . . . . . . . . . . 62

2.5.2 Convergência e Aperiodicidade . . . . . . . . . . . . . . . . . . . 65

2.6 O Teorema Ergódico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

3 C A D E I A S D E M A R K O V E O J O G O monopoly

69

3.1 Um pouco de história . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

3.2 Regras e versões

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71

3.3 A matemática do jogo . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

3.3.1 Uma visão geral

. . . . . . . . . . . . . . . . . . . . . . . . . . . 74

3.3.2 Modelando o jogo . . . . . . . . . . . . . . . . . . . . . . . . . . 76

3.3.3 Considerações para o caso k = 4 . . . . . . . . . . . . . . . . . . . 80

3.3.4 Considerações para o caso k = 7 . . . . . . . . . . . . . . . . . . . 86

xiii

Conteúdo

3.4 O Monopoly e seu tabuleiro clássico . . . . . . . . . . . . . . . . . . . . . 88

3.4.1 Breve Análise Estratégica . . . . . . . . . . . . . . . . . . . . . . 90

Bibliograﬁa

93

xiv

I N T R O D U Ç Ã O

“A humanidade precisou de centenas de anos

para se acostumar com um mundo onde alguns

eventos não tinham causa...ou eram

determinados por causas tão remotas que

somente podiam ser razoavelmente

representados por modelos probabilísticos.”

— Maurice g. Kendall

O que é o acaso? Diante de pergunta tão simples, nossa mente imediatamente é

convidada a analisar todos os acontecimentos que acontecem à sua volta, e de novo

questionar: de tudo o que se vê, se sente ou se percebe, quais são as coisas realmente

regidas pelo acaso? Haverá uma lei geral de tudo o que está em nosso redor?

Supondo que exista o acaso e que existam situações que são caracterizadas pela sua

presença, é possível, mesmo aceitando o acaso como fato, avançar na compreensão

desse acaso, caminhando pelas trilhas da investigação e método cientíﬁco? Será que o

acaso permite algum grau de determinação?

Antes de tudo é necessário especiﬁcar ou conceituar o que se entende por “acaso”.

Ao lançarmos uma moeda, por exemplo, é senso comum que os possíveis resultados,

exceto por alguma extravagância da natureza, são “cara” e “coroa”. No entanto, antes

de realizada a experiência não é possível antecipar com certeza qual dos dois possíveis

resultados irá ocorrer.

Isto acontece porque os fatores que determinam um destes

particulares resultados não podem ser identiﬁcados e caso isto ocorra não são passíveis

de controle.

A ideia de acaso é quase tão antiga quanto as primeiras civilizações, só que a per-

cepção de que isto é um fenômeno natural e passível de explicações cientíﬁcas, veio

ocorrer bem mais tarde. Inicialmente o acaso era percebido como fruto ou obra da

divindade e atualmente, devemos admitir, a ideia de existirem fenômenos sem causa

deﬁnida ainda encontra diﬁculdade para ser aceita; basta notar a popularidade al-

cançada por pessoas que dizem prever o futuro, dentro de determinados grupos da

sociedade contemporânea.

1

I N T R O D U Ç Ã O

Para escaparmos ao mero senso comum, que ora tende para a extrema simpliﬁcação,

ora tende para o místico, podemos entender o acaso, e por conseguinte a probabilidade,

sob o ponto de vista formal. Desse modo, de acordo com Viali em [22], devemos en-

tender o termo “acaso” como “[...] um conjunto de forças, em geral, não determinadas

ou controladas, que exercem individualmente ou coletivamente papel preponderante

na ocorrência de diferentes resultados de um experimento ou fenômeno. ”

Para exempliﬁcar, tomemos o lançamento de um dado, no qual se obtém qualquer

uma das seis faces e o “acaso” está na impossibilidade de prever quais faces serão

observadas ao longo de novos lançamentos, não podendo identiﬁcar seus resultados

previamente. O “acaso” relaciona-se também com muitos outros exemplos, como o

lançamento de uma moeda, a determinação da vida útil de um equipamento eletrônico,

as previsões do tempo, etc. Desta maneira, observamos como o “acaso” pode estar

associado aos jogos de azar (nos quais a chance de ganhar não depende da habilidade

do jogador), aos fenômenos naturais ou aos eventos ocorridos no cotidiano.

No entanto, não podemos nos afastar por completo das abordagens mais intuitivas

e até ingênuas do conceito de probabilidade; tais abordagens, do ponto de vista de

uma pedagogia da matemática que entenda ser o objetivo último da ciência que ela

possa ser acessível e entendida por todos, têm importante valor. Considerar o esmero

didático que deve ser empreendido para que essas várias discussões sobre aleatorie-

dade, chance e percepção do universo que nos cerca cheguem ao entendimento dos

estudantes, através de eﬁcazes estratégias de ensino, é absolutamente fundamental.

As visões divergentes sobre a compreensão do que é “probabilidade” e “evento alea-

tório” remontam à Antiguidade; diversos físicos, ﬁlósofos e matemáticos dedicaram-se

nessa tarefa de dar sentido a esse debate, e quantas correntes distintas de pensamento

foram originadas! Ingenuidade seria a nossa pensar que, no ato de ensinar tais concei-

tos, sobrepujasse de maneira natural e incontestável na mente dos alunos os conceitos

de probabilidade clássica tais como os colocados na obra Teoria Analítica das Probabi-

lidades, de Pierre S. Laplace.

Com efeito, na Matemática certas suposições fundamentais são feitas e delas são

deduzidas as conclusões, segundo o raciocínio lógico formal, garantindo assim vali-

dade ao nosso pensamento. Entretanto, nem todos os pensamentos são matemáticos,

grande parte das crenças não é certa, apenas provável. Mas dizer que um aconteci-

mento é determinado pelo acaso é declarar que não se sabe como ele é determinado.

Mesmo assim, no “reino do acaso”, percebe-se certa regularidade, certa “ordem dentro

2

I N T R O D U Ç Ã O

Figura 1: Teoria Analítica das Probabilidades (1a edição em 1812), que traz a deﬁnição de pro-
babilidade matemática tal qual a encontramos atualmente nos livros didáticos de matemática

do Ensino Básico

da desordem” e acerca de acontecimentos atribuídos ao acaso formamos uma gradação

de crença racional.

Em geral, os julgamentos na tomada de decisão são feitos por dedução provável, nos

negócios, na mesa de jogos, em um processo de júri, até mesmo em experimentos. Cos-

tumamos dizer em dias quentes e nebulosos que provavelmente choverá. Um meteo-

rologista pode precisar de maiores evidências, mas não o cidadão comum. Costuma-se

raciocinar assim, no senso comum, em assuntos que vão do mais trivial ao mais impor-

tante, com o uso frequente das palavras “provável” e “probabilidade”, sem precisar seu

signiﬁcado.

De fato, segundo Bennett em [3], se a incerteza em um processo aleatório é fruto da

nossa ignorância a respeito das forças que determinam o seu desfecho ou da existência

de mecanismos inacessíveis inerentes aos recursos e condições que o circunscrevem e

que determinam o seu desfecho, estas são questões que estão no centro da discussão

ﬁlosóﬁca envolvendo as noções de aleatoriedade e chance e que continuam em debate

até os dias de hoje.

Em qual seara deveremos então caminhar? Como investigar a verdade que subjaz

oculta no âmago dos acontecimentos aleatórios? Qual o equilíbrio que devemos en-

3

I N T R O D U Ç Ã O

contrar entre a formalização matemática, a observação dos fatos, a intuição geral e as

concepções ﬁlosóﬁcas?

Claro está que esta lide ainda se encontra em processo, mas dentro das ciências

exatas, mais especiﬁcamente dentro da Matemática, deveremos optar por um caminho

que leve à construção lógica da verdade, que seja naturalmente sistematizável e tra-

duzível para uma linguagem simbólica. A tentativa de se estabelecer um elo entre a

Matemática e a intuição geral, falando de Probabilidades, passa por voltar às origens

de todas essas discussões: retornar ao elemento lúdico, ao jogo, à percepção que existe

uma chance de ganhar e uma chance de perder em um jogo.

Figura 2: “Todo o conhecimento humano começou com intuições, passou daí aos conceitos e termi-

nou com ideias” - Immanuel Kant (1724 – 1804)

Portanto, à luz dessas considerações iniciais, a proposta desse trabalho será, ao anali-

sar um objeto lúdico, poder discorrer sobre os conceitos matemáticos da Teoria Clássica

da Probabilidade, e ir além, fazendo uso de uma ferramenta um pouco mais moderna

do ponto de vista teórico e histórico para aprofundar tal análise, adentrando nos do-

mínios da Estatística e da Teoria Moderna da Probabilidade.

No Capítulo 1 traremos uma breve introdução histórica sobre a Teoria da Probabi-

lidade, destacando os principais nomes de vulto na construção cientíﬁca nesta área.

Em seguida, faremos uma introdução clássica às Probabilidades, trazendo situações-

exemplo e formalizando os elementos básicos desse sistema teórico, chegando às Pro-

babilidades da União e da Intersecção de eventos.

No Capítulo 2 abordamos os processos estocásticos, que descrevem sistemas que

variam em algum grau, de forma imprevisível, à medida que o tempo passa; é apre-

sentada ao leitor uma rápida digressão sobre a natureza desses processos e colocados

4

I N T R O D U Ç Ã O

alguns exemplos. Dentre os vários processos estocásticos, uma Cadeia de Markov é

aquele no qual o conjunto de estados do sistema é discreto, onde a probabilidade fu-

tura de um estado depende unicamente de seu estado corrente. Estudamos, então, as

principais características de uma Cadeia de Markov. Compreenderemos algumas apli-

cações básicas, formalizaremos os elementos fundamentais e sistematizaremos toda a

parte inicial dessa teoria, chegando à discussão sobre a ergodicidade de uma Cadeia.

No Capítulo 3 trazemos uma aplicação do estudo feito nos capítulos anteriores, ao

analisar a dinâmica de uma versão simpliﬁcada do internacionalmente famoso jogo

Monopoly. É possível enxergar o desenrolar do jogo como um processo iterativo do

tipo estocástico, mais precisamente como a progressão temporal de uma Cadeia de

Markov. Oferecemos ao leitor uma sucinta visão sobre o desenvolvimento do jogo,

desde os seus primórdios até os dias atuais. Fazemos então algumas considerações so-

bre características do jogo que o tornam interessante para análise, estudando algumas

iterações para n razoavelmente grande, dentro de uma versão mais simples desse jogo;

chegamos, por ﬁm, a algumas conclusões parciais.

5

1

P R I N C Í P I O S D E P R O B A B I L I D A D E

“Se o ensino de Matemática se deve ocupar mais

de uma forma de pensar do que de uma forma

de escrever fórmulas ou numerais, se o ensino da

Matemática se deve ocupar mais da tomada

consciente de decisões do que do estrito cálculo,

então a teoria das probabilidades é

fundamental.”

— Bernardes, 1987

1.1 P R E Â M B U L O

1.1.1 Sobre as Ideias

O desenvolvimento matemático da teoria das probabilidades foi uma invenção do

homem que permitiu a ele fazer aﬁrmações deﬁnitivas acerca de acontecimentos cu-

jos resultados não podiam ser determinados com antecedência. Em outras palavras,

a teoria das probabilidades forneceu um método quantitativo para avaliar fenômenos

randômicos. Todos aqueles que já jogaram cartas, lançaram dados ou moedas, inves-

tem na bolsa ou dirigem numa autoestrada percebem que a aleatoriedade desempenha

um papel fundamental nas experiências do dia-a-dia.

A física clássica lida com eventos de resultado ﬁnal bem determinado, ou pelo me-

nos com eventos cujo desfecho é razoavelmente previsto. No entanto, a teoria das

probabilidades abarca aqueles eventos nos quais o desfecho é incerto. Qualquer pes-

soa pode aﬁrmar, impunemente, que o sol se levantará amanhã, que objetos próximos

à superfície da terra serão atraídos gravitacionalmente por ela, que a água vai ferver

7

P R I N C Í P I O S D E P R O B A B I L I D A D E

após aquecida até uma certa temperatura, que a corrente elétrica existirá em um ﬁo

condutor se existirem locais nesse condutor com potenciais elétricos distintos. As leis

da física inventadas pelo homem que explicam esses fatos parecem funcionar muito

bem, e seria surpreendente se elas fossem violadas.

Figura 3: Partículas em Movimento Browniano, uma das aplicações da moderna teoria da

probabilidade em Física

Em contraponto com esses acontecimentos com resultados bem determinados, exis-

tem acontecimentos nos quais o resultado ﬁnal é completamente desconhecido antes

que o evento ocorra de fato. Se uma moeda honesta é lançada, ninguém pode dizer

com certeza antecipada se sairá cara ou coroa. Antes de viajar, nenhum de nós poderá

aﬁrmar com certeza que não ocorrerá um acidente com o veículo que nos transporta.

Ninguém poderá aﬁrmar com toda a certeza qual será o tempo atmosférico na cidade

daqui a uma semana.

Vamos supor que estamos interessados em determinar a probabilidade de sair cara

quando uma moeda honesta é lançada. Se tivermos paciência, podemos jogar a moeda

um número muito grande de vezes. Se após n lançamentos nós tivermos obtido rn
caras, podemos então formar a razão rn/n, que indica a proporção de caras em relação
ao número total de lançamentos. Deﬁnimos então

p = lim
•
n
!

rn
n

como sendo a probabilidade de ocorrer cara no lançamento dessa moeda. Infelizmente,

nós não podemos de fato deﬁnir esse limite precisamente, pois rn não é uma função
determinada por n. Essa é a grande questão básica subjacente à teoria de probabilida-

des.

8

1.1 P R E Â M B U L O

E já que estamos falando em ideias, algumas ideias aparentemente triviais podem

“pregar peças” em gente gabaritada...

Vamos pensar em uma questão aparentemente simples: qual resultado é mais pro-

vável no lançamento simultâneo de duas moedas: duas caras, duas coroas ou uma de

cada? Para esta pergunta, algumas pessoas poderiam pensar (equivocadamente) que

os três resultados são equiprováveis, cada um com probabilidade de 1/3. É comum

deixarem de considerar que sair faces distintas nesse tipo de lançamento de moedas

tem probabilidade dobrada do que faces iguais.

Entretanto, mesmo o conceituado matemático do século XVIII, Jean Le Rond D’Alembert,

à época um dos mais inﬂuentes cientistas franceses, sustentou que a probabilidade de

se conseguir uma cara em dois lançamentos consecutivos era de 2/3, por entender que

haveria apenas três casos possíveis equiprováveis, ou seja, C, KC e KK (K representa

o resultado coroa e C, cara). Na verdade, ao pensar num primeiro lançamento sendo

cara, nem cogitou o segundo lançamento neste caso, por já ter obtido o resultado

esperado...

Em Teoria da Probabilidade, talvez por essa aproximação histórica com o senso co-

mum e o pensamento do cidadão médio, todo o cuidado é pouco - inclusive nos con-

ceitos mais basilares.

Figura 4: Representação gráﬁca das Equações de Edward Lorenz (1963) – o famoso “Efeito

Borboleta”

Por ﬁm, é importante lembrar que com o desenvolvimento da teoria moderna das

probabilidades, a aproximação entre Probabilidades e Estatística foi se estreitando

cada vez mais. Teorias sobre regularidades estatísticas estudadas em fenômenos alea-

9

P R I N C Í P I O S D E P R O B A B I L I D A D E

tórios fortaleceram a concepção de que há uma teoria da desordenação ordenada que

cerca o imprevisível e o deﬁne de certa forma. No Capítulo 2 deste trabalho estuda-

remos os rudimentos da teoria das Cadeias de Markov, que é historicamente um dos

primeiros esforços dos estatísticos e probabilistas em compreender essa “arrumação no

caos” e atribuir signiﬁcado a ela.

1.1.2 Um pouco de História

A humanidade tem lidado com a incerteza desde épocas as mais remotas na tentativa

de obter vantagens em disputas e evitar perdas advindas de fatores imprevisíveis. Há

milhares de anos jogos de azar têm sido parte de nossa civilização. Pinturas em tumbas

egípcias feitas em 3500 a.C. mostram pessoas jogando uma forma primitiva de dados

feitos de um osso do calcanhar de nome astragalus.

Dados de 6 faces datados de 3000 a.C. foram encontrados no norte do Iraque. Du-

rante as Cruzadas vários jogos de dados foram trazidos para o Ocidente (a palavra

“azar” sendo derivada de al zahr, que signiﬁca “dado” em árabe). O baralho moderno

surgiu na França no século XIV. Por outro lado, levantamentos de dados estatísticos

para censos populacionais e avaliação de produções agrícolas foram realizados na Eu-

ropa a partir do século XI; apólices de seguros navais baseados em conceitos de risco

foram emitidos na Itália e Holanda já no século XIV. No período dos séculos XV e XVI,

além de considerações ﬁlosóﬁcas sobre causalidade e acaso, várias investigações de

problemas relativos a jogos de azar, ou, mais geralmente, a eventos sujeitos ao acaso,

foram realizadas de forma esparsa; maiores detalhes podem ser encontrados em [7].

O frei Luca Pacioli (1445 – 1517), embora não tenha publicado nada de original

é reconhecido pela obra Summa de arithmetica, geometria, proportioni e proportiona-

lità (Veneza, 1494), que o tornou conhecido para a história do desenvolvimento da

probabilidade, se ﬁrmando como um tratado grandioso para a época. Pacioli apresen-

tava na Summa conteúdos de Aritmética, Álgebra, Geometria e Trigonometria e é o

primeiro autor conhecido que estudou os jogos de azar. Estudou ainda o problema dos

pontos (divisão da aposta), embora sua solução tenha sido incorreta, conforme lemos

em [4, 22].

O autodidata Niccolo de Fontana de Brescia (1499 – 1557), também conhecido

como Tartaglia, publicou sua obra General Trattato, em 1556, que dedicava algumas

páginas aos problemas propostos por Pacioli, dentre eles o problema dos pontos. Se

10

1.1 P R E Â M B U L O

coloca assim tal problema: um jogo equitativo termina quando um dos jogadores ven-

cer seis partidas. Suponha-se que por algum motivo o jogo tenha que ser interrom-

pido quando o primeiro jogador tenha vencido cinco partidas e o segundo apenas três.

Como as apostas devem ser repartidas? Niccolo argumentou que a divisão deveria ser

5:3, que não é correta; a solução correta para esse problema foi dada mais tarde por

Fermat e Pascal, de acordo com o que se encontra em [4, 22].

O médico Girolamo Cardano (1501 – 1576), que também era um inveterado joga-

dor de cartas, dados e xadrez, publicou o livro Liber de Ludo Aleae, que na realidade

era um manual de jogos de azar. Contudo, ele foi o primeiro a estudar o lançamento de

dados, baseado na hipótese de que existia um princípio cientíﬁco governando as pro-

babilidades de se obter um par de “seis”, além de mera sorte. Foi também o primeiro a

introduzir técnicas de combinatória no cálculo dos casos possíveis de um evento e con-

siderar a probabilidade de um evento como a razão entre o número de casos favoráveis

e o número de casos possíveis, vide [4, 22].

O destacado cientista italiano Galileo Galilei (1564 – 1642) também publicou um

manual sobre jogos, o Considerações sobre o Jogo de Dados. Nesta obra ele fornece a

famosa explicação da razão pela qual, embora sejam seis as somas que fornecem nove

pontos no lançamento de três dados e que também sejam seis as que fornecem dez

pontos, a experiência mostra que a soma dez é mais comum de ocorrer que a soma

nove.

O ﬁlósofo, matemático e teólogo francês Blaise Pascal (1623 – 1662) teve conheci-

mento do problema dos pontos (divisão da aposta) através de Chevalier de Mèrè, um

intelectual francês apaixonado por jogos e inﬂuente na corte de Luís XIV, e que ﬁcou

imortalizado por essa sua participação na gênese da teoria da probabilidade. Para

resolver o problema dos pontos era preciso técnicas mais apuradas envolvendo um

grande número de possibilidades, que foi o que Pascal fez. Esse e outros problemas

motivaram a correspondência entre Pascal e Pierre de Fermat (1601 – 1665), um

advogado de grande erudição e talvez um dos mais brilhantes matemáticos amadores

que já existiu. As correspondências entre Pascal e Fermat foram publicadas em 1679,

e desde então têm sido consideradas a origem do desenvolvimento da teoria matemá-

tica da probabilidade. Pascal e Fermat foram os pioneiros na solução de problemas

genéricos em probabilidade, e a solução correta do problema dos pontos (divisão da

aposta) foi o marco inicial desse tipo de abordagem. Conﬁrmamos essas informações

em [4, 7, 22].

11

P R I N C Í P I O S D E P R O B A B I L I D A D E

O desenvolvimento da probabilidade como área da matemática teve grande impulso

em 1657, com a publicação de um pequeno livro, De Ratiociniis in Ludo Aleae, escrito

pelo astrônomo e físico Christiaan Huygens (1629 – 1695). Huygens era de uma

importante família holandesa, e ﬁcou muito mais conhecido pelas suas importantes

contribuições à Astronomia e à Física Ondulatória. No entanto, em uma visita à Paris

em 1655, tomou conhecimento da correspondência entre Pascal e Fermat e dos proble-

mas de probabilidade nela investigados, e isto foi um impulso importante para a es-

crita do Ludo Aleae. Escrevendo a van Schooten (que era seu professor de Geometria),

Huygens justiﬁca a publicação do Ludo Aleae aﬁrmando que “...não estamos tratando

apenas com jogos mas com os fundamentos de uma nova teoria, tanto profunda como

interessante”. Foi o primeiro a utilizar o conceito de esperança matemática; outros

detalhes são encontrados em [7, 22].

Trabalhando sobre a abordagem (combinatória) que Fermat utilizava na resolução

dos problemas em probabilidade, o matemático suíço Jacob Bernoulli (1654 – 1705)

iniciou o processo de sistematização da probabilidade deixando de lado os seguros e

os jogos de azar. Em torno de 1689 ele publicou um trabalho sobre séries dando a

conhecer um dos primeiros resultados fundamentais da Teoria Clássica de Probabilida-

des: que a frequência relativa de um evento tende para a probabilidade matemática

deste evento, quando o número de repetições do experimento tende ao inﬁnito. Foi

devido a J. Bernoulli, então, o primeiro grande tratado de probabilidade, Ars Conjec-

tandi, publicado postumamente em 1713. Neste seu livro, J. Bernoulli provou a Lei dos

Grandes Números, que é a formalização do resultado fundamental citado acima; esta

demonstração marcou o início de uma nova era na teoria da probabilidade. Ele provou

tal Lei usando cálculos com coeﬁcientes binomiais, sem usar a aproximação de Stirling

(abordagem feita por De Moivre), e sem evidentemente utilizar ferramentas da “ainda

não nascida” análise (abordagem feita por matemáticos russos ao ﬁnal do século XIX,

culminando com o trabalho de Komolgorov), conforme o que se lê em [7, 12, 22].

Logo após, em 1718, foi publicado pelo matemático franco-inglês Abraham de Moi-

vre (1667 – 1754) a obra Doctrine of Chances, onde são exibidas técnicas de reduzir

problemas de probabilidade a equações de diferenças, e de usar funções geratrizes para

solucionar essas equações, que foram mais tarde aperfeiçoadas por Laplace. Ainda

nesta primeira edição, De Moivre apresenta a deﬁnição de independência de eventos,

além de investigar taxas de mortalidade e os fundamentos da teoria das anuidades. A

segunda edição do Doctrine apareceu em 1738; nesta obra é introduzida pela primeira

vez a distribuição normal, que usou como uma aproximação para a distribuição bino-

12

1.1 P R E Â M B U L O

mial (apresentando a distribuição normal em forma de série). De Moivre nesta obra

ainda provou e usou em seus resultados a aproximação de Stirling; mais detalhes são

encontrados em [7, 22].

No entanto, foi devido ao matemático francês Pierre Simon de Laplace (1749 –

1827) o grande salto qualitativo para consolidar a Teoria Clássica da Probabilidade.

Até Laplace, a probabilidade ainda mantinha sua essência no cálculo de jogos de azar.

Laplace ampliou o campo de aplicações da teoria para outras áreas, como a teoria

dos erros, a matemática atuarial e a mecânica estatística. De fato, em 1812 publica a

obra fundamental desta fase, Théorie Analytique des Probabilités. Os fundamentos da

teoria de probabilidade foram colocados por Laplace nesta obra em uma forma que

se manteve praticamente inalterada até o início do século XX. Nesse tratado, Laplace

fez novas contribuições e reuniu, sistematizou e ampliou resultados desenvolvidos por

seus predecessores: estabeleceu os métodos de equações de diferenças e de funções

geratrizes e deu uma nova formulação e uma prova heurística do teorema central do

limite. Foi a partir da obra de Laplace que os estudos na área realmente cresceram

e tiveram a atenção de outros grandes matemáticos.

Informações complementares

veriﬁcar [7, 21, 22].

No ﬁnal do século XIX, o russo Pafnuty Lvovich Chebyshev (1821–1884) fundou

a denominada escola de São Petersburgo que produziu grandes matemáticos russos

com contribuições fundamentais à teoria de probabilidade. Chebyshev foi inﬂuenci-

ado pelos matemáticos russos V. Ya. Bunyakovskii, que publicou o importante livro

Fundamentos da Teoria Matemática de Probabilidades, e M. V. Ostrogradskii, que fa-

zem parte da linhagem inaugurada por Daniel Bernoulli e Euler em São Petersburgo.

Chebyshev foi o primeiro a raciocinar sistematicamente em termos de variáveis alea-

tórias e seus momentos. Usando esses conceitos, Chebyshev estabeleceu uma simples

desigualdade que permitiu uma prova trivial da Lei dos grandes números. O conceito

de momentos foi utilizado por ele e, em seguida, por seu aluno Andrei Andreyevich

Markov (1856–1922) para dar uma prova rigorosa do teorema central do limite. Um

outro de seus famosos estudantes, Alexander Mikhailovich Lyapunov (1857–1918),

posteriormente usou o conceito de funções características para dar uma prova mais

simples desse importante teorema. Markov fez estudos sobre dependência de variá-

veis aleatórias analisando as hoje denominadas cadeias de Markov em tempo discreto.

O trabalho fundamental sobre as cadeias de Markov em tempo contínuo foi desenvol-

vido posteriormente por Kolmogorov, como lemos em [7].

13

P R I N C Í P I O S D E P R O B A B I L I D A D E

Andrei Nikolaevich Kolmogorov (1903–1987) foi um dos mais importantes mate-

máticos do século XX. Komolgorov axiomatizou a teoria da probabilidade da mesma

forma que a Geometria foi axiomatizada por Euclides. Seu interesse por probabili-

dades iniciou-se em 1924 e em 1925 publicou seu primeiro trabalho nesta área com

Aleksandr Ya. Khintchine (1894–1959) contendo o importante “teorema das três

séries” e resultados em inequações de somas parciais de variáveis aleatórias que se tor-

naram a base para as desigualdades de martingales e do cálculo estocástico. Em 1928

ele determinou condições necessárias e suﬁcientes para a Lei forte dos grandes núme-

ros e provou, sob condições bastante gerais, a lei do logaritmo iterado para somas de

variáveis aleatórias independentes. Em 1929, havia sido publicado seu trabalho Teoria

Geral de Medidas e Teoria de Probabilidade, onde era apresentada a primeira descrição

de uma construção axiomática baseada na teoria de medidas que havia sido criada

em torno de 1901 por Henri Lebesgue (1875–1941) e Èmile Borel (1871–1956).

Em 1933 publicou em alemão um pequeno livro intitulado Grundbegriffe der Wahrs-

cheinlichkeitsrechnung (traduzido para o inglês sob o título Foundations of the Calculus

of Probability) onde desenvolve a teoria de probabilidade de forma matematicamente

rigorosa a partir dos fundamentos axiomáticos baseados na teoria de medidas. A axio-

matização de Kolmogorov marcou o início do desenvolvimento da teoria moderna de

probabilidade. Em 1931 Kolmogorov publicou um importante artigo, Métodos Analíti-

cos na Teoria da Probabilidade, no qual estabelece os fundamentos da teoria moderna

de processos estocásticos, dando início à teoria dos processos de difusão. Em 1938

ele publicou mais um artigo na área da teoria probabilística que se tornou a base dos

processos aleatórios de Markov. Maiores informações são encontradas em [7, 22].

1.2 E L E M E N T O S D A T E O R I A D A P R O B A B I L I D A D E

A seguir vamos exibir alguns conceitos básicos da chamada teoria da probabilidade.

Nos aprofundaremos apenas o necessário para a compreensão dos temas tratados neste

trabalho. O leitor interessado em mais detalhes pode encontrar em [10, 13, 19].

Há vários acontecimentos que, embora sejam repetidos muitas vezes e sob as mes-

mas condições, não apresentam os mesmos resultados – há uma variabilidade intrín-

seca na gama de resultados ﬁnais, mesmo se garantirmos que os parâmetros iniciais

sejam os mesmos ou pelo menos muito próximos. Chamamos de experimentos alea-

tórios ou fenômenos aleatórios esses acontecimentos dotados de tal variabilidade: o

14

1.2 E L E M E N T O S D A T E O R I A D A P R O B A B I L I D A D E

resultado ﬁnal é imprevisível, não se pode determiná-lo antes de ser realizado. Por

exemplo, são aleatórios os fenômenos:

a) Lançar um dado não viciado e registrar seu resultado;

b) Lançar duas moedas e observar as faces voltadas para cima;

c) Retirar 1 carta de um baralho com 52 cartas e observar o seu naipe;

d) Número de pessoas que ganharão o próximo sorteio da Megasena;

e) Número de gotas de água que atingirão o telhado de uma casa durante uma chuva

forte.

A matemática busca compreender esses fenômenos, buscando mensurar as chances

(ou probabilidades) de, em um certo experimento aleatório, um determinado resultado

ocorrer, já que não há maneiras de se ter exatidão na previsão do resultado. A Teoria

das Probabilidades é o ramo da matemática que se encarrega de compreender mais a

fundo esses fenômenos aleatórios e seus resultados, criando, elaborando e pesquisando

modelos para seu estudo.

Estudando um experimento aleatório, nos interessaremos naturalmente por conhe-

cer todos os resultados que podem acontecer naquele experimento, ao mesmo passo

que atentaremos para resultados especíﬁcos dentro daquele experimento.

Desse modo, deﬁnimos primeiramente Espaço Amostral de um experimento como

sendo o conjunto de todos os seus possíveis resultados de um experimento aleatório.

Assim, para os experimentos exempliﬁcados acima, teremos respectivamente

a) Wa =

{

1, 2, 3, 4, 5, 6

;

}

KK, KC, CK, CC

onde K representa cara e C representa coroa;

{
Copas, Espadas, Ouros, Paus

}

;

}

b) Wb =

c) Wc =

d) Wd =

e) We =

{

1, 2, 3, 4,

{
1, 2, 3, 4,

{

;

· · ·}
;

· · ·}

Também deﬁniremos por Evento como sendo qualquer subconjunto do Espaço Amos-

tral daquele experimento. Um evento pode ser caracterizado por um fato que se quer

observar, uma condição matemática, ou uma outra escolha especíﬁca qualquer que

focalize o olhar do experimentador para um certo tipo de resultado desejado. No

15

P R I N C Í P I O S D E P R O B A B I L I D A D E

exemplo a) acima descrito, poderíamos estar interessados em observar a ocorrência de

um número que seja divisor de 6. Neste caso, o evento de interesse seria

D =

{

1, 2, 3, 6

.

}

Tomando o exemplo e), poderíamos querer estudar quando uma quantidade maior

que 10000 gotas e menor que 15000 gotas atinge o telhado, e assim teríamos

E =

{

10001, 10002, 10003, . . . , 14999

.

}

Como subconjuntos do espaço amostral, podemos manipular eventos através das

operações tradicionais de conjuntos, como união, interseção e complemento.

Neste sentido, o evento complementar de um dado evento E, notado por Ec, será
exatamente o conjunto dos resultados do experimento que não estão em E. Voltando

nos exemplos que estamos explorando, poderíamos colocar para o exemplo a), sobre

a rolagem dos dados, o evento

e portanto

A =

{

Número par

=

}

{

2, 4, 6

,

}

Ac =

1, 3, 5

.

}

{

E se no exemplo b) estivéssemos interessados no evento

Ao menos um resultado coroa

B =

{

=

}

{

KC, CK, KK

,

}

teríamos

Bc =

CC

.

}

{

Como comentamos anteriormente, ao olhar para eventos estamos olhando para con-

juntos, e portanto pode-se falar em união de dois ou mais eventos, bem como em

intersecção de dois ou mais eventos. Voltando a clássica rolagem de um dado, já ci-

tado várias vezes, podemos considerar, por exemplo os eventos

A =

1, 2, 3

, B =

}

3, 6

}

{

{

e C =

2, 4, 6

,

}

{

e assim

enquanto

16

B =

A

[

{

1, 2, 3, 6

,

}

C =

A

\

2

.

}

{

1.2 E L E M E N T O S D A T E O R I A D A P R O B A B I L I D A D E

Como comentamos acima é comum descrevermos os eventos de interesse de maneira

textual, descrevendo uma propriedade ou característica que desejamos observar no

resultado. Deste modo, os eventos A, B e C acima poderiam ser descritos por

A =

B =

C =

{

{

{

resultado menor que 4

;

}

resultado é multiplo de 3

;

}

resultado é par

.

}

Para entender o que é a união ou a intersecção de dois eventos, lembre-mos primeiro

como são deﬁnidas tais operação entre dois conjuntos A e B.

Lembrando, diremos que um elemento a

A

B se, e somente se, a

A ou A

B.

2

[

2

2

Ou seja, a união é formada por todos os elementos que fazem parte de ao menos um

dos conjuntos.

Da mesma forma, diremos que um elemento a

B. Ou seja, a intersecção é formada por todos os elementos que fazem parte dos

A

2

dois conjuntos simultaneamente.

A

B se, e somente se, a

A e

2

\

2

Quando falamos de eventos, podemos usar estas mesmas deﬁnições para descrever

a união ou intersecção de eventos.

Ao realizarmos um dada experimento aleatório, podemos dizer que observamos A

B quando o observamos o evento A ou o evento B.

[

Já para observarmos a intersecção de dois eventos teremos de observar a ocorrência

de A e de B simultaneamente.

Assim, para os eventos descritos acima teríamos

B =

A

[

{

resultado é menor que 4 OU múltiplo de 3

,

}

e

C =

A

\

{

resultado é menor que 4 E par

.

}

Para melhor ilustrar todos os conceitos acima, consideremos um novo exemplo.

Exemplo 1.1. Colocamos 3 bolas numeradas aleatoriamente em 3 urnas, identiﬁcadas

pelas letras a, b e c. Estamos interessados em observar o evento

A =

{

nenhuma urna está vazia

.

}

17

P R I N C Í P I O S D E P R O B A B I L I D A D E

Gostaríamos também de entender a relação entre A e os eventos

A1 =

A2 =

A3 =

{

{

{

a urna a está vazia

}

a urna b está vazia

a urna c está vazia

}
.

}

O primeiro passo aqui é descrever o espaço amostral que descreve tal experimento.

Para isso precisamos primeiro decidir como descreveremos resultados individuais do

experimento, que neste caso são uma relação de bolas e suas respectivas urnas. Se va-

lendo da numeração das bolas, podemos representar um resultado por uma sequência

de três letras, indicando as urnas onde estão as bolas 1, 2 e 3 respectivamente.

Assim, (a, b, a) indica que as bolas 1 e 3 foram colocadas na urna a e a bola 2 na urna

b.

Deste modo, o espaço amostral é

W =

{

(a, a, b); (a, b, a); (b, a, a); (a, b, b); (b, a, b); (b, b, a); (a, a, c); (a, c, a); (c, a, a);

(a, c, c); (c, a, c); (c, c, a); (b, b, c); (b, c, b); (c, b, b); (b, c, c); (c, b, c); (c, c, b);

(a, b, c); (a, c, b); (b, a, c); (b, c, a); (c, a, b); (c, b, a); (a, a, a); (b, b, b); (c, c, c)

.

}

Para descrever os eventos A, A1, A2 e A3 note se um trio em W não possui uma letra,

então naquele resultado a caixa ausente está vazia. Assim,

A =

A1 =

A2 =

A3 =

{

{

{

{

(a, b, c); (a, c, b); (b, a, c); (b, c, a); (c, a, b); (c, b, a)

}

(b, b, c); (b, c, b); (c, b, b); (b, c, c); (c, b, c); (c, c, b); (b, b, b); (c, c, c)

}

(a, a, c); (a, c, a); (c, a, a); (a, c, c); (c, a, c); (c, c, a); (a, a, a); (c, c, c)

}
(a, a, b); (a, b, a); (b, a, a); (a, b, b); (b, a, b); (b, b, a); (a, a, a); (b, b, b)

.

}

Agora, para escrever A em função de A1, A2 e A3, volte à descrição do evento A e

observe que podemos descrever Ac por

ao menos uma caixa está vazia

}
a caixa a está vazia ou a caixa b está vazia ou a caixa c está vazia

,

}

Ac = A1 [

A2 [

A3,

Ac =

=

{

{

e portanto

18

1.3 D E F I N I N D O P R O B A B I L I D A D E

ou ainda

A = (A1 [

A2 [

A3)c.

Tal igualdade pode ser facilmente veriﬁcada simplesmente listando os elementos dos

conjuntos envolvidos.

Outra maneira de descrever tal relação é olhar para os eventos A1, A2 e A3 e notar

que

e além disso

Ac

1 =

Ac

2 =

Ac

3 =

{

{

{

a caixa a não está vazia

}

a caixa b não está vazia

a caixa c não está vazia

}
.

}

A =

{

a caixa a não está vazia e a caixa b não está vazia e a caixa c não está vazia

.

}

Segue daí que

A = Ac

1 \

Ac

2 \

Ac
3.

1.3 D E F I N I N D O P R O B A B I L I D A D E

Nosso objetivo agora é tentar encontrar uma boa deﬁnição para o que conhecemos

por probabilidade. É importante observar que este é um processo de modelagem. Ou

seja, queremos tentar representar matematicamente a imprevisibilidade do resultado

em um certo experimento. Queremos então associar a cada resultado do experimento,

ou mais geralmente a cada evento, um número que representará probabilidade de

observarmos tal evento.

Algumas situações são bastante simples, e foram historicamente as primeiras a serem

tratadas. Tais situações aparecem quando o espaço amostral é ﬁnito com n elementos,

e não existe nada que indique que um dado resultado deva ser mais provável que

os demais. Neste caso simplesmente dizemos que cada resultado possui a mesma

probabilidade, nominalmente 1/n.

Mais formalmente, dado um espaço amostral W e um evento E

de ocorrer o evento E pode ser deﬁnida como o número real P(E) dado por

W, a probabilidade

✓

P(E) =

n(E)
n(W)

,

19

P R I N C Í P I O S D E P R O B A B I L I D A D E

onde n(E) representa o número de elementos do evento E e n(W) o número de elemen-

tos do espaço amostral W.

No escopo dessa deﬁnição, ﬁca claro que 0

que seja o evento E

W.

✓

P(E)





1, pois n(E)



n(W), qualquer

Exemplo 1.2. Considere o experimento de lançarmos duas moedas honestas e obser-

varmos o resultado obtido. Queremos então medir as probabilidades da ocorrência de

dois resultados iguais, e da ocorrência de no mínimo uma cara.

Para começar, o espaço amostral deve ser

W =

{

KK, KC, CK, CC

.

}

Os eventos que considerados são

e

E1 =

{

dois resultados iguais

=

}

{

KK, CC

}

E2 =

{

ao menos uma cara

=

}

{

KK, CK, KC

.

}

Assim, considerando que todos os resultados possíveis tem a mesma probabilidade,

temos

e

P(E1) =

n(E1)
n(W)

=

2
4

=

1
2

P(E2) =

n(E2)
n(W)

=

3
4

.

Essa forma de deﬁnir probabilidade funciona bem para conjuntos simples, experi-

mentos estáticos e situações pouco complexas. Mas alguns exemplos simples não po-

dem ser descritos desta forma. Considere, por exemplo, o experimento onde jogamos

uma moeda até observar “cara” pela primeira vez. O total de resultados possíveis neste

experimento é inﬁnito, e portanto a deﬁnição acima não contempla este caso.

Mas mesmo em experimentos com ﬁnitos resultados possíveis, não podemos garantir

que todos eles tenham a mesma probabilidade de ocorrência. Podemos, por exemplo,

rolar um dado feito de material não homogêneo, ou que durante sua fabricação tenha

adquirido bolhas internas próximas a uma das faces. Este dado seria então “viciado” e

dizer que todos os valores tem a mesma probabilidade de ocorrer seria incoerente.

20

1.3 D E F I N I N D O P R O B A B I L I D A D E

Observação 1.3.1. Hoje sabemos que existe um valor limite e ele é exatamente a probabi-

lidade do evento. Este resultado é conhecido Lei Forte dos Grandes Números de Bernoulli,

e é uma das ferramentas utilizadas pela estatística para testar a validade de modelos.

Mas como decidir então qual probabilidade deveremos associar a cada evento? Uma

possibilidade é proceder de forma experimental. Para isso considere um experimento

aleatório, cujo espaço amostral é W. Realize repetidas vezes esse experimento, sob as

mesmas condições iniciais. Para cada evento E

W, seja n(E) o número de vezes que

acontece o evento E ao longo de n repetições do experimento. Dessa forma, podemos

✓

deﬁnir P(E), a probabilidade de ocorrência do evento E, por

P(E) = lim
•
!

n

n(E)
n

.

Isto é, P(E) é deﬁnida como a frequência-limite da ocorrência de E, ao considerar

um número arbitrariamente grande (tão grande quanto se queira) de repetições do

experimento em questão.

Não é difícil perceber que esta deﬁnição não é satisfatória. Antes de mais nada, ela

depende de um limite que em geral não temos como calcular ou tão pouco garantir a

existência. Além disso, na prática deveríamos repetir o experimento um total muito

grande de vezes, e esperar que este resultado esteja próximo suﬁciente do limite.

Mas este não é o caminho natural de se fazer modelagem matemática. A ideia cen-

tral da modelagem é encontrar um modelo matemático baseado no que conhecemos

sobre o que queremos medir, para depois tentar corroborar o modelo com experimen-

tos ou dados.

Assim, cada experimento aleatório trará um desaﬁo a parte, e precisaremos alocar a

cada evento um valor, baseado no que conhecemos do problema.

Exemplo 1.3. Consideremos o experimento de lançar uma moeda não viciada até

atingir cara pela primeira vez.

Cada resultado deste experimento pode ser representado por uma sequência de C’s

terminando em um K, representando as coroas lançadas e o último lançamento onde

observamos cara. Algo como

K

C
· · ·
1 vezes

CC

n

 

|

{z

}

21

P R I N C Í P I O S D E P R O B A B I L I D A D E

é um resultado típico deste experimento, onde foram necessárias n lançamentos para

se observar cara pela primeira vez.

Assim

W =

{

K, CK, CCK, CCCK,

.

· · ·}

Para determinar as probabilidades dos diferentes eventos, vamos inicialmente deﬁnir

as probabilidade de um resultado individual. Ou seja, vamos deﬁnir a probabilidade

dos eventos

En =

{

C
· · ·
1 vezes

CC

n

 

K

.

}

{z
Do fato da moeda ser não viciada, podemos concluir que em cada lançamento temos

|

}

probabilidade 1/2 de observar cara e 1/2 de observar coroa. É razoável supor, portanto,

que

P(E1) = P(

) =

K

{

}

1
2

.

Para observar E2 precisamos que em um lançamento de 2 moedas aconteça exata-

mente o resultado CK, que é um em 4 possíveis. Portanto, colocamos

e generalizando esta ideia fazemos

P(E2) =

P(En) =

1
4

,

1
2n .

Agora, para deﬁnir a probabilidade de um evento qualquer podemos simplesmente

somar as probabilidades dos resultados individuais que formam aquele evento. Assim,

por exemplo, a probabilidade do evento

A =

{

no máximo dois lançamentos foram feitos

=

{

}

K, CK

}

seria

P(A) =

1
2

+

1
4

=

3
4

.

Assim como no exemplo acima, para deﬁnir um modelo de probabilidades devemos

associar valores para a probabilidade de cada evento. Mas temos que tomar cuidado

com os valores que associamos, para que o modelo não ﬁque inconsistente.

As regras que devem ser observadas são conhecidas como axiomas das Probabilida-

des, e são parte da seguinte deﬁnição.

22

1.3 D E F I N I N D O P R O B A B I L I D A D E

Deﬁnição 1.1. Considere um experimento aleatório, cujo espaço amostral é W. Dire-

mos que uma função P que associa a cada evento E desse espaço amostral um número

real P(E), é uma distribuição de probabilidade em W (ou simplesmente uma proba-

bilidade em W) se satisfaz os seguintes três axiomas:

Axioma 1 - Para todo evento E, 0

P(E)

1;





Axioma 2 - P(W) = 1;

Axioma 3 - Para toda sequência de eventos E1, E2, . . . , En tais que Ei \

que i

= j, vale que

Ej = ∆ sempre

P(E1 [

E2 [· · ·[

En) = P(E1) + P(E2) +

+ P(En).

· · ·

Os axiomas acima formam um conjunto mínimo de exigências para que a associação

de probabilidades feitas seja consistente. Os axiomas 1 e 2 são bastante intuitivos e

concordam com tudo o que ﬁzemos até este ponto. O axioma 3 pode ser mais com-

plicado, e talvez seja melhor entendido se olharmos no caso particular de 2 eventos.

Neste caso ele diz que a probabilidade de 2 eventos que não podem ocorrer simulta-

neamente é a soma das probabilidades individuais dos eventos, o que está de acordo

com a noção de probabilidade como frequência.

Para entender melhor os axiomas, voltemos ao Exemplo 1.3. Lembrando, neste

exemplo consideramos o lançamento de uma moeda não viciada repetidamente até
observarmos a primeira cara. Deﬁnimos P associando a probabilidade 1/2n ao resul-
tado onde são necessários exatamente n lançamentos. Ou seja,

CC

P(

{

C
· · ·
1 vezes

n

 

) =

K

}

1
2n .

}
Para E um evento qualquer, deﬁnimos então P(E) como a soma das probabilidades

{z

|

de seus elementos, o que é imediatamente compatível com o axioma 3.

23

6
P R I N C Í P I O S D E P R O B A B I L I D A D E

A seguir veriﬁquemos o axioma 2. Para isso observe que pela construção de P temos

P(W) = P(

K

) + P(

CK

) + P(

CCK

{

}

) + P(

{

CCCK

) +

}

· · ·

{
+

1
2

1
2

1

✓
1
2

=

=

=

}
1
+
4
1

1
8

+

}
+

{
1
16
2

1
2

+

◆

· · ·
1
2

✓

+

✓

◆
1
1/2

 

3

+

◆

✓

4

+

1
2

◆

· · ·

= 1,

o que segue direto da expressão para a soma de uma PG inﬁnita.

O axioma 1 agora segue diretamente do fato de que cada evento, por ser subcon-

junto de W, tem probabilidade dada pela soma de parte dos valores da soma acima, e

portanto não pode ultrapassar 1. Além disso, como os valores somados são positivos,

a probabilidade também deve ser.

1.3.1 Propriedades de uma Probabilidade

Vamos agora explorar algumas propriedades comuns a toda distribuição de proba-

bilidade. Estas propriedades nos permitem estudar probabilidades de nosso interesse

conhecendo quase nada sobre elas, e estão por detrás de quase todos os cálculos feitos

no próximo capítulo.

P R O P R I E D A D E S D E U M A P R O B A B I L I D A D E

1. P(∆) = 0

Para perceber isso, basta notar que W

Assim, pelos Axiomas 2 e 3, vale que

\

∆ = ∆, de modo que W e ∆ são disjuntos.

1 = P(W) = P(W

[

∆) = P(W) + P(∆) = 1 + P(∆),

e a propriedade segue.

2. Probabilidade do Complementar

Para qualquer evento A

W vale que

✓

P(Ac) = 1

P(A).

 

24

1.3 D E F I N I N D O P R O B A B I L I D A D E

Para perceber isso, note que A

Ac = ∆ (A e Ac são disjuntos) e que A

Assim, novamente pelos Axiomas 2 e 3, temos que

\

Ac = W.

[

1 = P(W) = P(A

[

Ac) = P(A) + P(Ac),

e o resultado segue.

3. Monotonicidade

Para quaisquer eventos A, B

W tais que A

B, vale que

✓

✓

P(A)



P(B).

Para isso observe que, como ilustramos na Figura 5, vale que B = A
Além disso, A e Ac

B são disjuntos. Assim, pelos Axiomas 1 e 3,

\

(Ac

B).

\

[

P(B) = P(A) + P(Ac

B)

\

 

P(A).

Figura 5: Escrevendo B como união de dois eventos disjuntos

4. Inclusão-Exclusão

Para quaisquer eventos A, B

W vale que

✓

P(A

[

B) = P(A) + P(B)

P(A

B).

\

 

Para obtermos a expressão para P(A

B), notemos inicialmente que A

B pode

[

[

ser escrito como a união de dois eventos disjuntos (ver Figura 6). Nominalmente

B = A

A

[

(Ac

B).

\

[

Do Axioma 3, podemos escrever

P(A

[

B) = P(A

(Ac

[

\

B)) = P(A) + P(Ac

B).

\

25

P R I N C Í P I O S D E P R O B A B I L I D A D E

Figura 6: Escrevendo A

[

B como união de dois eventos disjuntos

Por outro lado, é fácil ver que B = (A

B)

do Axioma 3 que P(B) = P(A

\
Substituindo a última igualdade obtida na expressão de P(A

\

\
B) + P(Ac

[
B).

(Ac

B). Obtemos novamente do

\

B), chegamos à

[

expressão ﬁnal

P(A

[

B) = P(A) + P(B)

P(A

B).

\

 

Tal expressão pode ser estendida para os casos de três, quatro ou mais eventos.

Como exemplo, uma expressão para a situação envolvendo três eventos A, B e C

quaisquer seria

P(A

B

[

[

C) = P(A) + P(B) + P(C)

P(A

B)

\

 

P(B

\

C)

 

 

P(A

\

C) + P(A

B

\

\

C).

Exemplo 1.4. Criando uma aplicação prática: se uma pessoa retirar uma carta ao

acaso de um baralho comum de 52 cartas, e considerar os eventos não-disjuntos

e

A =

{

Observa-se uma carta de espadas

}

B =

{

Observa-se um valete

.

}

ela poderá calcular a probabilidade de a carta retirada ser de espadas ou ser um valete

da seguinte maneira

P(A

[

B) =

13
52

+

4
52  

1
52

=

16
52

.

26

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

Para ﬁnalizar este capítulo vamos tratar de um conceito fundamental na teoria das

probabilidades: a medida de quanto o conhecimento da ocorrência de um evento

altera a probabilidade de ocorrência de outro evento.

Para melhor entender o problema, comecemos por analisar um exemplo simples

para posteriormente tentar generalizar o que aprendemos.

Exemplo 1.5. Em um certo momento durante um jogo de dados Breno aposta que em

uma rolagem de 2 dados distintos um deles mostrará o número 6. Alberto, o respon-

sável pelo jogo, lança os dados e diz para Breno que a soma dos valores sorteados foi

igual à 8, dando a ele a possibilidade de alterar sua aposta. Como Breno pode decidir

o que fazer?

Para começar, vamos antes de mais nada explicitar o espaço amostral deste experi-

mento. Aqui cada resultado pode ser representado por um par de valores, (a, b), com

a, b

2{
Assim

1, 2, 3, 4, 5, 6

}

, representado a face sorteada nos dados 1 e 2 respectivamente.

W =

{

(1, 1); (1, 2); . . . ; (6, 5); (6, 6)

,

}

e n(W) = 6

6 = 36.

·

Observe agora que Breno está interessado no evento

A =

=

{

{

em um dos dados a face sorteada é 6

}

(1, 6); (2, 6); (3, 6); (4, 6); (5, 6); (6, 6); (6, 5); (6, 4); (6, 3); (6, 2); (6, 1)

,

}

que a princípio, considerando que todos os resultados são igualmente prováveis, tem

probabilidade

P(A) =

n(A)
n(W)

=

11
36

.

Mas Alberto dá uma nova informação sobre o sorteio, dizendo que ocorreu o evento

B =

=

{

{

a soma dos resultados foi 8

}
(2, 6); (3, 5); (4, 4); (5, 3); (6, 2)

}

.

27

P R I N C Í P I O S D E P R O B A B I L I D A D E

Ao receber esta informação Breno pode imediatamente descartar qualquer resultado

fora do evento B. Assim, o evento

(6, 1); (1, 6)

, por exemplo, passa a ter probabili-

{

}

dade 0, uma vez que neste evento a soma dos resultados é sempre 7.

Assim ele “reduz seu espaço amostral” à B, que possui apenas 5 elementos. A seguir

ele “descarta” todos os elementos de A que não estão em B, ﬁcando apenas com

B =

A

\

{

(2, 6); (6, 2)

.

}

Assim, considerando que todos os resultados em B sejam ainda equiprováveis, Breno

calcula nova probabilidade de vitória fazendo

n(A

B)

\
n(B)

=

2
5  

11
36

,

(1.1)

e decide aumentar sua aposta.

O valor calculado acima por Breno é conhecido na matemática como probabilidade

condicional de A dado B, e denotado por P(A

B).

|

No caso de Breno foi razoavelmente simples calcular P(A

B), mas o calculo ﬁnal

|

dependeu fortemente do fato dos resultados individuais em W terem todos a mesma

probabilidade. Surge então a dúvida: como calcular esta quantidade de modo geral?

Vamos para isso analisar passo a passo o raciocínio de Breno. Antes de mais nada

ele “reduziu” o espaço amostral para B, o que na prática levou-o a considerar apenas

o evento A

B no lugar de todo o evento A.

Isso por que a informação sobre a

ocorrência de B tem o efeito primário de levar a probabilidade de todo resultado em
Bc a 0.

\

Matematicamente, isso signiﬁca que P(A

B) deve ser proporcional à P(A

|

B). Ou

\

seja

para algum aA.

P(A

B) = aA ·

|

P(A

\

B),

É importante observar, no entanto, que a princípio aA pode depender tanto de A
B) = 0 sempre

quanto de B, de modo que até agora a expressão diz apenas que P(A

|

que P(A

B) = 0.

\

A seguir Breno ponderou que se os resultados eram equiprováveis a princípio, a

nova informação não deveria mudar tal fato. Em um espaço onde os resultados não

28

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

são todos igualmente prováveis, poderíamos argumentar que para dois eventos A e C a

razão entre as probabilidades de A

B e C

B deveria ser mantida após a informação

da ocorrência de B. Ou seja, se C

B era, digamos, 2 vezes mais provável que A

\

\

\

B

\

antes, a informação da ocorrência de B não deveria alterar isso.

Escrevendo isso, encontramos que

\
\
e portanto aA = aC, mostrando que aA deve depender apenas de B e

\
\

=

=

,

P(C
P(A

aC ·
aA ·

B)
B)

B)
B)

P(C
|
P(A
|

P(C
P(A

B)
B)

B) = a

P(A

|

P(A

B).

\

·

Para encontrar o valor de a basta notar que a informação sobre a ocorrência de B

leva a probabilidade de B para 1! Ou seja,

e portanto

1 = P(B

B) = a

|

P(B

·

\

B) = a

P(B),

·

a =

1
P(B)

.

Com isso chegamos à seguinte deﬁnição.

Deﬁnição 1.2. Dada uma probabilidade P em um espaço amostral W e eventos A, B
W, com P(B) > 0, deﬁnimos a probabilidade condicional de A dado B por

✓

P(A

|

B) =

P(A

B)

\
P(B)

.

(1.2)

É interessante observar que no caso de espaços onde os resultados são igualmente

prováveis, a equação (1.2) se reduz à

P(A

|

B) =

n(A

B)/n(W)

\

n(B)/n(W)

=

n(A

B)

\
n(B)

que é exatamente a expressão usada por Breno em (1.1).

Outra forma de escrever (1.2) é dizer que

P(A

\

B) = P(A

B)P(B),

|

,

29

P R I N C Í P I O S D E P R O B A B I L I D A D E

ou ainda

P(A

\

B) = P(B

A)P(A).

|

Expressões que estão “escondidas” no currículo do ensino médio, normalmente em

exercícios do tipo “sorteio sem reposição”, como mostramos no exemplo abaixo, bas-

tante comum em livros de matemática de ensino médio.

Exemplo 1.6. Uma caixa contém 8 bolas, sendo 5 brancas e 3 pretas. Uma bola é

sorteada ao acaso desta caixa e a seguir, sem que a primeira bola seja devolvida à

caixa, uma nova bola é sorteada. Neste caso, qual a probabilidade de sortearmos uma

bola branca seguida de uma bola preta?

Para resolver o problema considere os eventos

e

A =

{

a primeira bola sorteada é branca

}

B =

{

a segunda bola sorteada é preta

.

}

Queremos calcular P(A

\

B), mas antes disso observe que

P(A) =

5
8

,

pois existem 5 bolas brancas dentre as 8 bolas na caixa. E além disso

A) =

P(B

|

3
7

,

pois ao sortearmos uma bola branca no primeiro sorteio, restaram 7 bolas na caixa,

das quais 3 são pretas.

Assim

P(A

\

B) = P(A)P(B

A) =

|

5
8 ·

3
7

=

15
54

.

É importante comentar que podemos usar a probabilidade condicional para calcular

a probabilidade da intersecção de 3 eventos, ou mais. Para isso basta fazer

P(A

B

\

\

C) = P(C

A

|

\

B)P(A

\

B) = P(C

A

|

\

B)P(B

|

A)P(A),

ou seja

30

P(A

B

\

\

C) = P(A)P(B

A)P(C

A

|

\

B).

|

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

O mesmo raciocínio no caso de n eventos A1, A2, . . . , An nos dá

P(A1 \

A2 \· · ·\

An) = P(A1)P(A2|

A1)P(A3|

A1 \

A2)

P(An|

A1 \· · ·\

· · ·

An

1).

 

1.4.1 Independência

Vamos agora tentar entender um dos conceitos centrais na teoria das probabilidades,

a independência de eventos. Em linhas gerais, diremos que dois eventos são indepen-

dentes quando a ocorrência de um dos eventos não trás nenhuma informação sobre

o outro. Antes de colocar esta deﬁnição de forma mais clara, vamos tentar deixar as

coisas mais claras com um exemplo.

Exemplo 1.7. Voltando ao jogo de dados de Breno, considere que os dados são distin-

tos, sendo um deles azul e o outro vermelho. Nesta jogada Breno apostou que o dado

vermelho mostraria a face 6. Alberto, por sua vez, revela a Breno após a jogada que o

dado azul mostrou um resultado menor que 3.

Breno se recorda então que o espaço amostral W deste experimento é composto

pelos 36 pares de número (a, b) onde a representa o resultado do dado azul e o b o do

vermelho. Os eventos em jogo desta vez são

E =

=

{

{

o dado vermelho mostrou 6

}

(1, 6); (2, 6); (3, 6); (4, 6); (5, 6); (6, 6)

,

}

e

F =

=

{

{

o dado azul mostrou um número menor que 3

}

(1, 1); (1, 2); (1, 3); (1, 4); (1, 5); (1, 6); (2, 1); (2, 2); (2, 3); (2, 4); (2, 5); (2, 6)

,

}

e portanto

P(E) =

6
36

=

1
6

e

P(F) =

12
36

=

1
3

.

Para calcular P(E

|

F) precisamos ainda de P(E

F), mas como

\

F =

E

\

{

(1, 6); (2, 6)

,

}

temos que P(E

F) = 1/18, e

\

F) =

P(E

|

P(E

F)

\
P(F)

=

1/18
1/3

=

1
6

= P(E).

31

P R I N C Í P I O S D E P R O B A B I L I D A D E

Assim Breno conclui que a informação de Alberto não ajudou em nada, e decide

manter a aposta inicial.

|

No exemplo acima P(E

F) = P(E), mostrando que a informação sobre a ocorrência

de F não interferiu na probabilidade de E, e neste sentido podemos dizer que E é

independente de F.

A primeira questão que aparece é se E ser independente de F também implica que

F é independente de E. Ou ainda se

F) = P(E)

P(E

|

()

P(F

|

E) = P(F).

Antes de responder a questão, podemos voltar ao exemplo e ver que

E) =

P(F

|

P(E

F)

\
P(E)

=

1/18
1/6

=

1
3

= P(F),

e portanto neste caso podemos também dizer que F é independente de E.

De modo geral, tomando dois eventos A e B de probabilidade positiva, note que

P(A

|

B) = P(A)

,

,

,

P(A

B)

\
P(B)

= P(A)

P(A

B) = P(A)

P(B)

·

\

P(A

B)

\
P(A)

= P(B)

P(B

|

,

A) = P(B).

Mostramos assim que independência é uma característica do par de eventos, e

olhando na segunda linha do argumento acima encontramos uma maneira mais sim-

ples de caracterizar independência, que explicitamos na deﬁnição a seguir.

Deﬁnição 1.3. Dada uma probabilidade P em um espaço amostral W, diremos que

dois eventos A e B são independentes se

P(A

\

B) = P(A)

P(B).

·

Como ilustrado no exemplo 1.7, independência é uma propriedade esperada quando

um mesmo experimento é repetido sem que o resultado de um inﬂua diretamente no

32

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

outro, como seguidos sorteios da loteria, repetidos lançamentos de uma moeda ou

algo similar.

Mas não é apenas nestes casos que esperamos encontrar independência. Para ilus-

trar, voltemos por um instante ao exemplo 1.7, e suponha que a informação dada por

Alberto seja que a soma dos resultados dos dois dados é 7. Neste caso, a informação

de Alberto leva em conta o resultado dos dois dados, então é razoável supor que a

probabilidade de vitória de Breno seja alterada.

Para veriﬁcar esta hipótese deﬁna o evento

G =

=

{

{

a soma dos resultados é 7

}

(1, 6); (2, 5); (3, 4); (4, 3); (5, 2); (6, 1)

,

}

E =

=

{

{

o dado vermelho mostrou 6

}

(1, 6); (2, 6); (3, 6); (4, 6); (5, 6); (6, 6)

,

}

o dado vermelho mostrou 6 e a soma dos resultados foi 7

}

(1, 6)

.

}

lembre que

e observe que

G =

E

\

=

{

{

Segue assim que

1
6 ·
de onde concluímos que E e G são de fato independentes, contrariando nossa hipótese

= P(E)

P(G),

1
36

G) =

P(E

1
6

\

=

·

inicial!

É interessante observar que o evento F do exemplo 1.7 também é independente de

G, uma vez que

G =

F

\

{

(1, 6); (2, 5)

,

}

e

2
6 ·
Isso mostra que E, F são independentes, F, G são independentes, assim como E, G

= P(F)

P(G).

2
36

G) =

P(F

1
6

\

=

·

também são. Mas o trio E, F, G não pode ser independente! Isso por que, se a soma

dos resultados é 7 e o dado vermelho é 6, então o dado azul é obrigatoriamente menor

que 3. Ou seja, P(F

G) = 1.

E

|

\

Isso mostra que para deﬁnir a independência de diversos eventos precisamos pedir

mais que apenas independência dois a dois, como se veriﬁca na deﬁnição a seguir.

33

P R I N C Í P I O S D E P R O B A B I L I D A D E

Deﬁnição 1.4. Dada uma probabilidade P em um espaço amostral W, diremos
que eventos A1, A2, . . . , An em W são independentes se para quaisquer índices
i1, i2, . . . , ik 2{

, distintos 2 a 2, com 1

n, vale que

1, 2, . . . , n





}

k

P(Ai1 \

Ai2 \· · ·\

Aik ) = P(Ai1)

P(Ai2)

·

· · ·

P(Aik ).

O exemplo a seguir descreve uma importante distribuição de probabilidade que faz

uso do conceito de independência em sua deﬁnição.

Exemplo 1.8 (Distribuição Geométrica). Para este exemplo considere um experimento

aleatório qualquer de sua preferência. Pode ser a rolagem de um dado, o lançamento

de uma moeda, o sorteio de carta, um sorteio da loteria, ou mesmo a escolha de uma

pessoa na rua para responder uma pesquisa eleitoral.

Considere também um evento A no espaço amostral de tal experimento, com proba-

bilidade p.

Imagine agora a possamos repetir tal experimento quantas vezes forem necessárias,

de modo que cada repetição seja independente das demais.

Vamos agora repetir este experimento até que o evento A seja observado. Feito

isso, queremos associar uma probabilidade P aos elementos de W =

indicam o total de repetições necessárias.

1, 2, 3, 4, . . .

que

}

{

A chave para a deﬁnição de P está na palavra independente usada para descre-

ver as repetições do experimento. Matematicamente, podemos dizer que os eventos

A1, A2, . . . , dados por

Ak =

{

o evento A foi observado na k-ésima repetição do experimento

,

}

são independentes, no sentido da deﬁnição 1.4.

Para deﬁnir P em W precisamos atribuir uma probabilidade para cada valor k

o que formalmente é o mesmo que atribuir uma probabilidade aos eventos

W,

2

Bk =

{

foram necessárias k repetições

=

k

.

}

{

}

Para isso, observe que

Bk = Ac

1 \· · ·\

Ac
k

 

1 Ak,

34

1.4 P R O B A B I L I D A D E C O N D I C I O N A L E I N D E P E N D Ê N C I A

e como, por hipótese, P(Ai) = p para todo i

1 e A1,

 

· · ·

, Ak são independentes, então

P(Bk) = P(Ac

1 \· · ·\

Ac
k

 

1 Ak) = (1

 

p)k

1 p.

 

35

2

C A D E I A S D E M A R K O V

“O raciocínio estatístico será um dia tão

necessário à cidadania eﬁciente quanto a

capacidade de ler e escrever”

— H.G.Wells

2.1 I N T R O D U Ç Ã O

Já vimos que um grande número de matemáticos contribuiu para a gênese da Teo-

ria Moderna das Probabilidades, em especial a escola russa do ﬁnal do século XIX e

início do século XX, iniciada por Chebyshev e coroada por Kolmogorov com brilhantes

e fundamentais estudos. Era uma época em que se buscava, além da axiomatização

da Teoria, um modo de compreender padrões de distribuição de probabilidades emer-

gentes em sistemas simples. Começava, de maneira mais programática, a busca pela

ordenação do caos a que ﬁzemos referência no capítulo anterior.

Para tentar ilustrar o que vamos estudar neste capítulo, pensemos no seguinte expe-

rimento aleatório, encontrado em [9] ou [18].

Exemplo 2.1. Em um laboratório de testes comportamentais, um ratinho é colocado

numa gaiola com três espaços distintos, todos comunicáveis entre si. Cada espaço

tem aproximadamente a mesma área. Ele se encontra inicialmente no espaço 1 e já foi

treinado para mudar de espaço atravessando uma porta sempre que soa um alarme (de

minuto em minuto). Cada vez que soa o alarme o ratinho escolhe qualquer uma das

37

C A D E I A S D E M A R K O V

portas disponíveis, com igual probabilidade e sem ser afetado por escolhas anteriores.

Imaginemos agora esse experimento se repetindo continuamente, minuto após mi-

nuto, por um intervalo arbitrariamente grande de tempo. Será que o ratinho ﬁcou

mais ou menos a mesma proporção de tempo em cada um dos espaços?

Dado o que estudamos até o momento, o problema acima não possui uma resposta

trivial, e à primeira vista é possível pensarmos sim. Mas uma análise mais cuidadosa

rapidamente coloca dúvidas em tal hipótese. Note que entre as salas 2 e 3 existem 2

portas, enquanto a sala 1 se comunica com as demais através de uma única porta para

cada sala. Isso faz com que o rato tenha uma maior probabilidade de ir da sala 2 para

a 3 (ou vice-versa) do que retornar para a sala inicial, fazendo com que ele ﬁque mais

tempo nestas salas.

Ao longo deste capítulo vamos estudar as ferramentas necessárias para responder tal

pergunta. Para tal modelaremos este experimento usando um tipo especial de processo

temporal aleatório conhecido como Cadeias de Markov, que levam este nome em home-

nagem à Andrei Andreyevich Markov (1856 - 1922), um matemático russo que fez

importantes contribuições no estudo da perda de memória em processos estocásticos.

38

2.2 C O N C E I T O S I N I C I A I S

Acompanhando o desenvolvimento contemporâneo da Teoria de Probabilidades, o

estudo das Cadeias de Markov também tem experimentado notáveis avanços, desde

sua sistematização, realizada em 1938 por Kolmogorov das bases dos processos aleató-

rios que as caracterizam. Os trabalhos do próprio Kolmogorov e de Aleksandr Yakovle-

vich Khintchine (1894 – 1959) permitiram o surgimento desigualdades martingales

e do cálculo estocástico mais rigorosamente estabelecido, ao lado das contribuições

dos matemáticos Joseph Leo Doob (1910 – 2004) e Paul Lévy (1886 – 1971); ao

longo do século XX, a Teoria das Cadeias de Markov vem ganhando mais espaço e se

expandindo para a aplicação em várias áreas: física, química, biologia, ciências sociais,

Teoria dos Jogos, música, linguística, processos do tipo Monte-Carlo, neurociências, bi-

oinformática, reconhecimento de imagens, reconhecimento de assinaturas, sistemas de

comunicação e internet, ciências da computação, teorias econômicas, Teoria das ﬁlas,

estudo de processos migratórios, processos de modelagem de evolução populacional,

modelos de difusão, dentre muitos outros.

2.2 C O N C E I T O S I N I C I A I S

A seguir introduziremos alguns conceitos e resultados envolvendo cadeias de Mar-

kov. Vários detalhes serão omitidos, pois fogem ao escopo deste trabalho. Maiores

detalhes poderão ser encontrados em [9, 18].

Antes de introduzir mais formalmente o que entendemos por uma Cadeia de Mar-

kov, voltemos ao exemplo 2.1, e tentemos descrever seus elementos principais. Antes

de mais nada, denote por X0, X1, X2, X3, . . . a sequência aleatória de quartos visitados
pelo rato durante seu passeio. Assim, X0 denota o quarto onde o rato começa seu pas-
seio (X0 = 1), X1 o primeiro quarto visitado depois de iniciar o passeio, X2 o segundo
quarto visitado, e assim por diante. Deste modo X0, X1, X2, . . . é uma sequência alea-
, formada de acordo com algumas regras, que
tória de números do conjunto

1, 2, 3

tentaremos descrever a seguir.

{

}

Antes de prosseguir, vamos estabelecer algumas notações, que deixaram nossa vida

mais simples. Para este problema, e ao longo de todo o capítulo, estaremos interessa-

dos principalmente nos eventos

. Para deixar a notação mais limpa faremos

Xn = i

}

{

duas pequenas alterações na notação que usamos até aqui.

1. Deixaremos de lado as chaves em

i) ou P(Xn+1 = j

Xn = i);

|

Xn = i

}

{

e escreveremos simplesmente P(Xn =

39

C A D E I A S D E M A R K O V

2. Quando estivermos falando da intersecção de eventos deste tipo, substituiremos

o símbolo

por ponto e vírgula (;). Assim, ao invés de P(

\

escreveremos P(Xn = 1; Xk = 2).

Xn = 1

}\{

Xk = 2

),

}

{

Voltando ao problema, considere que sempre que soa a campainha o rato escolhe

aleatoriamente uma das portas disponíveis no quarto onde ele está e passa por ela,

mudando de quarto.

Isso pode ser representado pelas seguintes equações, validas

para qualquer instante de tempo n

0.

 

P(Xn+1 = 2

P(Xn+1 = 3

P(Xn+1 = 1

P(Xn+1 = 3

P(Xn+1 = 1

P(Xn+1 = 2

Xn = 1) =

Xn = 1) =

Xn = 2) =

Xn = 2) =

Xn = 3) =

Xn = 3) =

|

|

|

|

|

|

1
2
1
2
1
3
2
3
1
3
2
3

.

Como o rato começa na sala 1, temos que P(X0 = 1) = 1 e P(X0 = 2) = P(X0 = 3) = 0.

Com estas informações em mãos podemos começar a entender o problema.

Queremos tentar calcular a proporção de tempo que o rato passa em cada sala após

uma grande número de movimentos, o que mais formalmente poderia ser encontrado

como

n(i)
n

,

lim
•
n
!

onde n(i) denota o total de vezes que o rato visitou a sala i após n minutos.

Para entender um pouco melhor a expressão acima, pensamos em um caso mais

simples. Suponha que jogamos um dado n vezes, e contamos a proporção de vezes
que o número 1 foi observado. Como a probabilidade do valor 1 ser observado é 1/6

em cada uma das n jogadas, esperamos que quando n for suﬁcientemente grande, a
fração n(1)/n esteja próxima de 1/6.

Um elemento essencial neste exemplo é o fato de que a probabilidade de observar-

mos o valor 1 é constante e igual a 1/6. Mas isso não ocorre no caso do nosso ratinho.
No nosso caso P(Xn = i) parece depender de n para qualquer i. Mais a frente mostra-
remos como calcular tais valores, mas por enquanto observe, por exemplo que

P(X0 = 2) = 0

40

e como da sala 1 o rato pode ir para as salas 2 ou 3 com a mesma probabilidade,

2.2 C O N C E I T O S I N I C I A I S

P(X1 = 2) =

1
2

= P(X1 = 3).

Além disso

P(X2 = 2) = P(X2 = 2; X1 = 1) + P(X2 = 2; X1 = 3)

= P(X2 = 2
2
3 ·

0 +

=

|

X1 = 1)P(X1 = 1) + P(X2 = 2
1
2

|

X1 = 3)P(X1 = 3)

1
2 ·
1
3

.

=

Assim P(X0 = 2) = 0, P(X1 = 2) = 1/2 e P(X2 = 2) = 1/3, o que ilustra a dependência
de P(Xn = 2) em n. Isso deixa claro que se quisermos encontrar a proporção de tempo
que o rato passa em cada sala, precisamos antes entender como se comporta P(Xn = i)
para cada sala i.

Neste sentido, observe que neste exemplo, sempre que o rato decide para que sala

ele vai a única informação necessária é a sala onde ele se encontra, sem precisar saber

como ele chegou até ali ou mesmo a quanto tempo ele está andando pelo labirinto.

Sequências aleatórias com este tipo de propriedade são conhecidas como Cadeias de

Markov, e serão nosso objeto de estudo pelo resto deste capítulo.

Deﬁnição 2.1. Uma Cadeia de Markov é uma sequência aleatória X0, X1, X2, . . . de
elementos em um conjunto S =

tal que

a1, a2, . . . , al}

{

P(Xn+1 = j

Xn = i; Xn

1 = in

 

 

|

1; . . . ; X0 = i0) = P(Xn+1 = j

Xn = i),

|

(2.1)

para qualquer n

0 e quaisquer i0, i1, . . . , in

1, i, j

S.

 

 
O conjunto S é chamado espaço de estados da cadeia, e a probabilidade P(Xn+1 =
Xn = i) é conhecida como probabilidade de transição do estado i para o estado j, e

2

j
|
representada por Pij. Ou seja,

Pij = P(Xn+1 = j

Xn = i).

|

A equação (2.1) é central na deﬁnição de Cadeias de Markov e nos diz que, assim

como no caso do rato no exemplo 2.1, a única informação necessária na decisão do

41

C A D E I A S D E M A R K O V

estado da cadeia no instante n é o estado no instante anterior, sendo portanto indepen-

dente de todo o resto da trajetória até aquele momento.

Para cada sítio i, as entradas Pia1 , Pia2 , . . . , Pial representam as probabilidades de cada
caminho disponível quando a cadeia sai do estado i, e devem portanto formar por si
só uma distribuição de probabilidade. Ou seja, Piaj  
+ Pial = 1.

Pia1 + Pia2 +

0 e

· · ·

M AT R I Z D E T R A N S I Ç Ã O

Agora que deﬁnimos os elementos que caracterizam uma

cadeia de Markov, precisamos organizar estas informações de modo a melhor visuali-

zar todos os elementos envolvidos. Assim, dada uma cadeia de Markov (Xn)n
espaço de estados S =
nimos a matriz de transição P = (Pai aj)m
coluna de P a probabilidade de transição Pai aj do estado ai para o estado aj.

e probabilidades de transição Pij,

2
ésima linha e j

m colocando na i

a1, . . . , am}

i, j

 

{

⇥

0 com
 
S, deﬁ-

ésima

 

A matriz P não apenas ajuda na organização dos elementos da cadeia, como tem

um papel central nos cálculos que faremos mais a frente.

A seguir damos alguns exemplos para ilustrar melhor tudo o que vimos até aqui.

Exemplo 2.2. Voltando ao exemplo 2.1, o passeio do rato entre as 3 salas pode ser re-

presentado por uma cadeia de Markov X1, X2, . . . , com espaço de estados S =
e matriz de transição dada por

{

1, 2, 3

}

0
1
3
1
3

1
2
0
2
3

P = 2

6
6
4

1
2
2
3
0

3

.

7
7
5

Exemplo 2.3. Considere um sistema de comunicação que transmite os dígitos 0 e 1.

Cada dígito passa por várias etapas, e em cada passagem há uma probabilidade p que

o dígito que entrou permaneça inalterado quando sair.

Se denotarmos por Xn o digito transmitido após a n-ésima passagem temos que

P(Xn+1 = 1

|

Xn = 1) = P(Xn+1 = 0

Xn = 0) = p

|

P(Xn+1 = 1

|

Xn = 0) = P(Xn+1 = 0

Xn = 1) = 1

|

p

 

e

42

Assim, este problema pode ser modelado por uma Cadeia de Markov de dois estados,

0, 1

}

{

, com matriz de transição dada por

2.2 C O N C E I T O S I N I C I A I S

P =

"

1

p

 

p

1

p

 
p #

.

Exemplo 2.4. Sabemos que o humor de uma pessoa varia com o tempo. Para tentar

modelar estas mudanças, suponha que uma pessoa pode estar bem humorada (B),

indiferente (I) ou mal humorada (M). Se ela está bem humorada hoje, então ela estará

bem humorada (B), indiferente (I) ou mal humorada (M) amanhã com probabilidades

0, 5, 0, 4 e 0, 1 respectivamente. Se ela está indiferente hoje, então ela estará B, I ou M

amanhã com probabilidades 0, 3, 0, 4 e 0, 3 respectivamente. Finalmente, se ela estiver

mal humorada hoje, então ela estará B, I ou M amanhã com probabilidades 0, 2, 0, 3 e

0, 5 respectivamente. Deste modo modelamos o humor de uma pessoa dia a dia como

uma Cadeia de Markov de três estados (S =

B, M, I

{

}

), e matriz de transição

0, 5 0, 4 0, 1

P = 2

0, 3 0, 4 0, 3

3

0, 2 0, 3 0, 5

6
6
4

7
7
5

Exemplo 2.5 (Bêbado no trânsito). Consideremos uma pessoa guiando um automóvel

por uma pista que tem três faixas de rolamento (estados i = 1, i = 2 e i = 3); tal

pista não tem acostamentos, contando com um abismo à esquerda (estado i = 0)

e à direita (estado i = 4). A permanência ou não do carro na faixa de rolamento

atual é completamente aleatória, e a cada minuto (digamos) existe a possibilidade

de mudança de faixa. Coloquemos probabilidade de 1/3 do carro ir para a faixa à

esquerda no minuto seguinte, probabilidade de 1/3 dele permanecer na mesma faixa

no minuto seguinte, e probabilidade de 1/3 do carro ir para a faixa à direita no minuto

seguinte. Podemos modelar tal situação por uma Cadeia de Markov, dado que o fato

do carro mudar ou não de faixa no minuto seguinte é determinado apenas pelo estado

43

C A D E I A S D E M A R K O V

atual em que está o carro. A matriz de transição para um passo (mudança do primeiro

minuto para o segundo minuto) será:

1
3
1
3
0 0

1 0 0 0 0
1
1
3
3
1
0
0
3
1
1
3
3
0 0 0 0 1

0 0
1
3
1
3

.

3

7
7
7
7
7
7
7
5

P =

2

6
6
6
6
6
6
6
4

Essa fatídica viagem terminará se o carro cair em qualquer um dos dois abismos, o

que signiﬁca alcançar o estado i = 0 ou o estado i = 4. Alcançado esse estado, o carro

não sai mais de lá. Isso está representado nas linhas associadas aos estados 0 e 4 da

matriz de transição, nas quais a probabilidade de permanência é 1 e as demais são

0. Assim , ao chegar nesses estados, o processo é “absorvido” e permanece ali para

sempre. Por esta razão, chamamos tais estados de absorventes.

2.3 A T R A N S I Ç Ã O E M n PA S S O S E A E Q U A Ç Ã O D E C H A P M A N - K O L M O G O R O V

Dando sequência ao nosso estudo, lembre-se que queremos tentar entender como

se comportam as probabilidades P( X n = a) da cadeia estar em cada estado a no
instante n. É importante observar que P( X n = a) depende não apenas do estado a e
do instante n, como também do estado em que iniciamos o processo. Deste modo, o
que estamos interessados de fato são as probabilidades P( X n = a
X0 = b) para cada
par de estados a , b

S.

|

2

Tais valores para n = 1 são representados na matriz de transição da cadeia, mas

gostaríamos de entender como calcular tais valores para qualquer instante n. Antes

de mais nada, lembre-se que a cada passo a cadeia “esquece” sua trajetória até aquele

X k = j) não depende de k. Isso nos permite deﬁnir
como a probabilidade do processo sair do estado a e chegar no estado b em n

|

instante, de modo que P( X k+n = i
P (n)
i j
passos, isto é

P (n)
i j = P( X k+n = j

X k = i).

|

Assim podemos deﬁnir a matriz de transição de n passos para a cadeia com estados
a 1 , . . . , a m }

como a matriz P (n) com entradas P (n)
a i a j .

{

44

2.3 A T R A N S I Ç Ã O E M n PA S S O S E A E Q U A Ç Ã O D E C H A P M A N - K O L M O G O R O V

Deste ponto em diante notaremos Pa i a j simplesmente por Pi j, e desta forma i poderá

ser um estado em S ou representará o estado a i 2

S.

Para entender como calcular P (n) precisamos antes entender como as matrizes P (n)
se relacionam entre si para distintos valores de n. Neste sentido, vamos primeiro tentar

entender a probabilidade de que o processo, estando no estado i, chegar ao estado k

em n passos e de, na sequência, sair do estado k e alcançar o estado j em mais m passos

adicionais. Ou seja, queremos calcular

P( X n = k; X n+m = j

X0 = i).

|

Mas aplicando diretamente as deﬁnições de probabilidade condicional e de cadeia de

Markov, encontramos que

P( X n = k; X n+m = j

X0 = i) =

|

P( X n+m = j; X n = k; X0 = i)
P( X0 = i)

= P( X n+m = j

= P( X n+m = j

|

|

X n = k; X0 = i)

P( X n = k; X0 = i)
P( X0 = i)

·

X n = k; X0 = i)P( X n = k

X0 = i).

|

Ou seja,

P( X n = k; X n+m = j

X0 = i) = P (n)
i k

|

P (m)
k j

.

·

Com isso podemos relacionar as entradas de P (n+m), P (n) e P (m), bastando para isso
perceber que para chegar de i até j em n + m passos, a cadeia precisará passar por

algum estado k

2

S no instante n, antes de seguir até j após mais m passos. Assim,

P (n+m)
i j

= P( X n+m = j

X0 = i)

|

= P( X n = 1; X n+m = j
1 j + P (n)
P (m)
= P (n)
i1

i2

|
P (m)
2 j +

·

·

· · ·

· · ·
+ P (n)
i l

P (m)
l j

.

·

X0 = i) +

+ P( X n = l ; X n+m = j

X0 = i)

|

Mostramos assim o seguinte resultado.

Proposição 2.2 (Equação de Chapman-Kolmogorov). Dada uma cadeia de Markov com
matriz de transição de n passos P (n) = ( P (n)
i j

l , vale que

) l

⇥

P (n+m)
i j

=

l
Â
k=1

P (n)
i k

·

P (m)
k j

.

(2.2)

A equação (2.2) vem de encontro a interpretação matricial das equações. De fato,
P (m) devemos

lembre-se que para calcular o elemento da linha i coluna j em P (n)

·

45

C A D E I A S D E M A R K O V

P(n)
11
P(n)
21
...
P(n)
l1

2

6
6
6
6
6
4

· · ·

· · ·
. . .

P(n)
12
P(n)
21
...
P(n)
l2

P(n)
1l
P(n)
2l
...
P(n)
ll

3

2

·

P(m)
11
P(m)
21
...
P(m)
l1

P(m)
12
P(m)
21
...
P(m)
l2

6
6
6
6
6
4
Figura 7: Esquema de cálculo de P(n+m)

7
7
7
7
7
5

· · ·

· · ·

21

· · ·

· · ·
. . .

P(m)
1l
P(m)
2l
...
P(m)
ll

3

7
7
7
7
7
5

tomar os elementos da linha i de P (n) e multiplicar pelos respectivos elementos da
coluna j de P (m) e somar, exatamente como é feito na equação (2.2). E portanto

como ilustrado na ﬁgura 7.

P (n+m) = P (n)

P (m) ,

·

Conseguiremos perceber melhor esta aﬁrmação utilizando um exemplo simples. Seja

2 a matriz que traz a evolução de n passos de uma cadeia de dois estados, e
2 a matriz que traz a evolução de m passos da mesma cadeia. Tendo duas

(P(n))2
⇥
seja (P(m))2
matrizes de mesma ordem, lançamos mão da multiplicação usual obtendo

⇥

P(n)
11
P(n)
21

"

P(n)
12
P(n)
22 # · "

P(m)
11
P(m)
21

P(m)
12
P(m)
22 #

=

"

P(n)
11 P(m)
21 P(m)
P(n)

11 + P(n)
11 + P(n)

12 P(m)
22 P(m)

21

21

P(n)
11 P(m)
21 P(m)
P(n)

12 + P(n)
12 + P(n)

12 P(m)
22
22 P(m)
22 #

,

que pela equação (2.2) é equivalente à

P(n)

·

P(m) = P(n+m).

É interessante observar também que

P(n)

·

P(m) = P(n+m) = P(m+n) = P(m)

P(n).

·

Outra consequência importante da equação de Chapman-Kolmogorov é que P(n) =

Pn. Para ver isso, comece percebendo que por deﬁnição

P(1) = P = P1.

Calculando para n = 2 vemos que, por Chapman-Kolmogorov

P(2) = P(1+1) = P(1)

Seguindo, para n = 3 vale

P(3) = P(2+1) = P(2)

P(1) = P

P(1) = P2

P = P2.

P = P3.

·

·

·

·

46

2.3 A T R A N S I Ç Ã O E M n PA S S O S E A E Q U A Ç Ã O D E C H A P M A N - K O L M O G O R O V

Assim, seguindo o mesmo raciocínio para os demais valores de n concluímos que, de
fato, P(n) é a n-ésima potência de P.

ij no lugar de P(n)

Por esta razão, deste ponto em diante, passaremos a usar Pn para indicar a matriz
. É importante apontar, no entanto, que apesar de Pn ser a
n, de modo que

P(n), e Pn
n-ésima potência de P, em geral não podemos aﬁrmar que Pn
Pn
ij não deve ser visto como uma potência.

 

 

ij =

Pij

ij

Exemplo 2.6. Voltando mais uma vez ao exemplo 2.1, queremos agora calcular a

probabilidade do rato ir da sala 1 para a sala 3 em 4 passos. Ou seja, queremos
encontrar P4

X0 = 1).

13 = P(X4 = 3

|

Para isso lembramos que a matriz de transição P é dada por

0
1
3
1
3

1
2
0
2
3

1
2
2
3
0

3

,

7
7
5

10
27
77
182
5
18

10
27
5
18
77
182

3

.

7
7
5

P = 2

6
6
4

7
27
20
81
20
81

P = 2

6
6
4

e calculando P4 encontramos

Assim

P(X4 = 3

|

X0 = 1) =

10
27 ⇡

0, 3703.

2.3.1 Tentando Interpretar Pn

Como comentamos no início do capítulo, estamos interessados em calcular a propor-

ção de tempo que o rato passa em cada um das salas 1, 2 e 3, e para isso concluímos

que precisamos antes entender o comportamento de P(Xn = i

X0 = 1) para n grande.

|

Calculando então a matriz de transição de n passos para n = 8 e n = 16 encontramos

P8

⇡

0, 25012 0, 37494 0, 37494

2

0, 24996 0, 39452 0, 35552

3

0, 24996 0, 35552 0, 39452

6
6
4

7
7
5

47

C A D E I A S D E M A R K O V

e

P16

⇡

0, 25

0, 375

0, 375

2

0, 24999 0, 37576 0, 37425

3

.

0, 24999 0, 37425 0, 37576

6
6
4

7
7
5

Apesar dos valores acima serem aproximados, eles parecem indicar que algo bas-

tante interessante está acontecendo: as distribuições de probabilidade de cada linha

parecem estar se aproximando rapidamente de [0, 25

0, 375

0, 375].

Se isso for verdade podemos concluir duas coisas bastante importantes. A primeira

é que a proporção de tempo que o rato passa em cada sala após um longo período

de caminhada, deve ser aproximadamente igual à [0, 25

0, 375

0, 375], respondendo

nossa questão inicial!

Mas além disso, este comportamento parece ser o mesmo para cada linha da matriz,

o que reforçaria a ideia de que o rato realmente esquece a sala de onde saiu.

Mas surgem agora algumas novas questões. Este comportamento está realmente

acontecendo, ou foi apenas uma feliz escolha de potências? Ele acontece para qualquer

cadeia de Markov? Se não, sob quais condições ele acontece?

Antes de continuar explorando estas questões, vamos colocar mais alguns exemplos.

Exemplo 2.7. Um laboratório faz testes para medir a memória recente de camundon-

gos, e para isso os submete a um labirinto simples, que pode levar a três caminhos:

recompensa (R), choque elétrico (C) e encontro com o espelho (E). Um camundongo

é exposto a uma sequência de passeios pelo labirinto, com um intervalo de algumas

horas entre um passeio e outro. Através de levantamento das frequências relativas de

ocorrência dos diversos comportamentos da cobaia, chegou-se a algumas conclusões:

a) O camundongo nunca vai para o espelho duas vezes seguidas;

b) Se ele encontra a recompensa, a chance de encontrar novamente a recompensa no

próximo passeio é de 50%, e a probabilidade de encontrar o espelho (bem como o

choque elétrico) é de 25%;

c) Se ele encontra o espelho, as probabilidades de ele ir para a recompensa ou para o

choque elétrico no próximo passeio são iguais;

d) Se ele encontra o choque, a chance dele no próximo passeio encontrar novamente

o choque é de 50%, e a probabilidade de encontrar a recompensa (bem como o

espelho) é de 25%.

48

2.3 A T R A N S I Ç Ã O E M n PA S S O S E A E Q U A Ç Ã O D E C H A P M A N - K O L M O G O R O V

Tem-se então uma matriz de transição da forma:

0, 5

0, 25 0, 25

P = 2

0, 5

0

0, 5

3

0, 25 0, 25

0, 5

6
6
4

7
7
5

Podemos agora calcular as probabilidades de transição para tempos maiores.

0, 4375 0, 1875

0, 375

P2 = 2

0, 375

0, 25

0, 375

3

6
6
4

0, 375

0, 1875 0, 4375

7
7
5

e

P4

⇡

P8

⇡

0, 40234 0, 19922 0, 39844

2

0, 39844 0, 20312 0, 39844

3

0, 39844 0, 19922 0, 40234

6
6
4

7
7
5

0, 40001

0, 2

0, 39999

2

0, 39999 0, 20002

0, 3999

3

0, 39999

0, 2

0, 40001

6
6
4

7
7
5

Assim como no exemplo 2.1, Pn parece estar se aproximando de uma matriz de tran-
sição com todas as linhas iguais. Isso signiﬁca que após algumas tentativas, a proba-

bilidade de que o camundongo encontre o choque elétrico será 0,40 e isso independe

de qualquer resultado de passeios anteriores.

Considere agora que, por qualquer razão, nós saibamos que Pn se aproxima de uma
dada matriz P⇤ quando n cresce, e que todas as linhas de P⇤ são iguais. Será que é
possível encontrar tal matriz sem precisar calcular Pn exaustivamente?

Para responder esta pergunta, vamos primeiro lembrar uma importante propriedade

da multiplicação de matrizes: ao multiplicarmos duas matrizes A e B, a i-ésima linha

do produto A

B é de fato o resultado do produto da i-ésima linha de A, vista como

·
uma matriz com 1 linha, por B.

Para ilustrar melhor esta propriedade considere o produto

1

2

1

1

1 3

 

2

6
6
4

0

1

 
2

·

3

7
7
5

2

6
6
4

 
0

3

1 0

1

1

1

1

3

= 2

 

1

7
7
5

6
6
4

 

 
7

1 1 2

5 0 4

5 0

3

,

7
7
5

49

C A D E I A S D E M A R K O V

e observe que

1 1 0

h

·

i

2

6
6
4

2 1

h

1

 

·

i

2

6
6
4

e

1

1

 

1

1

1

1 0

 
0

3

 
0

3

1

1

1

1

1 0

1 1 2

,

i

 

h

3

=

7
7
5

3

=

5 0 4

,

i

 

h

 

1

7
7
5

1

1

1

 

7
7
5

1 0

1

1

 
0

3

2

·

6
6
4

1 3 2

i

 

h

3

=

7 5 0

.

h

i

Posto isso, voltemos à nossa matriz P⇤. Sabemos que Pn se aproxima de P⇤ quando
P⇤. Com isso podemos

n é muito grande, e para simpliﬁcar notaremos isso por Pn
dizer que, mas se Pn

P⇤, então deveríamos ter que

!

!

mostrando que P⇤ deve ser tal que

Pn = Pn

 

1

P

·

⇡

P⇤

P,

·

P⇤ = P⇤

P.

·

Agora, como todas as linhas de P⇤ são iguais, se chamarmos esta linha comum de v,

segue da propriedade acima que

vP = v.

Além disso, como para todo n as entradas de cada linha de Pn são positivas, e somam
1, o mesmo acontece com os elementos de v.

Em resumo, se a cadeia possui m estados, estamos buscando v = [x1 x2 · · ·

xm], com

0, i = 1, . . . m, e x1 +

+ xm = 1, tal que vP = P.

xi  

· · ·

Voltando ao exemplo anterior, onde

0, 5

0, 25 0, 25

P = 2

0, 5

0

0, 5

3

,

6
6
4
Estamos buscando v = [x y z], com x + y + z = 1 tal que vP = P. Ou seja,

7
7
5

0, 25 0, 25

0, 5

0, 5

0, 25 0, 25

x y z

2

0, 5

0

0, 5

3

=

x y z

.

h

i

6
6
4

0, 25 0, 25

0, 5

h

i

7
7
5

50

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

Isso nos leva ao sistema

0, 5x + 0, 5y + 0, 25z = x

0, 25x +

+ 0, 25z = y

0, 25x + 0, 5y + 0, 5z

= z

,

x

+

y

+

z

= 1

8

>>>>><
>>>>>:

v =

0, 4 0, 2 0, 4

,

h

i

e consequentemente a

como esperávamos.

Como comentamos antes, v é uma distribuição de probabilidade, que representa o
comportamento das probabilidades P(Xn = j
X0 = 1) para n suﬁcientemente grande,
e não depende do estado i. Pois estas razões, ele é conhecido como distribuição de

|

equilíbrio da cadeia. Voltaremos a isso mais tarde, ainda neste capítulo.

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

Em uma cadeia de Markov, tanto a análise das características de cada estado como

o estudo da relação entre dois estados quaisquer têm grande relevância.

Com efeito, se consideramos o conjunto dos estados possíveis em uma Cadeia de

Markov, podemos partir de um ponto arbitrário para iniciar o processo interativo? Se

isso estiver garantido, é possível passar por todos os estados da Cadeia ou existirão

estados que são inacessíveis? E se damos início ao processo partindo desses estados

inacessíveis, o que acontece no decorrer do processo? Existe caminho de ida e de volta

entre quaisquer dois estados escolhidos ao acaso? Haverá na Cadeia um estado (ou um

grupo de estados) com a característica peculiar de absorver o processo para ele? Se o

processo passa por um dado estado, é possível retornar a ele? Com qual probabilidade?

Existe algum tipo de periodicidade no processo interativo? Como detectá-la?

Sob este enfoque, traremos aqui algumas deﬁnições centrais para a construção da

teoria; utilizaremos, além do tratamento matricial das cadeias, uma explicitação de

cada deﬁnição por meio de um desenho esquemático do espaço de estados e das pro-

babilidades de transição, que auxiliará a visualização de algumas destas propriedades.

Deﬁnição 2.3. Dada uma cadeia de Markov com espaço de estados S e matriz de

transição P, diremos que o estado j

S é acessível a partir do estado i

S (i

j),

!

2

2

51

C A D E I A S D E M A R K O V

se existir n

0 tal que Pn
positiva de atingir j em algum instante.

 

ij > 0. Ou seja, se partindo de i temos uma probabilidade

Se i

!

j e j

!

i, diremos que i e j são comunicáveis, e notaremos por i

j.

$

Veriﬁcar se i

j calculando potências da matriz de transição pode ser um trabalho

árduo e pouco frutífero. Uma maneira mais prática é usar a equação de Chapman-

!

Kolmogorov. Para isso, lembre-se que de (2.2) temos que

Pn
ij =

l
Â
k=1

PikPn

1
 
kj  

Pii1 Pn
 
i1 j

1

.

Assim, se encontrarmos um caminho i = io, i1, i2 . . . , in = j com

Pikik+1 > 0,

para todo k = 0, 1, . . . , n

1, temos que

 

Pn
ij  

Pii1 Pn

1
 
i1 j  

Pii1 Pi1i2 Pn

2
 
i2 j  

Pii1 Pi1i2 · · ·

Pin

2in

 

 

1 Pin

 

1 j > 0.

Uma forma que pode auxiliar na decisão de acessibilidade entre estados é fazer

uma representação pictórica da cadeia usando um grafo. Para cada estado da cadeia,

colocamos um ponto no plano. Se Pij > 0 colocamos uma seta de i para j. Se Pii > 0
desenhamos um laço em i.

Para ilustrar melhor o processo e a deﬁnição de acessibilidade, vamos a uma exem-

plo.

Exemplo 2.8. Considere uma Cadeia de Markov com espaço de estados S =

e matriz de transição

1, 2, 3, 4, 5

}

{

0

1
4
0

1
4
0 0

1
0
2
3
1
4
4
0 0 0 1 0
1
1
3
3
0 0 1 0 0

0 0

1
3

.

3

7
7
7
7
7
7
7
5

P =

2

6
6
6
6
6
6
6
4

Graﬁcamente, a cadeia acima pode ser representada por

52

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

5, usando o caminho 1, 2, 4, 5 ou o caminho 1, 3, 4, 5.

!

Pela ﬁgura é fácil ver que 1

No entanto 5

1.

6!

Do mesmo modo 2

Por outro lado, 3

!

3, mas 3

2.

!
6!
5, pelo caminho 3, 4, 5, e 5

3, de modo que 3

5.

$

!

De fato, uma análise mais cuidadosa mostra que

e

2

1

$

$
e qualquer outra relação de acessibilidade tem apenas uma direção. Com isso podemos

$

$

3

4, 4

5 e 3

5,

dividir os estados desta cadeia em dois grupos, ou classes, formados por elementos que

se comunicam entre si.

Esta divisão é possível pelo seguinte resultado.

Proposição 2.4. A relação de comunicabilidade (

Markov é uma relação de equivalência. Ou seja, para quaisquer i, j, k

) entre estados de uma cadeia de

$

1. i

$
2. Se i

3. Se i

i;

$

$

j, então j

i;

$

j e j

$

k, então i

k.

$

S vale que

2

53

C A D E I A S D E M A R K O V

Demonstração. Note que, pela deﬁnição de probabilidade condicional, P(X0 = i
i) = 1 para qualquer i

S, e portanto P0

i.

ii = 1 > 0 e i

X0 =

|

2

$

A propriedade 2 segue direto da deﬁnição de comunicabilidade.

Para terminar, note que se i
Pm
jk > 0, e portanto por Chapman-Kolmogorov

j e j

$

$

k, então existem n e m tais que Pn

ij > 0 e

Pn+m
ik  

Pn
ij ·

Pm
jk > 0,

e portanto i

k.

$

Como comentamos acima, este resultado nos permite separar os estados da cadeia

em conjuntos ou classes disjuntas, formadas apenas por estados que se comunicam

entre si.

Para isso, dado um estado i

S deﬁna a classe de i por

2

Ci =

j

{

2

S : i

j

.

}

$

Ou seja, Ci é o conjunto de todos os estados que se comunicam com i. A Classe Ci é
irredutível se j percorre todo S.

É interessante notar que se Ci \

Cj 6

= ∆, então Ci = Cj. Para ver isso tome a

e note que um estado k está em Cj se, se só se, j
a

a, e portanto k

Cj, temos que j

$
a. Agora, como a

k ou ainda k

$
Ci temos que i

2

onde segue que i

$
k, de onde concluímos que k

$

2
Ci. Assim

Cj,
2
j. Assim, como

Ci \

a, de

$

$

2

e portanto Ci = Cj.

k

Cj ,

k

2

2

Ci,

Outra forma de colocar a propriedade acima é que duas classes irredutíveis em uma

Cadeia de Markov, ou são idênticas ou são disjuntas.

Deﬁnição 2.5. Uma cadeia de Markov é dita irredutível se a relação de comunicabili-

dade divide o espaço de estados em apenas uma classe irredutível. Em outras palavras,

a cadeia é irredutível se para qualquer par de estados i, j

S temos que i

j.

$

2

54

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

Exemplo 2.9. A Cadeia de três estados

0, 1, 2

{

}

representada pela matriz de transição

1
2
1
2
0

1
2
1
4
1
3

0
1
4
2
3

2

6
6
4

3

,

7
7
5

é claramente irredutível, pois se transita do estado 0 para o estado 1 com probabilidade

1/2, do estado 1 para o estado 2 com probabilidade 1/4, do estado 2 para o estado 1

com probabilidade 1/3 e ﬁnalmente do estado 1 para o estado 0 com probabilidade

1/2, completando o ciclo.

Exemplo 2.10. Uma Cadeia, de quatro estados

sição

0, 1, 2, 3

}

{

e que tenha matriz de tran-

1
2
1
2
1
4

0 0

1
2
1
0 0
2
1
1
1
4
4
4
0 0 0 1

,

3

7
7
7
7
7
5

2

6
6
6
6
6
4
{

revela três classes, a saber:

0, 1

,

3

e

2

. Colocando mais explicitamente,

0, 1

}
{
é uma classe pois, entre os estados 0 e 1 há acessibilidade de ida e volta independen-

{

}

{

}

}

temente se o processo está em 0 ou em 1. Se conﬁgura

como uma classe pois é

um estado absorvente da Cadeia e isolado do processo, inacessível a partir de qualquer

3

{

}

outro estado e que não acessa nenhum outro ponto da Cadeia, a não ser ele mesmo.

2

{

}

Temos que

é uma classe pois não há acessibilidade para ele a partir dos estados

0 e 1. Pelo exposto acima, a Cadeia apresentada não é irredutível, o que também ﬁca

mostrado na representação esquemática da ﬁgura abaixo

55

C A D E I A S D E M A R K O V

Continuando nosso estudo, vamos agora olhar para o comportamento dos estados da

cadeia ao longo do tempo. A próxima deﬁnição diz respeito a possibilidade da cadeia

retornar a um dado estado ao longo da sua trajetória. Em outras palavras, estamos

interessados aqui em saber se ao sair de um certo estado i, a cadeia voltará ou não a

visitar tal estado.

Deﬁnição 2.6. Para um estado i

S qualquer, denotemos por fi a probabilidade que
o processo iniciado no estado i retorne novamente ao estado i. Diremos que o estado
i é recorrente se fi = 1 e transiente se fi < 1.

2

Além disso, se todos os estados da cadeia forem recorrentes (resp.

transientes),

diremos simplesmente que a cadeia é recorrente (resp. transiente).

Esta é um conceito mais complicado de entender, então gastaremos algum tempo

nele. Veriﬁcar a recorrência ou transiência de um estado nem sempre é fácil de de-

terminar olhando apenas para a matriz, mas vamos tentar colocar algumas ideias de

como fazê-lo.

Para isso, voltemos ao exemplo 2.10, e analisemos estado por estado.

Xn = 3) = 1 e assim, se a
Estado 3 - Este é o mais simples, pois a P(Xn+1 = 3
cadeia iniciar em 3, ela nunca mais sairá de lá, e portanto f3 = 1 e 3 é recorrente;

|

Estados 0 e 1 - Começando em qualquer um destes estados, o próximo poderá

ser qualquer um deles com probabilidade 1/2 cada. Ou seja,

P(X1 =

|

X0 = 1) = P(X1 = 2

|

X0 = 1) = P(X1 = 1

|

X0 = 2) = P(X1 = 2

X0 = 2) =

|

1
2

.

•

•

56

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

Isso se repetirá a cada instante de tempo, e portanto os estados se alterarão como

no lançamento de uma moeda, e portanto f1 = f2 = 1.

•

Estado 2 - Este estado é um pouco mais complicado. Observe que se a cadeia

iniciar em 4, para retornar à 4 ela, de fato, não pode sair! Isso por que se ele for

para 3, a cadeia permanecerá lá, como já vimos. E o mesmo acontecerá se for

para 1 ou 2. Com isso,

f4 = P(X1 = 4

X0 = 4) =

|

1
4

< 1,

e portanto 4 é transiente.

Para entender melhor o conceito de recorrência e transiência, suponha que um certo

estado i seja recorrente ( fi = 1), e que a cadeia partiu deste mesmo estado. Como
a probabilidade de retorno é 1, certamente a cadeia visitará novamente o estado i.

Quando isso acontecer, como os próximos passos da cadeia não dependem da trajetória

dela até este momento, a probabilidade de retorno é novamente 1, e cadeia certamente

retornará uma terceira vez ao estado i. Este argumento pode ser repetido a cada visita

da cadeia à i, e portanto o estado i será visitado inﬁnitas vezes durante a trajetória

da cadeia.

Por outro lado, se o estado i for transiente há uma probabilidade f c

fi > 0
de que o processo não retorne mais ao estado i, sempre que passar por ele. Ou seja,

i = 1

 

iniciado o processo no estado i, a probabilidade do processo retornar ao menos k vezes
à i tendo começar a i, antes de abandonar deﬁnitivamente o estado, é f k
i .

Chame de Ni o total de vezes que a cadeia visita i ao longo de sua trajetória. Dizer

que Ni é inﬁnito é o mesmo que dizer que Ni  

n para todo n > 0, e portanto

P(Ni = •) = P(Ni  

n para todo n > 0)

P(Ni  



k) = f k
i ,

para qualquer k.

Assim, como fi < 1 e

P(Ni = •)

P(Ni  



k) f k
i ,

para qualquer k,

podemos tomar k tão grande quanto quisermos para concluir que P(Ni = •) = 0.

Logo, podemos dizer que i é transiente se o total de visitas à i é ﬁnita.

Dentre outras coisas, que estudaremos posteriormente, esta relação nos revela uma

propriedade interessante, descrita na seguinte proposição.

Proposição 2.7. Em uma Cadeia de Markov com ﬁnitos estados, é impossível que todos

sejam transientes.

57

C A D E I A S D E M A R K O V

}

{

· · ·

, M

1, 2,

Demonstração. Para ver isso, suponha que S =
e denote por a1 o estado
no qual a cadeia tem início. Como a1 é transiente, vai existir um instante t1 que
marcará a última visita da cadeia à a1. Chame o estado que a cadeia se encontra em
= a1 e como a2 é transiente, existirá um tempo t2 tal
t1 + 1 de a2, e observe que a2 6
que em t1 + t2 a cadeia visitará a2 pela última vez. Chamando o próximo elemento de
= a2, e seguindo o raciocínio até aM, encontraremos um tempo
a3, temos a3 6
+ tM para o qual a cadeia visitou aM pela última vez. Como a cadeia não para,
t1 +
· · ·
no tempo t1 +
+ tM + 1 ela deve visitar um novo sítio x, que deverá ser igual a ak
para algum k, contrariando o fato de ak já ter sido visitado pela última vez.

= a1, a3 6

· · ·

Concluímos assim que existe ao menos um estado recorrente.

Suponha que i é recorrente e que i

ij > 0, e
portanto a probabilidade qij da cadeia chegar à j após passar por i é positiva. De fato
qij  

j. Isso signiﬁca que existe n tal que Pn

Pn
ij > 0.

!

Assim, podemos dizer que após n visitas ao estado i (n grande), em aproximada-

n destas visitas, a cadeia também visitou j, e portando o total de visitas à j

mente qij ·
é inﬁnita, e j é recorrente.

Mostramos assim o seguinte resultado.

Proposição 2.8. Em uma Cadeia de Markov, tanto recorrência quanto transiência são

propriedades de classe.

Juntando agora as Proposições 2.7 e 2.8, concluímos o seguinte.

Corolário 2.9. Toda cadeia irredutível com espaço de estados ﬁnito é recorrente.

A proposição 2.8 começa a simpliﬁcar bastante nossa busca por estados transientes e

recorrentes em uma cadeia, permitindo que analisemos apenas um elemento em cada

classe.

Para facilitar um pouco mais, considere agora uma cadeia de Markov qualquer, e

tome uma classe irredutível C
S. Suponha que exista nesta classe um estado j com
probabilidade qj > 0 da cadeia não mais retornar à classe C uma vez que passe por j.
Na representação gráﬁca, isso signiﬁcaria a existência de uma seta de j para fora da

⇢

classe C, sem nenhum outra de um estado externo para dentro de C.

Isso signiﬁca que j é transiente, pois 1

elemento em C são também transientes.

fj  

 

qj > 0, e pela Proposição 2.8 todo

58

2.4 C L A S S I F I C A N D O E S TA D O S D E U M A C A D E I A

Por outro lado, se não existir tal elemento em C, então ao iniciar a trajetória em C a

cadeia não deixará a classe, e pelos mesmos argumentos que levam à Proposição 2.7,

podemos aﬁrmar que existe um estado recorrente em C, e portanto todo estado em C

é recorrente.

Exemplo 2.11. Considere uma cadeia de Markov com matriz de transição dada por

P =

1
2
1
3
0 0

1
2
0 0
2
3
3
4

0 0
2
3
1
3
1
4

0 0

2

6
6
6
6
6
4

.

3

7
7
7
7
7
5

Podemos representar graﬁcamente esta cadeia da seguinte forma.

Antes de analisar a recorrência, vamos localizar as classes desta cadeia. Pela repre-

sentação gráﬁca, é fácil ver que 1

2 e 3

4. Também é fácil de ver que existe

apenas uma seta do conjunto

1, 2

para o conjunto

3, 4

, mas não o contrário. As-

{

}

{

}

sim, podemos concluir que elementos de

são acessíveis a partir de elementos de

$

$

3, 4

}

{

1, 2

}

{

, mas não o contrário. Portanto, as classes são

1, 2

e

3, 4

.

}

{

}

{

Observando a cadeia com cuidado vemos que existe uma probabilidade positiva

da cadeia ir de 2 para 4 e deixar a classe

transientes.

1, 2

}

{

. Segue daí que 1 e 2 são estados

Por outro lado, se a cadeia tiver início na classe

mostrando que os estados 3 e 4 são recorrentes.

3, 4

}

{

, ela permanecerá na classe,

A próxima propriedade que estudaremos está relacionado com a existência de algum

“padrão” na sequência de visitas que uma cadeia faz a um determinado estado.

59

C A D E I A S D E M A R K O V

Para tentar ilustrar a propriedade que buscamos, considere uma cadeia de Markov

cuja representação gráﬁca é dada abaixo.

Considere que a cadeia tem início no estado 3, e observe que para retornar à 3

existem, a princípio, duas possibilidades:

1. Seguir para 4 e imediatamente voltar para 3, o que tomaria 2 movimentos;

2. Ir para 4 (1 movimento), seguir para 1 (1 movimento), ﬁcar alternando entre 1 e

2, terminando em 1 (2k movimentos, ir de 1 para 2 e em seguida para 3 (mais 2

movimentos). Isso tomaria um total de 2k + 4 movimentos.

Concluímos assim que a cadeia precisa de um total par de passos para retornar ao

estado 3, e por esta razão diremos que 3 é periódico de período 2. Sendo um pouco
mais formal podemos aﬁrmar que Pn
33 > 0 apenas para n par, ou ainda que o maior
inteiro que divide todo n > 0 tal que Pn

33 > 0 é 2.

Generalizando esta ideia, temos a seguinte deﬁnição.

Deﬁnição 2.10. Dada uma cadeia de Markov com matriz de transição P e espaço de

estados S, deﬁnimos o período de i por

d(i) = mdc

n

{

 

0 : Pn

ii > 0

.

}

2 diremos que i é periódico com período d(i), e se d(i) = 1 diremos que i é

Se d(i)

 

aperiódico.

Se todos os estados da cadeia tiverem o mesmo período d diremos que a cadeia é

periódica, se d

 

2, ou aperiódica, se d = 1.

A relação de acessibilidade entre dois estados quaisquer da Cadeia também pode ser

objeto de considerações sobre a periodicidade desses estados. Dizendo de uma forma

60

2.5 C O N S I D E R A Ç Õ E S S O B R E A C O N V E R G Ê N C I A D E P n

mais direta, se dois estados i, j arbitrários são comunicáveis, que tipo de relação existe

entre os respectivos períodos?

Conduziremos essa discussão supondo que i
ij > 0 e Pm
Pk

ji > 0 . Pelas equações de Chapman-Komolgorov segue então

$

j. Assim, existem k, m tais que

P(k+m)
ii

Pk
ij ·

 

Pm
ji > 0,

e como o período do estado i é d(i) = mdc

n

{

 

0

|

Pn
ii > 0

}

, concluímos que d(i)

k + m.

|

Damos continuidade à análise tomando n > 0 tal que Pj jn > 0. Nos valemos nova-

mente de Chapman-Komolgorov para colocar que

Pk+n+m
ii

Pk
ij ·

Pn
jj ·

 

Pm
ji > 0,

trazendo-nos a conclusão que d(i)

k + m + n. Mas vimos que d(i)

k + m, e portanto

|

|

d(i)

n.

|
Em resumo, vimos que d(i) é divisor de todo elemento em

n

{

 

0 : Pn

jj > 0

, e

}

portanto d(i)

d(j).



Usando exatamente os mesmos argumentos, apenas invertendo os papéis de i e de

j, mostramos que d(j)



d(i), e concluímos ﬁnalmente que d(i) = d(j).

Acabamos de demonstrar que a periodicidade é uma propriedade de classe, ou seja,

entre estados comunicáveis os períodos se transmitem e são numericamente idênticos.

Nessa altura, é fundamental perceber que, se estivermos lidando com uma Cadeia de

Markov irredutível, então teremos então um único padrão de periodicidade que regerá

toda a Cadeia.

2.5 C O N S I D E R A Ç Õ E S S O B R E A C O N V E R G Ê N C I A D E P n

Nesta sessão vamos voltar ao problema que permeou todo este capítulo. Ou seja,
o comportamento de P n para n suﬁcientemente grande. Já vimos exemplos que nos
indicaram a possibilidade de P n convergir uma matriz P ⇤, com todas as linhas iguais.

Esta matriz-linha ou vetor, que chamamos de v, representa a chamada distribuição

de equilíbrio da cadeia, e representa a probabilidade da cadeia se encontrar em cada

estado do sistema depois de um total razoável de movimentos.

61

C A D E I A S D E M A R K O V

Mais claramente, se a cadeia tem estados S =

de equilíbrio tem forma

1, 2, 3 . . . , m

{

}

então a distribuição

v =

v 1

v 2

h

· · ·

v m

,

i

onde vj representa a probabilidade de equilíbrio do estado j, ou seja, independente
que estado a cadeia tenha início, a probabilidade dela estar em j se aproxima de vj
depois de um tempo suﬁcientemente grande. Matematicamente,

para qualquer i.

Pn
ij = P(Xn = j

X0 = i)

|

vj,

!

Outra interpretação, como já colocamos no início do capítulo, é ver estas entradas

como a proporção de tempo que a cadeia passa em cada estado ao longo de sua traje-

tória.

Nós já vimos como calcular a distribuição de equilíbrio, caso ela exista, mas ainda

não discutimos quando ela realmente existe.

Dessa maneira, queremos saber quais serão as condições que garantiriam essa con-
vergência de Pn. Vimos conceitos como: comunicabilidade entre estados, transiência e
recorrência, periodicidade, e tudo isso estará em jogo para decidirmos se uma Cadeia

de Markov convergirá.

2.5.1 Convergência, Recorrência e Irredutibilidade

Comecemos tratando da relação entre recorrência/transiência e o comportamento

de Pn.

Lembre-se que estamos estudando apenas cadeias com espaço de estados ﬁnito, e

portanto teremos sempre algum estado recorrente.

Suponha agora que i é um estado transiente de uma certa cadeia de Markov. Como

i é transiente, o total de visitas a ele durante a cadeia é certamente 0, e assim a

proporção de visitas à i durante a trajetória da cadeia deverá ser 0. Em outras palavras,
se i é transiente vi = 0.

Isso signiﬁca apenas que estados transientes não são importantes no estudo da con-

vergência de Pn, e portanto podemos considerar apenas cadeias recorrentes.

Considere inicialmente uma cadeia de Markov, com matriz P, e com mais de uma

classe irredutível de estados recorrentes.

62

2.5 C O N S I D E R A Ç Õ E S S O B R E A C O N V E R G Ê N C I A D E P n

Tome C1 e C2 duas classes distintas, e considere i

C2. Como ambas
as classes são recorrentes, sabemos que não existe comunicação entre estados destas

C1 e j

2

2

classes. Em particular, sabemos que i

j e j

6!

6!

i. Isso signiﬁca que

ji = Pn
Pn

ij = 0,

para todo n

0,

 

e deveríamos ter vi = vj = 0, o que claramente é um absurdo.

Isso mostra que para garantir a convergência de Pn nas condições que estamos bus-

cando, é importante que a cadeia tenha apenas uma classe de estados recorrentes.

Isso não signiﬁca que não exista um vetor de probabilidades que satisfaça vP = v,
ou mesmo que não ocorra a convergência de Pn para uma matriz com linhas distintas
uma das outras.

De fato, se i, j

ij > 0 para algum n > 0, de modo que Pn
ij
ainda pode se aproximar de algum valor, mas este valor agora dependeria tanto de i

C1, por exemplo, então Pn

2

quanto de j.

Vamos tentar esclarecer isso com um exemplo.

Exemplo 2.12. Considere uma cadeia de Markov com estados

transição

1, 2, 3, 4

}

{

e matriz de

1
1
2
2
2
1
3
3
0 0

0 0

2

6
6
6
6
6
4

0 0

0 0
3
1
4
4
2
1
3
3

3

.

7
7
7
7
7
5
3, 4

{

Fica claro que a cadeia tem classes

estados recorrentes.

1, 2

}

{

e

Calculando P2 encontramos

e que ambas são compostas de

}

5
12
7
18
0

0

7
12
11
18
0

0

0

0
5
16
11
36

0

0
11
16
25
36

2

6
6
6
6
6
4

.

3

7
7
7
7
7
5

Observe que os elementos de P2 que representam transição entre classes permanecem
0, como deveriam. O mesmo acontece nas demais potências de P.

63

C A D E I A S D E M A R K O V

O que vemos no exemplo anterior é que matrizes de transição não-irredutíveis po-

dem ser escritas em “blocos matriciais”, que representarão as distintas classes irredu-

tíveis da Cadeia. Assim, ao passo em que n cresce, os blocos continuarão presentes
na matriz Pn, e cada um desses conjuntos disjuntos poderá convergir para um vetor
distinto dos outros.

Para tentar entender um pouco mais sobre o problema, tentemos resolver o sistema

que levaria à distribuição de equilíbrio. Neste caso teríamos

1

2 x + 1
3 y
2 x + 2
3 y

1

x

+

y

+

= x

= y
3 w = z
3 w = w
= 1

1

3

4 z + 1
4 z + 2
+ w
z

,

8

>>>>>>><
>>>>>>>:

que é um sistema com inﬁnitas soluções. Para tentar encontrar algumas destas solu-

ções, vamos separar os equações por classes irredutíveis. Para isso, vamos separar a

equação x + y + z + w = 1 em x + y = l e z + w = 1

assim os sistemas

l, para algum l > 0, e encontrar

 

1

1

2 x + 1
3 y = x
2 x + 2
3 y = y
= l
+
y
x

8
>><
>>:
Resolvendo os sistemas acima, encontramos

8
>><
>>:

e

3 w =
3 w =

1

3

4 z + 1
4 z + 2
+ w
z

= 1

.

z

w

 

l

x y z w

=

2

5 l 3
5 l

4
13 (1

h

i

h
= l

2
5

h

3
5

0 0

i

l)

 
+ (1

9
13 (1

l)

 
0 0

l)

 

h

i

4
13

9
13

i

Com isso encontramos inﬁnitas “distribuições de equilíbrio” para a cadeia, em fun-

ção de dois vetores, cada um deles assumindo valores positivos para uma classe dife-

rente. Podemos ver tais vetores como as probabilidades de equilíbrio de cada classe.

Isso porque, iniciando dentro da classe

aproxima de 2/5 quando n cresce.

1, 2

}

{

, a probabilidade da cadeia estar em 1 se

Percebemos, concluindo essa análise, que é fundamental que a Cadeia seja recor-

rente e irredutível para que possamos tentar obter a convergência que desejamos.

64

2.5 C O N S I D E R A Ç Õ E S S O B R E A C O N V E R G Ê N C I A D E P n

2.5.2 Convergência e Aperiodicidade

Para entender como a periodicidade de elementos da cadeia pode inﬂuenciar no

comportamento das matrizes Pn, vamos primeiro analisar uma cadeia especíﬁca.

Considere então a cadeia de Markov (Xn)n

ção

0 com estados

 

0, 1

}

{

e matriz de transi-

P =

0 1

"

1 0#

.

Esta é uma cadeia periódica, de período 2, que consiste apenas da inversão ao longo

do tempo entre os estados 0 e 1.

Assim, se X0 = 0 teremos Xn = 1 nos instantes ímpares e Xn = 0 para n par. O

contrário acontece se X0 = 1.

Estamos buscando uma distribuição de equilíbrio, e isso é conseguido se resolvermos

a equação matricial

0 1

"

1 0#

x y

h

i

=

x y

,

h

i

com x + y = 1. Ou seja, queremos x, y com x = y e x + y = 1. Isso nos leva a x = y = 1/2.

Portanto, a periodicidade da cadeia não nos impediu de calcular o candidato à dis-
tribuição de equilibrio, mas isso ainda não garante que Pn converge para o vetor en-
contrado.

De fato, como os estados se alternam, garantimos que, por exemplo, Pn
X0 = 0) = 0 sempre que n for par, e do mesmo modo Pn

1
|
mostra que, neste exemplo ao menos, os valores de Pn
aproximar de nenhum valor.

0,1 = P(Xn =
0,1 = 1 para n impar. Isso
01 ﬁcam se alternando, sem se

Matricialmente, calculando Pn vemos facilmente que

para n par, e

para n ímpar.

Pn =

0 1

"

1 0#

Pn =

1 0

"

0 1#

Este simples exemplo já nos mostra que se quisermos que a matriz Pn se aproxime

de uma matriz P⇤ com linhas iguais, é necessário que a cadeia seja aperiódica.

65

C A D E I A S D E M A R K O V

2.6 O T E O R E M A E R G Ó D I C O

Nas duas últimas seções entendemos melhor o signiﬁcado das linhas da matriz de

transição de uma Cadeia de Markov, bem como conseguimos classiﬁcar seus estados,

chamando atenção especial para as características de recorrência/transiência e perio-

dicidade de um estado.

Conseguimos também entender a relação de tais propriedades com a possível con-
vergência de Pn. Para concluir este capítulo vamos apresentar um teorema central no
estudo de cadeias de Markov. Este é o teorema que cuida da convergência da sequência
Pn, dando condições suﬁcientes para que ela ocorra.

Infelizmente, a demonstração de tal resultado foge muito do escopo deste trabalho,

de modo que o enunciaremos sem provar.

Teorema 2.11 (Teorema Ergódico). Seja (Xn)n
irredutível e aperiódica, com matriz de transição P e espaço de estados S =

0 uma cadeia de Markov recorrente,
.

1, 2,

, m

 

{

· · ·

}

Nestas condições, para cada j

2

para qualquer estado inicial i

S.

2

0 tal que

S, existe vj  
Pn
ij !

vj,

Além disso, os valores vj,

j

equações

2

S formam a única solução não-negativa do sistema de

i=0 viPij,

vj = Âm
Âm

j=0 vj = 1

8
<

S

j

2

.

Por esta razão, cadeias recorrentes, irredutíveis e aperiódicas são chamadas de ca-

:

deias ergódicas.

Para ﬁnalizar o capítulo, estudemos um último exemplo.

Exemplo 2.13. Consideremos três hotéis à beira-mar, em uma das movimentadas

praias do nordeste brasileiro, que recebem milhares de turistas todo o ano. Os ho-

téis Areado (A), Bromélias (B) e Ceará (C), todos da mesma rede hoteleira, estão

dispostos em sequência ao longo da faixa de areia; devido à estreiteza dessa praia, é

impossível ir diretamente do hotel Areado ao hotel Ceará. As distâncias entre os ho-

66

2.6 O T E O R E M A E R G Ó D I C O

téis Areado e Bromélias e entre os hotéis Bromélias e Ceará são aproximadamente as

mesmas.

Alguns turistas gostam de ir trocando de hotel durante a estada nesta praia, outros

não. Qualquer que seja o hotel em que o turista esteja, seja de 50% a chance de ele per-

manecer nesse mesmo hotel no dia seguinte. Consideremos também que quem está no

Areado tem 50% de se dirigir ao Bromélias no dia seguinte; em contrapartida, quem

está no Bromélias tem apenas 25% de chance de optar pelo Areado no dia seguinte.

Além disso, os hóspedes do Bromélias tem 25% de chance de querer trocar de hospe-

dagem e se dirigirem ao Ceará no outro dia, enquanto 50% das pessoas que estão no

Ceará acabam indo para o Bromélias no dia subsequente.

Para poder controlar melhor os custos de cada hotel, a rede que os gerencia gostaria

de saber qual a proporção do total de hospedes da rede que se hospeda em cada hotel

ao longo de uma temporada agitada.

Para isso, vamos modelar o problema com uma matriz de transição de 3 estados

A, B e C, cuja matriz de transição será dada por

0, 5

0, 5

0

2

0, 25 0, 5 0, 25

3

.

6
6
4

0

0, 5

0, 5

7
7
5

Representando a cadeia graﬁcamente, encontramos

e ﬁca claro que a matriz é irredutível, e portanto recorrente. Para ver que é aperiódica,

basta notar que Pii > 0 para todo estado da cadeia.

67

C A D E I A S D E M A R K O V

Por ser uma cadeia irredutível, com estados todos recorrentes e aperiódicos, sua

distribuição de equilíbrio, denotada por v = (v1, v2, v3), pode ser obtida resolvendo o
sistema linear associado à cadeia. Assim temos

0, 5x + 0, 25y

= x

0, 5x + 0, 5y + 0, 5z = y

+ 0, 25y + 0, 5z = z

x

+

y

+

z

= 1

,

8

>>>>><
>>>>>:

o que nos dá x = 0, 25, y = 0, 5 e z = 0, 25.

Pelo teorema ergódico sabemos que Pn

vj para todo i, j, e assim podemos concluir
ij !
que na alta temporada a cada momento, o hotel Areado ﬁca com 25% dos hóspedes, o

hotel Bromélias com 50% e o hotel Ceará com os outros 25%.

68

3

C A D E I A S D E M A R K O V E O J O G O M O N O P O LY

3.1 U M P O U C O D E H I S T Ó R I A

O Monopoly é um jogo mundialmente conhecido, do qual existem múltiplas versões

nacionais; no Brasil, conhecemos este jogo pelo nome Banco Imobiliário. Nestas di-

versas versões mudam o nome das cidades e das propriedades a ser comercializadas,

mas a dinâmica do jogo permanece razoavelmente inalterada desde a primeira ver-

são conhecida. A primeira versão foi feita em uma toalha de mesa e desde o início o

passatempo dava ao jogador a possibilidade de comprar e vender terrenos em locais

valorizados.

Figura 8: Tabuleiro piloto original de 1934. Neste jogo cada uma das peças foi moldada em

madeira à mão, e o tabuleiro foi todo desenhado com caneta e tinta.

69

C A D E I A S D E M A R K O V E O J O G O monopoly

Em 1934 Charles B. Darrow, americano da Pensilvânia, mostrou o jogo aos execu-

tivos da Parker Brothers. Mas o jogo foi rejeitado por conter “52 erros especíﬁcos".

Darrow, desempregado naquela época de recessão, decidiu produzir o jogo sozinho.

Com a ajuda de um amigo, Darrow vendeu 5.000 unidades feitas à mão para lojas

de departamentos da Filadélﬁa, Boston e Nova York. As pessoas adoraram o jogo e

a demanda cresceu rapidamente, ao ponto que Darrow não podia mais supri-la. Mas

o sucesso instantâneo fez com que a Parker Brothers revisse sua posição e lançasse o

jogo em 1935.

Mas na verdade, ele não levou à Parker Brothers uma ideia original. Um jogo muito

parecido havia sido patenteado por Lizzie J. Magie em 1904, com o nome de The

Landlord’s Game. A diferença principal é que no jogo de Magie, o conceito básico era

o de mostrar como os monopólios são injustos e como as cobranças de aluguel por

grandes proprietários inescrupulosos podiam ser exorbitantes.

Por seu conteúdo pró-capitalismo, o jogo foi proibido na União Soviética até 1987.

70

3.2 R E G R A S E V E R S Õ E S

3.2 R E G R A S E V E R S Õ E S

A partir de 1935, numerosos Monopoly ﬂoresceram na Europa, marcando o início

de uma imensa difusão, que continua até nossos dias. Mais de 200 milhões de jogos

foram vendidos no mundo. O Monopoly permanece um dos jogos mais populares:

mais de 80 países têm a sua versão e o jogo existe já em mais de 30 línguas. Existem

igualmente versões sobre temas inesperados, em função das modas do momento ou

dos acontecimentos da atualidade.

No entanto, a dinâmica do jogo permanece a mesma nas versões comerciais espalha-

das pelo mundo. As regras podem ser resumidas da seguinte forma:

•

•

•

•

•

•

os jogadores (geralmente de 2 a 6) alternam turnos, nos quais rolam dois dados

que deﬁnirão quantas casas devem andar;

ao cair em uma casa que representa uma propriedade ou uma empresa, esta po-

derá ser comprada pelo jogador (caso ainda não tenha dono) ou então o jogador

deverá pagar um valor de aluguel ao dono da propriedade, sempre de acordo

com o valor atual daquela propriedade;

ao longo do jogo cada jogador pode desenvolver suas propriedades, construindo

casas e hoteis, aumentando assim o valor a ser cobrado de seus adversários;

algumas casas exigem que o jogador pague algo ao banco, como taxas;

uma casa no tabuleiro envia o jogador para a prisão, cujas regras para sair serão

resumidas mais adiante;

algumas casas dão ao jogador a chance de sortear cartas aleatórias que podem

ter diversos efeitos, como enviar para a prisão, ou mesmo dar uma chance do

jogador deixar a prisão quando entrar nela.

A ideia original do jogo é a mesma desde a sua aparição: um jogo de base aleató-

ria (pois cada jogada consiste no lançamento de dois dados idênticos), com peças se

deslocando através de casas no caminho de um tabuleiro cíclico, onde os jogadores

ganham dinheiro com suas propriedades e perdem dinheiro dependendo da casa em

que estão, e o vencedor sendo aquele jogador que permaneceu com dinheiro enquanto

todos os outros foram à falência. De acordo com as regras oﬁciais, “a idéia do jogo é

vender, comprar ou alugar propriedades de maneira vantajosa, de tal maneira que um

dos jogadores ﬁque mais rico e chegue ao monopólio’.

71

C A D E I A S D E M A R K O V E O J O G O monopoly

As inúmeras versões encontradas por todo o planeta diferem basicamente no tabu-

leiro; o nome das propriedades ofertadas em cada versão e obviamente a língua em que

estão escritas as nominações são distintas. Em todas as versões há notas de dinheiro-

fantasia (em exemplos mais modernos, há cartão de crédito), ícones representando

casas/hotéis (ou similares), dados e peões para movimentação dos jogadores.

(a) Versão Norte Americana

(b) Versão alternativa brasileira

Figura 9: Versões de Monopoly ao redor do mundo

(a) Versão Francesa

(b) Versão do Congo (cidade de Kinshasa)

Figura 10: Versões de Monopoly ao redor do mundo

Percebe-se no tabuleiro a mesma conﬁguração nestas e nas outras tantas versões ao

redor do mundo: são 40 casas no total, sendo

Uma casa para o início;

Uma casa de “Parada Livre”;

•

•

72

3.2 R E G R A S E V E R S Õ E S

•

•

•

Uma casa de “Prisão”;

Uma casa “Vá para a Prisão”;

Três ou seis casas do tipo “sorte ou revés”, que na versão original, em inglês, se

chamam “chance” ou “comunity chest”.

(a) Versão Japonesa

(b) Versão Iraquiana

Figura 11: Versões de Monopoly ao redor do mundo

(a) Versão Alemã (cidade de Baden-Baden)

(b) Versão Israelense

Figura 12: Versões de Monopoly ao redor do mundo

A P R I S Ã O

Esta é uma casa bastante importante para o jogo, e suas regras são alvo

de diversas alterações em versões alternativas.

73

C A D E I A S D E M A R K O V E O J O G O monopoly

No jogo oﬁcial um jogador pode ser enviado para a prisão de duas formas: sorteando

uma carta que o envie para lá, ou terminando seu movimento na casa “Vá para a

Prisão”. Quando em uma jogada regular o jogador termina seu movimento na casa

“Prisão” ela funcionará exatamente como a casa de “Parada Livre”.

Para sair da prisão existem algumas possibilidades:

Pagar uma quantia ﬁxa ($50 na versão original);

Usar uma carta “sair da prisão”;

Sortear uma dupla de números iguais nos dados. Situação na qual o jogador

deverá andar exatamente a quantidade sorteada;

Na terceira rodada após a prisão o jogador sai sem pagar nada;

•

•

•

•

Por ser um jogo essencialmente probabilístico, vem o natural questionamento sobre

a existência ou não de uma estratégia vencedora, bem como a dúvida sobre a ﬁnitude

do tempo de disputa de uma partida. Para responder parcialmente à questão sobre a

melhor estratégia utilizaremos as ferramentas desenvolvidas ao longo deste trabalho.

3.3 A M AT E M ÁT I C A D O J O G O

3.3.1 Uma visão geral

Queremos agora tentar modelar matematicamente o jogo de Monopoly, e para isso

vamos usar cadeias de Markov. A escolha de cadeias de Markov é natural, uma vez

que a cada jogada um jogador salta de uma casa para outra aleatoriamente, de acordo

com o resultado da rolagem de 2 dados.

Para simpliﬁcar as análises que faremos, vamos antes montar uma versão reduzida

do jogo, com regras similares, mas em tabuleiros menores.

Considerar uma versão do Monopoly como uma Cadeia de Markov implica construir

uma matriz de transição P que nos dê a probabilidade de, estando na casa i, ir para

a casa j imediatamente em um passo, na próxima jogada, independentemente das

jogadas anteriores. Nesse ponto, importa saber quais as características do tabuleiro

que vamos construir.

Como vimos nas várias versões do jogo ao redor do mundo, o tabuleiro de Monopoly

é sempre de formato quadrado, e o número total de casas do tabuleiro (C) dado por

74

3.3 A M AT E M ÁT I C A D O J O G O

Figura 13: Tabuleiros alternativos com k = 1, 2 e 3 respectivamente.

C = 4.k, k > 0 . Além disso, os quatro cantos do tabuleiro estão sempre deﬁnidos

na mesma ordem: um início na casa 1, uma casa de prisão (que funciona tanto como

visita livre para quem passa, como para saída para quem está preso) na casa k + 1, uma

casa de parada livre na casa 2k + 1, e “vá para a prisão” na casa 3k + 1. As demais casas

são as “propriedades’ que devem ser compradas e manipuladas ao longo da partida,

juntamente com casas de sorte ou revés.

Nessa perspectiva, ponderamos que:

•

•

•

Para obter uma dinâmica similar ao jogo real, nosso modelo deverá comportar o

jogo com dois dados, de modo que em uma única jogada não será possível dar

a volta completa no tabuleiro, garantindo a inexistência de loops espúrios que

atrapalhariam a análise do jogo. Descartamos então os valores de k = 1, 2 ou 3;

A prisão é uma casa complicada para a modelagem. Existem diversas regras

diferentes de como sair da prisão, diﬁcultando muito a modelagem. Em [17],

o autor considerou que a saída da prisão se daria em uma jogada, mediante

pagamento de uma multa. Neste caso a ida para a prisão é apenas um transporte

da casa 3k + 1 para a casa k + 1 , sem nenhum ônus adicional. Tornaremos nosso

modelo mais realístico, usando a regra que para a saída da prisão o jogador deve

tirar uma dupla de números iguais na rolagem dos dados, senão permanece na

prisão;

Para k = 4, 5 e 6 surgem problemas com a regra de saída da prisão: o joga-

dor está na prisão, tira uma dupla e portanto sai da prisão...e dependendo da

rolagem retorna à prisão imediatamente! Isso conﬁgura um “loop” que altera

demasiadamente a dinâmica do modelo e a similaridade com o jogo Monopoly.

O menor valor para o qual consegue-se resolver esse problema é para k = 7. De

75

C A D E I A S D E M A R K O V E O J O G O monopoly

todo modo, apresentaremos uma versão com k = 4 para esclarecer melhor estes

pontos;

•

O objetivo deste trabalho é analisar apenas a dinâmica probabilística do jogo.

Questões como casas de sorte-revés, preço das propriedades, colocação de ca-

sas/hotéis, salário recebido a cada rodada etc. não serão consideradas aqui.

3.3.2 Modelando o jogo

O ponto central desse trabalho é analisar o jogo Monopoly (e seus similares mais

simples) como sendo uma cadeia de Markov. Nos deteremos brevemente para entender

como isso pode ser feito.

a) Identiﬁcamos as casas do tabuleiro como estados de uma cadeia: Existem 4.k casas
(estados) no tabuleiro que compõem o jogo, k > 0. A cada jogada, uma e apenas

uma casa é alcançada. A interpretação fundamental que permite classiﬁcar o pro-

cesso como cadeia de Markov é que a casa que o jogador estará na jogada n + 1

depende exclusivamente da casa em que o jogador está no instante n. De fato, a

quantidades de casas a andar depende apenas do lançamento de dois dados, de

modo que a chance de ir para uma certa casa é completamente independente das

casas anteriormente visitadas, dependendo apenas da casa onde o jogador está.

b) Montamos a matriz de transição: Para isso, como explicamos anteriormente, nu-

meramos as casas de 1 a 4.k, fazendo 1 a casa de início e seguindo direção de mo-
vimento das peças. Para determinar a probabilidade Pij lembre-se que, de acordo
com a regra, estando em na casa i o jogador moverá sua peça para a casa i + s

sempre que a soma dos resultados da rolagem dos dados for igual à s. Assim temos
que P13 = 1/36 e P18 = 1/6, ao mesmo tempo que P12 = 0, assim como P1,1+j = 0
para todo j

13.

 

Como o tabuleiro é cíclico, devemos reiniciar a contagem quando passarmos da

casa 4k. Assim, a casa 4k + 5 será considerada como a casa 5. Para exempliﬁcar,

considere 4k = 40 e note que se o jogador está na casa 36 e rola 8 na soma dos
dados, ele cai então na casa 4, de modo que P36,4 = 1/6.

Para a casa k + 1, onde ﬁca a prisão, funciona exatamente como as demais. Isso

por que, de acordo com as regras, se o jogador apenas passar por esta casa com

uma rolagem de dados, ela funciona exatamente como as demais. Assim, as proba-

76

3.3 A M AT E M ÁT I C A D O J O G O

bilidades de transição a partir de k + 1 serão feitas normalmente, como nas demais

casas.

O jogador só vai “preso” de fato quando cai na casa 3k + 1, “vá para a prisão”. Uma

vez nesta casa, a regra diz que o jogador vai para a casa k + 1, onde ele ﬁcará preso

até algo acontecer (varia de regra para regra). O fato do jogador ﬁcar “preso” na

casa k + 1 não tem nenhum efeito prático, a não ser o fato de que a contagem de

para onde o jogador vai ao ser liberado é feita a partir desta casa. Podemos portanto

considerar que o jogador ﬁca parado nesta casa até conseguir sair, e quando isso

acontecer contamos as transições a partir da casa k + 1.

As transições da casa “vá para a prisão” dependem portanto de que regra usaremos

para sair, e explicaremos cada caso separadamente, quando ocorrer.

Montada a matriz de transição, queremos ter certeza que podemos seguir nossa aná-

lise sem problemas. Para considerar algo sobre a estratégia precisamos descobrir a

proporção de tempo que um jogador passa em cada casa ao longo do jogo, o que para

nós signiﬁca determinar se a cadeia que acabamos de montar é ou não ergódica. Preci-

samos então analisar duas características principais: irredutibilidade e aperiodicidade.

O J O G O É I R R E D U T Í V E L

Por simplicidade, desconsideremos momentaneamente

as casas “vá para a prisão” e “prisão”, localizadas em 3k + 1 e k + 1 respectivamente,

tratando-as como casas de passagem livre.

O jogo tem início sempre na casa 1, e saindo dela podemos ir para qualquer casa

entre 3 e 13 (lembrando que passando da casa 4k devemos reiniciar a contagem).
Como Pi,i+2 > 0 para todo i, então a partir de 1 podemos acessar qualquer outra casa
m para todo m ímpar. Em particular, temos que após alguns
ímpar. De modo que 1

passos podemos retornar à 1, fechando o ciclo, e mostrando que 1

m para todo m

$

ímpar.

Considere agora que o jogador se encontra na casa 4. A mesma análise que ﬁzemos

acima mostra que 4

m para toda casa m par. Já sabemos que 1

4, pois o jogador

pode tirar 3 na soma dos dados. Da mesma forma, temos que 4k

é par sabemos que 4

4k

2. Chapman-Kolmogorov nos garante agora que 4

 
ligando pares e impares, e garantindo a irredutibilidade.

!

!
2

 

!

1, e como 4k2
1

!

A análise acima só poderia ser atrapalhada pela casa “vá para a prisão”, cuja transi-

ção é feita de forma distinta.

77

!

$

C A D E I A S D E M A R K O V E O J O G O monopoly

Para incorporar esta casa ao jogo, considere primeiro que k é par, como no tabuleiro

oﬁcial. Neste caso, a casa “vá para a prisão” é impar, pois está na posição 3k + 1. Desta

forma, considerando apenas movimentos de dois passos, vemos facilmente que ela é

acessível a partir de qualquer casa i impar, e que podemos nos mover entre casas pares

sem passar pela casa 3k + 1.

É importante notar também que também é possível o jogador se mover entre duas

casas impares sem passar por 3k + 1. De fato, fazendo movimentos de dois passos o jo-

gador chegará primeiro chegar à casa 3k

1. Neste momento, fazendo um movimento

de 4 casas, ele vai diretamente para 3k + 3 sem passar por 3k + 1. Ilustramos isso na

 

ﬁgura 14.

Figura 14: Um ciclo fechado, passando por todas as casas ímpares, evitando a casa “Vá Para a

Prisão”, no tabuleiro k = 4.

Isso tudo mostra que é qualquer par de casas se comunicam (i

que não incluam 3k + 1.

j) por caminhos

$

Com isso, para mostrar que a cadeia é irredutível, nos resta apenas mostrar que

3k + 1

$

i para algum i

= 3k + 1.

Já vimos que se i é impar, então i

!

usada, ao sair da prisão o jogador seguirá para alguma casa j

= 3k + 1. Sabemos assim

3k + 1. Agora note que, independente da regra

78

6
6
que existe j tal que 3k + 1

!
1, concluindo que i

3k + 1

!

3.3 A M AT E M ÁT I C A D O J O G O

j, e como certamente j

3k + 1.

$

i sem voltar a 3k + 1, temos que

!

Concluímos assim que a cadeia é irredutível, e pelo Corolário 2.9 é também recor-

rente.

O J O G O É A P E R I Ó D I C O

A aperiodicidade, neste caso, é um problema bem mais

simples de ser abordado.

Já sabemos que a cadeia é irredutível, e como periodicidade é propriedade de classe,

só precisamos encontrar um sítio aperiódico e concluiremos a aperiodicidade de toda

a cadeia.

Supondo que k é impar, tome então o sítio 1 (se k for par, basta tomar o sítio 2 e

fazer a mesma análise). Já sabemos que fazendo apenas movimentos de comprimento

2, é possível voltar para a casa 1 sem passar pela casa 3k + 1.

O total de movimentos de tamanho 2 necessários para dar a volta em um tabuleiro

de 4k casas é exatamente 2k. Se apenas no primeiro movimento o jogador andar 4

casas, e depois seguir com movimentos de tamanho 2, ele demorará 2k

para retornar à 1.

1 movimentos

 

Mas mdc(2k

 

1, 2k) = 1 para todo k, e portanto o período d(1) = 1, e 1 é aperiódico.

Com isso concluímos que a cadeia é recorrente, irredutível e aperiódica, e portanto

ergódica. Podemos assim seguir normalmente a análise de proporção de visitas que

queremos fazer.

Na sequência, começaremos a analisar as características de tabuleiros menores, si-

milares ao jogo original, e que obedecem à lei de formação de tabuleiro C = 4k, k

como já explicado antes.

1 ,

 

O trabalho computacional que será visto nas próximas seções foi realizado com o au-

xílio do Software Excel 2013 operacional em uma máquina com processador IntelCore-

i5 a 2,6GHz.

79

C A D E I A S D E M A R K O V E O J O G O monopoly

3.3.3 Considerações para o caso k = 4

Tomemos por base o seguinte tabuleiro.

Considere agora as seguintes regras alternativas

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

4

16

Casa 2 - parada livre

Não existe prisão

Casa 1 - Início

Casa 3 - parada livre

Casa 4 - parada livre

Esse é o modelo mais simples que podemos exibir, no qual o jogo com dois dados é

possível sem existência de loops indesejados. A matriz de transição nesse caso será:

80

3.3 A M AT E M ÁT I C A D O J O G O

P =

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

2

6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36

1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18

1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12

1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9

1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36

5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6

1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36

5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9

1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12

1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18

1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36

1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

3

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5

Aqui obtemos uma convergência razoavelmente rápida: em 16 passos já consegui-

mos uma boa aproximação para o equilíbrio, que neste caso é dado por

v =

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

1
16

h

.

i

Esta uniformidade pode, a princípio, parecer estranha. Mas sem a prisão, o jogo

ganha uma grande simetria. De fato, sem a prisão, podemos começar o jogo em qual-

quer casa, e ele se comportará exatamente da mesma forma, apenas “rotacionado”!

Esta simetria se exprime pela uniformidade da distribuição no equilíbrio.

Mas este modelo está longe da realidade, então propomos uma alteração para deixa-

lo mais próximo do que queremos estudar. Tome então o seguinte conjunto de regras

especiais.

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

4

16

Casa 2 - parada livre Uma jogada após chegar na casa 13,

Casa 1 - Início

Casa 3 - parada livre

o jogador sai partir da casa 5.

Casa 4 - parada livre

81

C A D E I A S D E M A R K O V E O J O G O monopoly

Neste caso é introduzido uma casa de desequilíbrio da distribuição de probabilida-

des: a casa 13. A perturbação causada neste modelo será evidenciada, mesmo que a

prisão só se mantenha por uma jogada. Cair na prisão, neste modelo, é simplesmente

ser transportado de volta para a casa 5 na jogada seguinte. A matriz de transição será

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
0
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
0
1
12
1
18
1
36

1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
0
1
9
1
12
1
18

1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
0
5
36
1
9
1
12

1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
1
1
6
5
36
1
9

1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
0
5
36
1
6
5
36

5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
0
1
9
5
36
1
6

1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
0
1
12
1
9
5
36

5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
18
1
12
1
9

1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12

1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18

1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36

1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
0

0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
0
1
36
0

0

,

3

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5

P =

2

6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4

com distribuição de equilíbrio dada, aproximadamente, pelos valores abaixo.

Início

Casa 2

Casa 3

Casa 4

Prisão

Casa 6

Casa 7

Casa 8

0, 057

0, 054

0, 053

0, 051

0, 116

0, 053

0, 055

0, 057

Casa 9 Casa 10 Casa 11 Casa 12 V.P.P. Casa 14 Casa 15 Casa 16

0, 059

0, 062

0, 063

0, 065

0, 064

0, 063

0, 061

0, 059

É interessante notar que a prisão é a casa mais visitada do tabuleiro! Isso faz com

que as casas subsequentes, especialmente as que estão à distância 5, 6, 7, 8 e 9 da

prisão, sejam mais visitadas que as demais. Ao mesmo tempo, as casas mais distantes

da prisão são menos frequentes. Principalmente aquelas que não são atingidas em um

só passo, como as casas 2, 3, 4 e 6.

Isso acontece por conta da não uniformidade dos resultados no lançamento de dois

dados, como vemos no histograma da ﬁgura 15.

Esta é também a principal alteração na distribuição de equilíbrio causada pela pre-

sença da prisão, e estará presente em todas as análises que faremos a seguir.

82

3.3 A M AT E M ÁT I C A D O J O G O

Figura 15: Histograma mostrando a distribuição de probabilidade da soma de dois dados.

Analisemos agora um próximo modelo, um pouco mais próximo do modelo real,

com as seguintes regras.

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

4

16

Casa 2 - parada livre

Sai da prisão ao conseguir

Casa 1 - Início

Casa 3 - parada livre

rolar uma dupla de 1, 3 ou 5.

Casa 4 - parada livre

Aqui consideramos uma regra alternativa onde, para sair da cadeia o jogador deve

rolar uma dupla de 1, de 3 ou de 5 nos dados, andando o total indicado pelo dado. Isso

inclui no modelo uma alta probabilidade (11/12) do jogador permanecer na casa “vá

para a prisão”, antes de sair pela casa da prisão, movendo de acordo com o resultado

dos dados.

Observação 3.3.1. Alteramos a regra original neste caso, considerando apenas duplas

de números ímpares, pois uma dupla de 4’s levaria o jogador de volta para a casa 13.

83

C A D E I A S D E M A R K O V E O J O G O monopoly

A matriz de transição será então

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
0
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
0
1
12
1
18
1
36

1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
0
1
9
1
12
1
18

1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
0
5
36
1
9
1
12

1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
0
1
6
5
36
1
9

1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
0
5
36
1
6
5
36

5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
36
1
9
5
36
1
6

1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
0
1
12
1
9
5
36

5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
18
1
12
1
9

1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12

1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0
1
36
0
1
36
1
18

1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36

1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0
11
12
0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
0
1
36
0

0

,

3

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5

P =

2

6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4

com distribuição de equilíbrio dada, aproximadamente, pelos valores abaixo.

Início

Casa 2

Casa 3

Casa 4

Prisão

Casa 6

Casa 7

Casa 8

0, 036

0, 035

0, 034

0, 033

0, 034

0, 035

0, 047

0, 035

Casa 9 Casa 10 Casa 11 Casa 12 V.P.P. Casa 14 Casa 15 Casa 16

0, 035

0, 036

0, 048

0, 036

0, 437

0, 038

0, 049

0, 036

Vemos agora que a maior probabilidade pulou agora para a casa 13. Isso por que, do

modo como modelamos, após chegar à casa “vá para a prisão”, o jogador não chega a

ir para a casa prisão. Esta serve apenas como referência para determinarmos que casa

o jogador vai quando sair.

Assim, as casas mais prováveis depois da casa 13 são aquelas que estão à distância

2 (jogador rola dois 1’s), distância 6 (dois 3’s) ou distância 10 (dois 5’s), sempre

contando da casa 5 (prisão).

Mas perceba que neste modelo, cada jogador passa próximo a 43% do jogo na prisão,

o que está bastante longe da realidade. Temos então que alterar tal modelo de alguma

forma.

Pelas regras originais o jogador sai automaticamente da prisão após três jogadas, ou

pode sair antes mediante o pagamento de alguma quantia.

84

3.3 A M AT E M ÁT I C A D O J O G O

Para aproximar estas regras, vamos considerar que cada jogador sempre tenta rolar

o dado na primeira jogada preso, e se não conseguir sair ele paga para sair na segunda

rodada. Ou seja, na primeira rodada após a chegada na casa “vá para a prisão” o

jogador terá uma probabilidade 11/12 de ir a casa 5, de onde sairá na próxima jogada.

Com probabilidade 1/12 ele se moverá de acordo com o resultado do dado, como na

regra anterior.

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

4

16

Casa 2 - parada livre

ou sair automaticamente

Casa 1 - Início

rolar uma dupla de 1, 3 ou 5

Casa 3 - parada livre

na jogada seguinte

Casa 4 - parada livre

Isso nos leva à seguinte matriz de transição.

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
0
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
0
1
12
1
18
1
36

1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
0
1
9
1
12
1
18

1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
0
5
36
1
9
1
12

1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
1
9
11
12
1
6
5
36
1
9

1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12
0
5
36
1
6
5
36

5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
36
1
9
5
36
1
6

1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
0
1
12
1
9
5
36

5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
18
1
12
1
9

1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36
1
18
1
12

1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0
1
36
0
1
36
1
18

1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0
1
36

1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
1
18
1
36
0

0

0

0

0

0
1
36
1
18
1
12
1
9
5
36
1
6
5
36
1
9
1
12
0
1
36
0

0

,

3

7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5

P =

2

6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4

com distribuição de equilíbrio dada, aproximadamente, pelos valores abaixo.

Início

Casa 2

Casa 3

Casa 4

Prisão

Casa 6

Casa 7

Casa 8

0, 057

0, 055

0, 054

0, 052

0, 112

0, 054

0, 058

0, 058

Casa 9 Casa 10 Casa 11 Casa 12 V.P.P. Casa 14 Casa 15 Casa 16

0, 060

0, 062

0, 065

0, 065

0, 064

0, 063

0, 063

0, 059

85

C A D E I A S D E M A R K O V E O J O G O monopoly

Observe que a prisão é novamente a mais visitada, mas agora apenas 11% do tempo

de jogo. Novamente, as casas mais visitadas são as casas de 10 à 14, com uma pequena

inﬂuência (quase imperceptível) da probabilidade de sair com a rolagem de dois dados

iguais.

Este é o modelo mais próximo do original que encontramos, e portanto vamos ﬁcar

com ele. A única coisa ainda problemática é o fato de que ao sair da casa 5, podemos

voltar à casa 13 (vá para a prisão) imediatamente. Mas isso ocorre devido ao tamanho

do tabuleiro.

Antes de passar para a análise do jogo original, façamos um tabuleiro com k = 7.

3.3.4 Considerações para o caso k = 7

Seguindo a análise para k = 7, o tabuleiro será agora da seguinte forma.

Aqui a “prisão” está na casa 8, enquanto a casa “vá para a prisão” está na posição

22.

Como já apontado, este é o primeiro valor de k para o qual o tamanho do tabuleiro

não traz problemas à anállise do jogo, como proposto em Monopoly. Fazemos, por-

tanto, diretamente a análise do modelo mais ﬁel ao desenrolar do jogo clássico. Ou

86

3.3 A M AT E M ÁT I C A D O J O G O

seja, na jogada seguinte à chegada na casa 22, o jogador deve rolar um dado. Ao tirar

qualquer dupla de resultados iguais ele sai para a casa indicada, contando a partir da

casa 8. Caso contrário ele segue para a casa 8, de onde sairá normalmente na jogada

seguinte.

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

7

28

Casa 8 - prisão

ou sair automaticamente

Casa 1 - Início

rolar dupla de valores iguais

Casa 15 - parada livre

na jogada seguinte

Casa 22 - vá para a prisão

A matriz de transição neste caso tem dimensão 28

28 e portanto sua representação

aqui é muito complicada. De todo modo, as linhas se comportam muito similarmente

⇥

às do caso k = 4, mudando apenas a linha relativa à casa 22 (vá para a prisão), que

apresentamos abaixo.

1

2

3

22

0 0 0

h

7

0

8

5
6

9

0

···

· · ·

10

11

12

13

14

15

16

17

18

19

1
6

0

1
6

0

1
6

0

1
6

0

1
6

0

28

0

···

· · ·

i

A distribuição de equilíbrio da cadeia é dada, aproximadamente, pelos valores da

tabela abaixo.

3, 04% 3, 11% 3, 15% 3, 18% 3, 20% 3, 23% 3, 27% 6, 29%

3, 18%

3, 31%

3, 43%

3, 54%

3, 64%

3, 73%

3, 19%

3, 36%

3, 35%

3, 55%

3, 55%

3, 77%

3, 70% 3, 65% 3, 77% 3, 68% 3, 80% 3, 71% 3, 84% 3, 78%

Tabela 1: Distribuição de equilíbrio para tabuleiro com k = 7. Os valores estão dispostos de
acordo com a posição correspondente no tabuleiro, a casa mais frequente (6,29%) corresponde

à prisão.

Notamos algumas coisas interessantes. A primeira é que à medida que aumenta o

tabuleiro, as porcentagens vão diminuindo, como que se “diluindo” no conjunto total

87

C A D E I A S D E M A R K O V E O J O G O monopoly

de estados, e vemos que as diferenças são pequenas para um tempo de jogo muito

curto (por exemplo, 0,8% é a diferença entre a casa mais visitada e a casa menos

visitada, excetuando obviamente a prisão, que continua a ser a casa mais visitada).

A segunda coisa é que padrão semelhante ao do caso k = 4 continua acontecendo.

Ou seja, as casas seguintes à do prisão são as mais visitadas (excetuando-se a prisão).

Aqui, no entanto, não são apenas as probabilidades das somas dos dados que deter-

minam as casas mais prováveis. Parece existir uma contribuição da probabilidade de

saída rolando duplas. Observe que as casas 6, 8, 10 e 12 são as mais prováveis após a

prisão.

3.4 O monopoly E S E U TA B U L E I R O C L Á S S I C O

Para os tabuleiros anteriores, versões simpliﬁcadas do jogo, observamos que:

•

•

•

Se não existe a casa “Prisão”, o jogo tem uma distribuição simétrica;

Existindo a casa “Prisão” nota-se que é introduzido um desequilíbrio no jogo, de

forma que passam a existir casas que serão mais visitadas ao longo do tempo e

casas que serão menos visitadas. A casa “Prisão” aparece como a mais visitada

nos dois tabuleiros analisados;

As casas com maior probabilidade de visita são as que seguem a casa da “Prisão”,

em especial as casas que estão à distância 6, 8, 10 e 12 da prisão.

A análise no tabuleiro oﬁcial se dará da mesma forma. Utilizaremos as mesmas

regras de saída da prisão do caso k = 7 para aproximar as regras originais.

Valor de k Total de Casas

Casas Especiais

Regra para Saída de Prisão

10

40

Casa 8 - prisão

ou sair automaticamente

Casa 1 - Início

rolar dupla de valores iguais

Casa 21 - parada livre

na jogada seguinte

Casa 31 - vá para a prisão

88

3.4 O monopoly E S E U TA B U L E I R O C L Á S S I C O

Aqui a matriz de transição tem dimensão 40

40, e assim como no tabuleiro anterior,

apresentaremos a única linha que se comporta de forma distinta, que neste caso é a

⇥

linha 31.

1

2

3

31

0 0 0

h

···

· · ·

10

11

12

13

14

15

16

17

18

19

20

21

22

0

5
6

0

1
6

0

1
6

0

1
6

0

1
6

0

1
6

0

40

0

···

· · ·

i

A distribuição de equilíbrio está representada na tabela abaixo, também represen-

tando a disposição de casas da tabuleiro original.

2, 24 2, 26 2, 28 2, 30 2, 27 2, 25 2, 24 2, 24 2, 25 2, 26 4, 45

2, 22

2, 19

2, 15

2, 25

2, 33

2, 48

2, 41

2, 56

2, 63

2, 26

2, 40

2, 38

2, 52

2, 51

2, 66

2, 67

2, 72

2, 63

2, 63 2, 64 2, 64 2, 65 2, 64 2, 63 2, 61 2, 58 2, 67 2, 61 2, 69

Tabela 2: Distribuição de equilíbrio para tabuleiro oﬁcial. Os valores estão dispostos de acordo

com a posição correspondente no tabuleiro e em percentagem, a casa mais frequente (4,45%)

corresponde à prisão. A casa superior à esquerda marca o início.

Apresentamos também um histograma comparando as diversas probabilidades na

ﬁgura.

É interessante observar que os padrões apresentados no tabuleiro k = 7 se repetem,

mas agora os valores são mais próximos uns dos outros. A casa mais visitada após a

prisão é a 19 (8 casas após a prisão), com 2,72% de probabilidade, enquanto a menos

visitada é a 38, com 2,15%. A diferença entre as duas é de apenas 0,57%.

As casas que se encontram à distância 6, 8, 10 e 12 depois da prisão, continuam den-

tre as mais visitadas, assim como no caso anterior, enquanto as casas menos visitadas

ainda estão concentradas próximas do início.

89

C A D E I A S D E M A R K O V E O J O G O monopoly

Distribuição de probabilidades - Tabuleiro k=10 

l

o
r
i
e
u
b
a
t
o
n
a
s
a
c
a
d
o
r
e
m
ú
N

39	

37	

35	

33	

31	

29	

27	

25	

23	

21	

19	

17	

15	

13	

11	

9	

7	

5	

3	

1	

0,00%	

1,00%	
Porcentagem	média	de	visitas	à	casa	

3,00%	

2,00%	

4,00%	

5,00%	

Figura 16: Histograma os as probabilidades de equilíbrio no tabuleiro oﬁcial.

3.4.1 Breve Análise Estratégica

Os dados calculados acima dizem muito pouco sobre uma possível estratégia de jogo.

Lembre-se que a maneira de ganhar dinheiro (e o jogo) é comprar terrenos e cobrar

aluguel daqueles que parem no mesmo espaço. A primeira vista, a distribuição de

equilíbrio parece indicar que a melhor estratégia é concentrar negócios entre as casas

17 e 30, especialmente nas casas 17, 18, 19, 21 e 23. Assim o jogador recolheria

aluguel com mais frequência, aumentando a chance de ganhar o jogo.

90

	
	
	
	
	
	
3.4 O monopoly E S E U TA B U L E I R O C L Á S S I C O

No entanto existem diversas outros fatores que devem ser levados em considera-

ção, e a pequena diferença entre as probabilidades de cada casa podem arruinar esta

primeira análise.

Dentre os fatores mais importante, e fácil de ser incorporado em nossa análise, está

a preço da propriedade. O valor em dinheiro marcado em cada casa deﬁne não apenas

o custo de compra daquele terreno, mas também o preço do aluguel que será cobrado

de quem parar ali.

Assim, denotando por v1 a probabilidade de equilíbrio da casa i, e por Mi o valor da
Mi para as diferentes casas são mais importantes para a

propriedade, os valores de vi ·
deﬁnição de estratégia que apenas os valores de vi.

Considere então os valores de propriedades abaixo, como encontrados no tabuleiro

oﬁcial de Monopoly.

0

60

0

60

200 200 100

0

100 120

0

400

0

350

0

200

320

0

300

300

140

150

140

160

200

180

0

180

200

0

280 150 260 260 200 240 220

0

220

0

Tabela 3: Valores das propriedades no tabuleiro oﬁcial. Deixamos marcadas as casas mais

frequentes.

De cara notamos que 3 das casas mais frequentes não tem valor, enquanto as demais

tem valor baixo se comparados com os das casas seguintes. Precisamos saber agora se

a maior probabilidade destas casas compensa o seu baixo valor, e isso calculamos na

próxima tabela.

Vemos agora que as casas que melhor pagam se concentrar no ﬁnal do tabuleiro,

logo antes da casa de início, justamente onde estavam as casas de menor frequência

de visita.

91

C A D E I A S D E M A R K O V E O J O G O monopoly

0

1, 36

0

1, 38 4, 53 4, 50 2, 24

0

2, 25 2, 71

0

8, 88

0, 00

7, 53

0

4, 66

7, 95

0

7, 67

7, 88

3, 17

3, 59

3, 33

4, 03

5, 02

4, 79

0

4, 89

5, 25

0

7, 38 3, 96 6, 88 6, 87 5, 27 6, 27 5, 67

0

5, 73

0

Tabela 4: Valores das propriedades no tabuleiro oﬁcial pesados pela frequência de visita.

Isso ainda não garante que a melhor estratégia seria comprar as casas ﬁnais. O

jogo possui outros elementos importantes, como o desenvolvimento de propriedades

que aumenta o valor do aluguel, e pode compensar esta diferença. Além disso as

propriedades no tabuleiro são divididas em tipos, e possuir várias propriedades de um

mesmo tipo pode aumentar o valor cobrado dos demais jogadores.

Ainda que não consigamos estabelecer uma estratégia clara para vencer o jogo, con-

seguimos fazer uma análise inicial importante, que nos mune de informações preciosas

na hora de decidir como queremos jogar.

92

B I B L I O G R A F I A

[1] Monopoly Wiki. Fandom, 2016. http://monopoly.wikia.com/wiki/Main_Page.

[2] Almeida Nogueira, F. M. de: Modelagem e Simulação: Cadeias de Markov. Notas

de aula da Disciplina EPD-042-Pesquisa Operacional II, UFJF, 2015.

[3] Bennett, D. J.: Aleatoriedade. Martins Fontes, São Paulo, 2003.

[4] Calabria, A. R. e M. F. Cavalari: Coleção História da Matemática para Professores.

Em Um passeio histórico pelo início da Teoria das Probabilidades. Sociedade Brasi-

leira de História da Matemática, Campinas, 2013.

[5] Dimuro, G. P., R. H. S. Reiser, A. C. R. Costa e P. L. R. Sousa: Modelos de Markov e

Aplicações (tutorial). Em Educat (ed.): VI Oﬁcina de Inteligência Artiﬁcial, Univer-

sidade Católica de Pelotas, pp. 37–59, Pelotas, 2002.

[6] Eves, H.: Introdução à História da Matemática. Editora da Unicamp, 3a ed., 2002.

[7] Gadelha, A.: Uma Pequena História da Probabiidade. Notas de aula da disciplina

Teoria de Probabilidade I, Curso de Pós-Graduação em Estatística, UFRJ, 2004.

[8] Gray, J. R.: Probability. Oliver & Boyd, 1a ed., 1967.

[9] Hinojosa, A. e A. Milanés: Uma Introdução aos Processos Estocásticos com Aplica-

ções. UFMG-Dep. de Estatística, 2011.

[10] Hoel, P. G., S. C. Port e C. J. Stone: Introdução à Teoria da Probabilidade. Editora

Interciência, 4a ed., 1978.

[11] Júnior, D. P. F. e V. V. Júnior: Conceitos e Simulação de Cadeias de Markov. XIX

Seminário de Iniciação Cientíﬁca da UFG – PIVIC, 2011.

[12] Junqueira, A. L. N.: A probabilidade que a história nos conta. XIV Conferência

Interamericana de Educação Matemática, México, 2015.

[13] Lass, H. e P. Gottlieb: Probability and Statistics. Addison-Wesley, 1a ed., 1971.

[14] Lipschutz, S.: Matemática Finita. Editora McGraw-Hill do Brasil, 1a ed., 1972.

[15] Lipschutz, S.: Probabilidade. Editora McGraw-Hill do Brasil, 2a ed., 1978.

93

BIBLIOGRAFIA

[16] Lopes, C. E. e E. Meirelles: O Desenvolvimento da Probabilidade e da Estatística.

XVIII Encontro Regional de Professores de Matemática, LEM/IMECC/UNICAMP,

2005.

[17] Marino, R.: Banco Imobiliário - Post do Blog Todas as Conﬁgurações Possíveis. http:

//www.todasasconfiguracoes.com/2012/10/19/banco-imobiliario/.

[18] Ross, S. M.: Introduction to Probability Models. Probability and Statistics. Acade-

mic Press, 2007, ISBN 9780123736352.

[19] Ross, S. M.: Probabilidade: Um Curso Moderno com Aplicações. Bookman, Porto

Alegre, 8a ed., 2010, ISBN 9788577806881.

[20] Santos, T. A. R. dos: A Matemática por trás do Google. Tese de Mestrado, Profmat,

CMCC-UFABC, 2014.

[21] Silva, C. B. da e C. de Queiroz e Silva Coutinho: O nascimento da Estatística e sua

relação com o surgimento da Teoria de Probabilidade. Integração, (41):191–196,

2005.

[22] Viali, L.: Algumas Considerações sobre a Origem da Teoria da Probabilidade. Revista

Brasileira de História da Matemática, 8(16):143–153, 2008.

94


PAULO ROBERTO CONSTANTINO JUNIOR

INFERÊNCIA NO ENSINO MÉDIO:

UMA INTRODUÇÃO AOS TESTES DE HIPÓTESE

Santo André, 2016

UNIVERSIDADE FEDERAL DO ABC

CENTRO DE MATEMÁTICA, COMPUTAÇÃO E COGNIÇÃO

PAULO ROBERTO CONSTANTINO JUNIOR

INFERÊNCIA NO ENSINO MÉDIO:

UMA INTRODUÇÃO AOS TESTES DE HIPÓTESE

Orientador: Prof. Dr. André Ricardo Oliveira da Fonseca

Dissertação de mestrado apresentada ao Centro de

Matemática, Computação e Cognição para

obtenção do título de Mestre

ESTE EXEMPLAR CORRESPONDE À VERSÃO FINAL DA DISSERTAÇÃO

DEFENDIDA PELO ALUNO PAULO ROBERTO CONSTANTINO JUNIOR,

E ORIENTADA PELO PROF. DR. ANDRÉ RICARDO OLIVEIRA DA FONSECA.

SANTO ANDRÉ, 2016

Sistema de Bibliotecas da Universidade Federal do ABCElaborada pelo Sistema de Geração de Ficha Catalográfica da UFABCcom os dados fornecidos pelo(a) autor(a).Constantino Junior, Paulo Roberto     Inferência no Ensino Médio : uma introdução aos testes de hipótese /Paulo Roberto Constantino Junior. — 2016.     114 fls. : il.     Orientador: Prof. Dr. André Ricardo Oliveira da Fonseca     Dissertação (Mestrado) — Universidade Federal do ABC, MestradoProfissional em Matemática em Rede Nacional - PROFMAT, SantoAndré, 2016.     1. curva normal. 2. Inferência estatística. 3. probabilidade. I. Oliveirada Fonseca, Prof. Dr. André Ricardo. II. Mestrado Profissional emMatemática em Rede Nacional - PROFMAT, 2016. III. Título.    Dedico este trabalho ao meu ﬁlho Murilo.

vii

A G R A D E C I M E N T O S

Agradeço em primeiro lugar a minha mãe. Ela sempre esteve ao meu lado em todos

os momentos, me inspirando e apoiando. Foi sempre meu maior exemplo de vida.

Agradeço por toda a compreensão, por entender as ausências que muitas vezes de

ﬁzeram necessárias.

A minha querida esposa Áurea, pelo apoio, compreensão, pelos sonhos compartilha-

dos. Por entender que nem sempre podia estar presente em certos momentos.

Ao meu ﬁlho Murilo e a Brenda, minha ﬁlha do coração, por estarem sempre ao meu

lado, apoiando esse processo de construção desse projeto de vida.

Ao meu pai que, apesar da distância esteve sempre presente em pensamentos.

Aos meus irmãos Daniela e Carlos por sempre me apoiarem, estarem dispostos a

ajudar no que fosse preciso e entender os momentos em que tive que me fazer ausente

para estudar e me dedicar a esse sonho.

Aos meus familiares e amigos, agradeço por todo apoio. Em especial a minha prima

Débora, pelo auxílio nas traduções.

Aos colegas da Turma do PROFMAT, em especial ao meu amigo Rodolfo, pela com-

preensão, por compartilhar os momentos de diﬁculdade, as alegrias com os sucessos

obtidos, a ajuda mútua, as caronas, os momentos compartilhados de estudo, meu

muito obrigado.

A Direção, Coordenação, corpo Docente e funcionários da E. E. Professora Therezi-

nha Closa Eleutério, em especial aos alunos do 3o ano A.

A Professora Sueli pela revisão ortográﬁca, e a Professora Elaine que gentilmente

me cedeu alguns horários de aula para realização das atividades.

A UFABC, por ter me dado a oportunidade de crescimento proﬁssional e aberto as

portas de sua instituição para concretização e realização desse sonho.

Ao corpo Docente da UFABC pelas aulas ministradas, que me permitiram uma evo-

lução pessoal e proﬁssional.

ix

Ao meu orientador Professor Doutor André Ricardo Oliveira da Fonseca, que sempre

me orientou de forma positiva, com muita disposição e presteza nos retornos do meu

Projeto.

Aos Professores da Banca Examinadora pelas críticas construtivas que me enriquece-

ram pessoal e proﬁssionalmente para a conclusão deste Projeto.

A CAPES pelo apoio ﬁnanceiro, sem o qual não seria possível a dedicação e conclusão

deste trabalho.

x

“Quando você elimina o impossível, o que sobra por mais

incrível que pareça só pode ser a verdade.”

(Sir Arthur Conan Doyle)

xi

R E S U M O

No mundo contemporâneo é comum constantes pesquisas em diversos âmbitos,

tanto sociais, quanto econômicos, entre outros. Para tais pesquisas é fundamental

a coleta de dados, organizar os dados, como também construir tabelas e gráﬁcos es-

tatísticos, entretanto é inadmissível não haver uma interpretação consistente sobre os

resultados. Desta forma, o objetivo deste trabalho é introduzir os alunos do Ensino

Médio, especiﬁcamente os do terceiro ano, na teoria da inferência estatística, por meio

de atividades experimentais, para que eles possam, num nível elementar, desenvolver

as primeiras compreensões a respeito dos meios de obtenção de uma amostra e das

conclusões possíveis sobre a respectiva população. Assim, estimulando os educandos

em buscar constantemente informações sobre pesquisas estatísticas, as quais estarão

presentes em vários momentos da sua vida em sociedade.

Palavras-chave: curva normal, inferência estatística, probabilidade.

xiii

A B S T R A C T

In the contemporary world it is common to come across frequent research from vari-

ous scopes, both social and economical amongst others. For such research, it is vital to

collect data, organize it as well as put together statistical charts and graphs. However

it is unacceptable that there is no consistent interpretation about the results. There-

fore, the objective of this work is to introduce High School students, more speciﬁcally

the seniors, to the theory of statistical inference, through experimental activities, so

that they can, at an elementary level, develop their primary understanding of both

the means to obtain a sample and the possible conclusions drawn about its respective

population. Thus, we expect to stimulate the students to constantly seek information

about statistical research, which will be present in many different moments in their

lives as part of society.

Keywords: normal curve, statistical inference, probability.

xv

C O N T E Ú D O

I N T R O D U Ç Ã O

1 F U N D A M E N TA Ç Ã O T E Ó R I C A

1.1 Síntese Histórica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Estatística Descritiva . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2.1 Variáveis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2.2 Medidas de Posição . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2.3 Medidas de Dispersão . . . . . . . . . . . . . . . . . . . . . . . .

1.3 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.3.1 Espaço amostral e evento . . . . . . . . . . . . . . . . . . . . . .

1.3.2 Deﬁnição e algumas probabilidades importantes . . . . . . . . . .

1

3

3

6

6

7

7

8

8

9

1.3.3 Contagem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

1.3.4 Tipos de Probabilidades . . . . . . . . . . . . . . . . . . . . . . . 11

1.3.5 Probabilidade condicional e independência . . . . . . . . . . . . 11

1.4 Variáveis Aleatórias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

1.4.1 Função de distribuição acumulada . . . . . . . . . . . . . . . . . 13

1.4.2 Função de probabilidade ou densidade de probabilidade . . . . . 15

1.4.3 Valor esperado . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

1.4.4 Momentos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

1.4.5 Variância e desvio padrão . . . . . . . . . . . . . . . . . . . . . . 16

1.5 Distribuições de probabilidade discretas

. . . . . . . . . . . . . . . . . . 18

1.5.1 Distribuição uniforme discreta . . . . . . . . . . . . . . . . . . . . 18

1.5.2 Distribuição binomial

. . . . . . . . . . . . . . . . . . . . . . . . 20

1.5.3 Distribuição de Poisson . . . . . . . . . . . . . . . . . . . . . . . . 23

1.6 Distribuições de probabilidade contínuas . . . . . . . . . . . . . . . . . . 25

1.6.1 Distribuição uniforme . . . . . . . . . . . . . . . . . . . . . . . . 25

1.6.2 Distribuição normal

. . . . . . . . . . . . . . . . . . . . . . . . . 26

1.6.3 Distribuição exponencial . . . . . . . . . . . . . . . . . . . . . . . 30

1.6.4 Distribuição gama . . . . . . . . . . . . . . . . . . . . . . . . . . 31

1.7 Variáveis aleatórias múltiplas

. . . . . . . . . . . . . . . . . . . . . . . . 33

xvii

Conteúdo

1.7.1 Distribuições condicionais e independência . . . . . . . . . . . . 34

1.7.2 Covariância e correlação . . . . . . . . . . . . . . . . . . . . . . . 36

1.8 Funções geratrizes de momentos

. . . . . . . . . . . . . . . . . . . . . . 38

2 I N F E R Ê N C I A E S TAT Í S T I C A

43

2.1 Conceitos iniciais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

2.1.1 População e amostra . . . . . . . . . . . . . . . . . . . . . . . . . 43

2.1.2 Amostras aleatórias simples . . . . . . . . . . . . . . . . . . . . . 43

2.1.3 Diferenciando estatística de parâmetro . . . . . . . . . . . . . . . 44

2.2 Distribuições amostrais . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

2.2.1 Distribuição amostral da média . . . . . . . . . . . . . . . . . . . 45

2.2.2 Distribuição normal da média . . . . . . . . . . . . . . . . . . . . 47

2.2.3 Teorema do Limite Central . . . . . . . . . . . . . . . . . . . . . . 48

2.2.4 Aproximação normal para a distribuição binomial . . . . . . . . . 50

2.2.5 Distribuição amostral de uma proporção . . . . . . . . . . . . . . 52

2.2.6 Distribuição da variância da amostral . . . . . . . . . . . . . . . . 53

2.3 Estimadores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

2.3.1 Estimadores de Momentos . . . . . . . . . . . . . . . . . . . . . . 54

2.3.2 Estimadores de máxima verossimilhança . . . . . . . . . . . . . . 55

2.3.3 Erro quadrático médio . . . . . . . . . . . . . . . . . . . . . . . . 56

2.4 Intervalos de conﬁança . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

2.4.1 Intervalo de conﬁança para a média, com variância conhecida . . 59

2.4.2 Intervalo de conﬁança para a média, com variância desconhecida 61

2.4.3 Intervalo de conﬁança para a variância e o desvio padrão . . . . 63

2.4.4 Intervalo de conﬁança para uma proporção . . . . . . . . . . . . 64

2.5 Testes de hipótese

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

2.5.1 Teste de hipótese para a média com variância conhecida . . . . . 68

2.5.2 Teste de hipótese para a média com variância desconhecida . . . 69

2.5.3 Teste de hipótese para a variância . . . . . . . . . . . . . . . . . . 70

2.5.4 Teste de hipótese para uma proporção . . . . . . . . . . . . . . . 71

3 P R O P O S TA D E AT I V I D A D E S

73

3.1 Atividade 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

3.2 Atividade 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75

3.3 Atividade 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

3.4 Atividade 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77

xviii

4 A P L I C A Ç Ã O D A S AT I V I D A D E S

Conteúdo

79

4.1 Aplicação da Atividade 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

4.2 Aplicação da Atividade 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

4.3 Aplicação da Atividade 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 96

4.4 Aplicação da Atividade 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

5 C O N S I D E R A Ç Õ E S F I N A I S

A

TA B E L A S

B

R E C U R S O S A U X I L I A R E S

Bibliograﬁa

105

107

111

113

xix

I N T R O D U Ç Ã O

A estatística está cada vez mais presente em nosso cotidiano através dos meios de

comunicação em massa, nas indústrias e no comércio. Na escola diferentes disciplinas

utilizam gráﬁcos e tabelas de dados estatísticos, além da própria matemática. A geogra-

ﬁa faz uso da estatística nos estudos comparativos de dados populacionais, a biologia

na análise dados coletados, a história e a sociologia no tratamento da informação.

O presente trabalho justiﬁca-se pela crescente necessidade de produtos com quali-

dade em um mercado atual e dinâmico, como também maior agilidade na entrega do

produto ﬁnal ao consumidor, que cada vez está mais exigente.

Assim, dentre vários objetivos da educação básica no Brasil, sem dúvida o de prepa-

rar os jovens para este mercado atual é imprescindível.

O objetivo deste trabalho é introduzir os alunos do Ensino Médio, especiﬁcamente

os do terceiro ano, na teoria da inferência estatística, por meio de atividades experi-

mentais, para que eles possam, num nível elementar, desenvolver as primeiras compre-

ensões a respeito dos meios de obtenção de uma amostra e das conclusões possíveis

sobre a respectiva população.

Os dois primeiros capítulos são baseados em [1].

No primeiro capítulo é apresentado o desenvolvimento da estatística como área de

conhecimento, deﬁnindo as principais medidas de posição e de dispersão da estatís-

tica descritiva; analisando as diferentes distribuições de probabilidade, algo de grande

importância para a estatística inferencial.

As deﬁnições e os teoremas, como o Teorema do Limite Central, com suas demonstra-

ções, no ramo da inferência estatística encontram-se no segundo capítulo. Incluem-se,

ainda, os intervalos de conﬁança e os testes de hipótese para a média, a variância e

proporções.

O terceiro capítulo destina-se a atividades propostas aos alunos, dentre as quais: a

aproximação da distribuição binomial à normal e a inferência de uma amostra obtida

1

I N T R O D U Ç Ã O

pelos próprios alunos. Assim, orientando aos educandos do terceiro ano do Ensino

Médio para que sejam protagonistas do próprio conhecimento.

A aplicação das atividades em uma sala de aula do terceiro ano do Ensino Médio

da escola estadual Professora Therezinha Closa Eleutério, na cidade de Guarulhos, em

São Paulo, encontra-se no quarto capítulo, no qual se registra o diálogo entre professor

e aluno.

Diante do proposto, espera-se que os alunos visualizem o conceito de probabilidade

e da sua variação para uma variável aleatória.

2

1

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.1 S Í N T E S E H I S T Ó R I C A

Muitos foram os nomes ao longo da história que contribuíram para a Teoria Esta-

tística, desde Gauss e Legendre com a descoberta do método dos mínimos quadrados,

até Yule, que o relacionou à regressão linear.

Primeiramente com o surgimento das primeiras cidades, houve a necessidade de se

contar a quantidade de habitantes, de inimigos, dos animais nos rebanhos, inclusive

da produção agrícola; para isso utilizaram o censo, o qual também foi utilizado pelos

povos da antiguidade, justamente pela necessidade da distribuição de terras para o

plantio, da manutenção do exército, da coleta de impostos, entre outros.

John Graunt que no ano de 1662, publicou estudos estatísticos sobre os índices de

mortalidade ocorridos em Londres, dando ênfase aos dados obtidos; bem como reali-

zou os primeiros trabalhos no desenvolvimento da teoria das probabilidades, trabalhos

primeiramente iniciados com a troca de correspondências entre os matemáticos Pascal

e Fermat. Vale ressaltar que as primeiras pesquisas de Graunt se restringiam sobretudo

ao seu interesse inicial, ou seja, os jogos de azar.

Jacob Bernoulli (1654 − 1705), que também contribuiu à probabilidade, mostrou
através de seus estudos que quanto maior o número de observações, menor a incerteza

no resultado.

Abraham De Moivre (1667 − 1754) publicou, em 1733, o que hoje é conhecido como
aproximação normal à binomial. Também foi o primeiro a trabalhar com a curva

característica em forma de sino da distribuição normal, a curva de frequência normal

y = ce−hx2

,

3

F U N D A M E N TA Ç Ã O T E Ó R I C A

com c e h constantes.

Thomas Simpson (1710 − 1761) em seus estudos sobre o raciocínio reverso das proba-
bilidades envolvendo a distribuição binomial, voltou seu foco aos erros de observação,

não nas observações.

Thomas Bayes (1701 − 1761) e Pierre-Simon de Laplace (1749 − 1827) deram de
forma independente, uma prova formal do que hoje é conhecido como teorema de

Bayes, demonstrado anteriormente, mas não formalmente, por Jacob Bernoulli.

Florence Nightingale (1820 − 1910) , enfermeira durante a Guerra da Criméia (1854 −
1856) mostrou, por meio de gráﬁcos, que as péssimas condições de higiene dos hospi-

tais na época matavam mais soldados do que a própria guerra.

Problemas envolvendo as órbitas de Júpiter e Saturno e a órbita da Lua, ganharam

grande destaque no século XV I I I. Tais problemas levaram à introdução e ao desen-

volvimento de métodos de resolução das equações, resultantes das observações destas

órbitas.

Em 1749, Leonhard Euler (1707 − 1783) publicou seus estudos sobre as órbitas de
Júpiter e Saturno e Johann Tobias Mayer (1723 − 1762) publicou, no ano seguinte,
seus estudos sobre a órbita da Lua.

Euler trabalhou como matemático, com base em observações realizadas anterior-

mente, enquanto que Mayer realizou diversas observações, de modo que obteve su-

cesso em encontrar uma solução estatística para o problema da órbita da Lua; porém

Euler não.

O método de Mayer levava a resultados aceitáveis e, mesmo não sendo o melhor

método para se encontrar as soluções das equações lineares, inﬂuenciou os estudos

seguintes em estatística.

Além das órbitas de Júpiter e Saturno e da órbita da Lua, outro grande problema do

século XV I I I, estudado por Boscovich, era determinar o formato da Terra. Antes de

Boscovich outros já haviam dividido a Terra em arcos e sabiam que ela era achatada

no pólos, o problema era saber quanto.

Por isso Boscovich comparou a medida de arcos bem separados em latitude, pois em

medidas muito próximas os erros poderiam ser maximizados, como resultado apresen-

tou uma descrição geométrica de seu método, enquanto Laplace, em 1789, fez uma

descrição algébrica do método de Boscovich.

4

1.1 S Í N T E S E H I S T Ó R I C A

Adrien-Marie Legendre (1752 − 1833) propôs, em 1805, em seu trabalho sobre a
órbita dos cometas, o método dos mínimos quadrados, no qual os erros resultantes

poderiam ser minimizados tomando-se a soma dos quadrados dos desvios.

Legendre, diante dos problemas das órbitas e da medição da Terra, na mesma época

em que os métodos foram desenvolvidos, percebeu que o método dos mínimos qua-

drados não se resumia à órbita dos cometas; então Laplace formalizou uma prova da

teoria dos mínimos quadrados.

Carl Friedrich Gauss (1777 − 1855) investigou os erros de observação das órbitas dos
planetas em termos probabilísticos, dando origem ao modelo de distribuição normal,

conhecido como distribuição gaussiana. Da mesma maneira que a curva normal é

conhecida por curva de Gauss.

Gauss descobriu o método dos mínimos quadrados em 1795, não o publicando antes

de 1805, criando uma disputa pela prioridade da descoberta, entretanto, não há indí-

cios de que Gauss viu seu potencial antes dos trabalhos de Legendre serem publicados.

O método dos mínimos quadrados se mostrou útil nos estudos astronômicos e geo-

désicos, no entanto não havia ainda aplicação às ciências sociais. [18]

Adolphe Quetelet (1796 − 1874) estudou vários aspectos sociais, desta forma encon-
trou um padrão nas distribuições, sendo que os dados seguiam a curva normal. Foi

falho, porém contribuiu em avaliar e encontrar meios de classiﬁcar dados para análise,

fazendo-o apenas em situações especíﬁcas.

Siméon-Denis Poisson (1781 − 1840) publicou, em 1837, um livro sobre a aplicação
das probabilidades em vereditos de um júri, o qual introduziu um modelo de distribui-

ção de probabilidades, a distribuição de Poisson.

Wilhelm Lexis (1837 − 1914) publicou, no ano de 1876, séries estatísticas sobre taxas
de natalidade e mortalidade. Três anos depois, publicou um artigo sobre a estabilidade

de séries estatísticas, encontrando séries estáveis determinadas mais geneticamente do

que socialmente.

Gustav Theodore Fechner (1801 − 1887) criou uma metodologia quantitativa em psi-
cologia, seu método consistia em estímulos e respostas, logo após diversas repetições,

contava-se a quantidade de respostas certas e erradas.

Hermann Ebbinghaus (1850 − 1909) utilizando as ideias de Fechner, desenvolveu um

argumento para justiﬁcar o tratamento dos dados, baseado na distribuição normal.

5

F U N D A M E N TA Ç Ã O T E Ó R I C A

Francis Galton (1822 − 1911) aplicou a estatística aos estudos sobre hereditariedade,
para mostrar que as variações tendem a retornar à população geral, entretanto não

conseguiu desenvolver matematicamente suas próprias ideias.

Francis Ysidro Edgeworth (1845 − 1926) traduziu as ideias de Galton para a forma
matemática, no estudo das estatísticas sociais e econômicas, aproximando a distribui-

ção da população à distribuição normal.

Karl Pearson (1857 − 1936) usou a correlação nas estatísticas sociais, encontrando
diversidade onde Galton encontrou uniformidade, limitando-se exclusivamente aos

estudos das ciências sociais.

George Udny Yule (1871 − 1951) não limitou o estudo da estatística à sua área de

conhecimento, a biologia; relacionando a regressão linear aos mínimos quadrados.

O geneticista britânico Sir Ronald Aylmer Fischer (1890 − 1962) mostrou a importân-

cia do planejamento experimental e desenvolveu a análise da variância, ANOVA.

1.2 E S TAT Í S T I C A D E S C R I T I VA

A coleta, a organização, redução e representação dos dados, constituem o ramo da

estatística descritiva, que tem por interesse os próprios dados, não preocupando-se em

tirar conclusões.

1.2.1 Variáveis

O conhecimento dos tipos de variáveis envolvidas determina o tipo de tratamento

que será dado às informações obtidas. Essas variáveis podem ser classiﬁcadas em

qualitativas ou quantitativas.

As variáveis qualitativas, tais como rótulos, qualidades ou entradas não numéricas,

podem ser nominais, quando os dados a serem considerados não podem ser ordenados;

ou ordinais, em que os dados podem ser ordenados.

As variáveis quantitativas podem ser discretas, sendo que os dados, obtidos geral-

mente através de uma contagem, formam um conjunto enumerável; ou contínuas, na

qual os dados pertencem a um intervalo de números reais, resultando de medições.

6

1.2.2 Medidas de Posição

1.2 E S TAT Í S T I C A D E S C R I T I VA

As medidas de posição são valores representativos de toda a série de dados. Uma

medida de posição central descreve uma entrada central do conjunto de dados, sendo

as mais usuais: a média, a mediana e a moda.

Deﬁnição 1.1. A média aritmética da variável X é a soma das entradas x1, x2, . . . , xn
dividida pelo número n de entradas.

x =

x1 + x2 + · · · + xn
n

.

Deﬁnição 1.2. A mediana da variável X é o valor que está no centro do conjunto
ordenado de n entradas, x1, x2, . . . , xn, dividindo-o em duas partes iguais.

md(X) =






x( n+1
2 ),
2 ) + x( n
x( n
2

2 +1)

se n ímpar;

,

se n par.

Deﬁnição 1.3. A moda da variável X é a entrada mais frequente de um conjunto de

dados.

1.2.3 Medidas de Dispersão

A dispersão mede o quanto um conjunto de dados está afastado de sua média; se os

valores estão próximos, ela é pequena e se estão espalhados, ela é grande.

Dada uma variável X, de entradas x1, x2, . . . , xn e média x, os desvios das entradas

em relação à média são as diferenças:

x1 − x, x2 − x, . . . , xn − x

A soma destes desvios é igual a zero.

n
∑
i=1

(xi − x) = (x1 − x) + (x2 − x) + · · · + (xn − x)

= (x1 + x2 + · · · + xn) − n · x

= n · x − n · x

= 0.

A passagem de 1.1 para 1.2 segue da Deﬁnição 1.1.

(1.1)

(1.2)

7

F U N D A M E N TA Ç Ã O T E Ó R I C A

Para que a soma dos desvios não seja igual a zero, devemos considerar os valores

absolutos dos desvios ou o quadrado dos desvios. Desta forma,

ou

n
∑
i=1

|xi − x|

n
∑
i=1

(xi − x)2

Assim, deﬁnimos o desvio médio, a variância e o desvio padrão, de uma variável X.

Deﬁnição 1.4. O desvio médio é a média da soma dos valores absolutos dos desvios.

dm(X) =

∑n

i=1|xi − x|
n

.

Deﬁnição 1.5. A variância é a média da soma dos quadrados dos desvios.

var(X) =

∑n

i=1(xi − x)2
n

.

Deﬁnição 1.6. O desvio padrão é a raiz quadrada da variância.

dp(X) =

(cid:112)

var(X).

1.3 P R O B A B I L I D A D E

1.3.1 Espaço amostral e evento

Deﬁnição 1.7. Espaço amostral é o conjunto de todos os resultados possíveis de um

experimento, sendo representado pela letra S. Evento é um subconjunto do espaço

amostral.

Considerando dois eventos E e F quaisquer de um espaço amostral S, temos as

seguintes operações com conjuntos:

• A união é o conjunto dos elementos que pertencem a E ou a F, ou a ambos:

E ∪ F = {x : x ∈ E ou x ∈ F};

8

1.3 P R O B A B I L I D A D E

• A interseção é o conjunto dos elementos que pertencem a E e a F simultanea-

mente:

E ∩ F = {x : x ∈ E e x ∈ F};

• O complemento de E, denotado por EC, é o evento formado por todos os elemen-

tos do espaço amostral que não pertencem a E:

EC = {x : x /∈ E}.

1.3.2 Deﬁnição e algumas probabilidades importantes

A cada evento E do espaço amostral S está associado um número, denotado por

P(E), chamado de probabilidade do evento E.

Deﬁnição 1.8. Uma probabilidade é uma função P com domínio em S, que associa a

cada evento E um número P(E) que satisfaz as seguintes propriedades:

1. 0 ≤ P(E) ≤ 1, para todo evento E;

2. P(S) = 1;

3. Se os eventos E1, E1, . . ., são mutuamente excludentes dois a dois, isto é, eventos

para os quais Ei ∩ Ej = ∅ quando i (cid:54)= j, então

(cid:33)

Ei

=

(cid:32) ∞
(cid:91)

i=1

P

∞
∑
i=1

P(Ei).

(1.3)

As propriedades apresentadas na Deﬁnição 1.8 são conhecidas como Axiomas de

Probabilidade. O terceiro axioma é conhecido como Axioma da Aditividade Contável.

Teorema 1.9. Se P é uma função de probabilidade e E é um subconjunto de S, então:

(i) P(EC) = 1 − P(E);

(ii) P(∅) = 0, onde ∅ é o conjunto vazio.

Demonstração. Inicialmente, provaremos (i).

Os conjuntos E e EC são tais que S = E ∪ EC. Portanto, pelo Segundo Axioma das

Probabilidades,

P(E ∪ EC) = P(S) = 1

(1.4)

9

F U N D A M E N TA Ç Ã O T E Ó R I C A

Como, E e EC são mutuamente excludentes, temos, pelo Terceiro Axioma das Probabi-
lidades,

P(E ∪ EC) = P(E) + P(EC)

(1.5)

De (1.4) e (1.5), resulta (a).

Para provar (ii), utilizamos o fato de que S = S ∪ ∅, e que S e ∅ são mutuamente

excludentes, então, por um raciocínio análogo, temos,

1 = P(S) = P(S ∪ ∅) = P(S) + P(∅),

e, portanto, P(∅) = 0.

1.3.3 Contagem

A seguir serão apresentadas algumas técnicas de contagem, que serão úteis no cál-

culo de probabilidades e serão abordadas de maneira implícita nas atividades.

Teorema 1.10 (Teorema Fundamental da Contagem). Se uma escolha consiste em k

passos, a i-ésima pode ser realizada de ni modos, i = 1, . . . , k, então a escolha total pode
ser feita de n1 · n2 · · · · · nk maneiras.

Demonstração. A demonstração será feita pelo Princípio da Indução Finita.

A primeira escolha pode ser feita de n1 modos, e para cada um desses modos, temos

n2 opções para a segunda escolha. Desse modo, podemos realizar as escolhas de

(1 · n2) + (1 · n2) + · · · + (1 · n2)
(cid:124)
(cid:123)(cid:122)
(cid:125)
n1 termos

= n1 · n2

modos, provando o teorema para k = 2.

Supondo que o teorema seja válido para k escolhas, então, a quantidade de maneiras

de se fazer a escolhas é:

n1 · n2 · · · · · nk.

O objetivo agora, é mostrar que o teorema seja válido para nk+1 escolhas. Assim,

(n1 · n2 · · · · · nk · 1) + · · · + (n1 · n2 · · · · · nk · 1)
(cid:124)
(cid:123)(cid:122)
(cid:125)
nk+1 termos

= n1 · n2 · · · · · nk · nk+1.

Portanto, o teorema é válido para k escolhas.

10

1.3 P R O B A B I L I D A D E

A seguir, será apresentada a deﬁnição de fatorial de um número inteiro positivo.

Deﬁnição 1.11. Para um número inteiro positivo n, deﬁnimos n! como o produto de

todos os números inteiros positivos menores que ou iguais a n.

n! = n · (n − 1) · (n − 2) · · · · · 3 · 2 · 1.

Deﬁnimos, ainda, 0! = 1.

Deﬁnição 1.12. Para números inteiros não negativos, n e r, com r (cid:54) n, deﬁnimos (n
como

r),

(cid:19)

(cid:18)n
r

=

n!
(n − r)! r!

1.3.4 Tipos de Probabilidades

Supondo que todos os resultados de um experimento, no qual o espaço amostral
S = {s1, s2, . . . , sN} é um conjunto ﬁnito, são igualmente prováveis. Podemos dizer
que

Então,

P({s1}) = P({s2}) = · · · = P({sN}).

P({si}) =

1
N

, com i = 1, . . . , N.

Do Terceiro Axioma das Probabilidades, resulta que, para cada evento E,

P(E) =

n(E)
n(S)

(1.6)

onde n(E) e n(S) são, respectivamente, os números de elementos em E e S.

A equação 1.6 é conhecida como probabilidade clássica.

Um outro tipo de probabilidade, conhecida como probabilidade empírica, é baseada

na frequência com que um evento ocorre a longo prazo. Considerando um evento E,

nestas condições, temos,

P(E) =

Frequência do evento E
Frequência total

1.3.5 Probabilidade condicional e independência

A probabilidade de um evento ocorrer, dado que outro evento já ocorreu, é denomi-

nada probabilidade condicional.

11

F U N D A M E N TA Ç Ã O T E Ó R I C A

Deﬁnição 1.13. Dados dois eventos E e F, P(F) > 0, deﬁnimos a probabilidade condi-
cional de E dado F, representada por P(E|F), como

P(E|F) =

P(E ∩ F)
P(F)

.

(1.7)

A relação a seguir, obtida de (1.7), é a chamada regra do produto das probabilidade,

Podemos também escrever,

P(E ∩ F) = P(F)P(E|F).

P(F ∩ E) = P(E)P(F|E),

devido à simetria de (1.7).

Como P(E ∩ F) = P(F ∩ E), temos

Ou seja,

P(F)P(E|F) = P(E)P(F|E).

P(E|F) =

P(E)P(F|E)
P(F)

.

Que é a versão mais simples da Regra de Bayes.

Considere os eventos E e F, o evento F pode ser escrito como

F = (F ∩ E) ∪ (F ∩ EC).

(1.8)

Como (F ∩ E) e (F ∩ EC) são mutuamente excludentes, temos da Equação (1.3), que

P(F) = P(F ∩ E) + P(F ∩ EC)

= P(E)P(F|E) + P(EC)P(F|EC).

(1.9)

Substituindo (1.9) em (1.8), obtemos

P(E|F) =

P(E)P(F|E)
P(E)P(F|E) + P(EC)P(F|EC)

(1.10)

Podemos generalizar (1.10).

Sejam E1, E2, . . . uma partição de espaço amostral, e F um conjunto qualquer, então

a probabilidade de ocorrência de Ei, supondo-se a ocorrência de F, é dada por

P(Ei|F) =

P(Ei)P(F|Ei)
j=1 P(Ej)P(F|Ej)

∑∞

,

(1.11)

12

para todo i = 1, 2, . . . .

Pode ocorrer de um evento F não ter inﬂuência sobre um evento E. Neste caso,

1.4 VA R I Á V E I S A L E AT Ó R I A S

temos

P(E|F) = P(E).

Então, pela Regra de Bayes, obtemos, dessa forma

P(F|E) =

P(F)P(E|F)
P(E)

=

P(F)P(E)
P(E)

= P(F).

Como P(E ∩ F) = P(E)P(F|E), temos

P(E ∩ F) = P(E)P(F).

Motivando, assim, a seguinte deﬁnição.

Deﬁnição 1.14. Dois eventos E e F são estatisticamente independentes se

P(E ∩ F) = P(E)P(F).

(1.12)

1.4 VA R I Á V E I S A L E AT Ó R I A S

Deﬁnição 1.15. Uma variável aleatória é uma função X deﬁnida no espaço amostral

S que assume valores no conjunto dos números reais.

1.4.1 Função de distribuição acumulada

A função de distribuição acumulada (f.d.a.) de X é uma função associada a cada

uma das variáveis aleatórias X.

Deﬁnição 1.16. Dada uma variável aleatória X, a função de distribuição acumulada

(f.d.a.) de X, denotada por FX(x), é dada por

FX(x) = PX(X (cid:54) x), para todo x.

Exemplo 1.1. Exemplo extraído de [1].

13

F U N D A M E N TA Ç Ã O T E Ó R I C A

Considere o experimento de lançar três moedas equilibradas e seja X = número de

caras observado. A (f.d.a.) de X é

FX(x) =






0,

1
8 ,
1
2 ,
7
8 ,

1,

se −∞ < x < 0
se 0 (cid:54) x < 1
se 1 (cid:54) x < 2
se 2 (cid:54) x < 3
se 3 (cid:54) x < ∞.

(1.13)

A função escada FX(x) é representada na Figura 1.

Figura 1: F.d.a. do Exemplo 1.13

Fonte: Arquivo próprio do autor, baseado em [1].

Existem vários pontos a ser observados na Figura 1. FX é deﬁnido para todos os

valores de x. Deste modo, por exemplo,

FX(2, 5) = P(X (cid:54) 2, 5) = P(X = 0, 1 ou 2) =

7
8

.

Pela Figura 1, FX pode ser descontínua, com saltos em determinados valores de x.
Pela Deﬁnição 1.16, nos pontos de saltos FX assume o valor na parte superior do salto.
O tamanho do salto em qualquer ponto de x é igual a P(X = x).

Deﬁnimos a seguir os dois tipos de variáveis aleatórias.

Deﬁnição 1.17. Uma variável aleatória X é discreta se FX for uma função escada de x.
Uma variável aleatória X é contínua se FX for uma função contínua de x.

14

1.4.2 Função de probabilidade ou densidade de probabilidade

1.4 VA R I Á V E I S A L E AT Ó R I A S

A função de probabilidade (f.p.), no caso de variável aleatória discreta, ou função

densidade de probabilidade (f.d.p.), no caso de variável aleatória contínua, é uma

função associada a uma variável aleatória X e a sua (f.d.a.).

Deﬁnição 1.18. A função de probabilidade (f.p.), de uma variável aleatória discreta X,

é dada por:

fX(x) = P(X = x), para todo x.

No caso discreto, podemos somar os valores da (f.p.) para obter a (f.d.a.), no caso

contínuo podemos substituir as somas por integrais, obtendo, dessa forma,

P(X (cid:54) x) = FX(x) =

(cid:90) x

−∞

fX(t)dt.

Se fX(x) for contínua, temos

d
dx

FX(x) = fX(x).

Deﬁnição 1.19. A função densidade de probabilidade (f.d.p.), de uma variável aleatória

contínua X, é a função que satisfaz:

FX(x) =

(cid:90) x

−∞

fX(t)dt, para todo x.

A área compreendida entre dois valores a e b quaisquer, sob a curva de FX(x), nos
fornece a probabilidade de uma variável aleatória com distribuição contínua pertencer

ao intervalo [a, b]. Podemos escrever

P(a (cid:54) X (cid:54) b) =

(cid:90) b

a

fX(x)dx = FX(b) − FX(a).

(1.14)

1.4.3 Valor esperado

A média, ou valor esperado, de uma variável aleatória é um número que representa

um valor que se espera de uma observação da variável aleatória.

15

F U N D A M E N TA Ç Ã O T E Ó R I C A

Deﬁnição 1.20. O valor esperado de uma variável aleatória X, de uma função g(X),

representado por Eg(X), é

Eg(X) =






∑ g(X)P(X = x),
(cid:82) ∞
−∞ g(X) fX(x)dx,

se X for uma variável discreta;

se X for uma variável contínua.

1.4.4 Momentos

Deﬁnição 1.21. Para cada n inteiro, o n-ésimo momento de X é deﬁnido como

µ(cid:48)
n = EXn.

O n-ésimo momento central de X é dado por

µn = E(X − µ)n,

onde µ = µ(cid:48)

1 = EX.

1.4.5 Variância e desvio padrão

A variância é o segundo momento central, podemos deﬁnir a variância e o desvio

padrão de uma variável aleatória.

Deﬁnição 1.22. A variância de uma variável aleatória X, com média µ, representada

por Var(X), é

Var(X) = E(X − EX)2.

(1.15)

O desvio padrão de uma variável aleatória X é a raiz quadrada positiva de Var(X),

representado por DP(X).

DP(X) =

(cid:112)

Var(X).

O desvio padrão mede a dispersão da população em torno da média.

Podemos simpliﬁcar o cálculo a variância, antes, porém, precisamos do seguinte

teorema.

Teorema 1.23. Sejam X uma variável aleatória, e a, b e c constantes. Para quaisquer
funções g1(X) e g2(X), desde que seus valores esperados existam, temos

E(ag1(X) + bg2(X) + c) = aEg1(X) + bEg2(X) + c.

16

1.4 VA R I Á V E I S A L E AT Ó R I A S

Demonstração. No caso das variáveis aleatórias discretas, temos

E(ag1(X) + bg2(X) + c) = ∑(ag1(X) + bg2(X) + c) fX(x)

= ∑ ag1(X) fX(x) + ∑ bg2(X) fX(x) + ∑ c fX(x)
= a ∑ g1(X) fX(x) + b ∑ g2(X) fX(x) + c ∑ fX(x)
= aEg1(X) + bEg2(X) + c.

No caso em que as variáveis aleatórias são contínuas,

E(ag1(X) + bg2(X) + c) =

=

(cid:90) ∞

−∞
(cid:90) ∞

−∞
(cid:90) ∞

−∞

(ag1(X) + bg2(X) + c) fX(x)dx

ag1(X) fX(x)dx +

bg2(X) fX(x)dx +

c fX(x)dx

(cid:90) ∞

−∞
(cid:90) ∞

−∞

(cid:90) ∞

−∞
(cid:90) ∞

−∞

= a

g1(X) fX(x)dx + b

g2(X) fX(x)dx + c

fX(x)dx

= aEg1(X) + bEg2(X) + c.

Temos da Equação 1.15 que

Var(X) = E(X − EX)2 = E[(X2 − 2XEX + (EX)2].

Aplicando o Teorema 1.23, temos:

Var(X) = E(X2) − 2E(XEX) + (EX)2.

Usando o fato de EX ser uma constante, podemos escrever

E(XEX) = (EX)(EX) = (EX)2.

Portanto,

Var(X) = E(X2) − (EX)2.

(1.16)

17

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.5 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E D I S C R E TA S

1.5.1 Distribuição uniforme discreta

Nesta distribuição cada um dos resultados 1, . . . , N, tem a mesma probabilidade de

ocorrer. Uma variável aleatória discreta X tem distribuição uniforme se

P(X = x|N) =

1
N

, x = 1, . . . , N.

Para o cálculo do valor esperado e da variância de X, podemos fazer uso dos seguintes

teoremas:

Teorema 1.24. A soma dos n primeiros números naturais é

n(n + 1)
2

.

Demonstração. A demonstração será feita pelo Princípio da Indução Finita.

Seja ∑n

i=1 i =

n(n + 1)
2

.

Para n = 1, a igualdade é verdadeira, pois

verdadeira, para algum n ∈ N. Então,

1(1 + 1)
2

= 1. Suponha que ela seja

n
∑
i=1

i =

n(n + 1)
2

.

Adicionando (n + 1), a ambos os lados, obtemos:

Resolvendo,

Portanto,

n
∑
i=1

i + (n + 1) =

n(n + 1)
2

+ (n + 1).

n+1
∑
i=1

i =

n(n + 1)
2

+

2(n + 1)
2

=

(n + 1)(n + 2)
2

.

n
∑
i=1

i =

n(n + 1)
2

é verdadeira para todo n ∈ N.

Teorema 1.25. A soma dos quadrados dos n primeiros números naturais é

n(n + 1)(2n + 1)
6

.

Demonstração. A demonstração será feita pelo Princípio da Indução Finita.

Seja ∑n

i=1 i2 =

n(n + 1)(2n + 1)
6

.

18

1.5 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E D I S C R E TA S

A igualdade é verdadeira para n = 1, pois

1(1 + 1)(2 · 1 + 1)
6

= 1 = 12.

Suponha que ela seja verdadeira, para algum n ∈ N. Então,

n
∑
i=1

i2 =

n(n + 1)(2n + 1)
6

.

Adicionando (n + 1)2, a ambos os lados, obtemos:

n
∑
i=1

i2 + (n + 1)2 =

n(n + 1)(2n + 1)
6

+ (n + 1)2.

Resolvendo, temos,

n+1
∑
i=1

i2 =

(n + 1)[n(2n + 1) + 6(n + 1)]
6

=

(n + 1)(2n2 + 7n + 6)
6

=

(n + 1)(n + 2)(2n + 3)
6

.

Portanto,

n
∑
i=1

i2 =

n(n + 1)(2n + 1)
6

é verdadeira para todo n ∈ N.

Logo, o valor esperado é dado por:

EX =

N
∑
x=1

xP(X = x) =

1
N

N
∑
x=1

x.

Do Teorema 1.24, temos

então,

Como,

1
N

N
∑
x=1

x =

N + 1
2

EX =

N + 1
2

.

EX2 =

1
N

N
∑
x=1

x2.

Do Teorema 1.25, obtemos,

logo,

1
N

N
∑
x=1

x2 =

(N + 1)(2N + 1)
6

EX2 =

(N + 1)(2N + 1)
6

.

(1.17)

(1.18)

19

F U N D A M E N TA Ç Ã O T E Ó R I C A

Portanto, de (1.17) e (1.18), temos que a variância é

Var(X) = EX2 − (EX)2

(cid:19)2

−

(cid:18) N + 1
2

=

=

(N + 1)(2N + 1)
6
(N − 1)(N + 1)
12

.

(1.19)

1.5.2 Distribuição binomial

Na distribuição binomial um experimento apresenta apenas dois resultados possí-

veis, podendo ser classiﬁcado como sucesso ou fracasso.

Deﬁnimos a seguir a variável aleatória de Bernoulli.

Deﬁnição 1.26. Uma variável aleatória X, que assume os valores 0, classiﬁcado como

fracasso, e 1, classiﬁcado como sucesso, cuja função de probabilidade é

P(X = x) = px(1 − p)1−x, com x = 0, 1

onde p é a probabilidade de se obter sucesso, é chamada de variável aleatória de

Bernoulli.

O valor esperado e a variância da variável aleatória de Bernoulli, são:

EX = 1p1(1 − p)1−1 + 0p0(1 − p)1−0.

Logo

Da Equação (1.15), obtemos:

EX = p.

(1.20)

Var(X) = E(1 − p)2 + E(0 − p)2 = (1 − p)2 p + (0 − p)2(1 − p).

Portanto

Var(X) = p(1 − p).

(1.21)

Suponhamos que sejam realizados n ensaios de Bernoulli, tal que n é previamente
determinado, todos idênticos e independentes, com probabilidade p de sucesso e 1 − p
de fracasso.

Se em n ensaios, obtemos x sucessos, então X é uma variável aleatória binomial

com parâmetros n e p, ao qual denotamos X ∼ Binomial(n, p).

20

1.5 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E D I S C R E TA S

Sua função de probabilidade é dada por:

P(X = x) =

(cid:19)

(cid:18)n
x

px(1 − p)n−x, com x = 0, . . . , n.

(1.22)

Para calcularmos o valor esperado e a variância de uma variável aleatória de binomial,

precisamos do Teorema binomial.

Antes, porém, se faz necessário o uso de uma igualdade muito importante.

Teorema 1.27. Para números inteiros não negativos, n e r, com 1 (cid:54) r (cid:54) s, temos:
(cid:18)n − 1
r − 1

(cid:18)n − 1
r

(cid:18)n
r

(cid:19)

(cid:19)

(cid:19)

+

=

(1.23)

Demonstração. Da Deﬁnição 1.12, podemos escrever a igualdade da seguinte maneira:

(cid:19)

(cid:18)n − 1
r − 1

(cid:19)

(cid:18)n − 1
r

+

=

=

=

=

(n − 1)!
(n − r)! (r − 1)!

+

(n − 1)!
(n − r − 1)! r!

(n − 1)!
(n − r − 1)! r(r − 1)!

+

(n − 1)!
(n − r)(n − r − 1)! (r − 1)!
n(n − 1)! +(n − r)(n − 1)!
(n − r)(n − r − 1)! r(r − 1)!
(cid:18)n
r

n!
(n − r)! r!

(cid:19)

=

.

Teorema 1.28 (Teorema binomial). Para números reais x e y e inteiros não negativos n,

temos:

(x + y)n =

(cid:19)

(cid:18)n
i

n
∑
i=0

xiyn−i.

(1.24)

Demonstração. A demonstração foi extraída de [15].

A demonstração será pelo Princípio da Indução Finita.

Quando n = 1, a Equação (1.24) reduz-se a
(cid:18)1
1

(cid:18)1
0

x0y1 +

x + y =

(cid:19)

(cid:19)

x1y0 = y + x.

Supondo a Equação (1.24) válida para n − 1. Então,

(x + y)n = (x + y)(x + y)n−1
(cid:18)n − 1
i

= (x + y)

(cid:19)

xiyn−i−1

n−1
∑
i=0
(cid:18)n − 1
i

=

n−1
∑
i=0

(cid:19)

xi+1yn−i−1 +

n−1
∑
i=0

(cid:19)

(cid:18)n − 1
i

xiyn−i

21

F U N D A M E N TA Ç Ã O T E Ó R I C A

Fazendo k = i + 1 no primeiro somatório e k = i no segundo, temos

(x + y)n =

(cid:19)

(cid:18)n − 1
k − 1

n
∑
k=1

xkyn−k +

(cid:18)n − 1
k
(cid:19)(cid:21)

n−1
∑
k=0
(cid:18)n − 1
k

(cid:19)

+

(cid:19)

xkyn−k

xkyn−k + yn

= xn +

xkyn−k + yn

(cid:20)(cid:18)n − 1
k − 1
(cid:19)

(cid:18)n
k

xkyn−k.

n−1
∑
k=1
n−1
∑
k=1
(cid:19)
(cid:18)n
k

= xn +

=

n
∑
k=0

A penúltima igualdade segue da Equação (1.23).

Fazendo x = p e y = 1 − p na Equação (1.24), obtemos

(cid:19)

(cid:18)n
i

n
∑
i=0

pi(1 − p)n−i = (p + 1 − p)n = 1.

(1.25)

Logo, a soma da f.p. da distribuição binomial é igual a 1.

Podemos, então, calcular o valor esperado da distribuição binomial.

Da Deﬁnição 1.20 e da Equação (1.22), temos

EX =

(cid:19)

(cid:18)n
x

x

n
∑
x=0

px(1 − p)n−x =

(cid:19)

(cid:18)n
x

x

n
∑
x=1

px(1 − p)n−x

pois, em x = 0 o termo é 0.

Usando o fato que
(cid:18)n
x

x

(cid:19)

Temos,

Fazendo x = y + 1,

= x

n!
(n − x)! x!

=

n(n − 1)!
(n − x)! (x − 1)!

= n

(cid:18)n − 1
x − 1

(cid:19)

.

EX =

(cid:19)

(cid:18)n − 1
x − 1

n

n
∑
x=1

px(1 − p)n−x.

EX = n

n−1
∑
y=0

(cid:19)

(cid:18)n − 1
y

py+1(1 − p)n−(y+1) = np

n−1
∑
y=0

(cid:19)

(cid:18)n − 1
y

py(1 − p)n−y−1.

Como a última soma é a soma da f.p. da distribuição binomial (n − 1, p) ela deve ser
igual a 1.

Portanto,

22

EX = np.

(1.26)

1.5 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E D I S C R E TA S

Para calcular a variância da distribuição binomial, devemos encontrar o valor e EX2.

Temos,

Usando o fato que

EX2 =

x2

(cid:19)

(cid:18)n
x

n
∑
x=1

px(1 − p)n−x

x2

(cid:19)

(cid:18)n
x

= x2

n!
(n − x)! x!

= x

n(n − 1)!
(n − x)! (x − 1)!

= nx

(cid:18)n − 1
x − 1

(cid:19)

.

Temos,

Fazendo x = y + 1,

EX2 =

nx

(cid:19)

(cid:18)n − 1
x − 1

n
∑
x=1

px(1 − p)n−x.

EX2 = n

n−1
∑
y=0

(y + 1)

(cid:19)

(cid:18)n − 1
y

py+1(1 − p)n−(y+1)

= np

n−1
∑
y=0

(cid:19)

(cid:18)n − 1
y

y

py(1 − p)n−y−1 + np

n−1
∑
y=0

(cid:19)

(cid:18)n − 1
y

py(1 − p)n−y−1.

A primeira soma é o valor esperado de uma distribuição binomial (n − 1, p), sendo
igual a (n − 1)p e a segunda soma é igual a 1. Então,

EX2 = (n − 1)np2 + np.

(1.27)

Da Equação (1.16) e de (1.26) e (1.27), segue que

Var(X) = (n − 1)np2 + np − (np)2 = np − np2.

Logo,

Var(X) = np(1 − p).

(1.28)

1.5.3 Distribuição de Poisson

A distribuição de Poisson é utilizada quando desejamos obter o número de ocorrên-

cias de um certo tipo de evento em um determinado intervalo de tempo.

Uma variável aleatória X com valores nos inteiros não negativos tem uma distribui-
ção de Poisson com parâmetro λ > 0, a qual denotamos X ∼ Poisson(λ), se sua função
de probabilidade é

P(X = x|λ) =

e−λλx
x!

, com x = 0, 1, . . . .

(1.29)

Para calcularmos o valor esperado precisamos da Fórmula de Taylor, que aproxima

uma função por um polinômio.

23

F U N D A M E N TA Ç Ã O T E Ó R I C A

Deﬁnição 1.29. Seja f : I → R uma função que admite derivadas até ordem r, isto é,
f (r)(x) = dr
dxr f (x) num ponto c do intervalo I. O polinômio de Taylor de ordem r de f
no ponto c é dado por

Tr(x) =

r
∑
i=0

f (i)(c)
i!

(x − c)i.

Exemplo 1.2. Cálculo do polinômio de Taylor de f (x) = ex no ponto c = 0.

Temos,

e

Logo,

f (x) = f (cid:48)(x) = f (cid:48)(cid:48)(x) = · · · = f (n)(x) = ex

f (0) = f (cid:48)(0) = f (cid:48)(cid:48)(0) = · · · = f (n)(0) = e0 = 1.

ex =

n
∑
i=0

f (i)(0)
i!

(x − 0)i =

∞
∑
i=0

xi
i!

.

(1.30)

O valor esperado da distribuição de Poisson é dado por:

EX =

∞
∑
x=0

x

e−λλx
x!

= λe−λ

∞
∑
x=1

λx−1
(x − 1)!

.

Fazendo y = x − 1, obtemos

Da Equação (1.30), segue que

e, portanto,

EX = λe−λ

∞
∑
y=0

λy
y!

.

EX = λe−λeλ

EX = λ.

(1.31)

Para determinar a variância, calculamos o valor de EX2.

EX2 =

∞
∑
x=0

x2 e−λλx
x!

= λ

∞
∑
x=1

x

e−λλx−1
(x − 1)!

.

Fazendo y = x − 1, obtemos

EX2 = λ

∞
∑
y=0

(y + 1)

e−λλy
y!

= λ

(cid:34) ∞
∑
y=0

y

e−λλy
y!

+

∞
∑
y=0

e−λλy
y!

(cid:35)

.

A primeira soma é o valor esperado e a segunda é igual a 1 pela Equação (1.30).

24

1.6 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E C O N T Í N U A S

Então,

EX2 = λ(λ + 1).

(1.32)

Logo, da Equação (1.16) e de (1.31) e (1.32) temos

Var(X) = λ(λ + 1) − λ2

e, portanto.

Var(x) = λ.

(1.33)

1.6 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E C O N T Í N U A S

1.6.1 Distribuição uniforme

Uma variável aleatória X é distribuída uniformemente ao longo do intervalo [α, β]

se sua f.d.p. é dada por

fX(x|α, β) =




1
β − α

,



0,

se α (cid:54) x (cid:54) β;

caso contrário.

O valor esperado da distribuição uniforme é dado por:

EX =

=

=

(cid:90) β

x
β − α

dx

α
β2 − α2
2(β − α)
β + α
2

.

(1.34)

(1.35)

Para calcular a variância, primeiro calculamos EX2.

EX2 =

=

=

(cid:90) β

x2
β − α

dx

α
β3 − α3
3(β − α)
β2 + αβ + α2
3

.

(1.36)

Da Equação (1.16) e de (1.35) e (1.36), obtemos:

Portanto,

Var(X) =

β2 + αβ + α2
3

−

(β + α)2
4

.

Var(X) =

(β − α)2
12

.

(1.37)

25

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.6.2 Distribuição normal

Uma variável aleatória X tem distribuição normal, com parâmetros µ, −∞ < µ < ∞

e σ > 0, denotada por X ∼ N(µ, σ2), se sua f.d.p. é dada por

fX(x|µ, σ2) =

1
√

2π

σ

−(x−µ)2
2σ2

e

, −∞ < x < ∞.

(1.38)

A variável aleatória Z = (X−µ)

σ
distribuição normal padrão. Isto é estabelecido escrevendo

tem uma distribuição Z ∼ N(0, 1), conhecida como

P(Z (cid:54) z) = P

(cid:18) X − µ
σ

(cid:19)

(cid:54) z

= P(X (cid:54) zσ + µ)
(cid:90) zσ+µ

1
√

=

σ

2π

−∞

−(x−µ)2

2σ2 dx.

e

Fazendo t =

(x − µ)
σ

, obtemos

P(Z (cid:54) z) =

1
√

2π

(cid:90) z

−∞

−t2
2 dt,

e

o que mostra que P(Z (cid:54) z) é a f.d.a. normal padrão.

Portanto, a f.d.p. da distribuição normal padrão é dada por

1
√

2π

−z2
2 , −∞ < z < ∞.

e

Podemos nos referir à f.d.p. da distribuição normal padrão por Φ(z).

Neste caso, podemos escrever

Φ(z) =

1
√

2π

−z2
2 .

e

Para provar que (1.38) é de fato uma f.d.p., precisamos mostrar que

1
√

2π

σ

(cid:90) ∞

−∞

e

−(x−µ)2

2σ2 dx = 1

ao longo de toda reta real.

A demonstração de (1.40) foi extraída de [1].

(1.39)

(1.40)

26

1.6 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E C O N T Í N U A S

Fazendo z = (x−µ)

σ

, obtemos

1
√

2π

σ

(cid:90) ∞

−∞

e

−(x−µ)2

2σ2 dx =

1
√

2π

(cid:90) ∞

−∞

−z2
2 dz.

e

Como a integral sobre (−∞, 0) é igual a integral sobre (0, ∞), pois na distribuição
normal padrão obtemos um gráﬁco simétrico, vide Figura 2, reduzimos o problema

mostrando que

(cid:90) ∞

0

−z2
2 dz =

e

(cid:114) π
2

.

Como ambos os lados da igualdade são positivos, a igualdade se manterá admitindo

que os quadrados são iguais, então

(cid:18)(cid:90) ∞

(cid:19)2

−z2
2 dz

e

0

=

=

(cid:18)(cid:90) ∞

−u2
2 du

e

(cid:19) (cid:18)(cid:90) ∞

(cid:19)

−v2
2 dv

e

0
(cid:90) ∞

(cid:90) ∞

0

0

0

−(u2+v2)
2

e

dudv.

Fazendo uma mudança de variáveis para coordenadas polares, obtemos u = r cos θ

e v = r senθ.

Dessa forma, u2 + v2 = r2, dudv = rdθdr e os limites de integração passam a ser

0 < r < ∞ e 0 < θ < π

2 . Então,

(cid:18)(cid:90) ∞

(cid:19)2

−z2
2 dz

e

0

=

=

=

=

(cid:90) ∞

(cid:90) π
2

−r2
2 rdθdr

e

0
(cid:90) ∞

−r2
2 dr

re

0
(cid:20)

−e

(cid:21)

−r2
2

|∞
0

,

0
π
2
π
2
π
2

o que demonstra (1.40).

Para demonstrar o valor esperado e a variância da distribuição normal, precisamos

do teorema a seguir.

Teorema 1.30. Seja X uma variável aleatória com variância ﬁnita, então, para quais-

quer a e b constantes, temos

Var(aX + b) = a2Var(X).

27

F U N D A M E N TA Ç Ã O T E Ó R I C A

Demonstração. Da Equação (1.15) e aplicando o Teorema 1.23 duas vezes, obtemos

Var(aX + b) = E[(aX + b) − E(aX + b)]2

= E[(aX + b) − (aEX + b)]2

= E(aX − aEX)2

= E[a2(X − EX)2]

= a2E(X − EX)2

= a2Var(X).

Inicialmente, determinamos o valor esperado e a variância de uma variável aleatória

padrão Z = (X−µ)

σ

.

EZ =

(cid:90) ∞

−∞

z fZ(z)dz =

1
√

2π

(cid:90) ∞

−∞

−z2
2 dz = −

ze

1
√

2π

−z2
2 |∞

−∞= 0.

e

Dessa forma temos,

Var(Z) = EZ2 =

1
√

2π

(cid:90) ∞

−∞

z2e

−z2
2 dz.

Fazendo u = z e dv = ze

−z2
2 e integrando por partes, obtemos

Var(Z) =

1
√

(cid:20)

−e

−z2
2 |∞

−∞+

(cid:90) ∞

(cid:21)

−z2
2 dz

e

= −

−z2
2 |∞

−∞+

e

2π
1
√

2π

−∞
1
√

2π

(cid:90) ∞

−∞

−z2
2 dz,

e

onde a primeira parcela é igual a EZ = 0 e a segunda, pela Equação (1.40), é igual a

1.

Portanto,

Var(Z) = 1.

Para X ∼ N(µ, σ2), temos, pelo Teorema 1.23,

EX = E(µ + σZ) = µ + σEZ = µ.

(1.41)

Da mesma forma, pelo Teorema 1.30,

Var(X) = Var(µ + σZ) = σ2Var(Z) = σ2.

(1.42)

28

1.6 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E C O N T Í N U A S

O desvio padrão é a raiz quadrada da variância.

DP(X) = σ.

(1.43)

A curva da distribuição normal é simétrica, com valor máximo em x = µ e pontos de

inﬂexão em µ ± σ.

De (1.40), a área sob a curva normal é igual a 1. A probabilidade dentro de 1 desvio

padrão é:

P(µ − σ (cid:54) X (cid:54) µ + σ) = P(−1 (cid:54) Z (cid:54) 1)
= Φ(1) − Φ(−1)
= Φ(1) − [1 − Φ(1)]

= 0, 8413 − [1 − 0, 8413]

= 0, 6826.

O valor de Φ(1) foi obtido da Tabela 2.

Observação 1.6.1. Φ(−x) = 1 − Φ(x).

Procedendo de forma análoga, obtemos:

P(µ − 2σ (cid:54) X (cid:54) µ + 2σ) = P(−2 (cid:54) Z (cid:54) 2) = 0, 9544

e

P(µ − 3σ (cid:54) X (cid:54) µ + 3σ) = P(−3 (cid:54) Z (cid:54) 3) = 0, 9974.

Figura 2: Curva normal com desvios padrão

Fonte: Arquivo próprio do autor, baseado em [10].

29

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.6.3 Distribuição exponencial

Uma variável aleatória X tem distribuição exponencial, com parâmetro λ > 0, deno-

tada por X ∼ Exp(λ), se sua f.d.p. é dada por

fX(x|λ) =




λe−λx,

se x (cid:62) 0;



0,

se x < 0.

(1.44)

O valor esperado de uma distribuição exponencial é

EX =

(cid:90) ∞

0

xλe−λxdx.

Vamos calcular EXn para n > 0.

O cálculo de EXn foi extraído de [15].

EXn =

(cid:90) ∞

0

xnλe−λxdx.

Fazendo u = xn e dv = λe−λx e integrando por partes, obtemos

EXn = −xne−λx|∞

0 +n

(cid:90) ∞

0

xn−1e−λxdx

λxn−1e−λxdx

(cid:90) ∞

0

=

=

n
λ
n
λ

EXn−1.

EX =

1
λ

.

EX2 =

2
λ

EX =

2
λ

·

1
λ

=

2
λ2 .

Para n = 1, temos

Para n = 2, temos

(1.45)

(1.46)

Pela Equação (1.16) e de 1.45 e 1.46, a variância da distribuição exponencial é dada

Var(X) =

(cid:19)2

2
λ2

−

(cid:18) 1
λ

=

1
λ2 .

(1.47)

por

30

1.6 D I S T R I B U I Ç Õ E S D E P R O B A B I L I D A D E C O N T Í N U A S

1.6.4 Distribuição gama

Uma variável aleatória X tem distribuição gama, com parâmetros α > 0 e λ > 0, se

sua f.d.p. é dada por

(1.48)

(1.49)

fX(x) =




λe−λx(λx)α−1
Γ(α)

,



0,

se x (cid:62) 0;

se x < 0.

onde deﬁnimos a função gama, denominada por Γ(α), como

Γ(α) =

(cid:90) ∞

0

e−yyα−1dy.

A média de uma distribuição gama é dada por

EX =

1
Γ(α)

(cid:90) ∞

0

λxe−λx(λx)α−1dx =

1
Γ(α)

(cid:90) ∞

0

e−λx(λx)αdx.

Fazendo u = λx, obtemos du = λdx. Então,

EX =

1
λΓ(α)

(cid:90) ∞

0

e−uuαdu =

Γ(α + 1)
λΓ(α)

.

Integrando Γ(α + 1) = (cid:82) ∞

0 e−yyαdy por partes, obtemos

Γ(α + 1) = −e−yyα|∞
0 +

(cid:90) ∞

0

e−yαyα−1dy

(cid:90) ∞

= α
= αΓ(α).

0

e−yyα−1dy

Portanto,

EX =

α
λ

.

(1.50)

Para encontrar Var(x), calculemos EX2.

EX2 =

1
Γ(α)

(cid:90) ∞

0

λx2e−λx(λx)α−1dx =

1
λΓ(α)

(cid:90) ∞

0

e−λx(λx)α+1dx.

Fazendo u = λx, obtemos du = λdx. Então,

31

F U N D A M E N TA Ç Ã O T E Ó R I C A

EX2 =

1
λ2Γ(α)

(cid:90) ∞

0

e−uuα+1du =

Γ(α + 2)
λ2Γ(α)

.

Integrando Γ(α + 2) = (cid:82) ∞

0 e−yyα+1dy por partes, obtemos

e−y(α + 1)yαdy

Γ(α + 2) = −e−yyα+1|∞
0 +
(cid:90) ∞

(cid:90) ∞

0
e−yyαdy

0

= (α + 1)
= (α + 1)Γ(α + 1)
= α(α + 1)Γ(α).

Portanto,

EX2 =

α(α + 1)
λ2

.

Pela Equação (1.16), segue que

Var(X) =

α(α + 1)
λ2

−

(cid:16) α
λ

(cid:17)2

=

α
λ2 .

Distribuição qui-quadrado

(1.51)

(1.52)

Deﬁnição 1.31. Sejam Z1, . . . , Zn variáveis aleatórias normal padrão independentes,
chamamos χ2
n de variável aleatória qui-quadrado com n graus de liber-
dade.

1 + · · · + Z2

n = Z2

Seja n um inteiro positivo, a distribuição gama com λ = 1/2 e α = n/2 , é chamada

de distribuição qui-quadrado com n graus de liberdade.

fχ2

n

(x) =




x[(n/2)−1]e−x/2
2n/2Γ(n/2)

,



0,

se x (cid:62) 0;

se x < 0.

De (1.50) e (1.52), obtemos:

E(χ2

n) = n

Var(χ2

n) = 2n.

e

32

(1.53)

(1.54)

(1.55)

1.7 VA R I Á V E I S A L E AT Ó R I A S M Ú LT I P L A S

1.7 VA R I Á V E I S A L E AT Ó R I A S M Ú LT I P L A S

Em um experimento, frequentemente nos deparamos com mais de uma variável

aleatória. Inicialmente, nos ocuparemos com o caso de duas variáveis aleatórias.

Deﬁnição 1.32. Para quaisquer duas variáveis aleatórias discretas X e Y, deﬁnimos a
função fX,Y(x, y) : R2 → R, chamada função de probabilidade conjunta, ou simples-
mente, f.p. conjunta de X e Y como

fX,Y(x, y) = P(X = x, Y = y).

As funções de probabilidade marginal de X e Y, obtidas de fX,Y(x, y), são dadas por

fX(x) = P(X = x) = ∑

fX,Y(x, y).

y

fY(y) = P(Y = y) = ∑

fX,Y(x, y).

x

Deﬁnição 1.33. Para quaisquer duas variáveis aleatórias contínuas X e Y, deﬁnimos
a função fX,Y(x, y) : R2 → R, chamada função densidade de probabilidade conjunta, ou
simplesmente, f.d.p. conjunta de X e Y se, para cada A ⊂ R2, vale

P((X, Y) ∈ A) =

(cid:90)

(cid:90)

A

fX,Y(x, y)dxdy.

As funções densidade de probabilidade marginal de X e Y, obtidas de fX,Y(x, y), são

dadas por

fX(x) =

fY(y) =

(cid:90) ∞

−∞

(cid:90) ∞

−∞

fX,Y(x, y)dy, com −∞ < x < ∞.

fX,Y(x, y)dx, com −∞ < y < ∞.

Deﬁnição 1.34. O valor esperado de uma variável aleatória, deﬁnida pela função

g(X, Y), representado por Eg(X, Y) é

Eg(X, Y) =






∑

(x,y) g(X, Y) fX,Y(x, y),

no caso discreto;

(cid:82) ∞
−∞

(cid:82) ∞
−∞ g(X, Y) fX,Y(x, y)dxdy, no caso contínuo.

33

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.7.1 Distribuições condicionais e independência

Para duas variáveis aleatórias X e Y, com f.p. ou f.d.p. conjunta f (x, y) e f.p. ou

f.d.p. marginal fX(x) e fY(y), temos as seguintes deﬁnições:

Deﬁnição 1.35. Para qualquer x tal que P(X = x) = fX(x) > 0, deﬁnimos a f.p., ou
f.d.p. condicional de Y dado que X = x como a função de y dada por

f (y|x) =

f (x, y)
fX(x)

.

Para qualquer y tal que P(Y = y) = fY(y) > 0, deﬁnimos a f.p., ou f.d.p. condicional de
X dado que Y = y como a função de x dada por

f (x|y) =

f (x, y)
fY(y)

.

Deﬁnição 1.36. O valor esperado condicional de uma função de uma variável aleató-
ria g(X), dado que Y = y, denotado por E(g(X)|Y) é

E(g(X)|Y) =






∑x g(X) f (x|y),
(cid:82) ∞
−∞ g(X) f (x|y)dx, no caso contínuo.

no caso discreto;

Para E(g(Y)|X) temos uma deﬁnição análoga.

O Teorema 1.23 é válido para Eg(X, Y), E(g(X)|Y) e E(g(Y)|X).

Deﬁnição 1.37. As variáveis aleatórias X e Y, para cada x, y ∈ R, são variáveis alea-
tórias independentes se

f (x, y) = fX(x) fY(y).

Se X e Y são independentes, temos, então,

f (x|y) =

f (x, y)
fY(y)

=

fX(x) fY(y)
fY(y)

= fX(x)

f (y|x) =

f (x, y)
fX(x)

=

fX(x) fY(y)
fX(x)

= fY(y).

Teorema 1.38. Sejam X e Y variáveis aleatórias, tais que EX e EY sejam ambos ﬁnitos,

então

34

E(X + Y) = EX + EY.

1.7 VA R I Á V E I S A L E AT Ó R I A S M Ú LT I P L A S

Demonstração. Tome na Deﬁnição 1.34 g(X, Y) = X + Y.

Para o caso discreto, temos:

E(X + Y) = ∑

x

= ∑

x

= ∑

x

∑
y
∑
y
x ∑
y

(x + y) f (x, y)

x f (x, y) + ∑

y f (x, y)

∑
y
y ∑
x

x

f (x, y) + ∑

y

f (x, y)

= ∑

x fX(x) + ∑

y fY(y)

x

y

= EX + EY.

Para o caso contínuo, temos:

E(X + Y) =

=

(cid:90) ∞

(cid:90) ∞

−∞
(cid:90) ∞

−∞
(cid:90) ∞

−∞

−∞
(cid:90) ∞

(x + y) f (x, y)dxdy

x f (x, y)dydx +

(cid:90) ∞

(cid:90) ∞

−∞

−∞

y f (x, y)dxdy

=

x fX(x)dx +

y fY(y)dy

−∞
= EX + EY.

(cid:90) ∞

−∞

Teorema 1.39. Sejam X e Y variáveis aleatórias independentes, então

E(XY) = EX · EY.

Demonstração. Tome na Deﬁnição 1.34 g(X, Y) = XY.

Para o caso discreto, temos:

E(XY) = ∑

x

= ∑

x

∑
y
∑
y

xy f (x, y)

xy fX(x) fY(y)

= ∑

x fX(x) ∑

y fY(y)

x
= EX · EY.

y

35

F U N D A M E N TA Ç Ã O T E Ó R I C A

Para o caso contínuo, temos:

E(XY) =

=

=

(cid:90) ∞

(cid:90) ∞

−∞
(cid:90) ∞

−∞
(cid:90) ∞

xy f (x, y)dxdy

xy fX(x) fY(y)dxdy

−∞

(cid:90) ∞

y fY(y)

x fX(x)dxdy

−∞
(cid:90) ∞

−∞
(cid:90) ∞

−∞

(cid:90) ∞

−∞

=

x fX(x)dx

y fY(y)dy

−∞
= EX · EY.

Podemos generalizar o Teorema 1.39.

Considere as variáveis aleatórias X1, . . . , Xn, mutuamente independentes. Então,

E(X1, . . . , Xn) = EX1 · · · · · EXn.

(1.56)

1.7.2 Covariância e correlação

A covariância é uma medida da relação linear entre as variáveis aleatórias X e Y.

Deﬁnição 1.40. A covariância de duas variáveis aleatórias é um número deﬁnido por

Cov(X, Y) = E[(X − EX)(Y − EY)].

Podemos simpliﬁcar o cálculo da covariância.

Cov(X, Y) = E[(X − EX)(Y − EY)]

= E[XY − XEY − YEX + EX · EY]

= E(XY) − EX · EY − EY · EX + EX · EY

= E(XY) − EX · EY.

(1.57)

A correlação é uma medida que não depende das unidades de medida das variáveis

aleatórias X e Y.

Deﬁnição 1.41. A correlação de duas variáveis aleatórias é um número deﬁnido por

ρXY =

√

Cov(X, Y)
Var(X)Var(Y)

.

36

1.7 VA R I Á V E I S A L E AT Ó R I A S M Ú LT I P L A S

Teorema 1.42. Se as variáveis aleatórias X e Y são independentes, então Cov(X, Y) = 0
e ρXY = 0.

Demonstração. Pela Teorema 1.39 temos

E(XY) = EX · EY

e, portanto, da Equação (1.57), obtemos

Cov(X, Y) = EX · EY − EX · EY = 0

e

ρXY =

√

Cov(X, Y)
Var(X)Var(Y)

=

√

0
Var(X)Var(Y)

= 0.

Teorema 1.43. Sejam X e Y duas variáveis aleatórias, e a e b constantes, então

Var(aX + bY) = a2Var(X) + b2Var(Y) + 2abCov(X, Y).

Demonstração. A demonstração foi extraída de [1].

Do Teorema 1.23 temos

E(aX + bY) = aEX + bEY.

Logo, pela Deﬁnição 1.15,

Var(aX + bY) = E[(aX + bY) − (aEX + bEY)]2

= E[a(X − EX) + b(Y − EY)]2

= E[a2(X − EX)2 + b2(Y − EY)2 + 2ab(X − EX)(Y − EY)]

= a2E(X − EX)2 + b2E(Y − EY)2 + 2abE[(X − EX)(Y − EY)]

= a2Var(X) + b2Var(Y) + 2abCov(X, Y).

Se as variáveis aleatórias X e Y são independentes, então Cov(X, Y) = 0 e, portanto,

Var(aX + bY) = a2Var(X) + b2Var(Y).

37

F U N D A M E N TA Ç Ã O T E Ó R I C A

1.8 F U N Ç Õ E S G E R AT R I Z E S D E M O M E N T O S

A função geratriz de momentos (f.g.m.) é uma função associada à distribuição de

probabilidade, auxiliando a caracterizá-la.

Deﬁnição 1.44. A função geratriz de momentos de uma variável aleatória X, denotada

por MX(t), para todos os valores reais de t, como

MX(t) = EetX =






∑x etX P(X = x),
(cid:82) ∞
−∞ etX fX(x)dx,

se X for discreta;

se X for contínua.

Os momentos da variável aleatória X podem ser obtidos das sucessivas derivadas de

MX(t) avaliada em t = 0, como no teorema a seguir.

Teorema 1.45. Se X é uma variável aleatória e possui um f.g.m. MX(t), então

EXn = M(n)

X (0).

(1.58)

Deﬁnimos

M(n)

X (0) =

dn
dtn MX(t)|t=0.

Demonstração. No caso discreto, consideramos que

d
dt

∑
x

etxP(X = x) = ∑

x

(cid:19)

etx

(cid:18) d
dt

P(X = x).

Logo,

d
dt

MX(t) =

d
dt

∑
x

etxP(X = x) = ∑

x

(cid:19)

(cid:18) d
dt

etxP(X = x) = ∑

(cid:0)xetx(cid:1) P(X = x) = EXetx.

x

No caso contínuo, assumindo como legítima a hipótese de diferenciar sob o sinal da

integral, temos

Então,

d
dt

(cid:90) ∞

−∞

etx fX(x)dx =

(cid:90) ∞

−∞

(cid:19)

etx

(cid:18) d
dt

fX(x)dx.

d
dt

MX(t) =

d
dt

(cid:90) ∞

−∞

etx fX(x)dx =

(cid:90) ∞

−∞

(cid:19)

etx

(cid:18) d
dt

fX(x)dx =

(cid:90) ∞

−∞

(cid:0)xetx(cid:1) fX(x)dx = EXetx.

Portanto,

Analogamente, temos

d
dt

MX(t)|t=o= EXetx|t=o= EX.

dn
dtn MX(t)|t=o= EXnetx|t=o= EXn.

38

Teorema 1.46. Para a e b constantes, a f.g.m. da variável aleatória aX + b é dada por

1.8 F U N Ç Õ E S G E R AT R I Z E S D E M O M E N T O S

MaX+b(t) = ebt MX(at).

Demonstração.

MaX+b(t) = E

(cid:16)

e(aX+b)t(cid:17)

(cid:16)

eaXtebt(cid:17)

.

= E

Como ebt é uma constante, segue do Teorema 1.23, que
eaXt(cid:17)

MaX+b(t) = ebtE

(cid:16)

.

Da deﬁnição de f.g.m., temos

MaX+b(t) = ebt MX(at).

A seguir são dados exemplos da f.g.m. de algumas distribuições.

Exemplo 1.3. F.g.m. da distribuição binomial.

Seja X ∼ Binomial(n, p), sua f.p. é dada por

P(X = x) =

(cid:19)

(cid:18)n
x

px(1 − p)n−x.

Então,

MX(t) =

etx

(cid:19)

(cid:18)n
x

n
∑
x=0

px(1 − p)n−x =

(cid:19)

(cid:18)n
x

n
∑
x=0

(pet)x(1 − p)n−x.

Do Teorema 1.24, obtemos

MX(t) = [pet + (1 − p)]n.

Exemplo 1.4. F.g.m. da distribuição de Poisson.

Seja X ∼ Poisson(λ), sua f.p. é dada por

Então,

P(X = x|λ) =

e−λλx
x!

.

MX(t) =

∞
∑
x=0

etx e−λλx
x!

= e−λ

∞
∑
x=0

(λet)x
x!

.

39

F U N D A M E N TA Ç Ã O T E Ó R I C A

De (1.30) temos,

Portanto,

ex =

∞
∑
i=0

xi
i!

.

MX(t) = e−λeλet

= exp (cid:8)λ(et − 1)(cid:9) .

Exemplo 1.5. F.g.m. da distribuição normal.

Seja Z ∼ N(0, 1), sua f.d.p. é dada por

Então,

MZ(t) =

1
√

(cid:90) ∞

−∞

2π
Adicionando e subtraindo t2

1
√

2π

(cid:90) ∞

−∞

(cid:26)

exp

MZ(t) =

Logo,

Como, de (1.40)

Segue que,

Φ(z) =

1
√

2π

−z2
2 .

e

etze

−z2
2 dz =

1
√

2π

(cid:90) ∞

−∞

exp

(cid:26)

−

z2
2

(cid:27)

+ tz

dz.

2 , obtemos,
t2
z2
2
2

+ tz −

−

(cid:27)

+

t2
2

dz =

1
√

2π

(cid:90) ∞

−∞

(cid:26)

exp

−

(z − t)2
2

+

t2
2

(cid:27)

dz.

MZ(t) = e

t2
2

1
√

2π

(cid:90) ∞

−∞

e− (z−t)2

2 dz.

1
√

2π

(cid:90) ∞

−∞

e− z2

2 dz = 1.

MZ(t) = e

t2
2 .

(1.59)

Para obtermos X ∼ N(µ, σ2) basta fazer X = µ + σZ, então,

MX(t) = EetX

= Eet(µ+σZ)
(cid:16)

etµetσZ(cid:17)

= E

Do Teorema 1.46, segue que

MX(t) = etµE

(cid:16)

etσZ(cid:17)
= etµ MZ(tσ)
= etµe

(tσ)2
2
(cid:26)

(cid:27)

.

σ2t2
2

= exp

µt +

40

1.8 F U N Ç Õ E S G E R AT R I Z E S D E M O M E N T O S

Exemplo 1.6. F.g.m. da distribuição exponencial.

Seja X ∼ Exp(λ), sua f.d.p. é dada por

fX(x|λ) = λe−λx, para todo x (cid:62) 0.

Então,

Portanto,

MX(t) = λ

(cid:90) ∞

0

etxe−λxdx = λ

(cid:90) ∞

0

e−(λ−t)xdx =

λ
λ − t

e−(λ−t)x|∞
0 .

MX(t) =

λ
λ − t

, para t < λ .

Exemplo 1.7. F.g.m. da distribuição gama.

Seja X uma variável aleatória com distribuição gama, sua f.d.p. é dada por

fX(x) =

λe−λx(λx)α−1
Γ(α)

, para todo x (cid:62) 0.

Então,

MX(t) =

λ
Γ(α)

(cid:90) ∞

0

etxe−λx(λx)α−1dx =

λα
Γ(α)

(cid:90) ∞

0

e−(λ−t)xxα−1dx.

Fazendo u = (λ − t)x, obtemos du = (λ − t)dx, então,

MX(t) =

λα
Γ(α)

(cid:90) ∞

0

e−u

(cid:18) u

λ − t

(cid:19)α−1 du
λ − t

=

(cid:18) λ

λ − t

(cid:19)α 1
Γ(α)

(cid:90) ∞

0

e−uuα−1du.

De (1.49), temos,

Portanto,

Γ(α) =

(cid:90) ∞

0

e−uuα−1du.

MX(t) =

(cid:18) λ

(cid:19)α

λ − t

, para t < λ .

41

F U N D A M E N TA Ç Ã O T E Ó R I C A

Teorema 1.47. Sejam X e Y variáveis aleatórias independentes, que possuam f.g.m.

MX(t) e MY(t), respectivamente, tais que Z = X + Y. Então,

MZ(t) = MX(t)MY(t).

MZ(t) = E(et(X+Y) = E(etXetY).

Demonstração.

Do Teorema 1.39, temos,

MZ(t) = E(etX)E(etY) = MX(t)MY(t).

Podemos generalizar o Teorema 1.47.

Considere as variáveis aleatórias X1, . . . , Xn, mutuamente independentes, tais que

Z = X1 + · · · + Xn. Então,

MZ(t) = MX1(t) · · · · · MXn(t).

(1.60)

Em particular, se todos os X1, . . . , Xn têm a mesma distribuição com f.g.m. MX(t).
Então,

MZ(t) = [MX(t)]n.

(1.61)

42

2

I N F E R Ê N C I A E S TAT Í S T I C A

O ramo da estatística que faz uso de uma amostra para fazer aﬁrmações sobre carac-

terísticas de uma população, tendo como ferramenta a probabilidade, é o da inferência

estatística.

2.1 C O N C E I T O S I N I C I A I S

2.1.1 População e amostra

A seguir serão apresentadas as deﬁnições de população e amostra, importantes no

desenvolvimento deste trabalho.

Deﬁnição 2.1. Uma população é um conjunto de todos os elementos ou resultados

de uma característica de interesse. Um subconjunto de uma população é dita uma

amostra.

2.1.2 Amostras aleatórias simples

A amostragem aleatória simples (a.a.s.) é um modo para selecionar uma amostra de

uma população, de tal forma que todos os elementos da população, em um processo

aleatório de seleção, tenham a mesma probabilidade de serem selecionados.

No decorrer deste trabalho, serão consideradas as amostragens aleatórias simples

com reposição, ou seja, uma amostra retirada tem a possibilidade de ser sorteada no-

vamente, de modo que se tenha uma independência entre os elementos selecionados.

43

I N F E R Ê N C I A E S TAT Í S T I C A

A redação da Deﬁnição 2.2 é dada por [1].

Deﬁnição 2.2. As variáveis aleatórias X1, . . . , Xn são chamadas amostra aleatória sim-
ples de tamanho n de uma população f (x) se X1, . . . , Xn forem variáveis aleatórias mu-
tuamente independentes e a f.d.p. ou f.p. marginal de cada Xi for a mesma função
f (x). De modo alternativo, X1, . . . , Xn são chamadas variáveis aleatórias independentes
e identicamente distribuídas, com f.d.p. ou f.p. f (x). Isto é comumente abreviado como

variáveis aleatórias (i.i.d.).

2.1.3 Diferenciando estatística de parâmetro

Obtida uma amostra X1, . . . , Xn, geralmente calculamos uma função T(X1, . . . , Xn)

cujo domínio inclui todo o espaço amostral de (X1, . . . , Xn).

Deﬁnição 2.3. Dada uma amostra aleatória de tamanho n, X1, . . . , Xn, uma estatística
é uma variável aleatória, ou um vetor aleatório Y = T(X1, . . . , Xn), sendo T(X1, . . . , Xn)
uma função com valor real ou por vetor, cujo domínio inclui todo o espaço amostral

de (X1, . . . , Xn).

A variável aleatória, ou vetor aleatório Y = T(X1, . . . , Xn) descreve uma caracterís-

tica da amostra.

As estatísticas mais utilizadas são: a média amostral, a variância amostral e o desvio

padrão amostral, deﬁnidas a seguir.

Deﬁnição 2.4. A média amostral é a média aritmética dos valores em uma variável

aleatória.

¯X =

X1 + · · · + Xn
n

=

1
n

n
∑
i=1

Xi.

Deﬁnição 2.5. A variância amostral é deﬁnida por

S2 =

1
n − 1

n
∑
i=1

(Xi − ¯X)2.

O desvio padrão amostral é deﬁnido por S =

√

S2.

Deﬁnição 2.6. Um parâmetro descreve uma característica populacional.

Os parâmetros média e variância, de uma variável aleatória X, serão denotados,

respectivamente, por EX e Var(X).

44

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

Dada uma população X, estamos interessados em se aﬁrmar algo sobre um parâme-
tro θ. Retiramos, então, amostras X1, . . . , Xn de tamanho n por meio de uma determi-
nada técnica de amostragem.

Para cada amostra, obtemos um valor t para a estatística T = f (X1, . . . , Xn), que
é uma função da amostra. Todos os valores de t formam uma nova população, e

baseados nesta nova população que fazemos aﬁrmações sobre o parâmetro θ.

A distribuição de T quando (X1, . . . , Xn) assume todos os valores possíveis é cha-

mada distribuição amostral da estatística T.

2.2.1 Distribuição amostral da média

Para calcular o valor esperado e a variância da média, precisamos do lema a seguir.

Lema 2.7. Seja X1, . . . , Xn uma amostra aleatória simples de tamanho n de uma popu-
lação X e g(X) uma função tal que existam Eg(Xi) e Varg(Xi), com i = 1, . . . , n. Então,

e

(cid:32) n
∑
i=1

E

Var

(cid:32) n
∑
i=1

(cid:33)

g(Xi)

= n (Eg(X1))

(cid:33)

g(Xi)

= n (Varg(X1)) .

(2.1)

(2.2)

Demonstração. Inicialmente provaremos (2.1).

Como X1, . . . , Xn são variáveis aleatórias identicamente distribuídas, então Eg(Xi) é

a mesma para todo i. Logo,

Portanto,

n
∑
i=1

Eg(Xi) = n(Eg(X1)).

(cid:32) n
∑
i=1

E

(cid:33)

g(Xi)

=

n
∑
i=1

Eg(Xi) = n(Eg(X1)).

A independência de X1, . . . , Xn não é necessária para que (2.1) se mantenha.

45

I N F E R Ê N C I A E S TAT Í S T I C A

Para provar (2.2), temos, pela Equação (1.15),
(cid:34) n
∑
i=1

(cid:32) n
∑
i=1

(cid:32) n
∑
i=1

g(Xi) − E

g(Xi)

g(Xi)

Var

= E

(cid:33)

(cid:33)(cid:35)2

= E

(cid:34) n
∑
i=1

(cid:35)2

(g(Xi) − Eg(Xi))

.

Temos, na última igualdade n2 termos. Sendo n termos [g(Xi) − Eg(Xi)]2 e n(n − 1)

termos [g(Xi) − Eg(Xi)][g(Xj) − Eg(Xj)], com i (cid:54)= j.

Pela Deﬁnição 1.40 e pelo o fato de X1, . . . , Xn serem variáveis aleatórias indepen-

dentes, temos

E[(g(Xi) − Eg(Xi))(g(Xj) − Eg(Xj))] = Cov(g(Xi), g(Xj)) = 0.

Pela Equação (1.15) e pelo o fato de X1, . . . , Xn serem variáveis aleatórias identica-

mente distribuídas, temos

E[g(Xi) − Eg(Xi)]2 = Var(Xi) = Var(X1).

Obtendo, assim, a Equação (2.2).

Teorema 2.8. Seja X1, . . . , Xn uma amostra aleatória simples de tamanho n de uma
população X com EX = µ e Var(X) = σ2 < ∞. Temos, então,

e

E ¯X = µ

Var( ¯X) =

σ2
n

(2.3)

(2.4)

Demonstração. Pela Deﬁnição 2.4, temos

¯X =

1
n

n
∑
i=1

Xi.

Para provar (2.3) temos, pelo Teorema 1.23 e pela Equação (2.1),

E ¯X = E

(cid:32)

1
n

n
∑
i=1

(cid:33)

Xi

=

1
n

E

(cid:32) n
∑
i=1

(cid:33)

Xi

=

1
n

nEX1 = µ.

Para provar (2.4) temos, pelo Teorema 1.30 e pela Equação (2.2),
(cid:33)

(cid:33)

(cid:32)

Var( ¯X) = Var

Xi

=

1
n

n
∑
i=1

1
n2 Var

(cid:32) n
∑
i=1

Xi

=

1
n2 nVar(X1) =

σ2
n

.

O desvio padrão da distribuição amostral da média, ou erro padrão da média, deno-

tado por σ ¯X, é

46

σ ¯X =

σ
√
n

.

(2.5)

2.2.2 Distribuição normal da média

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

Para encontrar a distribuição normal da média, o teorema a seguir e as funções

geratrizes de momentos mostram-se úteis.

Teorema 2.9. Seja X1, . . . , Xn uma amostra aleatória simples de tamanho n de uma
população X com média ¯X = 1

n (X1 + · · · + Xn) e f.g.m. MX(t). Então,

M ¯X(t) = [MX(t/n)]n.

Demonstração. Considere Y = X1 + · · · + Xn, então pela Deﬁnição 1.44 temos,

M ¯X(t) = Eet ¯X = Eet( 1

n )(X1+···+Xn) = Ee

t

n Y = MY(t/n).

Sendo X1, . . . , Xn identicamente distribuídas, temos

MX1(t/n) = · · · = MXn(t/n).

Então, pela Equação (1.61) segue que,

E, portanto,

MY(t/n) = [MX(t/n)]n.

M ¯X(t) = [MX(t/n)]n.

Teorema 2.10. Seja X1, . . . , Xn uma amostra aleatória simples de tamanho n de uma
população normal N(µ, σ2). Então,

¯X ∼ N

(cid:18)

µ,

(cid:19)

.

σ2
n

Demonstração. Do Exemplo 1.5 e do Teorema 2.9 temos,

(cid:40)

(cid:40)

M ¯X(t) =

exp

µ

t
n

+

(cid:40)

(cid:40)

= exp

n

µ

t
n

(cid:1)2

σ2 (cid:0) t
n
2
σ2 (cid:0) t
n
2

+

(cid:41)(cid:41)n

(cid:1)2

(cid:41)(cid:41)

(cid:26)

= exp

µt +

(cid:27)

.

σ2t2
2n

(2.6)

47

I N F E R Ê N C I A E S TAT Í S T I C A

Calculando a primeira e a segunda derivadas, obtemos,

M(cid:48)

X(t) =

(cid:18)

µ +

σ2t
n

(cid:19)

(cid:26)

exp

µt +

(cid:27)

σ2t2
2n

e

Então,

e

M(cid:48)(cid:48)

X(t) =

(cid:18)

µ +

σ2t
n

(cid:19)2

(cid:26)

exp

µt +

σ2t2
2n

(cid:27)

(cid:19)

(cid:18) σ2
n

+

(cid:26)

exp

µt +

(cid:27)

.

σ2t2
2n

EX = M(cid:48)

X(0) = µ

EX2 = M(cid:48)(cid:48)

X(0) = µ2 +

σ2
n

.

E a variância é dada por

Var(X) = EX2 − (EX)2 = µ2 +

σ2
n

− µ2 =

σ2
n

.

O que prova o resultado.

2.2.3 Teorema do Limite Central

O Teorema do Limite Central aproxima grandes amostras da distribuição amostral

da média a uma distribuição normal, o que justiﬁca o uso da curva normal em diversas

situações.

Antes de demonstrar o Teorema do Limite Central precisamos do seguinte lema.

Lema 2.11. Seja a1, . . . , an uma sequência de números tal que limn→∞ an = a. Então

lim
n→∞

(cid:16)

1 +

(cid:17)n

an
n

= ea.

Demonstração. Seja

(cid:16)

1 +

L = lim
n→∞

Neste caso, temos uma indeterminação do tipo 1
la numa indeterminação do tipo ∞/∞. Então,

(cid:17)n

an
n
∞. Usando logaritmos, vamos transformá-

ln L = ln

(cid:104)

(cid:16)

1 +

lim
n→∞
(cid:104)

(cid:16)

ln

= lim
n→∞
n→∞ n ln

= lim

1 +
(cid:16)

1 +

(cid:17)n(cid:105)

(cid:17)n(cid:105)

(cid:17)

an
n
an
n
an
n

= lim
n→∞

ln (1 + an/n)
(1/n)

.

48

Temos agora, uma indeterminação do tipo ∞/∞. Aplicando a regra de L’Hospital,

obtemos

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

ln L = lim
n→∞

−(an/n2)/(1 + an/n)
−(1/n2)

an
1 + an/n

= lim
n→∞

= a.

Dessa forma, L = ea e, portanto,

lim
n→∞

(cid:16)

1 +

(cid:17)n

an
n

= ea.

Teorema 2.12 (Teorema do Limite Central). Sejam X1, . . . , Xn variáveis aleatórias i.i.d.,
tais que as f.g.m., MXi (t), existam para |t|< h, h > 0. Sejam EXi = µ e Var(Xi) = σ2 > 0,
ambos ﬁnitos. Deﬁna ¯Xn = 1
n

∑n
(cid:18) √

i=1 Xi. Então, para qualquer x ∈ R,
(cid:19)
n ( ¯Xn − µ)
σ

1
√

< x

(cid:90) x

−y2
2 dy.

−∞

=

e

2π

n→∞ P
lim

Demonstração. Mostraremos que, para |t|< h, a f.g.m. de
para a f.g.m. de X ∼ N(0, 1).

√

n ( ¯Xn − µ) /σ converge

Deﬁna X∗
√

i = (Xi − µ) /σ e seja MX∗(t) a f.g.m. comum à X∗
∑n

√

n (cid:0) 1

(∑n

i . Temos,

n ( ¯Xn − µ)
σ

=

n

i=1 Xi − µ(cid:1)
∑n
σ

=

i=1 Xi − nµ)
nσ

√

=

i=1 (Xi − µ)
nσ

√

=

1
√
n

n
∑
i=1

X∗
i .

Então, a f.g.m. de

√

i=1 X∗
n ( ¯Xn − µ) /σ é igual à f.g.m. de ∑n
i /
√

√

n.

Basta mostrar que, para |t|< h, a f.g.m. de ∑n

i=1 X∗
i /

n converge para a f.g.m. de

X ∼ N(0, 1).

Pelo Teorema 1.46 e pela Equação (1.61), temos

M∑n

i=1 X∗
i /

√

n(t) = M∑n

i=1 X∗
i

(cid:18) t
√

n

(cid:19)

(cid:20)

=

MX∗

(cid:18) t
√

n

(cid:19)(cid:21)n

.

Expandindo MX∗ (cid:0)t/

√

n(cid:1), em uma série de Taylor em torno de 0, obtemos

MX∗

(cid:18) t
√

n

(cid:19)

=

∞
∑
k=0

M(k)

X∗(0)

(cid:0)t/

√

k!

n(cid:1)k

.

Uma vez que, por construção, a média e a variância são, respectivamente 0 e 1,

obtemos,

MX∗ = 1,

49

I N F E R Ê N C I A E S TAT Í S T I C A

e

Então,

MX∗

onde deﬁnimos RX∗(t/
de Taylor.

√

M(cid:48)

X∗ = 0

M(cid:48)(cid:48)

X∗ = 1.

(cid:19)

(cid:18) t
√

n

= 1 +

n(cid:1)2

(cid:0)t/

√

2!

+ RX∗

(cid:18) t
√

(cid:19)

,

n

n) como sendo o termo restante da aproximação do polinômio

Como M(k)

X∗(0) = dk

dxk MX∗(t)|t=0 existe, e admitindo a utilização do Teorema de Taylor,

então, para qualquer t (cid:54)= 0 ﬁxo, obtemos o seguinte resultado:

RX∗(t/
√
(cid:0)t/

√
n)
n(cid:1)2 = 0.

lim
n→∞

E, em particular, para t = 1,

RX∗(1/
√
(cid:0)1/

√
n)
n(cid:1)2 = lim

n→∞ nRX∗

(cid:19)

(cid:18) 1
√
n

= 0.

lim
n→∞

Para t = 0, temos RX∗(0/

√

n) = 0.

Logo, para todo t ∈ R, temos

(cid:20)

lim
n→∞

MX∗

(cid:19)(cid:21)n

(cid:18) t
√

n

= lim
n→∞

1 +

(cid:34)

(cid:20)

= lim
n→∞

1 +

√

(cid:0)t/

n(cid:1)2

(cid:18) t
√

+ RX∗

2!
(cid:18) t2
2

1
n

+ nRX∗

(cid:18) t
√

n

(cid:19)(cid:35)n

n
(cid:19)(cid:19)(cid:21)n

.

Fazendo [(t2/2) + nRX∗(t/

√

n)] = an no Lema 2.11, obtemos

(cid:20)

lim
n→∞

MX∗

(cid:19)(cid:21)n

(cid:18) t
√

n

t2
2

= e

que é a f.g.m. de X ∼ N(0, 1), o que prova o resultado.

2.2.4 Aproximação normal para a distribuição binomial

O Teorema a seguir nos diz que quando n é grande, X ∼ Binomial(n, p) tem aproxi-

madamente a mesma distribuição que X ∼ N(np, np(1 − p)).

50

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

Teorema 2.13. (Teorema Limite de DeMoivre e Laplace) Seja Sn o número de sucessos
em n tentativas individuais, cada uma com probabilidade p de sucesso, então para a < b

(cid:40)

n→∞ P
lim

a (cid:54) Sn − np
(cid:112)np(1 − p)

(cid:41)

(cid:54) b

= Φ(b) − Φ(a).

Demonstração. Este teorema é um caso particular do Teorema do Limite Central.
(cid:41)

(cid:40)

n→∞ P
lim

a (cid:54) Sn − np
(cid:112)np(1 − p)

(cid:54) b

=

(cid:90) b

1
√

a

2π

−z2
2 dz = Φ(b) − Φ(a).

e

Figura 3: Probabilidade binomial exata

Fonte: Arquivo próprio do autor, baseado em [8].

Quando aproximamos uma distribuição normal contínua para uma distribuição bi-

nomial, que é discreta, devemos fazer uma correção pela continuidade, que consiste

em mover 0, 5 unidade tanto à esquerda quanto à direita, a ﬁm de incluir todos os

valores possíveis de x no intervalo.

Figura 4: Aproximação normal da binomial

Fonte: Arquivo próprio do autor, baseado em [8].

Assim, escrevemos a distribuição binomial P(X = i) como P(i − 0, 5 < X < i + 0, 5)

ao aproximar da normal.

51

I N F E R Ê N C I A E S TAT Í S T I C A

Podemos fazer tal aproximação quando np (cid:62) 5 e n(1 − p) (cid:62) 5.

2.2.5 Distribuição amostral de uma proporção

Considerando uma população tal que p é a proporção de elementos com uma deter-

minada característica, deﬁnimos a variável aleatória X a seguir,

X =




1,



0,

se o elemento for portador da característica

se o elemento não for portador da característica.

Retirada uma amostra aleatória, com reposição, e denotando por Sn o total de ele-

mentos portadores da característica, temos,

Sn =

n
∑
i=1

Xi, com i = 1, . . . , n.

onde cada Xi, tem distribuição de Bernoulli, com média µ = p e variância σ2 = p(1 − p),
independentes duas a duas, então,

Sn = n ¯X.

Pelo Teorema do Limite Central, temos,

Logo,

¯X ∼ N

(cid:18)

p,

p(1 − p)
n

(cid:19)

.

Sn ∼ N(np, np(1 − p)).

(2.7)

(2.8)

Denotando por ˆp a proporção de elementos portadores da característica na amostra,

obtemos,

Dessa forma,

52

ˆp =

Sn
n

.

(2.9)

P(Sn = k) = P(Sn/n = k/n) = P( ˆp = k/n).

E como, ¯X = ˆp, temos,

2.2 D I S T R I B U I Ç Õ E S A M O S T R A I S

ˆp ∼ N

(cid:18)

p,

p(1 − p)
n

(cid:19)

.

(2.10)

2.2.6 Distribuição da variância da amostral

A variância amostral, deﬁnida em 2.5, é uma estatística. Podemos calcular ES2.

Para calcular ES2 precisamos do teorema a seguir.

Teorema 2.14. Sejam x1, . . . , xn números reais e ¯x = x1+···+xn

n

, Então,

n
∑
i=1

(xi − ¯x)2 =

n
∑
i=1

x2
i − n ¯x2.

(2.11)

Demonstração. Tome ∑n

i=1 x2

i e adicione e subtraia ¯x. Obtendo, dessa forma,

n
∑
i=1

x2
i =

n
∑
i=1

(xi − ¯x + ¯x)2 =

n
∑
i=1

(xi − ¯x)2 + 2

n
∑
i=1

(xi − ¯x) ¯x +

n
∑
i=1

¯x2.

Observando que ∑n

i=1(xi − ¯x) = 0 e que ∑n

i=1 ¯x2 = n ¯x2, obtemos (2.11)

Teorema 2.15. Sejam X1, . . . , Xn uma amostra aleatória simples de tamanho n de uma
população X com EX = µ e Var(X) = σ2 < ∞. Então, a variância amostral é dada por

ES2 = σ2.

(2.12)

Demonstração. Pela Deﬁnição 2.5, e do Teorema 2.14, temos

ES2 = E

(cid:32)

1
n − 1

n
∑
i=1

(cid:33)

(cid:32)

(Xi − ¯X)2

= E

1
n − 1

(cid:34) n
∑
i=1

(cid:35)(cid:33)

X2

i − n ¯X2

=

1
n − 1

(cid:0)nEX2

1 − nE ¯X2(cid:1) .

Da Equação (1.16), obtemos

E(X2) = Var(X) − (EX)2.

Logo, de (2.3) e (2.4),

ES2 =

(cid:20)

1
n − 1

n(σ2 + µ2) − n

(cid:18) σ2
n

(cid:19)(cid:21)

+ µ2

= σ2.

53

I N F E R Ê N C I A E S TAT Í S T I C A

2.3 E S T I M A D O R E S

Seja X1, . . . , Xn uma amostra de uma população com f.p. ou f.d.p.

f (x|θ), temos a

seguinte deﬁnição.

Deﬁnição 2.16. O estimador pontual T de um parâmetro θ é qualquer função g(X1, . . . , Xn)
de uma amostra, ou seja, T = g(X1, . . . , Xn).

Um estimador é uma estatística associada a um parâmetro.

Uma estimativa é um valor observado de um estimador.

Deﬁnição 2.17. Uma estatística T = g(X1, . . . , Xn) é suﬁciente para θ, quando a distri-
buição condicional de X1, . . . , Xn, dado T for independente de θ.

2.3.1 Estimadores de Momentos

Seja X1, . . . , Xn uma amostra de uma população X com f.p. ou f.d.p. f (x|θ1, . . . , θk),

dependendo de k parâmetros, temos as seguintes deﬁnições:

Deﬁnição 2.18. Deﬁnimos o k-ésimo momento amostral por

mk =

1
n

n
∑
i=1

Xk

i , com k = 1, . . . , n.

Deﬁnição 2.19. Dizemos que ˆθ1, . . . , ˆθk são estimadores obtidos pelo método dos mo-
mentos se eles forem solução do seguinte sistema de equações.

m1 = µ(cid:48)

1(θ1, . . . , θk),

m2 = µ(cid:48)

2(θ1, . . . , θk),

...

mk = µ(cid:48)

k(θ1, . . . , θk).

Exemplo 2.1. Método dos momentos da normal.

Seja X ∼ N(µ, σ2), então θ1 = µ e θ2 = σ2. Temos, µ(cid:48)
∑n

i=1 Xi = ¯X e m2 = 1
n

i . Então,

i=1 X2

∑n

m1 = 1
n

1 = EX = µ, µ(cid:48)

2 = EX2 = σ2 + µ2,

¯X = µ

54

2.3 E S T I M A D O R E S

e

1
n

n
∑
i=1

X2

i = σ2 + µ2.

Os estimadores obtidos pelo método dos momentos serão

ˆµM = ¯X

e

M = m2 − m2
ˆσ2

1 =

1
n

n
∑
i=1

X2

i − ¯X2 =

1
n

n
∑
i=1

(Xi − ¯X)2 .

2.3.2 Estimadores de máxima verossimilhança

Seja X1, . . . , Xn uma amostra i.i.d. de uma população X com f.p. ou f.d.p. f (x|θ1, . . . , θk),

temos a seguinte deﬁnição.

Deﬁnição 2.20. A função de verossimilhança é deﬁnida por

L(θ|x) = L(θ1, . . . , θk|x1, . . . , xn) =

n
∏
i=1

f (xi|θ1, . . . , θk).

Exemplo 2.2. Exemplo extraído de [17].

Verossimilhança da média de uma distribuição normal com variância conhecida.

Seja X ∼ N(µ, σ2), com σ conhecido e µ desconhecido, a função de verossimilhança

de µ é

L(µ) = f (x|µ) =

n
∏
i=1

1
σ(cid:112)2µ

e

(cid:32)

−(xi −µ)2
2σ2

=

1
σ(cid:112)2µ

(cid:33)n

− ∑ (xi −µ)2
2σ2

e

.

Essa função tem valor máximo quando

g(µ) =

1
2σ2

n
∑
i=1

(xi − µ)2

é mínimo. Derivando e fazendo g(cid:48)(µ) = 0, obtemos

g(cid:48)(µ) = −

1
2σ2

n
∑
i=1

2(xi − µ) = 0.

55

I N F E R Ê N C I A E S TAT Í S T I C A

De onde

n
∑
i=1

xi − nµ = 0.

Consequentemente,

n
∑
i=1
é o valor crítico de µ. Desde que g(cid:48)(cid:48)(µ) = n/σ2 > 0, a função g tem um mínimo e a
função L, um máximo em ˆµ = ¯xn.

xi = ¯xn.

µ =

1
n

2.3.3 Erro quadrático médio

Deﬁnição 2.21. O erro quadrático médio (EQM) de um estimador T de um parâmetro
θ é a função de θ deﬁnida por Eθ(T − θ)2.

Deﬁnimos a tendência de um estimador T do seguinte modo.

Deﬁnição 2.22. O viés de um estimador T de um parâmetro θ é vi ´esθ T = Eθ T − θ, ou
seja, é a diferença entre o valor esperado de T e θ. Um estimador T é não-viesado se
Eθ T = θ, e seu viés é igual a zero.

Da Deﬁnição 2.21, e adicionando e subtraindo Eθ T, temos

Eθ(T − θ)2 = Eθ(T − Eθ T + Eθ T − θ)2

= Eθ(T − Eθ T)2 + 2Eθ[(T − Eθ T)(Eθ T − θ)] + Eθ(Eθ T − θ)2.

Como Eθ T − θ é uma constante e Eθ(T − Eθ T) = 0, obtemos

Eθ(T − θ)2 = Eθ(T − Eθ T)2 + Eθ(Eθ T − θ)2.

Das Deﬁnições 1.15 e 2.22, segue

Eθ(T − θ)2 = Varθ(T) − vi ´esθ T.

Se um estimador T é não-viesado, seu EQM é igual a sua variância, ou seja,

Eθ(T − θ)2 = Varθ(T).

56

2.4 I N T E R VA L O S D E C O N F I A N Ç A

∑N

Exemplo 2.3. Seja X uma população de tamanho N com variância populacional
i=1(Xi − µ)2, com média populacional µ = 1
σ2 = 1
i=1 Xi. Extraída uma amos-
N
N
i=1(Xi − ¯X)2, é um possível
tra aleatória simples de tamanho n, temos que σ2 = 1
n
estimador para σ2.

∑N

∑n

Queremos mostrar que este estimador é viesado, para tal, procedemos de maneira

análoga à utilizada no Teorema 2.15.

Do Teorema 2.14, temos

E(σ2) = E

(cid:32)

1
n

n
∑
i=1

(cid:33)

(cid:32)

(Xi − ¯X)2

= E

(cid:34) n
∑
i=1

1
n

X2

i − n ¯X2

(cid:35)(cid:33)

=

1
n

(cid:0)nEX2 − nE ¯X2(cid:1) .

Então,

E(σ2) =

(cid:20)

1
n

n(σ2 + µ2) − n

(cid:18) σ2
n

(cid:19)(cid:21)

+ µ2

=

n − 1
n

σ2.

Portanto, σ2 é um estimador viesado.

Como E ¯X = µ e ES2 = σ2, temos que ¯X e S2 são estimadores não-viesados para µ e
σ2, respectivamente. Por essa razão, escrevemos n − 1 no denominador da variância
amostral.

Com o objetivo de se encontrar o melhor estimador não-viesado, temos a seguinte

deﬁnição.

Deﬁnição 2.23. Dados dois estimadores não-viesados, T e T∗, de um mesmo parâme-
tro θ, dizemos que T é um melhor estimador, ou um estimador mais eﬁciente do que
T∗, se Var(T) < Var(T∗).

2.4 I N T E R VA L O S D E C O N F I A N Ç A

Os intervalos de conﬁança baseiam-se na distribuição amostral do estimador pontual.

Os resultados a seguir são frequentemente utilizados em sua construção, bem como nos

testes de hipóteses para populações normais.

Deﬁnição 2.24. Uma variável aleatória T tem distribuição t de Student com n graus de
liberdade, T ∼ tn se sua f.d.p. for dada por

fT(t) =

Γ (cid:0) n+1
(cid:1)
2
(cid:1)
Γ (cid:0) n
2

1
(nπ)1/2

1
(1 + t2/n)(n+1)/2

, −∞ < t < ∞.

(2.13)

57

I N F E R Ê N C I A E S TAT Í S T I C A

Teorema 2.25. Sejam X1, . . . , Xn uma amostra aleatória de tamanho n da distribuição
N ∼ (µ, σ2), e ¯X = ∑n

i=1(Xi − ¯X)2/(n − 1). Então,

i=1 Xi/n e S2 = ∑n

(i) ¯X e S2 ão variáveis aleatórias independentes;

(ii) (n − 1)S2/σ2 tem uma distribuição qui-quadrado com n − 1 graus de liberdade;

√

(iii)

n( ¯X − µ)/S tem uma distribuição t de Student com n − 1 graus de liberdade.

Demonstração. A demonstração foi extraída de [2].

(i) Temos que

¯X ∼ N(µ, σ2/n),

enquanto que Xi − ¯X ∼ N
tos de Y1 = ¯X e Y2 = Xi − ¯X é dada por

0, σ2 (n−1)

n

(cid:16)

(cid:17)

. Por outro lado, a função geradora de momen-

MY1,Y2(s1, s2) = E

(cid:104)

es1 ¯X+s2(Xi− ¯X)(cid:105)
(cid:20)

(cid:17)

(cid:16)

s2+

(s1−s2)
n

Xi+

(cid:104)

= E

es2Xi+ ¯X(s1−s2)(cid:105)
(cid:21)

(s1−s2)
n

∑n

j(cid:54)=i Xj

= E

e

(cid:20)

(cid:16)

= E

e

s2+

(s1−s2)
n

(cid:21)

(cid:17)

Xi

(cid:20)

E

e

(s1−s2)
n

∑n

j(cid:54)=i Xj

(cid:21)

Como Xi ∼ N(µ, σ2) e ∑n

j(cid:54)=i Xj ∼ N((n − 1)µ; (n − 1)σ2), temos que

MY1,Y2(s1, s2) = exp

µ

s2 +

(cid:40)

(cid:18)

(s1 − s2)
n

(cid:19)

·

exp

(cid:40)

(cid:26)

= exp

µs1 +

(n − 1)
n

(s1 − s2)µ +

(cid:27)

s2
1σ2
2n

exp

(cid:19)2(cid:41)

(s1 − s2)
n

(cid:19)2

(n − 1)σ2

(cid:41)(cid:41)

(cid:18)

+ σ2

s2 +
(cid:40)(cid:18) s1 − s2
1
n
2
(cid:26) s2
2(n − 1)σ2
2n

(cid:27)

que é o produto das funções geradoras de momentos das distribuições de ¯X e Xi − ¯X.
Portanto temos que Xi − ¯X e ¯X são independentes, pois a função geradora da distri-
buição conjunta é o produto das funções geradoras de momentos das distribuições
marginais. Como ∑n
i=1(Xi − ¯X)2 é função de Xi − ¯X que é independente de ¯X, temos
que S2 é independente de ¯X.

(ii) Temos que

n
∑
i=1

(Xi − µ)2
σ2

=

n
∑
i=1

(Xi − ¯X)2
σ2

+ n

( ¯X − µ)2
σ2

.

(2.14)

58

Como (Xi − µ)/σ ∼ N(0, 1), temos que (Xi − µ)2/σ2 ∼ χ2

1, i = 1, . . . , n, de modo que

2.4 I N T E R VA L O S D E C O N F I A N Ç A

Y1 =

n
∑
i=1

(Xi − µ)2
σ2

∼ χ2
n.

Também n(Xi − µ)2/σ2 ∼ χ2
qui-quadrado com g graus de liberdade é dada por

1. Como a função geradora de momentos da distribuição

Mg(s) = (1 − 2s)−g/2,

temos que as funções geradoras das distribuições qui-quadrado com g = 1 e g = n

graus de liberdade são dadas respectivamente por

M1(s) = (1 − 2s)−1/2 e Mn(s) = (1 − 2s)−n/2,

(2.15)

Além disso, como ¯X e S2 são independentes, temos que os dois termos do lado direito
de (2.14) que dentamos por Y2 e Y3, respectivamente, são independentes, de modo
que

ou seja, de (2.15) segue que

MY1(s) = MY2(s)MY3(s),

MY2(s) =

MY1(s)
MY3(s)

= (1 − 2s)−(n−1)/n,

logo o distribuição de Y2 = (n − 1)S2/σ2 é qui-quadrado com n − 1 graus de liberdade.

(iii) Note que podemos escrever

√

n

( ¯X − µ)
S

=

√

n ( ¯X−µ)
σ
(cid:113) (n−1)S2
(n−1)σ2

,

(2.16)

que corresponde ao quociente entre duas variáveis aleatórias independentes em que o

numerador é uma variável aleatória com distribuição N(0, 1) e o denominador é a raiz
quadrada de uma variável aleatória com distribuição qui-quadrado com n − 1 graus de
liberdade (veja(ii)) dividido pelo pelo número de graus de liberdade, de modo que a
variável (2.16) tem distribuição t de Student com n − 1 graus de liberdade.

2.4.1 Intervalo de conﬁança para a média, com variância conhecida

Ao obtermos uma amostra, sua média µ pode não ser exatamente a média popu-

lacional. Podemos estimar que µ pertence a um intervalo, desta forma, temos uma

estimativa intervalar.

59

I N F E R Ê N C I A E S TAT Í S T I C A

Deﬁnição 2.26. Uma estimativa intervalar é um intervalo utilizado para estimar um

parâmetro populacional.

Quando tomamos ¯x como uma estimativa de µ, precisamos determinar o quanto

estamos conﬁantes de que µ pertença ao intervalo estimado.

Deﬁnimos, a seguir, o nível de conﬁança para um parâmetro populacional.

Deﬁnição 2.27. O nível de conﬁança 1 − α é a probabilidade de que o parâmetro
populacional pertença ao intervalo estimado.

Figura 5: Distribuição normal com nível de conﬁança 1 − α

Fonte: Arquivo próprio do autor, baseado em [10].

O nível de conﬁança é a área entre os valores críticos −zα/2 e zα/2 na Figura 5,

obtidos na Tabela 2.

A margem de erro E é a maior diferença possível entre o valor estimado e o verda-

deiro valor do parâmetro, e é dada por:

E = zα/2

σ
√
n

.

A distribuição amostral da média se aproxima de uma distribuição normal com mé-

dia µ e variância σ2/n, de modo que

z =

¯x − µ
√
σ/
n

é o valor de uma variável aleatória que tem aproximadamente uma distribuição normal
padrão, com probabilidade 1 − α de que

−zα/2 < z < zα/2.

60

2.4 I N T E R VA L O S D E C O N F I A N Ç A

Substituindo a equação anterior, temos

−zα/2 <

¯x − µ
√
σ/
n

< zα/2.

Multiplicando cada termo por σ/

√

n, subtraindo ¯x e multiplicando o resultado ob-

tido por −1, obtemos

Logo, podemos escrever:

¯x + zα/2

σ
√
n

> µ > ¯x − zα/2

¯x − zα/2

σ
√
n

< µ < ¯x + zα/2

σ
√
n

.

σ
√
n

.

Este intervalo é conhecido como intervalo de conﬁança para a média, com variância

conhecida. E, neste caso,

(cid:18)

P

¯x − zα/2

σ
√
n

< µ < ¯x + zα/2

(cid:19)

σ
√
n

= 1 − α.

Para uma mesma amostra, à medida que o nível de conﬁança aumenta, o inter-

valo de conﬁança ﬁca mais largo e a precisão da estimativa decresce. Aumentando

o tamanho da amostra aumentamos a precisão da estimativa. Logo, dados o nível
de conﬁança 1 − α e uma margem de erro E pré-determinada, o tamanho mínimo da
amostra n para estimar a média populacional, com σ2 conhecido é:

n =

(cid:18) zα/2 · σ
E

(cid:19)2

.

2.4.2 Intervalo de conﬁança para a média, com variância desconhecida

Geralmente, o desvio padrão populacional é desconhecido. Sendo a população nor-

malmente distribuída, ou aproximadamente normalmente distribuída, pelo Teorema

2.25 (iii), temos que

tn−1 =

¯x − µ
√
s/
n

onde tn−1 denota uma variável aleatória com distribuição t de Student com n − 1 graus
de liberdade.

61

I N F E R Ê N C I A E S TAT Í S T I C A

Figura 6: Distribuição t de Student com nível de conﬁança 1 − α

Fonte: Arquivo próprio do autor, baseado em [10].

O nível de conﬁança é a área entre os valores críticos −tα/2;n−1 e tα/2;n−1 na Figura

6, obtidos na Tabela 3.

Temos, com probabilidade 1 − α, que

−tα/2;n−1 < t < tα/2;n−1.

Substituindo a equação anterior, temos

−tα/2;n−1 <

¯x − µ
√
s/
n

< tα/2;n−1.

Multiplicando cada termo por s/

√

n, subtraindo ¯x e multiplicando o resultado obtido

por −1, obtemos

¯x + tα/2;n−1

s
√
n

> µ > ¯x − tα/2;n−1

Logo, podemos escrever:

¯x − tα/2;n−1

s
√
n

< µ < ¯x + tα/2;n−1

s
√
n

.

s
√
n

.

Este intervalo é conhecido como intervalo de conﬁança para a média, com variância

desconhecida. E, neste caso,

(cid:18)

P

¯x − tα/2;n−1

s
√
n

< µ < ¯x + tα/2;n−1

(cid:19)

s
√
n

= 1 − α.

62

2.4 I N T E R VA L O S D E C O N F I A N Ç A

2.4.3 Intervalo de conﬁança para a variância e o desvio padrão

Pode haver o interesse em fazer estimativas sobre outros parâmetros populacionais,

como a variância e o desvio padrão. Podemos deﬁnir as estimativas pontuais para estes

parâmetros.

Deﬁnição 2.28. As estimativas pontuais para σ2 e σ são, respectivamente, s2 e s. Temos,
ainda, que s2 é a melhor estimativa não tendenciosa para σ2.

Para uma população que tenha aproximadamente uma distribuição normal, temos,

pelo Teorema 2.25 (ii), que

(n − 1)s2
σ2
n−1 denota uma variável aleatória com distribuição qui-quadrado com n − 1

n−1 =

χ2

onde χ2
graus de liberdade.

Figura 7: Distribuição qui-quadrado com nível de conﬁança 1 − α

Fonte: Arquivo próprio do autor, baseado em [10].

O nível de conﬁança é a área entre os valores críticos χ2

1−α/2;n−1 e χ2

α/2;n−1 na Figura

7, obtidos na Tabela 4.

A distinção entre χ2

1−α/2;n−1 e χ2

α/2;n−1 se faz necessária pois a curva da distribuição

qui-quadrado não é simétrica.

Temos, com probabilidade 1 − α que

1−α/2;n−1 < χ2 < χ2
χ2

α/2;n−1.

Substituindo a equação anterior, temos

χ2
1−α/2;n−1 <

(n − 1)s2
σ2

< χ2

α/2;n−1,

63

I N F E R Ê N C I A E S TAT Í S T I C A

que podemos reescrever como

1

χ2

1−α/2;n−1

>

σ2
(n − 1)s2

>

1

χ2

α/2;n−1

.

Multiplicando cada termo por (n − 1)s2, obtemos

Logo, podemos escrever:

(n − 1)s2
χ2

1−α/2;n−1

> σ2 >

(n − 1)s2
χ2

α/2;n−1

.

(n − 1)s2
χ2

α/2;n−1

< σ2 <

(n − 1)s2
χ2

1−α/2;n−1

Este intervalo é conhecido como intervalo de conﬁança para a variância. E, neste

caso,

(cid:32)

P

(n − 1)s2
χ2

α/2;n−1

< σ2 <

(cid:33)

(n − 1)s2
χ2

1−α/2;n−1

= 1 − α.

Podemos obter um intervalo de conﬁança para o desvio padrão:

(cid:118)
(cid:117)
(cid:117)
(cid:116)

(n − 1)s2
χ2

α/2;n−1

< σ <

(cid:118)
(cid:117)
(cid:117)
(cid:116)

(n − 1)s2
χ2

1−α/2;n−1

Dessa forma,



P



(cid:118)
(cid:117)
(cid:117)
(cid:116)

(n − 1)s2
χ2

α/2;n−1

< σ <

(cid:118)
(cid:117)
(cid:117)
(cid:116)

(n − 1)s2
χ2

1−α/2;n−1


 = 1 − α.

2.4.4 Intervalo de conﬁança para uma proporção

Da Equação (2.9), temos que

ˆp =

Sn
n

64

2.4 I N T E R VA L O S D E C O N F I A N Ç A

é uma estimativa pontual para p e a estatística

z =

x − np
(cid:112)np(1 − p)

.

é o valor de uma variável aleatória que tem aproximadamente uma distribuição normal
padrão, com probabilidade 1 − α de que

−zα/2 < z < zα/2.

Substituindo a equação anterior, temos

−zα/2 <

x − np
(cid:112)np(1 − p)

< zα/2.

Multiplicando cada termo por (cid:112)np(1 − p), subtraindo x e multiplicando o resultado

obtido por −1, obtemos

(cid:112)

x + zα/2

np(1 − p) > np > x − zα/2

(cid:112)

np(1 − p).

Dividindo cada termo por n e rearranjando, obtemos,

(cid:114)

x
n

− zα/2

p(1 − p)
n

< p <

(cid:114)

x
n

+ zα/2

p(1 − p)
n

.

Sendo p um parâmetro desconhecido e de (2.7) segue que

(cid:114)

p(1 − p)
n

é o desvio padrão da distribuição amostral de uma proporção.

Fazendo Sn = x em (2.9) e substituindo

ˆp =

x
n

para p em

(cid:114)

p(1 − p)
n

.

obtemos um intervalo de conﬁança para uma proporção,

ˆp − zα/2

(cid:114)

ˆp(1 − ˆp)
n

< p < ˆp + zα/2

(cid:114)

ˆp(1 − ˆp)
n

.

Logo,

(cid:32)

(cid:114)

P

ˆp − zα/2

ˆp(1 − ˆp)
n

< p < ˆp + zα/2

(cid:114)

(cid:33)

ˆp(1 − ˆp)
n

= 1 − α.

65

I N F E R Ê N C I A E S TAT Í S T I C A

2.5 T E S T E S D E H I P Ó T E S E

Para iniciar esta seção deﬁnimos hipótese estatística.

Deﬁnição 2.29. Uma hipótese estatística é uma aﬁrmação sobre um parâmetro popu-

lacional.

Em um teste de hipótese devemos decidir, a partir de uma amostra populacional,

entre duas hipóteses complementares, qual é verdadeira.

Deﬁnição 2.30. As duas hipóteses complementares são chamadas hipótese nula, H0 e
hipótese alternativa, H1.

Seja θ um parâmetro populacional e aﬁrmamos que θ = θ0, onde θ0 é o valor do

parâmetro θ sob hipótese. Temos, então,

H0 : θ = θ0.

De forma mais geral, a hipótese alternativa seria

H1 : θ (cid:54)= θ0.

Podemos ter hipóteses nulas na forma

H1 : θ (cid:62) θ0 ou H1 : θ (cid:54) θ0.

Sendo suas respectivas hipóteses alternativas:

H1 : θ < θ0 ou H1 : θ > θ0.

Devemos, então, decidir se aceitamos H0 como verdadeira ou se a rejeitamos, acei-

tando H1 como verdadeira.

Para testar uma hipótese devemos saber para quais valores amostrais aceitamos H0
como verdadeira e para quais valores amostrais rejeitamos H0 e aceitamos H1 como
verdadeira.

Deﬁnimos, a seguir, a região crítica.

66

2.5 T E S T E S D E H I P Ó T E S E

Deﬁnição 2.31. A região crítica ou região de rejeição é o subconjunto do espaço amos-

tral para o qual rejeitamos H0, seu complemento é chamado de região de aceitação.

Ao testar uma hipótese dois tipos de erros podem ocorrer, o erro do tipo I e o erro

do tipo II.

O erro do tipo I ocorre quando rejeitamos H0 sendo H0 verdadeira e o erro do tipo

II ocorre quando não rejeitamos H0 sendo H0 falsa.

A Tabela 1 descreve esta situação:

Tabela 1: Tipos de erros em testes de hipóteses
H0 é falsa
Decisão
Erro do tipo II

H0 é verdadeira
Decisão correta

Aceitar H0
Rejeitar H0

Erro do tipo I
Fonte: [2].

Decisão correta

A probabilidade máxima permissível para cometer um erro do tipo I é denominado

nível de signiﬁcância.

As probabilidades de cometer os erros do tipo I e do tipo II são denotadas α e β,

respectivamente.

α = P(erro do tipo I).

β = P(erro do tipo II).

Seja RC a região crítica para um teste de hipótese. O teste resultará em um erro,
para θ = θ0, se x ∈ RC, dessa forma, a probabilidade de um erro do tipo I é Pθ(X ∈ RC).
E a probabilidade de um erro do tipo II é 1 − Pθ(X ∈ RC). Temos

Pθ(X ∈ RC) =




probabilidade de erro do tipo I,

se θ = θ0;



1− a probabilidade de erro do tipo II,

caso contrário.

O que nos leva à seguinte deﬁnição:

Deﬁnição 2.32. A função poder de um teste de hipótese com região crítica RC é a
função de θ deﬁnida por β(θ) = Pθ(X ∈ RC).

67

I N F E R Ê N C I A E S TAT Í S T I C A

2.5.1 Teste de hipótese para a média com variância conhecida

O teste de hipótese para a média com variância conhecida é utilizado quando a

distribuição amostral da média pode ser aproximada por uma distribuição normal.

Sejam ¯x a média amostral, µ0 o valor da média sob a hipótese nula e σ2/n a variância.
A estatística do teste padronizado z, onde z é o valor de uma variável aleatória que

tenha uma distribuição normal padrão, é:

z =

¯x − µ0
√
σ/
n

Nos referimos a esse teste como teste z para a média µ.

Figura 8: Teste z bicaudal, H1 : µ (cid:54)= µ0

Fonte: Arquivo próprio do autor baseado em [10].

Figura 9: Teste z unicaudal à esquerda, H1 : µ < µ0

Fonte: Arquivo próprio do autor baseado em [10].

68

2.5 T E S T E S D E H I P Ó T E S E

Figura 10: Teste z unicaudal à direita, H1 : µ > µ0

Fonte: Arquivo próprio do autor baseado em [10].

2.5.2 Teste de hipótese para a média com variância desconhecida

Recorremos à distribuição t de Student para o teste de hipótese para a média com va-

riância desconhecida com a população normalmente distribuída, ou aproximadamente

normalmente distribuída.

Pelo Teorema 2.25 (iii), temos

tn−1 =

¯x − µ
√
s/
n

.

Nos referimos a esse teste como teste t para a média µ.

Figura 11: Teste t bicaudal, H1 : µ (cid:54)= µ0

Fonte: Arquivo próprio do autor baseado em [10].

69

I N F E R Ê N C I A E S TAT Í S T I C A

Figura 12: Teste t unicaudal à esquerda, H1 : µ < µ0

Fonte: Arquivo próprio do autor baseado em [10].

Figura 13: Teste t unicaudal à direita, H1 : µ > µ0

Fonte: Arquivo próprio do autor baseado em [10].

2.5.3 Teste de hipótese para a variância

Recorremos à distribuição distribuição qui-quadrado para o teste de hipótese para

a variância, com a população normalmente distribuída, ou aproximadamente normal-

mente distribuída.

Pelo Teorema 2.25 (ii), temos

χ2

n−1 =

(n − 1)s2
σ2

.

Nos referimos a esse teste como teste χ2.

70

2.5 T E S T E S D E H I P Ó T E S E

Figura 14: Teste χ2 bicaudal, H1 : σ (cid:54)= σ0

Fonte: Arquivo próprio do autor baseado em [10].

Figura 15: Teste χ2 unicaudal à esquerda, H1 : σ < σ0

Fonte: Arquivo próprio do autor baseado em [10].

Figura 16: Teste χ2 unicaudal à direita, H1 : σ > σ0

Fonte: Arquivo próprio do autor baseado em [10].

2.5.4 Teste de hipótese para uma proporção

Uma proporção ˆp com n ˆp (cid:62) 5 e n(1 − ˆp) (cid:62) 5 tem uma distribuição binomial que
pode ser aproximada a uma distribuição normal. Neste caso, o teste estatístico a ser

utilizado é o teste z.

71

I N F E R Ê N C I A E S TAT Í S T I C A

z =

(cid:112)

ˆp − p0
ˆp(1 − ˆp)/n

.

Onde p0 é o valor da proporção sob a hipótese nula.

A rejeição da hipótese nula ocorre como nas Figuras 8, 9 e 10.

72

3

P R O P O S TA D E AT I V I D A D E S

Este capítulo tem como ﬁnalidade apresentar uma proposta de atividades sobre in-

ferência no ensino médio, especiﬁcamente aos alunos do 3o ano.

Sendo que ao término de cada atividade proposta, os alunos tenham condições de

realizarem inferências sobre uma determinada amostra.

Serão desenvolvidas diversas atividades, todas com objetivos especíﬁcos.

As atividades são originais, com exceção da terceira atividade, baseada em [19].

A primeira atividade, por exemplo, consiste em motivar os jovens à introdução de

conceitos mais complexos.

Para a realização das atividades, a metodologia aplicada será através de questioná-

rios, com o objetivo de realizar uma avaliação diagnóstica, como também de diversos

cálculos propostos.

Assim, o exercício 1 tem como objetivo primordial relembrar o cálculo para uma

distribuição binomial.

No entanto, para a efetiva realização da atividade 1, o aluno deverá possuir prévio

conhecimento de como proceder no cálculo de probabilidades binomiais, e se necessá-

rio, retomar explicações sobre o assunto.

No exercício 2, será apresentada a curva da distribuição normal, bem como a Tabela

2.

Desta forma, no exercício 1 o aluno relembrará o cálculo de uma distribuição bino-

mial, enquanto que no exercício 2, os alunos compreenderão sobre a curva normal e

também a consultar tabelas.

73

P R O P O S TA D E AT I V I D A D E S

3.1 AT I V I D A D E 1

Primeiramente a atividade inciará com uma discussão envolvendo todos os alunos

referente a variáveis discretas e contínuas.

Em seguida farão exercícios sobre o assunto, os quais servirão de motivação para a

próxima atividade.

Concluídos os dois exercícios, discutirão sobre a facilidade ou complexidade dos

mesmos, expondo oralmente os motivos.

Espera-se que ao ﬁnal da atividade os alunos realizem questionamentos, como por

exemplo, se é possível resolver o Exercício 1 utilizando uma tabela, como no Exercício

2, consequentemente motivando-os para a próxima atividade.

Recursos: Calculadora (opcional) e a Tabela 2.

Duração: 2 horas-aula de 50 minutos cada.

Os Exercícios abaixo serão realizados pelos alunos.

O Exercício 1 foi extraído de [10], p. 196, conforme a questão:

1. Um estudo mostra que em 60% dos casos de divórcio requeridos num certo mu-

nicípio, a incompatibilidade é apontada como causa. Encontre as probabilidades

de que entre 15 casos de divórcio requeridos naquele município

(a) no máximo cinco apontem a incompatibilidade como causa;

(b) de oito a onze apontem a incompatibilidade como causa;

(c) no mínimo onze apontem a incompatibilidade como causa.

O Exercício 2 foi extraído de [8], p. 208.

2. As contas de consumo mensais em uma cidade são normalmente distribuídas

com uma média de R$100, 00 e um desvio padrão de R$12, 00. Uma conta de

consumo é escolhida aleatoriamente.

(a) Encontre a probabilidade de a conta de consumo ser menor que R$70, 00;

(b) Encontre a probabilidade de a conta de consumo estar entre e R$90, 00 e

R$120, 00;

(c) Encontre a probabilidade de a conta de consumo ser maior que R$140, 00.

74

3.2 AT I V I D A D E 2

3.2 AT I V I D A D E 2

O objetivo desta atividade é mostrar, de maneira simples, que uma distribuição nor-

mal pode ser aproximada de uma distribuição binomial, e sob quais condições tal

aproximação é possível.

Lembrar que a aproximação é possível quando np (cid:62) 5 e n(1 − p) (cid:62) 5.

Os recursos utilizados serão: Tábua de Galton (confeccionada pelo professor), bo-

las de gude ou de rolamento em quantidade suﬁciente para cada aluno, calculadora

(opcional) e a Tabela 2.

Para a concretização da atividade será apresentada a Tábua de Galton aos alunos, e

também questionamento aos mesmos de onde é mais provável que a bola pare e onde

é menos provável; solicitando que justiﬁquem as respostas apresentadas.

Em seguida, os alunos, um por vez, liberam as bolas, e veriﬁcam se suas hipóteses

iniciais estavam ou não corretas.

Após realizada a atividade, o professor explica as probabilidades de cada bola nos

primeiros pinos, deixando que os alunos façam as demais probabilidades.

Como forma de aguçar o raciocínio dos alunos serão realizadas as seguintes pergun-

tas e atividades devem ser feitas:

• Podemos montar um gráﬁco da distribuição binomial? Como seria? Faça um

gráﬁco que a represente.

• É possível formam um gráﬁco que indique a posição das bolas no experimento?

Em caso aﬁrmativo, este gráﬁco se aproxima do obtido anteriormente?

• Compare o gráﬁco com a curva normal, apresentada na Atividade anterior. O

que podemos concluir?

Com tais exercícios espera-se que os alunos observem que existe uma relação entre

as distribuições binomial e normal.

Após realizada esta fase, farão novamente o exercício 1 da atividade 1, desta vez

através da distribuição normal.

Enfatizando que deve adicionar 0, 5 em cada extremidade, explicando-os que tal

adição chama-se correção pela continuidade.

75

P R O P O S TA D E AT I V I D A D E S

Assim, encerrada a Atividade 2, os alunos serão questionados quanto aos resultados

obtidos, observando se ocorreu diferenças ao realizado anteriormente e se é possível

sempre fazer a aproximação.

Duração: 2 horas-aula de 50 minutos cada.

3.3 AT I V I D A D E 3

O objetivo desta atividade é mostrar, de maneira informal, como obter uma amostra

de uma proporção, além de mostrar que a média das proporções das amostras é igual

à proporção da população.

Em primeiro lugar será feita uma indagação aos alunos sobre o que seria uma amos-

tra como forma de observar os conhecimentos sobre o assunto. Dividir os alunos em

grupos e, em seguida apresentar a situação-problema através do enunciado:

Em um determinado município todas as famílias de um certo bairro têm animais de

estimação, entre cães e gatos, cada família tem apenas um dos dois animais. Qual a

proporção, neste bairro, de famílias que preferem ter cães como animais de estimação?

Exposto o enunciado fornecer uma folha com desenhos de cachorros e gatos, Figura

46, para que os alunos delimitassem uma região que represente a amostra considerada.

O professor pergunta aos alunos o que seria mais fácil, contar todos os animais ou

apenas uma parte dos animais?

Ouvidas as respostas, pede-se que os alunos marquem na folha, em um lugar aleató-

rio, a quantidade de animais que eles quiserem, da maneira que preferirem, e contem

apenas os animais que estão na área demarcada, anotando a quantidade de cães e ga-

tos. O professor pode fazer a anotação caso algum grupo assim preﬁra, como também

pode fazer uso exemplos para demonstrar como a marcação pode ser feita.

Anotados os valores de todas as duplas, faz-se a média da proporção de cães, e

compara-se com o valor exato, previamente conhecido pelo professor.

Em seguida, faz-se as seguintes perguntas aos alunos:

• O resultado está próximo da proporção real? Justiﬁque.

• Qual amostra nos daria uma melhor estimativa, uma amostra pequena ou uma

grande? Justiﬁque.

76

• Nesta atividade várias amostras foram obtidas, na prática trabalha-se com quan-

3.4 AT I V I D A D E 4

tas amostras?

Recursos: Calculadora (opcional) e a Figura 46.

Duração: 1 hora-aula de 50 minutos.

3.4 AT I V I D A D E 4

O objetivo desta atividade é obter a proporção de elementos com determinada ca-

racterística de uma população a partir de uma única amostra, bem como obter um

intervalo de conﬁança e veriﬁcar uma hipótese.

Será exposto a seguinte situação-problema:

Uma máquina fabrica 300 peças por hora, sendo que uma porcentagem destas peças

apresenta algum defeito. O fabricante aﬁrma que, para um intervalo de conﬁança de

95%, apenas 10% das peças são defeituosas. A aﬁrmação do fabricante é verdadeira?

Para a realização desta atividade, será colocado em um saco plástico 300 peças, de

duas cores distintas, as quais representam as peças fabricadas pela máquina, peças

defeituosas na proporção 15% e peças que não possuem defeito na proporção 85%. As

peças serão retiradas uma a uma com reposição.

A cada peça retirada anotamos a sua cor e a devolvemos para uma nova retirada.

Ao ﬁnal calculamos a proporção de peças de cada cor.

Após contagem e observação das peças serão feitas as seguintes perguntas:

• O que é um intervalo de conﬁança?

• O que é um intervalo de conﬁança de 95%?

Mostra-se como se efetua o cálculo de um intervalo de conﬁança de 95% para esta

amostra com o uso da Tabela 2.

E na mesma continuidade mais questões serão apresentadas aos alunos:

• O que vem a ser uma hipótese?

• Qual é a hipótese a ser testada?

• A hipótese inicial pode ser aceita ou deve ser rejeitada? Justiﬁque.

77

P R O P O S TA D E AT I V I D A D E S

Comparando o resultado obtido com a proporção real, serão feitas as seguintes per-

guntas:

• O resultado obtido é igual ou próximo ao real?

• A proporção real pertence ao intervalo de conﬁança?

• A aceitação (ou rejeição) da hipótese inicial foi uma decisão acertada?

Apresentado o teste para uma proporção e resolvendo-a, é veriﬁcado se a aceitação

(ou rejeição) da hipótese inicial foi uma decisão acertada.

Recursos: Saco plástico ou sacola, 300 peças ou botões de duas cores distintas, cal-

culadora (opcional) e Tabela 2.

Duração: 2 hora-aula de 50 minutos cada.

78

4

A P L I C A Ç Ã O D A S AT I V I D A D E S

Este capítulo destina-se à aplicação das atividades anteriormente propostas, bem

como as respostas dos alunos aos questionamentos, suas observações e fotos da reali-

zação das atividades.

Os nomes dos alunos são ﬁctícios e os cálculos foram efetuados com o auxílio de

uma calculadora cientíﬁca.

4.1 A P L I C A Ç Ã O D A AT I V I D A D E 1

Antes de se iniciar a atividade, houve o seguinte diálogo:

Professor: O que são variáveis aleatórias?

Marcelo: São coisas diferentes, mas ocorrem repetidamente.

Adriana: Uma coisa que varia de uma para outra.

Professor: De modo informal, variáveis aleatórias são os possíveis resultados de um

evento que você espera que aconteçam, mas não sabe quando eles irão ocorrer.

Professor: E o que são variáveis aleatórias discretas? E variáveis aleatórias contí-

nuas?

Adriana: Contínuas sempre se repetem.

Bianca: Discretas ocorrem de forma mais lenta.

Professor: Como assim, “mais lenta”?

Bianca: Demoram mais para acontecer do que as contínuas.

Renato: Contínuas seguem um padrão.

79

A P L I C A Ç Ã O D A S AT I V I D A D E S

Fiz uma reta no quadro indicando apenas os números inteiros, a partir do zero.

Professor: As variáveis aleatórias discretas podem ter, por exemplo, estes valores

(circulei os números naturais com um giz colorido), e as variáveis aleatórias contínuas

podem ter um valor entre o 2 e o 3, por exemplo.

Marcelo: Como assim?

Professor: Por exemplo, 2, 03 ou 2, 57.

Os alunos foram divididos em grupos escolhidos por eles e foi apresentado o Exercí-

cio 1:

Professor: Lembram dos exercícios do ano passado, de sucesso e fracasso?

Alunos: Sim.

Professor: Neste caso, a incompatibilidade é sucesso ou fracasso?

Vários alunos: Fracasso.

Professor: Mas, o que é esperado que ocorra?

Marcelo: A incompatibilidade.

Professor: Então, a incompatibilidade é sucesso ou fracasso?

Marcelo: Sucesso.

Os demais concordaram com a resposta de Marcelo, e seguimos a análise do exercí-

cio.

Professor: Qual o signiﬁcado de no máximo 5 no item (a)?

Bianca: Mais do que 5.

Carla: 5.

Professor: Exatamente 5?

Carla: Sim.

Adriana: Menores do que 5, o 5 também faz parte.

Professor: Isso mesmo. E o zero?

Marcelo: O zero também.

Escrevi no quadro a conta a ser feita, com a participação dos alunos, e estes auxili-

aram na resolução do item (a), cada grupo fez uma parte, compartilhando a mesma

calculadora.

80

4.1 A P L I C A Ç Ã O D A AT I V I D A D E 1

No item (b) Michele perguntou se poderia fazer apenas os cálculos do oito e do onze.

Professor: Precisamos fazer a conta com o nove e o dez.

Neste item os alunos chegaram ao resultado com orientação e Márcio indagou se

contínuas estão no intervalo.

Professor: O que seria no mínimo 11 no item (c)?

Carla: Não pode ser mais do que 11.

Adriana: Devem ser de 11 “pra” cima.

Professor: E o 11?

Adriana: O 11 também.

Alguns alunos disseram que a conta era difícil, outros que era trabalhosa, compli-

cada, confusa.

Mesmo assim, tentaram encontrar o resultado novamente, pois a calculadora que

usaram inicialmente faz a combinação direto e eles queriam usar a calculadora deles,

com o fatorial, e conseguiram obter os resultados corretos.

Seguem os cálculos efetuados no Exercício 1:

(a) (15

+(15

0 )(0, 6)0(0, 4)15 + (15
4 )(0, 6)4(0, 4)11 + (15
8 )(0, 6)8(0, 4)7 + (15
11)(0, 6)11(0, 4)4 + (15
+(15
15)(0, 6)15(0, 4)0 = 0, 217.

(b) (15

(c) (15

1 )(0, 6)1(0, 4)14 + (15
5 )(0, 6)5(0, 4)10 = 0, 034.

2 )(0, 6)2(0, 4)13 + (15

3 )(0, 6)3(0, 4)12+

9 )(0, 6)9(0, 4)6 + (15
12)(0, 6)12(0, 4)3 + (15

10)(0, 6)10(0, 4)5 + (15
13)(0, 6)13(0, 4)2 + (15

11)(0, 6)11(0, 4)4 = 0, 696.

14)(0, 6)14(0, 4)1+

O Exercício 2 é apresentado e diversas perguntas são feitas aos alunos:

Professor: O que signiﬁca “normalmente distribuídas”?

Michele: São coisas distribuídas igualmente.

Professor: Não, não é isso.

Marcelo: São coisas distribuídas de forma diferente.

Professor: Também não. Quando se diz que algo é normalmente distribuído, é

porque ele segue uma curva normal.

Faço um esboço de uma curva normal no quadro.

81

A P L I C A Ç Ã O D A S AT I V I D A D E S

Professor: No exercício anterior, a variável aleatória era discreta.

Carla: Por quê?

Professor: Porque os valores são números inteiros. Temos 8 casais e meio?

Marcelo: Não.

Professor: Agora, uma conta de consumo pode ser de R$ 117, 35?

Marcelo: Pode.

Professor: Então, nesse exercício, a variável aleatória é contínua?

Adriana: É.

Professor: O que é uma média 100?

Bianca: Mais ou menos 100.

Professor: Se somarmos todas as contas e dividirmos esse resultado pelo total de

contas encontramos cem, que é a média do exercício. E em que lugar do gráﬁco

(apontando para a reta abaixo da curva) vai estar a média cem?

Carla: Bem no meio da curva.

Professor: E o que é um desvio padrão?

Bianca: É um desvio que ocorre regulamente.

Professor: O desvio padrão indica o quanto um conjunto de valores se afasta da

média.

Faço novamente o esboço de uma curva normal, indicando os valores 88, 100 (média)

e 112.

Professor: Os valores entre 100 e 112 estão dentro de um desvio padrão à direita, e

os valores entre 88 e 100 estão dentro de um desvio padrão à esquerda.

Com o item (a) surgiram muitas dúvidas por parte dos alunos.

Michele: Quando o número ﬁca para a esquerda da média é negativo? (referindo-se

à Tabela da distribuição normal).

Professor: Na tabela sim.

Adriana: Existe uma tabela que tenha os valores negativos?

Professor: Existe sim.

Adriana: Então por que você usou essa?

82

4.1 A P L I C A Ç Ã O D A AT I V I D A D E 1

Professor: Eu tinha que fazer uma escolha, e optei por essa.

Michele: Desvio padrão interfere no número ser negativo ou positivo?

Professor: Não interfere, quando ﬁzermos os cálculos você verá.

Michele: Posso colocar qualquer valor abaixo da média? (perguntando se podia

escolher qualquer valor que fosse menor do que 100).

Professor: Pode sim, pode ser menor, maior ou igual a 100.

Carla: Por que a média é 100?

Professor: É o valor fornecido pelo problema, por exemplo, se você somar todas as

contas de consumo e dividir pelo número total de contas, você chegaria a cem, neste

caso.

Foi demonstrado como fazer o cálculo das probabilidade utilizando a Tabela de dis-

tribuição normal (esse assunto era novidade para eles).

Carla: O que se faz com o número negativo? Passa para positivo?

Professor: Tem uma observação ao ﬁnal da tabela.

Na folha fornecida com a Tabela de distribuição normal tinha a seguinte observação:

Φ(−x) = 1 − Φ(x).

Ester: Então, com o sinal negativo fazemos 1 menos o número só que agora positivo

e procuramos na tabela.

Os alunos tiveram uma certa diﬁculdade em fazer a subtração 1 − 0, 9938. Quando

mal havia terminado de explicar eles conseguiram terminar sem auxílio.

Iniciado o item (b) Carla perguntou novamente o porquê do cem sempre aparecer.

Ester: A média é 100, sempre iremos usar 100.

Professor: Somente neste exercício, pois a média é 100.

Ester: Isso, só nesse exercício.

No item (b) obtivemos Φ(1, 67) − Φ(−0, 83) e novos questionamentos surgiram.

Ester: O valor está na linha do 1, 6, não é professor?

Professor: Sim, mas é na 8a coluna de valores.

Adriana: Por que na 8a coluna é que se encontra o valor e não em outra?

83

A P L I C A Ç Ã O D A S AT I V I D A D E S

Professor: Olhem a 1a linha da tabela, elas representam os centésimos, temos que

fazer 1, 6 + 0, 07 = 1, 67.

Ester: Então, 0, 83 está na 4a coluna?

Professor: Isso mesmo.

Este item foi concluído com mais facilidade que o anterior.

Professor: No item (c) temos que fazer 1 − Φ(3, 33).

Marcelo: Por que, se ele é positivo?

Professor: É porque a tabela nos fornece valores à esquerda de Φ(3, 33), isso quer
dizer que nos fornece a área dos valores menores do que R$ 140, 00, e queremos a

área dos valores maiores do que R$ 140, 00. Como a área toda é igual a 1, fazemos
1 − Φ(3, 33).

Marcelo: Entendi.

Os alunos tiveram mais facilidade com este exercício, em comparação ao anterior.

Seguem os cálculos efetuados no Exercício 2:

(cid:18)

P

x <

(cid:19)

70 − 100
12

= P (x < −2, 5)

= Φ(−2, 5)
= 1 − Φ(2, 5)

= 1 − 0, 9938

= 0, 0062.

(cid:18) 90 − 100
12

P

(cid:54) x (cid:54) 120 − 100

12

(cid:19)

= P (−0, 83 (cid:54) x (cid:54) 1, 67)

= Φ(1, 67) − Φ(−0, 83)
= Φ(1, 67) − [1 − Φ(0, 83)]

= 0, 9525 − 1 + 0, 7967

= 0, 7492.

(a)

(b)

84

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

(c)

(cid:18) 140 − 100
12

P

(cid:19)

< x

= P (3, 33 < x)

= 1 − Φ(3, 33)

= 1 − 0, 9996

= 0, 0004.

Professor: Será que podemos fazer o cálculo do exercício 1 como ﬁzemos no exercí-

cio 2?

Carla: Com certeza.

Marcelo: Eu acho que sim, mas esse ainda é complicado.

Professor: É que foi a primeira vez que vocês ﬁzeram, as próximas serão menos

complicadas.

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Esta atividade começou antes de ser levada para a sala de aula, pela construção da

Tábua de Galton.

Em um primeiro momento foi feita uma construção geométrica com diversos losan-

gos e triângulo equiláteros, cujos vértices seriam os pontos no qual seriam colocados

os pregos, esta ﬁgura foi presa à tábua de madeira com ﬁta adesiva, Figura 17.

Figura 17: Construção da Tábua de Galton 1

Fonte: Arquivo próprio do autor.

Foram colocados os pregos na tábua, Figura 18.

85

A P L I C A Ç Ã O D A S AT I V I D A D E S

Figura 18: Construção da Tábua de Galton 2

Fonte: Arquivo próprio do autor.

As linhas laterais eram destinadas a colocar uma ripa de madeira com o intuito de

que as bolas de gude não escapassem, mas não funcionou muito bem, sendo necessário

a colocação de mais pregos, Figura 19.

Figura 19: Construção da Tábua de Galton 3

Fonte: Arquivo próprio do autor.

Por ﬁm, foram coladas as canaletas onde ﬁcariam as bolas de gude, Figura 20.

Figura 20: Construção da Tábua de Galton 4

Fonte: Arquivo próprio do autor.

86

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Após a confecção da tábua de Galton foi levada para a sala de aula, o que criou

grande curiosidade entre os alunos, sobre o que seria e qual a sua utilidade. Houve

a explicação sobre o que seria, mas sua utilidade não, pelo menos em um primeiro

momento.

Professor: Esta é a Tábua de Galton, quando colocarem uma bola de gude na parte

de cima ela cairá e baterá nos pregos, chegando em uma das canaletas. Onde vocês

acham que a bolinha cairá?

Adriana e Bianca: no meio.

Carla: Na ponta.

Marcelo: Na 3a canaleta.

Marcelo: Podemos numerar de 1 até 9?

Professor: Assim ﬁcaria mais fácil?

Marcelo: Sim.

Professor: Todos concordam, podemos numerar as casas de 1 até 9?

Todos: Sim.

Lançada a primeira bola, ela cai no canto, como Carla havia dito anteriormente.

Figura 21: Primeira bola lançada

Fonte: Arquivo próprio do autor.

Carla: Não falei que ia cair no canto?

Mas as 3 bolas seguintes caíram todas em um mesmo lugar e Carla já não parecia

tão certa de sua escolha.

Guilherme: Mas só vai cair aí?

87

A P L I C A Ç Ã O D A S AT I V I D A D E S

Figura 22: Quatro bolas lançadas

Fonte: Arquivo próprio do autor.

Figura 23: Lançando uma bola

Fonte: Arquivo próprio do autor.

Professor: Calma, vamos colocar mais bolas.

Mais bolas foram colocadas, até que atingimos o limite em uma das canaletas, num

total de 32 bolas. Figura 24.

Ester: Caiu mais no meio, por quê?

Comecei explicando as probabilidades na própria Tábua, Figura 25.

Professor: Quando a bola bate no primeiro prego, qual a probabilidade de que ela

vá para a esquerda?

Marcelo: É de 50%.

Professor: E para a direita?

88

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Figura 24: Final do experimento, 32 bolas lançadas

Fonte: Arquivo próprio do autor.

Figura 25: Explicando as probabilidades na Tábua

Fonte: Arquivo próprio do autor.

Marcelo: É de 50%.

Professor: Se a bola for para a direita ela bate no prego de baixo. Qual a probabili-

dade dela ir para a esquerda?

Ester: É de 50%.

Professor: Não é mais 50%, agora a probabilidade é de 25%.

Carla: Por que 25%?

Professor: A bola não tinha 50% de chance de ir para a esquerda?

Ester: Tinha.

Professor: Agora, só temos 50% de chance para a bola escolher um dos lados, 25%

de ir para a esquerda e 25% de ir para a direita. E se a bola for para a direta?

89

A P L I C A Ç Ã O D A S AT I V I D A D E S

Ester: A mesma coisa, 25% para cada lado.

Professor: Mas a bola não pode ir para o meio vindo de qualquer um dos lados?

Marcelo: Pode.

Professor: Então, ela tem 25% de chance de vir da esquerda e 25% de chance de vir

da direita?

Marcelo: Tem.

Professor: Isso signiﬁca que ela tem 50% de chance de cair no meio.

Marcelo: Sim.

Ester: Isso quer dizer que ela vai cair no meio?

Professor: Não necessariamente, porém a maior probabilidade é de que ela caia no

meio.

Ester: Por isso é que no meio caiu mais.

Professor: Isso mesmo.

Comecei fazendo as probabilidade no quadro, Figura 26. A sala foi dividida em

dois grupos, um grupo fez um gráﬁco da posição das bolas na Tábua e o outro as

probabilidades iniciadas no quadro.

Figura 26: Probabilidades no quadro

Fonte: Arquivo próprio do autor.

No início, os alunos ﬁzeram livremente os gráﬁcos.

Depois, foi explicado que seria melhor fazer um histograma, pois ele melhor repre-

senta a distribuição.

Ester: Como se faz um histograma?

90

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Figura 27: Gráﬁco da Carla

Fonte: Arquivo próprio do autor.

Figura 28: Primeiro gráﬁco da Marta

Fonte: Arquivo próprio do autor.

Professor: É como o gráﬁco que a Marta fez, mas as colunas são todas coladas umas

nas outras.

Marta: Assim está bom?

Professor: Está ótimo.

Figura 29: Segundo gráﬁco da Marta

Fonte: Arquivo próprio do autor.

Os alunos responsáveis pelas probabilidades tiveram diﬁculdades em concluir a ta-

refa. Adriana foi uma das poucas pessoas a concluir a tarefa.

Como houve muita diﬁculdade resolvi explicar no quadro.

91

A P L I C A Ç Ã O D A S AT I V I D A D E S

Figura 30: Probabilidades da Adriana

Fonte: Arquivo próprio do autor.

Professor: Lembram do triângulo de Pascal, estudado no ano anterior?

Pedro: Lembro.

Professor: O numerador segue o triângulo de Pascal. E o denominador, saberia

responder?

Adriana: A probabilidade em cada linha.

Carla: Por que 16? (referindo-se ao denominador)

Professor: A metade de 1/8 é 1/16.

Carla: Não entendi.

Professor: Lembra como dividimos uma fração por outra?

Carla: Não.

Através de um desenho no quadro, Carla entendeu.

Figura 31: Explicando as Probabilidades

Fonte: Arquivo próprio do autor.

Ester: Então o 20/64 é a probabilidade de cair no meio?

92

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Professor: Isso mesmo.

Ester: Mas o que signiﬁca o 64?

Professor: Signiﬁca que se colocarmos 64 bolas, espera-se que 20 caiam no meio.

Marcelo: E se não cair?

Professor: Exatamente 20?

Marcelo: É.

Professor: Não tem problema, 20 é o resultado esperado. Podem cair mais ou menos

do que 20 bolas.

Ester: Isso signiﬁca que sempre vai cair mais no meio?

Professor: Espera-se que sim.

Foi solicitado que os alunos ﬁzessem um gráﬁco das probabilidades que estavam no

quadro.

Figura 32: Gráﬁco do Marcelo

Fonte: Arquivo próprio do autor.

Após comparar os gráﬁcos da distribuição binomial e o obtido na Tábua com a curva

normal, houve concordância por parte dos alunos que ambos se aproximavam da curva

normal.

Resolveram novamente o Exercício 1, desta vez pela aproximação da binomial à

normal e a maior diﬁculdade dos alunos foi na compreensão da correção pela conti-

nuidade.

Professor: Como o cálculo é uma aproximação da binomial precisamos encontrar

uma média.

Adriana: Como encontramos a média?

93

A P L I C A Ç Ã O D A S AT I V I D A D E S

Professor: Qual a probabilidade de sucesso?

Adriana: É de 60%.

Professor: E em quantos casais estamos interessados?

Marcelo: Em 15.

Professor: A média é igual a 15 multiplicado por 0, 6, sendo igual a 9.

Calculamos o desvio padrão, encontrando 1, 8974.

Professor: Temos mais um problema, não podemos utilizar o 5 no item (a).

Marcelo: Por que?

Professor: Se observarmos o gráﬁco, o 5 está localizado bem no meio da coluna, se

usarmos somente o 5, ﬁca faltando metade da coluna, e a coluna toda está no intervalo

entre 4, 5 e 5, 5, por isso usamos o 5, 5.

Adriana: E porque não podemos usar o 4, 5?

Professor: Porque o 5 ﬁcaria de fora do cálculo, e queremos calcular no máximo 5.

E no item (b)?

Ester: Temos que fazer como antes. (Referindo-se ao item (a)).

Professor: Mas utilizamos 7, 5 ou 8, 5? 10, 5 ou 11, 5?

Ester: O 8, 5 e o 11, 5.

Professor: Não, um deles não está correto.

Adriana: É 7, 5?

Professor: Isso mesmo. Por quê?

Adriana: O 8 ﬁcaria de fora.

Através de um esboço, a explicação do porquê utiliza-se o intervalo entre 7, 5 e 11, 5;

foi mais clara.

Professor: E no item (c)?

Ester: Usamos o 10, 5.

Professor: Por quê?

Ester: Lembrei do desenho da aula anterior. Fica tudo para a direita, se fosse 11, 5

o 11 ﬁcaria de fora.

94

4.2 A P L I C A Ç Ã O D A AT I V I D A D E 2

Os alunos não apresentaram grandes diﬁculdades nos cálculos, eles estavam mais

familiarizados com a Tabela, logo encontraram os valores com certa facilidade.

Seguem os cálculos efetuados:

(a)

(b)

(c)

(cid:18)

P

x <

(cid:19)

5, 5 − 9
1, 8974

= P (x < −1, 85)

= Φ(−1, 85)
= 1 − Φ(1, 85)

= 1 − 0, 9678

= 0, 0322.

(cid:18) 7, 5 − 9
1, 8974

P

(cid:54) x (cid:54) 11, 5 − 9
1, 8974

(cid:19)

= P (−0, 79 (cid:54) x (cid:54) 1, 32)

= Φ(1, 32) − Φ(−0, 79)
= Φ(1, 32) − [1 − Φ(0, 79)]

= 0, 9066 − 1 + 0, 7852

= 0, 6918.

(cid:18) 10, 5 − 9
1, 8974

P

(cid:19)

< x

= P (0, 79 < x)

= 1 − Φ(0, 79)

= 1 − 0, 7852

= 0, 2148.

Professor: Os resultado encontrados, se comparados com os anteriores, podem ser

considerados boas aproximações?

Vários alunos: Sim.

Professor: Sempre é possível fazer a aproximação?

Nícolas: Sim.

Muitos alunos concordaram com a resposta do Nícolas, então foi mostrado que a

aproximação é possível quando np (cid:62) 5 e n(1 − p) (cid:62) 5.

95

A P L I C A Ç Ã O D A S AT I V I D A D E S

Ester: Por que não podemos fazer se forem menores do que 5?

Professor: Os resultados podem não ser conﬁáveis.

Adriana: Os resultados anteriores são exatos?

Professor: Sim, são exatos. Então, qual a vantagem em fazer aproximações?

Ester: Fazer menos contas.

Professor: Seria o de reduzir o tempo com cálculos excessivos, quando uma boa

aproximação já é suﬁciente.

4.3 A P L I C A Ç Ã O D A AT I V I D A D E 3

Esta atividade teve início com a seguinte pergunta:

Professor: O que seria uma amostra?

Fabíola: Uma parte de alguma coisa, por exemplo, uma amostra de xampu.

Marcelo: Ou uma amostra de perfume.

Professor: Temos uma amostra quando queremos fazer uma pesquisa sobre algo e

obtemos informações de uma parte da população, como por exemplo, uma pesquisa

eleitoral não entrevista toda a população de uma cidade ou de um país, pois tomaria

muito tempo e seria muita caro.

Os alunos foram divididos em duplas, alguns pediram para ser um trio, logo havia

duplas e trios. Foram distribuídas as folhas destinadas a esta atividade e explicada a

situação-problema.

Solicitando que selecionassem uma amostra da maneira que quisessem. No início

ﬁcaram desorientados, assim foi necessário apresentar um exemplo de como poderiam

obter uma amostra.

Os alunos se empenharam nessa atividade.

As proporções encontradas pelos grupos foram:

0, 76 ; 0, 72 ; 0, 69 ; 0, 62 ; 0, 72 ; 0, 71 ; 0, 87 ; 0, 73 e 0, 58.

A soma feita por Bianca foi igual a 6, 4.

96

4.3 A P L I C A Ç Ã O D A AT I V I D A D E 3

Figura 33: Exemplo do Professor

Fonte: Arquivo próprio do autor.

Figura 34: Participação dos alunos 1

Fonte: Arquivo próprio do autor.

Figura 35: Participação dos alunos 2

Fonte: Arquivo próprio do autor.

Este resultado foi dividido pela quantidade de grupos, onde obteve-se 0, 71.

A quantidade real era de 248 cães e 136 gatos, num total de 384 animais. Portanto,

64, 58% dos animais eram cães e 35, 42% eram gatos.

Professor: Como podemos considerar a nossa aproximação?

Marcelo: Boa.

97

A P L I C A Ç Ã O D A S AT I V I D A D E S

Professor: Por quê?

Marcelo: Chegamos a um resultado muito próximo do real.

A marcação de Adriana me chamou a atenção.

Professor: Por que você só fez uma linha?

Adriana: É porque eu gosto mais de cachorros.

Professor: Mas você percebeu que isso inﬂuenciou o resultado?

Adriana: Comparando com os outros resultados, sim.

Professor: Em uma pesquisa temos que ser imparciais, senão toda a pesquisa pode

ser comprometida.

Angélica: Por que alguns grupos contaram a mesma quantidade de animais mas a

quantidade de cachorros foi diferente?

Professor: Isso depende da região na qual esses grupos obtiveram seus resultados.

Professor: Coletamos ao todo 9 amostras, em uma pesquisa real, quantas amostras

são coletadas?

Nícolas: 10.

Bianca: 20.

Professor: Elas não podem ser muitas, pois a pesquisa tomaria muito tempo e seria

muito cara. Geralmente trabalhamos com uma única amostra.

A seguir seguem as marcações de alguns grupos:

Figura 36: Grupo do Marcelo

Fonte: Arquivo próprio do autor.

98

4.4 A P L I C A Ç Ã O D A AT I V I D A D E 4

Figura 37: Grupo da Ester

Fonte: Arquivo próprio do autor.

Figura 38: Grupo da Adriana

Fonte: Arquivo próprio do autor.

4.4 A P L I C A Ç Ã O D A AT I V I D A D E 4

Antes de iniciar a Atividade, explicou-se que haveria um sorteio e que iríamos obter

uma amostragem aleatória simples.

Professor: O que é uma amostragem?

Camila: É uma amostra de algo.

Professor: O que é uma amostragem aleatória simples?

Pedro: É uma amostra que você não sabe o que vai obter.

Professor: Em uma amostragem aleatória simples todos o elementos tem a mesma

chance de ser sorteados.

99

A P L I C A Ç Ã O D A S AT I V I D A D E S

Adriana: E como se faz isso?

Professor: Sempre que uma peça for sorteada ela é devolvida para que a probabili-

dade seja sempre a mesma. Chamamos de retirada com reposição.

Marcelo: E como a gente sabe o que foi sorteado?

Professor: Anotamos os resultados.

Explicada a situação-problema, os alunos foram orientados a considerar que os bo-

tões escuros representariam as peças não defeituosas enquanto os botões claros repre-

sentariam as peças defeituosas.

Figura 39: Botões representando peças

Fonte: Arquivo próprio do autor.

Marcelo, Ester e Carla ﬁzeram o sorteio com todos os alunos enquanto, anotava os

resultados no quadro. Foi feito o sorteio de 40 peças, apesar de haver 32 alunos na

sala.

Figura 40: Sorteio de uma peça

Fonte: Arquivo próprio do autor.

No primeiro sorteio obtivemos uma peça escura.

100

4.4 A P L I C A Ç Ã O D A AT I V I D A D E 4

Figura 41: Sorteio de uma peça escura

Fonte: Arquivo próprio do autor.

Figura 42: Anotando o resultado

Fonte: Arquivo próprio do autor.

O resultado foi anotado no quadro.

A primeira peça clara apareceu no sorteio da 7o peça.

Figura 43: Sorteio de uma peça clara

Fonte: Arquivo próprio do autor.

Enquanto as peças eram sorteadas, alguns alunos ﬁzeram comentários:

Karina: Tem mais botões escuros? (Ela fez este questionamento três vezes).

101

A P L I C A Ç Ã O D A S AT I V I D A D E S

Adriana: Eu tirei um botão escuro, eu não sou defeituosa.

Após as 40 retiradas foi veriﬁcado que 35 botões eram escuros e 5 eram claros.

Figura 44: Resultado do sorteio

Fonte: Arquivo próprio do autor.

Professor: O que é intervalo de conﬁança?

Marcelo: Quando se tem noção que a peça está em boas condições.

Karina: Quando você acredita que as peças estão boas.

Professor: E o que é um intervalo de conﬁança de 95%?

Marcelo: Que 95% das peças não apresenta vício.

Professor: Um intervalo de conﬁança de 95% é um intervalo em que você conﬁa

que a sua aﬁrmação está correta em 95% das amostras.

Apresentado o cálculo do intervalo de conﬁança, explicando que

(cid:114)

zα/2

ˆp(1 − ˆp)
n

seria o erro máximo cometido, n o número de retiradas e ˆp a proporção de peças

defeituosas na amostra, zα/2 explicando com mais detalhes.

Professor: Mas, antes de iniciar temos algo muito importante para veriﬁcar.

Ester: O quê?

Professor: Se podemos fazer a aproximação pela normal.

Marcelo: Podemos.

Professor: Como você sabe?

Marcelo: Fiz as contas.

Professor: Quais contas?

102

4.4 A P L I C A Ç Ã O D A AT I V I D A D E 4

Marcelo: Fiz 0, 125 · 40 = 5 e 0, 875 · 40 = 35.

Professor: O intervalo de conﬁança é 1 − α é igual a 0, 95, então α é igual a...

Ester: α é igual a 0, 05.

Professor: E α/2?

Ester: É igual a 0, 025.

Professor: Vamos fazer uma ﬁgura que represente o que acabamos de falar.

A ﬁgura em questão é a Figura 45.

Figura 45: Intervalo de conﬁança

Fonte: Arquivo próprio do autor.

Professor: A nossa tabela serve para os valores à direita do centro. Então temos que

fazer 1 − 0, 025.

Adriana: Que é igual a 0, 975.

Professor: Isso. Agora procurem 0, 975 na tabela.

Renato foi o primeiro a encontrar o valor correto de zα/2 que, neste caso, é 1, 96,
logo todos encontraram o valor correto, demonstrando mais habilidade em manusear

a tabela.

Obtemos o intervalo de conﬁança a seguir:

(cid:34)

(cid:114)

ˆp − zα/2

ˆp(1 − ˆp)
n

, ˆp + zα/2

(cid:114)

(cid:35)

ˆp(1 − ˆp)
n

= [0, 0225; 0, 2275] .

Os alunos ﬁzeram os cálculos com o auxílio de uma calculadora e orientação do

professor.

Professor: O que vem a ser uma hipótese?

103

A P L I C A Ç Ã O D A S AT I V I D A D E S

Marcelo: É uma coisa que você não sabe se é verdade e quer testar para saber se é

mesmo verdade.

Professor: Qual a hipótese a ser testada?

Adriana: Que 10% das peças serem defeituosas é verdade.

Professor: A hipótese inicial deve ser aceita ou rejeitada?

Adriana: Aceita.

Professor: Por quê?

Adriana: Ela está dentro do intervalo de conﬁança.

Professor: A quantidade de botões é de 45 claros e 255 escuros, 15% dos botões são

claros. Este valor está próximo do encontrado?

Ester: Sim.

Professor: E está dentro do intervalo de conﬁança?

Adriana: Está.

Professor: Pelo que vimos, a decisão de aceitar a hipótese foi uma decisão acertada?

Marcelo: Sim, foi, porque está dentro do intervalo de conﬁança.

Professor: Precisamos fazer um teste para descobrir.

Ester: Qual teste?

Foi apresentado o teste a seguir e seu resultado.

z =

(cid:112)

ˆp − p0
ˆp(1 − ˆp)/n

=

(cid:112)

0, 125 − 0, 1
0, 125 · 0, 875/40

= 0, 478.

Adriana: O que é p0?

Professor: É o valor que o fabricante informou. Como o resultado está entre −1, 96

e 1, 96 devemos aceitar a hipótese como verdadeira.

Marcelo: Então acertamos.

104

5

C O N S I D E R A Ç Õ E S F I N A I S

Ao pensar um determinado tema para escrever a conclusão do curso, queria um

assunto não exclusivamente para usar em sala de aula, nas aulas de matemática, mas

sim um assunto que extrapolasse os muros da escola, e que contribuísse de forma

signiﬁcativa na vida em sociedade dos jovens educandos, como também a utilidade

em outras áreas do conhecimento. Desta forma, a estatística foi escolhida, justamente

por cumprir as expectativas desejadas.

Logo surgiram as situações-problema entre elas: como seria se algum produto de

certa empresa onde uma pequena porcentagem dos itens produzidos por uma determi-

nada máquina tivesse algum defeito e esta empresa quisesse saber qual a porcentagem

destes itens, sem perder muito tempo veriﬁcando-os individualmente?

O principal objetivo seria veriﬁcar qual o método estatístico apropriado e de maior

conﬁabilidade para tal situação e principalmente mostrar aos alunos do Ensino Médio

de que forma é realizada uma estimativa a partir de uma amostra e porque ela fun-

ciona; como também veriﬁcar se o tamanho da amostra tem inﬂuência no resultado

obtido.

No entanto, em meados de 2015, após a leitura sobre a história da estatística, o

foco mudou completamente, então surgiu o interesse pela inferência estatística, o qual

considerei um assunto extremamente mais atrativo.

E consequentemente surgiu a ideia de construir a Tábua de Galton, sendo necessário

primeiramente uma atividade introdutória; a atividade foi considerada “maçante” pe-

los alunos; porque envolveu uma grande quantidade de cálculos; diferentemente das

posteriores atividades desenvolvidas.

A partir da segunda atividade, os alunos utilizaram a Tábua, despertando mais aten-

ção em todos, pois queriam ver as bolas batendo nos pregos e caindo nas canaletas.

105

C O N S I D E R A Ç Õ E S F I N A I S

O resultado foi satisfatório visto que aproximou-se muito da curva normal, principal-

mente o lado direito.

Na terceira atividade, o resultado obtido ﬁcou muito próximo do real, porém poderia

ser bem melhor, se as escolhas escolhas dos locais ocorressem de forma mais aleatória,

a pouca quantidade de exemplos inﬂuenciou a escolha dos alunos, e os resultados

obtidos na quarta atividade foram muito próximo do real.

Ao término das diversas atividades, exercícios, conversas, explicações, cálculos; conclui-

se que os resultados obtidos foram excelentes; principalmente porque todos os alunos

desenvolveram várias habilidades, entre elas compreenderam a importância de uma

pesquisa estatística e percebiam o impacto de uma única amostra na pesquisa.

Ao longo do trabalho algumas diﬁculdades surgiram, em especial a questão do

tempo para a aplicação das atividades, pois foram duas aulas semanais e o prazo para

o término do desenvolvimento das atividades.

Outro aspecto relevante foi que a estatística é tema do ﬁnal do terceiro ano, sendo

que as atividades foram trabalhadas no início do ano letivo, entre os meses de março

e abril, ou seja, os alunos ainda não possuíam completo domínio do assunto.

106

A

TA B E L A S

Tabela 2: Área de Φ(x) sob a curva normal padrão à esquerda de x.

X

0, 0

0, 1

0, 2

0, 3

0, 4

0, 5

0, 6

0, 7

0, 8

0, 9

1, 0

1, 1

1, 2

1, 3

1, 4

1, 5

1, 6

1, 7

1, 8

1, 9

2, 0

2, 1

2, 2

2, 3

2, 4

2, 5

2, 6

2, 7

2, 8

2, 9

3, 0

3, 1

3, 2

3, 3

3, 4

0, 00

0, 5000

0, 5398

0, 5793

0, 6179

0, 6554

0, 6915

0, 7257

0, 7580

0, 7881

0, 8159

0, 8413

0, 8643

0, 8849

0, 9032

0, 9192

0, 9332

0, 9452

0, 9554

0, 9641

0, 9713

0, 9772

0, 9821

0, 9861

0, 9893

0, 9918

0, 9938

0, 9953

0, 9965

0, 9974

0, 9981

0, 9987

0, 9990

0, 9993

0, 9995

0, 9997

0, 01

0, 5040

0, 5438

0, 5832

0, 6217

0, 6591

0, 6950

0, 7291

0, 7611

0, 7910

0, 8186

0, 8438

0, 8665

0, 8869

0, 9049

0, 9207

0, 9345

0, 9463

0, 9564

0, 9649

0, 9719

0, 9778

0, 9826

0, 9864

0, 9896

0, 9920

0, 9940

0, 9955

0, 9966

0, 9975

0, 9982

0, 9987

0, 9991

0, 9993

0, 9995

0, 9997

0, 02

0, 5080

0, 5478

0, 5871

0, 6255

0, 6628

0, 6985

0, 7324

0, 7642

0, 7939

0, 8212

0, 8461

0, 8686

0, 8888

0, 9066

0, 9222

0, 9357

0, 9474

0, 9573

0, 9656

0, 9726

0, 9783

0, 9830

0, 9868

0, 9898

0, 9922

0.9941

0, 9956

0, 9967

0, 9976

0, 9982

0, 9987

0, 9991

0, 9994

0, 9995

0, 9997

0, 03

0, 5120

0, 5517

0, 5910

0, 6293

0, 6664

0, 7019

0, 7357

0, 7673

0, 7967

0, 8238

0, 8485

0, 8708

0, 8907

0, 9082

0, 9236

0, 9370

0, 9484

0, 9582

0, 9664

0, 9732

0, 9788

0, 9834

0, 9871

0, 9901

0, 9925

0, 9943

0, 9957

0, 9968

0, 9977

0, 9983

0, 9988

0, 9991

0, 9994

0, 9996

0, 9997

0, 04

0, 5160

0, 5557

0, 5948

0, 6331

0, 6700

0, 7054

0, 7389

0, 7704

0, 7995

0, 8264

0, 8508

0, 8729

0, 8925

0, 9099

0, 9251

0, 9382

0, 9495

0, 9591

0, 9671

0, 9738

0, 9793

0, 9838

0, 9875

0, 9904

0, 9927

0, 9945

0, 9959

0, 9969

0, 9977

0, 9984

0, 9988

0, 9992

0, 9994

0, 9996

0, 9997

0, 05

0, 5199

0, 5596

0, 5987

0, 6368

0, 6736

0, 7088

0, 7422

0, 7734

0, 8023

0, 8289

0, 8531

0, 8749

0, 8944

0, 9115

0, 9265

0, 9394

0, 9505

0, 9599

0, 9678

0, 9744

0, 9798

0, 9842

0, 9878

0, 9906

0, 9929

0, 9946

0, 9960

0, 9970

0, 9978

0, 9984

0, 9989

0, 9992

0, 9994

0, 9996

0, 9997

0, 06

0, 5239

0, 5636

0, 6026

0, 6406

0, 6772

0, 7123

0, 7454

0, 7764

0, 8051

0, 8315

0, 8554

0, 8770

0, 8962

0, 9131

0, 9279

0, 9406

0, 9515

0, 9608

0, 9686

0, 9750

0, 9803

0, 9846

0, 9881

0, 9909

0, 9931

0, 9948

0, 9961

0, 9971

0, 9979

0, 9985

0, 9989

0, 9992

0, 9994

0, 9996

0, 9997

0, 07

0, 5279

0, 5675

0, 6064

0, 6443

0, 6808

0, 7157

0, 7486

0, 7794

0, 8078

0, 8340

0, 8577

0, 8790

0, 8980

0, 9147

0, 9292

0, 9418

0, 9525

0, 9616

0, 9693

0, 9756

0, 9808

0, 9850

0, 9884

0, 9911

0, 9932

0, 9949

0, 9962

0, 9972

0, 9979

0, 9985

0, 9989

0, 9992

0, 9995

0, 9996

0, 9997

0, 08

0, 5319

0, 5714

0, 6103

0, 6480

0, 6844

0, 7190

0, 7517

0, 7823

0, 8106

0, 8365

0, 8599

0, 8810

0, 8997

0, 9162

0, 9306

0, 9429

0, 9535

0, 9625

0, 9699

0, 9761

0, 9812

0, 9854

0, 9887

0, 9913

0, 9934

0, 9951

0, 9963

0, 9973

0, 9980

0, 9986

0, 9990

0, 9993

0, 9995

0, 9996

0, 9997

0, 09

0, 5359

0, 5753

0, 6141

0, 6517

0, 6879

0, 7224

0, 7549

0, 7852

0, 8133

0, 8389

0, 8621

0, 8830

0, 9015

0, 9177

0, 9319

0, 9441

0, 9545

0, 9633

0, 9706

0, 9767

0, 9817

0, 9857

0, 9890

0, 9916

0, 9936

0, 9952

0, 9964

0, 9974

0, 9981

0, 9986

0, 9990

0, 9993

0, 9995

0, 9997

0, 9998

Fonte: Arquivo do próprio autor, baseado em [15].

107

TA B E L A S

v

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

35

40

50

60

Tabela 3: Distribuição t de Student para um nível de conﬁança 1 − α.

0, 50

0, 60

0, 70

0, 80

0, 90

0, 95

0, 96

0, 98

0, 99

1, 000

1, 376

1, 963

3, 078

6, 314

12, 706

15, 894

31, 821

63, 657

0, 816

1, 061

1, 386

1, 886

2, 920

0, 765

0, 978

1, 250

1, 638

2, 353

0, 741

0, 941

1, 190

1, 533

2, 132

0, 727

0, 920

1, 156

1, 476

2, 015

0, 718

0, 906

1, 134

1, 440

1, 943

0, 711

0, 896

1, 119

1, 415

1, 895

0, 706

0, 889

1, 108

1, 397

1, 860

0, 703

0, 883

1, 100

1, 383

1, 833

0, 700

0, 879

1, 093

1, 372

1, 812

0, 697

0, 876

1, 088

1, 363

1, 796

0, 695

0, 873

1, 083

1, 356

1, 782

0, 694

0, 870

1, 079

1, 350

1, 771

0, 692

0, 868

1, 076

1, 345

1, 761

0, 691

0, 866

1, 074

1, 341

1, 753

0, 690

0, 865

1, 071

1, 337

1, 746

0, 689

0, 863

1, 069

1, 333

1, 740

0, 688

0, 862

1, 067

1, 330

1, 734

0, 688

0, 861

1, 066

1, 328

1, 729

0, 687

0, 860

1, 064

1, 325

1, 725

0, 686

0, 859

1, 063

1, 323

1, 721

0, 686

0, 858

1, 061

1, 321

1, 717

0, 685

0, 858

1, 060

1, 319

1, 714

0, 685

0, 857

1, 059

1, 318

1, 711

0, 684

0, 856

1, 058

1, 316

1, 708

0, 684

0, 856

1, 058

1, 315

1, 706

0, 684

0, 855

1, 057

1, 314

1, 703

0, 684

0, 855

1, 056

1, 313

1, 701

0, 683

0, 854

1, 055

1, 311

1, 699

0, 683

0, 854

1, 055

1, 310

1, 697

0, 682

0, 852

1, 052

1, 306

1, 690

0, 681

0, 851

1, 050

1, 303

1, 684

0, 679

0, 849

1, 047

1, 299

1, 676

0, 679

0, 848

1, 045

1, 296

1, 671

4, 303

3, 182

2, 776

2, 571

2, 447

2, 365

2, 306

2, 262

2, 228

2, 201

2, 179

2, 160

2, 145

2, 131

2, 120

2, 110

2, 101

2, 093

2, 086

2, 080

2, 074

2, 069

2, 064

2, 060

2, 056

2, 052

2, 048

2, 045

2, 042

2, 030

2, 021

2, 009

2, 000

1, 980

1, 960

4, 849

3, 482

2, 998

2, 756

2, 612

2, 517

2, 449

2, 398

2, 359

2, 328

2, 303

2, 282

2, 264

2, 248

2, 235

2, 224

2, 214

2, 205

2, 197

2, 189

2, 183

2, 177

2, 172

2, 166

2, 162

2, 158

2, 154

2, 150

2, 147

2, 133

2, 123

2, 109

2, 099

2, 076

2, 054

6, 965

4, 541

3, 747

3, 365

3, 143

2, 998

2, 896

2, 821

2, 764

2, 718

2, 681

2, 650

2, 624

2, 602

2, 583

2, 567

2, 552

2, 539

2, 528

2, 518

2, 508

2, 500

2, 492

2, 485

2, 479

2, 473

2, 467

2, 462

2, 457

2, 438

2, 423

2, 403

2, 390

2, 358

2, 326

9, 925

5, 841

4, 604

4, 032

3, 707

3, 499

3, 355

3, 250

3, 169

3, 106

3, 055

3, 012

2, 977

2, 947

2, 921

2, 898

2, 878

2, 861

2, 845

2, 831

2, 819

2, 807

2, 797

2, 787

2, 779

2, 771

2, 763

2, 756

2, 750

2, 724

2, 704

2, 678

2, 660

2, 617

2, 576

120
0, 677
∞ 0, 674

0, 845

1, 041

1, 289

1, 658

0, 842

1, 036

1, 282

1, 645

Fonte: Arquivo do próprio autor, baseado em [5] e [8].

108

Tabela 4: Distribuição qui-quadrado, valores de α.

v

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

0, 99
−

0, 020

0, 115

0, 297

0, 554

0, 872

1, 239

1, 646

2, 088

2, 558

3, 053

3, 571

4, 107

4, 660

5, 229

5, 812

6, 408

7, 015

7, 633

8, 260

8, 897

9, 542

10, 196

10, 856

11, 524

12, 198

12, 879

13, 565

14, 258

14, 953

0, 98
−

0, 040

0, 185

0, 429

0, 752

1, 134

1, 564

2, 032

2, 532

3, 059

3, 609

4, 178

4, 756

5, 368

5, 985

6, 614

7, 255

7, 906

8, 567

9, 237

9, 915

10, 600

11, 293

11, 992

12, 697

13, 409

14, 125

14, 847

15, 574

16, 306

0, 975

0, 001

0, 051

0, 216

0, 484

0, 831

1, 237

1, 690

2, 180

2, 700

3, 247

3, 816

4, 404

5, 009

5, 629

6, 262

6, 908

7, 564

8, 231

8, 906

9, 591

10, 283

10, 982

11, 688

12, 401

13, 120

13, 844

14, 573

15, 308

16, 047

16, 971

0, 95

0, 004

0, 103

0, 352

0, 711

1, 145

1, 635

2, 167

2, 733

3, 325

3, 940

4, 575

5, 226

5, 892

6, 571

7, 261

7, 962

8, 672

9, 390

10, 117

10, 851

11, 591

12, 338

13, 091

13, 848

14, 611

15, 379

16, 151

16, 928

17, 708

18, 493

0, 90

0, 016

0, 211

0, 584

1, 064

1, 610

2, 204

2, 833

3, 490

4, 168

4, 865

5, 578

6, 304

7, 042

7, 790

8, 547

9, 312

10, 085

10, 865

11, 651

12, 443

13, 240

14, 041

14, 848

15, 659

16, 473

17, 292

18, 114

18, 939

19, 768

20, 599

0, 10

2, 706

4, 605

6, 251

7, 779

9, 236

10, 645

12, 017

13, 362

14, 684

15, 987

17, 275

18, 549

19, 812

21, 064

22, 307

23, 542

24, 769

25, 989

27, 204

28, 412

29, 615

30, 813

32, 007

33, 196

34, 382

35, 563

36, 741

37, 916

39, 087

40, 256

0, 05

3, 841

5, 991

7, 815

9, 488

11, 070

12, 592

14, 067

15, 507

16, 919

18, 307

19, 675

21, 026

22, 362

23, 685

24, 996

26, 296

27, 587

28, 869

30, 144

31, 410

32, 671

33, 924

35, 172

36, 415

37, 652

38, 885

40, 113

41, 337

42, 557

43, 773

0, 025

5, 024

7, 378

9, 348

11, 143

12, 832

14, 449

16, 013

17, 534

19, 023

20, 483

21, 920

23, 337

24, 736

26, 119

27, 488

28, 854

30, 191

31, 526

32, 852

34, 170

35, 479

36, 781

38, 076

39, 364

40, 646

41, 923

43, 194

44, 461

45, 722

46, 979

0, 02

5, 412

7, 824

9, 837

11, 668

13, 388

15, 033

16, 622

18, 168

19, 679

21, 161

22, 618

24, 054

25, 472

26, 873

28, 259

29, 633

30, 995

32, 346

33, 687

35, 020

36, 343

37, 659

38, 968

40, 270

41, 566

42, 856

44, 140

45, 419

46, 693

47, 962

0, 01

6, 635

9, 210

11, 345

13, 277

15, 086

16, 812

18, 475

20, 090

21, 666

23, 209

24, 725

26, 217

27, 688

29, 141

30, 578

32, 000

33, 409

34, 805

36, 191

37, 566

38, 932

40, 289

41, 638

42, 980

44, 314

45, 642

46, 963

48, 278

49, 588

50, 892

Fonte: Arquivo do próprio autor, baseado em [5] e [8].

TA B E L A S

109

B

R E C U R S O S A U X I L I A R E S

Figura 46: Cães e gatos

Fonte: Arquivo do próprio autor, baseado em [19].

Crédito das imagens: http://emojipedia.org - Acessado em 30/01/16.

111

B I B L I O G R A F I A

[1] BERGER, Roger L.; CASELLA, George. Inferência Estatística, 2. ed. São Paulo:

Cengage Learning, 2014.

[2] BOLFARINE, Heleno; SANDOVAL, Mônica C. Introdução à inferência estatística,

2. ed. Rio de Janeiro: SBM, 2010.

[3] BOYER, Carl. B. História da Matemática, trad. Elza F. Gomide, 3. ed. São Paulo:

Blücher, 2010.

[4] BURTON, David M. The history of mathematics : an introduction, , 7. ed. New

York: McGraw-Hill, 2011.

[5] BUSSAB, Wilton de O., MORETTIN, Pedro A. Estatística básica, 5. ed. São

Paulo: Saraiva, 2002.

[6] CARVALHO, Paulo C. P.; MORGADO, Augusto C. Matemática Discreta: Coleção

PROFMAT, 1. ed. Rio de Janeiro: SBM, 2014.

[7] EVES, Howard. Introdução à história da matemática, trad. Hygino H. Domin-

gues, 5. ed. Campinas: Unicamp, 2011.

[8] FARBER, Betsy; LARSON Ron. Estatística aplicada, 4. ed. São Paulo: Pearson

Prentice Hall, 2010.

[9] FLEMMING, Diva M.; GONÇALVES, Mírian B. Cálculo A: funções, limite, deriva-

ção, integração, 5. ed. São Paulo: Makron, 2002.

[10] FREUND, John E. Estatística aplicada: economia, adiministação e contabilidade,

11. ed. Porto Alegre: Bookman, 2006.

[11] GRANDO, Regina C.; NACARATO, Aldair M. ; et al. Estatística e probabilidade

na educação básica: professores narrando suas experiências, 1. ed. Campinas:

Mercado de Letras, 2013.

[12] KEEPING, E. S. Introduction to statistical inference, New York: Dover, 1995.

[13] NACIONAIS, Parâmetros Curriculares. Ensino Médio. Brasília: Ministério da

Educação, 2000.

113

BIBLIOGRAFIA

[14] ROONEY, Anne. A História da Matemática: Desde a criação das pirâmides até a

exploração do inﬁnito,São Paulo: Mboobs, 2012.

[15] ROSS, Sheldon. Probabilidade: um curso moderno com aplicações, 8. ed. Porto

Alegre: Bookman, 2010.

[16] SANTANA, Mario de S. Estatística para professores da educação básica: Concei-

tos e aprendizagem para a cidadania, 1. ed. Curitiba: CRV, 2012.

[17] SCHAY, Géza. Introduction to Probability with Statisctical Applications, Boston:

Birkäuser, 2007.

[18] STIGLER, Stephen M. The History of Statistics: The Measurement of Uncertainty

before 1900, 9. ed. Cambridge: Harvard University Press, 2003.

[19] https://www.ime.usp.br/ativestat/atividades/aula/sa08

- Acessado

em

29/01/16.

114


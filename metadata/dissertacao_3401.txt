Universidade Federal do Piau´ı

Centro de Ci^encias da Natureza

P´os-graduac¸˜ao em Matem´atica

Mestrado Profissional em Matem´atica - PROFMAT

Aplica¸c˜ao Matem´atica no Mecanismo de Pesquisa do

Google

Rubens de Carvalho Almondes

Teresina - 2016

Rubens de Carvalho Almondes

Disserta¸c˜ao de Mestrado:

Aplica¸c˜ao Matem´atica no Mecanismo de Pesquisa do Google

Disserta¸c˜ao submetida ao Programa de

P´os-Gradua¸c˜ao - Mestrado Proﬁssional

em Matem´atica em Rede Nacional como

requisito parcial para a obten¸c˜ao do grau

de Mestre em Matem´atica.

Orientador:

Prof. Dr. Paulo Alexandre Ara´ujo Sousa

Teresina - 2016

Copia da folha de rosto assinada pelos membros da banca examinadora.

Ficha catalogr´aﬁca editada pela biblioteca setorial do CCN.

Almondes, R. C.

xxxx

Aplica¸c˜ao Matem´atica no Mecanismo de Pesquisa do Google.

Teresina, 2016.

Orientador: Prof. Dr. Paulo Alexandre Ara´ujo Sousa
1. ´Area de Concentra¸c˜ao

CDD 516.36

Dedico este trabalho a meus av´os; V´o Maria (In me-

moriam), V^o Manoel (In memoriam), V´o Teresa e

V^o Jos´e (In memoriam).

Agradecimentos

Agrade¸co primeiramente a Deus, Pai Criador, pelo dom da vida vivenciado a cada novo

amanhecer;

Agrade¸co a minha fam´ılia: pai (Ruﬁno), m˜ae (Bernadete), esposa (J´essica) e irm˜as (Rute,

Raquel, Rafaela, Rebeca e Renata), pelo irrestrito incentivo e motiva¸c˜ao di´aria, princi-

palmente nos momentos mais dif´ıceis;

Agrade¸co ao meu orientador, Prof. Dr. Paulo Alexandre Ara´ujo Sousa, pela paciˆencia e

insistˆencia durante todo processo;

Agrade¸co aos amigos de turma que caminharam, vivenciaram comigo e, por muitas vezes,

me motivaram a prosseguir essa jornada. De modo especial e fraterno Bruno, Delano,

Gideone, Gilson, Huerllen, Jerson, Pedro, Perivaldo, Queiroz, Raimundo, Renato, Renn´e,

Samuel e Viviam;

Agrade¸co aos amigos de Picos-PI que entenderam minha ausˆencia mas nunca deixaram

de acreditar e se fazerem presentes em meu dia a dia;

Agrade¸co ao IFPI, institui¸c˜ao a qual fa¸co parte e que permitiu a minha presen¸ca sema-

nalmente aos encontros com a ﬂexibiliza¸c˜ao de meus hor´arios de trabalho;

Agrade¸co `A PROFMAT/UFPI que oportunizou a realiza¸c˜ao deste sonho;

Agrade¸co aos professores da UFPI que deram o suporte necess´ario para a concretiza¸c˜ao

desta jornada;

Agrade¸co a CAPES pelo apoio ﬁnanceiro que foi de fundamental importˆancia para a

concretiza¸c˜ao deste momento.

“Nota-se entre os matem´aticos, uma ima-

gina¸c˜ao assombrosa... Repetimos: Havia

mais imagina¸c˜ao na cabe¸ca de Arquime-

des do que na de Homero”.

Fran¸cois Marie Arouet (Voltaire).

Resumo

Neste trabalho trataremos de forma simpliﬁcada os conceitos matem´aticos envolvidos em

um dos algoritmos utilizados no sistema de classiﬁca¸c˜ao das p´aginas pelo Google: o Pa-

geRank. Abordaremos de maneira informal, a ideia de se atribuir uma pontua¸c˜ao de

importˆancia para as p´aginas da internet e posteriormente formalizaremos matematica-
mente, com o aux´ılio da ´Algebra Linear, bem como do ponto de vista probabil´ıstico. O

presente trabalho tem por objetivo estimular os estudantes ao aprendizado de temas como

Matrizes, Determinantes e Sistemas de Equa¸c˜oes Lineares tendo como plano de fundo a

internet, a qual possui uma presen¸ca quase que constante na vida dos alunos e assim

servir como fonte de inspira¸c˜ao para o aprendizado da matem´atica.

Palavras-chave: Internet. Google. PageRank. ´Algebra Linear

Abstract

In this deal work simpliﬁed mathematical concepts involved in one of the algorithms used

in the classiﬁcation system of the pages by Google: the PageRank. We discuss informally

the idea of assigning a score of importance to websites and then mathematically forma-

lize, with the help of linear algebra and probabilistic point of view. This work aims to

encourage students to learning topics such as matrices, determinants and linear equations

systems having as background the internet, which has a presence almost constant in the

lives of students and thus serve as a source of inspiration for learning of mathematics.

Keywords: Internet. Google. PageRank. Linear Algebra

Sum´ario

Agradecimentos

Resumo

Abstract

1 Introdu¸c˜ao

2 No¸c˜oes Preliminares

2.1 Vetores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

i

i

ii

1

4

4

6

2.3 Autovalores e Autovetores . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3 Cadeias de Markov

4 Algoritmo PageRank

16

20

4.1 A Matem´atica do Google . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

4.1.1 Descri¸c˜ao do C´alculo PageRank . . . . . . . . . . . . . . . . . . . . 21
4.1.2 Do ponto de vista da ´Algebra Linear

. . . . . . . . . . . . . . . . . 25

4.1.3 Ponto de vista probabil´ıstico . . . . . . . . . . . . . . . . . . . . . . 26

4.1.4 Grafos desconectados . . . . . . . . . . . . . . . . . . . . . . . . . . 26

5 Considera¸c˜oes Finais

Refer^encias Bibliogr´aficas

30

32

iii

Cap´ıtulo 1

Introdu¸c˜ao

Durante as duas ´ultimas d´ecadas assistimos a um impulso tecnol´ogico. No ano de

1994, haviam menos de 3 mil sites. Cerca de 20 anos depois, em 2014, a marca de 1

bilh˜ao de sites em todo o mundo ´e alcan¸cada, no entanto, devido ao n´umero de p´aginas

desativadas, houve um decr´escimo, conforme ﬁgura 1.1. No in´ıcio de 2016 a marca de

1 bilh˜ao foi alcan¸cada novamente e desde mar¸co estabilizou acima dessa quantidade, de

acordo com o site Internet Live Stats, que fornece estat´ısticas em tempo real sobre o uso

da rede.

Figura 1.1: 1.50.5 Quantidade de sites na internet

Fonte: http://www.internetlivestats.com/total-number-of-websites/

´E not´orio o crescimento exponencial da Internet. Mesmo navegando de forma ocasi-

onal ´e o suﬁciente para que sejamos convencidos de que h´a uma enorme quantidade de

informa¸c˜oes e links dispon´ıveis. No entanto, todas estas informa¸c˜oes se tornam in´uteis,

1

Cap´ıtulo 1.

Introdu¸c˜ao

2

a menos que tenhamos uma forma de classiﬁca¸c˜ao e pesquisa. Vivemos na era da in-

forma¸c˜ao, a internet faz parte de nossas vidas e boa parte desta informa¸c˜ao ﬁca a apenas

um clique de distˆancia. Basta abrirmos um site de busca, como por exemplo Google,

Bing ou Yahoo, digitar a palavra ou termo que se deseja procurar, que ser˜ao exibidos

uma lista de p´aginas relevantes para a sua pesquisa. Mas como ´e que um site de busca

realmente funciona? Desde o primeiro mecanismo de busca, no in´ıcio da d´ecada de 1990,

para os modernos motores de busca que usamos hoje, o problema de decidir a relevˆancia

das informa¸c˜oes dispon´ıveis on-line tem sido uma quest˜ao crucial.

´E razo´avel imaginar que um site de busca mant´em um ´ındice de todas as p´aginas

da web, e quando o usu´ario digita uma pesquisa, o mecanismo de busca contido no site

navega atrav´es de seu ´ındice e conta as ocorrˆencias das palavras, ou termos, digitados em

cada arquivo web. As p´aginas com maior n´umero de ocorrˆencia das palavras pesquisadas

ser˜ao exibidas para o usu´ario.

Isto costumava ser a imagem correta no in´ıcio dos anos 1990, quando os primeiros mo-

tores de busca utilizavam sistemas de classiﬁca¸c˜ao baseados em textos para decidir quais

p´aginas que s˜ao mais relevantes em uma determinada pesquisa. Existia, no entanto, uma

s´erie de problemas com essa abordagem. Uma pesquisa sobre um termo comum, como

“internet” era problem´atico, bem como a possibilidade de encontrar p´aginas contendo cen-

tenas do mesmo termo pesquisado. Al´em disso, suponha que queiramos encontrar alguma

informa¸c˜ao sobre UFPI. Ao fazer uma busca sobre “UFPI” esperamos que “www.ufpi.br”

seria o resultado mais relevante para a nossa consulta. Contudo, pode haver milh˜oes de

p´aginas na web que usam termo UFPI e “www.ufpi.br” pode n˜ao ser onde o termo apare¸ca

com tanta frequˆencia. Suponhamos ainda que decidimos construir site que contenha ape-

nas a palavra “UFPI” repetida in´umeras de vezes, ent˜ao para um motor de busca que

conta o n´umero de ocorrˆencias das palavras, o nosso site seria o primeiro a ser exibido, o

que n˜ao seria relevante para quem busca.

Dentre todos os buscadores, o Google se destacou adquirindo uma supremacia em

quest˜oes de meses, tudo isto gra¸cas ao seu algoritmo de classiﬁca¸c˜ao de resultados: o

algoritmo PageRank.

O presente trabalho tem por objetivo o estudo de matrizes, apresentando a aplica¸c˜ao

em um dos mecanismo de pesquisa mais utilizados no mundo. A op¸c˜ao de abordar no

contexto da internet, mas especiﬁcamente o mecanismo de pesquisa do Google, e utiliz´a-lo

Cap´ıtulo 1.

Introdu¸c˜ao

3

com plano de fundo, serve de motiva¸c˜ao para o aprofundamento do estudo da ´Algebra

Linear, visto que ´e algo presente em nosso dia a dia e a curiosidade do “como funciona”faz

agu¸car nossa imagina¸c˜ao e motivar o aprofundamento do tema.

No cap´ıtulo 2 ser˜ao abordados os conceitos de Vetores, Matrizes, Autovetores e Au-

tovalores, bem como algumas propriedades que servir˜ao de base para o nosso estudo. O

cap´ıtulo 3 introduz a deﬁni¸c˜ao de Matrizes Coluna Estoc´astica e sua rela¸c˜ao com o pro-

cesso aleat´orio denominado Cadeias de Markov aplicando-os para modelarmos o problema

de encontrar uma pontua¸c˜ao de importˆancia para cada uma das p´aginas da internet. No

capitulo seguinte ´e descrito o algor´ıtimo do mecanismo de pesquisa do Google, o Pa-
geRank, tanto do ponto de vista probabil´ıstico como da ´Algebra Linear. Por ﬁm, no
´ultimo cap´ıtulo ´e destacado a importˆancia da ´Algebra Linear na constru¸c˜ao de modelos

matem´aticos para o desenviolamento de diversas ´areas.

Cap´ıtulo 2

No¸c˜oes Preliminares

Este cap´ıtulo ´e destinado `as no¸c˜oes preliminares onde abordaremos as deﬁni¸c˜oes de

vetores e matrizes, bem como algumas propriedades e opera¸c˜oes, de modo a dar suporte

ao desenvolvimento do presente trabalho. Para os leitores que sentirem necessidade de

uma explana¸c˜ao mais detalhada dos conceitos citados acima, al´em daquelas apresentadas

no decorrer do texto, indicamos a leitura de [1], [3] e [6]. Para tal, denotemos o conjunto

dos n´umeros naturais {1, 2, 3, · · · } por N, assim como o conjunto de todos os n´umeros reais

ser´a representado por R.

2.1 Vetores

Um vetor v, de comprimento n, ´e simplesmente uma lista ordenada contendo n ele-

mentos, com n ∈ N, sendo estes chamados entradas do vetor. Chamamos de vetor coluna

quando a lista de suas entradas ´e apresentado na vertical. A nota¸c˜ao de um vetor coluna

v de entradas x1, x2, · · · , xn ´e exibida a seguir:

v =











.











x1

x2
...
xn

A princ´ıpio, as entradas de um vetor podem ser quaisquer objetos, desde palavras,

4

Cap´ıtulo 2. No¸c˜oes Preliminares

5

cores, n´umeros, etc. S˜ao exemplos de vetores coluna:











2

5

−1

0





















,

(cid:7)

♠

♣

(cid:70)





















,

exemplo

de

um

vetor











.

Neste trabalho vamos apenas olhar para vetores cujas entradas s˜ao n´umeros reais, ou

seja, as entradas x1, x2, · · · , xn ∈ R.

Defini¸c˜ao 2.1. Dois vetores u e v, de mesmo tamanho n, entradas x1, x2, · · · , xn e

y1, y2, · · · , yn, respectivamente, s˜ao ditos iguais, se e somente se, todas as suas entradas
de mesma posi¸c˜ao forem iguais, ou seja, xi = yi para todo i ∈ N.

Os vetores colunas de entradas reais s˜ao munidos das opera¸c˜oes de soma e multiplica¸c˜ao

por um n´umero real, sendo este chamado de escalar. Para tal, consideremos os vetores
u, v e w, todos de mesmo comprimento n e entradas reais {x1, x2, · · · , xn}, {y1, y2, · · · , yn}
e {z1, z2, · · · , zn}, respectivamente, onde:

I. O vetor coluna w ´e dito vetor soma de u e v, representado por w = u + v, se, e

somente se, suas entradas forem z1 = x1 + y1, z2 = x2 + y2, · · · , zn = xn + yn,

ilustrado a seguir:

w = u + v ⇔





















z1

z2
...
zn











=

x1 + y1

x2 + y2
...
xn + yn











.

A opera¸c˜ao soma de vetores descrita a cima, possui as seguintes propriedades: co-

mutativa, associativa, elemento neutro e elemento sim´etrico. Para tal, consideremos

o vetores u, v, e w, todos de mesmo tamanho.

(a) Comutativa: u + v = v + u

(b) Associativa: u + (v + w) = (u + v) + w

(c) Elemento neutro: u + v = u ⇔ xi = 0 ∈ v, para todo i. Da´ı v = o

(d) Elemento sim´etrico: u + v = o ⇒ v = −u

Cap´ıtulo 2. No¸c˜oes Preliminares

6

II. O vetor coluna w ´e o produto de um vetor u por um escalar a ∈ R, representado por

w = a·u se e somente se, suas entradas forem z1 = a·x1, z2 = a·x2, · · · , zn = a·xn,

conforme ilustramos abaixo:

w = a · u ⇔





















z1

z2
...
zn











a · x1

a · x2
...
a · xn











.

=

A opera¸c˜ao de produto por um escalar real descrita a cima, com a, b ∈ R e os

vetores u e v de mesmo tamanho, possui as seguintes propriedades:

(a) a(u + v) = au + av

(b) (a + b)v = av + bv

(c) (ab)v = a(bv)

(d) 1v = v

Sob as nota¸c˜oes acima, podemos facilmente veriﬁcar que:





















3

−2

1

5











1

2

0

−2

+





















2

1

−2

4

=

3 ·































;











4

0

1

3

=











.

6

3

−6

12

2.2 Matrizes

Defini¸c˜ao 2.2. Dados dois n´umeros naturais m e n, n˜ao nulos, chama-se matriz real de

ordem m por n (indica-se m × n) toda tabela M formada por n´umeros reais distribu´ıdos

em m linhas, que s˜ao as filas horizontais, e n colunas, que s˜ao as filas verticais.

Cap´ıtulo 2. No¸c˜oes Preliminares

7

Tamb´em podemos ver uma matriz como sendo o emparelhamento de n vetores colunas

de comprimento m, um ao lado do outro. Para tal, denotaremos uma matriz A = [aij]m×n
de entradas reais aij, com i ∈ {1, 2, · · · , m} e j ∈ {1, 2, · · · , n} por:

A =











a11

a12

· · · a1n

a21
a22
...
...
am1 am2

· · · a2n
...
. . .
· · · amn











.

Isso signiﬁca que na interse¸c˜ao da linha i com a coluna j encontramos a entrada

aij ∈ R. Por exemplo, na primeira linha, segunda coluna encontra-se o elemento a12.

A =












a11

a12

· · · a1n

a21
a22
...
...
am1 am2

· · · a2n
...
. . .
· · · amn












.

Observe que um vetor de comprimento m pode ser visto como uma matriz de ordem

m × 1, assim como um n´umero a ∈ R tamb´em pode ser representado por uma matriz de

ordem 1 × 1:











a11

a21
...
am1





















x1

x2
...
xm











=

e [a11] = a.

Defini¸c˜ao 2.3. Dizemos que as matrizes A e B s˜ao iguais, se e somente se, tiverem

a mesma ordem e seus elementos de mesma posi¸c˜ao forem iguais, ou seja, Am×n =

Bm×n ⇔ aij = bij, para todo i e j,

A = B ⇔











a11

a12

· · · a1n

a22
a21
...
...
am1 am2

· · · a2n
...
. . .
· · · amn





















=

b11

b12

· · ·

b1n

b22
b21
...
...
bm1 bm2

· · ·
. . .

b2n
...
· · · bmn











.

Denominamos A de matriz quadrada de ordem n, sendo denotada por An, toda matriz

tal que o n´umero de linhas for igual ao n´umero de coluna, ou seja, m = n. Em uma

matriz quadrada An, ´e chamada diagonal da matriz A a ﬁla que cont´em os elementos

Cap´ıtulo 2. No¸c˜oes Preliminares

8

nos quais sua posi¸cc˜ao referente a linha e a coluna s˜ao as mesmas, ou seja, os elementos

a11, a22, · · · , ann.













a11

a12

· · ·

a1n

a21
a22
...
...
an1 an2

· · ·
. . .

· · ·

a2n
...

ann













.

A =

Uma matriz quadrada cujos os elementos fora da diagonal principal s˜ao todos iguais

a zero ´e chamada de matriz diagonal, caso os elementos da diagonal desta matriz sejam

iguais, denomina-se esta de matriz escalar. Se o escalar na diagonal for igual a 1, a matriz
´e chamada de matriz identidade e denotaremos por In, com n ∈ N:














Matriz Diagonal

a11

0

0

0
...
0

a22

0
...
0

0

0

a33
...
0

· · ·

· · ·

0

0

· · ·
. . .

0
...
· · · ann














;














Matriz Escalar

x 0 0 · · ·

0 x 0 · · ·

0

0

...

0 0 x · · ·
0
...
...
...
. . .
0 0 0 · · · x














;

Matriz Identidade



1 0 0 · · ·

0












0 1 0 · · ·

...

0 0 1 · · ·
...
...
. . .
0 0 0 · · ·

0

0
...
1

.












As opera¸c˜oes de adi¸c˜ao de matrizes e multiplica¸c˜ao de matriz por escalar, s˜ao feitas

de forma semelhante `as opera¸c˜oes deﬁnidas com vetores. Adicionando as matrizes A =

[aij]m×n e B = [bij]m×n retorna uma matriz C = [cij]m×n, de mesma ordem m × n e

cuja entrada na linha i e coluna j igual `a soma das entradas correspondentes de A e B,

ou seja cij = aij + bij:

A+B = C ⇔











a11 + b11

a12 + b12

a21 + b21
...

a22 + b22
...

· · ·

· · ·
. . .

a1n + b1n

a2n + b2n
...

am1 + bm1 am2 + bm2

· · · amn + bmn





















=

c11

c12

c22
c21
...
...
cm1 cm2

· · ·

· · ·
. . .

· · ·











.

c1n

c2n
...
cmn

Assim como a opera¸c˜ao soma de vetores, a soma de matrizes possui as seguintes

propriedades: comutativa, associativa, elemento neutro e elemento sim´etrico. Para tal,

consideremos as matrizes A, B, e C, todas de mesmo tamanho m × n.

Cap´ıtulo 2. No¸c˜oes Preliminares

9

I. Comutativa: A + B = B + A

II. Associativa: A + (B + C) = (A + B) + C

III. Elemento neutro: A + B = A ⇔ bij = 0 ∈ v, para todo i. Da´ı B = O

IV. Elemento sim´etrico: A + B = O ⇒ B = −A

Multiplicando matriz A = [aij]m×n com um n´umero real k ´e o mesmo que multiplicar

cada elemento de A por o escalar k, obtendo uma matriz B = [bij]m×n em que cada uma

de suas entradas ´e dada por bij = k · aij, para todo i e j:

k · A = B ⇔











k · a11

k · a12

k · a21
...

k · a22
...

· · ·

· · ·
. . .

k · a1n

k · a2n
...

k · am1 k · am2

· · · k · amn





















=

b11

b12

· · ·

b1n

b21
b22
...
...
bm1 bm2

· · ·
. . .

b2n
...
· · · bmn











.

A opera¸c˜ao de produto por um escalar real descrita a cima, com k, l ∈ R e as matrizes

A e B de mesmo tamanho m × n, possui as seguintes propriedades:

I. k(A + B) = kA + kB

II. (k + l)A = kA + lA

III. (kl)A = k(lA)

IV. 1A = A

Defini¸c˜ao 2.4. Dada duas matrizes A = [aij]m×n e B = [bjk]n×p, ambas de entradas

reais, chama-se a matriz produto A · B, a matriz Cm×p de entradas cik tal que, para todo
i ∈ {1, 2, · · · , m} e todo k ∈ {1, 2, · · · , p}, teremos:

cik = ai1 · b1k + ai2 · b2k + · · · + ai1 · bnk =

aijbjk

j=1

n(cid:88)

, i.e.,

A · B = C ⇔











a11

a12

· · · a1n

a21
a22
...
...
am1 am2

· · · a2n
...
. . .
· · · amn





















·

b11 b12

· · · b1p

b21 b22
...
...
bn1 bn2

· · · b2p
...
. . .
· · · bnp











=

Cap´ıtulo 2. No¸c˜oes Preliminares











a11 · b11 + a12 · b21 + · · · + a1n · bn1

a21 · b11 + a22 · b21 + · · · + a2n · bn1
...
am1 · b11 + am2 · b21 + · · · + amn · bn1

10

· · ·

· · ·
. . .

a11 · b1p + a12 · b2p + · · · + a1n · bnp

a21 · b1p + a22 · b2p + · · · + a2n · bnp
...

· · · am1 · b1p + am2 · b2p + · · · + amn · bnp











=











c11

c12

c22
c21
...
...
cm1 cm2

· · ·

· · ·
. . .

· · ·











.

c1p

c2p
...
cmp

´E f´acil ver que para existir o produto de duas matrizes ´e condi¸c˜ao necess´aria e suﬁciente

que o n´umero de colunas da matriz que est´a `a esquerda da opera¸c˜ao seja igual ao de linhas

da matriz que encontra-se a direita do operador, onde a matriz produto herda a quantidade

de linhas da matriz `a esquerda e o n´umero de colunas da matriz `a direita.

Podemos observar que, desde que as opera¸c˜oes sejam poss´ıveis, o produto de matrizes

possui as propriedades operat´orias:

I. Distributiva `a esquerda: A(B + C) = AB + AC

II. Distributiva `a direita: (A + B)C = AC + BC

III. Associativa: A(BC) = (AB)C

IV. Elemento Identidade: AI = IA = A

Tamb´em vale salientar que o produto de duas matrizes ´e uma opera¸c˜ao que n˜ao goza

da propriedade comutativa, ou seja, nem sempre ´e verdadeiro a igualdade AB = BA.

Defini¸c˜ao 2.5. Dada a matriz quadrada An e k ∈ N com k (cid:62) 2, definimos pot^encia

natural de matrizes:

A0 = In,

A1 = A,
...

Ak = AA · · · A
(cid:125)
(cid:124)

(cid:123)(cid:122)
k vezes

.

Cap´ıtulo 2. No¸c˜oes Preliminares

11

O produto de uma matriz de ordem m × n por um vetor com n entadas reais ´e feito

tomando o vetor como sendo uma matriz coluna, ou seja, de ordem n × 1, resultando um

novo vetor coluna de tamanho m ou uma matriz de coluna m × 1, que pode ser observado

com clareza no exemplo a seguir:





1 −2 3

2

1

0



 ·















−2

1

−1





=

1 · (−2) + (−2) · 1 + 3 · (−1)

2 · (−2) + 1 · 1 + 0 · (−1)





 =





 .

−7

−3

Defini¸c˜ao 2.6. Dada uma matriz A = [aij]m×n, chama-se transposta de A a matriz

At = [a (cid:48)

ji]n×m tal que a (cid:48)

ji = aij, para todo i e j.

At =











11 a (cid:48)
a (cid:48)
12
21 a (cid:48)
a (cid:48)
22
...
...
a (cid:48)
n1 a (cid:48)
n2

· · · a (cid:48)

1m

2m

· · · a (cid:48)
...
. . .
· · · a (cid:48)

nm





















=

a11 a21

· · · am1

a12 a22
· · · am2
...
...
...
. . .
a1n a2n · · · anm











.

Na pr´atica, como o pr´oprio nome sugere, a matriz At ´e a transposi¸c˜ao das colunas

para linhas da matriz A e vice e versa.

Defini¸c˜ao 2.7. A matriz A = [aij]n×n ´e uma matriz sim´etrica, se, e somente se, aij =

aji.

Ou seja, os elementos simetricamente dispostos em rela¸c˜ao `a digonal s˜ao iguais. Com

isso, ´e f´acil ver que toda matriz quadrada An, tal que A = At, ´e uma matriz sim´etrica.

a11

a21

...


















a12

a22

...

· · ·

· · ·

. . .

a1n

a2n

...


















an1

an2

· · ·

ann

A transposi¸c˜ao da matriz At ´e a pr´opria matriz A, em outras palavras, podemos

escrever (At)t = A. Tamb´em ´e poss´ıvel veriﬁcar que, para quaisquer matrizes A, B, as

propriedades de distributividade com rela¸c˜ao a soma e com rela¸c˜ao ao produto s˜ao v´alidas

para transposi¸c˜ao de matrizes:

(cid:4)
(cid:4)
(cid:5)
(cid:5)
(cid:6)
(cid:6)
(cid:54)
(cid:54)
(cid:5)
(cid:5)
(cid:6)
(cid:6)
(cid:53)
(cid:53)
(cid:55)
(cid:55)
(cid:5)
(cid:5)
(cid:53)
(cid:53)
(cid:54)
(cid:54)
(cid:54)
(cid:54)
Cap´ıtulo 2. No¸c˜oes Preliminares

12

I. (A + B)t = At + Bt

II. (A · B)t = Bt · At

2.3 Autovalores e Autovetores

Vamos agora introduzir duas no¸c˜oes importantes na teoria sobre matrizes: autovetor

e autovalor.

O adjetivo germ^anico eigen significa “pr´oprio” ou “caracter´ıstico de”.

Valores pr´oprios e vetores pr´oprios, ou autovalores e autovetores, s˜ao

caracter´ısticos de uma matriz no sentido de conterem informa¸c˜oes impor-

tantes sobre a natureza da matriz. A letra λ (lambda), letra grega equi-

valente ao L em portugu^es, ´e utilizada para designar autovalores porque

anteriormente esses n´umeros tamb´em eram chamados de valores laten-

tes. A pron´uncia fon´etica do prefixo alem˜ao eingen ´e “´aiguen”.(POOLE,

2004, p. 232)

Defini¸c˜ao 2.8. Seja A uma matriz quadrada de ordem n. Um escalar λ ´e chamado de

autovalor da matriz A se existir um vetor n˜ao nulo v tal que A · v = λ · v. Tal vetor ´e

chamado de um autovetor da matriz A correspondente ao autovalor λ.

A express˜ao da deﬁni¸c˜ao acima pode ser reescrita da seguinte forma:

A · v = λ · v ⇔ A · v = λ · I · v ⇔ A · v − λ · I · v = 0 ⇔ (A − λI) · v = 0 ⇔





















a11 a12

· · · a1n

a21 a22
...
...
an1 an2

· · · a2n
...
. . .
· · · ann











− λ











1 0 · · ·

0 1 · · ·
...
...
. . .
0 0 · · ·











a11 − λ

a12

· · ·

a21
...
an1

a22 − λ · · ·
. . .

...
an2

a1n

a2n
...











·

· · · ann − λ

0

0
...
1































·





















x1

x2
...
xn





















0

0
...
0

=

⇔











x1

x2
...
xn





















0

0
...
0

=

⇔

Cap´ıtulo 2. No¸c˜oes Preliminares

13






(a11 − λ) · x1 + a12 · x2 + · · · + a1n · xn = 0

a21 · x1 + (a22 − λ) · x2 + · · · + a2n · xn = 0
...
an1 · x1 + an2 · x2 + · · · + ann · (xn − λ) = 0

Para um vetor v n˜ao nulo, o sistema homogˆeneo admitir´a solu¸c˜ao al´em da trivial se

det(A − λI) = 0, sendo assim poss´ıvel determinar os valores de λ. O conjunto de todos

os autovetores correspondentes a um autovalor λ de uma matriz quadrada A, acrescido

do vetor nulo, ´e chamado de auto-subespa¸co de λ, e denotaremos por Eλ.

Teorema 1 (Teorema Espectral para matrizes sim´etricas). Seja A uma matriz real e

sim´etrica. Ent˜ao todos os autovalores de A s˜ao reais.

Demonstra¸c˜ao. Para demonstra¸c˜ao deste teorema 1, vamos considerar o vetor coluna

u de entradas complexas (C) zj = aj + bji, para todo j ∈ 1, 2, · · · , n, i =
nosso elemento imagin´ario e a, b ∈ R. Chamamos de conjugado de z, denotado por ¯z,

−1 sendo o

√

o complexo ¯z = a − bi. Com isso, denotaremos a transposta Hermitiana de u o vetor
uH = ¯ut = [ ¯z1, ¯z2, · · · , ¯zn]. No espa¸co Cn o produto interno canˆonico ´e deﬁnido como
sendo (cid:104)(z1, z2, · · · , zn)(cid:105) · (cid:104)(w1, w2, · · · , wn)(cid:105) = z1 ¯w1 + z2 ¯w2 + · · · + zn ¯wn, com zj ∈ C
e wj ∈ C para todo j. Seja a norma de um vetor u, denotado por (cid:107) u (cid:107), o valor
√
(cid:107) u (cid:107)= (cid:112)(cid:104)u, u(cid:105). Da´ı, teremos que (cid:107) u (cid:107)2= (

z1 ¯z1 + z2 ¯z2 + · · · + zn ¯zn)2 = uHu.

Seja A uma matriz sim´etrica, com u e λ, respectivamente, seus autovetor e autovalor,

com u de entradas complexas e λ ∈ C. Temos que Au = λu, multiplicando a equa¸c˜ao

`a esquerda por uH, obteremos uHAu = uHλu = λuHu = λ (cid:107) u (cid:107)2. Por outro lado,
uHAu = (uA)Hu = (λu)Hu = ¯λuHu = ¯λ (cid:107) u (cid:107)2. Como u (cid:54)= 0, chegamos que λ = ¯λ,
Logo λ ∈ R. (cid:4)

Logo, se assumirmos que An ´e uma matriz sim´etrica, ent˜ao sabemos que ela possui n

autovalores, sendo estes reais, e todos os autovetores tamb´em s˜ao de entradas reais. Na

verdade, uma matriz quadrada de ordem n pode ter no m´aximo n autovalores. Portanto,

se A ´e uma matriz quadrada de ordem n, o sistema homogˆeneo tem solu¸c˜ao n˜ao-trivial e

pode ter no m´aximo n autovalores.

Uma consequˆencia importante para o nosso estudo ´e que qualquer matriz A tem os

mesmos autovalores que sua transposta At, visto que det(A) = det(At). Por´em, em geral,

uma matriz A e sua transposta At n˜ao possuem os mesmos autovetores que correspondem

a autovalores comuns.

Cap´ıtulo 2. No¸c˜oes Preliminares

14

Defini¸c˜ao 2.9. Dada uma matriz n˜ao negativa A, ela ´e chamada de coluna estoc´astica

se a soma das entradas em cada coluna forem iguais a 1.

Portanto, para uma matriz de coluna estoc´astica An qualquer, temos que

(cid:80)

n
i=1 aij =

1, para todo j.

Com isso, podemos aﬁrmar que toda matriz coluna estoc´astica tem λ = 1 como auto-

valor. Para isto, primeiro mostramos que a matriz transposta At possui como autovalor

λ = 1, com seu correspondente autovetor. Ent˜ao, seja An uma matriz coluna estoc´astica,
tome o vetor coluna v com todos seus elementos iguais a 1, logo xj = 1, para todo j (cid:54) n.

Note que:











11 a (cid:48)
a (cid:48)
12
a (cid:48)
21 a (cid:48)
22
...
...
a (cid:48)
n1 a (cid:48)
n2

· · · a (cid:48)

1n

2n

· · · a (cid:48)
...
. . .
· · · a (cid:48)

nn





















·











1

1
...
1











=

11 + a (cid:48)
a (cid:48)
21 + a (cid:48)
a (cid:48)

12 + · · · + a (cid:48)
1n
22 + · · · + a (cid:48)
2n

...

a (cid:48)
n1 + a (cid:48)

n2 + · · · + a (cid:48)

nn











Sendo At a matriz transposta de A, ent˜ao temos que a (cid:48)

ji = aij, e como A ´e coluna
estoc´astica, a soma dos elementos de mesma coluna ´e sempre igual a 1, da´ı, na matriz At

(cid:80)

n
i=1 a (cid:48)

ji = 1. Assim,

a soma dos elementos de mesma linha tamb´em ser´a sempre 1, logo











a11 + a21 + · · · + an1

a12 + a22 + · · · + an2
...
a1n + a2n + · · · + ann











=





















1

1
...
1

= 1 ·











.











1

1
...
1

Portanto, temos que At · v = 1 · v, da´ı λ = 1 ´e auto valor da matriz At associado

ao vetor coluna v = [1, 1, · · · , 1]t. Como toda matriz tem o mesmo determinante de sua
transposta, temos que 1 tamb´em ´e um autovalor para a matriz A. ´E importante salientar

que o vetor v de entradas todas iguais a 1 n˜ao ´e o autovetor correspondente ao autovalor

λ = 1. Deseja-se encontrar um autovetor que corresponde a este autovalor para A, seja

u esse autovetor. A ﬁm de encontrar u = [x1, x2, · · · , xn]t explicitamente escrevemos a

equa¸c˜ao (A − I) · u = 0 onde











a11 − 1

a12

· · ·

a21
...
an1

a22 − 1 · · ·
. . .

...
an2

a1n

a2n
...





















·











x1

x2
...
xn





















0

0
...
0

=

⇔

· · · ann − 1

15

⇔

Cap´ıtulo 2. No¸c˜oes Preliminares





(a11 − 1) · x1 + a12 · x2 + · · · + a1n · xn = 0

a21 · x1 + (a22 − 1) · x2 + · · · + a2n · xn = 0
...
an1 · x1 + an2 · x2 + · · · + ann · (xn − 1) = 0





x1 = a11 · x1 + a12 · x2 + · · · + a1n · xn

x2 = a21 · x1 + a22 · x2 + · · · + a2n · xn
...
xn = an1 · x1 + an2 · x2 + · · · + ann · xn

.

Portanto, o autovetor u que corresponde ao autovalor λ = 1, ter´a suas entradas

(cid:80)

xi =

n

j=1 aijxj, para todos i (cid:54) n e j (cid:54) n.

Cap´ıtulo 3

Cadeias de Markov

Neste cap´ıtulo, abordaremos de maneira formal os conceitos matem´aticos de Matriz

Coluna Estoc´astica e Cadeias de Markov, que ser˜ao necess´arios para modelarmos o pro-

blema de encontrar uma pontua¸c˜ao de importˆancia para cada uma das p´aginas da internet.

Para os leitores que sentirem necessidade de uma explana¸c˜ao mais detalhada dos conceitos

citados acima, al´em daquelas apresentadas no decorrer do texto, indicamos a leitura de

[2] e [3].

A palavra estoc´astico ´e derivada do adjetivo grego stokhastikos, que sig-
nifica “capaz de aproximar” (ou adivinhar). ´E aplicada em qualquer

coisa governada pelas leis da probabilidade, no sentido de que probabili-

dade faz previs˜oes sobre a chance das coisas acontecerem. Na teoria das

probabilidades, os “processos estoc´asticos” s˜ao uma generaliza¸c˜ao das

cadeias de Markov. (POOLE, 2004, p. 204)

Chamamos vetor de probabilidade todo vetor com entradas reais n˜ao negativas cujo

somat´orio de todas as suas entradas seja igual a 1. Portanto, sendo u um vetor de
probabilidade com n entradas reais n˜ao negativas, ou seja, xi (cid:62) 0, para todo i ∈ N,

ent˜ao:

n(cid:88)

x1 + x2 + · · · + xn =

xi = 1.

i=1

Uma forma de transformar um vetor v de comprimento n e entradas reais positivos

y1, y2, · · · , yn em um vetor de probabilidade u, ´e dividir cada uma de suas entradas pelo

somat´orio de suas entradas:

16

Cap´ıtulo 3. Cadeias de Markov

17

y1(cid:80)

x1 =

y2(cid:80)

, x2 =

, · · · , xn =

yn(cid:80)

.

n
i=1 yi
Assim como em vetores, dizemos que uma matriz ´e “n˜ao negativa” se todas suas entra-

n
i=1 yi

n
i=1 yi

das forem maiores ou iguais a zero. E ´e dita positiva se todas as entradas forem maiores

que zero. Como podemos observar, pela deﬁni¸c˜ao 2.9, uma matriz coluna estoc´astica de

tamanho m × n pode ser vista como o emparelhamento de n vetores probabilidade com

m entradas em cada vetor.

Um resultado interessante ´e que o produto de duas matrizes coluna estoc´astica, An

e Bn, tamb´em ´e uma matriz coluna estoc´astica. Como aij, bij ∈ [0, 1], as entradas da

matriz A · B ser˜ao n˜ao negativas e











a11 a12

· · · a1n

a21 a22
...
...
an1 an2

· · · a2n
...
. . .
· · · ann
(cid:80)











·











b11 b12

· · · b1n

b21 b22
...
...
bn1 bn2

· · · b2n
...
. . .
· · · bnn











(cid:80)

(cid:80)

(cid:80)

n
j=1 a1jbj1
n
j=1 a2jbj1
...
n
j=1 anjbj1

(cid:80)

(cid:80)

n
j=1 a1jbj2
n
j=1 a2jbj2
...
n
j=1 anjbj2

(cid:80)

(cid:80)

(cid:80)

n
j=1 a1jbjn
n
j=1 a2jbjn
...
n
j=1 anjbjn

· · ·

· · ·
. . .

· · ·











=











.

Observe que a soma de cada uma das colunas ´e igual a 1:

a11 · b11 + a12 · b21 + · · · + a1n · bn1+

a21 · b11 + a22 · b21 + · · · + a2n · bn1+
...
an1 · b11 + an2 · b21 + · · · + ann · bn1 =

b11 (a11 + a21 + · · · + an1)
(cid:125)

(cid:124)

(cid:123)(cid:122)
1

(cid:124)

+b21 (a12 + a22 + · · · + an2)
(cid:125)

(cid:123)(cid:122)
1
b11 + b21 + · · · + bn1 = 1.

+ · · ·+bn1 (a1n + a2n + · · · + ann)
(cid:125)

(cid:124)

=

(cid:123)(cid:122)
1

Como consequˆencia, teremos que Ak, como k ∈ N, tamb´em ´e uma matriz coluna

estoc´astica. Outrossim, como podemos operar vetores coluna como matrizes de ordem

n × 1 (no caso do vetor linha 1 × n), vale ressaltar que o produto de uma matriz coluna

estoc´astica por um vetor de probabilidade obtemos tamb´em um vetor de probabilidade.

Cap´ıtulo 3. Cadeias de Markov

18

Outra observa¸c˜ao importante ´e que se A ´e uma matriz coluna estoc´astica, ent˜ao At n˜ao

´e. No entanto, a soma dos elementos de cada linha de At ´e igual a 1, logo

(cid:80)

n
j=1 a (cid:48)

ij = 1.

Andrei A. Markov (1856-1922) foi um matem´atico russo que estudou

e posteriormente lecionou na Universidade de S˜ao Petersburgo. Era

interessado na teoria de n´umeros, em an´alise, e na teoria de fra¸c˜oes

cont´ınuas, uma ´area rec´em-surgida que Markov aplicava na teoria de

probabilidade. Markov tamb´em tinha interesse em poesia, e um dos usos

que ele deu `as cadeias de Markov foi a an´alise de padr˜oes em poemas e

outros textos liter´arios. (POOLE, 2004, p. 202)

Um processo aleat´orio ou estoc´astico Xn, n = 0, 1, 2, 3, · · · ´e uma fam´ılia de vari´aveis

aleat´orias parametrizadas pelo inteiro n. Assumimos que cada uma destas vari´aveis

aleat´orias Xn toma seus valores num conjunto ﬁnito T . Em outras palavras, ´e um espa¸co

de amostras em que cada elemento ´e associado a uma fun¸c˜ao do tempo. Podemos ver

como uma probabilidade condicional P(A|B) que ´e a probabilidade de que o evento A

ocorra, dado que o evento B tenha ocorrido.

Defini¸c˜ao 3.1. Seja {Xn, n = 0, 1, 2, 3, · · · } um processo aleat´orio, tomando seus valores
num conjunto T = {A, B, C, · · · }. Dizemos que {Xn} ´e uma cadeia de Markov se a pro-

babilidade P(Xn = i), i ∈ T , depender somente do valor do processo no passo anterior,
Xn−1, e n˜ao em qualquer dos passos anteriores Xn−2, Xn−3, · · · . Definimos n ∈ N como

o n´umero de elementos em T .

Dados os vetores vk e vk+1 de mesmo tamanho n ∈ N e uma matriz P = [pij]n×n,
tal que vk+1 = Pvk, para k ∈ N, ent˜ao os vetores vk e vk+1 s˜ao chamados de vetores de

estado e a matriz P de matriz de transi¸c˜ao.

Cadeias de Markov possui um comportamento caracterizado por seu estado inicial
e por uma matriz de transi¸c˜ao dada por P(Xn = i|Xn−1 = j) = pij. Ou seja, n˜ao tem

mem´oria dos estados passados e o estado futuro ´e determinado completamente pelo estado

atual e por uma matriz de transi¸c˜ao.

Defini¸c˜ao 3.2. Seja P uma matriz quadrada, ´e dita matriz de transi¸c˜ao de uma Cadeia de
Markov, se e somente se, estiver definida por P(Xn = i|Xn−1 = j) = pij, com pij ∈ [0, 1]

(cid:80)

e

i∈T pij = 1 para todo i, j ∈ T .

Cap´ıtulo 3. Cadeias de Markov

19

Observando o comportamento das mudan¸cas sucessivas de estado, temos:

Ent˜ao, por recorrˆencia temos:

v1 = Pv0

v2 = Pv1
...
vk = Pvk−1.

v1 = Pv0

v2 = P(Pv0) = P2v0

v3 = P(P2v0) = P3v0
...
vk = Pk−1v = Pkv0.

Logo, (pk)ij ´e a probabilidade de se passar do estado j ao estado i em k transi¸c˜oes.

Assim a sequˆencia de vetores de probabilidade v1, v2, · · · , vn juntamente com a matriz de

transi¸c˜ao P forma uma Cadeia de Markov.

Cap´ıtulo 4

Algoritmo PageRank

Modernos motores de busca empregam m´etodos de classiﬁca¸c˜ao de resultados para

que seja fornecido primeiramente os “melhores”, ao inv´es de simplesmente um ranking

das p´aginas que apresentam o texto pesquisado. Um dos algoritmos mais conhecidos e

inﬂuentes para determinar a relevˆancia das p´aginas na internet ´e o algoritmo PageRank,

usado pelo motor de busca Google. Foi criado e desenvolvido por Larry Page e Sergey

Brin, enquanto eles eram estudantes de p´os-gradua¸c˜ao em Stanford, e tornou-se uma

marca Google em 1998. A ideia inicial para o desenvolvimento do PageRank foi a de que,

a importˆancia de qualquer p´agina da internet pode ser julgada olhando para as p´aginas

que apontam para ela. Quer falemos de popularidade ou autoridade, podemos, de maneira

repetida, atribuir uma classiﬁca¸c˜ao a cada p´agina, com base nas ﬁleiras das outras p´aginas
que a apontam. ´E bem semelhante ao conceito popular de moda, se muitas pessoas usam

um mesmo estilo de roupa ou mesmo uma determinada celebridade o usa, aquilo vira

moda a ser seguida, logo julga-se importante uma loja ter aquela roupa ou acess´orio em

sua vitrine, j´a que ser´a procurado por outros compradores.

Outra justiﬁcativa intuitiva ´e que uma p´agina de internet pode ter um alto PageRank

se existem muitas p´aginas que apontam para ela, ou se algumas p´aginas que a apontam

tˆem um alto PageRank. Intuitivamente, as p´aginas que s˜ao bem citados a partir de muitos

lugares ao redor da internet valem a pena olhar. Al´em disso, as p´aginas que tˆem, talvez,

apenas uma cita¸c˜ao de algo como a homepage do site da CAPES! geralmente vale a pena

olhar. Se uma p´agina n˜ao for de alta qualidade, ou era um link quebrado, ´e bastante

prov´avel que a p´agina inicial da CAPES n˜ao iria apontar para ele. O algoritmo PageRank

lida com esses dois casos e tudo mais por recursividade atrav´es da estrutura de links da

20

Cap´ıtulo 4. Algoritmo PageRank

21

pr´opria internet.

A utilidade de um motor de busca depende da relevˆancia do conjunto de resultados que

´e retornado. N˜ao pode ser, obviamente, milh˜oes de p´aginas de internet que incluem uma

determinada palavra ou frase, no entanto algumas dessas p´aginas ser˜ao mais relevantes,

ou popular, ou com maior autoridade do que outras. Um usu´ario n˜ao tem a habilidade,

ou paciˆencia, para fazer a varredura atrav´es de todas as p´aginas que contˆem as palavras

consultadas. Uma pessoa ao fazer uma pesquisa espera que as p´aginas relevantes sejam

exibidas dentre as primeiras devolvido pelo motor de busca.

4.1 A Matem´atica do Google

O motor de busca Google tem caracter´ısticas importantes que o ajudam a produzir

resultados de alta precis˜ao. Ele faz uso da estrutura de links j´a existente na internet para

calcular um ranking de qualidade para cada p´agina da web. Esta classiﬁca¸c˜ao ´e chamado

PageRank, que ´e o objeto de estudo deste trabalho e o descrevemos na sess˜ao seguinte.

4.1.1 Descri¸c˜ao do C´alculo PageRank

O modelo de cita¸c˜ao da literatura acadˆemica tem sido aplicado `a web, em grande

parte, pela contagem de cita¸c˜oes, ou backlinks, para uma determinada p´agina. Isto d´a

alguma aproxima¸c˜ao de importˆancia ou qualidade de uma p´agina. O algoritmo do Page-

Rank estende esta ideia, por n˜ao contar os links em todas as p´aginas igualmente, e por

normalizar pelo n´umero de links em uma p´agina.

Assumimos que uma p´agina A tenha T1, T2, · · · , Tn p´aginas com links que apontam
para ela, ou seja, s˜ao cita¸c˜oes, backlinks. Tomaremos o parˆametro d ∈ R, como sendo um

fator de amortecimento que pode ser ajustado no intervalo entre 0 e 1. H´a mais detalhes

sobre d na pr´oxima se¸c˜ao. Deﬁniremos C(A) como o n´umero de links que a p´agina A

possui apontando para outras p´aginas. Seja PR(A), o PageRank de uma p´agina A, que ´e

dado por:

PR(A) = (1 − d) + d

(cid:18)PR(T1)
C(T1)

+

PR(T2)
C(T2)

+ · · · +

(cid:19)

.

PR(Tn)
C(Tn)

Note-se que o PageRank formam uma distribui¸c˜ao de probabilidade sobre as p´aginas

da web, de modo que a soma de todos os PageRanks das p´aginas da web tamb´em ser´a

Cap´ıtulo 4. Algoritmo PageRank

22

um deles.

PageRank ou PR(A) pode ser calculada usando um algoritmo iterativo simples, e

corresponde ao principal autovetor da matriz de liga¸c˜ao normalizada da web. Al´em disso,

um PageRank de 26 milh˜oes de p´aginas da web pode ser calculado em algumas horas com

uma esta¸c˜ao de trabalho de tamanho m´edio.

O PageRank pode ser pensado como um modelo de comportamento para os usu´arios da

internet. Assumindo que um usu´ario resolve sair clicando de forma aleat´oria nos links das

p´aginas na web e continua a clicar nos links, mas eventualmente ﬁca entediado e come¸ca

em outra p´agina aleat´oria. A probabilidade de que este usu´ario visite uma determinada

p´agina ´e o que chamamos de PageRank. E o fator de amortecimento d ´e a probabilidade

do usu´ario sair da p´agina atual e acessar outra sem usar link.

Para este objetivo, come¸camos retratando a rede Web como um grafo direcionado,

com n´os representados por p´aginas web e bordas representadas pelas liga¸c˜oes entre eles.

Suponha, por exemplo, que temos uma pequena internet que consiste em apenas 4 sites,

www.pagina1.com, www.pagina2.com, www.pagina3.com e www.pagina4.com, referenci-

ando um ao outro da maneira sugerida pela ﬁgura 4.1:

Figura 4.1: uma pequena internet

N´os podemos “traduzir”a imagem em um grafo direcionado com 4 n´os, um para cada

p´agina. Quando um site i referencia um site j, n´os adicionamos uma aresta dirigida

entre o n´o i e o n´o j no gr´aﬁco. Para efeitos de computa¸c˜ao seu PageRank, ignoramos

Cap´ıtulo 4. Algoritmo PageRank

23

quaisquer links de navega¸c˜ao, tais como os bot˜oes pr´oximo, avan¸car e outros, j´a que s´o nos

preocupamos com as conex˜oes entre diferentes sites da web. Por exemplo, como exitem

liga¸c˜oes da pagina1 para todas as outras p´aginas, ent˜ao o n´o 1 no gr´aﬁco ter´a aresta de

sa´ıda para todos os outros n´os. Como a pagina3 tem apenas um link, para a pagina1,

portanto o n´o 3 ter´a uma aresta de sa´ıda para o n´o 1. Depois de analisar cada p´agina da

web, termos o gr´aﬁco a seguir:

1

3

(cid:47) 2

4

Figura 4.2: Grafo representando nossa pequena internet

Em nosso modelo, cada p´agina deve transferir uniformemente a sua importˆancia para

as p´aginas relacionadas a ela. O n´o 1 possui 3 links que apontam para as p´aginas 2, 3 e 4,

de modo que vai passar

1
3

da sua importˆancia para cada um dos outros 3 n´os. O n´o 3 tem

apenas uma extremidade de sa´ıda, por isso vai passar toda a sua importˆancia para o n´o

1. Em geral, se um n´o tem k arestas de sa´ıda, ele vai passar 1

k de sua importˆancia para
cada um de n´os que as vincula. Vamos visualizar melhor o processo atribuindo pesos a

cada aresta.

1

1

1
3

1
2

3

1
3

1
2

1
3

1
2

(cid:47) 2

1
2

4

Onde podemos denotar o gr´aﬁco pela matriz de transi¸c˜ao A = [aij]4×4, onde cada

entrada aij da matriz representa a probabilidade de estando em i ir para j.











A =











0 0 1 1
2
1
3 0 0 0
2 0 1
1
3
2
1
2 0 0

1
3

1

(cid:31)
(cid:31)
(cid:15)
(cid:15)
(cid:47)
(cid:15)
(cid:15)
(cid:127)
(cid:127)
(cid:79)
(cid:79)
(cid:111)
(cid:111)
(cid:95)
(cid:95)
(cid:31)
(cid:31)
(cid:15)
(cid:15)
(cid:47)
(cid:15)
(cid:15)
(cid:115)
(cid:115)
(cid:79)
(cid:79)
(cid:111)
(cid:111)
(cid:95)
(cid:95)
Cap´ıtulo 4. Algoritmo PageRank

24

Suponha-se que inicialmente a importˆancia ´e distribu´ıda uniformemente entre os 4 n´os,

obtendo 1

iguais a 1

4 para cada. Denote por v o vetor do ranking inicial, tendo todas as entradas
4. Cada link de entrada aumenta a importˆancia de uma p´agina web, ent˜ao
no passo 1, n´os atualizamos a classiﬁca¸c˜ao de cada p´agina adicionando ao valor atual

a importˆancia das liga¸c˜oes recebidas.

Isto ´e o mesmo que multiplicarmos a matriz A

com v. Ap´os o passo 1, o novo vetor de importˆancia ser´a v1 = Av. Podemos repetir

o processo, assim, no passo 2, o vetor de importˆancia ´e atualizado v2 = A(Av) = A2v.

Assim sucessivamente at´e um passo k :

v =





















0, 25

0, 25

0, 25

0, 25

, Av =





















0, 375
0, 08¯3
0, ¯3
0, 208¯3

, A2v =





















0, 4375

0, 125
0, 2708¯3
0, 1¯6

, A3v =











0, 3541¯6
0, 1458¯3
0, 291¯6
0, 208¯3











,











A4v =

0, 3958¯3
0, 1180¯5
0, 29513¯8
0, 19097¯2












, A5v =





















0, 390625
0, 1319¯4
0, 286458¯3
0, 19097¯2











, A6v =











,

0, 3819¯4
0, 130208¯3
0, 291¯6
0, 196180¯5












A7v =

0, 3897569¯4
0, 1273 ¯148
0, 29050 ¯925
0, 1924189 ¯814

, A8v =



















0, 38671875
0, 1299189 ¯814
0, 28978587 ¯962
0, 1935763¯8











, A9v =









0, 3865 ¯740

0, 12890625
0, 29065393 ¯518
0, 193865 ¯740











,

A10v =











0, 38758680¯5

0, 1288

¯
58024691

0, 290244020061728

0, 193311149691358











, · · ·

Notamos que a sequˆencia de intera¸c˜oes v, Av, · · · , Akv tende ao valor de equil´ıbrio em

que, aproximadamente:

vn−1 = vn =











0, 3870

0, 1290

0, 2903

0, 1935











.

Este vetor de equil´ıbrio vn ´e o vetor PageRank do nosso gr´aﬁco web.

Cap´ıtulo 4. Algoritmo PageRank

25

4.1.2 Do ponto de vista da ´Algebra Linear

Observando as intera¸c˜oes descritas na sess˜ao 4.1.1 onde tendem a um valor de equil´ıbrio,

tal que

vn−1 = vn ⇒ A · vn = vn.

Denotemos por v = [x1, x2, x3, x4]t o vetor de equil´ıbrio que representa a importˆancia das

quatro p´aginas. Analisando a situa¸c˜ao em cada n´o temos:











0 0 1 1
2
1
3 0 0 0
2 0 1
1
3
2
1
2 0 0

1
3

1





















·











x1

x2

x3

x4





















x1

x2

x3

x4

=

⇔






2 · x4

x1 = 1 · x3 + 1
x2 = 1
x3 = 1
x4 = 1
Fazendo x1 = t, com t ∈ R, encontramos o sistema equivalente:

3 · x1
3 · x1 + 1
3 · x1 + 1

2 · x2 + 1
2 · x2

2 · x4






x1 = t
x2 = 1
x3 = 3
x4 = 1

3 · t
4 · t
2 · t

Como as entradas do vetor formam uma distribui¸c˜ao de probabilidade, ou seja, a soma

de todas suas entradas ´e igual a 1, logo x1 + x2 + x3 + x4 = 1 ⇒ t + 1
t = 12

2 · t = 1 ⇒
31. Da´ı temos, com aproxima¸c˜ao por omiss˜ao das demais casas decimais seguintes:
x1 = 0, 3870; x2 = 0, 1290; x3 = 0, 2903; x4 = 0, 1935 os valores do PageRank de cada uma

3 · t + 3

4 · t + 1

das p´aginas.

Por outro lado, podemos observar que o vetor v ´e o autovetor associado ao autovalor

1 da matriz A











0 0 1 1
2
1
3 0 0 0
2 0 1
1
3
2
1
2 0 0

1
3

1





















·











x1

x2

x3

x4

= 1 ·











.











x1

x2

x3

x4

Cap´ıtulo 4. Algoritmo PageRank

26

4.1.3 Ponto de vista probabil´ıstico

Uma vez que a importˆancia de uma p´agina web ´e medida por sua popularidade, ou

seja, quantas liga¸c˜oes a apontam, podemos ver a importˆancia de uma p´agina i como a

probabilidade de que um usu´ario de forma aleat´oria a visite, sendo que o mesmo, ao

navegar pela internet, abra qualquer p´agina e comece a clicar pelos hiperlinks at´e chegar

na p´agina i.

Interpretaremos os pesos atribu´ıdos aos n´os e `as arestas direcionadas do

pagina2, tem probabilidade 1

gr´aﬁco de uma forma probabil´ıstica: Um usu´ario que est´a atualmente a visualizar a
2 de ir para a pagina4. ´E
poss´ıvel modelar o processo como um passeio aleat´orio em gr´aﬁco. Para a nossa “pequena

2 de ir para pagina3, e probabilidade 1

internet”, cada p´agina tem igual probabilidade de 1

4 de ser escolhido como ponto de
partida. Assim, a distribui¸c˜ao de probabilidade inicial ´e dada pelo vetor coluna v =
(cid:2) 1
4
chamaremos de passo, ´e igual a Av, ap´os o segundo clique, ou passo, ´e de A(Av) = A2v,

. A probabilidade de que a p´agina i seja visitada dado o primeiro clique, que

(cid:3)t

1
4

1
4

1
4

e assim por diante. Da´ı a probabilidade de que a p´agina i seja visitada depois de k ∈ N

passos ´e igual a Akv. A sequˆencia Av, A2v, A3v, · · · , Akv, · · · converge, neste caso, a um

vetor estacion´ario v∗, que ´e ´unico. Neste contexto v∗ ser´a o nosso vetor PageRank. Al´em

disso, a i-´esima entrada no vetor v∗ ´e simplesmente a probabilidade de que a cada momento

i uma p´agina receba visita do nosso usu´ario aleat´orio. Os c´alculos s˜ao idˆenticos aos que

ﬁzemos na sess˜ao 4.1.1, apenas o signiﬁcado que atribu´ımos a cada passo ´e ligeiramente

diferente.

4.1.4 Grafos desconectados

´E poss´ıvel calcular por m´etodos diferentes o vetor PageRank v∗, no qual indica que

a pagina1 ´e a mais relevante.

Isso pode parecer surpreendente, pois a pagina1 possui

2 backlinks, enquanto a pagina3 tem 3 backlinks. Se dermos uma olhada no gr´aﬁco da

ﬁgura 4.2, veremos que o n´o 3 tem apenas uma extremidade de sa´ıda para o n´o 1, por

isso transfere toda a sua importˆancia para o n´o 1. De forma equivalente, uma vez que

um internauta que segue clicando aleatoriamente nos links presentes em cada p´agina, ao

visitar pagina3, ele s´o poder´a ir para a pagina1. Observe tamb´em, como a classiﬁca¸c˜ao

de cada p´agina n˜ao ´e somente feita com a soma ponderada das arestas que entram no n´o.

Intuitivamente, no instante 1, um n´o recebe voto de importˆancia de seus vizinhos diretos,

no passo 2, recebe dos vizinhos de seus vizinhos, e assim sucessivamente.

Cap´ıtulo 4. Algoritmo PageRank

27

A web ´e muito heterogˆeneo, pela sua natureza, e, certamente, enorme, por isso n˜ao

esperamos que o seu gr´aﬁco seja todo conectado. Da mesma forma, haver´a p´aginas que

s˜ao simples descritivo e n˜ao contˆem links de sa´ıda. O que deve ser feito nesse caso?

Precisamos de um sentido n˜ao amb´ıguo da classiﬁca¸c˜ao de uma p´agina, para qualquer

gr´aﬁco web dirigido com n n´os.

Aﬁm de superar esse problema, ´e ﬁxada uma constante real positiva d entre 0 e 1,

que foi chamada de fator de amortecimento (um valor t´ıpico para d ´e de 0, 15). Da´ı,

deﬁnimos a matriz de PageRank (tamb´em conhecida como a matriz Google) do gr´aﬁco

por M = (1 − d) · A + d · B onde:

B =

1
n











1 1 · · ·

1 1 · · ·
...
...
. . .
1 1 · · ·











.

1

1
...
1

´E importante notar que M continua sendo uma matriz coluna estoc´astica com entradas

positivas. Veja que:

M = (1 − d)











a11 a12

· · · a1n

a21 a22
...
...
an1 an2

· · · a2n
...
. . .
· · · ann











+ d











1
n

1
n

...

1
n

1
n · · ·
1
n · · ·
...
. . .
1
n · · ·











1
n

1
n

...

1
n

⇒











M =

(1 − d)a11

(1 − d)a12

(1 − d)a21
...
(1 − d)an1

(1 − d)a22
...
(1 − d)an2

· · ·

· · ·
. . .

· · ·

(1 − d)a1n

(1 − d)a2n
...
(1 − d)ann











M =

(1 − d)a11 + d
n
(1 − d)a21 + d
n
...
(1 − d)an1 + d

(1 − d)a12 + d
(1 − d)a22 + d
...
n (1 − d)an2 + d

n · · ·
n · · ·
. . .

n · · ·











⇒











+











d
n

d
n

...

d
n

d
n · · ·
d
n · · ·
...
. . .
d
n · · ·

(1 − d)a1n + d
n
(1 − d)a2n + d
n
...
(1 − d)ann + d
n

d
n

d
n

...

d
n











.

Observe que a soma dos elementos de qualquer uma das colunas i da matriz M ´e igual

a 1 e suas entradas s˜ao sempre positivo:

Cap´ıtulo 4. Algoritmo PageRank

28

(1 − d)a1i +

d
n

+ (1 − d)a2i +

d
n

+ · · · + (1 − d)ani +

d
n

=

(1 − d)(a1i + a2i + · · · + ani) + n

d
n

= (1 − d) + d = 1.

A matriz M modela o nosso usu´ario aleat´orio da seguinte forma: na maioria das vezes,

ele vai seguir os links de uma p´agina, a partir de uma p´agina i, e passar para um dos

vizinhos de i. Uma porcentagem menor, mas positiva do tempo, o usu´ario vai sair da

p´agina atual e escolher arbitrariamente uma outra diferente a partir da web, digitando

seu endere¸co e “teletransporta-se” l´a. O fator de amortecimento d reﬂete a probabilidade

de o usu´ario fechar a p´agina atual e ir para uma nova sem utilizar links. Desde que seja

poss´ıvel efetuar esse “teletransporte” para qualquer p´agina da internet, cada uma tem

probabilidade de ser escolhida. Isto justiﬁca a estrutura da matriz 1

n B·

Intuitivamente, a matriz M faz a conex˜ao do gr´aﬁco e se livra do problema com

n´os desconectados. Um n´o que n˜ao possui sa´ıda tem probabilidade p

n de se mover para
qualquer outro n´o. Rigorosamente, para a matriz M, aplicam-se as seguintes teoremas:

Teorema 2 (Perron-Frobenius). Se M ´e uma matriz coluna estoc´astica positiva, ent˜ao:

I. 1 ´e um Autovalor de multiplicidade ´unica.

II. todos os outros autovalores t^em um valor absoluto menor do que 1, logo o maior

Autovalor ser´a 1.

III. os autovetores correspondentes ao autovalor 1 tem apenas entradas positivas ou ape-

nas entradas negativas. Em particular, para o autovalor 1 existe um ´unico autovetor

com a soma das suas entradas iguais a 1.

Teorema 3. Seja Mn uma matriz coluna estoc´astica positiva. Denote v∗ sendo seu

autovetor correspondente ao autovalor 1. Seja v o vetor coluna com todas entradas iguais

a 1

n . Ent˜ao, a sequ^encia v, Mv, · · · , Mkv converge para o vetor v∗.

Com isso, podemos concluir que, o vetor PageRank para um gr´aﬁco da internet com

matriz de transi¸c˜ao A, e fator de amortecimento d, ´e o Autovetor probabil´ıstico original

da matriz M, correspondente ao Autovalor 1.

Do ponto de vista matem´atico, uma vez que temos M, encontrar os Autovetores

correspondentes ao Autovalor 1 ´e, pelo menos em teoria, uma tarefa simples. Consiste

Cap´ıtulo 4. Algoritmo PageRank

29

apenas em resolver o sistema Ax = x. Por´em quando a matriz M tem tamanho 30 bilh˜oes,

como no caso da matriz para o gr´aﬁco real da Web, mesmo um software matem´atico,

como Matlab ou Mathematica s˜ao claramente sobrecarregado. Uma forma alternativa

de calcular o Autovetor probabil´ıstico correspondente ao Autovalor 1 ´e pelo m´etodo da

potˆencia. O teorema 3 garante que funciona para matrizes coluna estoc´astica positivas.

Em termos computacionais, ´e muito mais f´acil, a partir do vetor com todas as entradas 1,

para multiplicar x, Mx, ..., Mnx at´e a convergˆencia, do que ´e para calcular os Autovetores

de M. Na verdade, neste caso, a pessoa precisa apenas calcular os primeiros pares de

itera¸c˜oes a ﬁm de obter uma boa aproxima¸c˜ao do vetor PageRank. Para uma matriz

aleat´oria, o m´etodo de intera¸c˜ao ´e, em geral, conhecido por convergir lentamente. O

que torna o trabalho r´apido neste caso ´e o fato de que o gr´aﬁco web ´e escasso, ou seja,

que em um n´o ser´a pequeno n´umero de liga¸c˜oes de sa´ıda, na melhor das hip´oteses, duas

centenas, que ´e extremamente pequeno quando comparado aos 30 milh˜oes de n´os que

poderia, teoricamente, apontar. Da´ı a matriz de transi¸c˜ao A tem um monte de entradas

nulas, o que deixa o c´alculo bem mais r´apido.

Cap´ıtulo 5

Considera¸c˜oes Finais

O desenvolvimento da World Wide Web aponta para todo um novo campo da ma-
tem´atica chamado Matem´atica da Internet. ´E uma mistura de probabilidade, ´algebra

linear, teoria dos grafos e sistemas dinˆamicos, concebidos para responder a problemas

rigorosos sobre como a informa¸c˜ao se propaga atrav´es da rede.

Vimos como o Google usa o PageRank para determinar a relevˆancia das p´aginas

da web, tornando uma busca na Internet simples e eﬁciente. Da perspectiva de um

web designer, ´e importante n˜ao s´o para criar um site agrad´avel, com efeitos gr´aﬁcos

interessantes, mas ´e importante que outras p´aginas apontem para o seu web site. Um bom

PageRank pode transformar seu neg´ocio algo muito rent´avel. Do ponto de vista do Google,

´e importante manter os c´alculos PageRank exatos, e evitar tentativas de fraude. Link de

spam ´e deﬁnido como a tentativa intencional para melhorar o ranking de uma p´agina

no motor de busca, aumentando o n´umero de p´aginas que apontam a ela. As fazendas

de liga¸c˜oes envolvem a cria¸c˜ao de comunidades de p´aginas da web referenciando um a

outra, conhecidas como “sociedades de admira¸c˜ao m´utuas”. Embora algumas fazendas

de liga¸c˜oes possam ser criadas manualmente, a maioria delas s˜ao implementadas atrav´es
de programas e servi¸cos automatizados. ´E importante, portanto, reconhecer subgrafos

densos do gr´aﬁco web projetado para fazer exatamente isso, e para elimin´a-los a partir

de c´alculos PageRank. Embora em seu n´ucleo, o PageRank seja como descrito neste

trabalho, no mundo real, o Google usa algoritmos melhorados de busca para lidar com

estes problemas, podendo atribuir pesos diferentes para os links de sa´ıda, ou decidir que

determinadas liga¸c˜oes n˜ao devem transferir seu PageRank em tudo, isto para citar apenas

alguns dos recursos extras. Atualmente, os algoritmos do Google utilizam mais de 200

30

Cap´ıtulo 5. Considera¸c˜oes Finais

31

sinais ou “pistas” diferentes para adivinhar o que vocˆe realmente procura. Esses sinais

incluem coisas como os termos em websites, a atualiza¸c˜ao do conte´udo, a regi˜ao do usu´ario

e o PageRank.

A World Wide Web est´a em constante mudan¸ca, as p´aginas s˜ao adicionados e exclu´ıdos

a cada momento, a compreens˜ao da estrutura do gr´aﬁco Internet ´e um problema-chave de

pesquisa. Desenvolvimento de modelos para um gr´aﬁco de Internet que tem bilh˜oes de n´os,

´e, no entanto, longe de ser trivial. A web ´e muitas vezes descrito como tendo uma estrutura

de gravata borboleta. O n´o da gravata borboleta ´e representado por um componente

fortemente ligado do gr´aﬁco, chamado de n´ucleo. Um lado da gravata borboleta consiste

em p´aginas que apontam para o n´ucleo, enquanto o outro lado da gravata cont´em p´aginas

que com pelo menos uma liga¸c˜ao a partir do n´ucleo. O restante das p´aginas da web s˜ao,

ou em componentes desconectados, ou em gavinhas que s´o apontam para p´aginas de fora

do n´ucleo. Nesta teia de aranha, redes sociais, comunidades na web s˜ao deﬁnidos como

subgr´aﬁcos com links mais internos, em seguida, os externos. M´etodos espectrais s˜ao

usados para analisar a distribui¸c˜ao destas comunidades.

Compreender o gr´aﬁco da Internet pode ajudar a responder perguntas sobre como

a informa¸c˜ao se propaga atrav´es da rede. Propaga¸c˜ao do v´ırus de computador sobre

a rede ´e de particular interesse. Compreender a taxa em que os v´ırus de computador

podem ajudar a propagar os fabricantes de software antiv´ırus para antecipar e ´areas de

quarentena infectado.

Nesse contexto, a ´Algebra Linear ´e importante aliada na constru¸c˜ao de modelos ma-

tem´aticos lineares para auxiliar no desenvolvimento da inform´atica, por´em, sua aplica¸c˜ao

se estende em outras ´areas como avia¸c˜ao, economia, circuitos eletrˆonicos ou explora¸c˜ao

petrol´ıfera. Alguns conceitos, como matrizes, determinantes e sistemas lineares s˜ao traba-

lhados durante o ensino m´edio e que por muitas vezes somos questionados por aplica¸c˜oes

na qual usaremos esse conhecimento.

Dessa forma apresentamos aqui uma breve introdu¸c˜ao no estudo da ´Algebra Linear,

utilizando o algor´ıtimo do motor de busca do Google como motiva¸c˜ao, com o intuito

de instigar a curiosidade sobre o tema, visando n˜ao um estudo completo e deﬁnitivo

sobre o mesmo, mas sim como forma de incentivar uma busca mais aprofundada de suas

caracter´ısticas e propriedades.

Refer^encias Bibliogr´aficas

[1] HEFEZ, A., FERNANDEZ, C. S. - Introdu¸c˜ao `a ´Algebra Linear. Cole¸c˜ao PROF-

MAT - Rio de Janeiro: SBM. 2012.

[2] ROUSSEU, C., SAINT-AUBIN, Y. - Matem´atica e Atualidades, Volume 1.

Cole¸c˜ao PROFMAT - 1 ed. Rio de Janeiro: SBM. 2015.

[3] POOLE, D. - ´Algebra Linear. Tradu¸c˜ao de Mertha Salerno Monteiro, et al. S˜ao

Paulo: Pioneira Thomson Learning, 2004.

[4] LIMA, E. L. - An´alise Real, Volume 2, Fun¸c˜oes de n Vari´aveis. 6 ed. Rio de Janeiro:

IMPA. 2013.

[5] HANING, C.S. - Aplica¸c˜ao da Topologia `a An´alise. Projeto Euclides - IMPA, 1976.

[6] IEZZE, G. - Fundamentos da Matem´atica Elementar: Sequ^encias, Matrizes, Deter-

minantes e Sistemas, Volume 4. 2 ed. Atual, 1977.

[7] BRIAN, S., Page, L. - The Anatomy of a Large-Scale Hypertextual Web Search

Engine. Computer Science Department, Stanford University, Stanford, CA 94305.

Dispon´ıvel em:<http://infolab.stanford.edu/~backrub/google.html> Acesso
em: 07 de junho de 2016.

[8] INTERNET LIVE STATS. Dispon´ıvel em <http://www.internetlivestats.

com/>. Acesso em: 07 de junho de 2016.

[9] PAGE, L., BRIN, S., MOTWANI, R., WINOGRAD, T. - The PageRank

Citation Ranking: Bringing Order to the Web. Technical Report. Stanford Info-

Lab, 1999. Dispon´ıvel em: <http://ilpubs.stanford.edu:8090/422/1/1999-66.

pdf>. Acesso em: 20 de junho de 2016.

32

Refer^encias Bibliogr´aficas

33

[10] BARROS, C. D. V. - O Teorema do Ponto Fixo de Banach e Algumas Aplica¸c˜oes


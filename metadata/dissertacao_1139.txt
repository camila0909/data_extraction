Universidade Federal do Recˆoncavo da Bahia - UFRB

Centro de Ciˆencias Exatas e Tecnol´ogicas - CETEC

Programa de P´os Graduac¸˜ao em Matem´atica em Rede

Nacional - PROFMAT

Dissertac¸˜ao de Mestrado

Cadeias de Markov no Ensino M´edio

Ot´avio Augusto Rodrigues Melo

Cruz das Almas - Bahia

Julho de 2019

Cadeias de Markov no Ensino M´edio

Ot´avio Augusto Rodrigues Melo

Disserta¸c˜ao

de Mestrado

apresentada

ao

curso de Mestrado Proﬁssional em Matem´atica

em Rede Nacional do Centro de Ciˆencias Exatas

e Tecnol´ogicas da Universidade Federal do

Recˆoncavo da Bahia e Sociedade Brasileira

de Matem´atica como requisito parcial para

obten¸c˜ao do t´ıtulo de Mestre em Matem´atica.

Orientador: Prof. Dr. Anderson Reis Cruz.

Cruz das Almas - Bahia

Julho de 2019

                               FICHA CATALOGRÁFICA                          Ficha elaborada pela Biblioteca Universitária de Cruz das Almas – UFRB.                           Responsável pela Elaboração – Antonio Marcos Sarmento das Chagas (Bibliotecário – CRB5 / 1615).                        Os dados para catalogação foram enviados pelo usuário via formulário eletrônico. M528d              Melo, Otávio Augusto Rodrigues.                                 Cadeias de Markov no Ensino Médio / Otávio Augusto Rodrigues Melo._ Cruz das Almas, BA, 2019.              73f.; il.                                                      Orientador: Anderson Reis da Cruz.                                   Coorientadora: Katia Silene Ferreira Lima Rocha.                                                   Dissertação (Mestrado) – Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas.                                 1.Matemática – Processos de Markov. 2.Matemática – Estudo e ensino. 3.Ensino médio – Análise. I.Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas. II.Título.                                                                                                                                           CDD: 519.217 `A minha Tia Deuzinha.

Agradecimentos

Agrade¸co `as pessoas que me ajudaram neste trabalho, em especial ao meu orien-

tador o Professor Dr. Anderson Reis da Cruz, pela experiˆencia, entusiasmo, dedica¸c˜ao e

conselhos durantes as orienta¸c˜oes at´e o t´ermino da disserta¸c˜ao. Aos demais professores

pela oportunidade e por toda a contribui¸c˜ao neste processo de aprendizagem. Aos meus

colegas, em especial ao professor Paulo e ao professor Jos´e, pelos conselhos e discuss˜oes
que enriqueceram o conhecimento. `A minha esposa por sua paciˆencia e apoio durante o
per´ıodo de estudo. `A minha familia pelo seu apoio e entusiasmo nos principais momentos
de minha vida. E `a Deus que me deu for¸cas, sa´ude e f´e para concluir mais uma etapa na

minha vida.

“N˜ao h´a ramo da Matem´atica, por mais abs-

trato que seja, que n˜ao possa um dia vir a

ser aplicado aos fenˆomenos do mundo real.”

Lobachevski.

Resumo

Neste trabalho, estudaremos as Cadeias de Markov Homogˆeneas com o conjunto

de estados discreto. Desta forma, pretende-se discutir os principais conceitos dessa teoria

no ensino m´edio da educa¸c˜ao b´asica. Visto que, ´e poss´ıvel aprofundar os conte´udos de

Probabilidade e Matrizes e suas aplica¸c˜oes como em uma Cadeia de Markov. Al´em disso,

possibilita a contextualiza¸c˜ao destes t´opicos e interdisciplinaridade com outras disciplinas

desta etapa de ensino. No ﬁnal, apresentaremos uma proposta de sequˆencia did´atica para

o professor fazer uso em sala de aula, com o aux´ılio do software matem´atico MAXIMA,

contribuindo para uma melhor forma¸c˜ao dos estudantes.

Palavras-chave: Probabilidade. Matrizes. Cadeias de Markov. Aplica¸c˜oes.

Abstract

In this work, we will study Homogeneous Markov Chains with the set of discrete

states. In this way, it is intended to discuss the main concepts of this theory in the high

school of basic education. Seeing that it is possible to deepen the contents of Probability

and Matrices and their applications as in a Markov Chain.

In addition, it allows the

contextualization of these topics and interdisciplinarity with other disciplines of this stage

of teaching. At the end, there is a proposal of a didactic sequence for the teacher to

make use of in the classroom, with the aid of the MAXIMA mathematical software, thus

contributing to a better training of students.

Keywords:Probability. Matrices. Markov Chains. Applications.

Sum´ario

Introdu¸c˜ao

1 Conceitos Preliminares

1.1 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 No¸c˜oes de Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

4

4

9

1.2.1 Probabilidades Condicionais . . . . . . . . . . . . . . . . . . . . . . 13

1.3 Vari´aveis Aleat´orias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

1.4 Alguns Modelos Discretos

. . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2 Cadeias de Markov

24

2.1 Exemplos de Processos Estoc´asticos . . . . . . . . . . . . . . . . . . . . . . 24

2.2 Cadeias de Markov a Tempo Discreto . . . . . . . . . . . . . . . . . . . . . 27

2.3 Matrizes de Transi¸c˜ao de Ordem Superior

. . . . . . . . . . . . . . . . . . 31

2.4 Cadeias com Dois Estados . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

3 Exemplos de Cadeias de Markov para o Ensino M´edio

39

3.1 Previs˜ao do Tempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

3.2 Previs˜oes em Gen´etica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

3.3 Previs˜oes Populacionais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

3.4 Passeios Aleat´orios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4 Sugest˜ao de Sequˆencia Did´atica

44

4.1 Primeira Etapa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.2 Segunda Etapa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.3 Terceira Etapa

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

4.4 Quarta Etapa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

Referˆencias Bibliogr´aﬁcas

Referˆencias Bibliogr´aﬁcas

59

59

Lista de Figuras

1.3.1 Gr´aﬁco de F (x).

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

1.3.2 Fun¸c˜ao de distribui¸c˜ao para o n´umero de coroas. . . . . . . . . . . . . . . . 20

1.4.1 Fun¸c˜ao de distribui¸c˜ao da Uniforme Discreta em {1, 2, . . . , 6} .

. . . . . . . 21

2.2.1 Grafo chamado de Topologia da Cadeia.

. . . . . . . . . . . . . . . . . . . 29

2.3.1 Gr´aﬁco de ´arvore. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.4.1 Topologia da cadeia para o passeio aleat´orio simples com inﬁnitos estados.

42

4.1.1 Grafo de transi¸c˜oes entre classes.

. . . . . . . . . . . . . . . . . . . . . . . 46

4.1.2 Transi¸c˜oes com estado inicial 2 . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.3.1 P´agina Inicial do wxMaxima.

. . . . . . . . . . . . . . . . . . . . . . . . . 52

4.3.2 Comando para introduzir matriz.

. . . . . . . . . . . . . . . . . . . . . . . 53

4.3.3 Caixa da matriz.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

4.3.4 Caixa com os elementos da matriz.

. . . . . . . . . . . . . . . . . . . . . . 54

4.3.5 Matriz gerada pela caixa de elementos.

. . . . . . . . . . . . . . . . . . . . 54

4.3.6 Adi¸c˜ao de matrizes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

4.3.7 Multiplica¸c˜ao de matrizes.

. . . . . . . . . . . . . . . . . . . . . . . . . . . 55

4.3.8 Potˆencia de matriz. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

4.3.9 Solu¸c˜ao para quinze itera¸c˜oes.

. . . . . . . . . . . . . . . . . . . . . . . . . 57

4.4.1 Diagrama de transi¸c˜ao. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

Lista de Tabelas

1.1 Probabilidades da v.a. X.

. . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2.1 Classiﬁca¸c˜ao dos processos estoc´asticos. . . . . . . . . . . . . . . . . . . . . 26

3.1 Condi¸c˜oes clim´aticas de Santo Antˆonio de Jesus no mˆes de junho.

. . . . . 39

3.2 Tabela de gen´otipos.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

1

Introdu¸c˜ao

Andrei Andreyevich Markov (1856−1922), foi um matem´atico russo que se formou

e foi professor da Universidade St. Petersburg. Nesta ´epoca, realizou v´arios trabalhos na

´area da matem´atica, sendo os primeiros sobre limite de integrais, fra¸c˜oes cont´ınuas e teo-

ria da aproxima¸c˜ao. Depois de 1900, ele aplicou o m´etodo de fra¸c˜oes cont´ınuas, trabalho

inicialmente realizado pelo seu professor Pafnuty Chebyshev, `a teoria da probabilidade.

No entanto, Markov ´e reconhecido por seu trabalho sobre as Cadeias de Markov possibili-

tou uma nova abordagem na teoria das probabilidades e tamb´em na teoria dos processos

estoc´asticos.

As Cadeias de Markov s˜ao utilizadas para modelar matematicamente e resolver

muitos problemas da atual sociedade, entre eles: processos epidemol´ogicos, teoria dos

jogos, crescimento e decrescimento de uma determinada popula¸c˜ao, identiﬁca¸c˜ao de genes

do DNA entre outros. Al´em disso, ao n´ıvel da educa¸c˜ao b´asica pode-se utilizar este

conte´udo para discutir e analisar situa¸c˜oes em tempo discreto.

Neste trabalho apresentaremos um primeiro cap´ıtulo com conceitos preliminares

de Matrizes, Probabilidade e Vari´aveis Aleat´orias. No segundo cap´ıtulo, t´opicos b´asicos

da teoria matem´atica das Cadeias de Markov, enfatizando o caso homogˆeneo a tempo

discreto. Ou seja, tudo que ´e necess´ario para o ensino aprendizagem desta teoria na

educa¸c˜ao b´asica. No terceiro cap´ıtulo algumas aplica¸c˜oes das Cadeias de Markov como:

previs˜ao do tempo, passeio aleat´orio, crescimento populacionais e previs˜oes em gen´etica.

No ´ultimo cap´ıtulo do trabalho, trazemos uma sugest˜ao de sequˆencia did´atica de

Cadeias de Markov Homogˆenneas para o professor aplicar em sala de aula e contribuir

para uma discuss˜ao matem´atica mais aprofundada dos conte´udos previamente menciona-

dos.A inquieta¸c˜ao que ´e comum aos alunos no por quˆe do estudo de algumas deﬁni¸c˜oes

matem´aticas pode ser respondida, constru´ıda e participada na discuss˜ao das situa¸c˜oes pro-

postas nos planos de aula. Desta forma, os objetivos propostos s˜ao: mostrar a utiliza¸c˜ao

das matrizes em outras ´areas do conhecimento, possibilitar que os alunos enxerguem a

matriz como uma forma eﬁciente de representa¸c˜ao e manipula¸c˜ao de dados, discutir a

teoria das Cadeias de Markov, trabalhar com probabilidades dentro de matrizes e utilizar

o software MAXIMA como ferramenta nos c´alculos de grande itera¸c˜oes.

2

3

Portanto, o trabalho tem uma parte bibliogr´aﬁca de aprofundamento da teoria

matem´atica e uma parte de aplica¸c˜ao a educa¸c˜ao b´asica com o enfoque aos alunos do

segundo ano do ensino m´edio. Com isso, sugerimos uma sequˆencia did´atica que possibilite

uma maior aproxima¸c˜ao dos estudantes a uma aplica¸c˜ao paup´avel e assim contribua para

um melhor ensino e aprendizagem da matem´atica.

Cap´ıtulo 1

Conceitos Preliminares

Neste cap´ıtulo ser´a abordado conceitos b´asicos da Teoria de Matrizes e da Teoria

de Probabilidades que ser˜ao utilizados no decorrer do texto. Apresentaremos tamb´em

no¸c˜oes de experimentos aleat´orios, especiﬁcamente, discorrendo sobre vari´aveis aleat´orias

e suas propriedades. Ao leitor que desejar um estudo mais aprofundado nestes t´opicos,

recomendamos [7] para a Teoria de Matrizes e [12, 11, 14] para a Teoria de Probabili-

dades e o estudo de Vari´aveis Aleat´orias. Nestas referˆencias encontram-se os conceitos e

propriedades discutidas neste cap´ıtulo.

1.1 Matrizes

A ideia geral de uma matriz ´e a disposi¸c˜ao de elementos em linhas e colunas

muito ´uteis para organizar dados. Por exemplo, as notas ﬁnais dos alunos de uma s´erie

no col´egio podem formar uma matriz cujas linhas correspondem `as mat´erias lecionadas

naquela s´erie e cujas colunas representam os alunos. Conforme tabela abaixo:

Pedro Carlos Antˆonio

Juliana Paula

Matem´atica

5,4

Portuguˆes

Biologia

F´ısica

Qu´ımica

Hist´oria

Geograﬁa

3

3

2

6

6

7

6,6

4,3

5

5

6

7,5

8

7

4,5

5

5

5

9

9

7,5

6

7

8

9

5,5

7

8

9

8

8

9

9

9

Podemos formar uma matriz com essas informa¸c˜oes, na qual a interse¸c˜ao de uma linha

com uma coluna demonstra a nota que um determinado aluno tirou naquela mat´eria.

4

5



5, 4 6, 6

7

7, 5 8

















3

3

2

6

6

7

4, 3 4, 5

5

5

6

7, 5

8

5

5

5

9

9

6

7

8

9

7


9



8


8



9




9

5, 5 9

As matrizes podem aparecer tamb´em como quadro de coeﬁcientes de sistemas de

equa¸c˜oes lineares. Por exemplo,




4x + 5y = 7



2x − 15y = 9

podemos associar a matriz dos coeﬁcientes

(cid:34)

4

(cid:35)

5

2 −15

.

As linhas ou colunas de uma matriz podem representar vetores em Rn, o que as vezes ´e ´util
para solu¸c˜ao de problemas de geometria. Observamos que, v´arias t´ecnicas de resolu¸c˜ao

de problemas tomam como base o estudo de matrizes.

Na deﬁni¸c˜ao que adotaremos, uma matriz m × n ´e uma lista de n´umeros aij, onde
1 ≤ i ≤ m e 1 ≤ j ≤ n, dispostas em m linhas e n colunas, no qual o elemento aij situa-se
na i-´esima linha e na j-´esima coluna:

M =










a12
a11
a22
a21
...
...
am1 am2










.

. . . a1n
. . . a2n
...
. . .
... amn

A lista ordenada (ai1, ai2, ai3, ..., ain) chama-se a i-´esima linha ou o i-´esimo vetor-
linha da matriz M enquanto (a1j, a2j, a3j, ..., amj) ´e a j-´esima coluna ou j-´esimo vetor-
coluna de M . Denotamos ainda M = [aij]m×n ou, quando n˜ao houver necessidade em
explicitar o seu tamanho, M = [aij] .

A depender da quantidade de linhas ou colunas, ou ainda, pela natureza de seus

elementos, destacaremos alguns tipos especiais de matrizes:

• Uma matriz quadrada ´e aquela cujo n´umero de linhas ´e igual ao n´umero de colunas

(m = n) . Neste caso, dizemos que M = [aij]m×n ´e uma matriz de ordem m.

6

• Uma matriz nula ´e aquela em que aij = 0, para todo i e j. Note que, n˜ao necessari-

amente a matriz ´e quadrada.

• Uma matriz coluna ´e aquela que possui uma ´unica coluna (n = 1) . Analogamente,

uma matriz linha ´e aquela que possui uma ´unica linha (m = 1).

• Uma matriz diagonal ´e uma matriz quadrada (m = n) onde aij = 0, para i (cid:54)= j, isto

´e, os elementos que n˜ao est˜ao na diagonal principal s˜ao nulos

• Um caso particular de matriz diagonal ´e a matriz identidade, que ´e uma matriz

quadrada em que aii = 1 e aij = 0, para i (cid:54)= j. Denotamos tal matriz por In, onde
n representa a sua ordem.

• Uma matriz triangular superior ´e uma matriz quadrada onde todos os elementos

abaixo da diagonal principal s˜ao nulos, isto ´e, m = n e aij = 0, para i > j.

• Analogamente, uma matriz triangular inferior ´e aquela em que m = n e aij = 0,

para i < j.

• Uma matriz sim´etrica ´e uma matriz quadrada tal que aij = aji, para todo 1 ≤ i, j ≤

n.

• Uma matriz antissim´etrica ´e uma matriz quadrada tal que aij = −aji, para todo
1 ≤ i, j ≤ n. Em particular temos que aii = −aii, para todo 1 ≤ i ≤ n, ou seja,
aii = 0, para todo 1 ≤ i ≤ n.

Deﬁnimos algumas opera¸c˜oes entre matrizes.

Deﬁni¸c˜ao 1.1. A soma de duas matrizes do mesmo tipo m × n e o produto de uma

matriz por um n´umero s˜ao deﬁnidos elemento a elemento,

1. Se A = [aij] e B = [bij] s˜ao matrizes m × n ent˜ao A + B = [aij + bij] .

2. α · A = [αaij] para todo α pertencente a R.

Estas opera¸c˜oes tˆem as mesmas propriedades das opera¸c˜oes usuais de mesmo nome entre
vetores de Rn. Neste caso, o elemento neutro da soma ´e a matriz nula e o elemento oposto
de uma matriz A = [aij] ´e a matriz −A = [−aij] . De fato, o conjunto de matrizes do mesmo
tipo resulta em um espa¸co vetorial com essas opera¸c˜oes veja por exemplo [Boldrini].

Deﬁnimos uma opera¸c˜ao de multiplica¸c˜ao entre matrizes.

Intuitivamente, de-

ﬁnir´ıamos tal opera¸c˜ao tamb´em elemento a elemento. Entretanto, algumas situa¸c˜oes

pr´aticas requerem um c´alculo diferente. Vejamos o exemplo abaixo.

7

Exemplo 1.1. Uma empresa que possui duas padarias, chamadas de C e D, que fabrica

trˆes tipos de p˜ao: 1, 2 e 3, os quais s˜ao feitos de farinha, a¸c´ucar, leite, manteiga e ovos.

Em cada semana, as vendas dessas duas padarias ser˜ao estimadas conforme a matriz de

M de venda semanal abaixo:

Padaria P˜ao tipo 1

P˜ao tipo 2

P˜ao tipo 3

C

D

50 unidades

30 unidades

25 unidades

20 unidades

20 unidades

40 unidades

Para a fabrica¸c˜ao destes p˜aes, o material ´e usado de acordo com a matriz N

seguinte:

P˜ao

farinha

a¸c´ucar

leite manteiga

ovos

tipo 1

tipo 2

tipo 3

600 g

300 g

450 g

250 g

400 ml

100 g

200 ml

120 g

280 g

175 g

500 ml

0 g

6

4

4

A dire¸c˜ao da empresa, aﬁm de atender `a demanda, quer saber a quantidade de

cada uma das cinco mat´erias primas que deve alocar as suas duas padarias. A resposta

deve ser uma matriz, do tipo 2 × 5, onde as linhas representam as duas padarias e as

colunas correspondem aos cinco materiais usados.

Padaria

farinha

a¸c´ucar

leite manteiga

ovos

C

D

c11
c21

c12
c22

c13
c23

c14
c24

c15
c25

Assim, cij ´e quanto a i-´esima padaria deve guardar do j-´esimo material a ﬁm de

executar as vendas previstas.

Se escrevermos M = [aij] ; para 1 ≤ i ≤ 2,1 ≤ j ≤ 3 e N = [bij] , com 1 ≤ i ≤ 3,

1 ≤ j ≤ 5. Desta forma, cij = ai1b1j + ai2b2j + ai3b3j (1 ≤ i ≤ 2, 1 ≤ j ≤ 5) .

Logo, o n´umero de ovos necess´arios para a padaria C ´e

c15 = a11b15 + a12b25 + a13b35 = 50 × 6 + 30 × 4 + 25 × 4 = 520

.

Estendemos esta no¸c˜ao para caso geral a seguir:

Deﬁni¸c˜ao 1.2. Sejam M = [aij] e N = [bij] matrizes do tipo m×n e n×p respectivamente.
O produto dessas matrizes ´e a matriz M N = [xij] , de tipo m × p, cuja entrada ij ´e dado
por:

xij = ai1b1j + ai2b2j + . . . + ainbnj =

n
(cid:88)

k=1

aikbkj.

As opera¸c˜oes de soma, produto por escalar e multiplica¸c˜ao de matrizes obedecem

algumas propriedades que descreveremos nos resultados a seguir.

Proposi¸c˜ao 1.1. Dadas as matrizes A, B e C de mesma ordem m × n, temos:

8

1. A + B = B + A

2. A + (B + C) = (A + B) + C

3. A + 0 = A, onde 0 ´e a matriz nula m × n.

Proposi¸c˜ao 1.2. Dadas as matrizes A e B de mesma ordem m×n e n´umeros reais k, k1e
k2, temos:

1. k (A + B) = kA + kB

2. (k1 + k2) A = k1A + k2A

3. 0A = 0

4. k1 (k2A) = (k1k2) A

Observa¸c˜ao 1.1. Como as opera¸c˜oes de soma e produto por um n´umero real s˜ao deﬁnidas

elemento a elemento, as proposi¸c˜oes acima s˜ao consequˆencias imediatas das propriedades

associativa, comutativa e distributiva da soma e produto de n´umeros reais.

Proposi¸c˜ao 1.3. Dadas A e D matrizes de ordem m × n e B, C matrizes de ordem n × p,

temos:

1. A (B + C) = AB + AC

2. (A + D)B = AB + DB

Demonstra¸c˜ao. Sejam A = [aij]m×n , B = [bij]n×p e C = [cij]n×p . Temos que:

A(B + C) =

=

(cid:34) n

(cid:88)

k=1
(cid:34) n

(cid:88)

k=1

(cid:35)

aik(bkj + ckj)

=

(cid:35)

aikbkj

+

(cid:34) n

(cid:88)

k=1

aikbkj +

(cid:35)

aikckj

n
(cid:88)

k=1

(cid:34) n

(cid:88)

k=1
(cid:35)

aikckj

= AB + BC

Analogamente, provamos que (A + D)B = AB + DB.

Observa¸c˜ao 1.2. Note que o produto n˜ao ´e comutativo em geral. Considere por exemplo

A =

(cid:34)

1

1

(cid:35)

−1 −2

(cid:34)

(cid:35)

−1 −1

0

0

e B =

, temos AB (cid:54)= BA.

9

1.2 No¸c˜oes de Probabilidade

A Teoria das Probabilidades ´e um ramo da Matem´atica que foi iniciado atrav´es

de estudos de jogos de azar. Essa teoria busca reduzir todos os acontecimentos do mesmo

gˆenero a um certo n´umero de casos igualmente poss´ıveis, ou seja, tais que estejamos

igualmente desacreditados de sua existˆencia, e em determinar o n´umero de casos favor´aveis

ao acontecimento cuja probabilidade ´e buscada. Assim, a raz˜ao deste n´umero com o

de todos os casos poss´ıveis ´e a medida da probabilidade. Ou seja, uma fra¸c˜ao onde o

numerador ´e o n´umero de casos favor´aveis e o denominador ´e o n´umero de todos os casos

poss´ıveis.

A deﬁni¸c˜ao de probabilidade como quociente do n´umero de casos favor´aveis sobre

o n´umero de casos poss´ıveis foi a primeira deﬁni¸c˜ao formal de probabilidade, e apareceu

pela primeira vez na obra Liber de Ludo Aleae de Jerˆonimo Cardano (1501 − 1576). Para

compreens˜ao dos conceitos e propriedades iremos analisar alguns exemplos.

Exemplo 1.2. Considere o lan¸camento de um dado. Os resultados poss´ıveis s˜ao 1, 2, 3, 4, 5

e 6. Queremos saber a probabilidade de, em um lan¸camento obter um n´umero ´ımpar. Na

ideia do Ludo Aleae, tal probabilidade corresponde ao quociente entre o n´umero de casos

favor´aveis (obter 1, 3 ou 5 no lan¸camento) sobre o n´umero de casos poss´ıveis, ou seja, a
probabilidade de 1

2, que corresponde a 50% de chance.

Intuitivamente, entendemos um experimento como um procedimento realizado

sob determinadas condi¸c˜oes, repetido um n´umero de vezes sob estas mesmas condi¸c˜oes, a

partir do qual observamos os resultados obtidos. Um experimento ´e determin´ıstico quando

sob as mesmas condi¸c˜oes o seu resultado ´e completamente determinado. Por exemplo, um
recipiente com ´agua pura nas condi¸c˜oes normais de press˜ao atmosf´erica posto a 100oC,tem

como resultado a fervura da ´agua.

Um experimento ´e dito ser aleat´orio quando o seu resultado n˜ao pode ser deter-

minado, o que se sabe s˜ao apenas um conjunto poss´ıvel de resultados. Por exemplo o

lan¸camento de um dado pode ser considerado um experimento aleat´orio.

Deﬁni¸c˜ao 1.3. O conjunto Ω de resultados possiveis de um experimento aleat´orio ser´a

chamado de espa¸co amostral. Os elementos de Ω ser˜ao chamados de amostras.

Voltemos ao lan¸camento de dados. Neste caso o espa¸co amostral ´e o conjunto

Ω = {1, 2, 3, 4, 5, 6} . Podemos relacionar a obten¸c˜ao de um n´umero ´ımpar ao conjunto

A = {1, 3, 5} ,que chamaremos de evento Laplace.

No evento Laplace, os elementos de A s˜ao denominados como os casos favor´aveis.

Os elementos do espa¸co amostral Ω eram chamados os casos poss´ıveis. Desta forma, deﬁ-

nimos probabilidade como n´umero de casos favor´aveis sobre o n´umero de casos poss´ıveis.

10

A classe de eventos de um experimento aleat´orio deve ser rico suﬁciente de modo

a ser signiﬁcante.

Deﬁni¸c˜ao 1.4. Seja Ω um conjunto. Uma σ − ´algebra F de Ω ´e uma fam´ılia de subcon-

juntos de Ω satisfazendo:

i) ∅ e Ω pertencem a F.
ii) Se A ∈ F ent˜ao Ac ∈ F.

iii)Se Aj ∈ F, j = 1, 2, . . . ent˜ao ∪
j

Aj ∈ F.

Atribu´ımos o n´umero 1

2 a chance de ocorrer o evento A = {1, 3, 5} no lan¸camento
de dados e podemos interpretar essa chance como uma medida do conjunto A. Em geral

deﬁnimos uma probabilidade no conjunto Ω como uma fun¸c˜ao que atribui a elementos de

uma σ − ´algebra valores no intervalo [0, 1].

Deﬁni¸c˜ao 1.5. Sejam Ω um conjunto (espa¸co amostral) e F uma σ − ´algebra em Ω. Uma

fun¸c˜ao P : F → [0, 1] ´e chamada de probabilidade se satisfaz as seguintes condi¸c˜oes:

1. P (∅) = 0 e P (Ω) = 1;

2. Se {Aj}j∈N ´e uma fam´ılia de subconjuntos 2 a 2 disjuntos de F ent˜ao P

(cid:80)∞

j=1 P (Aj) .

(cid:16) ˙(cid:83)∞

j=1Aj

(cid:17)

=

No caso em que (cid:93)Ω < ∞ a σ − ´algebra ser´a sempre o conjunto de partes de Ω,

ou seja, a fam´ılia de todos os subconjuntos de Ω. Neste caso, a condi¸c˜ao 2 reduz-se a uma

uni˜ao ﬁnita.

Al´em disso, ´e razo´avel supor que:

a) Os eventos elementares s˜ao igualmente prov´aveis.

b) Todo evento A ´e uni˜ao de p eventos elementares onde p ≤ n.

A razoabilidade da condi¸c˜ao (a) ´e consequˆencia do seguinte fato: considere um

evento A resultado de um experimento aleat´orio. Podemos analisar a frequˆencia deste
evento em n repeti¸c˜oes do experimento atrav´es do quociente Fn(A)
onde Fn(A) denota
o n´umero de vezes em que o evento A aconteceu em n repeti¸c˜oes. Observe que este ´e

n

um dado emp´ırico, obtido atrav´es da repeti¸c˜ao do experimento um determinado n´umero
de vezes. Surge assim uma quest˜ao natural: o que acontece com Fn(A)
suﬁcientemente grande?

se tomarmos n

n

Caso tal n´umero se aproxime de algum valor, este seria uma boa representa¸c˜ao

para a probabilidade da ocorrˆencia do evento A. Um resultado central na Teoria de Pro-

babilidade garante que na maioria das sequˆencias de repeti¸c˜oes este n´umero se aproxima
de (cid:93)(A)
(cid:93)(Ω) , quando fazemos n suﬁcientemente grande. Este teorema ´e a chamada Lei dos
Grandes N´umeros, que n˜ao apresentaremos aqui, por ser um resultado mais complexo e

que foge dos nossos objetivos. Sugerimos [3] para mais informa¸c˜oes acerca deste resultado.

11

Logo, podemos deﬁnir, para cada A ⊂ Ω, a probabilidade P (A) = (cid:93)(A)
Observe que:

(cid:93)(Ω) = p
n .

a) Para todo evento A, 0 ≤ P (A) ≤ 1;

b) P (Ω) = 1;

c) P (∅) = 0, pois ((cid:93) (∅) = 0);
d) Se A ∩ B = ∅ ent˜ao P (A ˙∪B) = P (A) + P (B).

Portanto, P assim deﬁnida ´e uma probabilidade em Ω.

Exemplo 1.3. Trˆes moedas s˜ao jogadas simultaneamente. Vamos calcular a probabili-

dade de obter 2 caras e a probabilidade de obter pelo menos 2 caras.

Sendo K cara e C coroa, o espa¸co amostral ´e dado por

Ω = {(KKK) , (KKC) , (KCK) , (KCC) , (CKK) , (CKC) , (CCK) , (CCC)} .

Desta forma, (cid:93) (Ω) = 8. Se A indica o evento “obter 2 caras”, ent˜ao A =

{(KKC) , (KCK) , (CKK)}. Assim, (cid:93) (A) = 3 e portanto P (A) = 3
8.
Se B denota o evento “obter pelo menos duas caras”, ent˜ao

B = {(KKC) , (KCK) , (CKK) , (KKK)} .

Assim, (cid:93) (B) = 4 e P (B) = 4

8 = 1
2.

Exemplo 1.4. Dois dados s˜ao jogados simultaneamente. Vamos calcular a probabilidade

de que a soma dos n´umeros mostrados nas faces de cima seja 7.

O espa¸co amostral Ω consiste em todos os pares (i, j) onde i e j s˜ao inteiros

positivos compreendidos entre 1 e 6. Desta forma, podemos descrever o espa¸co amostral:

1

2

3

4

5

6

1

2

3

4

5

6

(1, 1)

(1, 2)

(1, 3)

(1, 4)

(1, 5)

(1, 6)

(2, 1)

(2, 2)

(2, 3)

(2, 4)

(2, 5)

(2, 6)

(3, 1)

(3, 2)

(3, 3)

(3, 4)

(3, 5)

(3, 6)

(4, 1)

(4, 2)

(4, 3)

(4, 4)

(4, 5)

(4, 6)

(5, 1)

(5, 2)

(5, 3)

(5, 4)

(5, 5)

(5, 6)

(6, 1)

(6, 2)

(6, 3)

(6, 4)

(6, 5)

(6, 6)

O n´umero de eventos elementares ´e igual a (cid:93) (Ω) = 36. Seja A o conjunto dos

pares (i, j) tais que i + j = 7.

Esses pares s˜ao justamente a anti-diagonal:

A = {(6, 1) , (5, 2) , (4, 3) , (3, 4) , (2, 5) , (1, 6)} .

Desta forma, (cid:93) (A) = 6 e portanto P (A) = 6

36 = 1
6.

A seguir apresentaremos algumas consequˆencias da deﬁni¸c˜ao de probabilidade.

12

Proposi¸c˜ao 1.4. P (cid:0)AC(cid:1) = 1 − P (A) , para todo A ∈ F.
Demonstra¸c˜ao. Sabemos que 1 = P (Ω) = P (cid:0)A ˙∪AC(cid:1) = P (A) + P (cid:0)AC(cid:1) . Portanto,
P (cid:0)AC(cid:1) = 1 − P (A) .

Proposi¸c˜ao 1.5. Se A, B ∈ F com A ⊂ B ent˜ao P (A) = P (B) − P (B − A) .

Demonstra¸c˜ao. Como B = A ˙∪ (B − A) , temos

P (B) = P (A ˙∪ (B − A)) = P (A) + P (B − A) .

Portanto, P (A) = P (B) − P (B − A) .

Corol´ario 1.1. Se A, B ∈ F com A ⊂ B ent˜ao P (A) ≤ P (B).

Demonstra¸c˜ao. Como P (A) = P (B) − P (B − A) e P (B − A) ≥ 0, ent˜ao P (A) ≤

P (B) .

Proposi¸c˜ao 1.6. P (A ∪ B) = P (A) + P (B) − P (A ∩ B) .

Demonstra¸c˜ao. Como P (A) = P (A − B)+P (A ∩ B) e P (B) = P (B − A)+P (A ∩ B) .

Temos,

P (A) + P (B) = P (A − B) + P (B − A) + P (A ∩ B) + P (A ∩ B) .

Observe que, A ∪ B = (A − B) ˙∪ (A ∩ B) ˙∪ (B − A) . Logo,

P (A ∪ B) = P (A − B) + P (A ∩ B) + P (B − A) .

Portanto, P (A ∪ B) = P (A) + P (B) − P (A ∩ B) .

Com o mesmo racioc´ınio usado para descrever e provar a proposi¸c˜ao acima pode-se

estabelecer uma f´ormula para P (A1 ∪ A2 ∪ An) onde A1, A2, . . .,An s˜ao n eventos, con-
forme enunciado abaixo:

Proposi¸c˜ao 1.7. Suponha Aj ∈ F, j = 1, . . . , n, temos que

P (A1 ∪ A2 ∪ · · · ∪ An) = P (A1) + P (A2) + · · ·

+ P (An) − P (A1 ∩ A2) − · · · − P (An−1 ∩ An) +
+ P (A1 ∩ A2 ∩ A3) + · · · + (−1)n−1 P (A1 ∩ A2 ∩ · · · ∩ An) .

As propriedades vistas acima nas proposi¸c˜oes s˜ao v´alidas para qualquer probabi-

lidade, ou seja, qualquer fun¸c˜ao de conjuntos satisfazendo as condi¸c˜oes da deﬁni¸c˜ao 1.5

atende `as proposi¸c˜oes 1.6 e 1.7. Note que, sobre o mesmo espa¸co amostral Ω ´e poss´ıvel

deﬁnir muitas probabilidades diferentes.

Um fenˆomeno aleat´orio ´e representado matematicamente por um trio de objetos:

o espa¸co amostral Ω, a fam´ılia de eventos da σ −´algebra F e uma probabilidade P deﬁnida

sobre os subconjuntos de Ω. O trio (Ω, F, P ) ´e chamdo de Espa¸co de Probabilidades.

Exemplo 1.5. Um n´umero entre 1 e 400 ´e escolhido aleatoriamente. Vamos calcular a

probabilidade de que ele seja divis´ıvel por 2 ou por 5.

Sejam A e B os eventos que acontecem se o n´umero escolhido for divis´ıvel por 2 e

por 5 respectivamente. Temos que calcular P (A ∪ B) . Os n´umeros entre 1 e 400 divis´ıveis

13

por 2 s˜ao 200, os divis´ıveis por 5 s˜ao 400/5 = 80 e os divis´ıveis por 2 e por 5 ao mesmo
tempo s˜ao 400/10 = 40. Assim, P (A) = 200
400 = 1
400 = 1
10.
Logo, P (A ∪ B) = P (A) + P (B) − P (A ∩ B) = 1

400 = 1
5, P (A ∩ B) = 40
10 = 6
10.

2, P (B) = 80
5 − 1
2 + 1

1.2.1 Probabilidades Condicionais

Em certas situa¸c˜oes ´e necess´ario compreender a rela¸c˜ao entre dois eventos. Uma

medida dessa rela¸c˜ao ´e probabilidade condicional, que corresponde a probabilidade da

ocorrencia de um evento A dado que ocorreu um evento B.

Deﬁni¸c˜ao 1.6. Dados dois eventos A e B, a probabilidade condicional de B dado A ´e

o n´umero P (A ∩ B) /P (A) onde P (A) > 0. Repesentaremos este n´umero pelo s´ımbolo

P (B | A) . A equa¸c˜ao tamb´em pode ser escrita como P (A ∩ B) = P (A) P (B | A) . Se

P (B) > 0, temos P (A ∩ B) = P (B) P (A | B) .

Elencamos abaixo algumas propriedades das probabilidades condicionais. Ver

[7, 12, 14].

Proposi¸c˜ao 1.8. Seja A ∈ F tal que P (A) > 0. Ent˜ao

a) P (∅ | A) = 0, P (Ω | A) = 1 e 0 ≤ P (B | A) ≤ 1, para qualquer que seja

B ∈ F;

b) P ((B ˙∪C) | A) = P (B | A) + P (C | A) .

Demonstra¸c˜ao. a) Segue da deﬁni¸c˜ao 1.6 que

P (∅ | A) =

P (∅ ∩ A)
P (A)

=

P (∅)
P (A)

=

0
P (A)

= 0

P (Ω | A) =

P (Ω ∩ A)
P (A)

=

P (A)
P (A)

= 1.

Como 0 ≤ P (A ∩ B) ≤ P (A) , temos 0 ≤ P (A∩B)
qualquer B ∈ F.

P (A) ≤ 1, isto ´e, 0 ≤ P (B | A) ≤ 1 para

b)Da deﬁni¸c˜ao 1.6 temos

P ((B ˙∪C) | A) =

=

P ((B ˙∪C) ∩ A)
P (A)
P (B ∩ A)
P (A)

+

P (C ∩ A)
P (A)

=

P ((B ∩ A) ˙∪ (C ∩ A))
P (A)

= P (B | A) + P (C | A) .

14

Como consequˆencia da proposic˜ao acima temos que, ﬁxado A ∈ F, a probabili-

dade condicional P (· | A) ´e outra probabilidade sobre o espa¸co amostral Ω.

Observe que para dois conjuntos A1 e A2 temos P (A1 ∩ A2) = P (A1) P (A2 | A1) .

Caso tenhamos A1, A2, A3, veriﬁcamos que:

P (A1 ∩ A2 ∩ A3) = P (A3 | (A1 ∩ A2)) P (A1 ∩ A2) = P (A3 | (A1 ∩ A2)) P (A2 | A1) P (A1) .

Usando o Princ´ıpio de Indu¸c˜ao Completa, temos a seguinte proposi¸c˜ao.

Proposi¸c˜ao 1.9. Sejam Aj ∈ F, j = 1, . . . , n. Se P (A1 ∩ A2 ∩ · · · ∩ An) (cid:54)= 0, ent˜ao

P (A1 ∩ A2 ∩ · · · ∩ An) =

= P (A1) P (A2 | A1) P (A3 | (A1 ∩ A2)) · · · P (An | (A1 ∩ A2 ∩ · · · ∩ An−1)) .

Exemplo 1.6. Sabe-se que 80% dos habitantes de Amargosa foram vacinados contra a

gripe. A probabilidade de uma vacina conseguir imunizar uma pessoa ´e de 40% se o

habitante for da regi˜ao rural e de 70% caso contr´ario. Ao realizar uma vacina¸c˜ao vamos

calcular a probabilidade da vacina imunizar uma pessoa, dado que o habitante ´e da zona

rural.

P ((cid:48)(cid:48)habitante de Amargosa (cid:48)(cid:48) e (cid:48)(cid:48) zona rural(cid:48)(cid:48)) = P (B ∩ C) .

Tal probabilidade ´e dada por

P (B ∩ C) = P (B) × P (C | B) = 0, 8 × 0, 4 = 0, 32.

Note que, nesta situa¸c˜ao precisamos saber a probabilidade de imuniza¸c˜ao da

vacina para uma pessoa da zona rural ou da zona urbana. Assim, podemos deﬁnir o evento

D como a uni˜ao de dois eventos disjuntos: “O habitante ´e da zona rural de Amargosa e

foi imunizado” e “ O habitante ´e da zona urbana de Amargosa e foi imunizado”.

Ent˜ao,

Logo,

onde

e

D = (E ∩ D) ∪ ( ¯E ∩ D).

P (D) = P (E ∩ D) + P ( ¯E ∩ D),

P (E ∩ D) = P (E) × P (D | E) = 0, 8 × 0, 4 = 0, 32

P ( ¯E ∩ D) = P ( ¯E) × P (D | ¯E) = 0, 2 × 0, 7 = 0, 14.

Logo, P (D) = 0, 32 + 0, 14 = 0, 46.

15

Podemos escrever a probabilidade de um evento atrav´es de probabilidades condi-

cionais como segue:

Proposi¸c˜ao 1.10 (Teorema da Probabilidade Total). Se B ´e um evento contido em uma
uni˜ao de eventos disjuntos A1, A2, . . . , An, ou seja, ∪n
i=1Ai = Ω e P (A1) > 0, P (A2) >
0, . . . , P (An) > 0 ent˜ao

P (B) = P (A1)P (B | A1) + P (A2)P (B | A2) + . . . + P (An)P (B | An).

Demonstra¸c˜ao. Como ∪n

i=1Ai = Ω, segue que B = (A1 ∩ B) ∪ (A2 ∩ B) ∪ · · · ∪ (An ∩ B),

onde (Ai ∩ Aj) = ∅, ∀i (cid:54)= j. Logo,

P (B) = P ((A1 ∩ B) ∪ (A2 ∩ B) ∪ · · · ∪ (An ∩ B))

= P (A1 ∩ B) + P (A2 ∩ B) + . . . + P (An ∩ B)

= P (A1)P (B | A1) + P (A2)P (B | A2) + . . . + P (An)P (B | An).

Deﬁni¸c˜ao 1.7. Seja A um conjunto n˜ao vazio. Uma parti¸c˜ao de um conjunto A ´e qualquer

cole¸c˜ao C de subconjuntos n˜ao vazios de A dotada da seguinte propriedade: todo elemento

de A pertence a um e apenas um dos elementos de C.

Assim, uma cole¸c˜ao de conjuntos C = {A1, A2, . . . , An} ´e uma parti¸c˜ao do con-

junto A, se as seguintes condi¸c˜oes forem simultaneamente satisfeitas:

1. Ai (cid:54)= ∅, para i = 1, 2, . . . , n;

2. Ai ⊂ A, para i = 1, 2, . . . , n;

3. A = A1 ˙∪A2 ˙∪ · · · ˙∪An;

4. A1, A2, . . . , An s˜ao mutuamente disjuntos, isto ´e, Ai ∩ Aj = ∅, para i (cid:54)= j, com

i, j = 1, 2, . . . , n.

Proposi¸c˜ao 1.11. Sejam A1, A2, . . . , An uma parti¸c˜ao do espa¸co amostral Ω e B e C
dois eventos quaisquer de Ω. Ent˜ao

P (B | C) =

n
(cid:88)

i=1

P (B | Ai ∩ C)P (Ai | C)

16

Demonstra¸c˜ao. Como A1, A2, . . . , An ´e uma parti¸c˜ao de Ω temos que Ai ∩ Aj = ∅, ∀i, j ∈
N.

P (B | C) = P (B ∩ ( ˙∪n

i=1Ai) | C) =

P (B ∩ ( ˙∪n

i=1Ai) ∩ C)

P (C)

=

P (( ˙∪n

i=1(B ∩ Ai)) ∩ C

P (C)

=

=

n
(cid:88)

i=1
n
(cid:88)

i=1

P (B ∩ Ai ∩ C)
P (C)

=

n
(cid:88)

i=1

P (B ∩ Ai ∩ C)
P (C)

·

P (Ai ∩ C)
P (Ai ∩ C)

P (B ∩ Ai ∩ C)
P (Ai ∩ C)

·

P (Ai ∩ C)
P (C)

=

n
(cid:88)

i=1

P (B | Ai ∩ C)P (Ai | C).

1.3 Vari´aveis Aleat´orias

Na observa¸c˜ao de um experimento aleat´orio podemos associar algumas quanti-

dades. Por exemplo, numa pesquisa sobre o perﬁl de determinada popula¸c˜ao (espa¸co

amostral) podemos indagar sobre a altura, idade ou peso de cada indiv´ıduo (amostra).

Podemos caracterizar cada uma destas quantidades por uma fun¸c˜ao

X : Ω → R.

Devido a natureza de um experimento aleat´orio, seus resultados n˜ao s˜ao deter-

minados, mas as suas probabilidades s˜ao. No estudo de quantidades associadas a esses
experimentos estamos interessados em analisar probabilidades do tipo P (X −1 (I)) onde

I ´e um intervalo da reta. Ou seja, analisaremos a probabilidade da fun¸c˜ao X atingir seus

valores no intervalo I.

Um experimento aleat´orio ´e totalmente caracterizado por seu espa¸co amostral

Ω, a fam´ılia de seus eventos (σ − ´algebra F) e uma probabilidade deﬁnida sobre os seus

intervalos. Nos referimos ao trio (Ω, F, P ) como um espa¸co de probabilidade. Uma
vari´avel aleat´oria ser´a ent˜ao uma fun¸c˜ao X : Ω → R, tal que possamos mensurar X −1 (I)
para todo intervalo I, ou seja, tal que X −1 (I) ∈ F, para todo intervalo I.

Deﬁni¸c˜ao 1.8. Seja (Ω, F, P ) um espa¸co de probabilidade. Denominamos de vari´avel
aleat´oria, qualquer fun¸c˜ao X : Ω → R tal que X −1 (I) = {w ∈ Ω : X (w) ∈ I} ∈ F,
para todo intervalo I ⊂ R. Ou seja, X ´e tal que sua imagem inversa de intervalos I ⊂ R
pertence a σ − ´algebra F.

Em geral representamos uma vari´avel aleat´oria por letra mai´uscula do alfabeto.

Para cada elemento w ∈ Ω, associamos um n´umero real X (w) . Garantimos o c´alculo de
probabilidades com vari´aveis aleat´orias ao exigir que para qualquer I ⊂ R, o conjunto

17

X −1 (I) seja um evento, ou seja, X −1 (I) ´e um elemento da σ − ´algebra F. Formalmente,

dizemos que a vari´avel aleat´oria ´e qualquer fun¸c˜ao real mensur´avel em F.

O espa¸co de probabilidade (Ω, F, P ) pode ser escrito simpliﬁcadamente (Ω, F) ,

quando n˜ao houver d´uvidas quanto a probabilidade considerada em F.

Para veriﬁcarmos que X : Ω → R ´e uma vari´avel aleat´oria basta veriﬁcar que
X −1(−∞, r] ∈ F para todo r. Isto se deve ao fato que qualquer intervalo I pode ser

gerado por intervalos da forma (−∞, r]. Veja o exemplo de [9, Cap´ıtulo 2].

Exemplo 1.7. Sejam Ω = {1, 2, 3, 4}, F = {∅, Ω, {1, 2} , {3, 4}} e considere os conjuntos

A = {1, 2} e B = {1, 3}. Vamos veriﬁcar que IA, onde IA ´e deﬁnido por

IA =




1,

se x ∈ A



0,

se x /∈ A

´e vari´avel aleat´oria em (Ω, F) , mas IB deﬁnida analogamente n˜ao ´e.
Como A ∈ F e B /∈ F, ent˜ao,

I −1
A (−∞, x] = {w ∈ Ω : IA (w) ∈ (−∞, x]} =





∅, se x < 0

Ac, se 0 ≤ x < 1

.

Ω, se ≥ 1

Portanto, a imagem inversa de IA para intervalos do tipo (−∞, x], x ∈ R e x ∈ F.
Por outro lado, para 0 ≤ x ≤ 1, temos IB(−∞, x] = {w ∈ Ω : IB (w) ∈ (−∞, x]} =

BC, que n˜ao est´a em F. Assim, IB n˜ao ´e vari´avel aleat´oria em (Ω, F).

Note que, podemos tornar IB uma vari´avel aletat´oria modiﬁcando a σ − ´algebra.
Assim, tomando σ − ´algebra suﬁcientemente “grande” podemos trabalhar com todas as

vari´aveis que nos interessem. O conjunto das partes ´e a maior σ − ´algebra poss´ıvel. Se
F = P (Ω) , ent˜ao qualquer fun¸c˜ao X : Ω → R ´e uma vari´avel aleat´oria.

Denotamos, X −1(I) = {w ∈ Ω : X (w) ∈ I} = [X ∈ I] . Por exemplo, para
I = (−∞, 0) , escreveremos [X < 0] para denotar X −1 (I) . Podemos simpliﬁcar a nota¸c˜ao

da probabilidade destes eventos por P (X ∈ I) .

No entanto, ao caracterizarmos uma vari´avel aleat´oria precisamos determinar a

distribui¸c˜ao de suas probabilidades.

Deﬁni¸c˜ao 1.9 (Fun¸c˜ao de Distribui¸c˜ao). Seja X uma vari´avel aleat´oria em (Ω, F, P ) ,

sua fun¸c˜ao de distribui¸c˜ao ´e deﬁnida por FX (x) = P (X ∈ (−∞, x]) = P (X ≤ x) , com
x percorrendo todos os n´umeros reais.

A fun¸c˜ao tamb´em ´e chamada fun¸c˜ao de distribui¸c˜ao acumulada, por acumular as

probabilidades dos valores inferiores ou iguais a x. Ao se referir a fun¸c˜ao de distribui¸c˜ao

o subescrito X pode ser omitido e escreveremos F ao inv´es de FX.

18

Proposi¸c˜ao 1.12 (Propriedades da Fun¸c˜ao de Distribui¸c˜ao). Uma fun¸c˜ao de dis-

tribui¸c˜ao de uma vari´avel aleat´oria X em (Ω, F, P ) obedece `as seguintes propriedades:

(F 1) limx→−∞ F (x) = 0 e limx→∞ F (x) = 1;

(F 2) F ´e n˜ao decrescente, ou seja, F (x) ≤ F (y) sempre que x ≤ y, ∀x, y ∈ R.

No item 1.3 limx→−∞ F (x) representa o comportamento da fun¸c˜ao F quando x toma
valores cada vez menores, ou seja, se a imagem F (x) se aproxima de algum valor quando

tomamos x cada vez menor. Analogamente, limx→+∞ F (x) representa o comportamento
da fun¸c˜ao F quando x toma valores cada vez maiores. A propriedade 1.3 diz ent˜ao

que P (X ≤ x) se aproxima de zero conforme o x descresce e P (X ≤ x) se aproxima

de 1 conforme o x cresce. A propriedade 1.3 ´e consequˆencia imediata da deﬁni¸c˜ao de

uma probabilidade (Deﬁni¸c˜ao 1.5e do Corol´ario 1.1), uma vez que {ω ∈ Ω|X (ω) ≤ x} ⊂

{ω ∈ Ω | X (ω) ≤ y}, se x ≤ y.

Destacamos que, se desejarmos saber a vari´avel, estamos na verdade querendo

descobrir qual ´e a fun¸c˜ao de distribui¸c˜ao. Essa caracteriza¸c˜ao ´e ´unica a menos de eventuais

conjuntos que tenham probabilidade zero. Veremos que existem fun¸c˜oes, relacionadas com

a fun¸c˜ao de distribui¸c˜ao, que tamb´em caracterizam unicamente uma vari´avel.

Exemplo 1.8. Para o lan¸camento de uma moeda, seja Ω = {cara, coroa} , F o conjunto

das partes de Ω e P dada por P (cara) = P (coroa) = 1/2. Deﬁnimos uma fun¸c˜ao X de Ω
em R da seguinte forma:




1,

X(w) =

se w = cara

.



0,

se w = coroa

Para qualquer conjunto I ⊂ R, X −1 (I) ∈F e, portanto, X ´e vari´avel aleat´oria.
Agora, se I = (−∞, 0) temos X −1 (I) = ∅; Entretanto, para I = (0, 2] temos
X −1 (I) = {cara}. Nos dois casos a imagem inversa pertence a F. Para obter a fun¸c˜ao de

distribui¸c˜ao analisamos os casos: Para x < 0, P (X ≤ x) = 0, uma vez que o menor valor
assumido pela var´avel ´e 0. No intervalo 0 ≤ x < 1, temos P (X ≤ x) = P (X = 0) = 1
2.
quando x ≥ 1, ganhamos P (X ≤ x) = P (X = 0) + P (X = 1) = 1. Assim, F (x) =

P (X ≤ x) foi deﬁnida para qualquer valor real. Resumidamente, temos:

F (x) =





0,

se x < 0

1/2,

se 0 ≤ x < 1

.

1,

se x ≥ 1

19

Figura 1.3.1: Gr´aﬁco de F (x).

Deﬁni¸c˜ao 1.10 (Vari´avel Aleat´oria Discreta e Fun¸c˜ao de Probabilidade). Uma

vari´avel aleat´oria ´e classiﬁcada como discreta, se assume somente um n´umero enumer´avel

de valores (ﬁnito ou inﬁnito). A fun¸c˜ao de probabilidade de uma vari´avel discreta ´e uma

fun¸c˜ao que atribue probabilidade a cada um dos poss´ıveis valores assumidos pela vari´avel,

ou seja, sendo X uma vari´avel com valores x1, x2, . . . , temos para i = 1, 2, . . .

p(xi) = P (X = xi) = P ({w ∈ Ω : X(w) = xi})

Proposi¸c˜ao 1.13. Se X ´e uma vari´avel aleat´oria ent˜ao a sua fun¸c˜ao de probabilidade de

X em (Ω, F, P ) satisfaz:

(FP1) 0 ≤ p (xi) ≤ 1, ∀i = 1, 2, . . . ;
(FP2)(cid:80)

p(xi) = 1.

i

com a soma percorrendo todos os poss´ıveis valores (eventualmente inﬁnitos).

Demonstra¸c˜ao. Por serem probabilidades, os valores da fun¸c˜ao de probabilidade est˜ao

sempre entre 0 e 1. Al´em disso, cada valor da vari´avel induz um subconjunto disjunto,

cuja uni˜ao ´e Ω, o que implica 1.13.

Para as vari´aveis discretas, a fun¸c˜ao de distribui¸c˜ao tem a forma de escada sendo

descont´ınua nos valores assumidos pela vari´avel. Da fun¸c˜ao de probabilidade obtemos a

fun¸c˜ao de distribui¸c˜ao e vice-versa. Se j´a sabemos a fun¸c˜ao de probabilidade obtemos,
∀x ∈ R, F (x) = (cid:80)
p(xi),com Ai = {i : xi ≤ x} ; onde a somat´oria se estende aos
´ındices para os quais xi ≤ x. Por outro lado, dada a fun¸c˜ao de distribui¸c˜ao temos
p(xi) = F (xi) − F (x−
i ) ´e o limite de F tendendo a xi pela esquerda (isto
´e, por valores anteriores `a xi).

i ), em que F (x−

i∈Ai

Exemplo 1.9. Considere dois lan¸camentos independentes de uma moeda equilibrada.

Com o espa¸co de probabilidade sendo o usual, deﬁna X como sendo o n´umero de coroas

nos dois lan¸camentos. A vari´avel X ser´a discreta e sua fun¸c˜ao de probabilidade ser´a dada

por:

20

X

p(xi)

0

1
4

1

1
2

2

1
4

Tabela 1.1: Probabilidades da v.a. X.

Desta forma, a fun¸c˜ao de distribui¸c˜ao ser´a:

F (x) =






0,

1/4,

3/4,

1,

se x < 0;

se 0 ≤ x < 1;

se 1 ≤ x < 2;

se x ≥ 2.

O gr´aﬁco de F (x) ´e em escada como apresentado abaixo. Note que, os pontos de des-

continuidade ocorrem nos valores assumidos pela vari´avel, sendo o tamanho do salto a

probabilidade da vari´avel assumir aquele determinado valor.

Figura 1.3.2: Fun¸c˜ao de distribui¸c˜ao para o n´umero de coroas.

1.4 Alguns Modelos Discretos

Como visto a fun¸c˜ao de distribui¸c˜ao caracteriza completamente uma vari´avel

aleat´oria. Apresentaremos a seguir algumas fun¸c˜oes de probabilidade que descrevem
vari´avel aleat´oria espec´ıﬁcas. ´E importante ressaltar que existem v´arios modelos. No
entato, traremos alguns modelos discretos, os quais podem a vir ser utilizados posterior-

mente e cujos exemplos foram discutidos na obra [5].

21

Deﬁni¸c˜ao 1.11 (Modelo Uniforme Discreto). Uma vari´avel ´e caracterizada pelo mo-

delo Uniforme Discreto, com valores x1, x2, . . . , xk, se tem fun¸c˜ao de probabilidade dada
por: p(xi) = 1/k, para i = 1, 2, . . . , k. Usamos a nota¸c˜ao X ∼ Ud[E], com E sendo o
conjunto de seus valores e no caso em que (cid:93)E < ∞.

Neste modelo temos situa¸c˜oes onde os poss´ıveis valores da vari´avel s˜ao equi-

prov´aveis, n˜ao existindo restri¸c˜ao aos valores da vari´avel, podendo ser qualquer n´umero

real. No entanto, o n´umero de valores diferentes precisa ser ﬁnito. Ou seja, (cid:93)E < ∞.

A fun¸c˜ao de distribui¸c˜ao de uma vari´avel Uniforme Discreta ´e uma fun¸c˜ao escada e os

pontos de descontinuidade s˜ao os valores assumidos pela vari´avel.

Exemplo 1.10. Em uma urna existem bolas numeradas de 1 at´e 6. Ao escolher uma

determinada bola observamos o n´umero que ocorreu.

Sendo X essa vari´avel, ´e f´acil veriﬁcar que X ∼ Ud[E], com E = {1, 2, 3, 4, 5, 6} .

Sua fun¸c˜ao de probabilidade ´e p(x) = 1/6 para x = 1, 2, . . . , 6.

Figura 1.4.1: Fun¸c˜ao de distribui¸c˜ao da Uniforme Discreta em {1, 2, . . . , 6} .

Deﬁni¸c˜ao 1.12 (Modelo Bernoulli). Uma vari´avel aleat´oria segue o modelo Bernoulli,

se assume apenas os valores 0 e 1. Sua fun¸c˜ao de probabilidade ´e dada por:

p(1) = P (X = 1) = p

p(0) = P (X = 0) = 1 − p

A nota¸c˜ao que ser´a utilizada ser´a X ∼ Bernoulli(p).
Nesta probabilidade, p ´e denominada de parˆametro do modelo. ´E de praxe con-
siderar sucesso a ocorrˆencia de 1 e fracasso a ocorrˆencia de 0. Assim, denominamos por

ensaio de Bernoulli, o experiemento que tem resposta dicotˆomica do tipo sucesso-fracasso.

Uma boa exempliﬁca¸c˜ao ´e o tiro ao alvo. Deﬁnindo sucesso como o acerto do

alvo e fracasso como o erro do alvo, temos:

22




1,

X =

se acertou;



0,

se errou.

Ent˜ao, X ∼ Bernoulli (p), com p = P (acerto). Logo, p = 1
2.

A repeti¸c˜ao de sucessivos ensaios de Bernoulli serve de estudo para v´arios proble-

mas. A partir de uma sequˆencia de n ensaios de Bernoulli independentes, outros modelos

podem ser contru´ıdos.

Deﬁni¸c˜ao 1.13 (Modelo Binomial). Seja X o modelo total de sucesso obtidos na

observa¸c˜ao de n ensaios de Bernoulli independentes. X segue o modelo Binomial com

parˆametros n e p e sua fun¸c˜ao de probabilidade ´e dada por:

p(x) =

(cid:19)

(cid:18)n
x

px(1 − p)n−x, x = 0, 1, . . . , n.

A nota¸c˜ao ser´a X ∼ B(n, p).

Exemplo 1.11. A taxa de imuniza¸c˜ao de uma vacina ´e 70%. Se um grupo de 20 pessoas

foram vacinadas, desejamos saber o comportamento probabil´ıstico do n´umero de pessoas

imunizadas desse grupo.

Seja Xa vari´avel de interesse. Para cada pessoa do grupo, a probabilidade de estar

imunizada ´e 0, 7 e admitimos, ainda, independˆencia entre os resultados das v´arias pessoas

vacinadas. Assim, teremos X ∼ B (n = 20, p = 0, 7) . Por exemplo, a probabilidade de 10

estarem imunizados ´e dada por:
P (X = 10) = p(10) = (cid:0)20

10

(cid:1)0, 7100, 320−10 = 0, 0308.

Deﬁni¸c˜ao 1.14 (Modelo Geom´etrico). Considere uma sequˆencia de ensaios de Ber-

noulli independentes. Sendo X o n´umero de fracassos anteriores ao primeiro sucesso, ou

simplesmente, o tempo de espera para o primeiro sucesso. A vari´avel Xsegue o modelo

Geom´etrico com parˆamentro p, 0 < p < 1, e tem fun¸c˜ao de probabilidade dada por:

p(x) = p(1 − p)x, x = 0, 1, . . . .

A nota¸c˜ao ser´a X ∼ Geo(p).

A restri¸c˜ao dos valores de p para aqueles estritamente entre 0 e 1 evita os casos

imediatos mas, cuidadosamente, os extremos 0 e 1 poderiam ser considerados. O modelo

Geom´etrico tamb´em pode ser deﬁnido como o n´umero de fracassos at´e o primeiro sucesso,

ou simplesmente, como o n´umero de ensaios at´e o primeiro sucesso. Neste caso, a fun¸c˜ao

de probabilidade sofre modiﬁca¸c˜ao, pois a vari´avel inicia seus valores em 1 ao inv´es 0.

23

Exemplo 1.12. Uma linha de fabrica¸c˜ao de um equipamento de precis˜ao ´e interrompida

na primeira ocorrˆencia de um defeito. A partir da manuten¸c˜ao, o equipamento tem

probabilidade de 0, 01 de apresentar defeito em um dia qualquer. Deseja-se planejar o

cronograma de manuten¸c˜ao preventiva e, para tal, decidiu-se avaliar probabilisticamente

a espera at´e a produ¸c˜ao ser interrompida. Seja X a vari´avel aleat´oria que conta o n´umero

de dias que antecedem a interrup¸c˜ao. Admitindo que o desemprenho, nos sucessivos

dias, sejam independentes, temos que X ∼ Geo(p = 0, 01). Dessa forma, P (X = x) =
0, 01 × 0, 99x, x = 0, 1, . . . .

Por exemplo, para uma interrup¸c˜ao no sexto dia temos P (X = 5) = 0, 01 ×

0, 995 = 0, 0095.

Qual seria o intervalo ideal para uma manuten¸c˜ao preventiva, se desejamos uma

probabilidade de, pelo menos, 0, 90 de que o defeito n˜ao ocorrer´a? A pergunta estar´a res-

pondida, se determinamos quantos dias s˜ao necess´arios para acumular uma probabilidade
de defeito pr´oxima de 0, 10. Ou ainda, obter k tal que P (X ≤ k) = 1 − 0, 99k+1 (cid:39) 0, 10.

Com o aux´ılio de uma planilha calculadora, obtemos P (X ≤ 9) = 0, 0956 e P (X ≤ 10) =

0, 1047. Para atender o requisito desejado, a manuten¸c˜ao preventiva dever´a ser feita ap´os

9 dias de opera¸c˜ao. Assim, teremos probabilidade de 0, 9044 de um defeito n˜ao ocorrer

entre essas manuten¸c˜oes.

Cap´ıtulo 2

Cadeias de Markov

Nesta parte do trabalho, abordaremos os conceitos b´asicos da teoria das Cadeias

de Markov e seus exemplos retirados da obra [5] os quais ser˜ao utilizados nas aplica¸c˜oes

que vir˜ao em sequˆencia. Al´em disso, com este aporte te´orico ser´a poss´ıvel sugerir tamb´em

uma sequˆencia did´atica. Caso o leitor se interesse em um maior aprofundamento da teoria,

sugerimos al´em de [5], as referˆencias [2, 10, 13, 15].

2.1 Exemplos de Processos Estoc´asticos

Fenˆomenos aleat´orios que evoluem ao longo do tempo s˜ao modelados por proces-

sos estoc´asticos. Devido a natureza randˆomica destes fenˆomenos essas mudan¸cas n˜ao s˜ao

totalmente previs´ıveis. O estudo da sua evolu¸c˜ao se dar´a atrav´es de suas distribui¸c˜oes de

probabilidade. Diversos fenˆomenos reais permitem a modelagem atrav´es de um processo

estoc´astico. Observe alguns exemplos da obra de [5].

Exemplo 2.1. Os parafusos de uma cadeia de montagem ap´os uma supervis˜ao `a que

s˜ao submetidos, podem ser considerados defeituosos ou n˜ao. Se o n-´esimo parafuso n˜ao

tiver defeito, atribu´ımos valor 1 a esse parafuso. Caso o n-´esimo parafuso seja defeituoso

atribu´ımos o valor 0 a esse parafuso. Podemos deﬁnir uma vari´avel aleat´oria que represente

este fenˆomeno, digamos Xn, com espa¸cos de estados {0, 1} , que representa a imperfei¸c˜ao
ou n˜ao do n-´esimo parafuso. Temos assim uma fam´ılia de vari´aveis aleat´orias {Xn}n∈N
em que cada um delas corresponde a imperfei¸c˜ao do n-´esimo parafuso.

N˜ao temos como determinar o estado do n-´esimo parafuso. Questionamos ent˜ao

acerca da probabilidade do parafuso ser defeituoso ou n˜ao, isto ´e, P (Xn = 0) e P (Xn = 1) .
Como um processo evolutivo, tais probabilidades podem depender ou n˜ao do estado dos

n − 1 parafusos anteriores. Suponha, por exemplo que um parafuso ´e defeituoso indepen-
dente dos outros j´a produzidos e que a probabilidade seja p. Neste caso {Xn}n∈N ´e uma

24

25

f´ormula de vari´aveis aleat´orias independentes de Bernoulli com parˆametro p de sucesso,

conforme 1.12.

Exemplo 2.2. Uma pequena loja de equipamentos eletrˆonicos vende um tipo de mi-

crosystem. No entanto, ela s´o pode ter em estoque no m´aximo sete unidades. Ent˜ao,

se no ﬁnal do dia a loja tem no estoque somente uma unidade ou nenhuma, o gerente

manda buscar o restante das unidades necess´arias para ter sete unidades na loja no dia

seguinte antes de come¸car o expediente de atendimento. Desta forma, podemos ter as

seguintes quantidades no ﬁnal do n-´esimo dia {0, 1, 2, 3, 4, 5, 6, 7}. Podemos deﬁnir uma

vari´avel aleat´oria que represente este fenˆomeno, digamos Xn, que ´e justamente `a quanti-
dade de unidades na loja no ﬁnal do n-´esimo dia. Elas podem ser consideradas vari´aveis

aleat´orias, pois ´e f´acil supor que n˜ao tem como prever a quantidade de microsystems que

ser˜ao comprados cada dia.

Exemplo 2.3. Considere a hist´oria de v´arias gera¸c˜oes de uma fam´ılia que ao longo do

tempo tem somente um ﬁlho. Neste modelo, observe que a classe social (alta, m´edia ou

baixa) da fam´ılia para cada gera¸c˜ao permite descrever sua evolu¸c˜ao social ao longo do

tempo.

Neste caso, uma sociedade composta por fam´ılias deste tipo, podemos escolher

ao acaso uma fam´ılia e para cada gera¸c˜ao Xn uma quantidade que valer´a 1 se a fam´ılia
´e de classe alta, 2 se a fam´ılia ´e de classe m´edia e 3 se a fam´ılia ´e de classe baixa. Desta

forma, cada Xn ser´a uma vari´avel aleat´oria e sua evolu¸c˜ao ao longo do tempo, permitiria
concluir sobre as mudan¸cas na estrutura da sociedade.

Exemplo 2.4. Suponhamos que uma empresa de seguros na pra¸ca receba c unidades

monet´arias (u.m.) pelo total dos prˆemios que ela cobra dos aﬁliados dentro de um deter-

minado tempo (mˆes, semestre, ano). Sabe-se tamb´em que a seguradora coleta os prˆemios

regularmente e que as ideniza¸c˜oes s˜ao pagas quando os sinistros ocorrem. Al´em disso,

as despesas administrativas ser˜ao desconsideradas, ou seja, ganhos ou perdas por inves-

timentos, etc. Desta forma, a reserva da empresa de seguros ser´a afetada somente pela

cobran¸ca dos prˆemios ou por pagamentos dos idenizados na corrˆencia dos sinistros. As-

sim, o lucro da empresa no n-´esimo per´ıodo ser´a c − Zn u.m. sendo Zn o valor total das
ideniza¸c˜oes pago pela empresa nesse per´ıodo. Se chamar de Ln ao lucro da seguradora
desde que ela come¸ca a operar at´e o ﬁnal do n-´esimo per´ıodo, teremos

Ln = cn −

n
(cid:88)

j=1

Zj .

Deﬁni¸c˜ao 2.1. Um processo estoc´astico ´e uma fam´ılia de vari´aveis aleat´orias {Xt}t∈T .
Chamamos T o espa¸co de parˆametros.

26

Em geral t ´e utilizado como tempo, mas poderia indicar outros parˆametros como

uma ´area ou medida de massa, conforme 2.1. Nos exemplos 2.1, 2.2, 2.3 e 2.4 temos que
T = N. No caso em que T ´e enumer´avel dizemos que o processo estoc´astico correspondente
´e a tempo discreto. Se T for um intervalo, o processo estoc´astico ser´a chamado a tempo

cont´ınuo. Note que, os exemplos 2.1, 2.2, 2.3 e 2.4 s˜ao todos discretos.

Estados ser˜ao os valores que tomam as vari´aveis do processo e o conjunto destes

estados chamamos de espa¸co de estados, que denotamos por E. Podemos classiﬁcar o

espa¸co de estados como discreto ou cont´ınuo, caso E seja enumer´avel ou n˜ao. No

exemplo 2.1 temos que E = {0, 1} , no exemplo 2.2 E = {0, 1, 2, 3, 4, 5, 6, 7} , no exemplo
2.3 E = {1, 2, 3} e no exemplo 2.4 temos que E = R. Logo, nos exemplos 2.1, 2.2 e 2.3
temos espa¸cos de estados discretos, enquanto que no exemplo 2.4 temos o espa¸co de

estados cont´ınuos.

E enumer´avel

E n˜ao enumer´avel

T enumer´avel

Processo a tempo discreto com Processo a tempo discreto com

espa¸co de estados discreto

espa¸co de estados cont´ınuo

T n˜ao enumer´avel

Processo a tempo continuo com Processo a tempo cont´ınuo com

espa¸co de estados discreto

espa¸co de estados cont´ınuo

Tabela 2.1: Classiﬁca¸c˜ao dos processos estoc´asticos.

Uma trajet´oria de um processo estoc´astico {Xt}t∈T ´e uma cole¸c˜ao de valores
no espa¸co de estados de cada vari´avel aleat´oria Xt, ou seja, {xt : t ∈ T } . No exemplo 2.1
poder´ıamos ter a seguinte trajet´oria {1, 0, 0, 0, 0, 0, 0, ...} . Ou seja, um primeiro parafuso

sem defeito e o restante com defeito.

Pode-se entender os processos estoc´asticos como generaliza¸c˜oes de vari´aveis e

vetores aleat´orios. Um vetor aleat´orio ´e justamente um vetor em que suas componentes
s˜ao vari´aveis aleat´orias. Se o processo estoc´astico {Xt}t∈T ´e tal que a cardinalidade
do espa¸co de parˆametros T ´e ﬁnita, ent˜ao o processo ser´a um vetor aleat´orio. Caso

T = {1, 2} , pode representar pelo vetor aleat´orio (X1, X2) . Caso T tenha apenas um
elemento, ent˜ao temos somente uma vari´avel aleat´oria.

O comportamento probabil´ıstico de vari´aveis aleat´orias ´e descrito atrav´es da

fun¸c˜ao de distribui¸c˜ao. No caso de vetores aleat´orios usa-se a fun¸c˜ao de distribui¸c˜ao con-

junta. A distribui¸c˜ao conjunta ´e uma fun¸c˜ao P : A → [0, 1] tal que A = {(x, y) | x, y ∈ E} ,

satisfazendo as seguintes condi¸c˜oes:

1. 0 ≤ P (x, y) ≤ 1;

2. (cid:80)

x

(cid:80)

y P (x, y) = 1.

27

A partir de agora, um processo estoc´astico {Xt}t∈T ser´a denotado apenas por X, para
simpliﬁcar a nota¸c˜ao.

Ao analisar os estados de um processo X pode-se encontrar rela¸c˜oes de de-

pendˆencia. Utilizaremos a interpreta¸c˜ao do espa¸co de parˆametros T como tempo.

A rela¸c˜ao de dependˆencia entre vari´aveis mais simples seria a ausˆencia total dela.

Chamamos de processo de estados independentes `aquele processo estoc´astico cujos

estados constituem uma fam´ılia de vari´aveis aleat´orias independentes, ou seja, para as

variaveis aleat´orias X e Y temos que P (X = xi, Y = yi) = P (X = xi) · P (Y = yi),com
i ∈ N.

Um processo estoc´astico X ´e dito um processo de Markov, ou Markoviano,

se para todo a, b, a1, . . . , an ∈ E, vale:

P [a ≤ Xt ≤ b | Xt1 = a1, Xt2 = a2, . . . , Xtn = an] = P [a ≤ Xt ≤ b | Xtn = an],

(2.1.1)

quaisquer que sejam os instantes t1, t2, t3, . . . , tn, t ∈ T, com t1 < t2 < · · · < t.
Ou seja, o estado Xt do processo depende da sua hist´oria anterior nos instantes
t1, t2, . . . , tn somente atrav´es do presente Xtne n˜ao do passado Xt1, Xt2, . . . , Xtn−1. Os
processo de estados independentes s˜ao exemplos muito simples de processos de Markov.

2.2 Cadeias de Markov a Tempo Discreto

Estamos interessados em processos estoc´asticos que admitam uma representa¸c˜ao

matricial. Veremos que se o espa¸co de estados ´e discreto podemos representar o processo

estoc´astico, pela matriz de suas probabilidades. Ademais, se o processo ´e Markoviano,

podemos estudar a sua evolu¸c˜ao atrav´es do produto destas matrizes. Vejamos o seguinte

exemplo.

Exemplo 2.5. Considere um jogo no qual em cada aposta vocˆe perde um real com

probabilidade 0, 6 ou ganha um real com probabilidade 0, 4. Suponha que vocˆe deseja

parar de jogar se a sua fortuna atingir N reais e se ela atingir 0 reais o cassino n˜ao deixa

vcˆe jogar mais.

Seja Xn a quantidade de dinheiro que vocˆe tem depois de n apostas. Note que,
esta quantidade e o resultado do pr´oximo sorteio v˜ao determinar a sua fortuna depois

da aposta seguinte. Qualquer que tenha sido a evolu¸c˜ao da sua fortuna no “passado”(ou
seja, os valores Xn−1, Xn−2, . . . , X0), n˜ao intefere na previs˜ao do pr´oximo estado Xn+1. ´E
suﬁciente conhecer a sua fortuna no “presente” (Xn) . De fato, se Xn = i, com 0 < i < N,
ent˜ao independente dos valores i0, . . . , in−1,teremos que:

28

P (Xn+1 = i + 1 | Xn = i, Xn−1 = in−1, . . . , Xo = io) = 0, 4.

Desta forma, se vocˆe ganhar a aposta n + 1, a sua fortuna vai ser acrescentada

em um real e portanto ´e suﬁciente conhecer o valor de sua fortuna no presente.

Ao decorrer das apostas sua fortuna ir´a aumentar ou diminuir em um real com

uma chance que n˜ao depende do n´umero de apostas que vocˆe fez. Portanto, esta pro-

babilidade condicional n˜ao depende de n. Fixe o valor de N = 5. Ent˜ao os valores que

pode ser a sua fortuna s˜ao {0, 1, 2, 3, 4, 5} . Suponha que depois de certa quantidade de

apostas, vocˆe tem R$2, 00. Note que, pode acontecer de vocˆe possuir R$1, 00 ou R$3, 00,

na pr´oxima aposta, dependendo de sua sorte. Logo, ´e poss´ıvel arranjar as apostas atrav´es

de um vetor linha da forma (0; 0, 6; 0; 0, 4; 0) . E quando fazemos o somat´orio da probabi-

lidade sempre teremos o resultado igual a 1, pois estamos considerando todos os valores

poss´ıveis da sua fortuna, ou seja, o vetor ´e justamente uma distribui¸c˜ao de probabilidade.

Fazendo isso para cada valor poss´ıvel da sua fortuna conseguimos uma matriz, onde cada

linha corresponde a um vetor de probabilidades:



1

0, 6













0

0

0

0

0

0

0

0, 4

0

0

0, 6

0

0, 4

0

0

0

0

0

0

0, 6

0

0, 4

0

0

0, 6

0

0

0















.

0

0

0

0

1

0, 4

Deﬁni¸c˜ao 2.2. Uma cadeia de Markov a tempo discreto ´e um processo estoc´astico dis-
creto {Xn}n∈T , com o espa¸co de estados E ﬁnito ou enumer´avel e que possui a propriedade
de Markov:

P (Xn+1 = j | X0 = i0, . . . , Xn = in) = P (Xn+1 = j | Xn = in),

para todos os estados i0, . . . , in, j e todo instante n.

Observe que a propriedade de Markov 2.2 ´e caso particular da propriedade apre-

sentada em 2.1.1. Uma cadeia de Markov a tempo discreto ´e um proesso de Markov

discreto com espa¸co de estados ﬁnito.

Na deﬁni¸c˜ao 2.2, o estado futuro do processo, Xn+1 = j, n˜ao depende do passado,
X0 = io, . . . , Xn−1 = in−1, e s´o depende do presente, Xn = in. A probabilidade condicional
P (Xn+1 = j | Xn = in) ´e chamada de probabilidade de transi¸c˜ao(in para j no tempo
n para n + 1).

29

No nosso trabalho nos restringimos a cadeias de Markov homogˆeneas, cujas

probabilidades de transi¸c˜ao independem de n, ou seja,

P (Xn−1 = j | Xn = i) = · · · = P (X1 = j | X0 = i) = Pi,j, ∀i, j ∈ E.

Ademais, pediremos que (cid:93)E < ∞.

Assim, Pi,j ´e a probabilidade de passar, em qualquer instante, do estado i ao

estado j.

A matriz de transi¸c˜ao ´e justamente o arranjo das probabilidades de transi¸c˜ao Pi,j

numa matriz P. Se E ´e ﬁnito, por exemplo E = {0, 1, 2, . . . , N } , ent˜ao:

P =










P0,0 P0,1
P1,0 P1,1
...
...
PN,0 PN,2










.

· · · P0,N
· · · P1,N
...
. . .
· · · PN,N

No exemplo 2.5, temos que:

Pi,i+1 = 0.4, Pi,i−1 = 0, 6, se 0 < i < N, P0,0 = 1 = PN,N , Pij = 0, caso contr´ario.

Caso E seja inﬁnito, por exemplo E = N, temos inﬁnitas probabilidades de

transi¸c˜ao, que poder´ıamos arranjar em uma matriz inﬁnita P descrita abaixo.

P =










P0,0 P0,1 P0,2
P1,0 P1,1 P1,2
P2,0 P2,1 P2,2
...
...
...










· · ·

· · ·

· · ·
. . .

.

Podemos descrever estas transi¸c˜oes atrav´es da seguinte interpreta¸c˜ao geom´etrica:

Figura 2.2.1: Grafo chamado de Topologia da Cadeia.

30

Contudo, ferramentas e conceitos mais complexos ser˜ao requeridos para o estudo

deste tipo de processo. Por isso, nos concentramos em cadeias de Markov homogˆeneas

com espa¸co de estados ﬁnito.

Exemplo 2.6 (Cadeias de Ehrenfest). Suponhamos que o total de bolas contidas em

duas urnas ´e N. A cada instante de tempo n, pegamos uma bola da primeira urna e

colocamos na segunda urna. Deﬁnimos Xn como a quantidade de bolas na primeira urna.
Ent˜ao Xn ´e uma cadeia de Markov com espa¸co de estados E = {0, 1, . . . , N } . Podemos
calcular as probabilidades de transi¸c˜ao.

Note que, se em algum instante n˜ao tivermos bolas da primeira urna ent˜ao ne-

cessariamente no instante seguinte teremos que passar uma bola da segunda urna para

a primeira. Desta forma, P0,1 = 1. Analogamente, PN,N −1 = 1. Se 1 < i < N, ent˜ao
Pi,i−1 = i/N e Pi,i+1 = (N − i)/N.

Para N = 3, temos a seguinte matriz de transi¸c˜ao

P =









0 1 0 0
1
3 0 2
3 0
0 2
3 0 1
3
0 0 1 0









.

Portanto, uma cadeia de Markov homogˆenea discreta corresponde a uma matriz

de transi¸c˜ao. A seguir iremos abordar as principais caracter´ısitcas destas matrizes:

Deﬁni¸c˜ao 2.3. Uma matriz P = [Pi,j]i,j∈E ´e uma matriz estoc´astica se:

i) Pi,j ≥ 0, para todo i, j ∈ E;
ii) P ara todo i ∈ E, (cid:80)
Note que, toda matriz de transi¸c˜ao ´e uma matriz estoc´astica. Pois, atrav´es dos

j∈E Pi,j = 1.

exemplos colocados anteriormente e do que foi citado acima temos que todas as entradas

de uma matriz estoc´astica s˜ao n˜ao negativas e qualquer linha tem soma igual a 1.

Exemplo 2.7. Uma cadeia de Markov com espa¸co de estado E = {0, 1, . . . , d} e com

probabilidade de transi¸c˜ao

Pi,j =





qi,

ri,

pi,

se j = i − 1

se j = i

se j = i + 1

onde pi + ri + qi = 1 e q0 = 0 e pd = 0 se d < ∞, ´e chamado de Processo de

Nascimento e Morte.

Para exempliﬁcar melhor temos a seguinte situa¸c˜ao. Em um hospital, foi feito

um levantamento junto aos pacientes para prever o poss´ıvel aumento, diminui¸c˜ao ou

31

estagna¸c˜ao da verba para oferecer um melhor tratamento de sa´ude. No caso, os pacientes

foram classiﬁcados da seguinte forma: (0) para o paciente que venha a ´obito, (1) para o

paciente curado e (2) para o paciente doente. Desta forma, um paciente que esteja curado

(1) pode permanecer curado (1), adoecer (2) ou vim a ´obito (0). J´a um paciente que esteja

doente (2), ele pode continuar doente (2), ser curado (1) ou ent˜ao vim a ´obito (0). J´a o

paciente que venha a ´obito (0), ele dever´a permanecer nesta situa¸c˜ao. Assim, podemos

construir a matriz de transi¸c˜ao que ´e dada abaixo.

P =







P0,0 P0,1 P0,2
P1,0 P1,1 P1,2
P2,0 P2,1 P2,2







.

2.3 Matrizes de Transi¸c˜ao de Ordem Superior

No in´ıcio deste cap´ıtulo, vimos no exemplo 2.3 que {Xn} ´e um processo es-
toc´astico. Assumindo que o processo Xn ´e uma cadeia de Markov, consideremos a seguinte
matriz de transi¸c˜ao







0.7 0.2 0.1

0.3 0.5 0.2

.

0.2 0.4 0.4







Desta forma, a matriz indica que a probabilidade de que os ﬁlhos de uma fam´ılia

de classe baixa (1) permane¸ca nessa classe ´e 0, 7.

Suponhamos que a fam´ılia come¸ca na classe m´edia (2) na gera¸c˜ao 0. Qual a

probabilidade que a gera¸c˜ao 1 ascenda `a classe alta (3) e a gera¸c˜ao 2 des¸ca para a baixa

(1)?

Assim, iremos calcular a probabilidade P (X1 = 3, X2 = 1 | X0 = 2) . Note que, ´e
a probabilidade de ir em um passo do estado (2) para o (1) e depois do (1) para o (3).

Pela propriedade de Markov, esta probabilidade deve ser P2,1P1,3. Logo, pela Proposi¸c˜ao
1.9, temos que

P (X1 = 3, X2 = 1 | X0 = 2) =

P (X2 = 1, X1 = 3, X0 = 2)
P (X1 = 3, X0 = 2)

P (X1 = 3, X0 = 2)
P (X0 = 2)

= P (X2 = 1 | X1 = 3, X0 = 2)P (X1 = 3 | X0 = 2)

= P (X2 = 1 | X1 = 3)P (X1 = 3 | X0 = 2).

Em geral, temos o seguinte resultado:

Teorema 2.1. Sejam i0, i1, i2, . . . , in ∈ E.

32

P (Xn+1 = i1, . . . , Xn+m = im | Xn = i0) =

m
(cid:89)

j=1

P (Xn+j = ij | Xn+j−1 = ij−1)

= Pim−1,imPim−2,im−1 . . . Pi0,i1

= Pi0,i1Pi1,i2 . . . Pim−1,im.

Exemplo 2.8. Agora considere que a fam´ılia come¸ca na classe m´edia (2) na gera¸c˜ao 0.

Vamos calcular a probabilidade que a gera¸c˜ao 2 ascenda para a classe baixa (1).

Considerando os trˆes casos poss´ıveis para a gera¸c˜ao 1 e usando o Teorema 2.1

visto anteriormente.

P (X2 = 1 | X0 = 2) =

=

3
(cid:88)

k=1
3
(cid:88)

k=1

P (X1 = k, X2 = 1 | X0 = 2)

P2,kPk,1

= 0.3 · 0.7 + 0.5 · 0.3 + 0.2 · 0.2

= 0.4.

Podemos representar atrav´es do seguinte gr´aﬁco:

Figura 2.3.1: Gr´aﬁco de ´arvore.

Analogamente, podemos provar que para i, j ∈ {1, 2, 3} vale

P (X2 = j | X0 = i) =

3
(cid:88)

k=1

Pi,kPk,j.

(2.3.1)

Note que, o termo da direita na igualdade anterior ´e o coeﬁciente (i, j) da matriz
P 2. E se for homogˆenea, o termo da esquerda ´e justamente a probabilidade de passar

do estado i para o estado j em dois passos. Desta forma, vale que a probabilidade de

transi¸c˜ao em m passos de uma cadeia de Markov X ´e dada por

P (m)
i,j

:= P (Xm+n = j | Xn = i) = P (Xm = j | X0 = i),

33

onde (i, j) ´e a entrada da m − ´esima potˆencia da matriz de transi¸c˜ao P. Ou seja, P m =

P · P · . . . · P
m vezes

existe m termos no produto. Vejamos:

Como ´e homogˆenea qualquer transi¸c˜ao de ordem 2 ´e dada por 2.3.1. Assim, para

as transi¸c˜oes de ordem dois, ou seja, entre os tempos n e n + 2 vale:

P (2)

i,j = P (Xn+2 = j | Xn = i) =

=

=

P (Xn+2 = j, Xn+1 = k | Xn = i)

P (Xn+2 = j | Xn+1 = k)P (Xn−1 = k | Xn = i)

Pi,kPk,j.

(cid:88)

k∈E
(cid:88)

k∈E
(cid:88)

k∈E

Novamente, temos que o termo da direita da ´ultima express˜ao ´e o elemento (i, j)
da matriz P 2 = P · P. Analogamente podemos encontrar as transi¸c˜oes de ordem trˆes,

quatro e assim por diante. Ou seja, entre os tempos n e n+3, n e n+4, que ´e equivalente

a 0 a 3 e 0 a 4.

Em geral, vale que P (m)
i,j

´e o elemento da (i, j) da matriz P m. Isto decorre do

seguinte resultado:

Teorema 2.2. Equa¸c˜oes de Chapman-Kolmogorov

P (m+n)
i,j

=

i,k P (n)
P (m)
k,j .

(cid:88)

k∈E

Demonstra¸c˜ao. Temos que,

P (Xn+m = j | X0 = i) =

(cid:88)

k∈E

P (Xn+m = j, Xm = k | X0 = i).

Utilizando a deﬁni¸c˜ao da probabilidade condicional, cada um dos somandos pode ser

escrito da forma,

P (Xn+m = j, Xm = k | X0 = i) =

=

P (Xn+m = j, Xm = k, X0 = i)
P (X0 = i)
P (Xn+m = j, Xm = k, X0 = i)
P (Xm = k, X0 = i)

P (Xm = k, X0 = i)
P (X0 = i)

= P (Xn+m = j | Xm = k, X0 = i)P (Xm = k | X0 = i)

= P (Xn+m = j | Xm = k)P (Xm = k | X0 = i).

Note que, na ´ultima linha usamos a propriedade de Markov. Substituindo na igualdade

acima obtemos o resultado desejado.

34

Note que, ao chamarmos de P (m) = (P (m)

i,j ) `a matriz de transi¸c˜ao de ordem m,
teremos que o teorema acima aﬁrma que P (m+n) = P (m) · P (n). Como P (1) = P, temos
ent˜ao que P (n+1) = P · P (n) e, usando o argumento indutivo obtemos que P (n) = P n. De
fato, para n = 1 temos que P (1) = P 1 = P que ´e v´alida pela deﬁni¸c˜ao. Suponhamos
que a senten¸ca seja v´alida para n = m, com m ∈ N e m > 1, isto ´e, P (m) = P m,
queremos mostrar que a senten¸ca ´e v´alida quando n = m + 1. Usando a Equa¸c˜ao de

Chapman-komogorov, para n = 1, temos que

P (m+1) = P (m+1)

i,j

=

i,k · P (m)
P (1)

k,j =

(cid:88)

k∈E

(cid:88)

k∈E

i,k · P m
P 1

k,j = P · P m = P m+1.

Agora, iremos ver como as distribui¸c˜oes conjuntas 2.1 de estados do processo

est˜ao determinadas pela matriz de transi¸c˜ao e a distribui¸c˜ao de probabilidade do estado

incial.

Deﬁni¸c˜ao 2.4. Seja π0 : E → [0, 1] uma distribui¸c˜ao de probabilidade no conjunto E,
tal que

1. π0(i) ≥ 0, para todo i ∈ E

2. (cid:80)

i∈E

π0(i) = 1.

Dizemos que π0 ´e uma distribui¸c˜ao inicial da cadeia de Markov {Xt}t∈N se para todo
i ∈ E vale P (X0 = i) = π0(i).

Logo, a distribui¸c˜ao inicial de uma cadeia ´e simplesmente a fun¸c˜ao de probabili-

dade do seu estado incial X0.

Atrav´es do teorema da probabilidade total podemos obter a distribui¸c˜ao de qual-

quer um dos estados em fun¸c˜ao da matriz de transi¸c˜ao e da distribui¸c˜ao inicial. Assim,
para todo n ∈ N,

P (Xn = k) =

=

(cid:88)

i∈E
(cid:88)

P (Xn = k | X0 = i)P (X0 = i)

P (n)

i,k π0(i).

i∈E
= π0P n.

Note que, π0 ´e justamente o vetor linha dos valores da distribui¸c˜ao inicial da cadeia.
Considere πn =

P (Xn = 1) P (Xn = 2) P (Xn = 3)

que fornece πn = π0P n.

(cid:16)

(cid:17)

Atrav´es do teorema 2.1 podemos obter o seguinte resultado,

35

Proposi¸c˜ao 2.1. Seja π0 a distribui¸c˜ao inicial da cadeia {Xn}n≥0 que tem matriz de
transi¸c˜ao P = (Pi,j)i,j∈E. Sejam i0, i1, i2, . . . , im ∈ E, ent˜ao vale

P (X0 = i0, X1 = i1, . . . , Xm = im) = π(i0)Pi0,i1 · · · Pim−1,im.

Demonstra¸c˜ao. Usando o Teorema 2.2, temos que

P (X0 = i0, X1 = i1, . . . , Xm) = im = P (X1 = i1, . . . , Xm = im | X0 = i0)P (X0 = i0)

= Pim−1,im · · · Pi0,i1π0(i0).

2.4 Cadeias com Dois Estados

Observamos que no caso em que temos o espa¸co de estados ﬁnito as probabilidades

de transi¸c˜ao de ordem superior foi calculada multiplicando a matriz de transi¸c˜ao P por

ela mesma. Assim, em alguns casos depois de certa ordem as ﬁlas v˜ao se aproximando

entre si. Ou seja, os valores das entradas nas matrizes v˜ao se aproximando. Agora nesta

parte do trabalho iremos abordar os casos em que temos cadeias com dois estados. Neste

caso particular, fornecemos estimativas sobre o comportamento assint´otico da evolu¸c˜ao

da cadeia de Markov.

Exemplo 2.9. Considere a cadeia de Markov Xn com espa¸co de estados E = {0, 1} e
matriz de transi¸c˜ao,

P =

(cid:34)

(cid:35)

0.5 0.5

0.3 0.7

.

Ent˜ao:
(cid:34)

P 2 =

0.40 0.60

(cid:35)

0.36 0.64

, P 3 =

(cid:34)

0.38

0.62

0.372 0.628

(cid:35)

(cid:34)

, P 4 =

0.3760 0.6240

(cid:35)

0.3744 0.6256

.

No caso em que E tem apenas dois elementos a matriz de transi¸c˜ao toma a forma:

P =

(cid:34)

1 − p

(cid:35)

p

q

1 − q

, onde 0 ≤ p ≤ 1, 0 ≤ q ≤ 1.

Ou seja,

• P (Xn+1 = 0 | Xn = 0) = 1 − p,

• P (Xn+1 = 1 | Xn = 0) = p,

36

• P (Xn+1 = 0 | Xn = 1) = q,

• P (Xn+1 = 1 | Xn = 1) = 1 − q.

Veremos que, se p − q > 0 a matriz P pode ser escrita como:

P =

1
p + q

(cid:35)

(cid:34)

q p

q p

+

1 − p − q
p + q

(cid:34)

p −p

−q

q

(cid:35)

.

Usando as seguintes rela¸c˜oes:

(cid:35)2

(cid:34)

q p

q p

= p + q

(cid:34)

(cid:35)

,

q p

q p

e

(cid:34)

(cid:35)

p −p

−q

q

= (p + q)

(cid:34)

q p

q p

(cid:35) (cid:34)

(cid:35)

p −p

−q

q

=

(cid:34)

(cid:34)

0 0

(cid:35)

0 0

,

(cid:35)

,

p −p

−q

q

´e poss´ıvel provar por argumento indutivo que

P n =

1
p + q

(cid:35)

(cid:34)

q p

q p

+

(1 − p − q)n
p + q

(cid:34)

p −p

−q

q

(cid:35)

.

De fato, para n = 1,temos que:

P 1 =

1
p + q

(cid:35)

(cid:34)

q p

q p

+

(1 − p − q)1
p + q

(cid:34)

(cid:35)

p −p

−q

q

= P.

Suponhamos que para m ∈ N, a senten¸ca tamb´em ´e v´alida. Queremos mostrar que para
(cid:35)
q p

m + 1 a senten¸ca tamb´em ´e v´alida. Para simpliﬁcarmos a escrita escrevemos A =

(cid:34)

q p

e B =

(cid:34)

(cid:35)

p −p

−q

q

. Observe que:

P m+1 = P m · P
(cid:18) 1

· B

(cid:19) (cid:18) 1

p + q

· A +

=

=

p + q
1
p + q

· A +

· A2 +

(1 − p − q)m
p + q
1
p + q
1 − p − q
p + q

·

·

·

1
p + q
(1 − p − q)m
p + q

+

1 − p − q
p + q

· B2

· A · B +

(cid:19)

· B

1 − p − q
p + q
(1 − p − q)m
p + q

·

1
p + q

· B · A

Atente tamb´em que A2 = (p + q) · A, A · B = B · A =

37

(cid:35)

(cid:34)

0 0

0 0

e B2 = (p + q) · B.

Ent˜ao,

P m+1 =

=

(1 − p − q)m+1
(p + q)2

· (p + q) · B

1

(p + q)2 · (p + q) · A +
(cid:35)
1
p + q

q p

+

(cid:34)

q p

(1 − p − q)m+1
p + q

(cid:34)

p −p

−q

q

(cid:35)

.

Portatno, pelo Princ´ıpio da Indu¸c˜ao Finita, a seten¸ca ´e v´alida para todo n ∈ N.
Estudaremos o comportamento de P n quando n → ∞. Analisemos os trˆes casos

a seguir.

Se p + q = 0. Ou seja, p = 0 e q = 0 :
P ´e a matriz identidade de dimens˜ao dois, vale que P n = P para todo n ∈ N
e portanto as linhas n˜ao se aproximam entre si. Ou seja, os valores de entrada destas

matrizes permanecem constantes. A cadeia vai visitar em todos os instantes o estado do

qual ela come¸cou.

Se p + q = 2. Ou seja, p = 1 e q = 1 :

P =

(cid:34)

0 1

(cid:35)

1 0

.

Se n for par, teremos que P n ´e a matriz identidade de ordem dois e para n ´ımpar,
P n = P. Como consequˆencia disto temos que o limite de P n quando n → ∞ n˜ao existe

pois a matriz oscila entre duas matrizes ﬁxas. Ou seja, ao analisar este processo ao longo

do tempo percebemos que os valores de entrada da matriz n˜ao convergem.

Se 0 < p + q < 2 :

Note que, [0 > (−1) · (p + q) > (−1) · 2 ⇒ 0 > −p − q > −2 ⇒ 0 + 1 > 1 − p − q >
(−2) + 1 ⇒ 1 > 1 − p − q > −1 ⇐⇒| 1 − p − q |< 1] e portanto (1 − p − q)n → 0 quando
n → ∞. Assim,

P n =

lim
n→∞

(cid:34) q
p+q
q
p+q

(cid:35)

p
p+q
p
p+q

No ´ultimo caso, as linhas da matriz convergem para o vetor de probabilidades de

uma distribui¸c˜ao que denotaremos como π∞, isto ´e,

lim
n→∞

lim
n→∞

P n

0,0 = lim
n→∞

P n

1,0 = π∞(0) =

P n

0,1 = lim
n→∞

P n

1,1 = π∞(1) =

q
p + q

,

p
p + q

.

Atrav´es do argumento indutivo tamb´em ´e poss´ıvel obter uma estimativa para a

taxa de convergˆencia das probabilidades de transi¸c˜ao em n passos para a distribui¸c˜ao π∞.

Proposi¸c˜ao 2.2. Para uma cadeia de Markov {Xn}n>1 com dois estados, E = {0, 1} e
tal que 0 < p + q < 2, vale

38

| P n

i,0 − π∞(0) |=| P n

i,0 −

q
p + q

|≤| 1 − p − q |n, com i = 0 ou i = 1.

Estas probabilidades de transi¸c˜ao se aproximam de π∞ com velocidade exponen-
cial. Por isso, de forma geral, quando 0 < p + q < 2, observamos a proximidade entre as
linhas de P n mesmo para valores de n pequenos.

Exemplo 2.10. No exemplo 2.9, temos que p = 0, 5 e q = 0, 3, portanto, 0 < p + q < 2 e
(cid:105)
(cid:104)
0, 375 0, 625

as linhas da matriz devem convergir para
.
A diferen¸ca entre elas vai para zero mais r´apido que (0, 2)n . Observe que, para n = 4,
obtivemos uma precis˜ao de duas casas decimais.

(cid:105)
π∞ (0) π∞(1)

(cid:104) 3
8

=

=

5
8

(cid:104)

(cid:105)

Quando existe π∞, temos que para instantes de tempo grandes, a matriz P n se
aproxima da matriz de transi¸c˜ao de ordem n de uma sequˆencia de vari´aveis aleat´orias.

Ou seja, para instantes tempo grandes, os estados ir˜ao se tornando “menos dependentes”

e ´e natural pensar que a cadeia “ignora” o estado onde ela come¸cou, em outras palavras,

sua distribui¸c˜ao inicial. De fato,

Supondo a distribui¸c˜ao inicial da cadeia igual π0, ou seja, temos P (X0 = 0) =
π0(0) e P (X0 = 1) = π0(1), sabemos que (P (Xn = 0), P (Xn = 1)) = (π0(0), π0(1)) · P n.
Usando a express˜ao que temos para P n e o fato que π0 ´e uma distribui¸c˜ao, obtemos:

P (Xn = 0) =

P (Xn = 1) =

q
p + q

p
p + q

+ (1 − p − q)n(π0(0) −

q
p + q

),

+ (1 − p − q)n(

q
p − q

− π0(0)).

Como no caso que estamos considerando vale (1 − p − q)n → 0 quando n → ∞,

concluimos que

lim
n→∞

P (Xn = 0) =

q
p + q

= π∞(0),

p
p + q
p+q e π∞(1) = p
p+q podem ser interpretadas como as
probabilidades da cadeia estar a longo prazo no estado 0 ou no estado 1, respectivamente,

As quantidades π∞(0) = q

P (Xn = 1) =

= π∞(1).

lim
n→∞

por isto π∞ ´e chamada de distribui¸c˜ao assint´otica da cadeia.

Cap´ıtulo 3

Exemplos de Cadeias de Markov

para o Ensino M´edio

Neste cap´ıtulo, exempliﬁcaremos processos que podem ser abordados na educa¸c˜ao

b´asica. Ou seja, existe a possibilidade de montar projetos e roteiros de aula de uma

maneira paup´avel e at´e mesmo interdisciplinar, pois estes foram sugeridos atrav´es de

fatos do cotidiano dos estudantes.

3.1 Previs˜ao do Tempo

Ao observar o mˆes de junho na cidade de Santo Antˆonio de Jesus na Bahia, a

condi¸c˜ao clim´atica ao dia foi classiﬁcada como Ensolarado, Chuvoso ou Nublado. Assim,

os dias deste mˆes podem ser classiﬁcados conforme a tabela abaixo:

Dia 1

Dia 2

Dia 3

Dia 4

Dia 5

Nublado

Ensolarado

Nublado

Nublado

Chuvoso

Dia 6

Dia 7

Dia 8

Dia 9

Dia 10

Ensolarado Ensolarado

Nublado

Ensolarado Nublado

Dia 11

Dia 12

Dia 13

Dia 14

Dia 15

Nublado

Chuvoso

Chuvoso

Nublado

Chuvoso

Dia 16

Dia 17

Dia 18

Dia 19

Dia 20

Chuvoso

Ensolarado Ensolarado Ensolarado Nublado

Dia 21

Dia 22

Dia 23

Dia 24

Dia 25

Ensolarado Ensolarado

Nublado

Nublado

Chuvoso

Dia 26

Dia 27

Dia 28

Dia 29

Dia 30

Ensolarado Ensolarado

Nublado

Ensolarado Nublado

Tabela 3.1: Condi¸c˜oes clim´aticas de Santo Antˆonio de Jesus no mˆes de junho.

39

40

Note que, atrav´es da informa¸c˜oes da tabela temos as seguintes probabilidades
PEnsolarado = 12
30. Desta forma, conseguimos corresponder
o estado 1 ao dia Ensolarado, o estado 2 ao dia Nublado e ao estado 3 ao dia Chuvoso.
Ent˜ao, o vetor inicial ´e dado por π(0) =

30 e PChuvoso = 6

30, PN ublado = 12

0.4 0.4 0.2

(cid:16)

(cid:17)

.

Suponhamos que o Instituto Nacional de Pesquisas Espaciais - INPE, tenha ao

longo de 10 anos de observa¸c˜ao gerado uma matriz de transi¸c˜ao do tempo para a cidade

de Santo Antˆonio de Jesus com as seguintes entradas:







0.3 0.4 0.3

P =

0.1 0.4 0.5

.

0.5 0.4 0.1







Atrav´es da matriz, se hoje temos um dia ensolarado h´a uma probabilidade de 40%

de termos um dia nublado amanh˜a, ou ainda, se est´a nublado hoje temos 10% de o dia ser

ensolarado amanh˜a. Como nossa vari´avel ´e mensal, ao multiplicar o vetor de probabilidade
inicial π(0) pela matriz de transi¸c˜ao P teremos o vetor de probabilidade π(1) que representa

a distribui¸c˜ao de probabilidades para o pr´oximo mˆes e assim sucessivamente.

Pelo exemplo, podemos concluir que o tempo em uma cidade ´e um fenˆomeno que

de fato independe do seu estado h´a um ano atr´as, mas ´e inﬂuenciado pelo estado em

que se encontra no dia anterior, ou seja, este ´e um fenˆomeno que possui a propriedade

Markoviana. O outro ponto positivo ´e que a matriz de transi¸c˜ao possui uma quantidade

pequena de estados, possibilitando facilmente sua interpreta¸c˜ao.

3.2 Previs˜oes em Gen´etica

De acordo com a gen´etica cl´assica, algumas caracter´ısticas das plantas e dos

animais s˜ao determinadas por um par de genes, cada um dos quais podendo ser de dois

tipos, denotados por A e a. Com isso, temos trˆes gen´otipos poss´ıveis: AA, Aa (aA) e aa.

Neste caso, o indiv´ıduo se chama dominante(D) se tem o gen´otipo AA, heterozigoto (H)

se tem o gen´otipo Aa e recessivo (R) se tem o gen´otipo aa. A previs˜ao de gen´otipos em

uma popula¸c˜ao ´e bastante ´util, pois ´e usada na monitora¸c˜ao e o controle de algumas

caracter´ısticas da sele¸c˜ao artiﬁcial, sejam elas desej´aveis ou n˜ao, como doen¸cas gen´eticas

por exemplo.

As Cadeias de Markov podem ser ´uteis nesse tipo de previs˜ao. Considerando

os estados como os gen´otipos D, H e R, e obtendo a probabilidade de cada gen´otipo

para cruzamentos entre indiv´ıduos D × D, D × H, D × R, H × H, H × R e R × R. As

probabilidades ser˜ao assim distribu´ıdas:

41

Gen´otipo/Cruzamento D(AA) H(Aa) R(aa)

D x D

D x H

D x R

H x H

H x R

R x R

1

0.5

0

0.25

0

0

0

0.5

1

0.5

0.5

0

0

0

0

0.25

0.5

1

Tabela 3.2: Tabela de gen´otipos.

Observando o cruzamento com indiv´ıduos do gen´otipo H,temos



0.5

0.5

0







P =

0.25 0.5 0.25

0

0.5

0.5

.





Ou seja, P ´e uma matriz de transi¸c˜ao. Assim, ´e poss´ıvel prever o comportamento

gen´etico para as futuras gera¸c˜oes. Suponhamos que, no processo de sele¸c˜ao artiﬁcial, a

primeira gera¸c˜ao a cruzar com o gen´otipo H seja formada exclusivamente por indiv´ıduos

dominantes (D), a previs˜ao para o per´ıodo de trˆes gera¸c˜oes ´e dado por:

π(3) = π(0) · P 3 =

(cid:16)

(cid:17)

1 0 0

·







0.3125 0.5 0.1875

0.25

0.5

0.25

0.1875 0.5 0.3125







(cid:16)

=

0.3125 0.5 0.875

(cid:17)

.

3.3 Previs˜oes Populacionais

Na regi˜ao metropolitana de Salvador, a cada ano, trˆes por cento da popula¸c˜ao

de Dias D´avila migra para a cidade de Salvador, enquanto que apenas um por cento da

popula¸c˜ao de Salvador migra para a cidade de Dias D´avila. Se todas as demais condi¸c˜oes

permanecerem est´aveis, as condi¸c˜oes pol´ıticas n˜ao mudaram, e estas porcentagens de

migra¸c˜ao continuam as mesmas, qual deve ser a rela¸c˜ao entre as popula¸c˜oes de Salvador

e Dias D´avila ao longo do tempo?

Sendo trˆes por cento da popula¸c˜ao de Dias D´avila migrando para Salvador, a

probabilidade de migra¸c˜ao de Dias D´avila para Salvador ´e de 0.03, j´a a probabilidade de

n˜ao migra¸c˜ao ´e de 0.97. Como um por cento da popula¸c˜ao de Salvador migra para Dias

D´avila a probabilidade de migra¸c˜ao de Salvador para Dias D´avila ´e de 0.01 e a de n˜ao

migra¸c˜ao ´e de 0.99. Denotando por S a cidade de Salvador e por D a cidade de Dias

D´avila, temos a matriz das probabilidades de transi¸c˜ao:

42

(cid:34)

P =

(cid:35)

PS,D PS,S
PD,S PD,D

P =

(cid:34)

0.01 0.99

(cid:35)

0.03 0.97

Logo, a longo prazo as probabilidades PD, de morar em Dias D´avila, e PS, de

morar em Salvador, devem satisfazer

(cid:16)

PS PD

(cid:34)

(cid:17)

·

0.01 0.99

(cid:35)

0.03 0.97

(cid:16)

=

PS PD

(cid:17)

,

onde 99PS = 3PD e, como PS + PD = 1, temos PD = 0.25 e PS = 0.75. Portanto,
a longo prazo, e se n˜ao houver modiﬁca¸c˜oes nas tendˆencias de migra¸c˜ao, teremos 25% da

popula¸c˜ao morando em Dias D´avila e 75% da popula¸c˜ao habitando em Salvador.

3.4 Passeios Aleat´orios

Quando temos o espa¸co de estados igual aos n´umeros inteiros, ou seja, E = Z
ent˜ao teremos um processo aleat´orio simples. As transi¸c˜oes neste caso ocorrem entre

estados vizinhos,

Pi,i+1 = p = 1 − Pi,i−1, com 0 ≤ p < 1.

Se p = 0 as transi¸c˜oes s˜ao somente para a esquerda e se p = 1 elas s˜ao somente

para a direita.

Figura 3.4.1: Topologia da cadeia para o passeio aleat´orio simples com inﬁnitos estados.

J´a no caso em que p = 1

2 as transi¸c˜oes s˜ao dadas por

Pi,j =






1
2,
0,

j = i − 1 ou j = i + 1,

caso contr´ario.

A cadeia vai de um estado para o da esquerda ou para o da direita com a mesma

probabilidade.

Analisemos o seguinte exemplo: Um homem est´a num ponto de coordenada inteira

sobre o eixo x entre a origem e o ponto 4. Ele d´a um passo de uma unidade para a direita

43

com probabilidade p ou para a esquerda com probabilidade q = 1 − p, exceto quando ele

estiver na origem, caso em que s´o pode d´a um passo para a direita chegando ao ponto 1,

ou quando estiver sobre o ponto 4, caso em que d´a exclusivamente um passo para esquerda

chegando ao ponto 3. Indiquemos por Xn a sua posi¸c˜ao ap´os n passos. Logo, o espa¸co de
estados ´e dado por E = {0, 1, 2, 3, 4}, em que cada estado representa que o homem est´a

sobre o eixo x no ponto de abscissa i, com i = 0, 1, 2, 3, 4. Assim, a matriz de transi¸c˜ao ´e

dada por



1 0 0 0 0

q 0 p 0 0

P =

0 q 0 p 0

0 0 q 0 p

0 0 0 1 0





















.

Cada coluna da matriz, exceto a primeira e a ´ultima, correspondem ao fato de

que o homem se move de um estado presente para um estado futuro, com probabilidade p

ou para o estado passado com probabilidade q = 1 − p. A primeira coluna corresponde ao

fato de que o homem passa do estado inicial 1 sempre para o pr´oximo estado 2 e a ´ultima

coluna corresponde ao fato de que o homem sempre passa do estado 4 para o estado 3.

Suponha agora que quando o homem atinge um estado de fronteira ele permanece
2 e se move para o outro estado de fronteira tamb´em

nesse estado, com probabilidade 1
com probabilidade 1

2. Nesse caso, a matriz de transi¸c˜ao ´e dada por



0.5 0.5 0

P =










q

0

0

0

0

q

0

0

p

0

q

0

0

p

0

0

0

0

p












.

0 0.5 0.5

Cap´ıtulo 4

Sugest˜ao de Sequˆencia Did´atica

A sequˆencia did´atica sugerida a seguir, possui 4 etapas, onde cada uma pode ter

o tempo de at´e 4 hor´arios de aula, resultando em um per´ıodo de at´e 12 hor´arios de aula.

A proposta ´e proporcionar a investiga¸c˜ao, a pr´atica e o entrela¸camento dos conte´udos

abordados anteriormente, sendo estes utilizados em atividades para alunos do segundo e

terceiro ano do ensino m´edio da educa¸c˜ao b´asica.

A divis˜ao das quatro etapas ser´a feita da seguinte forma:

• Primeira etapa: contecer´a a introdu¸c˜ao do tema e ,logo em seguida, a proposta de

um exerc´ıcio;

• Segunda etapa o professor apresentar´a as deﬁni¸c˜oes e as f´ormulas

P (m)
i,j = P (Xm+n = j | Xn = i), P (Xn = k) = π0P n e P =










P0,0 P0,1
P1,0 P1,1
...
...
PN,0 PN,2










,

· · · P0,N
· · · P1,N
...
. . .
· · · PN,N

que possibilitar˜ao a resolu¸c˜ao dos exerc´ıcios propostos;

• Terceira etapa: o professor mostrar´a aos alunos o software matem´atico Maxima,

com a ﬁnalidade de simpliﬁcar as opera¸c˜oes entre matriz e vetor e com potˆencia de

matrizes;

• Quarta etapa: o professor discutir´a com os alunos os resultados encontrados e apre-

sentar´a mais problemas que possam a vim ser trabalhados em sala de aula.

A proposta deste trabalho ´e mostrar ao professor a utiliza¸c˜ao de conte´udos da educa¸c˜ao

b´asica para modelagem de problemas que reﬂetem o cotidiano dos alunos. Ou seja,

pretende-se discutir e analisar os resultados de inquieta¸c˜oes de estudantes sobre a im-

portˆancia do estudo de Matrizes e Probabilidade. Para isso, sugere-se ao professor seguir

cada etapa atrav´es dos planos de aula abaixo.
44

45

4.1 Primeira Etapa

PLANO DE AULA 1

P´ublico alvo: 2o e 3o ano do ensino m´edio

Tem´atica da aula: Cadeias de Markov

Conte´udo (s):

1. Cadeia de Markov;

2. Matriz de Transi¸c˜ao;

3. Diagrama de Trans¸c˜ao.

Objetivo:

1. Apresentar as Cadeias de Markov;

2. Modelar um problema pr´atico atrav´es de uma representa¸c˜ao matricial que ´e justa-

mente a matriz de transi¸c˜ao;

3. Analisar o problema possibilitando a formaliza¸c˜ao do que ocorre atrav´es de um

diagrama de transi¸c˜ao.

N´umero de aulas: 3

Material necess´ario:

• Quadro branco;

• Piloto;

• Folha de papel com a atividade proposta.

Desenvolvimento:

Primeiro momento: O professor deve introduzir o conceito de Cadeias de

Markov, que poder´a ser feito no quadro branco;

Segundo momento: Exempliﬁcar uma situa¸c˜ao simples de Cadeia de Markov.

A sugest˜ao ´e o exemplo 2.3 apresentado no cap´ıtulo 2;

Terceiro momento: Analisar o exemplo 2.3 juntamente com os alunos e cons-

truir´a a matriz de transi¸c˜ao e uma ilustra¸c˜ao geom´etrica da situa¸c˜ao que ser´a o diagrama

de transi¸c˜ao;

Quarto momento: O professor ir´a entregar a cada aluno o exerc´ıcio proposto

abaixo e dever´a esperar o tempo de no m´aximo 25 minutos para come¸car a discuss˜ao os

resultados encontrados pelos estudantes.

46

Exercic´ıo Proposto

Em uma fam´ılia, existe um levantamento em rela¸c˜ao a classe social de cada

gera¸c˜ao. Ou seja, cada gera¸c˜ao pode estar na classe baixa (1), na classe m´edia (2) ou na

classe alta (3). Sobre a possibilidade de mudan¸ca de classes temos a seguinte matriz com

suas probabilidades.







0.3 0.3 0.4

0.3 0.5 0.2

0.2 0.3 0.5







a) Fa¸ca uma interpreta¸c˜ao geom´etrica da situa¸c˜ao (diagrama de transi¸c˜ao).

b) Se a fam´ılia est´a na primeira gera¸c˜ao e encontra-se na classe m´edia, qual a

probabilidade da fam´ılia se tornar classe alta, quando a pesquisa for realizada na terceira

gera¸c˜ao?

Resolu¸c˜ao:

a) Fa¸ca uma interpreta¸c˜ao geom´etrica da situa¸c˜ao (diagrama de transi¸c˜ao).

Figura 4.1.1: Grafo de transi¸c˜oes entre classes.

b) Se a fam´ılia est´a na primeira gera¸c˜ao e encontra-se na classe m´edia, qual a

probabilidade da fam´ılia se tornar classe alta, quando a pesquisa for feita na terceira

gera¸c˜ao?

O aluno ao responder este t´opico est´a sendo induzido a pensar de maneira inves-

tigativa, ou seja, sabendo que a fam´ılia encontra-se na classe m´edia a probabilidade para

a pr´oxima gera¸c˜ao ´e dada por:

classe 1

classe 2

classe 3

0.3

0.5

0.2

47

Figura 4.1.2: Transi¸c˜oes com estado inicial 2

Desta forma, a probabilidade da fam´ılia na terceira gera¸c˜ao ser da classe 3 ´e dada

por

P (M ´EDIA e BAIXA e ALT A) = 1 × 0.3 × 0.4 = 0.12
P (M ´EDIA e M ´EDIA e ALT A) = 1 × 0.5 × 0.2 = 0.10
P (M ´EDIA e ALT A e ALT A) = 1 × 0.2 × 0.5 = 0.10
Logo, a probabilidade da terceira gera¸c˜ao ser da classe alta ser´a de 0.12 + 0.10 +

0.10 = 0.32. Ou seja, 32%.

O professor deve enfatizar que foi utilizado a probabilidade condicional para che-

gar ao resultado e dever´a deixar claro que para uma futura gera¸c˜ao nem sempre os c´alculos

ser˜ao r´apidos. Por exemplo, a probabilidade agora da d´ecima quinta gera¸c˜ao ser da classe

alta. Os c´alculos a m˜ao ﬁcam quase imposs´ıvel para a proposta de tempo da aula. Desta

forma, o aluno come¸ca a perceber a necessidade da teoria matem´atica para ser utilizada

como uma ferramenta na resolu¸c˜ao de muitos problemas.

4.2 Segunda Etapa

PLANO DE AULA 2

P´ublico alvo: 2o e 3oano do ensino m´edio

Tem´atica da aula: Cadeias de Markov

Conte´udo (s):

1. Cadeias de Markov Homogˆeneas a tempo discreto;

2. Matriz de Transi¸c˜ao;

3. Vetor de Probabilidade Inicial.

Objetivo:

1. Apresentar as f´ormulas para facilitar os c´alculos do exerc´ıcio proposto na aula an-

terior e de grande itera¸c˜oes;

2. Aplicar os conceitos de Cadeias de Markov Homogˆenea a tempo discreto para resol-

48

ver o pr´oximo exerc´ıcio proposto.

N´umero de aulas: 3

Material necess´ario:

• Quadro branco;

• Piloto;

• Folha de papel com a atividade proposta.

Desenvolvimento:

Primeiro momento: O professor ir´a introduzir uma no¸c˜ao de Cadeias de Mar-

kov Homogˆeneas a tempo discreto;

Segundo momento: Apresentar as f´ormulas e construir o vetor inicial da si-

tua¸c˜ao colocada no exerc´ıcio proposto da ´ultima aula e resolvˆe-lo no quadro junto com os

estudantes;

Terceiro momento: O professor ir´a aplicar uma segunda atividade direcionada

ao conte´udo previamente apresentado pelo professor.

Na primeira parte da aula, o professor ir´a falar de forma exempliﬁcada sobre

Cadeias de Markov a tempo discreto. Em seguida, dever´a apresentar algumas f´ormulas

que ajudar˜ao a resolver uma inquieta¸c˜ao da aula anterior.

P (Xn = k) = πt

0P n e P (m)

i,j = P (Xm+n = j | Xn = i)

Exerc´ıcio Proposto (´ultima aula)

Em uma fam´ılia, existe um levantamento em rela¸c˜ao a classe social de cada

gera¸c˜ao. Ou seja, cada gera¸c˜ao pode estar em uma classe baixa (1), classe m´edia (2)

ou classe alta (3). Sobre a possibilidade de mudan¸ca de classes temos a seguinte matriz

com suas probabilidades.







0.3 0.3 0.4

0.3 0.5 0.2

0.2 0.3 0.5







b) Desta forma, se a fam´ılia est´a na primeira gera¸c˜ao e encontra-se na classe

m´edia, qual a probabilidade da fam´ılia se tornar classe alta, quando a pesquisa for reali-

zada na terceira gera¸c˜ao?

Resolu¸c˜ao

49

Sabendo que a primeira gera¸c˜ao est´a na classe m´edia ent˜ao o vetor inicial ´e
(cid:16)
. Em seguida, o professor ir´a calcular o vetor π(1) e depois o π(2) e

0 1 0

(cid:17)

π(0) =

mostrar que ´e o mesmo resultado ao fazer:

π(2) = π(0) · P 2

(cid:16)

=

(cid:17)

0 1 0







·

0.26 0.36 0.38



0.28

0.4

0.32

0.25 0.36 0.39





(cid:16)

=

0.28 0.4 0.32

(cid:17)

.

Portanto, a probabilidade ´e de 0.32 da terceira gera¸c˜ao ser de classe alta, ou seja,

32%.

Exerc´ıcio Proposto

Na cidade de Amargosa a chance de fazer sol ou chuva amanh˜a depende somente

das condi¸c˜oes clim´aticas de hoje. Atrav´es de observa¸c˜oes realizadas previamente, tem-se

que a probabilidade de fazer sol no pr´oximo dia, sendo que hoje foi ensolarado, ´e de 75%

e 25% de chover, mas a probabilidade de fazer sol no pr´oximo dia sendo que hoje foi um

dia chuvoso ´e de 50%.

De acordo com o conte´udo visto em sala de aula, responda os seguintes t´opicos:

a) Determine a matriz de transi¸c˜ao relacionada a situa¸c˜ao.

b) Se o estado incial for um dia ensolarado, qual a previs˜ao dos pr´oximos dois

dias para a cidade de Amargosa.

c) Se o estado inicial for o vetor

os pr´oximos trˆes dias em Amargosa.

(cid:16)

(cid:17)

0.25 0.75

, veriﬁque a previs˜ao do tempo para

Resolu¸c˜ao

a) Determine a matriz de transi¸c˜ao relacionada a situa¸c˜ao.

Neste caso, os alunos dever˜ao apresentar como solu¸c˜ao a seguinte matriz

0.5
b) Se o estado incial for um dia ensolarado, qual a previs˜ao dos pr´oximos dois

0.5

.

(cid:34)

0.75 0.25

(cid:35)

dias para a cidade de Amargosa.

O aluno ir´a determinar o vetor inicial e fazer uso das f´ormulas apresentadas pelo

professor anteriormente:

50

π(0) =

(cid:16)

(cid:17)

.

1 0

π(1) = π(0) · P =

(cid:16)

(cid:17)

·

1 0

(cid:34)

0.75 0.25

(cid:35)

0.5

0.5

(cid:16)

=

(cid:17)

0.75 0.25

.

π(2) = π(1) · P =

(cid:16)

(cid:17)

0.75 0.25

(cid:34)

·

0.75 0.25

(cid:35)

0.5

0.5

(cid:16)

=

0.6875 0.3125

(cid:17)

.

c) Se o estado inicial for o vetor

(cid:16)

0, 25 0, 75

(cid:17)

, veriﬁque a previs˜ao do tempo

para os pr´oximos trˆes dias em Amargosa.

Agora o aluno ir´a determinar um novo vetor inicial e novamente fazer uso das

f´ormulas apresentadas pelo professor anteriormente.

(cid:16)

π(0) =

(cid:17)

0.25 0.75

.

π(1) = π(0) · P =

(cid:16)

(cid:17)

0.25 0.75

π(2) = π(1) · P =

(cid:16)

0.5625 0.4375

(cid:17)

(cid:34)

(cid:34)

·

·

0.75 0.25

(cid:35)

0.5

0.5

(cid:16)

=

0.5625 0.4375

(cid:17)

.

0.75 0.25

(cid:35)

0.5

0.5

(cid:16)

=

0.646025 0.359375

(cid:17)

.

π(3) = π(2) · P =

(cid:16)

0.646025 0.359375

(cid:17)

(cid:34)

·

0.75 0.25

(cid:35)

0.5

0.5

(cid:16)

=

0.66015625 0.33984375

(cid:17)

4.3 Terceira Etapa

PLANO DE AULA 3

P´ublico alvo: 2o e 3oano do ensino m´edio

Tem´atica da aula: MAXIMA

Conte´udo (s):

1. Cadeias de Markov Homogˆeneas a tempo discreto;

2. Software matem´atico MAXIMA.

Objetivo:

1. Apresentar o software matem´atico MAXIMA com suas principais fun¸c˜oes para

opera¸c˜oes com Matrizes.

2. Utilizar o MAXIMA para os c´alculos de envolvendo grandes potˆencias de matrizes.

51

N´umero de aulas: 4

Material necess´ario:

• Quadro branco;

• Piloto;

• Computadores;

• Notebooks;

• Data-show.

Desenvolvimento:

Primeiro momento: O professor apresentar´a o software MAXIMA atrav´es de

um v´ıdeo tutorial;

Segundo momento: O professor ir´a junto aos estudantes interagir com o soft-

ware na aprendizagem dos comandos b´asicos;

Terceiro momento: Os estudantes dever˜ao fazer uso do MAXIMA para realizar

opera¸c˜oes com matrizes;

Quarto momento: O exerc´ıcio proposto na primeira aula dever´a ser refeito e

com uma maior quantidade de itera¸c˜oes atrav´es dos c´alculos realizados no MAXIMA.

Como visto anteriormente em aula, a partir de grandes itera¸c˜oes ﬁca invi´avel

realizar os c´alculos a m˜ao. Por isso, ´e necess´ario a utiliza¸c˜ao de ferramentas que auxiliem

o aluno nesta tarefa.

Hoje, podemos fazer uso de software matem´aticos gratuitos e de f´acil utiliza¸c˜ao. O

MAXIMA ´e um software neste formato, ou seja, livre e de f´acil utiliza¸c˜ao para a educa¸c˜ao

b´asica. Desta forma, o professor dever´a seguir o seguinte roteiro para sua utiliza¸c˜ao:

1. Baixar a vers˜ao correspondente a plataforma utilizada no ambiente escolar atrav´es

do site http://maxima.sourceforge.net/pt/download.html;

2. Seguir os passos da instala¸c˜ao e ler atentamente as informa¸c˜oes;

3. Ao terminar a instala¸c˜ao abrir o programa para veriﬁcar se aparece alguma mensa-

gem de erro, caso n˜ao apare¸ca, parab´ens a instala¸c˜ao foi conclu´ıda com sucesso.

52

Agora, o professor apresentar´a a turma o software, vale lembrar que os estudantes devem

acompanhar passo a passo as orienta¸c˜oes no data-show e nos respectivos notebooks ou

computadores.

A primeira parte da apresenta¸c˜ao o professor ir´a abrir o seguinte link:

https://www.youtube.com/watch?v=VQq9yMiebvU.

Neste v´ıdeo, ser´a abordado fun¸c˜oes b´asicas e que ser˜ao relevantes depois na

opera¸c˜ao entre matrizes. No segundo momento, cada dupla de alunos far´a uso de um

computador ou notebook e far´a os seguintes passos:

• Abrir o programa MAXIMA;

Figura 4.3.1: P´agina Inicial do wxMaxima.

• Na barra de comandos clique em ´Algebra e depois em Introduzir matriz;

53

Figura 4.3.2: Comando para introduzir matriz.

• Preencher o tipo e o nome da matriz;

Figura 4.3.3: Caixa da matriz.

• Ao clicar em OK no passo anterior, abrir´a uma nova caixa para preencher com os

elementos da matriz;

54

Figura 4.3.4: Caixa com os elementos da matriz.

• Depois de preencher a caixa com os elementos da matriz, clique em OK e o programa

ir´a gerar a matriz;

Figura 4.3.5: Matriz gerada pela caixa de elementos.

• Para realizar a opera¸c˜ao de adi¸c˜ao de matrizes o aluno dever´a seguir o roteiro

anterior e criar uma nova matriz (B) do mesmo tipo, em seguida, digitar na janela

do MAXIMA os comandos: A + B depois control mais enter;

55

Figura 4.3.6: Adi¸c˜ao de matrizes.

• Na opera¸c˜ao de multiplica¸c˜ao entre matrizes, o aluno dever´a digitar A.B depois

control mais enter ;

Figura 4.3.7: Multiplica¸c˜ao de matrizes.

• Agora o aluno ir´a realizar a potˆencia de matriz, para isso ele deve utilizar os se-
guintes comandos: A∧∧2 depois control mais enter. Nesta opera¸c˜ao a matriz A foi

multiplicada por ela mesma, pois estava elevado ao quadrado;

56

Figura 4.3.8: Potˆencia de matriz.

Neste momento da aula, o professor ir´a retomar o primeiro exerc´ıcio proposto.

Exercic´ıo Proposto

Em uma fam´ılia, existe um levantamento em rela¸c˜ao a classe social de cada

gera¸c˜ao. Ou seja, cada gera¸c˜ao pode estar em uma classe baixa (1), classe m´edia (2)

ou classe alta (3). Sobre a possibilidade de mudan¸ca de classes temos a seguinte matriz

com suas probabilidades.







0.3 0.3 0.4

0.3 0.5 0.2

0.2 0.3 0.5







Desta forma, se a fam´ılia est´a na primeira gera¸c˜ao e encontra-se na classe m´edia,

qual a probabilidade da fam´ılia se tornar classe alta, quando a pesquisa for realizada na

d´ecima quinta gera¸c˜ao?

Resolu¸c˜ao

57

Figura 4.3.9: Solu¸c˜ao para quinze itera¸c˜oes.

Logo, 36, 11%.

4.4 Quarta Etapa

PLANO DE AULA 4

P´ublico alvo: 2o e 3oano do ensino m´edio

Tem´atica da aula: MAXIMA

Conte´udo (s):

1. Cadeias de Markov Homogˆeneas a tempo discreto.

Objetivo:

1. Avaliar a participa¸c˜ao dos estudantes com o conte´udo proposto;

2. Discutir os resultados encontrados com uma maior quantidade de itera¸c˜oes;

3. Sugerir aos alunos outros problemas que poder˜ao ser modelados com o mesmo

conte´udo.

N´umero de aulas: 2

Material necess´ario:

• Quadro branco;

• Piloto;

58

• Notebooks;

• Data-show.

Desenvolvimento:

Primeiro momento: O professor ir´a avaliar a participa¸c˜ao dos alunos atrav´es

de todo o processo realizado, ou seja, ´e poss´ıvel atribuir uma pontua¸c˜ao ao estudante de

acordo com o trabalho realizado por cada um deles no decorrer das aulas. Por exemplo:

pontua¸c˜ao para representa¸c˜ao matricial do problema, representa¸c˜ao por diagrama do pro-

blema, interpreta¸c˜ao sobre o vetor inicial, c´alculos realizados manualmente e c´alculos de

grandes itera¸c˜oes realizados com ajuda do software;

Segundo momento: O professor ir´a deixar claro a necessidade da utiliza¸c˜ao do

software MAXIMA para o c´alculo de grandes itera¸c˜oes e observar o que poderia ter sido

encontrado no caso de cada instante do tempo (gera¸c˜ao). J´a que os exerc´ıcios propostos

abordam apenas Cadeias de Markov a tempo discreto;

Terceiro momento: Deixar uma atividade para que os alunos possam realizar

em outro momento.

ATIVIDADE

O caf´e tem uma colheita anual classiﬁcada como boa, m´edia ou ruim. Na regi˜ao

do Vale do Jiquiri¸ca na Bahia, observou-se que ap´os uma colheita ruim, existe uma pro-

babilidade de 0, 7 e 0, 2 de a colheita no ano seguinte ser classiﬁcada como m´edia ou boa,

respectivamente. Al´em disso, tamb´em foi observado que ap´os uma colheita m´edia, existe

a probabilidade de 0, 3 e 0, 2 de a pr´oxima ser classiﬁcada como boa ou ruim, respectiva-

mente. E ap´os uma colheita boa, h´a probabilidade de 0, 5 e 0, 1 de a pr´oxima colheita ser

classiﬁcada como m´edia ou ruim, respectivamente.

Sabendo que a colheita do ano posterior ´e inﬂuenciada somente pela colheita do

ano anterior a ela, responda:

a) Represente atrav´es do diagrama de transi¸c˜ao.

b) Monte a matriz de transi¸c˜ao P.

c) Em 4 anos, qual ´e a probabilidade de uma colheita vir a ser classiﬁcada como

boa, dado que a colheita atual ´e ruim?

d) Em 10 anos, qual a probabilidade de uma colheita vir a ser classiﬁcada como

m´edia, dado que a colheita atual ´e m´edia?

Resolu¸c˜ao

a) Represente atrav´es do diagrama de transi¸c˜ao.

b) Monte a matriz de transi¸c˜ao P.

59

Figura 4.4.1: Diagrama de transi¸c˜ao.







0.4 0.5 0.1

P =

0.3 0.5 0.2

.

0.2 0.7 0.1







c) Em 4 anos, qual ´e a probabilidade de uma colheita vir a ser classiﬁcada como

boa, dado que a colheita atual ´e ruim?

Se a colheita atual ´e ruim, ent˜ao π(0) =
(cid:16)

0 0 1
(cid:17)

π(4) = π(0) · P 4 =

0.31620 0.53040 0.15340

.

(cid:16)

(cid:17)

. Da´ı,

Logo, 31, 62% ´e a probabilidade da colheita ser boa.

d) Em 10 anos, qual a probabilidade de uma colheita vir a ser classiﬁcada como

m´edia, dado que a colheita atual ´e m´edia?

Se a colheita atual ´e m´edia, ent˜ao π(0) =
(cid:16)

π(10) = π(0) · P 10 =

0.31633 0.53061 0.15306

(cid:17)

.

(cid:16)

(cid:17)

0 1 0

.Da´ı,

Logo, 53, 061% ´e a probabilidade da colheita ser m´edia.

Referˆencias Bibliogr´aﬁcas

[1] J. P. d. A. Albuquerque, J. M. P. Fortes, and W. A. Finamore. Probabilidade,

vari´aveis aleat´orias e processos estoc´asticos. Editora PUC–Rio e Editora Interciˆencia,

Rio de Janeiro, Brasil, 2008.

[2] J. L. Boldrini, S. I. Costa, V. Figueredo, and H. G. Wetzler. ´Algebra linear. Harper

& Row, 1980.

[3] K. L. Chung. Elementary probability theory with stochastic processes. Springer Science

& Business Media, 2012.

[4] A. Golmakani, A. A. Silva, E. M. S. Freire, M. K. Barbosa, P. H. G. Carvalho, and

V. L. Alves. Cadeias de markov.

[5] A. Hinojosa and A. Milan´es. Uma introdu¸c˜ao aos processos estoc´asticos com

aplica¸c˜oes, departamento de estat´ıstica. ICEx. UFMG.

[6] E. L. Lima. Curso de An´alise, vol. 2. Instituto de Matem´atica Pura e Aplicada,

1976.

[7] E. L. Lima, P. C. P. Carvalho, E. Wagner, and A. Morgado. A matem´atica do ensino
m´edio, volume 2 of COLEC¸ ˜AO DO PROFESSOR DE MATEM ´ATICA. Instituto de
Matem´atica Pura e Aplicada, 2016.

[8] E. L. Lima, P. C. P. Carvalho, E. Wagner, and A. Morgado. A matem´atica do ensino
m´edio, volume 3 of COLEC¸ ˜AO DO PROFESSOR DE MATEM ´ATICA. Instituto de
Matem´atica Pura e Aplicada, 2016.

[9] M. N. Magalh˜aes. Probabilidade e vari´aveis aleat´orias. Edusp, 2006.

[10] G. Modica and L. Poggiolini. A ﬁrst course in probability and Markov Chains. Wiley

Online Library, 2013.

[11] P. A. Morettin and W. O. BUSSAB. Estat´ıstica b´asica. Editora Saraiva, 2017.

60

61

[12] A. C. d. O. Morgado, J. B. P. d. Carvalho, P. C. P. Carvalho, and P. Fernandez.

An´alise combinat´oria e probabilidade.

Instituto de Matem´atica Pura e Aplicada,

1991.

[13] J. R. Norris. Markov chains. Number 2. Cambridge university press, 1998.

[14] J. I. D. Pinheiro, S. B. d. Cunha, S. R. Carvajal, and G. C. Gomes. Estat´ıstica b´asica:

a arte de trabalhar com dados. Elsevier: Campus, 2009.

[15] N. Privault. Understanding Markov Chains: Examples and Applications. Springer,

2013.

Universidade Federal do Recˆoncavo da Bahia - UFRB

Centro de Ciˆencias Exatas e Tecnol´ogicas / Mestrado Proﬁssional em Matem´atica

em Rede Nacional

Rua Rui Barbosa, s/n, Campus Universit´ario de Cruz das Almas - BA

CEP: 44380 -000

<http://www.ufrb.edu.br/profmat>

<http://www.profmat-sbm.org.br>


UNIVERSIDADE TECNOLÓGICA FEDERAL DO PARANÁ - UTFPR
MESTRADO PROFISSIONAL EM MATEMÁTICA EM REDE NACIONAL -
PROFMAT

WILLIAN BURGARDT DE SOUZA

MÉTODO DOS MÍNIMOS QUADRADOS APLICADO A UM PROBLEMA DE
GEOPOSICIONAMENTO

CURITIBA

2018

WILLIAN BURGARDT DE SOUZA

MÉTODO DOS MÍNIMOS QUADRADOS APLICADO A UM PROBLEMA DE
GEOPOSICIONAMENTO

Dissertação apresentada ao Mestrado Proﬁssional em
Matemática em Rede Nacional da Universidade Tec-
nológica Federal do Paraná em Curitiba - PROFMAT-
UTCT como requisito parcial para obtenção do grau
de Mestre.
Orientadora: Denise de Siqueira
Coorientador: Rodolfo Gotardo Begiato

CURITIBA

2018

                                              Dados Internacionais de Catalogação na Publicação  S729m    Souza, Willian Burgardt de 2018        Método dos mínimos quadrados aplicado a um problema          de geoposicionamento / Willian Burgardt de Souza.--          2018.             51 f.: il.; 30 cm.              Disponível também via World Wide Web.             Texto em português com resumo em inglês.             Dissertação (Mestrado) - Universidade Tecnológica           Federal do Paraná. Programa de Mestrado Profissional em          Matemática em Rede Nacional, Curitiba, 2018.              Bibliografia: f. 51.              1. Sistemas lineares. 2. Mínimos quadrados. 3. Álgebra           linear. 4. Sistema de posicionamento global. 5. Solução           de problemas. 6. Matemática - Estudo e ensino. 7.           Matemática - Dissertações. I. Siqueira, Denise de, orient.           II. Begiato, Rodolfo Gotardi, coorient. III. Universidade          Tecnológica Federal do Paraná. Programa de Mestrado           Profissional em Matemática em Rede Nacional. IV. Título.                                                CDD: Ed. 23 – 510  Biblioteca Central do Câmpus Curitiba – UTFPR Bibliotecária: Luiza Aquemi Matsumoto CRB-9/794         Ministério da Educação Universidade Tecnológica Federal do Paraná Diretoria de Pesquisa e Pós-Graduação     TERMO DE APROVAÇÃO DE DISSERTAÇÃO Nº 48  A Dissertação de Mestrado intitulada Método dos mínimos quadrados aplicado a um problema de geoposicionamento, defendida em sessão pública pelo(a) candidato(a) Willian Burgardt de Souza, no dia 08 de fevereiro de 2018, foi julgada para a obtenção do título de Mestre, área de concentração Matemática, e aprovada em sua forma final, pelo Programa de Pós-Graduação em Matemática em Rede Nacional.  BANCA EXAMINADORA:  Prof(a). Dr(a). Denise Siqueira - Presidente - UTFPR Prof(a). Dr(a). Rodrigo Garcia Eustáquio - UTFPR Prof(a). Dr(a). Mael Sachine - UFPR  A via original deste documento encontra-se arquivada na Secretaria do Programa, contendo a assinatura da Coordenação após a entrega da versão corrigida do trabalho.  Curitiba, 08 de fevereiro de 2018.    Carimbo e Assinatura do(a) Coordenador(a) do Programa AGRADECIMENTOS

Aos professores do programa, agradeço por todo incentivo e conselhos, de ordem pro-
ﬁssional ou pessoal. Em especial, a minha orientadora professora Denise de Siqueira, por todo
o auxílio e compreensão, assim como ao meu orientador Rodolfo Gotardo Begiato, que não
poderiam ter sido melhores aliados durante a elaboração deste trabalho.

A minha família agradeço todo tipo de apoio que oportunizou estes estudos desde o
início. Em especial, ao meu pai e ao meu sogro por todo suporte. A minha esposa Ariel Marczaki,
que sempre me apoiou e auxiliou nos momentos mais difíceis.

Aos membros da banca examinadora pelas sugestões e contribuições, que auxiliaram

neste trabalho.

À CAPES pelo apoio ﬁnanceiro, através de bolsa de estudos, à minha pesquisa.

RESUMO

SOUZA, Willian Burgardt. Método dos mínimos quadrados aplicado a um problema de
geoposicionamento. 47 f. Dissertação - Programa de Mestrado Proﬁssional em Matemática em
Rede Nacional - PROFMAT, Universidade Tecnológica Federal do Paraná. Curitiba, 2018.

O objetivo deste trabalho é apresentar o método dos mínimos quadrados para resolver sistemas
lineares sobredeterminados, ou seja, sistemas da forma Ax = b, em que Am×n, com m > n.
Neste sentido, veremos como a resolução destes sistemas estão relacionados com encontrar a
projeção ortogonal b sobre o subespaço gerado pelas colunas de A. Este tipo de sistema é usado
ainda para modelar um problema de geoposicionamento, cujo objetivo é determinar a posição de
um receptor que recebe o sinal de vários satélites.

Palavras-chave: Sistemas Lineares. Mínimos Quadrados. Geoposicionamento.

ABSTRACT

SOUZA, Willian Burgardt. Least square method applied to a geo-positioning problem. 47
pg. Dissertation - Programa de Mestrado Proﬁssional em Matemática em Rede Nacional -
PROFMAT, Universidade Tecnológica Federal do Paraná. Curitiba, 2018

The main goal of this work is to present the least squares method to solve overdetermined linear
systems, that is, systems of the form Ax = b, where Am×n , with m > n. In this sense, we
showed that the resolution of these systems is related to the orthogonal projection problem of b
on the subspace generated by the columns of A. This type of system is used to model a problem
of geo-positioning, whose objective is to determine the position of a receiver that receives the
signal from several satellites.

Keywords: Linear System. Least Square Method. Geo-positioning.

LISTA DE ILUSTRAÇÕES

Figura 1 – Imagem b = Ax para dois vetores do R2 . . . . . . . . . . . . . . . . . . .
Figura 2 – Ação de A sobre os vetores deﬁdos em um quadrado unitário . . . . . . . .
Figura 3 – Representação de Im(A) e N (A) . . . . . . . . . . . . . . . . . . . . . . .
Figura 4 – Representação do N (A) . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 5 – Ilustrações de B[0, 1] utilizando diferentes normas . . . . . . . . . . . . . .
Figura 6 – Ilustração da norma 2 de matrizes . . . . . . . . . . . . . . . . . . . . . . .
Figura 7 – Ilustração da norma 1 de matrizes . . . . . . . . . . . . . . . . . . . . . . .
Figura 8 – Representação dos conjuntos S e S⊥ . . . . . . . . . . . . . . . . . . . . .
Figura 9 – Projeção do vetor u sobre o vetor v . . . . . . . . . . . . . . . . . . . . . .
Figura 10 – Projeção de u sobre v . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 11 – Projeção do vetor u sobre S . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 12 – Representação da superfície esférica de centro (a, b, c)
. . . . . . . . . . .
Figura 13 – Representação da interseção de duas superfícies esféricas de centros (a1, b1, c1)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 14 – Representação da interseção de três superfícies esféricas de centros (a1, b1, c1),
. . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 15 – Localização do receptor com 4 satélites . . . . . . . . . . . . . . . . . . . .
Figura 16 – Representação da posição real do receptor
. . . . . . . . . . . . . . . . . .
Figura 17 – Representação dos sinais “multi-path” . . . . . . . . . . . . . . . . . . . .

(a2, b2, c2), e (a3, b3, c3)

e (a2, b2, c2) .

.

.

.

21
22
23
24
27
29
29
32
33
34
35
44

45

45
47
49
50

SUMÁRIO

INTRODUÇÃO .

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

FUNDAMENTAÇÃO TEÓRICA . . . . . . . . . . . . . . . . . . . . . .

Espaços e subespaços vetoriais
Base e dimensão .
Norma de Vetores
Ortogonalidade .

. . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.

.

SISTEMAS SOBREDETERMINADOS . . . . . . . . . . . . . . . . . .

Projeção Ortogonal
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
Projeção de um vetor sobre outro vetor
Projeção de um vetor sobre um subespaço . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Mínimos quadrados

APLICAÇÃO .

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Sistema de Geoposicionamento por Satélite . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . .
Determinando a distância entre o satélite e o receptor

17

17
24
26
29

33

33
33
34
39

43

43
43

CONCLUSÃO .

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

REFERÊNCIAS .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

53

1

1.1
1.2
1.3
1.4

2

2.1
2.1.1
2.1.2
2.2

3

3.1
3.2

4

INTRODUÇÃO

9

O uso de sistemas lineares é empregado na resolução de diversos tipos de problemas
dentro da Matemática. No caso de sistemas lineares sobredeterminados, ou seja, sistemas lineares
com mais equações do que incógnitas, em geral, ou o sistema possui inﬁnitas soluções ou não
possui nenhuma solução. Este trabalho estudará o segundo caso, em que o sistema não possui
solução e neste caso o método dos mínimos quadrados é empregado para encontrar uma "solução
aproximada".

O método dos mínimos quadrados consiste em determinar uma aproximação para o

sistema de forma a tornar o resíduo o menor possível.

Ao longo deste trabalho, serão explorados todos os conceitos necessários para estabelecer

uma sistemática de resolução deste tipo de problema.

Como aplicação dos resultados teóricos estabelecidos é apresentado um problema de
geoposicionamento, ou seja, o objetivo é determinar a posição de um receptor em um sistema
de geoposicionamento global. Como exemplo deste tipo de sistema, o mais conhecido é o GPS
(Global Positioning System), traduzido do inglês como Sistema de Posicionamento Global.

Para isso este trabalho está assim dividido:

No Capítulo 1 são apresentados os conceitos básicos da álgebra linear, fundamentais
para o desenvolvimento do trabalho, explorando as ideias de espaços e subespaços vetoriais,
base e dimensão de um subespaço vetorial, norma de vetores e por ﬁm ortogonalidade.

O Capítulo 2 inicia com as principais propriedades de projeção ortogonal e posteri-
ormente, é apresentado o método dos mínimos quadrados, objeto principal de estudo deste
trabalho.

Por ﬁm, no Capítulo 3 é apresentado um sistema de geoposicionamento por satélite
(GPS) explicando o seu funcionamento de forma breve e desenvolvendo um modelo matemático
para determinar a posição de um receptor, com base nas informações obtidas pelos satélites.

1 FUNDAMENTAÇÃO TEÓRICA

10

O objetivo deste capítulo é apresentar uma revisão dos conceitos da álgebra linear que
serão abordados neste trabalho. Sempre que necessário será apresentado um exemplo para ilustrar
algum conceito. Todos os resultados apresentados aqui foram consultados em (GOLUB; LOAN,
1996), (LIMA, 2009), (MEYER, 2000), (STRANG, 2009) e (TREFETHEN; III, 1997).

1.1 ESPAÇOS E SUBESPAÇOS VETORIAIS

A noção de espaço vetorial será de grande importância para o estudo apresentado aqui.
Esta seção apresentará resultados sobre espaços, subespaços, espaço linha, espaço coluna, núcleo
e imagem, além de apresentar exemplos para ilustrar esses assuntos. Ainda será dada uma atenção
especial ao espaço das matrizes.

Deﬁnição 1.1. Um espaço vetorial V é um conjunto munido das operações de adição e multipli-
cação por escalar, em que dados u, v ∈ V e α, β ∈ R tem-se que αu + v ∈ V e satisfaz as
seguintes propriedades:

1. comutatividade: u + v = v + u;

2. associatividade: (u + v) + w = u + (v + w) e (αβ)v = α(βv) ;

3. elemento neutro da adição: existe um vetor 0 ∈ V , chamado de vetor nulo, tal que

v + 0 = 0 + v = v para todo v ∈ V ;

4. inverso aditivo: para cada vetor v ∈ V existe um vetor −v ∈ V chamado o inverso

aditivido, ou o simétrico de v tal que −v + v = v + (−v) = 0;

5. distributividade: (α + β)v = αv + βv e α(u + v) = αu + αv;

6. elemento neutro da multiplicação: 1 · v = v.

Exemplo 1.2. O conjunto Rn = {(x1, x2, . . . , xn) | x1, x2, . . . , xn ∈ R} munido das operações
usuais de adição e multiplicação por escalar é um espaço vetorial.
O elemento neutro da adição em Rn é o vetor 0 = (0, 0, . . . , 0) e o elemento neutro da
multiplicação é o escalar 1.

Exemplo 1.3. O conjunto Mm×n de todas as matrizes m × n munidos da operação de adição
([aij] + [bij] = [aij + bij]) e da operação de multiplicação por escalar (α[aij] = [αaij]) com
i = 1, . . . , m e j = 1, . . . , n, é um espaço vetorial. Neste caso, o elemento neutro da adição
em Mm×n é a matriz m × n em que todos os seus elementos são nulos, o elemento neutro da
multiplicação é o escalar 1 e o inverso aditivo da matriz [aij] é a matriz [−aij].

11

A partir deste momento sempre que for citado o conjunto Mm×n trata-se do conjunto das

matrizes m × n descrito conforme o Exemplo 1.3.

Muitas vezes necessitamos trabalhar com subconjuntos de um espaço vetorial. Estes
subconjuntos, munidos de algumas propriedades dão origem ao que chamamos de subespaços
vetoriais.

Deﬁnição 1.4. Seja V um espaço vetorial e W um subconjunto não vazio de V. Dizemos que W
é um subespaço vetorial de V se, dados u, v ∈ W e α ∈ R as seguintes propriedades forem
satisfeitas:

1. 0 ∈ W ,

2. u + αv ∈ W .

Note que o subconjunto W satisfaz todas as propriedades de espaço vetorial, sendo ele

próprio um espaço vetorial.

Exemplo 1.5. Seja S = {x ∈ Rn | Ax = 0} um subconjunto de Rn com A ∈ Mm×n. S assim
deﬁnido é um subespaço vetorial de Rn. De fato, observe inicialmente que 0 ∈ S, pois A0 = 0.
Além disso, dados x1, x2 ∈ S e α ∈ R, tem-se que

A(x1 + αx2) = A(x1) + A(αx2)

= A(x1) + αA(x2)

= 0 + α0

= 0.

Portanto S é um subespaço vetorial de Rn.

Exemplo 1.6. Seja S = {x ∈ Rn | Ax = b, b 6= 0} um subconjunto de Rn com A ∈ Mm×n.
S assim deﬁnido não é um subespaço vetorial de Rn, pois dados x1, x2 ∈ S, tem-se que

A(x1 + x2) = Ax1 + Ax2

= 2b /∈ S.

Exemplo 1.7. Seja V = M2×3 e S = {A ∈ V | aj,3 = 1, j = 1, 2}. S não é um subespaço
vetorial de V pois 02×3 /∈ S.

Uma das características de um espaço vetorial é que ele pode ser caracterizado por
somente uma parte de seus vetores. Nos casos em que trabalharemos ele pode ser caracterizado
por um conjunto ﬁnito de vetores. Veremos a seguir como fazer essa caracterização.

Deﬁnição 1.8. O vetor u é dito ser combinação linear de u1, · · · , un se existem escalares
α1, · · · , αn tais que

u = α1u1 + · · · + αnun =

αiui.

n
X

i=1

12

Deﬁnição 1.9. Sejam V um espaço vetorial e X ⊂ V um conjunto não vazio. O conjunto de
todas as combinações lineares de X é chamado espaço gerado por X e denotado por [X]. Ou
seja

[X] = {u ∈ V |u = α1u1 + · · · + αnun =

n
X

i=1

αiui, onde u1, · · · , un ∈ X e α1, · · · , αn ∈ R}.

Neste caso, dizemos que X é o conjunto gerador de [X].

Exemplo 1.10. Seja e1 = (1, 0, 0), e2 = (0, 1, 0), e3 = (0, 0, 1), u = (a, b, c) ∈ R3 e
α1, α2, α3 ∈ R. Os vetores e1, e2, e3 geram o R3. De fato, a equação vetorial

α1(1, 0, 0) + α2(0, 1, 0) + α3(0, 0, 1) = (a, b, c)

ou ainda

tem solução α1 = a, α2 = b, α3 = c. Portanto e1, e2, e3 geram o R3.

(α1, α2, α3) = (a, b, c)

(1.1)

(1.2)

Proposição 1.11. Sejam V um espaço vetorial e X ⊂ V um conjunto não vazio. O espaço
gerado por X é um subespaço vetorial.

Demonstração.

1. 0 ∈ [X]. De fato, dado v ∈ X temos que 0 = 0v.

2. u + αv ∈ [X]. De fato, dados u, v ∈ [X] temos que existem u1, · · · , un ∈ X e
α1, · · · , αn, β1, · · · βn ∈ R tais que u = α1u1 + · · · + αnun e v = β1u1 + · · · + βnun.
Assim, u + αv = (α1 + αβ1)u1 + · · · + (αn + αβn)un ∈ [X]

deﬁna

Aﬁm de explorar um pouco mais os espaços das matrizes considere o conjunto Mm×n e

a1 =











a1 1
a2 1
...
am 1











, a2 =











a1 2
a2 2
...
am 2











, · · · , an =











a1 n
a2 n
...
am n











(1.3)

os vetores formados pelas colunas de A ∈ Mm×n. Logo a matriz A pode ser reescrita como

(cid:16)

A =

a1 a2

· · · an

(cid:17)

.

(1.4)

Tome agora o conjunto de todas as combinações lineares das colunas de A, a este

conjunto denotamos de C(A),

C(A) =

( n
X

i=1

αiai | αi ∈ R, ai ∈ Rm

)

.

(1.5)

13

C(A) assim deﬁnido é um subspaço vetorial de Rm. Este subespaço é chamado de espaço
coluna de A.

Do mesmo modo deﬁnindo

(cid:16)

a1 =

a1 1 a1 2

· · · a1 n

(cid:17)

, · · · , am =

(cid:16)

am 1 am 2

· · · am n

(cid:17)

(1.6)

os vetores formados pelas linhas de A ∈ Mm×n, tem-se que A pode ser reescrita como

A =











a1
a2
...
am











.

De modo análogo a (1.5) deﬁne-se espaço linha da matriz A por

L(A) =

( m
X

i=1

αiai | αi ∈ R, ai ∈ Rn

)

.

Observe que L(A) é um subespaço de Rn.

Exemplo 1.12. Dada a matriz





A =





1 3 3
2 4 6

o espaço coluna de A é formado por todos os vetores da forma



v = α1




 + α2






 + α3






 .

3
6

3
4

1
2

O espaço linha de A é formado por todos os vetores da forma

(cid:16)

v = α1

1 3 3

(cid:17)

(cid:16)

+ α2

2 4 6

(cid:17)

,

com α1, α2 ∈ R.

(1.7)

(1.8)

(1.9)

(1.10)

(1.11)

Outros dois subespaços de grande importância para o nosso estudo são o núcleo e a

imagem de uma matriz.

Deﬁnição 1.13. Dada a matriz A ∈ Mm×n deﬁne-se

Im(A) = {b ∈ Rm | Ax = b, x ∈ Rn} .

(1.12)

Note que se x = (α1, . . . , αn) com α1, . . . , αn ∈ R e A ∈ Mm×n então Ax é o conjunto
de todas as combinações lineares das colunas de A, ou seja, Im(A) = C(A). Assim sendo,

Im(A) é gerada pelas colunas de A,

(cid:16)

b =

a1 a2

· · · an

(cid:17)





















α1
α2
· · ·
αn

=

(cid:16)

(cid:17)

α1 +

(cid:17)

(cid:16)

a2

a1

α2 + · · · +

(cid:17)

(cid:16)

an

αn ∈ C(A).

Deﬁnição 1.14. Dada a matriz Am×n deﬁne-se

N (A) = {x ∈ Rn | Ax = 0} .

14

(1.13)

(1.14)

(1.15)

Os próximos exemplos ilustram estes subespaços.

Exemplo 1.15. Considere A =





−1 0
1
0


. A Im(A) = R2. De fato, Im(A) é gerada por





−1
0


,





0
1


 e, dado (a, b) ∈ R2





a
b


 = (−a)





−1
0


 + b






 .

0
1

A Figura 1 ilustra a imagem de dois vetores após a aplicação da matriz A.

Figura 1 – Imagem b = Ax para dois vetores do R2

O N (A) é o conjunto formado por todos os vetores x = (x1, x2)T tais que





−1 0
1
0









x1
x2


 =






 .

0
0

(1.16)

Desta forma N (A) = {(0, 0)T }.

Exemplo 1.16. Considere A =





1 1
1 3


. A Im(A) = R2. De fato, Im(A) é gerada por


,









1
1

1
3


 e, dado (a, b) ∈ R2

15


 =





a
b

(3a − b)
2


 +





1
1

(b − a)
2


 .





1
3

A Figura 2 ilustra a ação da matriz A sobre os vetores deﬁnidos em um quadrado

unitário.

Figura 2 – Ação de A sobre os vetores deﬁdos em um quadrado unitário

O N (A) é o conjunto formado por todos os vetores x = (x1, x2)T tais que





1 1
1 3









x1
x2


 =






 .

0
0

(1.17)

Desta forma N (A) = {(0, 0)T }.

Exemplo 1.17. Considere A =





1 2
2 4


. Im(A) não gera R2, por exemplo (1, 1)T não é

gerado pois

C(A) = α


 + β









1
2

2
4


 = (α + 2β)






 .

1
2

Logo C(A) são todos os múltiplos de


 conforme ilustrado na Figura 3.





1
2

16

Além disso, N (A) é o conjunto formado por todos os vetores x = (x1, x2)T tais que





1 2
2 4









x1
x2


 =






 .

0
0

(1.18)

Desta forma N (A) = {x2(−2, 1)T | x2 ∈ R}. Assim N (A) é gerado por (−2, 1)T conforme
ilustra a Figura 3.

Figura 3 – Representação de Im(A) e N (A)

Exemplo 1.18. Considere A =

C(A) = a


 + b









1
2





0
1

1 0 2
2 1 6


 + c





Logo Im(A) é gerado por


,









1
2


.

0
1


. A Im(A) = R2. De fato, dado a, b, c ∈ R,


 = (a + 2c)






 + (b + 2c)






 .

0
1

1
2

2
6

O N (A) é o conjunto formado por todos os vetores x = (x1, x2, x3)T tais que





1 0 2
2 1 6



















x1
x2
x3





=


 .

0
0

(1.19)

Desta forma N (A) = {(−2x3, −2x3, x3)T : x3 ∈ R} ou seja, N (A) são todos os vetores que
estão sobre a reta gerada por v = (−2, −2, 1)T conforme Figura 4.

17

Figura 4 – Representação do N (A)

1.2 BASE E DIMENSÃO

Os espaços vetoriais de dimensão ﬁnita possuem uma estrutura algébrica que pode ser
evidenciada pelas ideias de base e dimensão. Determinada uma base para um espaço vetorial,
seus elementos são meras combinações lineares dos vetores que compõem a base. Nesta seção
serão apresentados as deﬁnições de base e dimensão mas para isso vejamos os conceitos de
dependência e independência linear.

Deﬁnição 1.19. Seja X = {v1, v2, · · · , vn} um subconjunto de um espaço vetorial V . Dizemos
que X é linearmente independente (abreviadamente L.I.) se α1v1 + · · · + αnvn = 0 implicar
que αi = 0 para todo i = 1, · · · , n. Se um conjunto não for L.I. dizemos que ele é linearmente
dependente (abreviadamente L.D.).

Exemplo 1.20. Seja S ⊂ R3 deﬁnido por S = {(1, 2, 3)T , (4, 5, 6)T , (7, 8, 9)T }. S assim
deﬁnido é um conjunto L.D. De fato, (7, 8, 9)T + (1, 2, 3)T + (−2)(4, 5, 6)T = (0, 0, 0)T .

Exemplo 1.21. Seja S ⊂ R3 deﬁnido por S = {(1, 2, 3)T , (4, 5, 6)T , (1, 8, 9)T }. S assim
deﬁnido é um conjunto L.I.. Veriﬁcar que este conjunto é L.I. é equivalente a resolver o sistema








1 4 1
2 5 8
3 6 9






















=








.








0
0
0

α1
α2
α3

(1.20)

Resolvendo o sistema, percebe-se que temos solução única α1 = α2 = α3 = 0, o que indica que
o conjunto é L.I..

Observe que se considerarmos uma matriz A, cujas colunas são formadas pelos vetores

ai, dizer que as colunas de A são L.I. é equivalente a dizer que

α1a1 + · · · + αnan = 0

tem solução única αi = 0 para todo i = 1, · · · , n. Ou seja, o sistema

18








A








α1
...
αn

= 0

deve ter solução única αi = 0 para todo i = 1, · · · , n, o que nos indica que o núcleo da matriz A
deve conter somente o vetor nulo.

Deﬁnição 1.22. Uma base de um espaço vetorial V é um conjunto X ⊂ V linearmente inde-
pendente que gera V .

Proposição 1.23. Se o espaço vetorial V admite uma base com n elementos, qualquer outra
base de V conterá também n elementos.

Demonstração. Ver (LIMA, 2009), pag. 30, Corolário 2.

Dessa maneira, se X é uma base de V então o número de elementos de X é a chamada

dimensão de V , denotada por dim(V ).

Seja A ∈ Mm×n, denominamos de posto coluna de A a dimensão do espaço coluna de
A, ou seja, dim(C(A)). Observe portanto que dim(C(A)) ≤ n. Do mesmo modo, denominamos
de posto linha de A a dimensão do espaço linha da matriz A, ou seja, dim(L(A)) e neste caso
dim(L(A)) ≤ m.

Teorema 1.24. Dada uma matriz A ∈ Mm×n tem-se que o posto linha é igual ao posto coluna.

Demonstração. Seja p o posto coluna de A ∈ Mm×n, logo existem vetores {w1, w2, · · · , wp}
que formam uma base para C(A). Além disso denotamos cada wk por,

wk =











w1 k
w2 k
...
wm k











.

Sendo assim para cada aj ∈ C(A) com j = 1, · · · , n tem-se

aj = αj 1w1 + αj 2w2 + · · · + αj pwp.

(1.21)

Tomando a i-ésima coordenada de cada elemento de (1.21) temos que

ai 1 = α1 1wi 1 + α1 2wi 2 + · · · α1 pwi p

ai 2 = α2 1wi 1 + α2 2wi 2 + · · · α2 pwi p

... =

...

ai n = αn 1wi 1 + αn 2wi 2 + · · · αn pwi p

19

Observe com isso que, para cada elemento da linha de A, ai = (ai 1
escrito como,

ai 2 · · · ai n) pode ser

ai = wi 1











α1 1
α2 1
...
αn 1











+ wi 2











α1 2
α2 2
...
αn 2











+ · · · + wi p











α1 p
α2 p
...
αn p











,

(1.22)

ou seja, as linhas de A são geradas por vetores da forma αk = (α1 1, α2 1, · · · , αnk)T , com
k = 1, · · · , p. Assim dim(L(A)) ≤ p e portanto p = dim(C(A)) ≥ dim(L(A)).

Repetindo este mesmo processo na matriz AT , como as colunas de AT são as linhas de A,
é possível mostrar que dim(C(AT )) = dim(L(A)) ≥ dim(L(AT )) = dim(C(A)) e portanto o
resultado segue.

Por ﬁm deﬁnimos o posto de uma matriz denotado por ρ(A), como sendo dim(C(A))

(ou dim(L(A))). Observe portanto que ρ(A) ≤ min{m, n}.

Observe que tanto no Exemplo 1.15 quanto no Exemplo 1.18 vale ρ(A) = dim(Im(A)) =

2, visto que as matrizes A desses exemplos possuem duas colunas L.I..

1.3 NORMA DE VETORES

Os vetores desempenham um papel importante na matemática e na física. Através deles
podemos representar velocidade, aceleração ou as forças que agem sobre um objeto por exemplo.
Nesta seção será apresentada a deﬁnição e os principais tipos de norma de vetor. Além disso será
deﬁnida norma de matrizes e sempre que possível serão apresentadas ilustrações para facilitar o
entendimento.

Deﬁnição 1.25. Dados u = (u1, . . . , un)T , v = (v1, . . . , vn)T ∈ Rn, o produto interno usual
do Rn é a função < ·, · >: Rn × Rn → R deﬁnida por

hu, vi = u1 · v1 + . . . + un · vn.

(1.23)

Deﬁnição 1.26. Dado x ∈ Rn, a norma usual de Rn é a função k·k : Rn → R deﬁnida por
kxk =

hx, xi.

q

Note que a norma satisfaz as seguintes propriedades:

1. kxk ≥ 0, ∀ x ∈ Rn e kxk = 0 se e somente se x = 0,

2. kx + yk ≤ kxk + kyk , ∀ x, y ∈ Rn,

20

3. kαxk = |α| kxk , α ∈ R, ∀x ∈ Rn.

É possível deﬁnir ainda outras normas em Rn, as mais usuais são as chamadas normas p,

em que dado x = (x1, x2, · · · , xn)T ,

kxkp = (|x1|p + · · · + |xn|p)

1
p ,

p ≥ 1.

(1.24)

Vejamos alguns casos:

1. p = 1, kxk1 = |x1| + |x2| + · · · + |xn|

2. p = 2, kxk2

2 = |x1|2 + |x2|2 + · · · + |xn|2

3. p = 3, kxk3

3 = |x1|3 + |x2|3 + · · · + |xn|3

4. p = ∞, kxk∞ = max1≤i≤n |xi|

Observação 1.27. Quando p=2 temos a norma usual.

Aﬁm de ilustrar geometricamente algumas das p- normas , considere em R2 o seguinte

conjunto:

A Figura 5, ilustra este conjunto para diferentes escolhas de normas.

B[0, 1] = {x ∈ R2 : kxkp ≤ 1}.

Figura 5 – Ilustrações de B[0, 1] utilizando diferentes normas

Como existem diferentes tipos de normas é importante nos questionarmos sobre qual
delas devemos escolher para solucionar um determinado problema. Para isso, o conceito de
equivalência de norma é importante.

21

Deﬁnição 1.28. Dadas k·kα e k·kβ normas, dizemos que k·kα e k·kβ são equivalentes se existem
constantes positivas, c1 e c2 tais que:

c1 kxkα ≤ kxkβ ≤ c2 kxkα .

Exemplo 1.29. Seja v = (1, −2, 3)T um vetor de R3. Assim temos que:

kvk1 = |1| + | − 2| + |3| = 6
12 + (−2)2 + 32 =
kvk2 =

q

√

14.

Observe que, tomando c1 = 0 e c2 = 1 tem-se que

√

0 · 6 ≤

14 ≤ 1 · 6.

O que ilustra a equivalência das normas k·k1 e k·k2 em R3.

(1.25)

(1.26)

(1.27)

(1.28)

O exemplo anterior ilustra um resultado mais geral no qual aﬁrma que em Rn todas as
normas são equivalentes, logo a escolha da norma pode ser tomada da forma mais conveniente,
de acordo com o problema abordado.

Para o espaço das matrizes Mm×n é possível deﬁnir as seguintes normas:

i) Norma de Frobenius

ii) Norma p

kAkF =

v
u
u
t

m
X

n
X

i=1

j=1

|aij|2

kAkp = sup
kxk=1

kAxkp

(1.29)

(1.30)

Aﬁm de ilusrar o comportamento da norma do espaço de matriz considere o seguinte

exemplo.

Exemplo 1.30. Seja A2×2 dada por

A =





1 1
0 1


 ,

(1.31)

u = (x1, x2)T ∈ R2. Logo kAk2 = supkuk=1 kAuk2. Observe que se kuk2 = 1 então o vetor u
está sobre a circunferência centrada na origem de raio 1, conforme ilustrado na Figura 6 (a).
Ao calcular Au o que se espera é a ação de A sobre cada vetor nesta circunferência. O que
pode ser visto na Figura 6 (b). Logo, neste caso kAk2 representa o maior valor da ação de A
sobre os vetores do circulo unitário que é representado pelo maior semieixo da cônica.

Neste caso obtemos que kAk2 =

r

1
2

(cid:16)

3 +

√
(cid:17)
5

.

22

(a) Vetor unitário

(b) Ação da matriz A sobre os vetores unitários

Figura 6 – Ilustração da norma 2 de matrizes

(a) Vetores kuk1 = 1

(b) Ação da matriz A sobre os vetores unitários

Figura 7 – Ilustração da norma 1 de matrizes

Exemplo 1.31. Considere, ainda a matriz A do exemplo anterior, e vejamos a ilustração da
norma 1 da matriz, ou seja,

kAk1 = sup
kuk=1

kAuk1.

(1.32)

Observe que se kuk1 = 1 então o vetor u está deﬁnido conforme ilustrado na Figura 7
(a). Ao calcular Au obtemos um paralogramo conforme ilustrado na Figura 7 (b). Logo kAk1
representa, neste caso, o valor da maior semidiagonal do paralelogramo. Neste caso obtemos
que kAuk1 =

√

2.

1.4 ORTOGONALIDADE

Nesta seção serão apresentados os principais conceitos envolvendo ortogonalidade de
vetores, de conjuntos e de subespaços vetoriais. Além disso será deﬁnido complemento ortogonal

23

de um subespaço vetorial.

Deﬁnição 1.32. Dados, V um espaço vetorial, u e v vetores de V , diz-se que u e v são
ortogonais se hu, vi = 0.

Deﬁnição 1.33. Um conjunto W = {v1, . . . , vn} ⊂ V é dito ortogonal quando seus elementos
são ortogonais dois a dois, isto é:

hvi, vji = 0,

∀ i, j = 1, . . . , n,

i 6= j

(1.33)

Exemplo 1.34. O conjunto A =
De fato, basta observar que

(1, −1, 0)T , (1, 1, 0)T , (0, 0, 1)T o
n

é um conjunto ortogonal.

h(1, −1, 0)T , (1, 1, 0)T i = 1 · 1 + (−1) · 1 + 0 · 0 = 0

h(1, −1, 0)T , (0, 0, 1)T i = 1 · 0 + (−1) · 0 + 0 · 1 = 0

h(1, 1, 0)T , (0, 0, 1)T i = 1 · 0 + 1 · 0 + 0 · 1 = 0.

O conceito de ortogonalidade também pode ser estendido para subespaços vetoriais.

Deﬁnição 1.35. Sejam, V um espaço vetorial, W1 e W2 subespaços de V . W1 e W2 são ditos
ortogonais se todo vetor v ∈ W1 é ortogonal a todo vetor w ∈ W2. Neste caso denota-se por
W1 ⊥ W2.

Observe que se W1 e W2 são ortogonais então W1 ∩ W2 = {0}.

Os próximos resultados estabelecem a ortogonalidade entre núcleo e imagem de uma

matriz A.

Proposição 1.36. Dada uma matriz Am×n, tem-se que o espaço linha de A é ortogonal ao N (A),
ou seja, L(A) ⊥ N (A).

Demonstração. Seja u ∈ L(A) de acordo com (1.8), u =

m
X

αi ai em que ai denota as linhas

da matriz A. Agora dado v ∈ N (A) tem-se que hai, vi = 0 para i = 1, · · · , m. Portanto

i=1

hu, vi = h

m
X

αi ai, vi

i=1
m
X

αi hai, vi

=

i=1
= 0.

Proposição 1.37. Dada uma matriz Am×n, tem-se que o espaço coluna de A é ortogonal ao
núcleo de AT , ou seja, C(A) ⊥ N (AT ).

Demonstração. Seja u ∈ C(A) de acordo com (1.5), u =

n
X

αi ai em que ai denota as colunas

da matriz A. Agora dado v ∈ N (AT ) tem-se que hai, vi = 0 para i = 1, · · · , n. Portanto

i=1

24

hu, vi = h

n
X

αi ai, vi

i=1
n
X

αi hai, vi

=

i=1
= 0.

Exemplo 1.38. Considere a matriz A deﬁnida por:

A =





1 2
2 4


 .

O N (A) é dado por todo vetor x = (x1, x2)T tal que





1 2
2 4









x1
x2


 =






 .

0
0

Assim tem-se que N (A) é todo vetor da forma x = (−2t, t)T , com t ∈ R. Além disso

note que os vetores linha de A são ortogonais ao núcleo. De fato

h(1, 2), (−2t, t)i = 1 · (−2t) + 2 · t = 0,

h(2, 4), (−2t, t)i = 2 · (−2t) + 4 · t = 0.

Assim vemos que o espaço linha de A é ortogonal a N (A).

Exemplo 1.39. Dada a matriz A deﬁnida por:

A =





1 3
2 6


 .

(1.34)

O N (AT ) é todo vetor da forma x = (x1, x2)T












1 2
3 6


 =






 .

0
0

x1
x2

Assim temos que o N (AT ) é formado por todo vetor da forma (−2x2, x2)T , com x2 ∈ R. Além
disso note que os vetores coluna de A são perpendiculares ao N (AT ). De fato:

h(1, 2), (−2x2, x2)i = 1 · (−2x2) + 2 · x2 = 0,

h(3, 6), (−2x2, x2)i = 3 · (−2x2) + 6 · x2 = 0.

Assim vemos que o espaço coluna de A é ortogonal a N (AT ).

25

Deﬁnição 1.40. Sejam V um espaço vetorial e S um subespaço de V . O complemento ortogonal
de S, denotado por S⊥ é deﬁnido por

S⊥ = {u ∈ V | hu, vi = 0, ∀ v ∈ S} .

(1.35)

Observe que S⊥ também é um subespaço de V . De fato, seja u1, u2 ∈ S⊥, ou seja,

hu1, vi = 0 e hu2, vi = 0 para v ∈ S, assim tem-se que

hu1 + αu2, vi = hu1, vi + αhu2, vi

= 0.

Exemplo 1.41. Seja S = {v ∈ R3 | v = (3α, α, 0)} com α ∈ R. O complemento ortogonal
de S é o conjunto formado por todos os vetores u = (x, y, z) tal que h(x, y, z), (3α, α, 0)i = 0.
Assim S⊥ = {(x, −3x, z) | x, z ∈ R}

Figura 8 – Representação dos conjuntos S e S⊥

2 SISTEMAS SOBREDETERMINADOS

26

Um sistema de equações lineares é um conjunto ﬁnito de equações lineares aplicadas a
um conjunto, também ﬁnito, de variáveis. O objetivo deste capítulo é explorar um método para
determinar uma solução para sistemas lineares sobredeterminados, ou seja, sistemas lineares em
que o número de equações é maior que o número de incógnitas. Para isso serão apresentadas as
principais deﬁnições relacionadas a projeção ortogonal e de matriz de projeção ortogonal para,
por ﬁm, aplicar na resolução de sistemas sobredeterminados através do método dos mínimos
quadrados.

2.1 PROJEÇÃO ORTOGONAL

Nesta seção serão apresentadas as ideias que envolvem projeção de um vetor sobre outro
vetor e projeção de um vetor sobre um subespaço de Rn. Posteriormente serão associados estes
resultados com matrizes de projeção, apresentando algumas propriedades importantes.

A partir deste momento, por simplicidade, será utilizada norma 2 e o produto interno

usual de Rn, salvo se menção em contrário.

2.1.1 PROJEÇÃO DE UM VETOR SOBRE OUTRO VETOR

Projetar um vetor u sobre um vetor v é determinar um vetor p pertencente à reta que

tem como vetor diretor u através de alguma relação, e é esta relação na qual temos interesse.

Aﬁm de ilustrar geometricamente a construção de uma projeção considere o seguinte
problema: Dados os vetores u e v em R2, encontrar um vetor p = α v com α ∈ R tal que u − p
seja ortogonal a v, como ilustra a Figura 9.

Figura 9 – Projeção do vetor u sobre o vetor v

Para determinar o valor de α observe que u − p é ortogonal a v, desta forma tem-se que:

0 = hu − p, vi

= hu, vi − αhv, vi.

Como v 6= 0 segue que α =

hu, vi
hv, vi

e portanto a projeção de u sobre v é dada por

p =

hu, vi
hv, vi

v.

27

(2.1)

(2.2)

(2.3)

Exemplo 2.1. Dados u = (2, 5) e v = (6, 4), a projeção ortogonal p de u sobre v é dada por:

p =

h(2, 5), (6, 4)i
h(6, 4), (6, 4)i

=

8
13

(6, 4).

(2.4)

Figura 10 – Projeção de u sobre v

2.1.2 PROJEÇÃO DE UM VETOR SOBRE UM SUBESPAÇO

O objetivo desta Seção é estabelecer a projeção de um vetor sobre um subespaço de
forma similar o que já foi descrito anteriormente. Para ilustrar esta situação considere o seguinte
problema: Dados o vetor u = (1, 1, 1)T e S um subespaço gerado pelos vetores v1 = (1, 2, 0)T
e v2 = (3, −1, 1)T encontrar a projeção ortogonal p de u sobre S.

Agora, como p ∈ S então p pode ser escrito como

p = α1v1 + α2v2

(2.5)

com αi ∈ R, i = 1, 2.

Observe que, para determinar a projeção p basta determinar os valores de αi ∈ R,

i = 1, 2. Para isso, note que u − p é ortogonal a S, então segue que






hu − p, v1i = 0
hu − p, v2i = 0.

(2.6)

Substituindo (2.5) no sistema (2.6) tem-se






hu, v1i − α1hv1, v1i − α2hv2, v1i = 0
hu, v2i − α1hv1, v2i − α2hv2, v2i = 0.

Tal sistema pode ser escrito na seguinte forma matricial

 =













hv1, v1i
hv1, v2i

hv2, v1i
hv2, v2i

α1
α2





hu, v1i
hu, v2i


 .

28

(2.7)

(2.8)

Pode-se provar que como os vetores v1 e v2 são linearmente independentes a matriz A dada pelo
lado esquerdo de (2.8) é não singular portanto, o sistema (2.8) tem única solução e é dada por

(cid:16)

p =

v1 v2

(cid:17)





hv1, v1i
hv2, v1i

hv1, v2i
hv2, v2i



−1 






 .

hu, v1i
hu, v2i

Aplicando os valores de u, v1 e v2 obtêm-se

p =








1
3
2 −1
1
0












1
5
1 11



−1 






 =

3
3








1
9








.

11
8
2

(2.9)

(2.10)

Figura 11 – Projeção do vetor u sobre S

Note que se adotarmos uma base ortonormal para S, o cálculo da projeção do vetor u
sobre S se torna mais simples. De fato, se {v1, v2} é ortonormal, tem-se que A = I e portanto a
projeção (2.9) ﬁca da forma:

(cid:16)

p =

v1 v2

(cid:17)






 ,

hu, v1i
hu, v2i

(2.11)

ou seja,

p = hu, v1iv1 + hu, v2iv2.

Exemplo 2.2. Seja u = ( 1, 1, 1)T e S o subspaço gerado por v1 =
(cid:16)
− 2
com (2.12) a projeção de u sobre S é dado por:

√
5
5 , 0

√
5
5 ,

(cid:17)T

(note que hv1, v2i = hv2, v1i = 0, hv1, v1i = 1 e hv2, v2i = 1). De acordo

29

(2.12)

e v2 =

(cid:16) √

√
5
5 , 0

5

5 , 2

(cid:17)T








+

p = hu, v1i








√

5
5
√

2

5

5
0

√
3

5

5








√

5
5
√

2

5

5
0















11
5
2
5
0








.

=

=

+ hu, v2i








√

5

−

5








√

−2
5√
5
5
0

5

√

−2
5√
5
5
0


5













(2.13)

(2.14)

(2.15)

Baseado nos exemplos apresentados, vamos estabelecer a projeção de um vetor u ∈ Rn
sobre um subespaço n-dimensional S gerado por {v1, · · · , vn}, vetores linearmente indepen-
dentes. Neste caso a projeção ortogonal é dada por,

p = α1v1 + · · · + αnvn.

(2.16)

Como o vetor u − p é ortogonal a S, então:

hu − p, vii = 0 ∀ i = 1, · · · , n,

(2.17)

ou ainda





hu − (α1v1 + · · · + αnvn), v1i = 0
...
hu − (α1v1 + · · · + αnvn), vni = 0.

O sistema (2.18) também pode ser escrito na forma matricial.








hv1, v1i · · · hvn, v1i
...
hv1, vni · · · hvn, vni















α1
...
αn















=








.

hu, v1i
...
hu, vni

.

(2.18)

(2.19)

30

O sistema (2.19) é chamado de sistema normal. É possível provar que a matriz do
sistema normal é simétrica e não singular, se as colunas da matriz A são L.I., portanto, neste
caso, o sistema admite única solução.

Aﬁm de caracterizar a solução do sistema observe que tomando A a matriz m × n cujas

colunas são formadas pelos vetores vi, com i = 1, · · · , n tem-se que:

AT A =








(cid:16)








v1
...
vn

v1

· · · vn

(cid:17)

=








hv1, v1i · · · hvn, v1i
...
hv1, vni · · · hvn, vni








e

AT u =















v1
...
vn

(cid:16)

(cid:17)

=

u








hu, v1i
...
hu, vni








.

Desta forma, tomando α = (α1, · · · , αn)T , o sistema (2.28) é equivalente à

AT Aα = AT u.

(2.20)

(2.21)

(2.22)

Como os vetores v1, · · · , vn são L.I. segue que AT A é não singular e portanto a solução

de (2.22) é dada por

α = (AT A)−1AT u.

Com isso tem-se que, a projeção ortogonal p é da forma

p = A(AT A)−1AT u.

(2.23)

(2.24)

A matriz P = A(AT A)−1AT é chamada de matriz de projeção ortogonal e assim a

projeção ortogonal toma a forma simpliﬁcada p = P u.

Note que, para fazer a projeção de qualquer vetor v ∈ Rn sobre S basta multiplicar a

matriz de projeção P por v. Além disso, a matriz P satisfaz as seguintes propriedades.

1.

P 2 = (A(AT A)−1AT )(A(AT A)−1AT )

= A(AT A)−1 (AT A)(AT A)−1
|
}

{z
I

AT

= A(AT A)−1AT

= P.

31

2.

P T = (A(AT A)−1AT )T

= (AT )T (A(AT A)−1)T

= A((AT A)T )−1AT

( AT A é simétrica)

= A(AT A)−1AT

= P.

Estas duas propriedades caracterizam a projeção ortogonal.

O próximo exemplo tem por objetivo caracterizar as projeções ortogonais em R2, para
isso tomaremos uma matriz simétrica A em R2 e estabeleceremos condições para que A2 = A.

Exemplo 2.3. Seja A =





a11 a12
a12 a22


 , logo A2 = A se e somente se





a11 a12
a12 a22









a11 a12
a12 a22


 =





a11 a12
a12 a22


 ,

ou seja,

a11

2 + a12

2 = a11

a12 · a11 + a22 · a12 = a12
2 = a22.
2 + a22

a12

(2.25)

(2.26)

(2.27)

(2.28)

De (2.27) tem-se que a12(a11 + a22 − 1) = 0 logo a12 = 0 ou a11 + a22 = 1.

1. Se a12 = 0 substituindo em (2.26) tem-se que a11 = 0 ou a11 = 1. Do mesmo modo
substituindo em (2.28) tem-se que a22 = 0 ou a22 = 1. Com isso obtemos as seguintes
matrizes de projeção ortogonal:





0 0
0 0


 ,





0 0
0 1


 ,





1 0
0 0


 ,





1 0
0 1


 .

(2.29)

2. Se a11 + a22 = 1 substituindo em (2.26) e (2.28) tem-se que a2

22 − a22 + a2

12 = 0, logo

a22 =

q

1 ±

1 − 4 · a2
12

2

.

Observe que (2.30) apenas faz sentido somente se

−

1
2

≤ a12 ≤

1
2

.

Portanto se

(2.30)

(2.31)

a) Se a22 =

q

1 +

1 − 4 · a2
12

2

então

a11 =

q

1 −

1 − 4 · a2
12

2

b) Se a22 =

q

1 −

1 − 4 · a2
12

2

então

a11 =

q

1 +

1 − 4 · a2
12

2

;

.

32

(2.32)

(2.33)

Com isso tem-se que em R2 uma matriz de projeção ortogonal devem ter seus coeﬁcientes

satisfazendo (2.30), (2.31), (2.32) e (2.33).

As matrizes abaixo são exemplos de matrizes de projeção ortogonal no caso em que
1
2

respectivamente.

e a12 = −

1
2

a12 =





1
2
1
2

1
2
1
2


 ,





1

2 − 1
− 1
2

1
2

2


 .

(2.34)

Dentre os assuntos abordados neste capítulo, a projeção ortogonal é de fundamental
importância para este trabalho. Na próxima Seção aplicaremos o estudo sobre projeção ortogonal
na resolução de sistemas sobredeterminados.

2.2 MÍNIMOS QUADRADOS

No início da Seção 2.1.2 vimos um exemplo em que o objetivo era encontrar a projeção
ortogonal de um vetor v sobre um subespaço S. Em termos de sistemas lineares o problema é
equivalente a encontrar x ∈ R2 tal que








|

3
1
2 −1
1
0

{z
A








}





x1
x2


 =















1
1
1
| {z }
b

.

(2.35)

Observe que ρ(A) = dim(C(A)) = 2, logo não é possível encontrar x ∈ R2 tal que
b ∈ R3 pertença a C(A). Este tipo de situação caracteriza os sistemas sobredeterminados. Neste
caso o que se pretende é encontrar x∗ ∈ C(A) de forma que Ax∗ esteja o mais próximo de b
possível, ou seja, resolver o problema

min
x∈C(A)

kAx − bk .

(2.36)

Vimos na Seção 2.1.2 que a projeção ortogonal de b sobre C(A) resolve o problema

(2.35). O próximo teorema garante que a projeção ortogonal resolve o problema (2.36).

Teorema 2.4. (Teorema da Aproximação) A projeção ortogonal P b ∈ C(A) é a mais próxima
de b do que qualquer outro elemento de C(A).

Demonstração. Seja P b a projeção ortogonal de b sobre C(A) e y ∈ C(A) um elemento
qualquer. Logo, como P b − y ∈ C(A) e b − P b ⊥ C(A)

33

kb − yk2 = kb − P b + P b − yk2

= kb − P bk2 + kP b − yk2
≥ kb − P bk2 .

Portanto P b resolve (2.36).

Como a projeção ortogonal resolve o problema de minimização e na Seção 2.1.2 resolve-
mos o problema (2.35) por meio das equações normais é de se esperar que para resolver (2.36)
basta resolvermos um sistema de equações normais, é o que aﬁrma o próximo resultado.

Teorema 2.5. Seja A uma matriz m × n. Então x∗ resolve (2.36) se e somente se x∗ resolve

AT Ax = AT b.

(2.37)

Demonstração. (⇒) Seja x∗ solução de (2.36), como Ax∗ ∈ C(A) e b − Ax∗ ⊥ C(A) segue
que b − Ax∗ ∈ C(A)⊥ = N (AT ), logo AT (b − Ax∗) = 0, ou seja, x∗ resolve (2.37).

(⇐) Seja x∗ a solução de (2.37), se mostrarmos que Ax∗ é a projeção ortogonal de b
sobre C(A) segue do Teorema 2.4 que x∗ resolve (2.36). Para isso deﬁna r(x) = b − Ax, logo

AT r(x∗) = AT (b − Ax∗) = 0,

ou seja, b − Ax∗ ∈ N (AT ) = C(A)⊥. Como Ax∗ ∈ C(A) e b − Ax∗ ⊥ C(A) segue que Ax∗
é a projeção ortogonal de b sobre C(A) e portanto, pelo Teorema 2.4, resolve (2.36).

Para garantir que (2.36) tenha uma única solução basta garantir que a matriz AT A seja

não singular.

Teorema 2.6. Se A é uma matriz m × n com m > n e o posto de A é n então AT A é não
singular.

Demonstração. Seja A uma matriz m × n com m > n de posto n, logo N (A) = 0, mostremos
que N (A) = N (AT A). De fato, seja x ∈ N (A), logo Ax = 0 e assim AT Ax = 0, ou seja,
x ∈ N (AT A).

Agora, dado x ∈ N (AT A) tem-se que AT (Ax) = 0, logo Ax ∈ N (AT ) = C(A)⊥.

Com isso temos que Ax ∈ C(A)⊥ ∩ C(A) = {0}, portanto x ∈ N (A).

34

Baseado nos resultados desta seção temos que dado um sistema Ax = b com Am×n e

m > n se posto de A é n o problema normal (2.37) tem única solução e é dada por

x∗ = (AT A)−1AT b.

(2.38)

O próximo exemplo ilustra os resultados apresentados ao longo desta Seção.

Exemplo 2.7. Considere o seguinte sistema











4 −2 1
1 −1 1
1
1
1
1
2
4

























x1
x2
x3

=











0
2
2
10











.

(2.39)

Denotando por A a matriz do sistema (2.39) , temos que ρ(A) = 3, e portanto o sistema normal








34
0
10

0
10
0

10
0
4






















x1
x2
x3








44
20
14








=

(2.40)

possui única solução e é dado por

x∗ =

=















34
0
10

0
10
0

10
0
4



−1 


















44
20
14








.

1
2
1

Neste caso kAx∗ − bk = 3.1622777.

Vimos ao longo deste capítulo que o método dos mínimos quadrados é uma importante
ferramenta para resolver sistemas sobredeterminados. Foram estabelecidos resultados que garan-
tem que, dado um sistema Ax = b com Am×n e m > n, a projeção ortogonal sobre o subespaço
gerado pelas colunas de A é a melhor aproximação para este problema, no sentido de minimizar
kAx − bk.

No próximo capítulo, aplicaremos os resultados aqui apresentados num problema de

geoposicionamento, que é modelado por um sistema sobredeterminado.

3 APLICAÇÃO

35

O objetivo deste capítulo é aplicar os assuntos vistos anteriomente em um problema de
geoposicionamento por satélite, onde o receptor observa mais do que quatro satélites. Todos os
resultados e conceitos aqui apresentados foram consultados em (AKALA et al., 2011), (RAHEMI
et al., 2014), (SAUER, 2012), (MOSAVI et al., 2014) e (OSZCZAK, 2014).

3.1 SISTEMA DE GEOPOSICIONAMENTO POR SATÉLITE

GPS é a sigla para Global Positioning System, que signiﬁca Sistema de Posicionamento
Global. Este é um sistema de posicionamento de satélites usado para determinar a posição de um
receptor em qualquer lugar sobre a Terra com uma grande precisão.

O projeto GPS foi projetado para uso militar, mas em 1980, por decisão do então
presidente dos Estados Unidos Ronald Reagan, foi implementado para uso civil. Ainda assim,
foi implantado um erro proposital no sistema GPS de uso civil. Isso se deu devido ao medo
do então governo americano de que nações inimigas se utilizassem deste sistema para realizar
atentados contra a nação americana.

Enquanto os receptores de uso militar possuem precisão de 1 metro, o de uso civil possuía
uma margem de erro de 100 a 140 m devido a um processo de deterioração da precisão das
informações dos satélites. Mas este processo foi abolido a 0h do dia 2 de maio de 2000, fazendo
com que a precisão do GPS de uso civil obtivesse uma melhora de até dez vezes na sua precisão,
fazendo com que a margem de erro variasse de 15 a 100 metros.

A precisão no receptor de uso militar se deve ao fato da existência de um relógio atômico
em cada satélite, propiciando uma medição de tempo mais precisa. Este é o sistema de medição
de tempo com maior precisão atualmente.

Para o correto funcionamento do GPS, é necessário o uso de três segmentos: espacial, de
controle e o receptor. O segmento espacial é composto pelos satélites que orbitam sobre o globo.
O de controle são as estações de controle ou de monitoramento dos satélites. E o receptor GPS
são os aparelhos que mostram a posição do usuário naquele instante.

3.2 DETERMINANDO A DISTÂNCIA ENTRE O SATÉLITE E O RECEP-

TOR

Para o cálculo da distância entre o satélite e o receptor, o satélite transmite um longo
sinal digital e, neste mesmo instante, o receptor gera o mesmo código. No momento em que o
sinal chega ao receptor, existe uma defasagem em relação ao sinal gerado pelo receptor. Esta

36

diferença é igual ao tempo de trânsito do sinal. Então o satélite calcula a distância utilizando o
fato de que:

d = c t,

(3.1)

onde d é a distância do satélite até o receptor, c é a velocidade da luz no vácuo que é dada
por c ≈ 299792.458 km/s e t é o tempo que este sinal demora para transitar entre o satélite e
o receptor. A medida desta distância é chamanda de pseudo-distância. Por conta de possíveis
erros na medição do tempo medido pelos receptores, a pseudo-distância não representa a
distância real entre o satélite e o receptor. Para minimizar os erros, os relógios dos receptores são
constantemente reiniciados e sincronizados com o relógio atômico dos satélites.

As informações utilizadas para determinar a posição do receptor são as posições dos
satélites e as distâncias dos satélite até o receptor. Se o receptor capta o sinal de apenas um
satélite percebe-se que todas as possíveis posições para o receptor estão na superfície de uma
esfera de centro (a, b, c), onde a, b, c são as coordenadas cartesianas da posição do satélite, e
raio d, ou seja, as coordenadas do receptor deve satisfazer:

(x − a)2 + (y − b)2 + (z − c)2 = (ct)2.

(3.2)

Figura 12 – Representação da superfície esférica de centro (a, b, c)

Se o receptor capta o sinal de dois satélites tem-se que a posição do receptor está contida
na interseção das duas esferas cujos centros são os satélites. Esta interseção é não vazia, já que
contém pelo menos um ponto em comum, que é a posição do receptor. Caso as esferas sejam
tangentes então o ponto de interseção é a posição do receptor (Figura 13 (a)), caso sejam secantes
a posição do receptor esta contido em uma circunferência de possibilidades (Figura 13 (b)).

Se o receptor capta o sinal de três satélites a posição do receptor está contida na interseção
de três esferas. Se considerar que as três esferas são secantes duas a duas, sua interseção será

37

(a) Superfícies esféricas tangentes

(b) Superfícies esféricas secantes

Figura 13 – Representação da interseção de duas superfícies esféricas de centros (a1, b1, c1) e

(a2, b2, c2)

o conjunto de dois pontos (Figura 14). Caso duas sejam tangentes, a interseção será um único
ponto, que neste caso será a posição do receptor.

Figura 14 – Representação da interseção de três superfícies esféricas de centros (a1, b1, c1),

(a2, b2, c2), e (a3, b3, c3)

Considere portanto um sistema de informações coletados de n satélites de posições
Si = (xi, yi, zi) e di = cti com i = 1, · · · , n. Neste caso o sistema de equações associado é dado
por,






(x − x1)2 + (y − y1)2 + (z − z1)2 = (ct1)2
(x − x2)2 + (y − y2)2 + (z − z2)2 = (ct2)2

...

=

...

(x − xn)2 + (y − yn)2 + (z − zn)2 = (ctn)2.

(3.3)

Sendo assim para determinar a posição de um receptor que recebe o sinal de n satélites

devemos resolver o seguinte sistema:

38






x2 + y2 + z2 − 2xx1 − 2yy1 − 2zz1 + x2
x2 + y2 + z2 − 2xx2 − 2yy2 − 2zz2 + x2

1 + y2
2 + y2

1 + z2
2 + z2

...

x2 + y2 + z2 − 2xxn − 2yyn − 2zzn + x2

1 + y2

n + z2

1 − (ct1)2 = 0
2 − (ct2)2 = 0
...
n − (ctn)2 = 0.

=

Aﬁm de transformar o sistema (3.4) em um sistema linear, subtraímos a primeira equação

das n − 1 equações restantes dando origem a um sistema de (n − 1) × 3.









2(x1 − x2)
2(x1 − x3)
...

2(y1 − y2)
2(y1 − y3)
...
2(x1 − xn) 2(y1 − yn) 2(z1 − zn)

2(z1 − z2)
2(z1 − z3)
...














x
y
z




 =









x2
1 − x2
1 − x2
x2

2 + y2
3 + y2

1 − y2
1 − y2

1 − z2
1 − z2

2 − c2(t2
3 − c2(t2

1 − t2
2)
1 − t2
3)

x2
1 − x2

n + y2

1 − y2

1 − z2

n − c2(t2

1 − t2
n)

2 + z2
3 + z2
...
n + z2

(3.4)









.

(3.5)

Como o sistema (3.5) possui mais equações que incógnitas resolveremos este sistema

usando a teoria desenvolvida no Capítulo 2.

A seguir são apresentados exemplos que ilustram toda a teoria desenvolvida ao longo

deste trabalho.

Exemplo 3.1. ((SAUER, 2012), pag. 240) Considere um barco que está em uma posição desco-
nhecida que recebe simultaneamente sinais de quatro satélites indicando as suas posições e o
tempo como mostrado na tabela abaixo.

Satélite
1
2
3
4

Posição(km)
(15600, 7540, 20140)
(18760, 27050, 18610)
(17610, 14630, 13480)
(19170, 610, 18390)

Tempo(s)
0,070
0,072
0,076
0,073

Tabela 1 – Dados dos satélites

Conhecido o tempo, determina-se a distância pela equação (3.1). Neste caso o sistema

linearizado (3.5) é da forma








−6320 −39020
3060
−4020 −14180 13320
3500
13860
−7140






















x
y
z








=

8.48121 × 107
3.0264 × 108
1.05984 × 108








.

(3.6)

39

O sistema normal associado é dado por








107082400
204649600
−97875600 −259768800

204649600 −97875600
1915732400 −259768800
199036000






















x
y
z








=

−2.50935 × 1012
−6.13187 × 1012
4.66164 × 1012








.

(3.7)

Logo as coordenadas da posição do receptor são x = (−3888.88, 159.374, 21716.7) e
o erro kb − Axk2 = 1.47514 ∗ 10−7. A Figura 15 ilustra a interseção das esferas duas a duas e
a solução do sistema.

Figura 15 – Localização do receptor com 4 satélites

A seguir são apresentados dois exemplos com um número maior de satélites. Estes

exemplos foram extraídos de (OSZCZAK, 2014).

Exemplo 3.2. Considere um sistema de GPS em que o receptor capta o sinal de 5 satélites cujas
posições em metros são:

x1 = 28573624.909,

y1 = 176258.719,

z1 = 475886.493

x2 = 20534972.474,

y2 = 3620869.695,

z2 = 20821515.054

x3 = 13834909.426,

y3 = 9331764.237,

z3 = 24705373.313

x4 = −18325015.195,

y4 = 12831313.778,

z4 = 20831862.073

x5 = −11441576.697,

y5 = 19817392.158,

z5 = 15998439.113

e suas respectivas pseudo-distâncias, também em metros são:

d1 = 25573786.094

d2 = 23269991.712

d3 = 23527045.278

d4 = 29205487.559

d5 = 26129807.790

40

Assim o sistema linearizado (3.5) é da forma











1.60773 × 107 −6.88922 × 106 −4.06913 × 107
2.94774 × 107 −1.8311 × 107 −4.8459 × 107
9.37973 × 107 −2.53101 × 107 −4.0712 × 107
8.00304 × 107 −3.92823 × 107 −3.10451 × 107

























x
y
z

=











−5.45835 × 1014
−7.10626 × 1014
−2.34798 × 1014
−2.26975 × 1014











.

Neste caso, o sistema normal associado é dado por








1.63302 × 1016 −6.16832 × 1015 −8.38587 × 1015
3.41761 × 1015
2.56645 × 1015
−6.16832 × 1015
6.62531 × 1015
3.41761 × 1015
−8.38587 × 1015






















x
y
z








=

−6.99113 × 1022
3.16315 × 1022
7.32525 × 1022








,

e portanto as coordenadas da posição do receptor são (5.83074 × 106, 5.71024 × 106, 1.5491 ×
107) . Neste caso o erro do problema de mínimos quadrados é 4.27462 × 1013. Note que o erro é
consideravelmente grande. Este fato ocorre por se tratar de um exemplo que não necessariamente
representa uma situação real.

Exemplo 3.3. Um receptor capta o sinal de 10 satélites de posições

x1 = 28573843.196,

y1 = 186705.396,

z1 = 458504.029

x2 = −13737297.587,

y2 = 23793697.380,

z2 = 440829.364

x3 = 135280.549,

y3 = 9472446.041,

z3 = 23550389.315

x4 = −17629491.025,

y4 = 10178391.389,

z4 = 20326540.307

x5 = 21444538.037,

y5 = 9999752.312,

z5 = 16543394.085

x6 = −8952698.519,

y6 = 24597337.024,

z6 = 12187985.352

x7 = 13576242.929,

y7 = 20905580.826,

z7 = 11605617.387

x8 = 2107612.980,

y8 = 24090126.595,

z8 = 19555410.293

x9 = −10553478.506,

y9 = 4921167.847,

z9 = 26114803.717

x10 = −290863.203,

y10 = 5550000.536,

z10 = 26104633.518,

e suas respectivas pseudo-distâncias

d1 = 25449152.282,

d2 = 28710125.200,

d3 = 22512803.080,

d4 = 27609639.021,

d5 = 22920682.547,

d6 = 27338791.883,

d7 = 22881688.771,

d8 = 26984600.739,

d9 = 25643828.772,

d10 = 21830588.390.

41

Aplicando os dados acima descritos, o sistema linearizado 9 × 3 obtido é


























35349.3

8.46223 × 107 −4.7214 × 107
5.68771 × 107 −1.85715 × 107 −4.61838 × 107
9.24067 × 107 −1.99834 × 107 −3.97361 × 107
1.42586 × 107 −1.96261 × 107 −3.21698 × 107
7.50531 × 107 −4.88213 × 107 −2.3459 × 107
2.99952 × 107 −4.14378 × 107 −2.22942 × 107
5.29325 × 107 −4.78068 × 107 −3.81938 × 107
7.82546 × 107 −9.46892 × 106 −5.13126 × 107
5.77294 × 107 −1.07266 × 107 −5.12923 × 107








































x
y
z

=


























1.76628 × 1014
−6.95244 × 1014
−2.98325 × 1014
−3.95775 × 1014
−4.85866 × 1013
−2.58568 × 1014
−3.01695 × 1014
−6.71826 × 1014
−8.52326 × 1014


























,

e o sistema normal associado é da forma








3.79292 × 1016 −1.5976 × 1016 −1.8182 × 1016
7.21257 × 1015
9.9494 × 1015
−1.5976 × 1016
1.25168 × 1016
7.21257 × 1015
−1.8182 × 1016






















x
y
z








=

−1.86957 × 1023
6.13151 × 1022
1.5332 × 1023








.

Logo as coordenadas da posição do receptor são

(1.60315 × 106, −3.14448 × 106, 1.63898 × 107).

(3.8)

Antes de ﬁnalizar o capítulo é necessário fazer algumas observações. No exemplos
anteriores não foi considerado que o sistema possa ter imprecisões ao tentar calcular a distância
entre o receptor e o satélite. Ao levar esta possibilidade em consideração pode acontecer do
receptor não estar contido na superfície da esfera obtida do sinal de um satélite, conforme
ilustrado na Figura 16 (a). Este mesmo fato pode ocorrer para mais de um satélite conforme
Figura 16 (b). Neste caso quanto mais satélites maior é a precisão obtida.

(a) Erro com 1 satélite

(b) Erro com 3 satélites

Figura 16 – Representação da posição real do receptor

Alguns fatores podem ocasionar perda de precisão, são eles:

42

(i) Atrasos da Ionosfera e Troposfera: A velocidade do sinal não é precisamente a velocidade
da luz. O sinal passa por 100 km de Ionosfera e 10 km de Trosposfera que possuem
propriedades eletromagnéticas que podem afetar a velocidade de transmissão. O atraso do
sinal ocorrido nesta parte da atmosfera é compensado por um modelo matemático incluído
no receptor, porém por fazer apenas uma média dos atrasos, deixa-se de utilizar dados
exatos perdendo assim um pouco da precisão.

(ii) Sinais “multi-path”: quando o sinal é reﬂetido por construções como prédios e também
formações rochosas, o tempo de propagação do sinal é alterado causando imprecisão.

Figura 17 – Representação dos sinais “multi-path”

(iii) Erros no relógio do receptor: Não é possível ter um relógio atômico em cada receptor, então
eles usam um cristal de quartzo comum que não tem a mesma precisão mas é reiniciado
em sincronia com quatro ou mais satélites. Mesmo assim podem ocorrer variações no
relógio do receptor, causando assim perda de precisão.

(iv) Números de satélites visíveis: Quanto maior for o número de satélites visíveis maior é a
precisão. Não se consegue um bom funcionamento do sistema dentro de locais fechados,
embaixo da água ou da terra.

(v) Geometria dos satélites/sombra: Existe uma geometria entre a posição dos satélites que
favorece a decodiﬁcação da posição do receptor. Se houver satélites muito próximos uns
dos outros ou alinhados, o resultado é uma precisão ruim.

Baseado nisso, existem trabalhos em que a possibilidade de erro é incluída no modelo,
como por exemplo (STRANG; BORRE, 1997), (OSZCZAK, 2014). No entanto este tipo de
situação não foi abordado neste trabalho por necessitar de outras ferramentas que não foram aqui
desenvolvidas.

4 CONCLUSÃO

43

Os sistemas lineares são empregados na resolução de vários tipos de problemas dentro
da Matemática. Um caso particular, que foi o objeto de estudo deste trabalho, são os sistemas
lineares sobredeterminados, aqueles em que o números de equações é maior do que o número de
incógnitas.

Para resolver este tipo de sistema foi apresentado o método dos mínimos quadrados. Para
dar clareza ao método fez-se necessário o estudo de conceitos de álgebra linear como espaços e
subespaços vetoriais, base e dimensão de um subespaço vetorial, norma de vetores e de matrizes
e por ﬁm, ortogonalidade de vetores, de conjuntos e de subespaços vetoriais.

Posteriormente foi apresentado o método dos mínimos quadrados explorando várias
ideias de projeção ortogonal culminando em uma sistemática de resolução de sistemas sobrede-
terminados.

O trabalho foi ﬁnalizado com uma apresentação de um problema de geoposicionamente
em que o objetivo era determinar a posição de um receptor em um sistema de coordenadas
cartesianas. Este tipo de problema foi modelado por meio de um sistema sobredeterminado de
equações lineares, que foi resolvido com o uso de mínimos quadrados.

Para que este trabalho fosse desenvolvido, foi necessário uma série de conhecimentos
que foram adquiridos ao longo deste processo tais como: aprimorar a experiência com a pesquisa
acadêmica, utilização de editores de texto, como o uso do Latex, o uso de softwares matemáticos
como o Geogebra e Wolfram Mathematica. Isso tudo somado contribuiu para uma formação
mais completa.

REFERÊNCIAS

44

AKALA, A. O. et al. Determined optimization technique for solving over-determined linear
systems. Latin-American Journal of Physics Education, 2011.

GOLUB, G. H.; LOAN, C. F. V. Matrix Computations (Johns Hopkins Studies in
Mathematical Sciences)(3rd Edition). EUA: Johns Hopkins University Press, 1996. ISBN
0-8018-5414-8.

LIMA, E. L. Álgebra Linear. Rio de Janeiro: IMPA, 2009.

MEYER, C. D. Matrix Analysis and Applied Linear Algebra. EUA: SIAM, 2000.

MOSAVI, M. R. et al. Least squares techniques for GPS receivers positioning ﬁlter using
pseudo-range and carrier phase measurements. Iran University of Science and Technology,
2014. ISSN 2383-3890.

OSZCZAK, B. GNSS position algoritms using methods of reference point indicatiors. Artiﬁcial
Satelites, v. 49, n. 1, p. 21–32, 2014.

RAHEMI, N. et al. Accurate solution of navigation equations in GPS receivers for very high
velocities using pseudorange measurements. Iran University of Science and Technology, p. 8,
2014. Disponível em: <http://dx.doi.org/10.1155/2014/435891>.

SAUER, T. Numerical Analysis. 2nd. edition. ed. Boston: Pearson Education, 2012.

STRANG, G. Introduction to Linear Algebra, Fourth Edition. EUA: Wellesley Cambridge
Press, 2009. ISBN 978-0-9802327-1-4.

STRANG, G.; BORRE, K. Linear Algebra, geodesy and GPS. EUA: Wellesley Cambridge
Press, 1997.

TREFETHEN, L. N.; III, D. B. Numerical Linear Algebra. Philadelphia: SIAM: Society for
Industrial and Applied Mathematics, 1997. ISBN 0-89871-361-7.


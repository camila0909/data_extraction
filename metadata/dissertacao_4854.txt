UNIVERSIDADE FEDERAL DO TRI ˆANGULO MINEIRO

MESTRADO PROFISSIONAL EM MATEM ´ATICA EM REDE

NACIONAL

WILLIAM JOS´E DOS SANTOS

Programa¸c˜ao Linear: Fundamentos e Aplica¸c˜oes

Uberaba-MG

2014

WILLIAM JOS ´E DOS SANTOS

Programac¸ ˜ao Linear: Fundamentos e Aplicac¸ ˜oes

Disserta¸c˜ao apresentada ao curso de Mes-
trado Proﬁssional em Matem´atica em Rede
Nacional-PROFMAT, como parte das ati-
vidades para obten¸c˜ao do t´ıtulo de Mestre
em Matem´atica da Universidade Federal do
Triˆangulo Mineiro - UFTM, Departamento
de Matem´atica.

Orientador: Prof. Dr. Thadeu Alves Senne

Uberaba

2014

   Santos, William José dos 

 S233p            Programação linear: fundamentos e aplicações / William José dos San- 
                 tos. -- 2014. 

   68 f. : il., fig., graf., tab. 

 Dissertação (Mestrado Profissional em Matemática em Rede Nacional)   

                  -- Universidade Federal do Triângulo Mineiro, Uberaba, MG, 2014 

         Orientador: Prof. Dr. Thadeu Alves Senne 

1. Programação linear. 2. Simplex (Matemática).  3.  Pesquisa operacio- 

    nal. I. Senne, Thadeu Alves. II. Universidade Federal  do Triângulo Mineiro. 
    III. Título.             

                                                                                                                     CDU 519.852 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
          
 
 
 
 
                                                                                                   
 
Agradecimentos

Ao t´ermino deste trabalho, deixo aqui meus sinceros agradecimentos:

– Agrade¸co a Deus por ter me dado tudo o que foi necess´ario at´e aqui.

– Agrade¸co a minha fam´ılia pelo apoio e paciˆencia.

– Agrade¸co a CAPES pelo apoio ﬁnanceiro durante o curso.

– Agrade¸co a todos envolvidos direta ou indiretamente neste grandioso projeto de

aperfei¸coamento e melhoria do ensino de matem´atica em todo o Brasil - PROFMAT.

– Agrade¸co, tamb´em, aos meus colegas de curso pela amizade e companheirismo.

– Por ﬁm, agrade¸co ao meu orientador Prof. Dr. Thadeu Alves Senne, pela com-

petˆencia, pela paciˆencia e principalmente pelo incentivo constante.

Resumo

Um professor de Matem´atica sempre precisa motivar o estudo de sua disciplina e apre-

sentar aplica¸c˜oes pertinentes. Com esse intuito, estudamos, neste trabalho, problemas de

Programa¸c˜ao Linear (PL), e abordamos os seus fundamentos te´oricos. Al´em disso, mos-

tramos como resolver graﬁcamente esses problemas nos casos em que eles possuem apenas

duas vari´aveis, apresentamos o M´etodo Simplex, e discutimos brevemente o conceito de

dualidade em problemas de PL. Com o objetivo de aplicar esses conceitos de uma maneira

acess´ıvel para alunos de Ensino M´edio, propomos uma atividade relacionada `a modelagem

e `a resolu¸c˜ao de um tipo especial de PL, conhecido como problema de transporte, usando

planilhas eletrˆonicas.

Palavras-chave: Programa¸c˜ao Linear, Simplex, Pesquisa Operacional.

Abstract

A Math teacher always needs to motivate the study of this subject and to show

pertinent applications. With this aim, we study, in this work, the Linear Programming

(LP) problems, and we approach its theoretical fundamentals. Moreover, we show how

to solve graphically these problems when they have only two variables, we present the

Simplex Method, and we discuss brieﬂy the concept of duality for LP problems. With the

objective of applying these concepts in an aﬀordable way to the high school students, we

propose an activity related to the modelling and to the solution of a special type of LP

problem, known as transportation problem, using electronic spreadsheets.

Key-words: Linear Programming, Simplex, Operational Research.

Sum´ario

Lista de Tabelas

Lista de Figuras

1 INTRODUC¸ ˜AO

10

1.1 Por que abordar a Programa¸c˜ao Linear na Escola B´asica? . . . . . . . . . . 11

1.2 O surgimento do M´etodo Simplex . . . . . . . . . . . . . . . . . . . . . . . 11

2 PROBLEMAS DE PROGRAMAC¸ ˜AO LINEAR

13

2.1 Forma Canˆonica e Forma Padr˜ao de um problema de PL . . . . . . . . . . 14

2.2 Representa¸c˜ao e Resolu¸c˜ao Gr´aﬁca . . . . . . . . . . . . . . . . . . . . . . 15

3 M ´ETODO SIMPLEX

20

3.1 Solu¸c˜oes B´asicas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

3.2 Rela¸c˜ao entre Pontos Extremos e Solu¸c˜oes B´asicas . . . . . . . . . . . . . . 22

3.3 Teorema Fundamental da Programa¸c˜ao Linear . . . . . . . . . . . . . . . . 24

3.4 O M´etodo Simplex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

3.5 Problemas Degenerados

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.6 O M´etodo Simplex em Duas Fases . . . . . . . . . . . . . . . . . . . . . . . 34

4 DUALIDADE

36

4.1 Formula¸c˜ao do Dual

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

4.2 Propriedades

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5 APLICAC¸ ˜OES

45

5.1 Problemas de Otimiza¸c˜ao em Rede . . . . . . . . . . . . . . . . . . . . . . 45

5.2 Problema de Transporte . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

5.2.1 Obtendo uma solu¸c˜ao b´asica inicial

. . . . . . . . . . . . . . . . . . 49

5.2.2 Viabilidade e Solu¸c˜ao ´Otima . . . . . . . . . . . . . . . . . . . . . . 53

6 CONSIDERAC¸ ˜OES FINAIS

Referˆencias

Apˆendice A

60

62

63

Lista de Tabelas

1

2

3

4

5

6

7

8

Compara¸c˜ao entre o primal e o dual, na forma canˆonica.

. . . . . . . . . . 36

Compara¸c˜ao entre o primal e o dual, na forma padr˜ao.

. . . . . . . . . . . 37

Rela¸c˜oes primal-dual. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

Viabilidade primal-dual.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

Custos de transporte, demandas e ofertas mensais. . . . . . . . . . . . . . . 48

Custos de transporte e capacidades das f´abricas e dos armaz´ens.

. . . . . . 51

Aplicando o m´etodo do canto noroeste.

. . . . . . . . . . . . . . . . . . . . 52

Aplicando o m´etodo do menor custo.

. . . . . . . . . . . . . . . . . . . . . 53

Lista de Figuras

1

2

3

4

5

6

7

8

9

Restri¸c˜oes de (2.4) escritas como igualdades.

. . . . . . . . . . . . . . . . . 16

Regi˜ao vi´avel de (2.4).

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

Localizando a solu¸c˜ao ´otima de (2.4).

. . . . . . . . . . . . . . . . . . . . . 17

Localizando a solu¸c˜ao ´otima de (2.5).

. . . . . . . . . . . . . . . . . . . . . 18

Regi˜ao vi´avel ilimitada de (2.6).

. . . . . . . . . . . . . . . . . . . . . . . . 19

As restri¸c˜oes de (2.7) n˜ao se intersectam.

. . . . . . . . . . . . . . . . . . . 19

Solu¸c˜ao gr´aﬁca de (3.22). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

Compara¸c˜ao das solu¸c˜oes gr´aﬁcas do problema primal (4.1) com o problema

dual (4.2).

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

Solu¸c˜ao gr´aﬁca de (4.4) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

10 Componentes de uma rede. . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

11 Diagrama de rede do problema de transporte.

. . . . . . . . . . . . . . . . 47

12 Diagrama de rede para o Exemplo 5.1.

. . . . . . . . . . . . . . . . . . . . 49

13 Planilha com os dados de (5.2).

. . . . . . . . . . . . . . . . . . . . . . . . 55

14

15

16

Janela “Parˆametros do Solver” para (5.2).

. . . . . . . . . . . . . . . . . . 55

Janela “Adicionar restri¸c˜ao”. . . . . . . . . . . . . . . . . . . . . . . . . . . 56

Janela “Op¸c˜oes do Solver”para (5.2).

. . . . . . . . . . . . . . . . . . . . . 56

17 Planilha com a solu¸c˜ao de (5.2). . . . . . . . . . . . . . . . . . . . . . . . . 57

18 Planilha com os dados de (5.3).

. . . . . . . . . . . . . . . . . . . . . . . . 57

19

Janela “Parˆametros do Solver”para (5.3). . . . . . . . . . . . . . . . . . . . 58

20 Planilha com a solu¸c˜ao de (5.3). . . . . . . . . . . . . . . . . . . . . . . . . 58

10

1

INTRODUC¸ ˜AO

A Programa¸c˜ao Linear (PL) ´e um tema especialmente interessante da Matem´atica.
Ela apresenta aplica¸c˜oes pr´aticas importantes da ´Algebra Linear, do C´alculo e da Geo-

metria Anal´ıtica que s˜ao fundamentais para viabilizar atividades importantes de admi-

nistra¸c˜ao e log´ıstica na ind´ustria, no com´ercio, nos transportes, e outras mais. O uso de

recursos computacionais para implementar as metodologias de resolu¸c˜ao de problemas de

Programa¸c˜ao Linear potencializam ainda mais a sua importˆancia.

Neste trabalho, apresentaremos a Programa¸c˜ao Linear com os seus conceitos e fun-

damentos, e mostraremos uma aplica¸c˜ao que pode ser estudada por alunos de Ensino

M´edio. Para tanto, na Se¸c˜ao 1.1 apresentamos uma breve justiﬁcativa para se trabalhar

com Programa¸c˜ao Linear na Educa¸c˜ao B´asica e, na Se¸c˜ao 1.2 falaremos brevemente sobre

o surgimento do M´etodo Simplex.

No Cap´ıtulo 2, apresentaremos a deﬁni¸c˜ao de um problema de Programa¸c˜ao Linear

em sua forma padr˜ao e o processo de resolu¸c˜ao gr´aﬁca de um problema de PL com duas

vari´aveis.

J´a no Cap´ıtulo 3, discorreremos sobre o M´etodo Simplex. Come¸caremos deﬁnindo o

que s˜ao solu¸c˜oes b´asicas e mostrando sua rela¸c˜ao com os pontos extremos do conjunto

de solu¸c˜oes vi´aveis de um problema de PL. Enunciaremos e demonstraremos o Teorema

Fundamental da Programa¸c˜ao Linear. Em seguida, apresentaremos a descri¸c˜ao do M´etodo

Simplex, acompanhada de dois exemplos. Discorreremos brevemente sobre problemas de

PL degenerados. Para ﬁnalizar, apresentaremos uma breve descri¸c˜ao do M´etodo Simplex

em Duas Fases.

A dualidade em PL ser´a tratada no Cap´ıtulo 4, no qual mostraremos como formular

o problema dual e apresentaremos as principais propriedades relacionadas.

No Cap´ıtulo 5, abordaremos o problema de transporte, que ´e um tipo de problema de

otimiza¸c˜ao em rede. Mostraremos os componentes de um problema de transporte, como

model´a-lo matematicamente, como obter uma solu¸c˜ao b´asica inicial e como resolvˆe-lo

11

utilizando uma planilha eletrˆonica.

1.1 Por que abordar a Programac¸ ˜ao Linear na Escola B´asica?

Os Parˆametros Curriculares Nacionais apontam que o Ensino M´edio deve proporcionar

um aprendizado ´util `a vida e ao trabalho, sem ser proﬁssionalizante. Nessa perspectiva,

algumas das diversas habilidades propostas para as Ciˆencias da Natureza, Matem´atica e

suas Tecnologias, s˜ao:

• Associar conhecimentos e m´etodos cient´ıﬁcos com a tecnologia do sistema

produtivo e dos servi¸cos.

• Desenvolver a capacidade de utilizar a Matem´atica na interpreta¸c˜ao e

interven¸c˜ao na vida real.

• Utilizar adequadamente calculadoras e computador, reconhecendo suas

limita¸c˜oes e potencialidades.

O ensino da Programa¸c˜ao Linear, devidamente adaptada `as condi¸c˜oes do Ensino

M´edio, proporciona o desenvolvimento dessas e outras habilidades. Ao se buscar a re-

solu¸c˜ao de problemas, a Programa¸c˜ao Linear contribui para uma constru¸c˜ao mais ampla

do conceito de eﬁciˆencia, muito em voga nos dias atuais.

Escolhemos o problema de transporte como exemplo de aplica¸c˜ao devido `as carac-

ter´ısticas econˆomicas na nossa regi˜ao: o Triˆangulo Mineiro, e em especial, a cidade de

Uberlˆandia. O com´ercio atacadista ´e desenvolvido e conta com a presen¸ca de empresas

importantes que promovem distribui¸c˜ao de produtos em todo o territ´orio nacional, de

forma que existe uma motiva¸c˜ao natural para se desenvolver habilidades relacionadas `a

Log´ıstica e `a Pesquisa Operacional.

1.2 O surgimento do M´etodo Simplex

Segundo BAZARAA et al. (2010), o matem´atico e economista sovi´etico L. V. Kanto-

rovich foi o primeiro a formular e resolver um problema de Programa¸c˜ao Linear ao lidar

com organiza¸c˜ao e planejamento, em 1939. Entretanto, o seu trabalho permaneceu des-

conhecido at´e 1959. Sendo assim, a concep¸c˜ao dos problemas de Programa¸c˜ao Linear ´e

creditada ao matem´atico norte americano George B. Dantzig, que tamb´em desenvolveu

esse tipo de problema ao trabalhar como consultor matem´atico para a United States Air

12

Force Controller, por volta de 1947, no desenvolvimento de uma ferramenta para resolver

problemas na ´area de planejamento de produ¸c˜ao e log´ıstica.

Um marco na hist´oria da Programa¸c˜ao Linear foi o desenvolvimento do M´etodo Sim-

plex, por George Dantzig, publicado em 1949. O seu m´etodo resolve de maneira eﬁciente

os problemas de Programa¸c˜ao Linear.

13

2

PROBLEMAS DE PROGRAMAC¸ ˜AO LINEAR

Neste cap´ıtulo, apresentaremos a deﬁni¸c˜ao matem´atica de um problema de Pro-

grama¸c˜ao Linear ou problema de PL, como ´e comumente chamado. Na Se¸c˜ao 2.1, dis-

correremos sobre a forma canˆonica e a forma padr˜ao de problemas de PL. Na Se¸c˜ao 2.2,

mostraremos a resolu¸c˜ao gr´aﬁca para problemas de PL com duas vari´aveis.

Problemas de PL s˜ao problemas de otimiza¸c˜ao que, ao serem modelados matematica-

mente, ﬁcam determinados por uma fun¸c˜ao linear z : Rn

→ R dada por

z = c1x1 + c2x2 + · · · + cnxn,

(2.1)

para a qual queremos encontrar um valor m´aximo ou m´ınimo que satisfa¸ca restri¸c˜oes

constitu´ıdas por equa¸c˜oes ou inequa¸c˜oes lineares do tipo

a11x1 + a12x2 + · · · + a1nxn (≤)(=)(≥) b1
a21x1 + a22x2 + · · · + a2nxn (≤)(=)(≥) b2
...

...

...

...

(2.2)

am1x1 + am2x2 + · · · + amnxn (≤)(=)(≥) bm.

Em (2.1), z = z(x1, · · · , xn) ´e chamada fun¸c˜ao objetivo, as n vari´aveis xj s˜ao
chamadas de vari´aveis de decis˜ao e os coeﬁcientes cj s˜ao chamados de coeﬁcientes de
custo. J´a em (2.2) temos m restri¸c˜oes em que os m.n coeﬁcientes aij s˜ao chamados de
coeﬁcientes t´ecnicos. Os termos independentes bi s˜ao tamb´em chamados de recursos.

De acordo com BAZARAA et al. (2010), algumas hip´oteses s˜ao assumidas quanto `as

grandezas envolvidas em um problema de PL. S˜ao elas:

(1) Aditividade: o custo total ´e igual `a soma dos custos individuais e a contribui¸c˜ao

total das restri¸c˜oes ´e a soma de cada restri¸c˜ao individual;

(2) Divisibilidade: valores n˜ao inteiros s˜ao permitidos para as vari´aveis de decis˜ao;

(3) Proporcionalidade: dada uma vari´avel xj, sua contribui¸c˜ao para o valor da fun¸c˜ao

14

objetivo ´e dada por cjxj e sua contribui¸c˜ao para cada restri¸c˜ao ´e dada por aijxj, para
i = 1, 2, · · · , m e j = 1, 2, · · · , n;

(4) Determinismo: todos os parˆametros presentes no modelo s˜ao constantes deter-

min´ısticas, ou seja, s˜ao parˆametros conhecidos com exatid˜ao.

2.1 Forma Canˆonica e Forma Padr˜ao de um problema de PL

Um problema de PL pode apresentar restri¸c˜oes em forma de igualdade ou desigual-

dade. Dizemos que um problema est´a na forma canˆonica quando todas as suas vari´aveis

s˜ao n˜ao negativas, suas restri¸c˜oes s˜ao do tipo “menor ou igual”e queremos encontrar um

valor m´ınimo para a fun¸c˜ao objetivo. Ou seja,

min z = c1x1 + c2x2 + · · · + cnxn
s. a a11x1 + a12x2 + · · · + a1nxn ≤ b1
a21x1 + a22x2 + · · · + a2nxn ≤ b2
...
am1x1 + am2x2 + · · · + amnxn ≤ bm

...

x1, x2, · · · , xn ≥ 0.

(2.3)

O problema (2.3) pode ser escrito na forma matricial como

min cT x
s. a Ax ≤ b
x ≥ 0,

no qual A ∈ Mm×n(R), b ∈ Rm e c, x ∈ Rn (vide [1] no Apˆendice).

Quando escrevemos x ≥ 0, usamos de um abuso de linguagem para mostrar que temos

xi ≥ 0 para todo i = 1, 2, · · · , n.

Se todas as restri¸c˜oes forem de igualdade, temos um PL na forma padr˜ao, que em

nota¸c˜ao matricial, ´e dado por

min cT x

s. a Ax = b
x ≥ 0.

O M´etodo Simplex, que ser´a descrito no Cap´ıtulo 3, exige que o problema de PL esteja

escrito na forma padr˜ao.

Dado um problema de PL, podemos escrevˆe-lo na forma padr˜ao efetuando as seguintes

manipula¸c˜oes:

1. N˜ao negatividade das vari´aveis

15

Se o problema apresenta uma vari´avel xi n˜ao positiva, substitu´ımos xi no problema
por x,
i com
i, x,,
x,

i = −xi. Caso a vari´avel xi seja irrestrita em sinal, fazemos xi = x,
i ≥ 0.

i − x,,

2. Transformando inequa¸c˜oes em equa¸c˜oes

Para transformar uma inequa¸c˜ao em uma equa¸c˜ao, basta adicionarmos ou subtrair-

mos uma nova vari´avel positiva conforme o caso:

(i) am1x1 + am2x2 + · · · + amnxn ≤ bm ⇒ am1x1 + am2x2 + · · · + amnxn + xn+1 = bm
com xn+1 ≥ 0.
(ii) am1x1 + am2x2 + · · · + amnxn ≥ bm ⇒ am1x1 + am2x2 + · · · + amnxn − xn+1 = bm
com xn+1 ≥ 0.
Nos dois casos, chamamos xn+1 de vari´avel de folga.

Caso seja necess´ario, podemos transformar um problema de maximiza¸c˜ao em mini-

miza¸c˜ao. Basta fazer max (z) = min (−z).

2.2 Representac¸ ˜ao e Resoluc¸ ˜ao Gr´aﬁca

Um problema de PL que tenha apenas duas vari´aveis pode ser representado e re-

solvido graﬁcamente com facilidade. A resolu¸c˜ao gr´aﬁca de problemas de PL com duas

vari´aveis ´e interessante por proporcionar uma melhor compreens˜ao dos conceitos que ser˜ao

apresentados para o M´etodo Simplex, no Cap´ıtulo 3.

Para resolver um problema de PL com duas vari´aveis, devemos, em primeiro lugar,

num sistema cartesiano de eixos coordenados, tra¸car as retas que representam as ine-

qua¸c˜oes, considerando-as como equa¸c˜oes. Em seguida, devemos veriﬁcar a intersec¸c˜ao

das desigualdades, incluindo a n˜ao negatividade das vari´aveis. O conjunto assim deﬁnido

´e chamado de regi˜ao vi´avel do problema. Assim, se a regi˜ao vi´avel for n˜ao vazia e se o

problema de PL tiver solu¸c˜ao ´otima, o ´ultimo passo consiste em identiﬁc´a-la. Para isso,
devemos tra¸car as curvas de n´ıvel da fun¸c˜ao objetivo (z = k, onde k ∈ R), observando o
seguinte:

(i) Se o problema for de maximiza¸c˜ao, escolhemos constantes k de forma crescente

at´e encontrarmos o maior valor de k tal que a curva de n´ıvel ainda intersecte a regi˜ao

16

vi´avel. Em outras palavras, “movemos” o plano z = k na dire¸c˜ao e sentido de ∇z (vide
[9] no Apˆendice) para identiﬁcar a solu¸c˜ao ´otima.

(ii) Se o problema for de minimiza¸c˜ao, escolhemos constantes k de forma decrescente

at´e encontrarmos o menor valor de k tal que a curva de n´ıvel ainda intersecte a regi˜ao
vi´avel. Aqui, “movemos” o plano z = k na dire¸c˜ao e sentido de −∇z.

Vamos apresentar quatro exemplos, sendo que o primeiro apresentar´a os passos des-

critos anteriormente. O primeiro exemplo possui uma ´unica solu¸c˜ao ´otima. J´a o segundo

possui um segmento de reta com inﬁnitas solu¸c˜oes ´otimas. O terceiro problema tem regi˜ao

vi´avel ilimitada. Finalmente, o quarto problema ´e invi´avel, ou seja, o conjunto vi´avel ´e

vazio.

Exemplo 2.1. Resolver graﬁcamente o PL abaixo:

min z = −x1 − x2
s. a 3x1 + 2x2 ≤ 6
x1 + 2x2 ≤ 5
x1, x2 ≥ 0.

(2.4)

1.◦ passo: Tra¸car as retas 3x1 + 2x2 = 6 e x1 + 2x2 = 5 num sistema cartesiano de

coordenadas, conforme a Figura 1.

x2

5

4

3

2

1

3x1 + 2x2 = 6

x1 + 2x2 = 5

0

1

2

3

4

5

6

x1

−1

−1

Figura 1: Restri¸c˜oes de (2.4) escritas como igualdades.

2.◦ passo: Veriﬁcar a intersec¸c˜ao das desigualdades, incluindo a n˜ao negatividade das

vari´aveis, e estabelecer a regi˜ao vi´avel para (2.4). A regi˜ao vi´avel ´e dada pelo quadril´atero

ABCD mostrado na Figura 2.

17

x2

4

3
D

2

1

C

B

2

3

4

x1

−1

A

0

1

−1

Figura 2: Regi˜ao vi´avel de (2.4).

3.◦ passo: Tra¸car as curvas de n´ıvel da fun¸c˜ao objetivo e localizar o v´ertice ´otimo. De

acordo com a Figura 3, o v´ertice C indica o valor ´otimo.

x2

4

C

3
z = −2
D
2
z = −1
1
z = 0

−1

A

0

1

−1

−∇z = −(−1, −1)

z = −2, 75

B
2

x1

3

4
z = −2, 5

Figura 3: Localizando a solu¸c˜ao ´otima de (2.4).

As coordenadas do v´ertice C s˜ao dadas pela solu¸c˜ao do sistema linear:

3x1 + 2x2 = 6

x1 + 2x2 = 5






que ´e x1 =

1
2

e x2 =

9
4

.

Exemplo 2.2. Seja o seguinte problema de PL:

min z = −3x1 − 2x2
s. a 3x1 + 2x2 ≤ 6
x1 + 2x2 ≤ 5
x1, x2 ≥ 0.

(2.5)

De maneira an´aloga ao o modelo apresentado no Exemplo 2.1, veriﬁcamos que o menor

valor de z se d´a para qualquer ponto do segmento BC, como mostra a Figura 4. Logo,

esse problema tem inﬁnitas solu¸c˜oes.

18

x2

4

3

D
2

1

C

−1

A

0

1

−1

−∇z = −(−3, −2)

z = −6

B
2

3

4

x1

Figura 4: Localizando a solu¸c˜ao ´otima de (2.5).

Exemplo 2.3. Resolva graﬁcamente o problema de PL:

max z = 3x1 + 2x2
x1 + x2 ≥ 1
s. a
−4x1 + x2 ≤ 1
x1 − 4x2 ≤ 1
x1, x2 ≥ 0.

(2.6)

Na Figura 5, vemos que o pol´ıgono que representa a regi˜ao vi´avel ´e ilimitado e que o

vetor gradiente de z n˜ao aponta para nenhum v´ertice. Portanto, trata-se de um problema

com regi˜ao vi´avel ilimitada e com valor ´otimo ilimitado.

Exemplo 2.4. Considere o problema de PL:

max z = x1 + x2
s. a 4x1 + x2 ≤ 4
2x1 − x2 ≥ 3
x1, x2 ≥ 0.

(2.7)

Considerando a n˜ao negatividade das vari´aveis, a primeira inequa¸c˜ao produz um triˆangulo

com v´ertices na origem e nos pontos A e B (observe a Figura 6) e a segunda inequa¸c˜ao

produz uma regi˜ao ilimitada `a direita do triˆangulo, mas n˜ao h´a intersec¸c˜ao das regi˜oes

delimitadas pelas restri¸c˜oes, ou seja, n˜ao existe (x1, x2) que satisfa¸ca todas as restri¸c˜oes
ao mesmo tempo. Nesse caso, conclu´ımos que (2.7) ´e um problema invi´avel.

19

x2

∇z = (3, 2)

A

0

B

1

2

3

4

x1

4

3

2

1

−1

−1

Figura 5: Regi˜ao vi´avel ilimitada de (2.6).

x2

A

4

3

2

1

B

0

1

C

2

3

4

x1

−1

−1

Figura 6: As restri¸c˜oes de (2.7) n˜ao se intersectam.

No pr´oximo cap´ıtulo, descreveremos o M´etodo Simplex para a resolu¸c˜ao de problemas

de PL.

20

3 M ´ETODO SIMPLEX

Neste cap´ıtulo, vamos apresentar o M´etodo Simplex, bem como resultados impor-

tantes relacionados a ele. Na Se¸c˜ao 3.1, apresentamos o conceito de solu¸c˜oes b´asicas de

sistemas lineares. Na Se¸c˜ao 3.2, discorremos sobre pontos extremos e sua rela¸c˜ao com

as solu¸c˜oes b´asicas. O Teorema Fundamental da Programa¸c˜ao Linear ´e enunciado e de-

monstrado na Se¸c˜ao 3.3. J´a na Se¸c˜ao 3.4, apresentamos uma descri¸c˜ao detalhada do

M´etodo Simplex e a resolu¸c˜ao de dois exemplos ilustrativos. Uma r´apida discuss˜ao sobre

problemas degenerados e uma breve descri¸c˜ao do M´etodo Simplex em Duas Fases ser˜ao

apresentados nas Se¸c˜oes 3.5 e 3.6, respectivamente.

Para o que ser´a exposto a seguir, consideramos o seguinte problema de PL escrito na

forma padr˜ao:

min z(x) = cT x

s. a Ax = b
x ≥ 0,
no qual A ∈ Mm×n(R) com m < n, posto(A) = m, b ∈ Rm e c, x ∈ Rn. Para o conceito
de posto de matrizes, consulte [8] no Apˆendice.

(3.1)

3.1 Soluc¸ ˜oes B´asicas

As restri¸c˜oes de (3.1) s˜ao dadas, em parte, por um sistema de equa¸c˜oes lineares escrito

na forma matricial Ax = b, em que A tem m linhas, n colunas e entradas reais. Se m = n
e A ´e n˜ao singular (ou seja, se det(A) ?= 0), o sistema tem uma ´unica solu¸c˜ao, dada por
x = A−1b. Quando n > m, o sistema linear Ax = b poder´a ter inﬁnitas solu¸c˜oes ou

nenhuma solu¸c˜ao. Entretanto, podemos obter submatrizes quadradas de A escolhendo m
colunas linearmente independentes (LI), que geram o Rm. Neste caso, essas m colunas
formam uma base (vide [7] no Apˆendice) para o Rm.

Sem perda de generalidade, supondo que as m primeiras colunas de A sejam LI,

21

denotamos

e

A = ?B N ?

x = ?xB
xN

? ,

em que B ∈ Mm×m(R) ´e uma matriz formada pelas m primeiras colunas LI de A, N ∈
Mm×(n−m)(R), xB ∈ Rm e xN ∈ Rn−m. Dessa forma, podemos reescrever o sistema linear
Ax = b como

?B N ?

? = b,

?xB
xN

ou seja,

BxB + N xN = b.

(3.2)

Como as m colunas de B s˜ao LI, temos que B ´e n˜ao singular. Pr´e-multiplicando os dois

membros de (3.2) por B−1 (ou seja, pela inversa de B), obtemos

xB + B−1N xN = B−1b,

ou seja,

xB = B−1b − B−1N xN .

(3.3)

Em particular, tomando xN = 0, obtemos

xB = B−1b.

Isso sugere a Deﬁni¸c˜ao 3.1.

Deﬁni¸c˜ao 3.1. O vetor x = [xB xN ]T , com xB = B−1b e xN = 0, ´e chamado de solu¸c˜ao
b´asica de (3.2). Se houver pelo menos uma componente nula em xB, dizemos que x ´e
uma solu¸c˜ao b´asica degenerada para (3.1). Chamamos de vari´aveis b´asicas os

elementos de xB e de vari´aveis n˜ao b´asicas os elementos de xN .

Vejamos um exemplo que ilustra a Deﬁni¸c˜ao 3.1:

Exemplo 3.2. Considere o seguinte sistema com duas equa¸c˜oes e trˆes vari´aveis:

a11x1 + a12x2 + a13x3 = b1

a21x1 + a22x2 + a23x3 = b2.






(3.4)

Na forma matricial Ax = b, temos que

22

A = ?a11 a12 a13
a21 a22 a23

? , x =







x1
x2
x3







e b = ?b1
b2

?. Supondo que posto(A) = 2 e que as 2

primeiras colunas de A sejam LI, temos a solu¸c˜ao xB = B−1b, onde B = ?a11 a12
a21 a22

? e

B−1 =

1
a11a22 − a12a21

? a22 −a12
a11
−a21

?. A vari´avel x3 ´e n˜ao b´asica, de modo que x3 = 0.

Note que, para o sistema linear do Exemplo 3.2, temos ?

3
2

? = 6 solu¸c˜oes b´asicas. No

caso geral, temos ?

n!
n
m!(n − m)!
m
com A ∈ Rm×n, m < n e posto(A) = m.

? =

solu¸c˜oes b´asicas para um sistema linear Ax = b,

No PL deﬁnido em (3.1), al´em das restri¸c˜oes de igualdade deﬁnidas pelo sistema linear
Ax = b, existem as restri¸c˜oes de n˜ao negatividade das vari´aveis, ou seja, x ≥ 0. Dessa
forma, devemos impor que as componentes do vetor xB sejam todas maiores que ou iguais
a zero. Com isso, temos a deﬁni¸c˜ao abaixo.

Deﬁni¸c˜ao 3.3. Uma solu¸c˜ao b´asica de (3.1) que satisfaz as condi¸c˜oes de n˜ao negatividade

das vari´aveis, ´e chamada de solu¸c˜ao b´asica vi´avel para (3.1).

Observe que o problema (3.1) ter´a, no m´aximo, ?

vi´aveis.

n
m

? =

n!
m!(n − m)!

solu¸c˜oes b´asicas

3.2 Relac¸ ˜ao entre Pontos Extremos e Soluc¸ ˜oes B´asicas

Na Se¸c˜ao 2.2, vimos que, no caso de duas vari´aveis, o conjunto de solu¸c˜oes vi´aveis ´e

um pol´ıgono convexo (no caso de duas vari´aveis) e que a solu¸c˜ao ´otima, quando ´e ´unica,

se encontra em um dos v´ertices. Se o problema tiver inﬁnitas solu¸c˜oes ´otimas, elas se

localizam em um segmento de reta ou em uma semirreta. No caso geral, o conjunto das

solu¸c˜oes vi´aveis, que ´e descrito pelo conjunto de solu¸c˜oes de Ax = b com componentes

n˜ao negativas, tamb´em formam um conjunto convexo (vide [10] no Apˆendice) que pode

ser chamado de poliedro (vide [12] no Apˆendice]). Se esse poliedro convexo ´e limitado,

temos um politopo (vide [12] no Apˆendice]). As solu¸c˜oes b´asicas vi´aveis s˜ao os v´ertices ou

pontos extremos desse poliedro. Isso est´a melhor deﬁnido e demonstrado a seguir, tendo

por base LUENBERGER & YE (2008).

23

Deﬁni¸c˜ao 3.4. Seja K ∈ Rn um conjunto convexo. Um ponto x ∈ K ´e um ponto
extremo se n˜ao existem dois elementos distintos x1, x2 em K tais que x = αx1+(1−α)x2,
para algum α ∈ (0, 1).

Teorema 3.5 (Teorema de Equivalˆencia entre Pontos Extremos e Solu¸c˜oes
B´asicas). Seja o conjunto convexo K = {x ∈ Rn
| Ax = b, x ≥ 0}. Ent˜ao, x ∈ K ´e
um ponto extremo deste conjunto se, e somente se, x ´e uma solu¸c˜ao b´asica vi´avel deste

conjunto.

Prova: Tomemos uma solu¸c˜ao b´asica vi´avel x de (3.1) e escrevamos x = [xB xN ]T
ou seja, x = (x1, x2, · · · , xm, 0, · · · , 0)T . Ent˜ao temos:

∈ Rn,

x1a1 + x2a2 + · · · + xmam = b,

(3.5)

onde a1, · · · , am s˜ao as colunas de A.

Suponha que x possa ser expresso como uma combina¸c˜ao linear convexa (vide [10] no

Apˆendice) de dois elementos distintos y, z ∈ K, ou seja, x = αy + (1 − α)z, 0 < α < 1.

Como α ∈ (0, 1) e as componentes de x, y e z s˜ao n˜ao negativas, as n − m ´ultimas
componentes de y e de z tamb´em s˜ao nulas. J´a que y e z satisfazem Ay = b e Az = b,

podemos escrever:

e

y1a1 + y2a2 + · · · + ymam = b

z1a1 + z2a2 + · · · + zmam = b,

(3.6)

(3.7)

em que ai ∈ Rm ´e a i-´esima coluna da matriz A para todo i = 1, · · · , m. Subtraindo (3.6)
de (3.5) temos: (x1 −y1)a1 +(x2 −y2)a2 +· · ·+(xm −ym)am = 0. Mas, como a1, a2, · · · , am
s˜ao linearmente independentes (LI) (vide [6] no Apˆendice), temos que xi − yi = 0 ∀ i =
1, · · · , m, ou seja, x = y. Analogamente, mostramos tamb´em que x = z. Logo, conclu´ımos
que x ´e um ponto extremo.

Reciprocamente, suponha que x seja um ponto extremo de K. Ent˜ao, n˜ao existem
x1, x2 ∈ K tais que x = αx1 + (1 − α)x2, α ∈ (0, 1). Suponha tamb´em que as k primeiras
componentes de x sejam n˜ao nulas, isto ´e:

x1a1 + x2a2 + · · · + xkak = b.

(3.8)

Para que x seja uma solu¸c˜ao b´asica vi´avel, a1, a2, · · · , ak devem ser LI. De fato, supo-
nha que a1, a2, · · · , aK sejam linearmente dependentes (LD). Isto signiﬁca que existem

y1, y2, · · · , yk n˜ao todos nulos tais que

y1a1 + y2a2 + · · · + ykak = 0

24

(3.9)

Como xi > 0 ∀ i = 1, · · · , k, tome ε > 0 tal que xi + εyi ≥ 0 e xi − εyi ≥ 0 ∀ i = 1, · · · , k.
Assim podemos escrever x = 1
2 (x − εy), contrariando a hip´otese de x ser um
ponto extremo. Portanto, a1, a2, · · · , ak s˜ao LI e x ´e uma solu¸c˜ao b´asica vi´avel para (3.1).
Observe que se k < m, teremos uma solu¸c˜ao b´asica vi´avel degenerada. ?

2 (x + εy) + 1

3.3 Teorema Fundamental da Programac¸ ˜ao Linear

Apresentaremos agora o resultado central deste cap´ıtulo, segundo o que ´e exposto em

LUENBERGER & YE (2008).

Teorema 3.6. Considere o problema de PL (3.1), e suponha que posto(A) = m.

(i) Se existe uma solu¸c˜ao vi´avel, ent˜ao existe uma solu¸c˜ao b´asica vi´avel.

(ii) Se existe uma solu¸c˜ao ´otima vi´avel, ent˜ao existe uma solu¸c˜ao ´otima b´asica vi´avel.

Prova:

(i) Vamos escrever A = ?a1 a2
T

· · · an?, onde a1, a2, · · · , an s˜ao as colunas de A.

Seja x = ?xB xN ?

uma solu¸c˜ao vi´avel para (3.1). Ent˜ao, Ax = b, ou seja,

x1a1 + x2a2 + · · · + xnan = b.

(3.10)

Sem perda de generalidade, suponha que x tenha as primeiras p componentes n˜ao nulas.

Da´ı,

x1a1 + x2a2 + · · · + xpap = b.

(3.11)

Devemos considerar dois casos: as primeiras p colunas de A podem ser LI ou LD.

Caso LI : Como a1, a2, · · · , ap s˜ao LI, temos que p ≤ m. Se p = m, teremos uma
solu¸c˜ao b´asica vi´avel e o teorema est´a provado. Se p < m, como posto(A) = m, escolhemos
m − p das n − p colunas restantes de A para formar um conjunto de m vetores LI,
encontrando, assim, uma solu¸c˜ao b´asica vi´avel degenerada.

Caso LD : Se os vetores a1, a2, · · · , ap s˜ao LD, ent˜ao existem y1, y2, · · · , yp, com

pelo menos um yi ?= 0 (i = 1, 2, · · · , p), tais que:

y1a1 + y2a2 + · · · + ypap = 0.

(3.12)

25

Suponha yi > 0 para algum i = 1, 2, · · · , p (se necess´ario, multiplique (3.12) por −1).
Tome ε ≥ 0. Multiplicando (3.12) por ε e subtraindo de (3.11) obtemos

(x1 − εy1)a1 + (x2 − εy2)a2 + · · · + (xp − εyp)ap = b.

(3.13)

Observe que ˜x = x − εy ´e uma solu¸c˜ao de Ax = b para todo ε, pois Ay = 0. Mas existe
a possibilidade de que para algum i = 1, 2, · · · , p tenhamos xi − εyi < 0. Nesse caso, a
solu¸c˜ao n˜ao ´e vi´avel para (3.1). Note que, se ε > 0, o valor de cada ˜xi = xi − εyi aumenta
quando yi < 0, diminui quando yi > 0 ou ´e mantido quando yi = 0. Como yi > 0 para
algum i = 1, 2, · · · , p, pelo menos uma das componentes de ˜x diminui quando ε aumenta.
Tome ε como sendo o menor valor tal que uma ou mais componentes de ˜x se anulem, ou

seja,

ε = min
1,2,··· ,p

?

yi > 0? .

xi
yi

?
?
?
?

(3.14)

xi
yj

. Usando esse valor de ε, eliminamos a componente

Seja j ∈ {1, · · · , p} tal que ε =
xj − εyj negativa e obtemos uma solu¸c˜ao vi´avel com, no m´aximo, p − 1 componentes
positivas. Caso o conjunto de vetores a1, a2, · · · , ap−1 ainda seja LD, repetimos o processo
at´e obtermos a1, a2, · · · , aq, com q < p, LI. Da´ı uma solu¸c˜ao b´asica vi´avel degenerada
pode ser obtida conforme o caso anterior.

(ii) Seja x∗ ∈ Rn uma solu¸c˜ao ´otima vi´avel para (3.1). Suponha, sem perda de
generalidade, que as p primeiras componentes de x∗ sejam n˜ao nulas. Como Ax∗ = b,

temos que x∗

1a1 + x∗

2a2 + · · · + x∗

pap = b.

Assim como no item (i), devemos considerar dois casos: as primeiras p colunas de

A podem ser LI ou LD. Nas duas situa¸c˜oes, a demonstra¸c˜ao ´e an´aloga `aquela feita an-

teriormente, restando apenas veriﬁcar que no caso LD a solu¸c˜ao obtida continua ´otima.
Para isso, vamos substituir x por ˜x = x∗ − εy na fun¸c˜ao objetivo de (3.1) e avaliar as
possibilidades. Note que

z(˜x) = cT ˜x = cT (x∗ − εy) = cT x∗ − εcT y.

?= 0 apenas quando x∗

Observe que yi
i > 0. Logo, para valores de ε suﬁcientemente
pequenos em magnitude, A˜x = b e ˜x = x∗ − εy ≥ 0. Isso nos faz concluir que cT y = 0,
pois, se n˜ao, para um valor adequado de ε, podemos obter uma solu¸c˜ao vi´avel ˜x, para a

qual, z(˜x) < z(x∗) contradizendo a hip´otese de que x∗ ´e solu¸c˜ao ´otima. ?

O Teorema Fundamental da Programa¸c˜ao Linear ´e especialmente importante porque

sua demonstra¸c˜ao fornece ferramentas para o desenvolvimento do M´etodo Simplex.

26

3.4 O M´etodo Simplex

Dado o problema de PL (3.1), resolvˆe-lo pelo M´etodo Simplex consiste em encontrar

uma solu¸c˜ao b´asica inicial e veriﬁcar se ela ´e ´otima. Se ela n˜ao for ´otima, deve-se achar

outra solu¸c˜ao b´asica determinando qual vari´avel b´asica dever´a sair da base e qual vari´avel

n˜ao b´asica dever´a entrar. Se a nova solu¸c˜ao n˜ao for ´otima, repete-se o processo. Em

outras palavras, o m´etodo vai de um ponto extremo a outro ponto extremo da regi˜ao

vi´avel do problema, gerando uma sequˆencia decrescente de valores da fun¸c˜ao objetivo.

Os pontos extremos s˜ao os v´ertices do poliedro que representa a regi˜ao vi´avel de (3.1).

Vamos, a seguir, fazer uma an´alise alg´ebrica do m´etodo, supondo a n˜ao ocorrˆencia de

solu¸c˜oes degeneradas.

Em (3.3), o vetor de vari´aveis b´asicas xB est´a expresso em fun¸c˜ao do vetor de vari´aveis
n˜ao b´asicas xN . Para fazer mudan¸cas de base, trocamos uma das colunas de B por uma
das colunas de N que seja linearmente independente com as colunas restantes de B.

Seja z : Rn

→ R, z(x) = cT x, a fun¸c˜ao objetivo de (3.1). O vetor de custos ´e dado
N ? ∈ Rn, onde cB ∈ Rm e cN ∈ Rn−m s˜ao, respectivamente, os vetores de

por cT = ?cT
custos associados `as vari´aveis b´asicas e `as vari´aveis n˜ao b´asicas.

B cT

Reescrevendo z e substituindo (3.3) em xB, temos:

z(x) = cT x = cT

BxB + cT

N xN = cT

B(B−1b − B−1N xN ) + cT

N xN =

= cT

BB−1b + (cT

N − cT

BB−1N )xN .

Fazendo

temos

N − cT
cT

BB−1N = rT
N

z(x) = cT

BB−1b + rT

N xN ,

(3.15)

(3.16)

em que rT

N ´e o vetor de custos relativos (ou reduzidos) associados `as vari´aveis n˜ao b´asicas.

Para escolher a vari´avel n˜ao b´asica xj que vai entrar na base, devemos observar o seu

custo relativo associado.

Observando (3.16), notamos que, quando rNj ´e maior, menor que ou igual a zero,
o valor da fun¸c˜ao objetivo aumenta, diminui ou n˜ao se altera, respectivamente.
Isso
nos mostra que, se rN ≥ 0, isto ´e, se rNj ≥ 0 para todo j = 1, · · · , n − m, temos
uma solu¸c˜ao ´otima para (3.1). Logo, rN ≥ 0 ´e o Crit´erio de Parada ou Crit´erio de
Otimalidade utilizado no M´etodo Simplex. Como pretendemos que o valor de z diminua

27

a cada itera¸c˜ao, as vari´aveis n˜ao b´asicas xj tal que rNj < 0 s˜ao candidatas a entrar na
base. Existem v´arios crit´erios para determinar qual vari´avel vai entrar na base, como por

exemplo, o Crit´erio de Dantzig (veja em ARENALES et al. (2007)), no qual ´e escolhida

a vari´avel com custo relativo mais negativo, ou a Regra de Bland (veja em BAZARAA et

al. (2010)), na qual o crit´erio de escolha ´e o menor ´ındice da vari´avel.

Para determinar a vari´avel que sair´a da base, observamos qual delas se anula primeiro

`a medida que xj aumenta de valor. Caso nenhuma vari´avel b´asica diminua de valor e, con-
sequentemente, xj aumente indeﬁnidamente sem violar a viabilidade de (3.1), conclu´ımos
que este problema ´e ilimitado.

Dada uma solu¸c˜ao b´asica vi´avel, seja xNj a vari´avel n˜ao b´asica que vai entrar na base.
Considere xNj = ε ≥ 0. De acordo com (3.16), com o acr´escimo de xNj , o valor de z passa
a ser

onde cNj ´e o custo associado a xNj .

¯z = cT

BB−1b + cNj ε,

Note que o valor de z decresce `a medida que ε cresce, j´a que cNj < 0.

Com a escolha de xNj , o vetor xN ter´a xNj = ε e as demais componentes nulas, ou

seja,









xN1
...
xNj
...
xNn−m
Isso implica que B−1N xN = B−1aNj ε, onde aNj ´e a coluna de N associada a xNj . Ent˜ao,
podemos reescrever (3.3) como:









































0
...
ε
...
0

xN =

=

.

xB = B−1b − B−1aNj ε.

Deﬁnindo ˆxB = B−1b e yj = B−1aNj , reescrevemos (3.17) como:

Observando (3.18) coordenada a coordenada, isto ´e,

xB = ˆxB − yjε.

xBi = ˆxBi − yijε, i = 1, · · · , m,

temos que:

(3.17)

(3.18)

(i) se yij ≤ 0 ∀ i = 1, · · · , m, ⇒ xBi ≥ 0 ∀ ε ≥ 0;

(ii) se yij > 0 para algum i = 1, · · · , m, devemos ter

ε = min ?

yij > 0? ,

ˆxBi
yij

?
?
?
?

para que a positividade das vari´aveis de (3.1) n˜ao seja violada.

28

(3.19)

Em (3.19), tomamos apenas as componentes positivas de yij. Caso contr´ario, o valor
da vari´avel xNj pode aumentar indeﬁnidamente, sem violar a viabilidade de (3.1). Se

ent˜ao xBk sair´a da base.

ˆxBk
yik
Chamamos de Teste da Raz˜ao o crit´erio de escolha da vari´avel que sai da base, dado

ε =

por (3.19).

Seja xBk a vari´avel que sai da base. A nova solu¸c˜ao b´asica ´e formada pela base anterior,
substituindo-se a coluna correspondente a xBk pela coluna correspondente a xNj . A nova
solu¸c˜ao ´e vi´avel e as vari´aveis que permaneceram na base s˜ao n˜ao negativas. Se o teste da

raz˜ao detectar que mais de uma vari´avel b´asica poder´a sair da base, isso signiﬁca que a

nova base ´e degenerada, pois cont´em vari´aveis b´asicas nulas. Nesse caso, escolhemos para
sair da base qualquer uma dessas vari´aveis que se anulam. Se yij ≤ 0 ∀ i = 1, · · · , m,
ε poder´a aumentar indeﬁnidamente, indicando que o conjunto solu¸c˜ao vi´avel de (3.1) ´e

ilimitado.

O processo descrito acima dever´a ser repetido at´e que rN ≥ 0.

Exemplo 3.7. Resolver o Exemplo 2.1 pelo M´etodo Simplex.

Primeiro reescrevemos o problema na forma padr˜ao, acrescentando x3 e x4 como

vari´aveis de folga:

min z = −x1 − x2
s. a 3x1 + 2x2 + x3

= 6

x1 + 2x2 +
x1, x2, x3, x4 ≥ 0.

x4 = 5

(3.20)

Escolhemos x3 e x4 para vari´aveis b´asicas iniciais. Ent˜ao temos que a solu¸c˜ao b´asica

inicial ´e










x1
x2
x3
x4










=



0



0

6

5















,

B = ?1 0
0 1
cN = ?−1
−1

?, N = ?3 2
1 2

?, B−1N xN = ?3 2
1 2

? = ?6
5

?, xB = ?x3
x4
? = ?0
0

? ?x1
x2

?, rT

29

?, xN = ?x1
x2

? = ?0
0

?, b = ?6
5

?, cB = ?0
0

?,

N = cT

N − cT

BB−1N = ?−1 −1?, e

z(x) = cT

BB−1b = ?0 0?

? = 0.

?6
5

1.a Itera¸c˜ao:

Como rN tem coeﬁcientes negativos, z = 0 n˜ao ´e o valor ´otimo. Escolhemos x1 para
entrar da base, usando como crit´erio o menor ´ındice, j´a que h´a empate no valor dos

coeﬁcientes.

Aplicando o teste da raz˜ao temos que min ?

6
3

,

5
1

? = 2, indicando que x3 deve sair da

base.

B = ?3 0
1 1

Fazendo as substitui¸c˜oes temos:
?, N = ?1 2
?, xB = ?x1
0 2
x4
?, xB = B−1b = ? 1/3 0
? ?6
−1/3 1
5
? = ? 1/3 2/3
−1/3 4/3

cN = ? 0
−1
B−1N = ? 1/3 0
−1/3 1

? ?1 2
0 2

? = ?2
3

?,

?.

?, xN = ?x3
x2

? = ?0
0

?, b = ?6
5

?, cB = ?−1
0

?,

A nova solu¸c˜ao b´asica ´e










x1
x2
x3
x4










=



2



0

0

3















,

N = cT
rT

N − cT

BB−1N = ?0 −1? − ?−1 0?

? 1/3 2/3
−1/3 4/3

? = ?1/3 −1/3? e

z(x) = cT

BB−1b = ?−1 0?

?2
3

? = −2.

2.a Itera¸c˜ao:

O valor de z diminui para −2, mas como x2 tem coeﬁciente negativo na fun¸c˜ao obje-

tivo, ainda n˜ao atingimos o valor ´otimo e x2 entra na base.

Teste da raz˜ao:

min ?

,

2
2
3

3
4
3

? = min ?3,

9
4

? =

9
4 ⇒ x4 sai da base.

Assim,
B = ?3 2
?, N = ?1 0
?, xB = ?x1
x2
1 2
0 1
? ?6
?, xB = B−1b = ? 1/2 −1/2
5
3/4

cN = ?0
0

−1/4

? = ?0
0

?, b = ?6
5

?, xN = ?x3
x4
? e B−1N = ? 1/2 −1/2
? = ?1/2
3/4
9/4

?, cB = ?−1
−1

?.

−1/4

30

?,

Solu¸c˜ao b´asica:










x1
x2
x3
x4












1/2



=








9/4

0

0

,








N = cT
rT

N − cT

BB−1N = ?0 0? − ?−1 −1?

? 1/2 −1/2
3/4
−1/4

? = ?1/4 1/4? e

z(x) = cT

BB−1b = ?−1 −1?

?1/2
9/4

? = −

11
4

.

Como, nessa itera¸c˜ao, rN ≥ 0, a solu¸c˜ao encontrada ´e ´otima e z assume valor ´otimo

igual a −

11
4

.

Exemplo 3.8. Resolver o Exemplo 2.2 pelo M´etodo Simplex.

Rescrevendo o problema (2.5) na forma padr˜ao temos:

min z = −3x1 − 2x2
s. a 3x1 + 2x2 + x3

= 6

x1 + 2x2 +
x1, x2, x3, x4 ≥ 0.

x4 = 5

(3.21)

Procedendo exatamente como no Exemplo 3.7, escolhendo x3 e x4 para vari´aveis

b´asicas iniciais, temos que a solu¸c˜ao b´asica inicial ´e










x1
x2
x3
x4










=



0



0

6

5















,

B = ?1 0
0 1
cN = ?−3
−2

?, N = ?3 2
1 2

?, B−1N xN = ?3 2
1 2

? = ?6
5

?, xB = ?x3
x4
? = ?0
0

? ?x1
x2

?, rT

?, xN = ?x1
x2

? = ?0
0

?, b = ?6
5

? cB = ?0
0

?,

N = cT

N − cT

BB−1N = ?−3 −2? e

31

z(x) = cT

BB−1b = ?0 0?

? = 0.

?6
5

1.a Itera¸c˜ao:

Como rN tem coeﬁcientes negativos, z = 0 n˜ao ´e o valor ´otimo. Escolhemos x1 para
entrar da base. Para determinar a vari´avel que deve sair da base, aplicamos o teste da

raz˜ao.

Como min ?

6
3

,

5
1

? = 2, x3 deve sair da base.

B = ?3 0
1 1

Fazendo as substitui¸c˜oes temos:
?, N = ?1 2
?, xB = ?x1
0 2
x4
?, xB = B−1b = ? 1/3 0
? ?6
−1/3 1
5
? = ? 1/3 2/3
−1/3 4/3

cN = ? 0
−2
B−1N = ? 1/3 0
−1/3 1

? ?1 2
0 2

?.

? = ?2
3

? e

?, xN = ?x3
x2

? = ?0
0

?, b = ?6
5

?, cB = ?−3
0

?,

Esta itera¸c˜ao produz solu¸c˜ao b´asica dada por

2

0

0

3

, com
















=

x1
x2









x3






x4



? ?1 2
? 1/3 0
0 2
−1/3 1

? = ?1 0? e

rT
N = cT

N − cT

BB−1N = ?0 −2? − ?−3 0?

z(x) = cT

BB−1b = ?−3 0?

?2
3

? = −6.

Como rN ≥ 0, conclu´ımos que z = −6 ´e o valor ´otimo da fun¸c˜ao objetivo. Entretanto,
no Exemplo 2.2, vimos que o problema em quest˜ao possui inﬁnitas solu¸c˜oes. Com o

objetivo de constatar esse fato atrav´es do Simplex, efetuaremos mais uma itera¸c˜ao do

m´etodo, retirando x4 da base, e colocando x2 na base.

Neste caso temos:

B = ?3 2
?, N = ?1 0
1 2
0 1
?, xB = B−1b = ? 1/2 −1/2
3/4

?, xB = ?x1
x2

cN = ?0
0

?, xN = ?x3
x4
? = ?1/2
9/4

? ?6
5

?,

B−1N = ? 1/2 −1/2
3/4
−1/4

? = ? 1/2 −1/2
3/4
−1/4

?,

−1/4
? ?1 0
0 1

? = ?0
0

?, b = ?6
5

?, cB = ?−3
−2

?,

N = cT
rT

N − cT

BB−1N = ?0 0? − ?−3 −2?

32

? 1/2 −1/2
3/4
−1/4

? = ?1 0? e

z(x) = cT

BB−1b = ?−3 −2?

?1/2
9/4

? = −6.

Logo, como rN ≥ 0, a nova solu¸c˜ao b´asica x =



1/2



9/4

0

0















permanece ´otima.

3.5 Problemas Degenerados

No M´etodo Simplex, quando temos uma solu¸c˜ao b´asica degenerada e a vari´avel que

sai da base tem valor nulo, a vari´avel que entra tamb´em ﬁca com valor nulo e a fun¸c˜ao

objetivo n˜ao se altera. Neste caso, acontece uma itera¸c˜ao degenerada e temos uma mesma

solu¸c˜ao com bases diferentes.

A ocorrˆencia de bases degeneradas, e consequentemente, de solu¸c˜oes degeneradas, faz

com que o Simplex efetue mais itera¸c˜oes. Outra possibilidade ´e a ocorrˆencia da ciclagem,

onde o Simplex repete inﬁnitamente uma mesma sequˆencia de solu¸c˜oes degeneradas. Neste

caso, o m´etodo falha, ou seja, n˜ao consegue encontrar a solu¸c˜ao ´otima do problema.

A Regra de Bland, citada na Se¸c˜ao 3.4, evita a ciclagem sem evitar as itera¸c˜oes

degeneradas. Uma outra alternativa consiste em evitar as itera¸c˜oes degeneradas. Para

tanto, perturbamos o vetor b adicionando um valor pequeno εi a cada componente de b.
Em geral toma-se εi = τi × 10−10, em que τi ∈ (0, 1).

Seja xB = B−1b a solu¸c˜ao ´otima do problema perturbado. Se xB ≥ 0, ent˜ao xB
´e solu¸c˜ao ´otima do problema original. Caso xB tenha alguma componente negativa,
mas com rN ≥ 0, dizemos que a solu¸c˜ao ´e otimista. Ou seja, ela satisfaz o crit´erio de
otimalidade, mas n˜ao ´e vi´avel.

Uma solu¸c˜ao b´asica vi´avel degenerada pode ser ´otima, mesmo que exista k tal que

rNk < 0. Uma solu¸c˜ao nestas condi¸c˜oes ser´a ´otima quando xBi = 0 e yij > 0, pois
aplicando o teste da raz˜ao para veriﬁcar qual vari´avel entrar´a na base, encontraremos

o que signiﬁca que n˜ao h´a como diminuir o valor da fun¸c˜ao objetivo sem violar a viabilidade

min ?

xBi
yij

?
?
?
?

yij > 0? = 0,

do problema.

Para ilustrar considere o seguinte exemplo:

Exemplo 3.9 (Adaptado do Exerc´ıcio 2.24-f de ARENALES et al. (2007)). Considere o

seguinte problema de otimiza¸c˜ao linear:

33

min z = −x1
s. a x1 + x2 ≤ 6
x1 − x2 ≤ 4
x2 ≤ 1

x1, x2 ≥ 0.

(3.22)

Obtenha graﬁcamente a solu¸c˜ao ´otima e, em seguida, veriﬁque que a solu¸c˜ao ´otima ´e dada

pela base correspondente `as vari´aveis x1, x2 e x4 (do problema na forma padr˜ao), por´em
a condi¸c˜ao de otimalidade n˜ao se veriﬁca.

Solu¸c˜ao:

A Figura 7 mostra que o v´ertice C ´e ´otimo. A solu¸c˜ao ´e dada por x1 = 5 e x2 = 1,

com valor ´otimo z = −5.

x2

D

A

0

2

x2 = 1
1

−1

−1

x1 + x2 = 6

C

−∇z

B

1

2

4
3
x1 − x2 = 4

5

6

z = −5

x1

Figura 7: Solu¸c˜ao gr´aﬁca de (3.22).

Reescrevendo (3.22) na forma padr˜ao e escolhendo as vari´aveis b´asicas de acordo com

o enunciado temos:

min z = −x1
s. a x1 + x2 + x3

= 6
x1 − x2 + x4 = 4
x5 = 1

x2 +

x1, x2, x3, x4, x5 ≥ 0,

B =

1
1 0
1 −1 1
1 0
0













, N =

1 0

0 0

0 1













, xB =







x1
x2
x4







, xN = ?x3
x5

? = ?0
0

?, b =

34

−1
0

0







,







6

4

1













, cB =

cN = ?0
0

?, xB = B−1b =

B−1N =







1 0 −1
0 0
1
−1 1

2

















6



4

1













=

5





1

0









e



1 0 −1
0 0
1
−1 1
1 0








2

=

0 0

0 1









1 −1
0
1
−1

2

.







Note que, nesta base, a solu¸c˜ao

vari´avel b´asica.












x1
x2
x3
x4
x5












=

5

1

0

0

0























´e degenerada, pois x4 = 0 e x4 ´e uma

N = cT
rT

N − cT

BB−1N = ?0 0? − ?−1 0 0?







1 −1
0
1
−1

2







= ?1 −1? e

z(x) = cT

BB−1b = ?−1 0 0?




N , a solu¸c˜ao ´e ´otima.

negativas em rT



5

1

0







= −5, ou seja, apesar de haver componentes

3.6 O M´etodo Simplex em Duas Fases

Na Se¸c˜ao 3.4 vimos que o Simplex parte de uma solu¸c˜ao b´asica vi´avel inicial. Em

problemas onde as restri¸c˜oes s˜ao da forma

Ax ≤ b
x ≥ 0,

(3.23)

onde b ≥ 0, a base inicial ´e obtida de forma imediata, pois ao acrescentarmos as vari´aveis
de folga xf para escrever o problema na forma padr˜ao, teremos

Ax + xf = b
≥ 0,

x, xf

e uma solu¸c˜ao b´asica vi´avel ´e dada por xf = b e x = 0.

Entretanto, uma solu¸c˜ao inicial nem sempre pode ser obtida de maneira trivial. Dado

um problema onde as restri¸c˜oes s˜ao da forma

35

Ax = b
x ≥ 0,

com A ∈ Mm×n(R), encontrar m colunas LI para formar uma submatriz B invert´ıvel pode
ser bastante trabalhoso, dependendo do valor de m.

Um procedimento para obter uma solu¸c˜ao b´asica vi´avel inicial em problemas assim

consiste em acrescentar novas vari´aveis xa, chamadas vari´aveis artiﬁciais, que, por n˜ao fa-

zerem parte do problema original, devem ser eliminadas resolvendo-se o problema artiﬁcial

dado por:

min za(x, xa) =

m
?j=1

xa
j

s. a Ax + xa = b

x, xa

≥ 0.

(3.24)

Em (3.24), uma base vi´avel ´e formada pelas colunas de A associadas `as vari´aveis

artiﬁciais. Aplica-se o M´etodo Simplex. Caso se obtenha solu¸c˜ao ´otima (ˆx, ˆxa) com

za(ˆx, ˆxa) = 0, teremos uma base formada por colunas de A associadas `as vari´aveis origi-

nais, que podem ser usadas para iniciar o problema original. Caso seja encontrada uma

solu¸c˜ao ´otima (ˆx, ˆxa) com za(ˆx, ˆxa) > 0, as vari´aveis artiﬁciais n˜ao s˜ao eliminadas do

problema original. Neste caso, conclui-se que o problema original ´e invi´avel.

Chamamos este procedimento de M´etodo Simplex em Duas Fases. A Fase I consiste

em resolver o problema artiﬁcial, e a Fase II consiste em resolver o problema original,

tomando como ponto inicial a solu¸c˜ao ´otima encontrada na Fase I.

No pr´oximo cap´ıtulo, deﬁniremos o conceito de dualidade em PL, e apresentaremos

algumas propriedades relacionadas a esse conceito.

36

4 DUALIDADE

Dado um problema de PL, existe um outro problema chamado dual, que ´e associado

ao problema original, chamado primal. No problema dual, o interesse ´e maximizar uma

nova fun¸c˜ao objetivo baseada nos recursos do primal e sujeita `a restri¸c˜oes relacionadas

aos custos do primal.

A teoria da dualidade fornece subs´ıdios importantes para o estudo de problemas de

PL, bem como uma abordagem alternativa para a resolu¸c˜ao dos problemas, atrav´es do

M´etodo Dual Simplex. O leitor interessado poder´a encontrar a descri¸c˜ao do m´etodo Dual

Simplex em ARENALES et al. (2007).

4.1 Formulac¸ ˜ao do Dual

Dado um problema de PL na forma canˆonica, o seu dual ´e obtido da seguinte forma:

os coeﬁcientes da fun¸c˜ao objetivo, agora de maximiza¸c˜ao, s˜ao os termos independentes do

primal; as restri¸c˜oes passam a ser de menor que ou igual a, e os novos termos independentes

s˜ao os coeﬁcientes da fun¸c˜ao objetivo original. Para haver correspondˆencia entre os custos

e recursos nos dois problemas, a matriz A deve ser transposta (vide [2] no Apˆendice).

Observe, na Tabela 1, primal e dual lado a lado.

Tabela 1: Compara¸c˜ao entre o primal e o dual, na forma canˆonica.

Problema primal:

Problema dual:

min z(x) = cT x

s. a Ax ≥ b
x ≥ 0

max w(y) = bT y

s. a AT y ≤ c

y ≥ 0

Para escrever o dual de um problema de PL na forma padr˜ao, procedemos de forma

semelhante: as restri¸c˜oes duais ﬁcam do tipo menor que ou igual a, a matriz A deve ser

transposta e as vari´aveis duais ﬁcam irrestritas com rela¸c˜ao ao sinal. Observe, na Tabela

2, o dual de um problema de PL na forma padr˜ao.

37

Tabela 2: Compara¸c˜ao entre o primal e o dual, na forma padr˜ao.

Problema primal:

Problema dual:

min z(x) = cT x

s. a Ax = b

x ≥ 0

max w(y) = bT y

s. a AT y ≤ c

y ∈ R

Todo vetor y que satisfaz as restri¸c˜oes duais ´e chamado de solu¸c˜ao dual vi´avel.

A Tabela 3 apresenta um resumo das regras para a constru¸c˜ao do dual. Caso o

problema de PL n˜ao esteja na forma padr˜ao ou na forma canˆonica, deve-se observar as

mudan¸cas em cada restri¸c˜ao e em cada vari´avel, como est´a indicado na tabela.

Tabela 3: Rela¸c˜oes primal-dual.

Primal (dual)

Minimiza¸c˜ao

Dual (primal)

Maximiza¸c˜ao

Coeﬁcientes da fun¸c˜ao objetivo

Termos independentes

Termos independentes

Coeﬁcientes da fun¸c˜ao objetivo

Matriz das restri¸c˜oes: A

Matriz das restri¸c˜oes: AT

Restri¸c˜ao

Vari´avel

?

?

=

?

?

livre

?

?

livre

?

?

=

Vari´avel

Restri¸c˜ao

Vejamos, agora, dois exemplos. No primeiro deles, al´em de escrever o dual, vamos com-

parar as solu¸c˜oes gr´aﬁcas de ambos os problemas. J´a no segundo, notaremos a redu¸c˜ao no

n´umero de vari´aveis para o problema dual, possibilitando resolvˆe-lo pelo m´etodo gr´aﬁco,

descrito na Se¸c˜ao 2.2.

Exemplo 4.1. O dual do problema de PL

´e dado por

min z = 2x1 + 3x2
s. a 3x1 + x2 ≥ 4
x1 + 4x2 ≥ 5
x1, x2 ≥ 0

max w = 4y1 + 5y2
s. a 3y1 + y2 ≤ 2
y1 + 4y2 ≤ 3
y1, y2 ≥ 0.

38

(4.1)

(4.2)

A Figura 8 mostra as solu¸c˜oes gr´aﬁcas dos problemas (4.1) e (4.2). O problema primal

tem solu¸c˜ao ´otima no v´ertice B, dada por x∗

1 = 1 e x∗

objetivo z∗ = 5. J´a o problema dual tem solu¸c˜ao no v´ertice F, dada por y∗

2 = 1, com valor ´otimo da fun¸c˜ao
7
11

5
11

1 =

2 =

e y∗

com valor ´otimo da fun¸c˜ao objetivo w∗ = 5.

Primal

Dual

y2

x2

A

5

4

3

2

1

B

2

1

G

−1

∇w

F

D

0

E

1

y1

2

w = 5

−1

0

1

2

3

4

C

5

x1

−1

−1

−2

−∇z

z = 5

Figura 8: Compara¸c˜ao das solu¸c˜oes gr´aﬁcas do problema primal (4.1) com o problema
dual (4.2).

Exemplo 4.2. O dual do problema de PL

´e dado por

min z = 5x1 + 7x2 + 3x3
s. a 2x1 + x2 + 3x3 ≥ 1
x1 + 2x2 − 4x3 ≥ 1
x1, x2, x3 ≥ 0

max w = y1 + y2
s. a 2y1 + y2 ≤ 5
y1 + 2y2 ≤ 7
3y1 − 4y2 ≤ 3
y1, y2 ≥ 0.

39

(4.3)

(4.4)

A Figura 9 mostra a solu¸c˜ao gr´aﬁca do dual de (4.3): o v´ertice D dado por y∗

1 = 1 e

2 = 3 ´e ´otimo para w∗ = 4.
y∗

y2

4
E

3

2

1

∇w

D

w = 4

C

A

0

B

1

−1

−1

2

3

4

5

y1

Figura 9: Solu¸c˜ao gr´aﬁca de (4.4)

A observa¸c˜ao do Exemplo 4.1 sugere que o valor ´otimo para o problema primal no

Exemplo 4.2 seja z = 4, igual ao valor observado no seu dual. De fato, esta e outras

propriedades s˜ao v´alidas, como veremos a seguir.

4.2 Propriedades

As propriedades aqui apresentadas, bem como suas demonstra¸c˜oes, s˜ao baseadas em

ARENALES et al. (2007) e em GOLDBARG & LUNA (2005).

Considere os conjuntos das solu¸c˜oes vi´aveis do primal (P) e das solu¸c˜oes vi´aveis do

40

dual (D), descritos a seguir:

P = {x ∈ Rn

|Ax = b, x ≥ 0},

D = {y ∈ Rm

|AT y ≤ c}.

Eles ser˜ao ´uteis para o que se segue.

Propriedade 4.3. O dual do dual ´e o primal.

Prova: Como vimos na se¸c˜ao anterior, o dual de um problema de PL na forma padr˜ao

´e mostrado na Tabela 2. Como as vari´aveis yi do dual s˜ao irrestritas em sinal, fazemos
− y− com y+, y− ≥ 0. Aplicando as manipula¸c˜oes apresentadas na Se¸c˜ao 2.1,
y = y+

temos:

min −bT y+ + bT y−
s. a AT y+

− Aty− + yf = c

y+, y−, yf

≥ 0,

(4.5)

em que yf ´e o vetor de vari´aveis de folga.

Note que o vetor de coeﬁcientes da fun¸c˜ao objetivo ´e dado por (−bT , bT , 0T ), c ´e o

vetor de termos independentes e a matriz de restri¸c˜oes ´e dada por ?AT

−AT

I?.

O dual de (4.5) ´e dado por:

max cT λ

s. a

?AT

−AT

T

I?

λ ≤ (−bT , bT , 0T )T ,

em que λ ´e o vetor de vari´aveis duais, ou seja,

max cT λ
s. a Aλ ≤ −b
−Aλ ≤ b
λ ≤ 0.

Como Aλ ≤ −b e −Aλ ≤ b, podemos rescrever (4.6) como

max cT λ
s. a Aλ = −b

λ ≤ 0.

(4.6)

(4.7)

Finalmente, fazendo λ = −x, obtemos:

min cT x

s. a Ax = b
x ≥ 0,

41

(4.8)

que ´e o problema primal. ?

Propriedade 4.4 (Dualidade Fraca). A fun¸c˜ao dual fornece um limitante inferior para
a fun¸c˜ao primal, ou seja, w(y) ≤ z(x), ∀ y ∈ D e ∀ x ∈ P.

Prova: Multiplicando `a esquerda, as restri¸c˜oes do primal, Ax = b, pela transposta do

vetor y de vari´aveis duais, temos

yT Ax = yT b.

As restri¸c˜oes do dual podem ser escritas como yT A ≤ cT . Como x ≥ 0, temos que

yT Ax ≤ cT x.

(4.9)

(4.10)

Logo, de (4.9) e (4.10), temos que: yT b ≤ cT x ⇒ bT y ≤ cT x ⇒ w(y) ≤ z(x). ?

Propriedade 4.5. O problema primal tem solu¸c˜ao ´otima se, e somente se, o dual tiver

solu¸c˜ao ´otima.

Prova: Faremos a prova supondo que a solu¸c˜ao ´otima do problema primal ´e n˜ao degene-

rada. Considere o problema primal e o seu dual como mostra a Tabela 2.

Suponha que x∗ seja a solu¸c˜ao ´otima do primal e seja B a base ´otima correspondente.

Ent˜ao x∗ = B−1b e rT

N = cT

N − cT

BB−1N ≥ 0. Logo cT

BB−1N ≤ cT

N . Agora, observe que:

BB−1N ≤ cT
cT

N ⇒ ?cT
BB−1N ? ≤ ?cT

B cT
B cT

BB−1N ? ≤ ?cT
N ? ⇒ cT

N ? ⇒ ?cT
B cT
BI
BB−1 ?B N ? ≤ ?cT
B cT

cT
BB−1N ? ≤ ?cT

B cT
BB−1A ≤ cT .

N ? ⇒ cT

N ? ⇒

?cT

BB−1B cT

Denotando y∗T = cT

BB−1 temos que y∗T A ≤ cT ou AT y∗ ≤ c, o que signiﬁca que y∗
´e uma solu¸c˜ao vi´avel para o dual. Resta-nos mostrar que y∗ ´e ´otima para o dual. Com

efeito, note que

bT y∗ = bT (B−1)T cB = (B−1b)T cB = x∗T

B cB = cT

Bx∗

B = cT

Bx∗

B + cT

N x∗

N = cT x∗, pois

N = 0.
x∗

Como x∗ ´e solu¸c˜ao vi´avel para o primal, bT y ≤ cT x∗ para todo y vi´avel para o dual.

Como bT y∗ = cT x∗, segue que y∗ ´e solu¸c˜ao ´otima do dual.

Suponha agora, que o dual tenha solu¸c˜ao ´otima. Escrevendo o dual na forma padr˜ao

42

e fazendo max w(y) = min − w(y), demostramos de maneira an´aloga que o primal tem
solu¸c˜ao ´otima. ?

Propriedade 4.6. Suponha que o primal tem solu¸c˜ao vi´avel (P ?= ∅). O problema primal
n˜ao tem solu¸c˜ao ´otima se, e somente se D = ∅, ou equivalentemente, o dual ´e invi´avel
se, e somente se o primal ´e ilimitado (z(x) → −∞).

Prova: Suponha que D ?= ∅. Temos 2 possibilidades:

(i) O dual n˜ao tem solu¸c˜ao ´otima. Neste caso, o dual ´e ilimitado. Isto signiﬁca que,
max{w(y) | y ∈ D} > +∞. Como P ?= ∅ e o primal n˜ao tem solu¸c˜ao ´otima, temos que
o primal ´e ilimitado. Logo, min{z(x) | x ∈ P} < −∞. Pela Propriedade 4.4, temos que
w(y) ≤ z(x) < −∞, o que ´e uma contradi¸c˜ao.

(ii) O dual tem solu¸c˜ao ´otima. Neste caso, pela Propriedade 4.5, o primal tem solu¸c˜ao

´otima, o que nega a hip´otese.

De (i) e (ii), conclu´ımos que D = ∅.

Reciprocamente, suponha que o primal tenha solu¸c˜ao ´otima. Ent˜ao, pela Propriedade
4.5, o dual tem solu¸c˜ao ´otima. Portanto, D ?= ∅, negando a hip´otese. Logo, o primal n˜ao
tem solu¸c˜ao ´otima. ?

Propriedade 4.7. Suponha que o dual tenha solu¸c˜ao vi´avel (D ?= ∅). O problema dual
n˜ao tem solu¸c˜ao ´otima se, e somente se P = ∅, ou equivalentemente, o primal ´e invi´avel
se, e somente se o dual ´e ilimitado (w(y) → ∞).

Prova: An´aloga `a demonstra¸c˜ao da Propriedade 4.6. ?

Propriedade 4.8. Sejam x∗ e y∗ solu¸c˜oes vi´aveis do primal e do dual, respectivamente.

Se z(x∗) = w(y∗), ent˜ao x∗ ´e solu¸c˜ao ´otima do primal e y∗ ´e solu¸c˜ao ´otima do dual.

Prova: Suponha que x∗ n˜ao seja solu¸c˜ao ´otima do primal. Ent˜ao existe x ∈ P tal que
z(x) < z(x∗) = w(y∗), contradizendo a Propriedade 4.4. Da mesma forma, suponha que
y∗ n˜ao seja solu¸c˜ao ´otima do dual. Ent˜ao existe y ∈ D tal que w(y) > w(y∗) = z(x∗),
tamb´em contradizendo a Propriedade 4.4. Logo, x∗ e y∗ s˜ao solu¸c˜oes ´otimas para o primal

e para o dual, respectivamente. ?

Seja o problema dual apresentado na Tabela 2. Escrevendo suas restri¸c˜oes na forma
padr˜ao e acrescentando, para vari´aveis de folga, o vetor µ ∈ Rn (com µ ≥ 0), temos
AT y + µ = c. Isolando µ e transpondo os dois membros, podemos reescrever esta equa¸c˜ao

como

µT = cT

− yT A.

43

(4.11)

Por outro lado, sejam x ∈ P e y ∈ D. Se z(x) = w(y), ent˜ao cT x = yT b. Substituindo
Ax = b temos cT x = yT Ax ⇒ cT x − yT Ax = 0 ⇒

(cT

− yT A)x = 0.

(4.12)

Note que o vetor cT

− yT A ´e o vetor de vari´aveis de folga µ escrito em (4.11). Cha-

mamos de folgas complementares essa rela¸c˜ao entre as solu¸c˜oes do primal e do dual.

Propriedade 4.9 (Folgas Complementares). As solu¸c˜oes x ∈ Rn e y ∈ Rm, do primal e
do dual, respectivamente, s˜ao ´otimas se, e somente se:

(x ´e solu¸c˜ao vi´avel primal)

Ax = b, x ≥ 0
AT y + µ = c, µ ≥ 0
(y ´e solu¸c˜ao vi´avel dual)
µjxj = 0, j = 1, · · · , n (folgas complementares)

Prova: Suponha que x∗ e y∗ sejam solu¸c˜oes ´otimas do primal e do dual, respectivamente.
Ent˜ao Ax∗ = b, x ≥ 0 e AT y∗ + µ∗ = c, µ ≥ 0, onde µ∗ ´e o vetor de vari´aveis de folga do
dual.

Pelo que foi demonstrado na Propriedade 4.5, se x∗ ´e solu¸c˜ao ´otima do primal e y∗ ´e

solu¸c˜ao vi´avel do dual, temos que cT x∗ = bT y∗. Desta igualdade, de (4.11) e de Ax∗ = b
segue que 0 = cT x∗ − bT y∗ = cT x∗ − y∗T b = cT x∗ − y∗T Ax∗ = (cT
− y∗T A)x∗ = µ∗T x∗.
Como µ∗

j ≥ 0 para j = 1, · · · , n, temos que µ∗

j = 0, para j = 1, · · · , n.

j ≥ 0 e x∗

j x∗

Reciprocamente, sejam x ∈ P e y ∈ D. Sejam ainda, AT y +µ = c, µ ≥ 0, as restri¸c˜oes
do dual escritas na forma padr˜ao. Suponha que µjxj = 0, j = 1, · · · , n. Ent˜ao µT x = 0.
− yT A)x = 0 ⇒ cT x = yT Ax.
Substituindo µ pela express˜ao dada em (4.11) temos (cT
Substituindo Ax = b temos cT x = yT b = bT y ⇒ z(x) = w(y). Logo, pela Propriedade
4.8, x e y s˜ao solu¸c˜oes ´otimas do primal e do dual. ?

Propriedade 4.10 (Dualidade Forte). As solu¸c˜oes x∗ ∈ P e y∗ ∈ D, do primal e do
dual, respectivamente, s˜ao ´otimas se, e somente se z(x∗) = w(y∗).

Prova: Suponha que x∗ e y∗ sejam solu¸c˜oes ´otimas do primal e do dual, respectivamente.

Ent˜ao, pela Propriedade 4.9, temos que

Ax∗ = b, x∗ ≥ 0;
AT y∗ + µ∗ = c, µ∗ ≥ 0 e
j x∗
µ∗

j = 0 para j = 1, · · · , n.

44

Mas µ∗

j x∗

j = 0 para todo j = 1, · · · , n implica em µ∗T x∗ = 0.

De (4.11) segue que µ∗ = c − AT y∗. Assim, temos que µ∗T x∗ = (cT

− y∗T A)x∗ ⇒ 0 =
(c − AT y∗)T x∗ ⇒ 0 = cT x∗ − y∗T Ax∗ ⇒ cT x∗ = y∗T Ax∗. Substituindo Ax∗ = b obtemos
cT x∗ = y∗T b = bT y∗, ou seja, z(x∗) = w(y∗).

A rec´ıproca ´e dada pela Propriedade 4.8. ?

A Tabela 4, extra´ıda de LACHTERMACHER (2007), apresenta resumidamente, as

rela¸c˜oes poss´ıveis entre as solu¸c˜oes dos problemas primal e dual de PL.

Tabela 4: Viabilidade primal-dual.

Dual

´Otimo

Ilimitado

Invi´avel

?

imposs´ıvel

imposs´ıvel

?

imposs´ıvel

?

?

Primal

´Otimo

Ilimitado

Invi´avel

No pr´oximo cap´ıtulo, abordaremos um exemplo cl´assico de problema de PL, conhecido

como “problema de transporte”, e uma proposta de atividade para alunos do Ensino

M´edio, que consiste na resolu¸c˜ao de uma vers˜ao simpliﬁcada desse problema, usando o

Microsoft Excel.

45

5 APLICAC¸ ˜OES

A Programa¸c˜ao Linear se aplica na modelagem e resolu¸c˜ao de problemas de diversas

´areas como, por exemplo, engenharia, economia, log´ıstica, agricultura e produ¸c˜ao indus-

trial. Os problemas s˜ao agrupados por semelhan¸ca na sua modelagem. Assim temos, por

exemplo, os problemas de mistura, que tratam, essencialmente, da combina¸c˜ao de mate-

riais preexistentes para gerar outros materiais, como acontece em fabrica¸c˜ao de ra¸c˜oes e

produ¸c˜ao de ligas met´alicas. Outros exemplos s˜ao citados e tratados em toda a bibliograﬁa

usada para este trabalho.

Neste cap´ıtulo, vamos tratar dos problemas de otimiza¸c˜ao em rede, na Se¸c˜ao 5.1, e,

com mais detalhes, dos problemas de transporte, na Se¸c˜ao 5.2.

5.1 Problemas de Otimizac¸ ˜ao em Rede

A estrutura de rede ou de grafo, segundo LACHTERMACHER (2007), ´e ´util para a

an´alise de diversos problemas pr´aticos.

Os diagramas que representam as redes s˜ao compostos por uma cole¸c˜ao de v´ertices ou

n´os simbolizados por c´ırculos que s˜ao interligados por linhas chamadas arcos, que revelam

a dire¸c˜ao do ﬂuxo de um n´o para outro. Observe a Figura 10.

A

a

c

1

c

d

2

e

f

B

Figura 10: Componentes de uma rede.

O problema de transporte, que vamos detalhar na pr´oxima se¸c˜ao, ´e um problema de

otimiza¸c˜ao em rede. Em ARENALES et al. (2007) e em LACHTERMACHER (2007),

encontramos outros exemplos. Entre eles, temos:

46

• Problemas de Roteamento de Ve´ıculos

S˜ao problemas nos quais se determinam rotas de entrega ou coleta a um custo

m´ınimo. As rotas (arcos) ligam uma ou mais origens a um n´umero de destinos. Os

n´os do diagrama de rede s˜ao as origens e os destinos.

• Problemas de Rede de Distribui¸c˜ao

S˜ao problemas em que os n´os representam origens, destinos e locais intermedi´arios,

e os arcos representam as rotas. O objetivo ´e otimizar o transporte entre origens e

destinos sem coleta ou entrega nos locais intermedi´arios.

• Problema do Menor Caminho

Neste tipo de problema, os arcos n˜ao representam rotas, mas distˆancias entre os

n´os. Aqui, o objetivo ´e minimizar distˆancias entre origens e destinos.

• Problemas de Fluxo M´aximo

Para estes problemas, o objetivo ´e maximizar a quantidade de ﬂuxo entre origens e

destinos. As restri¸c˜oes s˜ao dadas pelas capacidades de ﬂuxo em cada arco.

5.2 Problema de Transporte

Nosso objetivo nesta se¸c˜ao ´e apresentar os problemas de transporte em uma pers-

pectiva mais simples, visando a compreens˜ao dos seus componentes, a sua modelagem, a

obten¸c˜ao de uma solu¸c˜ao b´asica inicial e a sua resolu¸c˜ao, usando o Solver do Microsoft

Excel, por alunos de Ensino M´edio. O que ser´a apresentado est´a baseado, principal-

mente, em LACHTERMACHER (2007) e em HILLIER & LIEBERMAN (2006). Outras

referˆencias s˜ao citadas no decorrer do texto.

O problema de transporte consiste em determinar qual a maneira de distribuir produ-

tos que resulta em menor custo de transporte entre origens e destinos como, por exemplo,

f´abricas e centros de distribui¸c˜ao. Uma hip´otese a ser considerada ´e que o custo unit´ario

de transporte ´e constante, ou seja, independe da quantidade transportada.

Como exemplo, vamos considerar m origens, O1, O2, · · · , Om cada uma com, respecti-
vamente, a1, a2, · · · , am quantidades (ou ofertas) de um produto que devem ser enviadas

47

para n destinos D1, D2, · · · , Dn, cada um com, respectivamente, b1, b2, · · · , bn necessida-
des (ou demandas). A quantidade de produto a ser enviado da origem Oi ao destino Dj
´e dada por xij, sob um custo cij, para i = 1, · · · , m e j = 1, · · · , n. A Figura 11 ilustra a
rede que representa o problema.

origens

destinos

c11x11
c12x12

a1

O1

a2

O2

...

am

Om

cmnxmn

D1

b1

D2

b2

...

Dn

bn

Figura 11: Diagrama de rede do problema de transporte.

Quando o montante ofertado ´e igual ao total demandado, isto ´e, quando

m

?
i=1

ai =

n

?
j=1

bj,

dizemos que o problema est´a balanceado. Neste caso, o problema ´e expresso matematica-

mente por:

min z =

s. a

cijxij

n
?j=1

m
?i=1
xij = ai para i = 1, 2, · · · m,

n
?j=1
m
?i=1
xij ≥ 0 para todo i e j.

xij = bj para j = 1, 2, · · · n,

(a)

(b)

(c)

(5.1)

Em (5.1(a)) temos a fun¸c˜ao objetivo z : Rm+n

→ R, que representa o custo total de
transporte. As restri¸c˜oes de oferta s˜ao dadas por (5.1(b)) e em (5.1(c)) temos as restri¸c˜oes

de demanda.

Caso

m
?i=1

ai ?=

n
?j=1

bj podemos balancear o problema da seguinte forma:

(i) Se

m
?i=1

ai >

n
?j=1

bj (oferta maior que a demanda), acrescentamos um destino ﬁct´ıcio

chamado de dummy, com demanda igual a

nulo de todas as origens para este destino;

m
?i=1

ai −

n
?j=1

bj e custo de transporte unit´ario

48

(ii) Se

m
?i=1

ai <

n
?j=1

bj (oferta menor que a demanda), acrescentamos uma origem fan-

tasma, tamb´em chamada de dummy, com oferta igual a

unit´ario nulo para todos os destinos.

n
?j=1

bj −

m
?i=1

ai e custo de transporte

Apesar de facilitar a interpreta¸c˜ao dos resultados da otimiza¸c˜ao do problema, este

processo n˜ao ´e obrigat´orio para a sua resolu¸c˜ao.

Vejamos um exemplo simples:

Exemplo 5.1. Considere um produto produzido por duas f´abricas, A e B, que devem ser

transportados para 2 centros de distribui¸c˜ao, C1 e C2. Cada f´abrica produz 50 carrega-
mentos mensais e os centros de distribui¸c˜ao C1 e C2 necessitam de 40 e 50 carregamentos
mensais, respectivamente. A Tabela 5 mostra estas informa¸c˜oes, bem como os custos de

transporte de cada f´abrica a cada centro de distribui¸c˜ao.

Tabela 5: Custos de transporte, demandas e ofertas mensais.

Centro 1

Centro 2

Ofertas

F´abrica A

F´abrica B

Demandas

3

5

40

5

7

50

50

50

Observando a Tabela 5, notamos que s˜ao disponibilizados 10 carregamentos a mais do

que ´e necess´ario para suprir os centros de distribui¸c˜ao. Para balancear o sistema vamos

inserir um centro de distribui¸c˜ao ﬁct´ıcio denominado C3 com demanda de 10 carrega-
mentos e custo zero de transporte de cada f´abrica para ele. A introdu¸c˜ao deste centro

ﬁct´ıcio, ou dummy, indica uma capacidade ociosa das f´abricas e a mercadoria destinada

a ele continuar´a em estoque. A Figura 12 mostra o diagrama de rede para este problema

de transporte.

Matematicamente, o problema ´e dado por:

min z = 3x11 + 5x12 + 5x21 + 7x22
s. a x11 + x12 + x13

= 50

x11 +

x21 + x22 + x23 = 50
= 40
x21

x12 +

x22

= 50

x13 +
x11, x12, x13, x21, x22, x23 ≥ 0.

x23 = 10

(5.2)

F´abricas

Centros de distribui¸c˜ao

49

50

FA

50

FB

3x11
5x12

7x22

5x21

C1 40

C2 50

C3 10

Figura 12: Diagrama de rede para o Exemplo 5.1.

Para resolver um problema de transporte como (5.2), por exemplo, podemos aplicar

o M´etodo Simplex em Duas Fases (vide Se¸c˜ao 3.6), j´a que uma base vi´avel inicial n˜ao ´e

obtida imediatamente. Entretanto, veremos a seguir que, dada a estrutura do problema,

existem outras manteiras de se obter uma solu¸c˜ao inicial.

5.2.1 Obtendo uma soluc¸ ˜ao b´asica inicial

Observe que a matriz de restri¸c˜oes de (5.2) ´e dada por

A =

1 1 1 0 0 0

0 0 0 1 1 1

1 0 0 1 0 0

0 1 0 0 1 0

0 0 1 0 0 1












.












Note que a soma das 2 primeiras linhas ´e igual `a soma das 3 ´ultimas, indicando que

as linhas da matriz s˜ao LD. Entretanto, quaisquer 4 linhas s˜ao LI e, consequentemente,
qualquer submatriz B4×4 de A ´e n˜ao singular, indicando tamb´em, que temos 4 vari´aveis
b´asicas.

Problemas de transporte em geral tˆem matrizes de restri¸c˜oes semelhantes. Uma ma-

neira simpliﬁcada de representar essas matrizes ´e apresentada em LUENBERGER & YE
(2008). Para um problema com m origens e n destinos, seja I uma matriz identidade n×n
e 1T = (1, 1, · · · , 1), um vetor de dimens˜ao n, ent˜ao escrevemos a matriz de restri¸c˜oes, no
caso geral, como

50

1T



A =











1T

. . .

I

I

· · ·

,













1T

I

em que A tem m + n linhas e nm colunas.

Pode-se mostrar que, no caso geral, tamb´em temos m + n − 1 linhas linearmente

independentes. Uma base B ter´a dimens˜ao m + n − 1.

Essa caracter´ıstica dos problemas de transporte possibilita obter uma solu¸c˜ao b´asica

inicial sem acrescentar novas vari´aveis. Por serem simples e mais acess´ıveis para alunos

de Ensino M´edio, vamos descrever e exempliﬁcar o M´etodo do Canto Noroeste e o M´etodo

do Menor Custo (apresentado em WINSTON & GOLDBERG (2003)). Outros m´etodos

interessantes mas que n˜ao s˜ao tratados no texto s˜ao o M´etodo da Aproxima¸c˜ao de Vogel

e o M´etodo da Aproxima¸c˜ao de Russel, ambos descritos em HILLIER & LIEBERMAN

(2006).

Para aplicar qualquer um dos m´etodos citados acima, deve-se primeiro escrever o

problema no tableau de transportes, que ´e uma tabela t´ıpica para estes problemas, onde

est˜ao explicitados os custos de transporte e os valores de demanda e oferta. Veja a Tabela

6 no Exemplo 5.2.

M´etodo do Canto Noroeste

Na c´elula superior esquerda do tableau (da´ı o nome “canto noroeste”), alocamos o

m´aximo poss´ıvel da origem ou destino correspondente, zerando a disponibilidade da linha

ou da coluna da c´elula. Em seguida, escolhemos a c´elula `a direita ou abaixo que tenha

disponibilidade de linha e coluna correspondente e repetimos o processo, at´e completar a

quantidade de vari´aveis b´asicas. Neste m´etodo n˜ao consideramos o custo de transporte.

M´etodo do Menor Custo

Diferentemente do m´etodo anterior, agora observamos o custo para a escolha das

c´elulas. Inicialmente, escolhemos a c´elula com menor custo e alocamos o m´aximo para

ela, zerando a disponibilidade da linha ou da coluna da c´elula. Entre as linhas ou colunas

restantes, escolhemos a c´elula de menor custo e repetimos o processo, at´e completar

a quantidade de vari´aveis b´asicas ou at´e n˜ao haver mais disponibilidade de oferta ou

demanda. Em caso de empate, a escolha ´e arbitr´aria.

51

Nos dois m´etodos, ´e poss´ıvel que em uma c´elula, seja esgotada a disponibilidade da

linha e da coluna ao mesmo tempo. Isto ´e um indicativo de que a solu¸c˜ao encontrada ser´a

degenerada.

Para melhor compreens˜ao, vamos apresentar um exemplo adaptado de LACHTER-

MACHER (2007).

Exemplo 5.2. Uma vin´ıcola do sul de Santa Catarina possui trˆes f´abricas e trˆes armaz´ens

nos quais os vinhos s˜ao envelhecidos. Como as f´abricas e os armaz´ens est˜ao localizados

em diferentes locais do estado, a empresa deseja saber quantos ton´eis de vinho deve enviar

de cada f´abrica para cada armaz´em de forma a minimizar o seu custo de transporte. As

capacidades das f´abricas (C. F.) e dos armaz´ens (C. A.), em n´umero de ton´eis, bem

como os custos de transporte por tonel est˜ao explicitados na Tabela 6, a seguir. Modele

este problema e obtenha uma solu¸c˜ao b´asica inicial pelo M´etodo do Canto Noroeste e pelo

M´etodo do Menor Custo.

Tabela 6: Custos de transporte e capacidades das f´abricas e dos armaz´ens.

Arm. 1

Arm. 2

Arm. 3

C. F.

F´abrica A

F´abrica B

F´abrica C

20

10

12

16

10

18

24

8

10

300

500

200

C. A.

200

400

300

Solu¸c˜ao: As vari´aveis do problema s˜ao facilmente extra´ıdas da Tabela 6. Temos x11 que
representa a quantidade de ton´eis a serem transportados da F´abrica A at´e o Armaz´em 1,

com custo 20, x12, representando a quantidade de ton´eis a serem transportados da F´abrica
A at´e o Armaz´em 2, com custo 16, e assim por diante. A capacidade total dos armaz´ens

(demanda total) ´e de 900 ton´eis, enquanto que a capacidade total das f´abricas (oferta

total) ´e de 1000 ton´eis. Para balancear o sistema, vamos introduzir um armaz´em ﬁct´ıcio

(Arm. 4) com custos de transporte nulos para ele. Com isso, temos mais trˆes vari´aveis:

x14, x24 e x34. Assim, o modelo matem´atico do problema ´e dado por

52

min z = 20x11 + 16x12 + 24x13 + 10x21 + 10x22 + 8x23 + 12x31 + 18x32 + 10x33
= 300
s. a x11 + x12 + x13 + x14

x21 + x22 + x23 + x24

= 500

x11 +

x12 +

x21 +

x22 +

x13 +

x14 +

x23 +

x24 +

x31 + x32 + x33 + x34 = 200
= 200
x31

(5.3)

x32

x33

= 400

= 300

x34 = 100

x11, x12, x13, x14, x21, x22, x23, x24, x31, x32, x33, x34 ≥ 0.

Como o problema ﬁcou com 3 restri¸c˜oes de oferta e 4 restri¸c˜oes de destino, temos 6

vari´aveis b´asicas.

Obtendo uma solu¸c˜ao b´asica inicial pelo M´etodo do Canto Noroeste:

A Tabela 7 mostra o problema no tableau de transporte. Os n´umeros ordinais mos-

tram a ordem em que alocamos valores para as vari´aveis. Primeiro escolhemos a c´elula

correspondente a x11 e alocamos 200, que ´e o valor m´aximo para esta coluna. Em seguida
alocamos 100 para a c´elula correspondente a x12, zerando a capacidade de F A. Abaixo,
na c´elula de x22, alocamos 300 ton´eis completando a demanda de A 2. Alocamos 200
para x23, zerando a capacidade de F B, completamos a coluna de A 3 com 100 para x33
e, ﬁnalmente, designamos 100 ton´eis para x34, zerando as capacidades de F C e de A 4,
simultaneamente.

Tabela 7: Aplicando o m´etodo do canto noroeste.

A 1

A 2

A 3

A 4

C. F.

20

1o

10

12

F A

F B

F C

200

16

2o

10

3o

18

100

300

24

8

4o

10

5o

200

100

0

0

0

6o

300

500

200

100

C. A.

200

400

300

100

Logo, uma solu¸c˜ao b´asica inicial ´e dada por x11 = 200, x12 = 100, x22 = 300, x23 =

53

200, x33 = 100 e x34 = 100. As demais vari´aveis (n˜ao b´asicas) assumem valor nulo. Para
essa solu¸c˜ao, a fun¸c˜ao objetivo assume valor z = 11200.

Obtendo uma solu¸c˜ao b´asica inicial pelo M´etodo do Menor Custo:

Observe, agora, a Tabela 8. Como a coluna de A 4 tem custo zero, podemos come¸car

com qualquer uma delas. Escolhemos a c´elula correspondente a x14 e alocamos 100 ton´eis,
que ´e o m´aximo poss´ıvel para esta coluna. Entre as colunas restantes, a c´elula de menor

custo ´e a de x23. Alocamos 300 ton´eis para esta c´elula, zerando a capacidade da coluna de
A 3. Em seguida escolhemos a c´elula de x22 (note que h´a empate na escolha) e alocamos
200 ton´eis, zerando a capacidade da linha de F B. A pr´oxima c´elula deve ser a de x31 que
suporta 200 ton´eis, eliminando a linha e a coluna correspondente. Finalmente alocamos

200 para a c´elula de x12.

Tabela 8: Aplicando o m´etodo do menor custo.

A 1

A 2

A 3

A 4

C. F.

F A

F B

F C

20

10

12

4o

200

16

5o

10

3o

18

200

200

24

8

2o

10

300

0

1o

0

0

100

300

500

200

C. A.

200

400

300

100

Por este m´etodo, a solu¸c˜ao ´e dada por x12 = 200, x14 = 100, x22 = 200, x23 = 300 e
x31 = 200, com as demais vari´aveis nulas e a fun¸c˜ao objetivo assumindo o valor z = 10000.
Note que essa ´e uma solu¸c˜ao degenerada.

Para este exemplo, o m´etodo do menor custo apresenta uma solu¸c˜ao b´asica inicial

com menor valor de fun¸c˜ao objetivo que o m´etodo do canto noroeste, mas nem sempre ´e

assim, como se pode veriﬁcar ao se aplicar os dois m´etodos para o problema do Exemplo

5.2. Mesmo assim, os dois m´etodos s˜ao f´aceis de se aplicar e ensinar.

5.2.2 Viabilidade e Soluc¸ ˜ao ´Otima

Um problema de transporte balanceado ´e sempre vi´avel.

Isso decorre do fato de
termos n + m − 1 equa¸c˜oes linearmente independentes. Este resultado ´e enunciado e

54

demonstrado em LUENBERGER & YE (2008) e a aplicabilidade do M´etodo do Canto

Noroeste evidencia a viabilidade.

Para obter a solu¸c˜ao ´otima de problemas de transporte, pode-se usar o M´etodo Sim-

plex descrito no Cap´ıtulo 3. Por´em existe uma varia¸c˜ao do Simplex que se vale das

propriedades do problema dual para obter a solu¸c˜ao ´otima de maneira mais eﬁciente.

Uma op¸c˜ao interessante para se trabalhar com alunos de Ensino M´edio ´e o Solver do Mi-

crosoft Excel. O Solver ´e um suplemento do Microsoft Excel, desenvolvido pela empresa

Frontline Systems, Inc. Ao resolver problemas lineares, esse suplemento usa o M´etodo

Simplex. A planilha eletrˆonica Calc do LibreOﬃce, tamb´em oferecem recurso semelhante,

mas, por ser mais popular, vamos mostrar como obter a solu¸c˜ao ´otima de um problema

de transporte usando o Solver.

Vamos usar os problemas (5.2) e (5.3) como exemplos e a vers˜ao 2007 do Microsoft

Excel. Partimos do pressuposto de que o leitor tenha conhecimento b´asico do uso de

planilhas eletrˆonicas e que o Solver esteja habilitado.

Obtendo a solu¸c˜ao ´otima do problema (5.2)

(i) Escrevendo os dados do problema na planilha (acompanhe na Figura 13):

Para a fun¸c˜ao objetivo: identiﬁcamos as vari´aveis de decis˜ao na linha 3, para ajudar

na organiza¸c˜ao, delimitamos as c´elulas de D5 a I5, sem preenchimento, para representar

as vari´aveis de decis˜ao para o Excel e, na c´elula D6, escrevemos a f´ormula para o c´alculo

do valor de z, dada por

=(D5*D4)+(E5*E4)+(F5*F4)+(G5*G4)+(H5*H4)+(I5*I4).

Para as restri¸c˜oes: identiﬁcamos as vari´aveis de decis˜ao na linha 9. Nas linhas 10 a

14, escrevemos os coeﬁcientes das vari´aveis de cada uma das cinco restri¸c˜oes. Na coluna

RHS (right hand side), escrevemos os termos independentes e na coluna LHS (left hand

side), escrevemos a f´ormula pra cada restri¸c˜ao. Na c´elula J10 a f´ormula ´e dada por

=(D10*D$5)+(E10*E$5)+(F10*F$5)+(G10*G$5)+(H10*H$5)+(I10*I$5).

O s´ımbolo $, da maneira que foi usado, serve para ﬁxar a linha das c´elulas vari´aveis para

que se possa copiar a f´ormula para as outras restri¸c˜oes. Racioc´ınio an´alogo ´e empregado

para as c´elulas J11 a J14.

(ii) Utilizando o Solver :

55

Figura 13: Planilha com os dados de (5.2).

Na janela “Parˆametros do Solver”, mostrada na Figura 14 e obtida a partir do menu

“Dados”, devemos, primeiro, informar a c´elula de destino, D6, que indica o valor de z,

selecionar “Min”, uma vez que o nosso problema ´e de minimiza¸c˜ao, indicar as c´elulas

vari´aveis e adicionar as restri¸c˜oes, clicando no bot˜ao “Adicionar”.

Figura 14: Janela “Parˆametros do Solver” para (5.2).

Na janela “Adicionar restri¸c˜ao” (veja na Figura 15), para adicionar a primeira res-

tri¸c˜ao, escolhemos a c´elula J10 na coluna LHS, em “Referˆencia de c´elula”. Em seguida,

selecionamos o sinal de igual e, depois, em “Restri¸c˜ao”, inserimos a c´elula K10 da coluna

RHS. Clicamos em “Adicionar”, repetimos o processo para a segunda restri¸c˜ao, e assim

por diante, e clicamos em “OK” para ﬁnalizar.

De volta `a janela “Parˆametros do Solver”, clicamos em “Op¸c˜oes”. Na Janela “Op¸c˜oes

do Solver” (Figura 16), devemos marcar duas op¸c˜oes importantes: “Presumir modelo

linear” e “Presumir n˜ao negativos” para acrescentar as restri¸c˜oes de n˜ao negatividade

das vari´aveis. Para ﬁnalizar, clicamos em “OK” e, na janela “Parˆametros do Solver”,

56

Figura 15: Janela “Adicionar restri¸c˜ao”.

clicamos em “Resolver”.

Figura 16: Janela “Op¸c˜oes do Solver”para (5.2).

A solu¸c˜ao do problema ´e apresentada nas c´elulas vari´aveis, como mostra a Figura 17.

Como se pode ver, a solu¸c˜ao ´otima do problema (5.2) ´e dada por x11 = 40, x12 = 10,
x22 = 40, e x23 = 10. As demais vari´aveis ﬁcam nulas e a fun¸c˜ao objetivo assume valor
m´ınimo z = 450.

Obtendo a solu¸c˜ao ´otima do problema (5.3)

(i) Escrevendo os dados do problema na planilha (acompanhe na Figura 18):

Para a fun¸c˜ao objetivo: identiﬁcamos as vari´aveis de decis˜ao na linha 3, delimitamos

as c´elulas de D5 a O5, sem preenchimento, para representar as vari´aveis de decis˜ao, e na

c´elula D6, escrevemos a f´ormula para o c´alculo do valor de z, dada por

=(D5*D4)+(E5*E4)+(F5*F4)+(G5*G4)+(H5*H4)+(I5*I4)+

(J5*J4)+(K5*K4)+(L5*L4)+(M5*M4)+(N5*N4)+(O5*O4).

Para as restri¸c˜oes: identiﬁcamos as vari´aveis de decis˜ao na linha 9. Nas linhas 10 a

16, escrevemos os coeﬁcientes das vari´aveis de cada uma das sete restri¸c˜oes. Na coluna

57

Figura 17: Planilha com a solu¸c˜ao de (5.2).

RHS, escrevemos os termos independentes, e na coluna LHS escrevemos a f´ormula para

cada restri¸c˜ao. Na c´elula P10, a f´ormula ´e dada por

=(D10*D$5)+(E10*E$5)+(F10*F$5)+(G10*G$5)+(H10*H$5)+(I10*I$5)+

(J10*J$5)+(K10*K$5)+(L10*L$5)+(M10*M$5)+(N10*N$5)+(O10*O$5).

Racioc´ınio an´alogo ´e feito para as c´elulas P11 a P16.

Figura 18: Planilha com os dados de (5.3).

(ii) Utilizando o Solver :

Na janela “Parˆametros do Solver”, mostrada na Figura 19, devemos informar a c´elula

de destino, D6, selecionar “Min”, pois o problema ´e de minimiza¸c˜ao, indicar as c´elulas

vari´aveis e adicionar as restri¸c˜oes, clicando no bot˜ao “Adicionar”.

58

Figura 19: Janela “Parˆametros do Solver”para (5.3).

Na janela “Adicionar restri¸c˜ao” (Figura 15), para adicionar a primeira restri¸c˜ao, esco-

lhemos a c´elula P10 na coluna LHS, para “Referˆencia da c´elula”, em seguida selecionamos

igualdade e depois, para “Restri¸c˜ao”, inserimos a c´elula Q10 da coluna RHS. Clicamos em

“Adicionar”, repetimos o processo para a segunda restri¸c˜ao e assim por diante, e clicamos

em “OK” para ﬁnalizar.

De volta `a janela “Parˆametros do Solver”, clicamos em “Op¸c˜oes”, marcamos “Pre-

sumir modelo linear” e “Presumir n˜ao negativos”, clicamos em “OK” (assim como na

Figura 16) e, na janela “Parˆametros do Solver”, clicamos em “Resolver”.

A solu¸c˜ao do problema ´e apresentada nas c´elulas vari´aveis, como se pode observar na

Figura 20.

Figura 20: Planilha com a solu¸c˜ao de (5.3).

A solu¸c˜ao ´otima do problema 5.2 ´e dada por x12 = 200, x14 = 100, x21 = 200,
x22 = 200, x23 = 100 e x33 = 200. As demais vari´aveis ﬁcam nulas e a fun¸c˜ao objetivo

assume valor m´ınimo z = 10000.

Note que a solu¸c˜ao obtida pelo m´etodo do menor custo produziu o mesmo valor para

z, indicando que este problema tem mais de uma solu¸c˜ao ´otima.

59

60

6 CONSIDERAC¸ ˜OES FINAIS

Para apresentar a Programa¸c˜ao Linear e os seus fundamentos te´oricos, nos valemos, a

exemplo dos autores consultados, da resolu¸c˜ao gr´aﬁca para mostrar visualmente a regi˜ao

vi´avel de um problema de PL de duas vari´aveis e como localizar a sua solu¸c˜ao ´otima. Sob

esta perspectiva, temos uma melhor compreens˜ao dos conceitos relacionados ao M´etodo

Simplex, inclusive no que diz respeito `as itera¸c˜oes necess´arias para se chegar a solu¸c˜ao

´otima, pois, como cada v´ertice do pol´ıgono vi´avel ´e uma solu¸c˜ao b´asica, o Simplex n˜ao

precisa necessariamente passar por todas at´e identiﬁcar a ´otima, uma vez que, a cada

itera¸c˜ao, uma solu¸c˜ao melhor que a anterior ´e veriﬁcada. Na Se¸c˜ao 3.1 mostramos que

um problema de PL escrito na forma padr˜ao com m equa¸c˜oes e n inc´ognitas tem no

m´aximo

solu¸c˜oes b´asicas.

n!
m!(n − m)!

Outro aspecto interessante do m´etodo gr´aﬁco ´e que ele pode ser trabalhado no Ensino

M´edio sem grandes diﬁculdades, principalmente se for associado ao uso do GeoGebra.

Alguns trabalhos apresentados ao PROFMAT exploram esta possibilidade.

Os exemplos apresentados na Se¸c˜ao 3.4 foram resolvidos usando a mesma metodologia

usada para descrever o Simplex, uma vez que o nosso objetivo consiste apenas em descrever

o m´etodo, devido `a sua importˆancia, inclusive hist´orica.

Um outro m´etodo utilizado para resolver problemas de PL, chamado de M´etodo de

Pontos Interiores, foi desenvolvido a partir de 1984 pelo matem´atico indiano Narendra

K. Karmarkar. De acordo com HILLIER & LIEBERMAN (2006), semelhantemente ao

M´etodo Simplex, o algoritmo de Karmarkar ´e interativo, se inicia identiﬁcando uma

solu¸c˜ao experimental vi´avel e, a cada itera¸c˜ao, move-se da solu¸c˜ao experimental atual

para outra melhor dentro da regi˜ao vi´avel do problema. Entretanto, essas solu¸c˜oes expe-

rimentais s˜ao pontos do interior da regi˜ao vi´avel.

Para os problemas de transporte, vale ressaltar que a sua representa¸c˜ao em forma

de rede ajuda em muito a sua compreens˜ao, principalmente por alunos de n´ıvel m´edio.

N˜ao ´e dif´ıcil modelar matematicamente problemas semelhantes aos exemplos que foram

apresentados e ´e poss´ıvel explorar situa¸c˜oes reais que n˜ao envolvam muitas vari´aveis. O

uso de planilhas eletrˆonicas para resolver um problema de transporte ´e relativamente

simples e perfeitamente acess´ıvel para os alunos.

61

62

Referˆencias

1 ANTON, Howard; RORRES, Chris; ´Algebra Linear com Aplica¸c˜oes. 8 ed. Porto
Alegre: Bookman, 2001.

2 ARENALES, Marcos; ARMENTANO, Vin´ıcius; MORABITO, Reinaldo; YANASSE,
Horacio; Pesquisa Operacional. Rio de Janeiro: Elsevier, 2007.

3 BAZARAA, M. S.; JARVIS, J. J.; SHERALI, H. D.; Linear Programming and
Network Flows. 4. ed. New Jersey: Wiley, 2010.

4 BOLDRINI, Jos´e Luis; COSTA, Sueli I. Rodrigues; FIGUEIREDO, Vera L´ucia;
WETZLER, Henry G. ´Algebra Linear. 3 ed. S˜ao Paulo: HARBRA, 1986.

5 BRASIL. Minist´erio da Educa¸c˜ao, Secretaria de Educa¸c˜ao M´edia e Tecnol´ogica.
Parˆametros Curriculares Nacionais: Ensino M´edio. Bras´ılia: Minist´erio da
Educa¸c˜ao, 1999.

6 CAIXETA FILHO, J. V.; Pesquisa operacional aplicada ao sistema agro-
industrial. Relat´orio T´ecnico de Projeto de Pesquisa, apoiado pelo CNPq. 1997.
184p.

7 FRONTLINE Solvers. Developers of the Excel Solver. Dispon´ıvel em:
<http://www.solver.com>. Acesso em 10 out. 2014.

8 GOLDBARG, Marco; LUNA, Henrique; Otimiza¸c˜ao Combinat´oria e
Programa¸c˜ao Linear. 2 ed. Rio de Janeiro: Elsevier, 2005.

9 HILLIER, Frederick S.; LIEBERMAN, Gerald J.; Introdu¸c˜ao `a Pesquisa
Operacional. 8 ed. S˜ao Paulo: McGraw-Hill, 2006.

10 LACHTERMACHER, Gerson; Pesquisa Operacional na Tomada de Decis˜oes.
3 ed. Rio de Janeiro: Elsevier, 2007.

11 LUENBERGER, David G.; YE, Yinyu; Linear and Nonlinear Programming. 3
ed. New York: Springer Science+Business Media, LLC, 2008.

12 STEWART, James; C´alculo, volume 2. 5 ed. S˜ao Paulo: Thomson Learning, 2007.

13 WINSTON, Wayne L.; GOLDBERG, Jeﬀrey B. Operations Research
Applications and Algorithms. 4 ed. Belmont: Brooks/Cole, 2003.

63

AP ˆENDICE A

As deﬁni¸c˜oes apresentadas em [1] e [2] s˜ao encontradas em ANTON & RORRES

(2001), as deﬁni¸c˜oes mostradas em [3], [4], [5], [6], [7] e [8] s˜ao encontradas em BOL-

DRINI et al. (1986), em [9] a deﬁni¸c˜ao exposta est´a em STEWART (2007) e as deﬁni¸c˜oes

apresentadas em [10], [11] e [12] est˜ao em BAZARAA et al. (2010).

[1] Produto de matrizes e nota¸c˜ao matricial para sistemas lineares

Se A ´e uma matriz m × r e B ´e uma matriz r × n, ent˜ao o produto AB ´e a matriz
m × n cujas entradas s˜ao determinadas como segue. Para obter o elemento situado
na linha i e coluna j de AB, destaque a linha i de A e a coluna j de B. Multiplique

as entradas correspondentes desta linha e desta coluna e ent˜ao some os produtos

resultantes. Para que esta multiplica¸c˜ao seja poss´ıvel ´e necess´ario que o n´umero de

colunas do primeiro fator A seja igual ao n´umero de linhas do segundo fator B.

Matrizes-linha e coluna fornecem uma maneira alternativa de ver a multiplica¸c˜ao

matricial. Suponha, por exemplo, que

A =










a12
a11
a22
a21
...
...
am1 am2

· · · a1n
· · · a2n
...
· · · amn










e x =










x1
x2
...
xn










.

Ent˜ao

Ax =










a11x1 + a12x2 + · · · + a1nxn
a21x1 + a21x2 + · · · + a2nxn

...

...

...

am1x1 + am2x2 + · · · + amnxn

= x1



















a11
a21
...
am1










+ x2










a12
a22
...
am2










+ · · · + xn










a1n
a2n
...
amn










.

Dizemos que o produto Ax de uma matriz A por uma matriz-coluna x ´e uma com-

bina¸c˜ao linear das matrizes-coluna de A cujos coeﬁcientes s˜ao as entradas da matriz-

coluna x.

A multiplica¸c˜ao matricial pode ser aplicada a sistemas de equa¸c˜oes lineares como

veremos agora. Considere um sistema linear qualquer de m equa¸c˜oes em n inc´ognitas

64

a11x1 + a12x2 + · · · + a1nxn = b1
a21x1 + a22x2 + · · · + a2nxn = b2
...
am1x1 + am2x2 + · · · + amnxn = bm.

...

...

...






Como duas matrizes s˜ao iguais se, e somente se, suas entradas correspondentes s˜ao

iguais, podemos substituir as m equa¸c˜oes deste sistema por uma ´unica equa¸c˜ao

matricial










a11x1 + a12x2 + · · · + a1nxn
a21x1 + a21x2 + · · · + a2nxn

...

...

...

am1x1 + am2x2 + · · · + amnxn

=



















b1
b2
...
bm










.

A matriz m × 1 `a esquerda desta equa¸c˜ao pode ser escrita como um produto:










a11
a12
a21
a21
...
...
am1 am2

· · · a1n
· · · a2n
...
· · · amn



















x1
x2
...
xn










=










b1
b2
...
bm










.

Denotando estas matrizes por A, x e b, respectivamente, o sistema original de m

equa¸c˜oes em n inc´ognitas foi substitu´ıdo pela equa¸c˜ao matricial

Ax = b.

A matriz A nessa equa¸c˜ao ´e chamada matriz de coeﬁcientes do sistema linear.

No caso dos sistemas de inequa¸c˜oes lineares, como acontece em Programa¸c˜ao Linear,

aplica-se de maneira an´aloga o que foi exposto at´e agora. Quando escrevemos, por
exemplo, Ax ≤ b, estamos comparando as respectivas entradas de Ax e de b. De
maneira an´aloga, dado um vetor

x =










x1
x2
...
xn










,

escrever x ≥ 0 equivale a dizer que xi ≥ 0 ∀ i = 1, · · · , n.

65

[2] Transposta de matrizes e vetores

Se A ´e uma matriz m × n qualquer, ent˜ao a transposta de A, denotada por AT , ´e
deﬁnida como a matriz n × m que resulta da permuta¸c˜ao das linhas com as colunas
de A, ou seja, a primeira coluna de AT ´e a primeira linha de A, a segunda coluna
de AT ´e a segunda linha de A, e assim por diante. No caso de um vetor-coluna v,
basta consider´a-lo como uma matriz n × 1, assim, vT ter´a 1 linha e n colunas. No
caso de um vetor-linha u, basta consider´a-lo como uma matriz 1 × n, assim, uT ter´a
n linhas e 1 coluna.

[3] Produto Interno

Seja V um espa¸co vetorial sobre R. Entende-se por produto interno sobre V uma
aplica¸c˜ao que transforma cada par ordenado (u, v) ∈ V em um n´umero real, deno-
tado por ?u, v?, que satisfaz `as seguintes propriedades:

(a) ?u, u? ≥ 0 ∀ u ∈ V e ?u, u? = 0 ⇔ u = 0;

(b) ?αu, v? = α?u, v? ∀ α ∈ R e ∀ u, v ∈ V;

(c) ?u + v, w? = ?u, v? + ?v, w? ∀ u, v, w ∈ V; e

(d) ?u, v? = ?v, u? ∀ u, v ∈ V.

No espa¸co vetorial Rn o produto interno usual ´e deﬁnido da seguinte forma:

Dados v =










x1
x2
...
xn










e w =










y1
y2
...
yn










, vetores gen´ericos de Rn,

?v, w? = x1y1 + x2y2 + · · · + xnyn.

Uma maneira alternativa para escrever ?v, w? ´e dada pelo produto de uma matriz
linha por uma matriz coluna como segue:

?v, w? = vT w = ?x1

· · · xn?







y1
...
yn







= x1y1 + · · · + xnyn.

[4] Norma

Em espa¸cos vetoriais munidos de produto interno, a norma (ou comprimento) de

um vetor v ´e dada pelo n´umero real n˜ao negativo:

||v|| = ??v, v?.

Em Rn, com o produto interno usual, a norma de um vetor v =

66







x1
...
xn







´e dada por:

||v|| = ?x2

n.
1 + · · · + x2

[5] Combina¸c˜ao linear de vetores e subespa¸co gerado

Sejam V um espa¸co vetorial real, v1, v2, · · · , vn ∈ V e α1, α2, · · · , αn n´umeros reais,
ent˜ao o vetor

v = α1v1 + α2v2 + · · · + αnvn

´e um elemento de V e ´e chamado combina¸c˜ao linear de v1, v2, · · · , vn.
Mostra-se que, uma vez ﬁxados os vetores v1, v2, · · · , vn em V, o conjunto W de todos
os vetores v que s˜ao combina¸c˜ao linear de v1, v2, · · · , vn, ´e um subespa¸co vetorial de
V. Dizemos que W ´e um subespa¸co gerado por v1, v2, · · · , vn.

[6] Dependˆencia e Independˆencia Linear

De acordo com a deﬁni¸c˜ao dada por BOLDRINI et al. (1986), como Rn ´e um espa¸co
vetorial, dizemos que um conjunto de vetores {v1, v2, · · · , vn} ⊂ Rn ´e linearmente
independente (LI) ou que os vetores v1, v2, · · · , vn s˜ao LI se a equa¸c˜ao

a1v1 + a2v2 + · · · + anvn = 0

implica que a1 = a2 = · · · = an = 0. No caso em que existe algum ai ?= 0, dizemos
que {v1, v2, · · · , vn} ´e linearmente dependente (LD), ou que os vetores v1, v2, · · · , vn
s˜ao LD.

[7] Base

Um conjunto de vetores B = {v1, v2, · · · , vn} de um espa¸co vetorial V, ´e chamado
de base de V se B ´e LI e se qualquer vetor v de V pode ser escrito como uma
combina¸c˜ao linear de dos vetores de B, ou, em outras palavras, se B gera V.

[8] Posto de matrizes

Uma matriz m × n ´e linha reduzida `a forma escada se:

(a) O primeiro elemento n˜ao nulo de uma linha n˜ao nula ´e 1.

67

(b) Cada coluna que cont´em o primeiro elemento n˜ao nulo de alguma linha tem

todos os seus outros elementos iguais a zero.

(c) Toda linha nula ocorre abaixo de todas as linhas n˜ao nulas (isto ´e, daquelas

que possuem pelo menos um elemento n˜ao nulo).

(d) Se as linhas 1, · · · , r s˜ao as linhas n˜ao nulas, e se o primeiro elemento n˜ao nulo

da linha i ocorre na coluna kj, ent˜ao k1 < k2 < · · · < kr.

BOLDRINI et al. (1986) demonstra que toda matriz Am×n ´e linha equivalente a
uma ´unica matriz linha reduzida `a forma escada e deﬁne como posto de A, denotado
por p, o n´umero de linhas n˜ao nulas da matriz Bm×n que ´e linha equivalente a A.
Pode-se mostrar tamb´em que o posto de uma matriz A indica o n´umero de colunas

ou de linhas de A que s˜ao LI.

[9] Vetor Gradiente

Se f ´e uma fun¸c˜ao de duas vari´aveis x1 e x2, o gradiente de f ´e a fun¸c˜ao vetorial
deﬁnida ∇f por

∇f (x1, x2) = (fx1(x1, x2), fx2(x1, x2)) =

∂f
∂x1

i +

∂f
∂x2

j.

No caso de fun¸c˜oes lineares de duas vari´aveis como, por exemplo, f (x1, x2) = ax1 +
bx2 com a, b ∈ R, temos que ∇f (x1, x2) = ?a

?.

b

[10] Conjunto Convexo

Um conjunto Ω ⊂ Rn ´e convexo se, dados x1, x2 ∈ Ω, tem-se x = αx1+(1−α)x2 ∈ Ω,
para qualquer α ∈ [0, 1].

[11] Conjunto Limitado

Um conjunto Ω ⊂ Rn ´e limitado se existe uma constante

k > 0 tal que ||x|| ≤ k ∀ x ∈ Ω.

[12] Poliedro e Politopo

Um hiperplano em Rn ´e um conjunto da forma {x : pT x = k}, onde k ´e um escalar
(k ∈ R) e p ´e um vetor de Rn, tamb´em chamado de vetor normal ou gradiente ao
hiperplano. O conceito de hiperplano generaliza a ideia de reta em R2 e de plano em
R3 e, semelhantemente `a reta e ao plano (que dividem o plano ou o espa¸co em duas

68

regi˜oes), um hiperplano divide Rn em duas regi˜oes chamadas semi-espa¸cos, que s˜ao
conjuntos da forma {x : pT x ≤ k} ou {x : pT x ≥ k}, onde k ∈ R e p ∈ Rn.
Um poliedro ´e um conjunto formado pela intersec¸c˜ao de um n´umero ﬁnito de semi-
espa¸cos e ´e representado por {x : Ax ≤ b} onde A ´e uma matriz com m linhas e n
colunas e b ´e um vetor de dimens˜ao m. Um poliedro limitado ´e chamado de politopo.

Pode-se mostrar que um poliedro ´e um conjunto convexo.


SÉRGIO DA SILVA MEDEIROS

CADEIAS DE MARKOV OCULTAS

Santo André, 2017

UNIVERSIDADE FEDERAL DO ABC

CENTRO DE MATEMÁTICA, COMPUTAÇÃO E COGNIÇÃO

SÉRGIO DA SILVA MEDEIROS
Sérgio da Silva Medeiros

CADEIAS DE MARKOV OCULTAS

Orientador: Prof. Dr. Daniel Miranda Machado

Dissertação de mestrado apresentada ao Centro de

Matemática, Computação e Cognição para

obtenção do título de Mestre

ESTE EXEMPLAR CORRESPONDE A VERSÃO FINAL DA DISSERTAÇÃO

DEFENDIDA PELO ALUNO SÉRGIO DA SILVA MEDEIROS,

E ORIENTADA PELO PROF. DR. DANIEL MIRANDA MACHADO.

SANTO ANDRÉ, 2017

Sistema de Bibliotecas da Universidade Federal do ABCElaborada pelo Sistema de Geração de Ficha Catalográfica da UFABCcom os dados fornecidos pelo(a) autor(a).da Silva Medeiros, Sérgio     CADEIAS DE MARKOV OCULTAS / Sérgio da Silva Medeiros. — 2017.     65 fls. : il.     Orientador: Daniel Miranda Machado     Dissertação (Mestrado) — Universidade Federal do ABC, Mestrado Profissional emMatemática em Rede Nacional - PROFMAT, Santo André, 2017.     1. Probabilidade. 2. Matrizes. 3. Cadeias de Markov. I. Miranda Machado, Daniel. II.Mestrado Profissional em Matemática em Rede Nacional - PROFMAT, 2017. III. Título.Agradecimentos

A Deus.

À minha família, em especial minha esposa Silvana e minha ﬁlha Manuela.

À CAPES, pelo apoio ﬁnanceiro.

Ao coordenador professor Dr. Rafael Grisi e docentes do PROFMAT da UFABC.

Aos colegas de turma.

Em especial, ao professor Dr. Daniel Miranda Machado, por sempre ter sido solícito

desde suas aulas de recursos computacionais, como também por sua dedicação às

orientações, tornando-as grandes momentos de aprendizagem.

iii

Resumo

O foco principal deste trabalho é o estudo das Cadeias de Markov e das Cadeias de

Markov Ocultas. As cadeias de Markov fornecem uma forma prática para o estudo de

conceitos probabilísticos e matriciais.

Procuramos utilizar de forma contextualizada a aplicação do produto e potência de

matrizes associados ao software Geogebra.

Além dos exemplos, estão contidas questões de aprendizagem, sempre com objetivo

de torná-los aliados e valiosos ao aprendizado referente a este tema.

Palavras-chave: Cadeias de Markov Ocultas, Cadeias de Markov, Probabilidades

v

Abstract

The main focus of this work is the study of Markov Chains and the Markov Hidden

Chains, which in turn brings the study of probabilistic and matrix concepts into prac-

tice.

We seek to use in a contextualized way the application of the multiplication and po-

tency of matrices associated to the software Geogebra.

In addition to the examples, are contained learning issues, always with the goal of

making them allies and valuable to the learning related to this theme.

Keywords:Markov Hidden Chains, Markov Chains, Probabilities

vii

Conteúdo

Lista de Figuras

Lista de Tabelas

1 Probabilidades

1.1 Introdução aos conjuntos

. . . . . . . . . . . . . . . . . . . . . . . . . .

1.1.1 União e Interseção de Conjuntos

. . . . . . . . . . . . . . . . . .

1.1.2 Complementar de um conjunto . . . . . . . . . . . . . . . . . . .

1.2 Análise Combinatória . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2.1 Arranjos, Permutações e Combinações . . . . . . . . . . . . . . .

1.3 Introdução às Probabilidades

. . . . . . . . . . . . . . . . . . . . . . . .

1.3.1 Experimento Aleatório . . . . . . . . . . . . . . . . . . . . . . . .

xi

xiii

3

3

5

6

7

8

9

9

1.3.2 Espaço Amostral e Eventos

. . . . . . . . . . . . . . . . . . . . . 10

1.4 Axiomas de Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . 12

1.5 Probabilidades em espaços amostrais equiprováveis . . . . . . . . . . . . 13

2 Probabilidade Condicional

15

2.1 Probabilidade Condicional e Eventos Independentes

. . . . . . . . . . . 15

2.2 Probabilidade Total . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.3 Teorema de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

3 Cadeias de Markov

23

3.1 Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

3.2 Diagrama de Transição de Estado . . . . . . . . . . . . . . . . . . . . . . 26

3.3 Vetor Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

3.4 Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

3.5 Matriz de Transição . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

3.6 Equações de Chapman-Kolmogorov . . . . . . . . . . . . . . . . . . . . . 31

3.7 Classiﬁcação dos estados em Cadeias de Markov . . . . . . . . . . . . . . 32

3.8 Probabilidades limite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

3.9 Problema da Ruína do Jogador

. . . . . . . . . . . . . . . . . . . . . . . 36

ix

Conteúdo

4 Cadeias de Markov Ocultas

41

4.1 Abordando um exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

4.2 Notação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

4.3 Os três problemas fundamentais . . . . . . . . . . . . . . . . . . . . . . . 46

4.4 Problema 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.5 Problema 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.6 Problema 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.7 Discussão . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4.8 As três soluções . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.8.1 Solução para o problema 1 . . . . . . . . . . . . . . . . . . . . . 48

4.8.2 Solução para o Problema 2 . . . . . . . . . . . . . . . . . . . . . 49

4.8.3 Solução para o Problema 3 . . . . . . . . . . . . . . . . . . . . . 50

5 Atividades para salas de aulas

53

5.1 Geogebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

5.2 Atividade 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

5.3 Atividade 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

5.4 Atividade 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

Índice

63

x

Lista de Figuras

2.1 Três urnas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2.2 Moeda de Bertrand . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.1 Apresentação do Sistema . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

3.2 Árvore característica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

3.3 Árvore característica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

3.4 Estímulo de Skinner

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

3.5 Diagrama de transição do modelo experimental de Skinner . . . . . . . . 27

3.6 Diagrama de estados da ruína do jogador

. . . . . . . . . . . . . . . . . 39

4.1 Anéis de crescimento de árvores [5]

. . . . . . . . . . . . . . . . . . . . 43

4.2 Modelo Oculto de Markov . . . . . . . . . . . . . . . . . . . . . . . . . . 44

5.2 Janela principal do Geogebra . . . . . . . . . . . . . . . . . . . . . . . . 54

5.1 Divisões dos comandos e áreas de trabalho no Geogebra . . . . . . . . . 54

5.3 Confecção da Matriz M no Geogebra . . . . . . . . . . . . . . . . . . . . 54

5.4 Confecção da Matriz N no Geogebra . . . . . . . . . . . . . . . . . . . . 55

5.5 Produto de matrizes M e N . . . . . . . . . . . . . . . . . . . . . . . . . . 55

5.6 Quadrado da Matriz M . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

5.7 Cubo da Matriz M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

5.8 Diagrama de transição entre os estados do problema 1 . . . . . . . . . . 58

5.9 Diagrama de transição entre os estados do problema 2 . . . . . . . . . . 58

5.10 Agente de trânsito . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

5.11 Diagrama de transição de estados do agente de trânsito . . . . . . . . . . 60

xi

Lista de Tabelas

4.1 Probabilidades de sequências de estados . . . . . . . . . . . . . . . . . . 46

4.2 Probabilidades HMM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

5.1 Vetores de estados do agente de trânsito . . . . . . . . . . . . . . . . . . 61

xiii

Introdução

O propósito deste trabalho é apresentar os conceitos, bem como propriedades e tam-

bém a resolução de algumas situações-problema envolvendo Cadeias de Markov, e em

especial as Cadeias de Markov Ocultas, representadas por HM M . Para a realização

deste propósito, além da abordagem do citado anteriormente, ﬁzemos uso do software

Geogebra, visando obtenção de resultados com maior precisão e rapidez.

Este trabalho aborda as Cadeias de Markov, que por sua vez faz uso de conceitos ,

propriedades e demonstrações de Probabilidades , Matrizes e Sistemas Lineares. Em

relação ao estudo das probabilidades, a maioria dos casos são constituídos de proba-

bilidades condicionais, nunca descartando a hipótese ou situações de outros cálculos

probabilísticos.

Quando se aborda o estudo de probabilidades, a importância do mesmo vai além da

aprendizagem esperada em tal conteúdo. Trabalhar, quando possível, de forma prática

e contextualizada o relacionamento entre probabilidades e matrizes, proporciona um

rico aprendizado composto por abstração e dinamização da aplicabilidade de matrizes

à assuntos relacionados ao cotidiano. Neste trabalho, a abordagem das Cadeias de

Markov começa com um breve histórico à respeito do matemático que a desenvolveu,

seguindo suas teorias, propriedades e demonstrações, entre elas, matriz de transi-

ção de estados, diagrama de transição de estados, probabilidade limite, equações de

Chapmman-Kolmogorov, chegando por sua vez às Cadeias de Markov Ocultas.

Dentre tantas importantes utilizações das Cadeias de Markov, destaca-se a resolução

de situações-problema envolvendo Teoria das Probabilidades, e em especial os proces-

sos estocásticos que são processos que evoluem no tempo de maneira probabilística.

No capítulo 1, ocorre a abordagem do estudo da teoria dos Conjuntos e Probabilida-

des em espaços amostrais equiprováveis. No capítulo 2, a abordagem do teorema da

probabilidade total. Nos capítulos 3 e 4, as cadeias de Markov e as cadeias de Mar-

kov Ocultas, ﬁnalizando com atividades sugeridas a serem desenvolvidas em salas de

aulas, compostas por situações-problema de forma contextualizada, com o objetivo de

favorecer a aprendizagem e o conhecimento a respeito do tema abordado.

1

1 Probabilidades

1.1 Introdução aos conjuntos

Nesta seção, há uma sucinta descrição das principais noções da teoria dos conjuntos,

servindo como prévia base para o estudo das teorias das probabilidades e Cadeias de

Markov.

O agrupamento de objetos com características comuns constitui a formação de um

conjunto, que independente de suas apresentações, os mesmos são chamados de ele-

mentos ou membros do conjunto.

Os nomes dados aos conjuntos são representados geralmente por letras maiúsculas

do nosso alfabeto, e os elementos por letras minúsculas. As duas formas em que se

pode descrever um conjunto, podem ser:

• Propriedade dos elementos: É utilizada quando se pretende representar os elemen-

tos sem escrevê-los individualmente, para isso, escreve-se todos os elementos em uma

única propriedade caracterizada, genericamente descreve-se:{ x|x tem a propriedade

P}

Exemplo 1.1.

a) {x|x é divisor inteiro de 3 } é uma maneira de indicar o conjunto :{-1; 1; -3; 3 };

b) {x|x é inteiro e 0(cid:54)x(cid:54)500} pode ser indicado por: {0; 1; 2; . . . ; 500}.

• Enumeração dos elementos: Quando um conjunto é dado pela enumeração de

seus elementos, devemos indicá-lo escrevendo seus elementos entre chaves. Essa no-

tação também é empregada quando o conjunto é inﬁnito, escreve-se alguns elementos

que evidenciam a lei de formação com a utilização de reticências.

Exemplo 1.2.

a) Conjunto dos números ímpares positivos: {1,3,5,7,. . . }

3

1 Probabilidades

b) Conjunto dos números primos positivos: {2,3,5,7,11,13,. . . }

Conjuntos unitário e vazio

Chama-se conjunto unitário aquele que possui um único elemento.

Exemplo 1.3.

a) Conjunto dos divisores de 1, inteiros e positivos: {1}

b) Conjunto das soluções da equação 3x + 1 = 10 : {3}.

Chama-se conjunto vazio aquele que não possui elemento algum. O símbolo usual

para o conjunto vazio é o ∅.
A obtenção de um conjunto vazio ocorre quando se descreve um conjunto por meio de

uma propriedade P logicamente falsa.

Exemplo 1.4.

a) { x|x (cid:54)= x } = ∅

b) { x|x é ímpar e múltiplo de 2 } = ∅

c) { x|x > 0 e x < 0 } = ∅

Conjunto Universo

No desenvolvimento de um tema em Matemática, o conjunto universo represen-

tado por ∪, é aquele que engloba todos os elementos utilizados na abordagem de tal

assunto. Este conjunto, que por sua vez traz características distintas em relação ao

conjunto vazio, possui uma deﬁnição relativa associada à situação do assunto estu-

dado, ou seja, ele pode mudar de acordo com o contexto.

Ao descrevermos um conjunto através da propriedade dos elementos, considerando

uma determinada propriedade por P, é importante ﬁxar o conjunto universo ∪ em que
se está trabalhando, desa forma escreve-se: { x ∈ ∪ | x possui a propriedade P }.

4

1.1 Introdução aos conjuntos

Igualdade de conjuntos

Dois conjuntos A e B são iguais quando todo elemento de A pertence a B e, reci-

procamente, todo elemento de B pertence a A. Simbolicamente é representado por:

A = B ⇔ ∀x, x ∈ A ⇔ x ∈ B

1.1.1 União e Interseção de Conjuntos

Considerando dois conjuntos A e B, chama-se união de A e B o conjunto formado

pelos elementos que pertencem a A ou a B.

A ∪ B = {x | x ∈ A ou x ∈ B}

Para que haja existência da união de dois ou mais conjuntos, é necessário que os

elementos pertençam a pelo menos um dos conjuntos.

Propriedades da união conjuntos:

Para A, B e C conjuntos quaisquer, são válidas as seguintes propriedades:

1. A ∪ A = A (idempotente)

2. A ∪ ∅ = A ( elemento neutro)

3. A ∪ B = B ∪ A ( comutativa)

4. (A ∪ B ) ∪ C = A ∪ ( B∪ C) ( associativa)

Considerando dois conjuntos A e B, chama-se interseção de A e B 0 conjunto

formado pelos elementos que pertencem a A e a B.

A ∩ B = { x | x ∈ A e x ∈ B}

Para que haja existência da interseção de dois ou mais conjuntos, é necessário que os

elementos pertençam aos conjuntos envolvidos simultaneamente.

Propriedades da Interseção de conjuntos

Para A, B e C conjuntos quaisquer, são válidas as seguintes propriedades:

5

1 Probabilidades

• 1a) A ∩ A = A ( idempotente )

• 2a) A ∩ ∪ = A ( elemento neutro )

• 3a) A ∩ B = B ∩ A ( comutativa )

• 4a) A ∩ (B ∩ C ) = ( A ∩ B) ∩ C ( associativa )

Ainda, em relação à interseção de dois conjuntos, quando ocorrer o conjunto va-

zio, diz-se que tais conjuntos são disjuntos. Neste caso, considerando dois conjuntos

quaisquer A e B, pode-se escrever:

A ∩ B = ∅

1.1.2 Complementar de um conjunto

Considerando um conjunto A, seu complementar representado por A é aquele cons-
tituído por todos os elementos que não estão contidos em A, porém, estão no conjunto

universo.

A = {x|x /∈ A}

Exemplo 1.5. Supondo ∪ = { 1; 2; 3; 4; 5; 6; 7; 8; 9; 10;}, A = { 1; 2; 3; 4} e B =
{3; 4; 5; 6}, analisando os conceitos de união, interseção e complementação de con-

juntos, pode-se veriﬁcar que:

A = {5; 6; 7; 8; 9; 10}

B = {1; 2; 7; 8; 9; 10}

A ∪ B = {1; 2; 3; 4; 5; 6}

A ∩ B = {3; 4}

Proposição 1.1. Sendo A, B e C conjuntos quaisquer, as seguintes propriedades valem

para a inter-relação da união, interseção e complementar de um conjunto:

• A ∪ ( B ∩ C) = ( A ∪ B )∩ ( A ∪ C )

6

• A ∩ ( B ∪ C ) = ( A ∩ B )∪ ( A ∩ C )

1.2 Análise Combinatória

• A ∩ ∅ = ∅

• A ∪ ∅ = A

• (A ∩ B) = A ∪ B

• (A ∪ B) = A ∩ B

• A = A

1.2 Análise Combinatória

Considerando um determinado conjunto não-vazio com uma quantidade n de ele-

mentos, a Análise Combinatória através de métodos, faz com que seja possível a con-

tagem do número de agrupamentos desse considerado conjunto.

A abordagem, não detalhada, do estudo de Análise Combinatória neste trabalho tem

importante papel para o cálculo do número de elementos de eventos, experimentos e

espaços amostrais das Probabilidades que possam ocorrer no decorrer do mesmo.

Utilizando a notação matemática n(A) para indicar o número de elementos de um

conjunto A, e analogamente este conceito de notação a qualquer ou quaisquer outros

conjuntos, seguem alguns exemplos:
1o) A é o conjunto de números de dois algarismos distintos formados a partir dos dí-
gitos 1, 2 e 3.

A = { 12, 13, 21, 23, 31, 32 } ; n(A) = 6
2o) T é o conjunto das sequências de letras que se obtêm, mudando a ordem das letras
da palavra RUA (anagramas da palavra RUA).

T = { RUA, RAU, URA, UAR, ARU, AUR } ; n(B) = 6

Príncipio Multiplicativo

Proposição 1.2. Sendo os conjuntos A = { a1, a2, . . ., am } e B = { b1, b2,. . ., bn },
o número de pares ordenados (ai, bj), oriundos desses conjuntos, pode ser obtido pelo
produto m.n, em que ai ∈ A e bj ∈ B.

7

1 Probabilidades

Demonstração. Fixando o primeiro elemento do par ordenado e fazendo variar o se-

gundo elemento, numa quantidade de m linhas tem-se:

(a1, b1), (a1, b2), . . ., (a1, bn) −→ n pares
(a2, b1), (a2, b2), . . ., (a2, bn) −→ n pares
...
(am, b1), (am, b2), . . ., (am, bn) −→ n pares

Assim o número de pares ordenados será: n + n + n + . . . + n
(cid:125)

(cid:124)

(cid:123)(cid:122)
m vezes

= m.n

Fatorial

Deﬁnição 1.3. Sendo n um inteiro positivo, deﬁne-se o fatorial de n, denotado por n!

como

n! = n · (n − 1) · (n − 2) · . . . · 1

1.2.1 Arranjos, Permutações e Combinações

Havendo n elementos distintos num determinado conjunto, é possível calcular as

permutações dos mesmos, formando-se arranjos constituídos de n elementos.
Denotando-se por Pn as permutações de n elementos, temos:

Exemplo 1.6. P6 = 6! = 6.5.4.3.2.1 = 720

Pn = n!

Quando, dentre n elementos distintos, resolvermos tomar (considerar) uma quanti-

dade k desses elementos, 0 ≤ k ≤ n, permutando-se os k tomados, temos um Arranjo

de n elementos tomados k a k.
Denotando-se por An,k o número de arranjos de n elementos tomados k a k, temos:

An,k =

n!
(n − k)!

; n ≥ k

Exemplo 1.7. A8,5 = 8!

(8−5)! = 8!

3! = 8.7.6.5.4 = 6720

8

Considerando um conjunto com n elementos, chama-se de combinações de n ele-

1.3 Introdução às Probabilidades

mentos tomados k a k, aos subconjuntos constituídos de k elementos.
Denotando-se por Cn,k ou (cid:0)n
k, temos:

(cid:1) o número de combinações de n elementos tomados k a

k

Cn,k =

An,k
k!

=

n!
(n − k)! k!

; n ≥ k

Exemplo 1.8. C10,3 = (cid:0)10

(cid:1) = 10!

3

3!7! = 120

1.3 Introdução às Probabilidades

Etimologicamente, a palavra probabilidade deriva de probabilitas, probabilis ou probare,

que resumidamente, todas convergem aos signiﬁcados: provar, testar, examinar.

Segundo pesquisas cientíﬁcas e dados históricos, o cálculo de probabilidades surgiu

na Idade Média, período no qual os jogos de azar eram habitualmente realizados, tra-

zendo consigo ao mundo da Matemática a procura de uma modelagem, ou melhor,

matematização de tais jogos. Vale ressaltar que com o decorrer das teorias das pro-

babilidades, a mesma demonstrou ter diversas aplicações de grande importância em

outras ciências, entre elas destacam-se : Biologia, Economia, Engenharias e outras.

1.3.1 Experimento Aleatório

O entendimento de experimento aleatório se torna mais evidente quando o mesmo

está associado à exemplos sobre tal abordagem.

Alguns exemplos:

a) Lança-se uma moeda quatro vezes e observa-se a sequência de caras e coroas

b) Números de peças defeituosas num determinado lote

c) No lançamento de um dado, ocorrer face par, considerando a face voltada para

cima

Num experimento aleatório, conhecemos as possíveis saídas, e o mesmo pode ser repe-

tido sob as mesmas condições indeﬁnidamente, apresentando variações de resultado

e tendo como característica a indeterminação por todo período que o antecede. Nesse

texto consideraremos que os possíveis resultados podem ser descritos de forma enu-

merável.

9

1 Probabilidades

Estaremos interessados em experimentos aleatórios que quando repetidos uma grande

quantidade de vezes, torna-se observável uma regularidade em relação à frequência.

1.3.2 Espaço Amostral e Eventos

Considerando um experimento aleatório ε, deﬁne-se espaço amostral como o con-
junto de todos os resultados possíveis de ε, por questões simbólicas, costuma ser re-

presentado por Ω. Quando o número de elementos de um espaço amostral for um

número natural, o mesmo é considerado ﬁnito, caso contrário, inﬁnito enumerável ou

inﬁnito não-enumerável.

Exemplo 1.9.

a) Lançar uma moeda duas vezes e observar o número de caras;

Ω = { 0, 1, 2} : espaço amostral ﬁnito

b) Uma moeda é lançada até que o resultado cara ocorra pela primeira vez. Observa-

se em qual lançamento esse fato ocorre;

Ω = { 1, 2, 3, 4, . . . } : espaço amostral inﬁnito numerável

c) Um experimento consiste em registrar o retorno percentual diário do investi-

mento em uma carteira de ações. O espaço amostral é formado por um intervalo

contínuo de valores que, por conveniência, assumi-se estar entre - 100% e 100%.

Ω = {−100, 100} : espaço amostral inﬁnito não-numerável.

Eventos

Um evento, que costuma ser representado por uma letra maiúscula do nosso alfa-

beto, é um subconjunto de um espaço amostral Ω. Para que haja a ocorrência de um

evento, é necessário que o experimento aleatório realizado pertença ao evento.

Adotando n(Ω) ou # (Ω) como número de elementos de um espaço amostral, se n(Ω)
= n, n ∈ N ; Ω terá 2n subconjuntos e, portanto, 2n eventos.

Exemplo 1.10. No lançamento de uma moeda por três vezes consecutivas, observa-se

a sequência de caras e coroas;

Ω = {(K,K,K) ; (K,K,C) ; (K,C,K) ; (K,C,C,) ; (C,K,K) ; (C,K,C) ; (C,C,K) ; (C,C,C) }.

Alguns eventos:

10

1.3 Introdução às Probabilidades

A: Ocorrência de cara (k) no 1o lançamento
A = { (K,K,K) ; (K,K,C) ; (K,C,K) ; (K,C,C) }.

B: Ocorrência de três coroas

B = { ( C,C,C) }

Vale ressaltar dois eventos especiais:

• Evento impossível, representado por ∅ ;

• Evento certo, representado por Ω, onde o próprio evento é o espaço amostral.

Quando um experimento é realizado, seu resultado é inesperado. É necessário que

haja uma atribuição com teor de “escala” para veriﬁcação do grau de ocorrência de um

determinado evento.

Considerando o seguinte procedimento: Supondo que repetidas n vezes o experimento

ε, e sejam A e B dois eventos associados a ε. Admitindo que sejam, respectivamente,
nA e nB o número de vezes que o evento A e o evento B ocorram nas n repetições.

Deﬁnição 1.4. A frequência relativa do evento A nas n repetições de ε é denominada
fA = nA
n

A frequência relativa fA apresenta as seguintes propriedades, de fácil veriﬁcação:

• Propriedade (1) : 0 ≤ fA ≤ 1.

• Propriedade (2) : fA = 1,se e somente se, A ocorrer em todas as n repetições.

• Propriedade (3) : fA = 0, se e somente se, A nunca ocorrer nas n repetições.

• Propriedade (4) : Se A e B forem eventos mutuamente excludentes, e se fA∪B
for a frequência relativa associada ao evento A ∪ B, então, fA∪B = fA + fB.

• Propriedade (5) : Para n repetições do experimento , quando n → ∞, fA “con-

verge” em sentido probabilístico para P(A).

Exemplo 1.11. No lançamento de uma moeda, considerando a face voltada para cima

como resultado ocorrido, temos duas situações, cara(K) ou coroa(C). Denotando a i-
ésima face por Xi, onde Xi = 1 se a face for cara, e Xi = 0 se for coroa, observa-se
uma sequência, por exemplo, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1. É evidente que não há a

menor previsão do resultado que irá ocorrer. Calculando-se a frequência relativa em

relação ao evento k = { ocorrer face cara } e baseada nas observações das ocorrências
anteriores, temos: 1, 1, 2
8 , . . . . Nota-se que há um elevado grau de varia-
ção com maior evidência no início, analisando sua continuidade de forma indeﬁnida,

3 , 3

5 , 3

7 , 4

6 , 3

4 , 3

11

1 Probabilidades

essas frequências relativas chegariam próximas ao valor 1
2 .

A essência desta propriedade é que, se um experimento for executado um grande

número de vezes, a frequência relativa da ocorrência de algum evento tenderá a variar

cada vez menos à medida que o número de repetições for aumentada. Esta caracterís-

tica é também conhecida como regularidade estatística.

1.4 Axiomas de Probabilidade

Deﬁnição 1.5. Seja ε um experimento. Seja Ω um espaço amostral associado a ε. A
cada evento A, associaremos um número real representado por P(A) e denominado
probabilidade de A, que satisfaça às seguintes propriedades:

• Axioma (1): 0 (cid:54) P(A) (cid:54) 1

• Axioma (2): P(Ω) = 1

• Axioma (3): Se A1, A2, . . . , An,forem, dois a dois, eventos mutuamente exclu-
P(Ai)

dentes, então: P((cid:83)∞

i=1 Ai) = (cid:80)∞

i=1

Teorema 1.6. Se ∅ for o conjunto vazio, então P(∅) = 0.

Demonstração. Para qualquer evento A, podemos escrever A = A ∪ ∅. Uma vez que
A e ∅ são mutuamente excludentes, decorre do Axioma (3), que P(A) = P(A ∪ ∅)=
P(A) + P(∅).

Teorema 1.7. Se A for o evento complementar de A, então:

P(A) = 1 - P(A)

Demonstração. Podemos escrever Ω = A ∪ A e, empregando os Axiomas (2) e (3),
obteremos 1 = P(A) + P(A)

Teorema 1.8. Se A e B forem dois eventos quaisquer, então P(A ∪ B) = P(A)+P(B)-
P(A ∩ B).

Demonstração. A ∪ B = A ∪ (B ∩ A) e B = (A ∩ B) ∪ (B ∩ A )

Por consequência:
P(A ∪ B) = P(A) + P(B ∩ A)
P(B) = P(A ∩ B) + P(B ∩ A)

12

1.5 Probabilidades em espaços amostrais equiprováveis

P(A ∪ B) - P(B) = P(A)+P(B ∩ A) - P(A ∩ B) - P(B ∩ A)
P(A ∪ B) - P(B) = P(A) - P(A ∩ B)
P(A ∪ B) = P(A) + P(B) - P(A ∩ B)

Teorema 1.9. Se A, B e C forem três eventos quaisquer, então:
P(A ∪ B ∪ C) = P(A)+P(B)+P(C) - P(A ∩ B)- P(A ∩ C) - P(B ∩ C) + P(A ∩ B ∩
C).

Demonstração. Considerando A1, A2, . . ., Ak ; quaisquer k eventos.
P(A1 ∪ A2 ∪ . . . ∪ Ak)= Σk
P(Ai) - Σk
+ . . . + (−1)k−1 P(A1 ∩ A2 ∩ . . . ∩ Ak).

P(Ai ∩ Aj) + Σk

i<j=2

i=1

i<j<r=3

P(Ai ∩ Aj ∩ Ar)

Teorema 1.10. Se A ⊂ B , então P(A) ≤ P(B)

Demonstração. Decompondo B em dois eventos mutuamente excludentes, B = A ∪

(B ∩ A ).
P(B) = P(A) + P(B ∩ A) ≥ P(A) ; pois P(B ∩ A) ≥ 0, pelo Axioma (1).

1.5 Probabilidades em espaços amostrais equiprováveis

Considerando um espaço amostral Ω, formado por k pontos amostrais:

Ω = {a1, a2, a3, · · · ak}

Vamos associar a cada um desses pontos amostrais um número real, Pai, ou simples-
mente, Pi, chamado probabilidade do evento ai,tal que:
i. 0 (cid:54) Pi (cid:54) 1
ii. (cid:80)k

i=1 Pi = 1, isto é,P1 + P2 + · · · + Pk = 1

Teorema 1.11. Num espaço amostral equiprovável, a probabilidade de ocorrer determi-

nado evento é dada pela razão entre o número de casos favoráveis e o número de casos

possíveis.

Demonstração. Denotando por P a probabilidade de ocorrência de cada um dos pontos
amostrais de Ω:

P + P + ... + P
(cid:124)
(cid:123)(cid:122)
(cid:125)
vezes

k

= 1 ⇒ k.P = 1 ⇒ P =

1
k

13

1 Probabilidades

A probabilidade de ocorrência de um evento E, formado por r pontos amostrais E =
{a1, a2,· · ·, ar}, com r (cid:54) k, é dada por:

P(E) = P1 + P2 + · · · + Pr

=

=

=

1
k
r

+

1
k
(cid:124)
r
k
n(E)
n(Ω)

+ · · · +
(cid:123)(cid:122)
vezes

1
k
(cid:125)

(1.1)

Como E ⊂ Ω,temos que n(E) (cid:54) n(Ω). Dessa forma,temos :

P(E) =

n(E)
n(Ω)

tal

que

0 (cid:54) P(E) (cid:54) 1

14

2 Probabilidade Condicional

2.1 Probabilidade Condicional e Eventos Independentes

Probabilidade Condicional

Trata-se do estudo das possibilidades de um acontecimento condicionado a outro,

ou seja, é a probabilidade de ocorrer um evento com base num evento anterior. Ob-

viamente, dentro de um espaço amostral ﬁnito, haverá tais eventos como conjuntos

não-vazios.
Sendo A e B dois eventos associados a um experimento ε, denota-se por P(B|A) a
probabilidade condicionada do evento B, quando A tiver ocorrido. Ao calcular-se
P(B|A), calcula-se essencialmente P(B) em relação ao espaço amostral A, ao invés
de realizá-lo em relação ao espaço amostral original, comumente representado por Ω .

É importante destacar outra probabilidade também inserida no contexto de Probabili-
dade Condicional, trata-se de P(A ∩ B), “ probabilidade da interseção dos eventos A e
B ”.Utilizando o conceito de frequência relativa para uma deﬁnição formal de P(A|B),
temos:

Heurística 1. Para um experimento aleatório repetido n vezes, sejam nA, nB e nA∩B o
número de vezes que ocorrem A, B e (A ∩ B), respectivamente. A frequência relativa
de A nos resultados em que B ocorre é obtida por nA∩B
nB
de A condicionada à ocorrência de B.

, ou seja, a frequência relativa

nA∩B
nB

=

nA∩B
n
nB
n

=

fA∩B
fB

Considerando n “grande”, fA∩B se torna bem próxima e com desconsiderada mar-
gem de erro de P(A ∩ B) e fB se torna próxima de P(B). Logo, podemos considerar:

P(A|B) =

P(A ∩ B)
P(B)

; P(B) > 0

Exemplo 2.1. Dois dados, dx e dy são lançados respectivamente, fornecendo o se-
guinte espaço amostral:

15

2 Probabilidade Condicional

Ω =










(1, 1)

(1, 2)

(2, 1)
...
(6, 1)

(2, 2)
...
(6, 2)

· · ·

· · ·
. . .
· · ·










(1, 6)

(2, 6)
...
(6, 6)

Sejam os eventos:
A: o dado dx apresenta resultado 2,
B: a soma dos pontos nos dois dados é 6.
Calculando-se P(A|B), temos:
A = {(2,1), (2,2), (2,3), (2,4), (2,5), (2,6) } → P(A) = 6
B = { (1,5), (2,4), (3,3), (4,2), (5,1) } → P(B) = 5
36
(A ∩ B) = { (2,4) } → P(A ∩ B) = 1
36
∴ P(A|B) =
= 1
5

1
36
5
36

36 = 1

6

Probabilidade de Eventos Independentes

Considerando um espaço amostral Ω e dois eventos A e B contidos no mesmo, pode-
se dizer que A independe de B, se P(A|B) = P(A), ou seja, A independe de B se a
ocorrência de B não afeta a probabilidade de A.
Da mesma forma, quando se diz que P(A|B) = P(A), pode-se dizer também que
P(B|A) = P(B).

Heurística 2.

P(B|A) =

=

=

P(A ∩ B)
P(A)

P(B).P(A|B)
P(A)
P(B).P(A)
P(A)

= P(B)

Levando em consideração que se A independe de B, então B independe de A, pode-

se deduzir que o cálculo das probabilidades de dois eventos independentes pode ser

deﬁnida por:

Deﬁnição 2.1.

P(A ∩ B) = P(A). P(B|A)
(cid:124) (cid:123)(cid:122) (cid:125)
P(B)

= P(A) · P(B)

Exemplo 2.2. Lança-se uma moeda por três vezes consecutivas e analisa-se os eventos

e o espaço amostral:

16

Ω = { (K,K,K), (K,K,C), (K,C,K), (K,C,C), (C,K,K), (C,K,C), (C,C,K), (C,C,C) }

A: ocorrer pelo menos duas caras,

2.2 Probabilidade Total

B: ocorrer resultados iguais nos três lançamentos.
A = { (K,K,K), (K,K,C), (K,C,K), (C,K,K) } → P(A) = 4
B = { (K,K,K), (C,C,C) } → P(B) = 2
(A ∩ B) = { (K,K,K) } → P(A ∩ B) = 1
8
= P(A)
Logo,P(A ∩ B)
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:125)
(cid:124)
1
2

.P(B)
(cid:124) (cid:123)(cid:122) (cid:125)
1
4

8 = 1

(cid:123)(cid:122)
1
8

4

∴ A e B são independentes.

8 = 1

2

Exemplo 2.3. Uma moeda é lançada sete vezes. Qual a probabilidade de se observar

cara nos sete lançamentos?
A1: ocorrer cara no 1o lançamento
A2: ocorrer cara no 2o lançamento
...
A7: ocorrer cara no 7o lançamento
Pode-se admitir que A1, A2, · · ·, A7 são eventos independentes, pois cada lançamento
não é afetado pelos outros.
P(A1 ∩ A2 ∩ . . . ∩ A7)= P(A1).P(A2). . . . . P(A7)
A probabilidade de ocorrer cara em qualquer lançamento é 1
2 .
Logo:
P(A1 ∩ A2 ∩ . . . ∩ A7) =

.

= 1
128

1
2
(cid:124)

1
. . .
2
(cid:123)(cid:122)
7vezes

1
2
(cid:125)

2.2 Probabilidade Total

Dizemos que os eventos E1, E2, . . . , En ; formam uma partição do espaço amostral

Ω, quando:

• P(Ek) > 0 ; ∀k

• Ei ∩ Ej = ∅ para i (cid:54)= j
• (cid:83)n

i=1 Ei = Ω

Deduz-se que, os eventos E1, E2, . . . , En são dois a dois mutuamente exclusivos e

exaustivos, ou seja, sua união é Ω.
Sendo Ω um espaço amostral, A um evento qualquer de Ω e E1, E2, . . . , En uma parti-

17

2 Probabilidade Condicional

ção de Ω, vale a seguinte relação:

A = (E1 ∩ A) ∪ (E2 ∩ A) ∪ (E3 ∩ A) ∪ . . . ∪ (En ∩ A)

Em casos onde o cálculo da probabilidade apresentar maior diﬁculdade no processo

resolutivo, pode-se utilizar o Teorema da Probabilidade Total como método facilitador.

Considerando a relação acima, podemos escrevê-la como

P(A) = P(E1 ∩ A) + P(E2 ∩ A) + P(E3 ∩ A) + . . . + P(En ∩ A)

Exemplo 2.4. Existem três urnas, A, B e C. Sabe-se que a urna A contém 2 bolas

vermelhas (V) e 3 bolas brancas (B); a urna B contém 3 bolas vermelhas (V) e 1

branca (B); a urna C contém 4 bolas vermelhas (V) e 2 bolas brancas (B). Seleciona-

se uma urna ao acaso, e dela extraí-se uma bola. Qual a probabilidade de sortear-se

aleatoriamente uma bola vermelha?

Resolução:

Figura 2.1: Três urnas

A partição de Ω é composta pelos eventos:

EA : sair urna A
EB : sair urna B
EC : sair urna C
Sendo V o evento “sair bola vermelha”, pelo teorema da probabilidade total:

P(V ) = P(EA ∩ V ) + P(EB ∩ V ) + P(EC ∩ V )

18

2.2 Probabilidade Total

15

Analisando o diagrama e utilizando o teorema da multiplicação:
P(EA ∩ V ) = 1
P(EB ∩ V ) = 1
P(EC ∩ V ) = 1
Logo:
P(V ) = 2

5 = 2
4 = 1
6 = 2

3 · 2
3 · 3
3 · 4

15 + 1

4 + 2

9 = 109

180

4

9

Exemplo 2.5. Problema da moeda de Bertrand
Existem três caixas idênticas. A 1a(I) contém duas moedas de ouro, a 2a (II) contém
uma moeda de ouro e outra de prata, e a 3a (III), duas moedas de prata. Uma caixa
é selecionada ao acaso e da mesma é escolhida uma moeda ao acaso. Se a moeda

escolhida for de ouro, qual a probabilidade de que a outra moeda da caixa escolhida

também seja de ouro?

Resolução:

Podemos analisar esse problema também de outra forma: “Escolhendo-se a moeda de

ouro, qual a probabilidade de que ela tenha vindo da caixa (I)”?

Figura 2.2: Moeda de Bertrand

A partição de Ω é composta pelos eventos:

EI : sortear a caixa I
EII : sortear a caixa II
EIII : sortear a caixa III
Sendo O o evento “sortear moeda de ouro”, pelo teorema da probabilidade total:

19

2 Probabilidade Condicional

P(O) = P(∪I ∩ O) + P(∪II ∩ O) + P(∪III ∩ O)
1
3

· 1 +

1
3

1
3

1
2

· 0

=

+

·

Pela condição da moeda escolhida ser de ouro:

=

1
2

P(∪I |O) =

P(∪I ∩ O)
P(O)

=

1
3
1
2

=

2
3

2.3 Teorema de Bayes

O Teorema de Bayes é um encadeamento dedutivo do Teorema da Probabilidade

Total, que de forma conceitual, admitindo os eventos A e B e por consequência suas

probabilidades, apresenta-se por:

P(A|B) =

P(A ∩ B)
P(B)

=

P(B|A)P(A)
P(B)

Teorema 2.2. A probabilidade de ocorrência de um evento Ei, supondo-se a ocorrência
do evento A, é dada por:

P(Ei|A) =

P(Ei)P(A|Ei)

(cid:80)n

j=1

P(Cj)P (A|Cj)

, ∀i = 1, 2, . . . , n

Exemplo 2.6. A administração de um fundo de investimentos em ações pretende di-

vulgar, após o encerramento do pregão, a probabilidade de queda de um índice da

bolsa no dia seguinte, baseando-se nas informações disponíveis até aquele momento.

Supondo que a previsão inicial seja de 0,10. Após encerrado o pregão, nova informa-

ção sugere uma alta do dólar frente ao real. A experiência passada indica que, quando

houve queda da bolsa no dia seguinte, 20% das vezes foram precedidas por esse tipo

de notícia, enquanto, nos dias em que a bolsa esteve em alta, apenas 5% das vezes

houve esse tipo de notícia no dia anterior.

Resolução:

Chamando de E o evento que indica “queda da bolsa”, a sua probabilidade a priori é
P(E) = 0,10, enquanto a probabilidade de alta é P(E) = 0,90. Se B indicar alta do
dólar, então as verosimilhanças são dadas por:

P(B|E) = 0, 20 P(B|E) = 0, 05

20

Pelo Teorema de Bayes:

2.3 Teorema de Bayes

P(E|B) =

P(E)P(B|E)
P(E)P(B|E) + P(E)P(B|E)

=

(0, 10)(0, 20)
(0, 10)(0, 20) + (0, 90)(0, 05)

=

0, 02
0, 065

= 0, 31

Portanto, a nova informação aumenta a probabilidade de que haja queda na bolsa

de 10% para 31%.

21

3 Cadeias de Markov

3.1 Introdução

Em meados de 1907, Andrei Andrejevitch Markov, matemático russo, realizou es-

tudos a respeito de um importante tipo de processo, no qual o resultado dos estados

futuros dependiam apenas do estado atual e não dos estados que o antecediam. Estes

processos possuíam uma propriedade conhecida como “perda de memória ”(memory

loss) ou Propriedade de Markov.

A aplicabilidade das Cadeias de Markov está relacionada de forma concisa e ampla

à diversos setores e fenômenos associados ao nosso cotidiano, entre eles: previsão do

tempo, Economia, jogos, conﬁabilidade e outras. Tendo como princípio um estado ini-

cial, e este por sua vez, realizando transição com outro ou outros estados, por meio de

certas probabilidades envolvidas num intervalo de tempo discreto com probabilidade

de transição dependendo apenas do estado naquele determinado momento, dá-se o

nome de Processo de Markov. Este processo é importante no estudo de conﬁabilidade

pelo fato de permitir que um determinado estado apresentando necessidade de “repa-

ros” seja reparado, e ao mesmo tempo sua probabilidade de transição ou permanência

também serão conhecidas.

Exemplo 3.1. Considere um sistema formado por duas situações distintas, denomi-

nadas estados A e B. Representando simultaneamente, as situações descritas anterior-

mente, a inoperância e o funcionamento de um gerador de energia elétrica, assume-se

que as probabilidades são constantes para todos os instantes de tempos discretos no fu-

turo. Sabe-se que a probabilidade de permanecer no estado A é de 0,5, de permanência

em B de 0,75; de mudança, ou seja, transição de A para B de 0,5 e de B para A de 0,25.

Qual a probabilidade de se encontrar no estado A no terceiro instante de tempo,

numa situação iniciada pelo estado A ? E iniciada pelo estado B?

23

3 Cadeias de Markov

Solução:

Observação: Pelo fato do movimento entre os estados ocorrer em tempos discretos,

temos uma Cadeia de Markov a tempo discreto.

Apresentação do sistema

Figura 3.1: Apresentação do Sistema

Árvore característica do sistema iniciada no estado A

Figura 3.2: Árvore característica

Cálculo da probabilidade:
A1 = 0, 5 · 0, 75 · 0, 25 = 0, 09375
A2 = 0, 5 · 0, 25 · 0, 5 = 0, 0625
A3 = 0, 5 · 0, 5 · 0, 25 = 0, 0625
A4 = 0, 5 · 0, 5 · 0, 5 = 0, 125
Assim, a probabilidade de se encontrar no estado A no terceiro tempo = A1 + A2 +
A3 + A4 = 0, 34375.

Árvore característica do sistema iniciada no estado B

24

3.1 Introdução

Figura 3.3: Árvore característica

Cálculo da probabilidade:
B1 = 0, 25 · 0, 5 · 0, 5 = 0, 0625
B2 = 0, 25 · 0, 5 · 0, 75 = 0, 09375
B3 = 0, 75 · 0, 25 · 0, 5 = 0, 09375
B4 = 0, 75 · 0, 75 · 0, 75 = 0, 42187
A probabilidade de se encontrar no estado B no terceiro tempo = B1 + B2 + B3 + B4 =
0, 67187.

(cid:67)

Deﬁnição 3.1. Um Processo Markoviano é uma sequência de variáveis aleatórias
{Xn, n = 0, 1, 2, 3, . . . } satisfazendo:

P{Xn+1 = j|Xn = i, Xn−1 = in−1, . . . , X1 = i1, X0 = i0} = P{Xn+1 = j|Xn = i} = Pij

Um Processo Markoviano é dito ser uma Cadeia de Markov quando as variáveis randô-

micas estão deﬁnidas em um espaço de estado discreto.

O valor Pij representa a probabilidade de que o processo, quando no estado i, faça
uma transição para o estado j. Uma vez que as probabilidades são não-negativas e

25

3 Cadeias de Markov

uma vez que o processo deva fazer uma transição para algum estado, obtemos:

Pij ≥ 0;

i, j ≥ 0;

∞
(cid:88)

j=0

Pij = 1;

i = 0, 1, . . .

3.2 Diagrama de Transição de Estado

Para se representar uma Cadeia de Markov, utiliza-se um recurso gráﬁco denomi-

nado Diagrama de Transição de Estados composto por círculos ou elipses - tendo

estes, função de denominar os estados envolvidos - segmentos orientados ( localizados

entre os estados de transição ) - funcionando como indicações das transições entre os

estados, e acima ou ao lado desses segmentos orientados encontram-se na maioria dos

casos as probabilidades de transições entre os estados.

Retomando a apresentação do sistema do exemplo 3.1 envolvida com o conceito ci-
tado anteriormente pelo modelo generalizado Pij de representação de probabilidades
e considerando o estado A como 1 e estado B como 2, temos:

Exemplo 3.2. Baseado num experimento de estímulos de Skinner, que aborda experi-

ências sob inﬂuência de estímulos sensoriais, um cachorro foi colocado experimental-

mente num local com 3 divisões representadas por 1, 2 e 3 conforme a ﬁgura abaixo.

Sabe-se que por inﬂuência de estímulo sonoro, o animal muda de repartição em busca

de um determinado alimento, sabe-se que continua mantendo-se igual probabilidade

de escolha a qualquer uma das repartições, bem como, não haverá inﬂuência em rela-

ção às escolhas anteriores.

Referente ao exemplo acima, podemos citar um diagrama de transição de estados

da seguinte forma:

26

3.3 Vetor Probabilidade

Figura 3.4: Estímulo de Skinner

Figura 3.5: Diagrama de transição do modelo experimental de Skinner

3.3 Vetor Probabilidade

As probabilidades de transição entre os estados num intervalo de tempo discreto

na forma de matriz linha contidos numa Cadeia de Markov compreendem o que se

caracteriza por Vetor Probabilidade.

Genericamente, pode-se representar por:

Vi = [Pi1 Pi2 Pi3

. . . Pik]

Em que:

Pi1: representa a probabilidade de transição do estado i para o estado 1.

. . .
Pik: representa a probabilidade de transição do estado i para o estado k.

Considerações importantes:

I) Os elementos que constituem um vetor probabilidade são positivos, e seguindo os

conceitos probabilísticos, a soma dos mesmos será sempre igual a 1.

27

3 Cadeias de Markov

II) Quando nos referimos a uma certa observação, seja ela a enésima observação, por
exemplo, escrevemos V (n)
V (0)
i
V (1)
i
Utilizando os exemplos 3.1 e 3.2 para construção de seus respectivos Vetores Probabi-

: vetor de probabilidade numa referida observação inicial;

: vetor de probabilidade numa primeira observação.

, dessa forma, seguindo esta última consideração:

i

lidades, temos:

No caso do exemplo 3.1 :
1
V1 = [ 1
2 ]
2
3
V2 = [ 1
4 ]
4

No caso do exemplo 3.2 :
1
2 ]
2
3 ]
0 ]

V1 = [ 0
V2 = [ 1
3
V3 = [ 1
3

1
2
0
2
3

Observa-se que as probabilidades de permanência nos estados P11, P22 e P33 são
todas iguais a zero, justiﬁcando que o cachorro quando submetido ao estímulo sonoro

sempre mudará de um estado para outro.

3.4 Matrizes

Historicamente, os matemáticos Joseph Sylvester e Arthur Cayley há aproximada-

mente 150 anos , foram os precursores do estudo de matrizes, cabendo ao segundo,

maior aprofundamento em relação às demonstrações e aplicabilidades à respeito da

mesma.

Segundo os Parâmetros Curriculares Nacional (PCN), a abordagem do estudo de ma-

trizes deve ocorrer no ensino médio, salvo exceções. Dentro da abordagem do estudo

de matrizes, na maioria dos casos, são focadas suas propriedades, bem como exercí-

cios para ﬁxação, porém o vasto mundo das aplicações costumam ser deixadas para

um segundo plano. Tanto no ramo da Matemática, quanto em outros, as aplicações

de matrizes são várias, entre elas: computação gráﬁca, confecções de tabelas, pre-

visões climáticas e outras. Na área de Economia, por exemplo, onde são utilizados

comumente gráﬁcos e tabelas, as matrizes desenvolvem importante papel no armaze-

namento de dados, disponibilizando-os de forma organizada e precisa.

28

Nesse trabalho apresentaremos uma aplicação das matrizes na descrição das Cadeias

de Markov.

3.5 Matriz de Transição

Deﬁnição de matrizes

Chama-se matriz de ordem m por n (m x n) elementos, dos quais numéricos, um con-

junto de linhas e colunas disponibilizando os mesmos nesta ordem, possuindo suas

características e propriedades matemáticas deﬁnidas. Resumidamente, podemos deﬁ-

nir como uma tabela de informações codiﬁcadas de forma numérica.

Representação de uma Matriz

Para uma determinada matriz A, a mesma pode ser representada abreviadamente por
A = [aij], i variando de 1 a m (i = 1, 2, . . . , m) e j variando de 1 a n (j = 1, 2, . . . , n)

A =












a11
a12
a13
a21
a22
a23
a31
a32
a33
...
...
...
am1 am2 am3












. . .

. . .

a1n
a2n
. . .
a3n
...
...
. . . amn

Dessa forma, [aij], representa qualquer matriz A de ordem m por n.

Didaticamente, costuma-se chamar m por número de linhas e n por número de colu-

nas.

3.5 Matriz de Transição

É a matriz formada pelos vetores de probabilidades envolvidos numa Cadeia de Mar-

kov de k estados, seguindo as propriedades já mencionadas.
Representa-se a matriz de transição por M = [Pij].

M =










P11 P12 P13
P21 P22 P23
...
...
...
Pk1 Pk2 Pk3










. . . P1k
. . . P2k
...
...
. . . Pkk

Exemplo 3.3. Supondo que se hoje chove ou não, venha depender apenas das condi-

ções climáticas anteriores referentes aos últimos dois dias. Especiﬁcamente, supondo

29

3 Cadeias de Markov

que se choveu nos últimos dois dias, então choverá amanhã com probabilidade de 0,7;

se choveu hoje mas não ontem, então choverá amanhã com probabilidade de 0,5; se

choveu ontem mas não hoje, então choverá amanhã com probabilidade 0,4; se choveu

nos últimos dois dias, então choverá amanhã com probabilidade 0,2. Exiba, utilizando

uma matriz de transição, a distribuição das probabilidades envolvidas.

Resolução: Se deixarmos o estado no tempo n depender somente se está ou não
chovendo no tempo n, então não caracterizará uma Cadeia de Markov. No entanto,

podemos transformar este modelo em uma Cadeia de Markov dizendo que o estado a

qualquer momento é determinado pelas condições meteorológicas tanto naquele dia

como no dia anterior. Dessa forma, podemos expor o processo da seguinte forma:

• Estado 0: se chove hoje e choveu ontem

• Estado 1: se chove hoje, mas não choveu ontem

• Estado 2: se choveu ontem, mas não chove hoje

• Estado 3: se não choveu ontem ou hoje

P =



0, 7

0, 5







0

0

0

0

0, 4

0, 2

0, 3

0, 5

0

0









0

0

0, 6

0, 8

Exemplo 3.4. Considere um jogador que, em cada jogo, ganha R$ 1,00 com probabi-

lidade p ou perde R$ 1,00 com probabilidade 1 − p. Supondo que o referido jogador

deixa de jogar quando ele perde ou alcança uma fortuna de R$ N , então a fortuna do

jogador é uma Cadeia de Markov com probabilidade de transição dada por:

pi,i+1 = p = 1 − pi,i−1

;

i = 1, 2, . . . , N − 1

p00 = pN N = 1

Os estados 0 e N são chamados de estados absorventes, pois uma vez que se encontrar

nos mesmos, não é possível deixá-los.

30

3.6 Equações de Chapman-Kolmogorov

3.6 Equações de Chapman-Kolmogorov

As Equações de Chapman-Kolmogorov possibilitam obter o resultado a partir de uma
matriz de transição de passo n, n passos no tempo. Considerando P n
ij como a probabi-
lidade de transição do estado i para o estado j de passo n e ξ representando os estados,

podemos interpretar como:

P n

ij = P {Xn+k = j|Xk = i}, n ≥ 0;

i, j ≥ 0

P (n+m)
ij

=

ikP m
P n
kj

(cid:88)

k∈ξ

para todo

i,

j, m, n ≥ 0.

As probabilidades de transição P n
kj representam a probabilidade que a partir de i
o processo vá para o estado j em n + m transições através de um caminho que conduz

ik e P m

ao estado k na n-ésima transição. Assim, somando-se todos os estados intermediários

k, resultará a probabilidade de que o processo estará no estado j após transições n+m.

De forma generalizada, pode-se representar por:

P n+m
ij

= P {Xn+m = j|X0 = i}

=

=

=

(cid:88)

k∈ξ
(cid:88)

k∈ξ
(cid:88)

k∈ξ

P {Xn+m = j, Xn = k|Xo = i}

P {Xn+m = j, Xn = k, Xo = i}P {Xn = k|Xo = i}

kj P n
P m
ik

Como P n denota a matriz de probabilidades de transição de passon, com base na

equação citada anteriormente, podemos aﬁrmar que P (n+m) = P n.P m .
Por indução, pode-se demonstrar que:

P n = P (n−1+1) = P n−1.P = P n

Dessa forma, a matriz de transição de n passos, pode ser obtida, multiplicando-se a

matriz P por si mesma n vezes. Para isso, observemos um caso em particular:

P 2 = P (1+1) = P.P = P 2

Exemplo 3.5. Suponha que a chance de chuva amanhã dependa das condições climá-

ticas anteriores somente se está ou não chovedo hoje, e não das condições climáticas

do passado, e também, que se chover hoje, então choverá amanhã com probabilidade

α, e se não chover hoje, então choverá amanhã com probabilidade β.

Considerando que o processo está no estado 0 quando chove e estado 1 quando não

31

3 Cadeias de Markov

chove, então o precedente é uma Cadeia de Markov de dois estados cujas probabilida-

des de tansição são dadas por:

P =

(cid:35)

(cid:34)

α 1 − α

β 1 − β

Admitindo α = 0,7 e β = 0,4, qual a probabilidade de chuva quatro dias a partir de

hoje, dado que hoje está chovendo?

Resolução:

A matriz de probabilidade de transição de passo 1 é dada por:

P =

(cid:34)

(cid:35)

0, 7 0, 3

0, 4 0, 6

P 2 =

(cid:34)

(cid:35)
.

0, 7 0, 3

0, 4 0, 6

(cid:34)

0, 7 0, 3

0, 4 0, 6

(cid:35)

(cid:34)

=

0, 61 0, 39

(cid:35)

0, 52 0, 48

(cid:34)

P 4 = (P 2)2 =

0, 61 0, 39

0, 61 0, 39

0, 52 0, 48

0, 52 0, 48

(cid:34)

(cid:35)
.

(cid:35)

(cid:34)

=

0, 5749 0, 4251

(cid:35)

0, 5668 0, 4332

A probabilidade em questão é P 4

00, que equivale a 0,5749.

3.7 Classiﬁcação dos estados em Cadeias de Markov

a) Alcançável: Um estado j é dito ser alcançável ou acessível, a partir de um estado
ij > 0 para algum n > 0 . Isto implica na probabilidade do sistema

i, quando P n
entrar no estado j eventualmente quando este começa no estado i.

P [entrar em j| começando em i] = P {∪∞

n=0[Xn = j]|Xo = i}

≤

∞
(cid:88)

n=0

P Xn = j|Xo = i

∞
(cid:88)

n=0

P n
ij

b) Comunicante: Consiste em um estado j ser alcançável a partir do estado i, assim
como, o estado i ser alcançável a partir do estado j. Costuma-se representar tal

relação entre os estados comunicantes por i ↔ j.

32

3.7 Classiﬁcação dos estados em Cadeias de Markov

Quando qualquer estado se comunicar com seu próprio início, podemos deﬁnir

como:

P 0
ii = P{Xo = i|Xo = i} = 1

A relação de comunicação entre os estados satisfaz três propriedades:

• i) Estado i se comunica com estado i, para todo i ≥ 0

• ii) Se o estado i se comunica com o estado j, então, estado j se comunica

com estado i

• iii) Se o estado i se comunica com o estado j, e o estado j se comunica com

estado k, então o estado i se comunica com o estado k.

As propriedades (i) e (ii) seguem claramente a deﬁnição de comunicação.

Para provar a propriedade (iii), supõe-se que i se comunica com j, e j se comu-
nica com k. Portanto, existem inteiros n e m tais que P n
jk ≥ 0. Pelas
equações de Chapman-Kolmogorov, temos:

ij ≥ 0, P m

P n+m

ik =

∞
(cid:88)

r=0

irP m
P n

rk ≥ P n

ijP m

jk > 0

Consequentemente, o estado k é acessível a partir do estado i. Similarmente, po-

demos expor que o estado i é acessível a partir do estado k. Portanto, os estados

i e k se comunicam.

Quando dois estados são comunicantes entre si, podemos dizer que fazem parte

da mesma classe, e no caso em que todos os estados pertencem a uma única

classe, é dita ser irredutível.

c) Transiente: Uma cadeia é dita transiente, quando ao entrar neste estado, o

processo pode nunca retornar novamente ao mesmo. Portanto, o estado i é

transiente, se e somente se, existe um estado j, j (cid:54)= i, que é alcançável a partir

do estado i mas não vice-versa, ou seja, o estado i não é alcançável a partir

do estado j. Por consequência, um estado transiente será visitado somente um

número ﬁnito de vezes.

d) Recorrente: uma cadeia é dita recorrente, quando entrando neste estado, o pro-

cesso deﬁnitivamente retornará ao mesmo. Quando um estado é recorrente, não

pode ser transiente. Considerando o citado acima:

33

3 Cadeias de Markov

In = 1, se Xn = i;

0, seXn (cid:54)= i

Representando o número de períodos do processo no estado i por:

E

(cid:34) ∞
(cid:88)

n=0

(cid:35)

In|X0 = i

=

∞
(cid:88)

n=0

E [In|Xo = i]

=

∞
(cid:88)

n=0

P{Xn = i|Xo = i}

∞
(cid:88)

n=0

P n
ii

Dessa forma, pode-se dizer que, ocorre estado recorrente se (cid:80)∞
estado transiente, se (cid:80)∞
ii < ∞.

n=1 P n

n=1 P n

ii = ∞ e

e) Absorvente: ocorre quando, ao entrar neste estado, o processo nunca irá deixá-
lo. Portanto, um estado i é absorvente, se e somente se, Pii = 1 . Desse forma,
pode-se dizer que um estado absorvente é um caso especial de um estado recor-

rente.

3.8 Probabilidades limite

Em diversos casos, estamos interessados nas probabilidades de estados após um

número de períodos considerável, ou seja estamos interessados precisamente quando

n → ∞. Quando essas probabilidades convergem a valores constantes; tal fato é co-

nhecido como Probabilidades Limite dos estados.

Exemplo 3.6. Segundo uma pesquisa realizada sobre a prescrição de uma droga ao

tratamento de pacientes com certa infecção, foram avaliados três laboratórios, res-

pectivamente A, B e C. Esta pesquisa tem como estimativa de prescrição médica a

conﬁança em certo laboratório de 80%, possibilitando aos demais em questão, uma

chance de 20% para mudança. Os tratamentos são observados, podendo haver mu-

dança de acordo com a resposta ao tratamento num período de observação estipulado.

Foram notadas que as mudanças de indicação em relação aos laboratórios são as se-

guintes:

• Mudança do laboratório A para os laboratórios B e C são 12% e 8%, respectiva-

mente;

34

3.8 Probabilidades limite

• Mudança do laboratório B para os laboratórios A e C são 15% e 5%, respectiva-

mente;

• Mudança do laboratório C para os laboratórios A e B são 13% e 7%, respectiva-

mente;

M =






0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8






Para realização dos cálculos, substituiremos os estados A, B e C respectivamente

por 1, 2 e 3.

Foi necessária a utilização de um software matemático, visando um melhor entendi-

mento e menos dispêndio de tempo para realização dos produtos de Matrizes.

Levando em consideração que uma equipe médica mantém a conﬁança de prescrição

da droga fabricada pelo laboratório B, podemos analisar os vetores estados futuros da

seguinte forma:

2 = V 1
V 0

2 = [0, 15

0, 8

0, 05]

2 = V 1
V 2

2 · M = [0, 15 0, 8 0, 05] ·

2 = V 1
V 3

2 · M 2 = [0, 15 0, 8 0, 05] ·

2 = V 1
V 10

2 ·M 9 = [0, 15 0, 8 0, 05]·


















2 = V 1
V 11

2 ·M 10 = [0, 15 0, 8 0, 05]·



0, 8

0, 12 0, 08



0, 15

0, 8

0, 05

0, 13 0, 07

0, 8


 = [0, 247

0, 662

0, 092]

0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8

...

0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8

2





9





= [0, 308

0, 565

0, 126]

= [0, 411

0, 358

0, 231]

0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8

10






= [0, 413

0, 352

0, 236]

35

3 Cadeias de Markov

2 = V 1
V 12

2 ·M 11 = [0, 15 0, 8 0, 05]·





2 = V 1
V 30

2 ·M 29 = [0, 15 0, 8 0, 05]·





0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8

...

0, 8

0, 12 0, 08

0, 15

0, 8

0, 05

0, 13 0, 07

0, 8

11






29






= [0, 414

0, 347

0, 239]

= [0, 414

0, 340

0, 246]

Observa-se que, para todos os períodos maiores que n = 10, os vetores-probabilidade

se aproxima de um vetor constante, fato esse, chamado de Probabilidade Limite.

Pelo vetor-probabilidade em que n = 30, podemos deduzir que a probabilidade de mu-

dança de prescrição médica da droga fabricada pelo laboratório B para o laboratório

A é de aproximadamente 41,4%; de permanecer no laboratório B é de aproximada-

mente 34% e de mudança do laboratório B para C é de aproximadamente 24,6%.

3.9 Problema da Ruína do Jogador

Considerando um jogador que em cada jogo tem probabilidade p de ganhar uma

unidade e probabilidade q= 1-p de perder uma unidade. Assumindo que sucessivas

jogadas são independentes, qual é a probabilidade de que, começando com i unidades,

a fortuna do jogador alcance um referido valor N antes de atingir 0?
Se XN denota a fortuna do jogador no tempo n, então o processo {Xn, n = 0, 1, 2, · · ·}
é uma cadeia de Markov com probabilidade de transição

P00 = PN N = 1

Pi,i+1 = p = 1 − Pi,i−1;

i = 1, 2, · · · , N − 1

Esta cadeia de Markov tem três classes, ou seja, {0}, {1, 2, · · · , N − 1} e {N }; sendo

a primeira e a terceira, classes recorrentes e a segunda transitória. Uma vez que cada

estado transitório é visitado, apenas ﬁnitamente muitas vezes, segue-se que, após al-

guma consideração ﬁnita de tempo, o jogador vai atingir seu objetivo de atingir N ou

ir perdendo.
Seja Pi,
do jogador eventualmente alcance N. Ao condicionar o resultado do jogo inicialmente,

i = 0, 1, · · · , N , denota-se a probabilidade de que, a partir de i, a fortuna

obtemos:

36

Pi = pPi+1 + qPi−1,

i = 1, 2, · · · , N − 1

3.9 Problema da Ruína do Jogador

Ou equivalente, uma vez que p + q = 1

pPi + qPi = pPi+1 + qPi−1

Portanto, como P0 = 0, obtemos da linha precedente que

P2 − P1 =

q
p

(P1 − P0) =

q
p

P1

ou

Pi+1 − Pi =

q
p

(Pi − Pi−1) ,

i = 1, 2, · · · , N − 1

Portanto, como P0 = 0, obtemos da linha precedente que

P2 − P1 =

q
p

(P1 − P0) =

q
p

P1

P3 − P2 =

q
p

(P2 − P1) =

(cid:19)2

(cid:18) q
p

P1

...

Pi − Pi−1 =

q
p

(Pi−1 − Pi−2) =

(cid:19)i−1

(cid:18) q
p

P1

...

PN − PN −1 =

q
p

(PN −1 − PN −2) =

(cid:19)N −1

P1

(cid:18) q
p

A adição da primeira consideração i -1 dessas equações produz

Pi − P1 = P1

(cid:19)

(cid:34)(cid:18) q
p

+

(cid:18) q
p

(cid:19)2

+ · · · +

(cid:19)i−1(cid:35)

(cid:18) q
p

ou

Pi =





(cid:17)i
(cid:17) P1;

1−

1−

(cid:16) q
p
(cid:16) q
p

se

q
p (cid:54)= 1

iP1;

se

q
p = 1

Agora, usando o fato de que PN = 1, obtemos

P1 =






e consequentemente

1−

(cid:17)
(cid:17)N ;

(cid:16) q
p
(cid:16) q
p

1−

se p (cid:54)= 1
2

1
N ;

se p = 1
2

37

3 Cadeias de Markov

Pi =





1−

1−

(cid:17)i
(cid:17)N ;

(cid:16) q
p
(cid:16) q
p

se p (cid:54)= 1
2

i
N ;

se p = 1
2

Nota-se que, como N → ∞

Pi =




1 −

(cid:17)i

(cid:16) q
p

;

se p > 1
2


0

; se p (cid:54) 1
2

Assim, se p > 1
mentar indeﬁnidamente; enquanto que se p (cid:54) 1
ir à falência contra um adversário inﬁnitamente rico.

2 , há uma probabilidade positiva de que a fortuna do jogador irá au-
2 , o jogador vai, com probabilidade 1,

Exemplo 3.7. Num determinado cassino, um jogador resolve apostar no jogo da ro-

leta. Sabe-se que o mesmo possui apenas R$ 50,00 para realizar inicialmente suas

apostas.

Em cada rodada ele aposta R$ 25,00 no vermelho, se ocorrer vermelho como resultado

ele ganhará R$ 25,00, caso contrário, ele perde seus R$ 25,00. De forma prática, po-

demos considerar que as chances de ganhar equivalem a 50%, porém deve-se acreditar

que de forma real, tal chance seria bem menor.

A regra para analisar tal jogo é que ele para de jogar quando perde tudo ou adquire

R$ 75,00 no total. Analisando este processo e seu comportamento a longo prazo em

uma Cadeia de Markov, obtemos:

Considerando os valores limites em relação aos acréscimos ou decréscimos de R$

Diagrama de estados

25,00, temos:

Estado 1 : R$ 0

Estado 2 : R$ 25,00

Estado 3 : R$ 50,00

Estado 4 : R$ 75,00

Baseando-se em conceitos vistos sobre Cadeias de Markov, é importante ressaltar que

os estados 1 e 4 são classiﬁcados como absorventes, pois uma vez que se entra nestes

estados, é impossível sair dos mesmos .

38

3.9 Problema da Ruína do Jogador

Figura 3.6: Diagrama de estados da ruína do jogador









P11 P12 P13 P14
P21 P22 P23 P24
P31 P32 P33 P34
P41 P42 P43 P44









P =



1

0, 5







0

0

0

0

0, 5

0

0

0, 5

0

0









0

0

0, 5

1

Probabilidades a longo prazo



0



1

0

P 10 =













0, 333

0

0

0

0

0

0, 5

0, 25

0, 25

0, 666 0, 001

0, 333

0, 667 0 0 0, 333

0, 25

0, 25

0, 5

0, 001 0, 666

0, 333 0 0 0, 667

P 25 =



















0

1

0

0 0

1



0



1

0 0

0



P =



1

0

P 2 =







P ∞ =

0

0

1

0









0

0

0









0 0

1 0 0 0
1
2
3
3
2
1
3
3
0 0 0 1

0 0

Esta matriz não é regular, portanto a melhor forma para generalizarmos seria :

P ∞ = [ x 0 0 1-x]

Mas, relembrando, nosso jogador iniciou com R$ 50,00 caracterizando início no

estado 3. Portanto podemos utilizar começando um vetor de probabilidade da seguinte

forma:

V = [0 0 1 0]

V P 50 = [0 0 1 0 ] ·



1

0, 5







0

0

0

0

0, 5

0

0

0, 5

0

0

50



0

0

1







0, 5

39

3 Cadeias de Markov

V P 50 ≈

(cid:20) 1
3

0

0

(cid:21)

2
3

Portanto, quando iniciando com R$ 50,00, nosso referido jogador tem 1

3 de chance

de ir ao estado 1 e 2
Se o jogador iniciasse com R$ 25,00, ele iniciaria no estado 2. Portanto, poderia ser

3 de chance de adquirir R$ 25,00, ou seja, chegar ao estado 4.

representado por um vetor de probabilidade da seguinte forma:

V = [0 1 0 0]

V P 50 = [0 1 0 0 ] ·



1

0, 5







0

0

0

0

0, 5

0

V P 50 ≈

(cid:20) 2
3

0

0

50









0

0

0, 5

1

0

0, 5

0

0

(cid:21)

1
3

Porém, iniciando com R$ 25,00 nosso referido jogador tem 2
1 e 1

3 de adquirir R$ 25,00.

3 de chance de ir ao estado

40

4 Cadeias de Markov Ocultas

Num Modelo Markoviano dito padrão ou regular, é possível ao observador enxergar

o estado desejado. Entre os estados existem as probabilidades de transições de estados,

bem como a referida distribuição de probabilidade em relação aos possíveis resultados.

Tais itens são chamados de parâmetros.

Tratando-se de um Modelo de Markov Oculto, os parâmetros até então tidos como

observáveis no modelo de Markov regular, se tornam ocultos e também algo a serem

determinados. O desaﬁo é determinar os parâmetros ocultos a partir dos parâmetros

observáveis. Tal modelo é conhecido pelas importantes aplicações em diversos ramos

da Ciência, entre eles, diversos tipos de séries temporais e Biologia computacional,

também conhecida como Bioinformática.

4.1 Abordando um exemplo

Suponha que queremos determinar a temperatura média anual em um determinado

local da Terra ao longo de uma série de anos. Para tornar essa busca mais interessante,

consideraremos que num passado distante aconteciam possíveis veriﬁcações erradas a

respeito do mesmo , numa época antes da invenção dos termômetros. Uma vez que

não podemos voltar no tempo, em vez disso, procuramos indícios indiretos da tempe-

ratura.

Para simpliﬁcar o problema, consideramos apenas duas temperaturas anuais,sendo

elas quente ou fria, representadas por H ou C respectivamente . Supondo que dados

meteorológicos contemporâneos indiquem que a probabilidade de um ano quente ser

seguido por outro ano quente seja 0,7 e a probabilidade de que um ano frio seja se-

guido por outro ano frio é 0,6.

Vamos supor que essas probabilidades também aconteceram no passado distante ci-

tado anteriormente, sendo estado 1 representado por quente e estado 2 por frio, as

informações podem ser resumidas como:

(cid:34)

(cid:35)

.

0, 7 0, 3

0, 4 0, 6

41

4 Cadeias de Markov Ocultas

A pesquisa atual apresenta uma correlação entre os estados e três níveis de escalas de

graduação. Para simpliﬁcar, consideramos apenas três escalas diferentes, chamadas

de anéis, Pequeno, Médio e Grande, ou S, M e L, respectivamente. Estes anéis são

obtidos através de um corte transversal ao tronco de uma árvore, agindo como fonte

de observações e dados associados ao estudo da temperatura.

Finalmente, supondo que com base nas evidências meteorológicas, a relação probabi-

lística entre a temperatura anual e as escalas de graduação são representadas por

(cid:34)

0, 1 0, 4 0, 5

0, 7 0, 2 0, 1

(cid:35)

.

Onde, as linhas representam quente (H) e frio (C) sucessivamente, assim como as

colunas estão ordenadas em S, M e L sucessivamente.

Para este sistema, o estado é a temperatura média anual H ou C. A transição de um

estado para o outro é um processo de Markov (de ordem 1), uma vez que o próximo

estado depende apenas do estado atual e das probabilidades ﬁxadas . No entanto, os

estados estão escondidos, uma vez que não podemos observar diretamente a tempera-

tura no passado.

Embora não possamos observar o estado (temperatura) no passado, podemos ob-

servar o tamanho dos anéis envolvidos. Os anéis fornecem informações probabilísticas

a respeito da temperatura. Desde que os estados estejam “escondidos”, este tipo de

sistema é visto como um Hidden Markov Model “Modelo de Markov Oculto” (HMM). O

objetivo é fazer uso efetivo e eﬁciente das informações observáveis de modo a ganhar

a introspecção em vários aspectos do processo de Markov.

Sendo a matriz de transição de estado A, dada por:

(cid:34)

(cid:35)

0, 7 0, 3

0, 4 0, 6

e a matriz de observação B sendo:

(cid:34)

0, 1 0, 4 0, 5

0, 7 0, 2 0, 1

(cid:35)

.

Neste exemplo, supomos que a distribuição de estado inicial, denotada por π, é

(cid:104)

π =

0, 6 0, 4

(cid:105)

42

4.1 Abordando um exemplo

As matrizes π, A e B são estocásticas de linha, signiﬁcando que cada elemento é

uma probabilidade e os elementos de cada linha somam 1, ou seja, cada linha é uma

distribuição de probabilidade.

Agora considerando um período particular de quatro anos de interesse do passado

distante, para o qual observamos a série de anéis S, M, S, L.

Figura 4.1: Anéis de crescimento de árvores [5]

Aceitando 0 representar S, 1 representar M e 2 representar L, esta sequência de

observação é

O = (0, 1, 0, 2)

Podemos querer determinar a sequência de estado mais provável do processo de

Markov dada observação. Isto é, podemos querer saber as temperaturas médias mais

prováveis durante o período de quatro anos de interesse. Isto não é tão claro quanto

parece, uma vez que há provavelmente diferentes interpretações possíveis de “pro-

vavelmente”. Por um lado, pode-se razoavelmente deﬁnir “provavelmente” como a

sequência de estado com maior probabilidade dentre todas as possíveis sequências de

estado, ocorrer a de comprimento quatro. Por outro lado, podemos razoavelmente de-

ﬁnir “provavelmente” como a sequência de estado que maximiza o número esperado

de estados corretos. HM M pode ser usado para encontrar esta sequência.

Apresentamos um dos aspectos mais desaﬁadores dos HMM, ou seja, a notação. Em

seguida, discutimos os três problemas fundamentais relacionados aos HMM e fornece-

mos algoritmos para suas soluções. Consideramos também algumas questões compu-

tacionais críticas que serão abordadas ao escrever qualquer programa de computador

que aborde HMM. Concluímos com um exemplo, que não requer qualquer conheci-

mento especializado, mas ilustra bem a força da abordagem HMM.

43

4 Cadeias de Markov Ocultas

4.2 Notação

Consideremos:

• T = Comprimento da sequência de observação

• N = Número de estados no modelo

• M = Número de símbolos de observação

• Q = q0, q1, ..., qN −1 = Estados distintos do processo de Markov

• V = 0, 1, ..., M – 1 = conjunto de possíveis observações

• A = Probabilidades de transição de estado

• B = Matriz de probabilidade de observação

• π = Distribuição de estado inicial

• O = (O0, O1, ..., OT −1) = Sequência de observação

As observações são sempre denotadas por {0, 1, ..., M − 1}, uma vez que isso simpli-

ﬁca a notação sem perda de generalidade. Isto é, Oi ∈ V para i = 0, 1, ..., T − 1.

Um modelo genérico oculto de Markov é ilustrado na Figura 4.1, onde os Xi re-
presentam a sequência de estado oculto e toda outra notação é como dado acima. O

processo de Markov está escondido acima da linha tracejada e, é determinado pelo
estado atual e pela matriz A. Somente podemos observar os Oi, que estão relacionados
com os estados (ocultos) do processo de Markov pela matriz B.

Figura 4.2: Modelo Oculto de Markov

Para o exemplo de temperatura anterior, com a sequência de observações , temos

T = 4; N = 2; M = 3; Q = H, C; V = 0, 1, 2 (onde considerar os 0, 1, 2 representam

pequeno, médio e grande anéis, respectivamente). Neste caso, as Matrizes A, B e π
são dadas por (3), (4) e (5), respectivamente. A matriz A = {aij} é N x N com

aij = P(estado qj em t + 1|estado qi em t)

44

4.2 Notação

e A é linha estocástica. Observe que as probabilidades aij são independentes de t.

A matriz B = {bj(k)} é um N x M com

bj(k) = P(observação k em t | estado qj em t)

Como a matriz A, a matriz B é de linha estocástica e as probabilidades bj(k) são

independentes de t. A notação incomum bj(k) é padrão no mundo HM M .
Um HM M é deﬁnido por A, B e π (e, implicitamente, pelas dimensões N e M ). O

HMM é denotado por λ = (A, B, π).

Considere uma sequência genérica de estado de comprimento quatro

X = (x0, x1, x2, x3)

Com observações correspondentes

O = (O0, O1, O2, O3)

Então πx0 é a probabilidade de começar no estado x0. Além disso, bx0(O0) é a proba-
bilidade de iniciarmos observando O0 e ax0,x1 é a probabilidade de transitar do estado
x0 para o estado x1. Continuando, vemos que a probabilidade da sequência de estados
X é dada por

P(X, O) = πx0bx0(O0)ax0,x1bx1(O1)ax1,x2bx2(O2)ax2,x3bx3(O3)

Considere novamente o exemplo de temperatura na Seção 4.1 com a sequência de

observação O = (0, 1, 0, 2), conforme dado . Usando-a, podemos calcular, digamos,
P(HHCC) = 0,6·(0,1)·(0,7)·(0,4)·(0,3)·(0,7)·(0,6)·(0,1) = 0,000212.
Da mesma forma, podemos calcular diretamente a probabilidade de cada possível

sequência em relação ao estado de comprimento quatro, assumindo a sequência de

observação dada. Apresentamos esses resultados na seguinte tabela, onde as probabi-

lidades na última coluna são normalizadas de modo que a soma seja igual a 1.

Para obter a sequência de estado ótima, deve-se escolher a sequência com maior pro-

babilidade, ou seja, CCCH. Para obter o melhor no sentido HM M , escolhemos o

símbolo mais provável em cada posição. Para isso somamos as probabilidades na ta-

bela que têm um H na primeira posição. Fazendo isso, temos a probabilidade (nor-

malizada) de H na primeira posição que é 0,18817 e, portanto, a probabilidade de

C na primeira posição é 0,81183. Assim, o HM M escolhe o primeiro elemento da

sequência ótima para ser C. Repetimos isto para cada elemento da sequência, obtendo

as probabilidades na tabela 2.

A partir da tabela 2, temos que a sequência ótima no sentido HM M é CHCH.

45

4 Cadeias de Markov Ocultas

Estado Probabilidade Probabilidade Normalizada

HHHH

0,000412

HHHC

HHCH

HHCC

HCHH

HCHC

HCCH

HCCC

0,000035

0,000706

0,000212

0,000050

0,000004

0,000302

0,000091

CHHH

0,001098

CHHC

CHCH

CHCC

CCHH

CCHC

CCCH

CCCC

0,000094

0,001882

0,000564

0,000470

0,000040

0,002822

0,000847

0,042787

0,003635

0,073320

0,022017

0,005193

0,000415

0,031364

0,009451

0,114031

0,009762

0,195451

0.058573

0,048811

0,004154

0,293073

0,087963

Tabela 4.1: Probabilidades de sequências de estados

4.3 Os três problemas fundamentais

Existem três problemas fundamentais que podemos resolver usando HM M . Aqui,

descreveremos esses três problemas e, na próxima seção, fornecemos algoritmos para

soluções.

Elemento

0

1

2

3

P(H)
P(C)

0,188182 0,519576 0,228788 0,804029

0,811818 0,480424 0,771212 0,195971

Tabela 4.2: Probabilidades HMM

46

4.4 Problema 1

4.4 Problema 1

Dado o modelo λ = (A, B, π) e uma sequência de observações O, buscando P(O|λ).
Aqui queremos determinar a probabilidade da sequência observada O, dado o modelo.

4.5 Problema 2

Dado λ = (A, B, π) e uma sequência de observação O, busca-se uma sequência de

estado ótima para o Processo de Markov subjacente. Em outras palavras, queremos

descobrir a parte oculta do Modelo de Markov Oculto.

4.6 Problema 3

Dada uma sequência de observação O e as dimensões N e M , e o modelo λ =

(A, B, π) que maximiza a probabilidade de O. Isso pode ser visto como um modelo

de treinamento para melhorar dados observados. Alternativamente, podemos ver isso

como uma subida de colina (discreta) no parâmetro espaço representado por A, B e

π.

4.7 Discussão

Considere o problema do reconhecimento de fala ( ocorre por ser uma das mais

conhecidas aplicações de HM M ). Podemos usar a solução para o Problema 3 para
treinar um HM M , digamos, λ0 para reconhecer a palavra falada NÃO e treinar outro
HM M , digamos, λ1 para reconhecer a palavra SIM. Em seguida, dada uma palavra
falada desconhecida, podemos usar a solução para o Problema 1 para marcar esta
palavra contra λ0 e também contra λ1 para determinar se é mais provável NÃO, SIM
ou NENHUM. Neste caso, não é necessário resolver o problema 2, mas é possível que

tal solução que descobre os estados ocultos possa fornecer uma visão adicional sobre

o modelo de fala subjacente.

47

4 Cadeias de Markov Ocultas

4.8 As três soluções

4.8.1 Solução para o problema 1

Seja λ = (A, B, π) um modelo dado e seja O = (O0, O1, · · · , OT −1) uma série de

observações. Queremos encontrar P(O|λ).
Seja X = (x0, x1, · · · , xT −1) uma sequência de estados. Então, pela deﬁnição de B,
temos

P(O|X, λ) = bxo(O0)bx1(O1) · · · bxT −1(OT −1)

E pela deﬁnição de π e A segue-se que

P(X|λ) = πx0ax0,x1ax1,x2 · · · axT −2,xT −1.

P(O, X|λ) =

P(O ∩ X ∩ λ)
P(λ)

Desde que

e

P(O|X, λ)P(X|λ) =

P(O ∩ X ∩ λ)
P(X ∩ λ)

·

P(X ∩ λ)
P(λ)

=

P(O ∩ X ∩ λ)
P(λ)

temos

P(O, X|λ) = P(O|X, λ)P(X|λ).

Ao somar todas as possíveis sequências de estado, obtemos

P(O|λ) =

=

=

(cid:88)

X
(cid:88)

X
(cid:88)

X

P(O, X|λ)

P(O|X, λ)P(X|λ)

πx0bx0(O0)ax0,x1bx1(O1) · · · axT −2,xT −1bxT −1(OT −1)

No entanto, esta computação direta é geralmente inviável, uma vez que requer cerca
de 2T N T multiplicações. A força de HMM deriva em grande parte do fato de que existe
um algoritmo eﬁciente para obter o mesmo resultado.
Para encontrar P(O|λ), utiliza-se o chamado algoritmo progressivo, ou passo-α. Para
t = 0, 1, · · · , T − 1 e i = 0, 1, · · · , N − 1, deﬁne

αt(i) = P(O0, O1, · · · , Ot, xt = qi|λ)

48

4.8 As três soluções

Então αt(i) é a probabilidade da sequência de observação parcial até o tempo t,
onde o Processo de Markov está no estado qi no tempo t. O discernimento crucial aqui
é que o αt(i) pode ser computado recursivamente como segue.
1. Seja α0(i) =πibi(O0), para i = 0, 1, · · · , N − 1
2. Para t = 1, 2, · · · , T − 1 e

i = 0, 1, · · · , N − 1:





N −1
(cid:88)



αt−1(j)aji

 bi(Ot).

αt(i) =

Sendo:

j=0

P(O|λ) =

N −1
(cid:88)

i=0

αT −1(i).

O algoritmo progressivo precisa de N 2T operações.

4.8.2 Solução para o Problema 2

Dado o modelo λ = (A, B, π) e uma sequência de observações O, nosso objetivo é

encontrar a sequência de estado mais provável. Como mencionado acima, há diferen-

tes interpretações possíveis de “provavelmente”. Para HM M queremos maximizar o

número esperado de estados corretos. Em contraste, um programa dinâmico encontra

o caminho global de maior pontuação. Como vimos, essas soluções não são necessari-

amente as mesmas.

Primeiro, deﬁnimos o algoritmo retrocesso, ou passo-β. Isso é análogo ao passo- α dis-

cutido acima, distinguindo-se porque ele começa no ﬁnal e funciona de volta para o

início.

Para t = 0, 1, · · · , T − 1 e i = 0, 1, N − 1, deﬁne

βt(i) = P(Ot+1, Ot+2, · · · , OT −1|xt = qi, λ)

Então o βt(i) pode ser computado recursivamente (e eﬁcientemente) como segue.

1. Seja βT −1(i) = 1, para i = 0, 1, N − 1.
2. Para t = T − 2, T − 3, · · · , 0 e i = 0, 1, N − 1, computando

βi =

N −1
(cid:88)

j=0

aijbj(Ot+1)βt+1(j)

Para t = 0, 1, · · · , T − 1 e i = 0, 1, · · · , N − 1, deﬁne

γt(i) = P(xt = qi|O, λ)

49

4 Cadeias de Markov Ocultas

Uma vez que αt(i) mede a probabilidade relevante até o tempo t e βt(i) mede a pro-
babilidade após o tempo t,

γt(i) =

αt(i)βt(i)
P(O|λ)

Vale lembrar que o denominador P(O|λ) é obtido pela soma αT −1(i) sobre i. Pela
deﬁnição de γt(i) segue-se que o estado mais provável no tempo t é o estado qi para o
qual γt(i) é máxima, onde o máximo é tomado sobre o índice i.

4.8.3 Solução para o Problema 3

Aqui, queremos ajustar os parâmetros do modelo para aprimorar as observações. Os

tamanhos das matrizes N e M são ﬁxadas mas os elementos de A, B e π devem ser

determinados, para a condição estocástica de linha. O fato de que podemos reestimar

o próprio modelo é um dos aspectos mais surpreendentes de HM M .
Para t = 0, 1, · · · , T − 2 e i, j ∈ {0, 1, . . . , N − 1}, deﬁne-se “(di − γ)(cid:48)(cid:48) como

γt(i, j) = P(xt = qi, xt+1 = qj|O, λ).

Então γt(i, j) é a probabilidade de estar no estado qi no tempo t e em trânsito para
o estado qj no tempo t + 1. Os “di-gammas” podem ser escritos em termos de α, β, A
e B como

γt(i, j) =

αt(i)ai,jbj(Ot+1)βt+1(j)
P(O|λ)

Para t = 0, 1, . . . , T − 2, o γt(i) e γt(i, j) são relacionados por

γt(i) =

N −1
(cid:88)

j=0

γt(i, j)

Considerando o γ e “di-gama” veriﬁcamos abaixo que o modelo λ = (A, B, π) pode

ser reestimada do seguinte modo.

1. Para i = 0, 1, . . . , N − 1, temos

πi = γ0(i)

2. Para i = 0, 1, . . . , N − 1, e j = 0, 1, . . . , N − 1, computa-se

aij =

(cid:80)T −2

t=0 γt(i, j)
(cid:80)T −2
t=0 γt(i)

50

4.8 As três soluções

3. Para j = 0, 1, . . . , N − 1 e k = 0, 1, . . . , M − 1, computa-se

bj(k) =

(cid:80)

t∈{0,1,...,T −1}Ot=k γt(j)
t=0 γt(j)

(cid:80)T −1

O numerador do aij reestimado pode ser visto para dar o número esperado de transi-
ções do estado qi para o estado qj, enquanto o denominador é o número esperado de
transições de qi para qualquer estado. Então, a razão é a probabilidade de transitar do
estado qi para o estado qj, que é o valor desejado de aij.
O numerador do bj(k) reestimado é o número esperado de vezes que o modelo é no
estado qj com observação k, enquanto o denominador é o número esperado de vezes
que o modelo está no estado qj. A razão é a probabilidade de observar o símbolo k,
dado que o modelo está no estado qj, que é o valor desejado de bj(k).

A reestimação é um processo iterativo. Primeiro, inicializamos λ = (A, B, π) com

um melhor adivinho ou, se nenhuma suposição razoável estiver disponível, escolhemos
valores aleatórios tais que πi ≈ 1
M . É crítico que A, B e π seja
randomizado, uma vez que valores uniformes resultarão em um máximo local a partir

N e bj(k) ≈ 1

N e aij ≈ 1

do qual o modelo não pode subir. Como sempre, π, A e B devem ser estocásticos de

linha. A solução para o problema 3 pode ser resumida como se segue.

1. Inicializar, λ = (A, B, π)

2. Calcular αt(i), βt(i), γt(i, j)eγt(i)

3. Reestimar o modelo λ = (A, B, π)

4. Se P(O|λ) aumentar consideravelmente, redirecione-se para 2.

Claro, pode ser desejável parar se P(O|λ) não aumentar pelo menos em alguns pre-

determinados e, ou para deﬁnir um número máximo de iterações.

Exemplo 4.1. Numa sala de aula, um professor de Matemática propôs a seus alunos

a seguinte ideia em relação a uma atividade a ser realizada envolvendo perguntas a

respeito de alguns tópicos de Matemática. Os referidos tópicos eram simbolizados

numericamente conforme a distribuição a seguir: Equações (1), Probabilidades (2),

Funções (3), Logaritmos (4), Trigonometria (5), Geometria Analítica (6) e Análise

Combinatória (7). Os alunos eram submetidos às questões de acordo com os tópicos

através de sorteio, sabe-se que havia N urnas e dentro das mesmas estavam as M bo-

las numeradas de 1 a 7 conforme representadas anteriormente.

O processo pode ser descrito com detalhes da seguinte maneira: Inicialmente uma

urna é escolhida aleatoriamente, uma bola numerada de 1 a 7 é escolhida ao acaso

51

4 Cadeias de Markov Ocultas

observando-se seu respectivo número e por sua vez, o número se torna a observação

do processo. Recoloca-se a bola na urna de origem, e então, uma nova urna é esco-

lhida de forma aleatória. Este processo é realizado (repetido) muitas vezes, gerando

uma sequência de observações constituídas pelos números das bolas.

É possível modelar esse processo por HM M , pois há duas formações de um processo

estocático: o processo observável “número de bolas” e o processo não observável “esco-

lha aleatória da urna”. Os elementos que constituem um HMM em relação ao referido

exemplo são:

1. N representa o número de estados do modelo, que neste caso são representados

pelas urnas;

2. S = {S1, S2, . . . , SN } representa o conjunto dos estados individuais do modelo.
Neste exemplo, seria cada urna, como por exemplo S1 seria a primeira urna e S4
seria a quarta urna;

3. qt representa o estado no tempo t . Neste exemplo, podemos dizer que q2 = S3

signiﬁca que a segunda urna escolhida aleatoriamente foi a terceira urna;

4. M representa o número de observações distintas por estado;

5. V = {v1, v2, . . . , vM } representa o conjunto de observações individuais, neste

exemplo seria o conjunto de bolas de uma urna;

6. B = {bj(k)} representa a distribuição de probabilidade da observação no estado

Supondo que dentre N urnas, a escolhida foi a urna três na primeira escolha e

dentro dela haja duas bolas (1), uma bola (2), duas bolas (4) e uma bola (6),

a representação da distribuição de probabilidades das observações neste estado

são:

b3(1) = P(v1em t = 1|q1 = S3) =

2
6
b3(2) = P(v2em t = 1|q1 = S3) =

b3(4) = P(v3em t = 1|q1 = S3) =

2
6
b3(6) = P(v4em t = 1|q1 = S3) =

1
3

1
3

=

1
6

=

1
6

7. π = {πi} representa a distribuição inicial dos estados.

No caso deste exemplo, a probabilidade de escolher aleatoriamente uma urna é con-

siderada igual a todas. Logo:

πi =

1
N

para todo i e j

52

5 Atividades para salas de aulas

As questões de aprendizagem a seguir visam dinamizar em sala de aula os conteú-

dos até aqui abordados. O público alvo são alunos do ensino médio, e em especial

aqueles que estão no término do processo de aprendizagem sobre probabilidades com

conhecimentos prévios em operações com matrizes.

Para tais atividades, é necessário a utilização de um software capaz de facilitar as re-

soluções de potências e multiplicações de matrizes, ﬁcando a escolha ao encargo do

professor, respeitando disponibilidades ao mesmo. Utilizamos e recomendamos a uti-

lização do Geogebra.

5.1 Geogebra

Geogebra é um aplicativo matemático composto por conceitos, propriedades geo-

métricas e algébricas. Possui distribuição livre, o que possibilita maior acesso e pos-

sibilidades para utilização na aprendizagem de muitos conceitos matemáticos. Neste

trabalho, o Geogebra desempenha importante papel como ferramenta de cálculo em

relação às multiplicações e potências de matrizes.

Dentre tantas funções contidas neste aplicativo, abordaremos através de simples exem-

plos, as confecções , o produto de duas matrizes e duas potências de matrizes com o

propósito de servir como referências às demais situações de cálculos das probabilida-

des de transições das Cadeias de Markov.

53

5 Atividades para salas de aulas

Figura 5.2: Janela principal do Geogebra

Figura 5.1: Divisões dos comandos e áreas de trabalho no Geogebra

Exemplo 5.1. Para construir uma matriz M de ordem 3, na qual os elementos das

linhas serão 1,2 e 3; 4, 5 e 6; 7, 8 e 9 respectivamente, devemos realizar:

• Na área campo de entrada, digiar: M = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}

Figura 5.3: Confecção da Matriz M no Geogebra

54

5.1 Geogebra

Para construirmos uma matriz N de ordem 1 X 3 , composta pelos elementos 3, 5 e

5, devemos realizar:

• Na área campo de entrada, digiar: N = {{3, 5, 5}, }

Figura 5.4: Confecção da Matriz N no Geogebra

Exemplo 5.2. Para obtermos o produto de tais matrizes, M e N , devemos utilizar uma

letra como representação do produto e o comando de multiplicação “*” (asterisco), da

seguinte forma:

• Na área campo de entrada, digitar: P = N ∗M

Figura 5.5: Produto de matrizes M e N

55

5 Atividades para salas de aulas

Exemplo 5.3. O comando “^” é utilizado na obtenção de potências, neste caso, a

matriz M elevada ao quadrado e ao cubo respectivamente, são obtidas da seguinte

forma

• Na área de entrada, digitar Q = M^2 para elevá-la ao quadrado e R = M^3

para elevá-la ao cubo.

Figura 5.6: Quadrado da Matriz M

Figura 5.7: Cubo da Matriz M

56

5.2 Atividade 1

Para as seguintes atividades serem aplicadas em salas de aula, consideramos três

itens de grande importância:

Objetivo

Motivar as operações matriciais utilizando Cadeias de Markov. Dentre tais operações,

destaca-se produto e potência de matrizes.

Público-alvo

Alunos do ensino médio, salvo exceções. Em especial, aqueles que estejam no término

do processo de aprendizagem sobre probabilidades com conhecimentos prévios em

operações matriciais.

Recurso necessário

Utilização de um software, neste caso, o Geogebra.

5.2 Atividade 1

Um biólogo analisou o comportamento de um sapo em relação à permanência do

mesmo em dois locais distintos , água e terra. Os locais são representadas por 1 e 2

respectivamente. Através de uma série de observações, foi registrado que a probabi-

lidade de permanência no local 1 é de 0,8 e no local 2 é de 0,4. Ocorre também as

probabilidades de transições entre os locais , sendo que do local 1 para o local 2 é de

0,2 e do local 2 para o local 1 é de 0,6.

Conforme o enunciado , determine:

1. O vetor de estado inicial, levando em consideração que a observação foi iniciada

no local 1.

2. A matriz de transição P .

3. O diagrama de transição entre os locais.

4. Qual o vetor de probabilidade no 10o passo começando no local 1? E começando

no local 2?

Soluções 1.

1. E = {1, 0}

2. P =

(cid:35)

(cid:34)

P11 P12
P21 P22

⇒ P =

(cid:34)

0, 8 0, 2

(cid:35)

0, 6 0, 4

57

5 Atividades para salas de aulas

Figura 5.8: Diagrama de transição entre os estados do problema 1

3.

4. Estado1 : V 10 = [0,75 0,25] Estado2 : V 10 = [0,75 0,25]

5.3 Atividade 2

Admitindo que um jogador tenha inicialmente R$ 1,00 e, com probabilidade p > 0,

ele ganhe R$ 1,00 e, com probabilidade 1 − p, perca R$ 1,00. O mesmo participa de

apostas, onde a regra do jogo é terminar quando acumular R$3,00 ou perder tudo.

Baseado no enunciado , determine:

1. A representação do espaço de estados E em relação à quantia de dinheiro.

2. A matriz P de transição de estados.

3. Observando a matriz de transição acima, quais estados podemos classiﬁcá-los

como absorventes? Por quê?

4. Construa um diagrama de transição de estados ao referido enunciado.

Soluções 2.

1. E = {0, 1, 2, 3}


2. P =







P00 P01 P02 P03
P10 P11 P12 P13
P20 P21 P22 P23
P30 P31 P32 P33



1

1 − p









⇒ P =







0

0

0 0

p 0









0

0

1 − p 0 p

0

0 1

3. Estado (0) : P00 e Estado (3): P33.

Quando se entra nestes estados, nunca mais os deixam. Os mesmos representam

as duas situações do término do jogo.

Figura 5.9: Diagrama de transição entre os estados do problema 2

4.

58

5.4 Atividade 3

5.4 Atividade 3

Numa cidade, um agente de trânsito é responsável pelo controle e ﬂuidez do tráfego

em oito cruzamentos. Sabe-se que seu tempo de permanência em cada cruzamento é

de 1 hora, onde o mesmo pode mudar para outro cruzamento adjacente ou permane-

cer no mesmo. Por questões logísticas à ﬁscalização, seu local de controle a cada hora

é realizada de maneira aleatória, ocorrendo por exemplo, caso ele esteja de acordo

com a ﬁgura 5.3 no cruzamento 4, o próximo cruzamento pode ser 1, 3, 5 e 7, e em

caso de permanência, o 4.

Realizada sua jornada de trabalho, no dia seguinte, a mesma será iniciada no cruza-

mento em que parou no dia anterior

Figura 5.10: Agente de trânsito

Baseando-se no enunciado, determine:

1. O vetor estado inicial.

2. Um esboço do diagrama de transição em relação aos dados.

3. A matriz de transição P .

4. Nesta situação, podemos dizer que existe algum estado absorvente? Além desse,

quais outras classiﬁcações de estados ocorrem? Justiﬁque.

5. Utilizando recurso computacional como ferramenta de aprendizagem, obtenha
os cinco primeiros vetores de estado , e depois os do 20o ao 22o vetores . Faça
uma análise do comportamento dos mesmos em relação ao agente de trânsito

iniciando no cruzamento 4.

Soluções 3.

59

5 Atividades para salas de aulas

1. Como o agente de trânsito inicia no cruzamento 4, o vetor deve ser:

V 0 = [00010000]

Figura 5.11: Diagrama de transição de estados do agente de trânsito

2.

3. P =



















1
3
1
3
0
1
5
0

0

0

0

1
3
1
3
0

0
1
4
0

0

0

0

0
1
3
1
5
0
1
3
0

0

1
3
0
1
3
1
5
1
4
0
1
4
0

0
1
3
0
1
5
1
4
0

0
1
3

0

0
1
3
0

0
1
3
1
4
0

0

0

0
1
5
0
1
3
1
4
1
3



















0

0

0

0
1
4
0
1
4
1
3

4. Não ocorre estado absorvente. Outras classiﬁcações de estados que ocorrem são

as seguintes:

60

5.4 Atividade 3

• Estado recorrente: uma vez que se entra neste estado, um eventual retorno

é assegurado.

• Estado ergódico: uma vez que se entra neste estado, um retorno ao estado

é assegurado dentro de um número ﬁnito de passos, porém o estado não é

periódico e pode voltar antes de qualquer passo n.

n

0

1

2

3

4

5

X [1]
n
0

0,2

X [2]
n
0

0

X [3]
n
0

0,2

X [4]
n
1

0,2

X [5]
n
0

0,2

X [6]
n
0

0

X [7]
n
0

0,2

0,106 0,116 0,106 0,273

0,09

0,116

0,09

X [8]
n
0

0

0,1

0,109 0,109 0,109 0,182 0,132 0,109 0,139 0,104

0,108 0,108 0,108 0,179 0,141 0,107 0,141 0,107

0,107 0,107 0,108 0,179 0,143 0,109 0,143 0,107

20 0,107 0,107 0,107 0,179 0,143 0,107 0,143 0,107

21 0,107 0,107 0,107 0,179 0,143 0,107 0,143 0,107

22 0,107 0,107 0,107 0,179 0,143 0,107 0,143 0,107

Tabela 5.1: Vetores de estados do agente de trânsito

5.

Analisando os vetores de estados a partir de n ≥ 20 , observa-se a convergência a

um vetor de probabilidade. Daí podemos dizer que a probabilidade de estar no estado

4 é 17,9%, nos estados 1, 2, 3, 6 e 8 é de 10,7% e nos estados 5 e 7 é de 14,3%.

61

Índice

Absorvente, 34

Alcançável, 32

Cadeia de Markov, 25

complementar, 6

Comunicante, 32

conjuntos, 3

Diagrama de Transição de Estados, 26

espaço amostral, 10

evento, 10

interseção, 5

matriz de transição, 29

Processo Markoviano, 25

Recorrente, 33

Transiente, 33

união, 5

unitário, 4

universo, 4

63

Bibliograﬁa

1 HAGGSTROM, O. Finite Markov chains and algorithmic applications.

[sineloco]: Cambridge University Press, 2002. volume 52.

2 MEYER, P. L. Probabilidade: aplicaçõesà estatística. [sineloco]: Livro Técnico,

1970.

3 MORETTIN, P. A.; BUSSAB, W. O. Estatística básica. [sineloco]: Editora Saraiva,

2000.

4 RAMAGE, D. Hidden Markov models fundamentals. [sinelocosinenomine],

2007.

5 RIZZATO, B. Anéis de crescimento de árvores podem prever o futuro sobre as

próximas mudanças climáticas. 2016. URL:

<http://www.jornalciencia.com/aneis-de-crescimento-de-arvores-podem-

prever-o-futuro-sobre-as-proximas-mudancas-climaticas/>. Acedido em:

9 de ago. de 2017. Ver página 43.

6 STAMP, M. A revealing introduction to hidden Markov models.

[sinelocosinenomine], 2004.

7 STEINBRUCH, A.; WINTERLE, P. Introdução à álgebra linear. [sineloco]:

McGraw-Hill Medical, 1990.

65


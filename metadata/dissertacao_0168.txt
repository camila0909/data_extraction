Cleber Helio Garcia

SISTEMAS DE EQUAÇÕES LINEARES E SUAS APLICAÇÕES

Dissertação submetida ao Programa de Mestrado Proﬁssional
de Matemática em Rede Nacional - PROFMAT da Universi-
dade Federal de Santa Catarina como requisito parcial para a
obtenção do Grau de Mestre em Matemática. Com área de
concentração no Ensino de Matemática.
Orientador: Prof. Dr. Vinícius Viana Luiz Albani

Florianópolis

2020

 através do Programa de Geração Automática da Biblioteca Universitária da UFSC.

Ficha de identificação da obra elaborada pelo autor,

Garcia, Cleber Helio
   SISTEMAS DE EQUAÇÕES LINEARES E SUAS APLICAÇÕES / Cleber
Helio Garcia ; orientador, Vinícius Viana Luiz Albani, 2020.
   159 p.

   Dissertação (mestrado profissional) - Universidade
Federal de Santa Catarina, Centro de Ciências Físicas e
Matemáticas, Programa de Pós-Graduação em Matemática,
Florianópolis, 2020.

   Inclui referências. 

   1. Matemática. 2. Sistema lineares. 3. Matrizes. 4.
Determinantes. 5. Vetores. I. Albani, Vinícius Viana Luiz.
II. Universidade Federal de Santa Catarina. Programa de Pós
Graduação em Matemática. III. Título.

Cleber Helio Garcia

SISTEMAS DE EQUAÇÕES LINEARES E SUAS APLICAÇÕES

O presente trabalho em nível de mestrado foi avaliado e aprovado por banca exa-

minadora composta pelos seguintes membros:

Profa. Dra. Maria Inez Cardoso Gonçalves
UFSC

Prof. Dr. Eduardo Tengan
UFSC

Prof. Dr. Wagner Barbosa Muniz
UFSC

Certiﬁcamos que esta é a versão original e ﬁnal do trabalho de conclusão que foi
julgado adequado para obtenção do título de mestre em Matemática.

Profa. Dra. Maria Inez Cardoso Gonçalves
Coordenadora do Programa

Prof. Dr. Vinícius Viana Luiz Albani
Orientador

Florianópolis, 7 de dezembro 2020.

Este trabalho é dedicado aos meus queridos pais e a todos aqueles
que me apoiaram ao longo dos dois últimos anos. Muito obrigado!

AGRADECIMENTOS

Ao meu orientador, professor Dr. Vinícius Viana Luiz Albani, pela paciência e

contribuição na elaboração deste trabalho.

Aos professores da banca examinadora pelas contribuições.
Ao colega, professor Me. Adilson Pires, pelas sugestões e revisão ortográﬁca.
Aos colegas de trabalho pela compreensão na hora de organizar os horários das

aulas.

A minha família pelo apoio.
À UFSC e ao PROFMAT pela oportunidade de cursar um mestrado.
À CAPES pelo apoio ﬁnanceiro.

Comigo tudo se transforma em Matemática.

(René Descartes)

RESUMO

Esta dissertação aborda sistemas lineares e temas relacionados à busca de soluções para
estes. Buscam-se meios de abordar os temas matrizes e determinantes de forma que o
aluno consiga uma melhor compreensão sobre esses. Inicia-se buscando a solução de um
sistema linear e, a partir deste ponto, desenvolve-se a teoria a respeito de matrizes, veto-
res e determinantes. Os assuntos vão se desenvolvendo à medida que vamos construindo
teoremas e deﬁnições que nos permitam chegar a algumas conclusões acerca do problema
inicial e resolver o sistema linear; mostrando-se, assim, que há ligação entre os temas,
como também almejando um “aprender” mais signiﬁcativo. Também farão parte do es-
copo deste trabalho, aplicações de matrizes em computação gráﬁca e em imagens. Ainda
veremos como os sistemas lineares podem ser utilizados no cálculo de calorias, proteínas,
carboidratos e gorduras em uma dieta. Teremos uma abordagem sobre sistemas lineares
na economia e como seu estudo rendeu a Wassily Leontief um Prêmio Nobel de Economia
em 1973. Por ﬁm, discutiremos a possibilidade de se estabelecer uma ordem cronológica
dos assuntos no Ensino Médio.
Palavras-chave: Sistemas lineares. Matrizes. Determinantes. Espaços Vetoriais.

ABSTRACT

This dissertation is concerned with the study of matrices and methods of solutions to linear
systems applied to real-world problems. It proposes an alternative approach to teach such
abstract subjects in high school, from a contextualized perspective. It starts by asking
how to solve linear systems and, under this viewpoint, matrices, vectors determinants and
other related subjects are introduced. The theory is developed as theorems and deﬁnitions
are presented in connection with the original problem of solving linear systems. The use
of matrices and linear systems in diﬀerent applied areas, such as computer graphics and
image treatment are also presented. We also present how linear systems are useful to set
appropriately a diet by evaluating the number of calories and the number of proteins,
carbohydrates, and fats. Another application of the use of linear systems is in economics,
based on the study of Wassily Leontief, who won the Nobel Prize in Economics in 1973.
We end this work by discussing a chronological order of the subjects considered so far
should be presented in high school.
Keywords: Linear systems. Matrices. Determinants. Vector Spaces.

LISTA DE FIGURAS

Figura 1 Posição relativa entre retas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

Figura 2 Representação geométrica do sistema de equações. . . . . . . . . . . . . . . . . . . . . . . . 27

Figura 3 Representação vetorial do sistema de equações (2.5). . . . . . . . . . . . . . . . . . . . . . 28

Figura 4

Interseção de três planos pode ser um ponto A. . . . . . . . . . . . . . . . . . . . . . . . . . . 29

Figura 5

Interseção de três planos pode ser uma reta t. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

Figura 6

Interseção de três planos pode ser um plano. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

Figura 7 Pode não acontecer a interseção dos três planos. . . . . . . . . . . . . . . . . . . . . . . . . . 30

Figura 8 Representação geométrica do sistema (2.6). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

Figura 9 Representação vetorial do sistema (2.7).. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

Figura 10 Representação de ~v.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68

Figura 11 O vetor ~b pertence ao plano formado pelos vetores (1, 5, 3)T e (2, 3, 4)T .

. 71

Figura 12 O vetor ~b não pertence ao plano formado pelos vetores (1, 5, 3)T e (2, 3, 4)T . 71

Figura 13 O vetor (1, 2, 7)T não pertence ao espaço coluna gerado pelos vetores

1, 0)T e (1, 3, 0)T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

(2,

−

Figura 14 Vetores linearmente independentes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87

Figura 15 O R3 formado por duas bases diferentes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

Figura 16 Triângulo representado no plano cartesiano. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116

Figura 17 Paralelogramo dividido em dois triângulos congruentes. . . . . . . . . . . . . . . . . . . 118

Figura 18 Modelo matemático de um carro . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

Figura 19 Representação gráﬁca do L. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

Figura 20 Representação gráﬁca do L inclinado. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132

Figura 21 Comparação entre as três formas do L. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132

Figura 22 Imagem do Gato Félix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134

Figura 23 Imagem do Gato Félix com as cores representadas por 0 e 1 . . . . . . . . . . . . . . 135

Figura 24 Três matrizes vão representar as três imagens.. . . . . . . . . . . . . . . . . . . . . . . . . . . . 135

Figura 25 Imagem formada pela composição de três matrizes RGB. . . . . . . . . . . . . . . . . . 136

Figura 26 Sugestão de ensino de sistemas lineares. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137

Figura 27 Informações nutricionais de feijões-pretos e arroz integral . . . . . . . . . . . . . . . . 138

Figura 28 Representação gráﬁca do L. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142

Figura 29 Representação gráﬁca do L inclinado. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142

Figura 30 A letra L após sofrer uma inclinação e ampliação. . . . . . . . . . . . . . . . . . . . . . . . . 143

Figura 31 A letra T representada por alguns pontos. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144

Figura 32 A letra T representada com a ou e alterados.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

Figura 33 A letra T representada com b ou d alterados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

Figura 34 A letra T representada com c ou f alterados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146

Figura 35 A letra T representada com várias alterações. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146

Figura 36 Paralelogramo P = OACB de altura h. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157

Figura 37 Volume do paralelepípedo. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158

LISTA DE TABELAS

Tabela 1 Uma economia simples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

Tabela 2 Quantidade (gramas) fornecidas por 100g de ingredientes. . . . . . . . . . . . . . . . . 126

Tabela 3

Informação nutricional. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128

Tabela 4 Primeira tabela da multiplicação de matrizes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144

Tabela 5 Primeira tabela da multiplicação de matrizes com valores preenchidos. . . . 144

Tabela 6 Segunda tabela da multiplicação de matrizes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144

Tabela 7 Resultado da multiplicação de A

B. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

×

SUMÁRIO

1 INTRODUÇÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2 EQUAÇÕES LINEARES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

2.1 RESOLVENDO EQUAÇÕES LINEARES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 GEOMETRIA DAS EQUAÇÕES LINEARES . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 ELIMINAÇÃO DE GAUSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4 NOTAÇÃO MATRICIAL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4.1 Multiplicação de uma Matriz e um Vetor . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5 MATRIZES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.1 Matriz Identidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.2 Adição de Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.3 Multiplicação de Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.4 Transformação Elementar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.5 Matriz Elementar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.6 Matriz Transposta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.7 Matriz Inversa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5.8 Matriz Simétrica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.6 RETORNANDO À NOTAÇÃO MATRICIAL . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.7 UTILIZANDO A MATRIZ INVERSA NA RESOLUÇÃO DE SISTEMAS DE

25

26

32

37

38

40

40

41

43

47

48

49

50

52

55

EQUAÇÕES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

61

3 ESPAÇOS VETORIAIS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67

3.1 VETORES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1.1 Espaço-coluna de A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1.2 Espaço Nulo de A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2 RESOLUÇÃO DE AX = 0 E AX = B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3 FORMA ESCALONADA U E FORMA REDUZIDA R . . . . . . . . . . . . . . . . . . . .

3.4 VARIÁVEIS PIVÔS E VARIÁVEIS LIVRES . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.1 Resolução de A~x = ~b, U ~x = ~c e R~x = ~d . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 INDEPENDÊNCIA LINEAR, BASE E DIMENSÃO . . . . . . . . . . . . . . . . . . . . . . .

3.5.1 Base de um Espaço Vetorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.5.2 Dimensão de um Espaço Vetorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

67

70

73

74

76

77

79

82

89

89

4 DETERMINANTES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

4.1 CONCEITO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.2 PROPRIEDADES DOS DETERMINANTES . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

94

95

4.3 MÉTODOS PARA CALCULAR O VALOR DO DETERMINANTE . . . . . . . . . 105

4.3.1 Algumas Aplicações . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114

4.4 REGRA DE CRAMER . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

5 APLICAÇÕES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

5.1 SISTEMAS LINEARES NA ECONOMIA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

5.2 SISTEMAS LINEARES E NUTRIÇÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

5.3 COMPUTAÇÃO GRÁFICA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

5.3.1 Aplicações à Computação Gráﬁca . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

5.3.2 Coordenadas Homogêneas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133

5.4 MATRIZES E IMAGENS DIGITAIS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134

6 SISTEMA DE EQUAÇÕES LINEARES E O ENSINO MÉDIO . . . . . . . 137

6.1 ENSINO MÉDIO E UMA ABORDAGEM SOBRE O TEMA SISTEMAS LI-

NEARES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138

6.2 SEQUÊNCIA DIDÁTICA E O ENSINO DE MULTIPLICAÇÃO DE MATRIZES140

7 CONCLUSÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147

REFERÊNCIAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

ANEXO A -- Corpos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153

ANEXO B -- Produto Vetorial e Produto Misto . . . . . . . . . . . . . . . . . . . . . . . . 157

21

1 INTRODUÇÃO

Quando introduzimos o tema, números reais, para os alunos, apresentamos o exem-
plo da diagonal do quadrado de lado 1. Essa diagonal, que é igual √2, é um número irra-

cional e portanto, um número real. Mas, quando vamos comentar a respeito de matrizes

e determinantes, qual justiﬁcativa podemos dar para o surgimento desse tema? E qual a

sua importância atual?

As matrizes surgem a partir do estudo sobre sistemas lineares, conforme citado

abaixo:

“Como surgiram as matrizes

As matrizes teriam surgido com a escola inglesa Trinity College, em

um artigo do matemático Arthur Cayley (1821-1895), datado de 1858. Vale

lembrar, no entanto, que, bem antes, no século III a.C., os chineses já de-

senvolviam um processo de resolução de sistemas lineares em que aparecida a

ideia das matrizes”. (IEZZI, 2019, p. 67).

Essa dissertação será focada no estudo de sistemas lineares e a partir desse tema

será estudado: matrizes, vetores e determinantes.

Inciam-se os capítulos iniciais buscando a solução de um sistema linear e em se-

guida, surge um desses temas, como matrizes por exemplo. Em cada capítulo construímos
as demonstrações de forma que podem ser adaptadas tanto para o R2, como que para o
R3. Mas, é importante, sempre que possível, mostrar algumas demonstrações no Rn, uma
vez que os temas não limitam-se ao R3.

No capítulo 2, começaremos com uma introdução sobre sistemas lineares, o método

de eliminação de Gauss e matrizes. Sugerimos a seguinte ordem de apresentação de

conteúdos no Ensino Médio:

1. Equações Lineares: Revisando o Ensino Fundamental;

2. Geometria das Equações;

3. Eliminação de Gauss;

4. Notação Matricial;

5. Matrizes:

(a) Deﬁnição;

22

(b) Matriz Identidade;

(c) Matriz Elementar;

(d) Matriz Transposta;

(e) Matriz Inversa;

(f) Matriz Simétrica;

(g) Adição de Matrizes;

(h) Multiplicação de Matrizes;

(i) Forma Matricial: A~x por linhas e A~x por colunas;

(j) Utilizando a Matriz Inversa na resolução de sistemas de equações.

No capítulo 3, falaremos sobre vetores. Mesmo não sendo um tema pertencendo a

grade de conteúdos de matemática do Ensino Médio de Santa Catarina, acreditamos que

sua importância exige pelo menos uma breve abordagem. Podemos citar Peter D. Lax,

em sua obra Linear algebra and its applications:

“Concluo com um apelo para incluir os aspectos mais simples da álgebra linear

no Ensino Médio: vetores com dois e três componentes, o produto escalar, o

produto vetorial, a descrição das rotações por matrizes e as aplicações à geome-

tria. Essa modernização do currículo do Ensino Médio está muito atrasada”.

(LAX, 2007, P.8).

É de extrema importância atualizarmos o currículo de matemática do Ensino Mé-

dio.

A sugestão para apresentarmos o tema é:

6. Vetores:

(a) Deﬁnição;

(b) Soma;

(c) Multiplicação por Escalar;

(d) Espaço-coluna;

(e) Espaço Nulo;

(f) Independência Linear;

(g) Teorema 12.

No capítulo 4, novamente, buscamos a solução de um sistema linear, de duas

equações com duas incógnitas e o tema determinante surge naturalmente. Podemos falar

de determinantes mais focados em suas propriedades e não apenas no uso de regras e

fórmulas, para o cálculo de seu valor. Podemos trabalhar a ideia do desenvolvimento de

Laplace antes de fornecer a fórmula, por exemplo. Fazendo com que o aluno tenha uma

23

compreensão melhor do que está fazendo.

A nossa sugestão para os conteúdos é:

7. Determinantes:

(a) Propriedades;

(b) Formas para calcular o determinante de uma matriz;

(c) Regra de Cramer.

No capítulo 5, buscamos responder as perguntas: Onde vou usar isso? Onde

usa-se esse conteúdo? Esse capítulo vai apresentar aplicações sobre sistemas lineares e

multiplicação de matrizes. Temos, por exemplo, Wassily Leontief, professor de Harvard,

que ganhou o Prêmio Nobel de Economia em 1973. Ele dividiu em 500 setores a economia

americana e buscou, com o auxílio de sistemas lineares, compreender como comportava-se

a economia americana. Segundo, Lay: “O modelo de Entrada/Saída de Leontief é a base

de modelos mais elaborados usados em muitas partes do mundo”. (Lay, 2007, p. 137).

Nesse capítulo, citamos também o uso de sistemas lineares na nutrição, como por

exemplo, a dieta de Cambridge. Finalizamos o capítulo, falando sobre o uso de matrizes

na computação gráﬁca.

No capítulo 6, voltamos a falar sobre como esses temas podem ser apresentados no

Ensino Médio e apresentamos duas sequências didáticas sobre multiplicação de matrizes

e computação gráﬁca.

Finalizando, sabemos que ainda estamos longe de alcançar o nível de qualidade

que nossa educação merece, para isso, basta olharmos para os indicadores de qualidade

como a Prova Brasil. Devemos repensar como estamos ensinando e estar em constante

mudança e adaptação. Aproveitando o que deu certo, mas não caindo no comodismo de

que como está é o suﬁciente.

24

25

2 EQUAÇÕES LINEARES

Iniciamos este capítulo relembrando os métodos estudados no Ensino Fundamental

para resolver sistemas de equações lineares. Abordaremos o signiﬁcado geométrico das

possíveis soluções encontradas quando resolvemos um sistema linear. Também faremos

um breve comentário sobre a representação de um sistema linear por colunas. Falare-

mos sobre o método de eliminação de Gauss e a representação matricial de sistemas de

equações lineares. Neste ponto, aproveitaremos para inserir o tema matrizes e desenvol-

ver seus conceitos e propriedades. Encerraremos o capítulo comentando sobre o uso do

escalonamento para achar a matriz inversa e seu uso na resolução de sistemas lineares.

2.1 RESOLVENDO EQUAÇÕES LINEARES

Vamos, inicialmente, buscar resolver um sistema de n equações com n incógnitas,

com n = 2: Duas equações

1x + 2y = 3

4x + 5y = 6.

(2.1)

(2.2)

Duas incógnitas: x e y. Os métodos mais utilizados no ensino fundamental são os

de substituição e adição:

Adição: Multiplique equação (2.1) por

4 e some a equação (2.2)

−

4x

(

−

−

Logo,

4

(eq. 2.1) + (eq. 2.2)

·

−
8y) + 4x + 5y =

12 + 6

6.

−

−

3y =

−

y = 2.

Retrossubstituindo y = 2 em (2.1) temos que

1x + 2

·

2 = 3

x = 3

4 =

1.

−

−

26

Substituição: Temos da equação (2.1) que

aplicando em (2.2)

x = 3

2y,

−

(3

4

·

−

2y) + 5y = 6

8y + 5y = 6

12

−

12

3y = 6

−

3y = 6

12 =

6.

−

−

−

Logo, y = 2 que é semelhante ao que já havíamos encontrado. Portanto chegamos ao

mesmo resultado.

Veremos ao longo do texto que existem outras formas de encontrar o valor de x e

y, quando o sistema tiver solução.

Podemos, nesse caso em particular, analisar as equações (2.1) e (2.2) como retas no

plano. Pensando nessas equações como retas, temos três possibilidades: retas intersectam-

se em um ponto (retas concorrentes), não se cruzam (retas paralelas) ou em inﬁnitos

pontos (retas coincidentes).

Figura 1: Posição relativa entre retas.

Fonte: Elaborado pelo autor.

Vejamos como podemos interpretar, geometricamente, um sistema linerar.

2.2 GEOMETRIA DAS EQUAÇÕES LINEARES

Vamos analisar alguns exemplos:

Comecemos, pois, com as equações

4x

−

y = 2

x + y = 3.

(2.3)

(2.4)

Vamos, agora, considerar cada equação como uma “linha”, esse termo será im-

portante quando falarmos de matrizes. Como as equações têm apenas duas variáveis,

podemos representá-las como duas retas no plano, com o objetivo de melhor compreender

o que está acontecendo.

Da equação (2.3) temos:

27

Se x = 0 então y =

2 e para y = 0 achamos x = 1

2 . Assim, podemos construir o

−

primeiro gráﬁco e da equação (2.4) encontramos:

Se x = 0 então y = 3 e para y = 0 achamos x = 3.

Figura 2: Representação geométrica do sistema de equações.

Fonte: Elaborado pelo autor.

O ponto de interseção será x = 1 e y = 2. Podemos chegar neste resultado

sem construir gráﬁcos, mas é interessante conseguir imaginar geometricamente o que está

acontecendo.

Agora vamos olhar para o sistema como se fossem “colunas”, isto é, o sistema

4x

−

y = 2

x + y = 3,

como

Figura 4: Interseção de três planos pode ser um ponto A.

29

Fonte: Elaborado pelo autor.

Figura 5: Interseção de três planos pode ser uma reta t.

Dois planos coincidem e o terceiro os intersecta ao longo de uma reta.

Os três planos são distintos e intersectam-se ao longo de uma reta.
Fonte: Elaborado pelo autor.

30

Figura 6: Interseção de três planos pode ser um plano.

Os três planos são coincidentes.
Fonte: Elaborado pelo autor.

Figura 7: Pode não acontecer a interseção dos três planos.

Dois planos coincidem e o terceiro é paralelo a eles.

Dois planos são paralelos e o terceiro os intersecta segundo retas paralelas.

Os três planos são paralelos dois a dois.

Os três planos se intersectam, dois a dois, segundo retas paralelas.
Fonte: Elaborado pelo autor.

O resultado da interseção será um ponto, uma reta, um plano ou o conjunto vazio.

Vamos agora analisar o seguinte sistema de 3 equações com 3 incógnitas:

31

z = 1

z = 2

(2.6)

2x + y

x + 2y

−

−

3x

−

−

y + 2z = 1.

Resolvendo o sistema por algum dos métodos anteriores, encontraremos:

x = 1, y = 2 e z = 3.

Utilizando a representação por linhas, temos agora as equações representando pla-

nos e a solução do sistema sendo a interseção desses planos.

Figura 8: Representação geométrica do sistema (2.6).

Fonte: Elaborado pelo autor.

É importante ressaltar que caso não soubéssemos o ponto de interseção, não seria

muito prático identiﬁcá-lo no gráﬁco. Vamos agora analisar sua representação por colunas

e veriﬁcar o que podemos concluir.

2

1

3

−





x



·





1

2

1

−









1

1

−

−
2

1

2

1



















+ y



·



+ z



·



= 

.



(2.7)

Agora, temos três vetores gerando um quarto vetor. Os valores de x, y e z conti-

32

nuam os mesmos. E seu gráﬁco será

Figura 9: Representação vetorial do sistema (2.7).

Fonte: Elaborado pelo autor.

Tanto a representação por planos/retas ou vetores nos dão uma ideia de como se
comporta o sistema de equações. Porém, à medida que mudamos de R2 para R3 tanto

resolver os sistemas ou representá-los por meio de gráﬁcos ﬁca mais complexo. Além disso,

nem analisamos os casos nos quais o sistema não tem solução ou tem inﬁnitas soluções.

Devemos encontrar uma forma prática para resolver sistemas com n equações com n

incógnitas com n maior que 2 e 3 e uma alternativa é o chamado método de eliminação

Gaussiana.

2.3 ELIMINAÇÃO DE GAUSS

Para entender o método de eliminação de Gauss. Começaremos, pois, com um

sistema de três equações:

33

2x + 3y + z = 7

x

2x

−

−

y + z = 2

2y

−

2z =

4.

−

Tentaremos encontrar os valores de x, y e z que satisfaçam o sistema . Podemos

começar subtraindo a primeira equação das outras duas.

1o) Subtraímos a primeira equação da segunda multiplicada por 2.

2o) Subtraímos a primeira da segunda.

2x + 3y + z = 7

5y + z =

3

0

−

0

5y

3z =

−

−

−

−

11.

Ignoramos a primeira equação e subtraímos a segunda da terceira.

2x + 3y + z = 7

0

−
0 + 0

5y + z =

4z =

−

3

8.

−

−

Essa sequência de passos é a parte inicial do método de eliminação de Gauss e

apresentaremos no que segue uma representação alternativa e equivalente desse mesmo

processo. Vamos, agora, resolver essa mesma sequência de passos, utilizando a repre-

sentação matricial do método de eliminação de Gauss. Primeiramente, transformamos o

sistema em uma matriz estendida, ou seja, uma matriz com os coeﬁcientes das variáveis

mais os valores do lado direito das igualdades.

2

3

1

2

−

−



1

2





1

1

7

2

.



2

−

4

−





Na segunda linha, vamos subtrair a primeira linha do dobro da segunda e substituir

esse resultado na segunda linha. Vamos representar essa operação por: L2 →
com L2 representando a linha 2, L1 representando a linha 1 e

(seta) indicando que

2L2 −

L1,

aquilo que está à esquerda vai ser substituído pela operação entre linhas ou linha que está

→

à direita.

2

3

1

2

−

−



1

2





1

1

7

2

2

−

4

−







L2→2L2−L1

2

3

∼

5

2

−

−



0

2





1

1

2

−

7

−

−

3



.

4





34

Agora vamos subtrair a primeira linha da terceira e substituir na terceira linha.

2

3



0

2

−

5

2

1

1

2

7

L3→L3−L1

2

3

3



−

4

∼



0

0

−

5

5

1

1

3

7

3



.

−

11




Por último, subtraímos a segunda linha da terceira e colocamos o resultado na













−

−

−

−

−

−

terceira linha.

2

3

1

1

3

−

7

L3→L3−L2

2

3

∼

3



−

−

11





5

−
0



0

0





1

1

4

−

7

3



.

−

−

8





5

5

−

−



0

0





Chegamos com as mesmas operações ao mesmo resultado de quando operamos com

as equações. O fato de não termos as variáveis representadas nesse método, não alterou

o resultado almejado.

Os números 2, -5, -4 são chamados de pivôs. Eles são os primeiros elementos que

aparecem em cada linha e abaixo deles só há zeros. Concluímos o processo de eliminação,

chegamos a um sistema que se assemelha a forma de um triângulo, por isso chamamos de

sistema triangular. Desse novo sistema equivalente, podemos a partir da última equação

(linha), encontrar o valor de z.

−

8

4z =

−
z = 2.

Da segunda equação podemos encontrar o valor de y.

5z + z =

−

5y + 2 =

−

−

−

−

5y =

−
y = 1.

3

3

5

Da primeira equação chegamos ao valor de x.

2x + 3y + z = 7

2x + 3

1 + 2 = 7

·
2x + 5 = 7

2x = 2

x = 1.

O processo que utilizamos para encontrar o valor de x, y e z é chamado de re-

trossubstituição. Poderíamos ter feito o método de eliminação de Gauss de forma mais

reduzida, conforme abaixo:

35

2

3

7

2

3

2

3

1

2

−

−



1

2





1

1

7

2

2

−

4

−



∼







0

0





5

5

−

−

1

1

3

−

3



∼

−

−

11







0

0





5

−
0

1

1

4

−

7

3



.

−

−

8





Esse método vai tornar-se muito mais prático em comparação com o processo

abordado no início, na medida em que aumenta-se a quantidade de variáveis e equações.

A grande diﬁculdade é chegar à forma triangular, principalmente para sistemas

muito grandes, pois o procedimento repete-se, independente do tamanho do sistema. No

ﬁnal, basta fazer a retrossubstituição e encontrar o valor das variáveis. Por deﬁnição, os

pivôs devem ser diferentes de zero, pois faremos divisões com eles.

Então, esse método sempre encontrará a solução? Não, pois pode não haver a

interseção entre as equações (três planos paralelos). Se a interseção for um ponto, isso

nos permitirá chegar ao resultado.

Exemplo 1:

2x + 3y + z = 11

2x + 3y + 4z = 23

4x

−

−

6y + 2z =

6.

−

Utilizando o método de eliminação de Gauss, temos:

2

2



3

3

1

4

4

−

6 2

−

6

−





23







11

L2→L2−L1

2 3 1 11

∼
L3→L3+2L1



0 0 3 12



.

0 0 4 16









Descobrimos que um dos pivôs é igual a zero, não há forma de evitar isso, pois

não temos um pivô na segunda coluna. Conseguimos encontrar o valor de z = 4, mas os

valores de x e y são inﬁnitos. Para cada valor que colocarmos em x, encontraremos um

valor em y que satisfaz o sistema.

2x + 3y + 4 = 11

2x + 3y = 7.

Então, sempre que um dos pivôs for zero, o sistema não terá uma única solução?

36

Vamos analisar o próximo exemplo:

Exemplo 2:

2x + 4y + 3z = 9

2x + 4y + 4z = 10

2x + 5y + 5z = 12.

Aplicando o método de eliminação de Gauss, chegamos a:

2 4 3

9

L2→L2−L1

2 4 3 9



2 4 4 10



2 5 5 12

∼
L3→L3−L1



0 0 1 1



.

0 1 2 3

















Temos que o segundo elemento da segunda linha é igual a zero. Porém, basta

trocar a posição da segunda e terceira linhas.

2 4 3 9

L2→L3

2 4 3 9



0 0 1 1







0 1 2 3





∼
L3→L2



0 1 2 3



.





0 0 1 1





Exemplo 3: E, para um sistema com m equações com n variáveis, o método de Gauss vai

funcionar? A resposta é sim, o problema é que teremos que ir eliminado os coeﬁcientes

da matriz, do sistema listado abaixo, até chegarmos a matriz na forma escalonada.

a11x + . . . + a1n = b1
...
am1x + . . . + amn = bm.

Pelo método de eliminação de Gauss, temos:

a11
a21
...
am1










. . . a1n
. . . a2n
...
...
. . . amn

b1
b2
...
bm








L2→L2− a21
a11

L1





∼

a11

0
...
am1

a12
a21
a11 a12
a22 −
...

. . .

. . . a2n
...
. . .

−

a1n
a21
a11 a1n
...
amn

b1
a21
a11 b1
b2 −
...
bm










.








Repetiremos esse processo na primeira coluna m-1 vezes, no segundo pivô m-2

vezes e assim sucessivamente, até o pivô chegar na última linha, ou encontrarmos as

linhas restantes nulas.

É claro que para valores grandes de m e n ﬁca impraticável resolvermos o sistema

linear manualmente, nesse caso utilizaremos métodos computacionais.

Ao longo do texto abordaremos algumas condições sobre o sistema ter ou não

37

solução.

2.4 NOTAÇÃO MATRICIAL

Podemos ter uma noção sobre a solução de um sistema de equações por meio da

redução em um sistema triangular. Ainda podemos notar que as variáveis permanecem

em suas posições, não mudam de coluna. Portanto, podemos buscar um modo de repre-

sentar esse raciocínio de modo mais reduzido, isto é, representar o mínimo de informações

possíveis.

Utilizaremos a notação matricial para descrever o sistema original e a multiplicação

de matrizes para representar a operação, veremos, mais a frente, essa representação. Agora

vamos, novamente, analisar o sistema:

2u + 3v + w = 7

v + w = 2

u

−

2u

2v

−

−

2w =

4.

−

(2.8)

Continuamos com o caso de 3 equações com 3 incógnitas, mas a ideia pode ser

aplicada para o número de equações diferente do número de incógnitas. Temos a seguinte

notação matricial para os coeﬁcientes:

2

3

1

A = 

1

1

2

−

−

1



.

2

−





2





Temos o coeﬁciente de cada variável em uma coluna. Logo, se somarmos a linha 1

com a linha 2, teremos: u somado u, v somado com v e w somado com w. Nesse exemplo,

temos uma matriz quadrada, pois o número de variáveis é igual ao número de equações.

Podemos ter uma matriz 2 por 3.

B =

2 4 5

"

4 3 1#

.

Nesse exemplo, temos duas equações e três incógnitas. Trata-se de uma matriz retangu-

lar 2 por 3. Quando queremos generalizar, escrevemos uma “matriz m por n”, onde m

38

representa o número de linhas e n o número de colunas.

As matrizes podem ser somadas ou multiplicadas por uma constante, assim como

por vetores. Mas, é necessário na soma, por exemplo, que as duas matrizes tenham o

mesmo número de linhas e colunas, ou seja, o mesmo tamanho.

Exemplo de uma Adição de Matrizes

C + B =

2 4 2

"

1 5 7#

+

1 0

4

1 5

"

1#

−

=

2 + 1 4 + 0 2 + 4

1 + 1 5 + 5 7

"

1#

−

=

3

4

6

"

2 10 6#

.

Na seção 2.5.2 voltaremos a falar sobre adição de matrizes.

Exemplo de uma Multiplicação de uma Matriz por um Escalar

3

C = 3

·

2 4 2

3

2 3

4 3

2

=

·

·

·

=

6 12

6

· "

1 5 7#

3

"

1 3

5 3

7#

"

3 15 21#

.

·
Abordaremos de forma mais aprofundada a multiplicação de matrizes na seção

·

·

2.5.3.

2.4.1 Multiplicação de uma Matriz e um Vetor

Retornando ao sistema de equações (2.8), buscaremos representar o sistema em

uma forma simpliﬁcada. Podemos pensar na forma matricial A~x = ~b. Onde:

2

3

1

u

7

A = 

1

1



,

~x = 

v



e ~b = 

2



,

1

2

−

−

2





2

−





w













−

4





o que nos fornece a representação matricial do sistema

2

3

1

u

7

A~x = 

1

1

1





v



= 

2



= ~b.

−

2

2

·

2

w




Devemos, com essa representação, chegar ao sistema inicial. Podemos pensar em





















−

−

−

4

cada linha da matriz A multiplicando a coluna ~x.

39

2u + 3 v + 1 w = 7

2u + (

−

que é equivalente ao sistema

1u + (

1)v + 1 w = 2

−
2)v + (

2)w =

−

4

−

2u + 3v + 1w = 7

1u

−

v + w = 2

2u

2v

−

−

2w =

4

−

o que nos dá o sistema original.

Aqui, temos o primeiro termo da linha multiplicado pelo primeiro termo da coluna.

Somado com o segundo termo da linha multiplicado pelo segundo termo da coluna. Esse

processo repete-se para os n termos da linha e da coluna. Logo há necessidade de ter a

mesma quantidade de termos em cada linha com os números de termos da coluna.

Quando o sistema A~x = 0 dizemos que ele é homogêneo e quando A~x

= 0 dizemos

que o sistema não é homogêneo. Logo no exemplo

7

2

b = 

e, portanto, o sistema não é homogêneo.

4

−











Esse processo de multiplicar os elementos das linhas pelos elementos das colunas e

somar esses resultados é chamado de produto escalar. Temos da multiplicação da primeira

linha pela coluna, onde u = 1, v = 1 e w = 2:

u



v



=

2 3 1

1



1



= 2

2 3 1

h

·

i

w

h

·

i

2

1 + 3

·

·

1 + 1

·

2 = 7.




que é a primeira equação. Ainda temos que o resultado é um número e não mais um













vetor, logo o produto escalar de dois vetores (linha

coluna) é sempre um único número.

Podemos representar a multiplicação A~x, da matriz A pelo vetor ~x, de duas formas.

×

Representação da multiplicação A~x por linhas

6
40

~x.

Fazemos a multiplicação de cada elemento da linha pelo elemento do vetor coluna

2

3

1

1

2

1

2

−

−



1

2





·

1



−

2







1



= 

1





2





2





1 +3

1

1

1

2

−

−

1 +1

1 +1

1

2

−

·

·

·

·

·

·

·

·

·

2

7

2



= 

2



.

2









−

4





Representação da multiplicação A~x por colunas

Fazemos a multiplicação de cada coluna por um elemento do vetor coluna ~x.

2

3

1

1

2

3

1

7

1





1



= 1



1



+ 1

1



+ 2



1



= 

2



.

1

2

−

−



1

2





·

2

−









2





·





2







·

−

−





2





·





2









4

−





Em um primeiro momento, os métodos parecem parecidos, mas o segundo nos diz
que a coluna ~b é uma combinação das outras três colunas. Sendo mais especíﬁco, uma vez
a coluna 1 mais uma vez a coluna 2 e mais duas vezes a coluna 3.

Todo produto A~x pode ser representado na forma de colunas, como foi mostrado.

Logo A~x é uma combinação das colunas de A e os coeﬁcientes são os elementos de ~x.

É possível resolver um sistema de equações utilizando a forma matricial? A res-

posta é sim, desde que ele tenha solução. Vamos estudar um pouco sobre matrizes para,

então, entender como funciona esse tipo de solução.

2.5 MATRIZES

Uma matriz Am×n (lê-se m por n) é uma tabela formada por m linhas com n

colunas. Quando a matriz for quadrada, iremos representá-la apenas por An. Os elementos

dessa coluna podem ser qualquer elementos de um corpo (Ver anexo 1), mas abordaremos

apenas os elementos do corpo dos números reais. Podemos ainda representar a matriz

A = [aij] onde o i representa a linha e j a coluna a qual o elemento pertence.

2.5.1 Matriz Identidade

Uma matriz é dita "matriz identidade" se os elementos da diagonal principal são

todos iguais a 1 e os demais elementos são iguais a zero. Ou de forma equivalente: aij = 1

41

se i = j e aij = 0 se i

= j.

Exemplo 4:

1 0 0

0 0 1

A = 

0 1 0



e B = 

0 1 0



.





0 0 1









1 0 0





A primeira é uma matriz identidade e a segunda não.

Anteriormente, falamos de forma superﬁcial sobre adição e multiplicação de ma-

trizes por um escalar ou um vetor. Vejamos agora a deﬁnição de adição e multiplicação

de matrizes.

2.5.2 Adição de Matrizes

Seja A =

aij

e B =

bij

. Sejam ainda as duas matrizes de mesma ordem m

Então a soma de C = A + B, será:
h

i

h

i

n.

×

a11
...
am1







. . . a1n
...
...
. . . amn



+ 









b11
...
bm1

. . .
...
. . .

b1n
...
bmn



= 









a11 + b11
...
am1 + bm1

a1n + b1n
...

. . .
...
. . . amn + bmn

,







ou seja,

para todo 1

i

≤

≤

m e para todo 1

j

≤

≤

n.

cij = aij + bij,

Exemplo 5:

4 5 6

"

2 1 3#

+

1

−
4

"

3 2

4 + (

1) 5 + (

3) 6 + 2

−
0

=

"

3#

−
2 + 4

−
1 + 0

3 + 3#

=

3 2 8

"

6 1 6#

.

Veriﬁcaremos, agora, algumas propriedades conhecidas do corpo dos números reais

que mantêm-se na operação de adição de matrizes.

Proposição: Se A, B e C são matrizes de mesma ordem m

n, então:

×

I) A + (B + C) = (A + B) + C (associatividade).

6
42

Demonstração:

A + (B + C) = 





= 





= 





= 





= 





a11
...
am1

. . . a1n
...
...
. . . amn

a11
...
am1

. . . a1n
...
...
. . . amn




a11 + b11 + c11
...
am1 + bm1 + cm1



+



b11
...
bm1

. . .
...
. . .

b1n
...
bmn







+ 




b11 + c11
...
bm1 + cm1

. . .
...
. . .

c11
...
cm1



+ 







b1n + c1n
...
bmn + cmn




. . .
...
. . . amn + bmn + cmn

a1n + b1n + c1n
...



(a11 + b11) + c11
...
(am1 + bm1) + cm1

. . .
...
. . .




(a1n + b1n) + c1n
...
(amn + bmn) + cmn



a11 + b11
...
am1 + bm1

a1n + b1n
...

. . .
...
. . . amn + bmn

c11
...
cm1



+ 












c1n
. . .
...
...
. . . cmn

c1n
. . .
...
...
. . . cmn

!



















= (A + B) + C.

Como temos que dentro da matriz os elementos são números reais, podemos aplicar

todas as propriedades dos reais, inclusive a associatividade.

II) A + B = B + A (comutatividade).

Demonstração:

a11
...
am1

. . . a1n
...
...
. . . amn

b11
...
bm1

. . .
...
. . .

b1n
...
bmn

a11 + b11
...
am1 + bm1

a1n + b1n
...

. . .
...
. . . amn + bmn

A + B = 





= 

b11 + a11
...
bm1 + am1




= B + A.



+ 








. . .
...
. . .

b1n + a1n
...
bmn + amn



= 




b11
...
bm1




. . .
...
. . .



= 









b1n
...
bmn



+ 









a11
...
am1

. . . a1n
...
...
. . . amn













III) A + 0 = A onde 0 é a matriz nula (elemento neutro).

 
43



a11
...
am1

. . . a1n
...
...
. . . amn



+ 

0 . . . 0
...
...
...
0 . . . 0








a1n + 0
...

...

a11 + 0 . . .
...
am1 + 0 . . . +amn + 0





a11
...
am1



= 









. . . a1n
...
...
. . . amn







= A.

Demonstração:

A + 0 = 





= 





IV) A + (

A) = 0.

−
Demonstração:

A + (

−

A) = 





= 





a11
...
am1

. . . a1n
...
...
. . . amn

a11 + (
...
am1 + (

a11)

−

am1)

−

−

a11
...
am1

. . .
...
. . .



+ 









−

−

a1n + (
. . .
...
...
. . . +amn + (

−

a1n
...
amn

−
a1n)









= 

amn)

−









0 . . . 0
...
...
...
0 . . . 0







= 0.

Vejamos agora como comporta-se a multiplicação de matrizes.

2.5.3 Multiplicação de Matrizes

Sejam Am×n e Bn×p duas matrizes, temos que o produto de A

B é:

×

A

×

B = 





= 

a11
...
am1
a11 ·

am1 ·





. . . a1n
...
...
. . . amn





·

b11
...
bn1

. . .
...
. . .

b1p
...
bnp










b11 + . . . + a1n
...
b11 + . . . + amn

bn1

·

bn1

·




a11 ·

. . .
...
. . . am1 ·

b1p + . . . + a1n
...
b1p + . . . + amn

·

bnp

.



bnp

·





Ou de forma equivalente

cij = ai1 ·

b1j + . . . + ain

·

n

bnj =

aikbkj,

k=1
X

44

para todo 1

i

≤

≤

m e para todo 1

j

≤

≤

p.

Exemplo 6:

2 3
4 1# · "

3

1

"

1 2

−
2

3#

=

=

4

"

2

·

·
9

3 + 3

3 + 1

1 2

1 4

1) + 3

1) + 1

(

(

−

−

·

·

·

·

2 2

2 4

·

·

·

·

2 + 3

2 + 1

3

3#

·

·

4

13

.

13

"

2 11#

−

Exemplo 7: Vamos calcular o produto das matrizes A por B, B por A e analisar o que

acontece. Sendo:

A =

1 2

"

3 5#

e

B =

"

−
3

1 2

1#

B =

A

×

1 2
3 5# · "

"

−
3

1 2

1#

e

A =

B

×

"

−
3

1 2

1 2

1# · "

3 5#

1 + 6

2 + 2

=

"

−
3 + 15 6 + 5#

−

=

5

4

"

12 11#

=

1 + 6

−
3 + 3

"

2 + 10

−

6 + 5 #

=

5

8

"

6 11#

.

Com esse exemplo podemos concluir que a multiplicação de matrizes não é comu-

tativa. Vejamos, agora, algumas propriedades que são válidas.

Proposição: Desde que as operações sejam possíveis, temos:

I A(B + C) = AB + AC (distributividade);

II (A + B)C = AC + BC (distributividade);

III (AB)C = A(BC) (associatividade);

IV AI = IA = A (existência da identidade).

45







·
a11
...
am1

a11
...
am1

= 





= 





= 





= 





+ 

I) Demonstração: Sejam Am×n, Bn×p e Cn×p tal que:

A

(B + C)

. . . a1n
...
...
. . . amn

. . . a1n
...
...
. . . amn









b11
...
bn1

. . .
...
. . .

b1p
...
bnp



·  




b11 + c11
...
bn1 + cn1



·

. . .
...
. . .

c1p
. . .
...
...
. . . cnp

!









c11
...
cn1



+ 







b1p + c1p
...
bnp + cnp








a11(b11 + c11) + . . . + a1n(bn1 + cn1)
...
am1(b11 + c11) + . . . + amn(bn1 + cn1)
a11 ·
a11 ·

bm1

b11 + . . . + an1 ·
...
b11 + . . . + amn

c11 + . . . + a1n
...
c11 + . . . + amn

·

bn1

·
cn1

cn1

·

. . .
...
. . . am1 ·
. . .
a11 ·
...
. . . am1 ·

am1 ·
a11 ·

am1 ·








a11(b1p + c1p) + . . . + a1n(bnp + cnp)
...

. . .
...
. . . am1(b1p + c1p) + . . . + amn(bnp + cnp)

bnp

b1p + . . . + a1n
...
b1p + . . . + amn

·

c1p + . . . + a1n
...
c1p + . . . + amn

·













= A

·

B + A

C.

·

bnp

·
cnp

cnp

·

II) Demonstração: Sejam Am×n, Bm×n e Cn×p tal que:

c11
...
cn1

c1p
. . .
...
...
. . . cnp







(A + B)

C

·
. . . a1n
...
...
. . . amn

a11
...
am1

=





+ 

b11
...
bm1

. . .
...
. . .

b1n
...
bmn




a11 + b11
...
am1 + bm1







a1n + b1n
...

. . .
...
. . . amn + bmn

c11
...
cn1





·













! ·







c1p
. . .
...
...
. . . cnp

(a11 + b11)c11 + . . . + (a1n + b1n)cn1
...
(am1 + bm1)c11 + . . . + (am1 + bm1)cn1

. . .
...
. . .

= 





= 











(a11 + b11)c1p + . . . + (a11 + b11)cnp
...
(am1 + bm1)c1p + . . . + (amn + bmn)cnp







 
46

a11 ·

am1 ·
b11 ·

= 





= 

bm1 ·





·

c11 + . . . + a1n
...
c11 + . . . + am1 ·
c11 + . . . + b1n
...
c11 + . . . + bm1 ·

·

cn1

cn1

cn1

cn1

cnp







cnp

·
cnp

a11 ·

. . .
...
. . . am1 ·
. . .
b11 ·
...
. . .

c1p + . . . + a11 ·
...
c1p + . . . + amn
c1p + . . . + b11 ·
...
c1p + . . . + bmn

bm1 ·

= A

·

C + B

C.

·

cnp







·

III) Sejam Am×n, Bn×p e Cp×q. Vamos aplicar a deﬁnição de multiplicação de matrizes

por somatória. Aplicando a deﬁnição sobre C temos

agora sobre AB chegamos a

p

((AB)C)ij =

(AB)ikckj,

k=1
X

p

p

n

(AB)ikckj =

ailblkckj

,

k=1 (cid:16)
X
utilizando as propriedades das somatórias e transformando as somatórias em matrizes,

l=1
X

k=1
X

(cid:17)

chegamos ao resultado almejado.

p

n

n

p

n

ailblkckj

=

ail

blkckj

=

ail(BC)lj = (A(BC))ij.

k=1 (cid:16)
X

l=1
(cid:17)
X
IV) Sejam An×n e In

k=1
X

(cid:16)

l=1
X

(cid:17)

k=1
X





·

. . . a1n
...
...
. . . ann








1 + . . . + a1n
...
1 + . . . + ann

a11
...
an1
a11 ·

I = 

A

·





= 

an1 ·





e

1 . . . 0
...
...
0 . . . 1

1







0 . . . a11 ·
...
0 . . . an1 ·

·

·

0 + . . . + a1n
...
0 + . . . + ann

a11
...
an1

. . . a1n
...
...
. . . ann

1

·



= 

·

1









= A







47



= A.





A = 

I

·





= 

1 . . . 0
...
...
0 . . . 1

1





·

a11
...
an1

. . . a1n
...
...
. . . ann










a11 + . . . + 0
...
an1 + . . . + 0

a1n

ann

·

·




. . . 0
...
. . . 0

1

·

1

·





a11 + . . . + 1
...
an1 + . . . + 1

·

·

a1n

ann

·

·



= 









a11
...
an1

. . . a1n
...
...
. . . ann

Caso a matriz seja Am×n, existirão matrizes identidades à esquerda e à direita.

Porém, elas não serão iguais, uma será In e a outra Im para que seja possível efetuar a

multiplicação.

2.5.4 Transformação Elementar

Deﬁnimos uma transformação elementar sobre uma matriz m por n como uma das

seguintes operações sobre as linhas dessa matriz:

I Trocar duas linhas de posição, ou seja, Li

j

1

≤

≤

m.

Lj e Lj

Li, com 1

i

≤

≤

m e

→

→

II Multiplicar uma linha por um escalar, ou seja, Li

αLi, com 1

i

≤

≤

m e α

R.

∈

→

III Substituir uma linha pela soma desta linha com o múltiplo de outra, ou seja, Li

Li + αLj, com 1

i

≤

≤

m, 1

j

≤

≤

m e α

R.

∈

→

Exemplo 8:

A =

1 2

"

3 4#

e

A′ =

3 4

"

1 2#

.

A matriz A sofreu uma troca de linhas para virar A′, portanto por I ocorreu uma

transformação elementar.

Exemplo 9:

B =

3 1

"

2 0#

e

B′ =

3 1

"

4 0#

.

A segunda linha da matriz B teve seus valores dobrados para tornar-se B′, logo

por II sofre uma transformação elementar.

48

Exemplo 10:

1 0 0

1 0 0

C = 

0 1 0



e

C ′ = 

2 1 0



.





0 0 1









0 0 1





Aqui temos que a segunda linha tornou-se a soma da segunda linha com o dobro

da primeira linha. Portanto, por III é uma transformação elementar.

2.5.5 Matriz Elementar

Uma matriz elementar é uma matriz quadrada obtida a partir da matriz identidade

e através de uma transformação elementar.

Exemplo 11: Temos que e

I2

h

i

é uma matriz elementar. Com

0 1

"

1 0#

e

I2

=

h

i

, onde e : L1 ↔

L2.

Exemplo 12: A matriz e

I3

h

i

é uma matriz elementar. Com

1 0 0

e

I3

= 

2 1 0



h

i

0 0 1









, onde e : L2 →

2L1 + L2.

Quando aplicamos uma transformação elementar em uma matriz, teremos o mesmo

resultado que se multiplicarmos essa matriz por uma matriz elementar gerada pela mesma

transformação elementar.

Exemplo 13: Aplicando a transformação elementar, L2 →

2L2, na matriz A, temos:

A =

2 3

L2→2L2

2

3

"

4 5#

∼

"

8 10#

.

Agora se gerarmos uma matriz elementar com a mesma transformação elementar,

teremos:

1 0

L2→2L2

1 0

"

0 1#

∼

"

0 2#

.

Multiplicando a matriz A por essa matriz elementar chegaremos ao mesmo resul-

tado.

49

1 0
0 2# · "

"

2 3

4 5#

=

2 + 0

2 + 2

1

0

"

·

·

4 1

4 0

·

·

·

·

3 + 0

3 + 2

5

5#

·

·

=

2

3

"

8 10#

.

Exemplo 14: Aplicando, agora, uma transformação elementar, L1 →
matriz 3

3, temos:

×

2L1 −

L2, em uma

2

B = 

4

1

3

1

5



L1→2L1−L2

1

2 5

−









∼

2

1

1

2

−

−



0

1





1

3

−
5

.







Se gerarmos uma matriz elementar com a mesma transformação elementar, teremos:

1 0 0



0 1 0



L1→2L1−L2

0 0 1

∼





1

0

0



2

0





1 0

.



−
0

1





Multiplicando essas matrizes, chegamos a:





−

1

3

1

0

0

1 0

−
0

2



4

1





·







1



2

0





1

2 + 0 + 0 1 + 0 + 0 1 + 0 + 0

2

1

5



= 

4

4 + 0 2

3 + 0 2

5 + 0

0 + 0 + 1 0 + 0

−

−
2 0 + 0 + 5

−

2 5

−











= 

0





1





1

2

−

−

1

3

−
5

.







2.5.6 Matriz Transposta

A matriz transposta de uma matriz A é representada por AT e as linhas de A se
tornam as colunas de AT , o que faz também com que as colunas de A se tornem as linhas
AT . Logo, a 1a linha de A torna-se a 1a coluna de AT , a 2a linha de A torna-se a 2a coluna
de AT e assim sucessivamente. Ou, de forma equivalente, se A = [aij] então AT = [aji].

Exemplo 15:

A =

1 2 3

"

2 1 0#

1 2

e AT = 

2 1



.

3 0









50

2.5.7 Matriz Inversa

A inversa de uma matriz A é uma matriz B, tal que

e

AB = I

BA = I,

onde I é a matriz identidade e se B existir ela é única.

Teorema 2.1 Toda matriz elementar admite inversa.

Demonstração: Temos que uma matriz elementar é a matriz identidade que foi alterada

por uma transformação elementar. Logo, basta fazer a operação inversa a essa matriz

elementar que temos a identidade. Portanto, aplicando essa operação inversa a matriz

identidade temos a inversa da matriz elementar inicial. Ou, de forma semelhante, se E é

a matriz elementar, temos

e(I) = E e se e−1(E) = I então

e−1(e(I)) = I = e−1(E) = e−1(I)E = E−1E

e

e(e−1(I)) = I = e(E−1) = e(I)E−1 = EE−1.

Teorema 2.2 A matriz An não tem duas inversas diferentes.

Demonstração: Suponhamos que BA = I e AC = I. Então como BAC = BAC, temos:

o que nos mostra que C = B.

(BA)C = B(AC)

IC = BI

→

Teorema 2.3 O produto AB de matrizes invertíveis tem sua inversa igual a B−1A−1.

Demonstração: Vamos provar a igualdade utilizando o fato de que AB(AB)−1 = I e
(AB)−1AB = I. Como a inversa é única, basta mostrar que a multiplicação à esquerda e
à direita tem como resultado a identidade.

(AB)(B−1A−1) = ABB−1A−1 = AIA−1 = AA−1 = I.

(B−1A−1)(AB) = B−1A−1AB = B−1IB = B−1B = I.

51

Teorema 2.4 Temos que a inversa de uma matriz n por n existe, se e somente se, a

eliminação produzir n pivôs, ou seja, teremos que ter todos os pivôs diferentes de zero.

Demonstração: Suponhamos que a matriz An tenha n pivôs. Assim, ao fazermos o esca-

lonamento de A, encontramos uma matriz triangular superior, que pode ser reduzida a

matriz identidade (pois tem n pivôs). Para isso, basta dividir cada linha por seu respectivo

pivô e depois utilizar cada pivô para zerar a posição acima dele. Logo, podemos repre-

sentar esse processo com matrizes elementares, E1...EkA = I. Portanto, A é invertível e
sua inversa é E1...Ek = A−1.

Agora, suponhamos que A seja invertível e escalonável. Temos que A = E1...EkB,
onde B é a forma escalonada de A. Além disso, temos que as matrizes elementares são
invertíveis pelo Teorema 2.1 e E−1
1 A = B. Como B é um produto de matrizes
invertíveis, temos que B é invertível pelo Teorema 2.3. Agora, suponhamos que B tenha
uma linha nula. Logo, BB−1
temos uma contradição e logo B não pode ter uma linha nula. Com isso, concluímos que

= In, pois esse produto vai ter uma linha nula. Portanto,

k ...E−1

B tem n pivôs e o que queríamos demonstrar. Pois B é a forma escalonada de A.

Suponhamos que A seja invertível e não escalonável. Assim, ela já está na forma

triangular superior, pois sempre podemos utilizar um pivô para zerar os elementos que
estão abaixo dele. Suponhamos que A tenha uma linha nula. Logo, AA−1
produto vai ter uma linha nula. Portanto, temos uma contradição e logo A não pode ter

= In, pois esse

uma linha nula. Com isso, concluímos que A tem n pivôs e o que queríamos demonstrar.
É importante notar que se A é invertível temos que a única solução de A~x = ~b é
~x = A−1~b. Chegamos a ~x = A−1~b multiplicando a equação A~x = ~b à esquerda dos dois
lados por A−1.

A−1A~x = A−1~b
I~x = A−1~b
~x = A−1~b.

Teorema 2.5 Se A é invertível então ela pode ser escrita como um produto de matrizes

elementares. Ou, de forma equivalente:

A = E1 . . . Ek,

onde Ei, com 1

i

≤

≤

k, são matrizes elementares.

Demonstração: Como A é invertível, ela tem n pivôs, pelo Teorema 2.4. Assim, ao

fazermos o escalonamento de A encontramos uma matriz triangular superior que pode ser

6
6
52

reduzida a matriz identidade, pois tem n pivôs. Para isso, basta dividir cada linha por

seu respectivo pivô e depois utilizar cada pivô unitário para zerar a posição acima dele.

Logo, podemos representar esse processo com matrizes elementares, E1...EkA = I. Como
matrizes elementares são invertíveis pelo Teorema 2.1 temos A = E−1
1 I. Assim,
temos A = E−1

1 que é o que queríamos demonstrar.

k ...E−1

k ...E−1

2.5.8 Matriz Simétrica

Uma matriz é simétrica se ela for igual à sua transposta.

A = AT .

Essa matriz tem que ser quadrada

A =

1 3

"

3 7#

e AT =

1 3

"

3 7#

.

Teorema 2.6 A matriz transposta do produto de duas matrizes é igual ao produto das

transpostas dessas matrizes em ordem inversa.

(AB)T = BT AT .

Demonstração: Sejam Am×n e Bn×p, temos que

AB = 

a11b11 + . . . + a1nbn1
...
am1b11 + . . . + amnbn1




Logo, sua transposta é

. . . a11b1p+ . . . +a1nbnp
...
. . . am1b1p+ . . . +amnbnp

...

.







(AB)T = 





= 





a11b11 + . . . + a1nbn1
...
a11b1p + . . . + a1nbnp

. . . am1b11+ . . . +amnbn1
...
. . . am1b1p+ . . . +amnbnp

...

b11a11 + . . . + bn1a1n
...
b1pa11 + . . . + bnpa1n

. . .
...
. . .

b11am1+ . . . +bn1amn

...

b1pam1+ . . . +bnpamn













b11
...
b1p

. . .
...
. . .

bn1
...
bnp

a11
...
a1n

. . . am1
...
...
. . . amn







·













= 





= BT AT .

Teorema 2.7 A inversa de uma matriz A transposta é igual a transposta da matriz in-

versa de A.

(AT )−1 = (A−1)T .

Demonstração: Vamos utilizar o fato de que a inversa de uma matriz é única.

53

e pelo Teorema 2.6 temos

(AT )−1(AT ) = I

(A−1)T (AT ) = (AA−1)T = (I)T = I.

Exemplo 16: Seja

Temos que

A =

1 2

"

0 1#

e AT =

1 0

"

2 1#

.

B =

A

×

1 2
0 1# · "

1

0

"

2

−
1 #

=

1

0

"

−

2 + 2

1

#

=

1 0

"

0 1#

= I2.

Logo,

Além disso,

Logo,

B = A−1 =

1

0

"

2

−
1 #

e

(A−1)T =

1

0

2 1#

"

−

.

AT

×

C =

1 0
2 1# · "

"

1

0

2 1#

−

=

2

"

1

−

0

2 1#

=

1 0

"

0 1#

= I2.

Portanto, temos que (A−1)T =

C = (AT )−1 =

1

0

2 1#

"

−

.

1

0

2 1#

"

−

= (AT )−1.

1

0

2 3

1 3



A = 

1 0

e AT = 

2 1

1

−
5

.







−

1 5 3





3 3

3









54

Exemplo 17: Seja

Temos que

B

A

×
1

2 3

= 

0

1 3



3
5 −
2
1
5
5

4
5 −
1
5 −
7
1
15 −
15
1
15 )
1
15 )
1
15 )

−
(

−

(

(

·

·

−

1
5



1
15

1

0




(
·

(

·
1



·

−
1

0

·

·
1





= 





1 5 3




·


−


1
5 + 3
1
5 + 3
·
1
5 + 3

·

4
5 + 2
4
5 + 1
·
4
5 + 5

·
−
1 0 0

·

3
5 ) + 2
3
5 ) + 1
·
3
5 ) + 5

−

−
(

·

2
5 ) + 3
2
5 ) + 3
·
2
5 ) + 3

(

(

·

−

−
(

−

7
15 )
7
15 )
7
15 )

·

1

0

·

·
1

−

(

(

·

−

−
(

−

·

1
5 ) + 2
1
5 ) + 1
·
1
5 ) + 5

·

1
5 + 3
1
5 + 3
·
1
5 + 3

·

(

(

·

−

−
(

−

1
15 )
1
15 )
1
15 )







−

·

−

= 

0 1 0



= I3.




Assim,

0 0 1





B = A−1 = 





Além disso,

1
5

3
5 −
1
2
5
5

4
5 −
1
5 −
7
1
15 −
15

1
15

−







e (A−1)T = 





4
5

−

−

1
1
15
5 −
7
2
15
5
1
15

3
5 −
1
1
5 −
5

.







AT

×

1 0

C = 

2 1

1

−
5

3 3

3





4
5

·













−

−

1
1
15
5 −
7
2
15
5
1
15

3
5 −
1
1
5 −
5







1

3
5 )
−
3
5 ) + 5
3
5 ) + 3

·

·

·

(

(

(

−

−

−

1
5 ) 1
1
5 ) 2
1
5 ) 3

1
5 + 0
1
5 + 1
1
5 + 3

·

·

·

·

·

·

(

−
(

−

(

−

1

2
5 )
−
2
5 ) + 5
2
5 ) + 3

1
5 1
1
5 2
1
5 3

·

·

·

·

·

·

(

−
(

−

(

−

1
15 ) + 0
1
15 ) + 1
1
15 ) + 3

1

7
15 −
7
15 + 5
7
15 + 3

·

·

·

·

·

·

(

(

(

−

−

−

1
15 )
1
15 )
1
15 )







1

= 

2

4
5 + 0
4
5 + 1
4
5 + 3

·

·

·

·

·

·

(

−
(

−

(

−

3





1 0 0

= 

0 1 0



= I3.





0 0 1





55

Logo,

Portanto, temos que

C = (AT )−1 = 





4
5

−

−

1
1
15
5 −
7
2
15
5
1
15

3
5 −
1
1
5 −
5

.







(A−1)T = 

4
5

−

1
1
15
5 −
7
2
15
5
1
15

3
5 −
1
1
5 −
5

= (AT )−1.






Que é o que o Teorema 2.7 nos aﬁrma, ou seja, (A−1)T = (AT )−1.





−

2.6 RETORNANDO À NOTAÇÃO MATRICIAL

Vamos agora retornar a forma matricial A~x = ~b. Analisando o sistema

2u + 3v + w = 7

v + w = 2

u

−

2u

2v

−

−

2w =

4,

−

veriﬁcamos que existem matrizes elementares que fazem a forma matricial comporta-se

da mesma forma que a eliminação de Gauss.

1

C = 

0

0

1

0

0



1





1 1

−





1

D = 

0

·







0

1

e

1

0 0

2

3

2

3

1

0

0 0

1 0



1 0 1

−





·







−
0

1 2 0

0 1

·









1

2





1

2

−

−

1

1

4

−







1

1

−

2





7

2

4

−







= 

0

5

−
0

0





7



= 

3



.

−

−





8





0

0









·





1

0

0 0

1 0



1 0 1

−

−
0



·









1

0 0

1 2 0

0 1





·









1

1 1

−





Escrevendo C e D na equação matricial temos C~x = ~d, ou de forma equivalente

2

3

5

−
0



0

0





1

1

4

−

·







y



z



= 

w













7

−

−

3



8





56

que é equivalente à solução que encontramos anteriormente.

2u + 3v + w = 7

0

0

−

−

5v + w =

4w =

0

−

3

8.

−

−

É importante ressaltar, que como não queremos alterar o termo ~x da equação ma-
tricial A~x = ~b, devemos fazer a multiplicação à esquerda dos dois lados da igualdade, pois
a multiplicação de matrizes nem sempre é válido a propriedade comutativa. Ainda te-

mos que as matrizes utilizadas para alterar a equação matricial são matrizes elementares.

Essas matrizes elementares funcionam como etapas no método de eliminação de Gauss.

Porém, sempre haverá matrizes elementares que transformam uma matriz em uma forma

triangular superior? A resposta é não. Uma condição suﬁciente para que uma matriz

quadrada possa ser transformada em uma matriz triangular superior é que ela seja inver-

tível conforme Teorema 2.4. Se multiplicarmos as matrizes elementares da esquerda para

a direita, temos:

1



0

0





0

1

0

0



1 1

−





·







1

0

0 0

1 0



2 0 1

−





·







1

0 0

1 2 0

0 1

−
0







1

0 0

1 2 0

0 1

−
0

·













1

0

0

1

0

0



= 





2

−
1

1

1

−

−





1 1





0

−
0

2 1

−





= 

2

0



= M

que é uma matriz triangular inferior. Logo, podemos representar o sistema como

M A~x = M~b.

Se chamarmos M A = U onde U é uma matriz triangular superior e M~b = ~c, temos
U~x = ~c. Portanto, basta encontrar os valores das componentes do vetor ~x através de

retrossubstituição, mas é sempre possível retornar o sistema ao estado inicial? A resposta é

sim, pois todas as matrizes elementares admitem inversa. Logo, basta fazer a multiplicação

de cada passo por sua inversa . Com isso, chegamos ao sistema original.

M A~x = M~b

E−1
1

E−1
2

·

·

E−1
3

·

E3 ·
E3 ·

E2 ·
E2 ·

E1 ·
E1 ·

A~x = E3 ·
A~x = E−1
1

~b

E1 ·

E2 ·
E−1
2

·

E−1
3

·

E3 ·

E2 ·

E1 ·

·

~b

57

(2.9)

Exemplo 18: Seja o seguinte sistema linear:

A~x = ~b.

1u + 3v + 4w = 2

2u + 5v + 1w = 3

1u

−

3v + 3w = 5.

Podemos representar esse sistema na forma A~x = ~b, com:

1

A = 

2

3

5

4

u

2

1



,

~x = 

v



e

~b = 

3



,

utilizando a matriz estendida da notação matricial, temos:

1

3 3

−









w













5





1



2

1





3

5

4 2

1 3



.

3 3 5

−





Podemos escalonar esse sistema

1



2

1





3

5

1 3



3 3 5

−





4 2

L2→L2−2L1

1

3

∼

L3→L3−6L2

∼

4

7

−
3

4

7

−
41

2

1

−
5

2

1

−
9





1

3

−

−

3

1

−
0



0





1

1



0

0





L3→L3−L1

1

3

∼

1

6

−

−



0

0











.



4

7

1

−

−

2

1

−
3







Vamos, agora, achar as matrizes elementares que funcionam como as etapas no

método de eliminação de Gauss.

A primeira transformação elementar que ﬁzemos foi e1 : L2 →

L2 −

2L1, logo,

vamos aplicar essa transformação na identidade e achar a primeira matriz elementar

1 0 0

1

0 0

E1 = e1I3 = e1 

0 1 0



= 

0 0 1













−
0

2 1 0

0 1

.







58

A segunda transformação elementar foi e2 : L3 →

matriz elementar

L3 −

L1, que nos dá a seguinte

1 0 0

E2 = e2I3 = e2 

0 1 0



= 

1

0

0 0

1 0



.





0 0 1









−

1 0 1





E, por último, temos a terceira transformação elementar que foi e3 : L3 →
isso, chegamos a última matriz elementar que é

L3 −

6L2. Com

1 0 0

1

E3 = e3I3 = e3 

0 1 0



= 

0

0

1

0

0



.





0 0 1





0





6 1

−





Portanto, temos o escalonamento que ﬁzemos sendo representado pela seguinte multipli-

cação de matrizes elementares:

E3E2E1A~x = E3E2E1

~b,

ou de forma equivalente,

1



0

0





0

1

0

0







6 1

−

1

= 

0

·






0

1

0

0



1

0

0 0

1 0



1 0 1

−

1

0 0

2 1 0

0 1

1



2

3

5

4

1



−

1




0 0





3 3

2

u

·



v



w











·




1



·

−
0




0 0




1

·



0

1 0







−

1 0 1





·







−
0

2 1 0

0 1

·









3



.





5








Podemos agora achar a matriz M





−

6 1

0

1

M = 

0

0

1

0

0



1

0

0 0

1 0



1 0 1



·

1

0 0

2 1 0



= 

0 1









1

2

−
11

0

1

0

0



6 1

−





−
0

·














que é uma matriz triangular inferior.









−

−

6 1

0

Assim, podemos reescrever o sistema como

M A~x = M~b,

ou de forma equivalente,

1



2

−
11

0

1

0

0



1



2

3

5

4

1



u



v



= 

·

·

6 1




Ou ainda, fazendo U = M A e ~c = M~b, temos:

















−

−

3 3

1

w









59

1

2

−
11

0

1

0

0



6 1

−





2

·



3



.

5









ou de forma equivalente,

U~x = ~c,

1

3

1

−
0



0

0





4

7

−
41

·







u



v



= 

w













2

1

−
9







que é o resultado que encontramos com o método de eliminação de Gauss.

Exemplo 19: Vamos, agora, encontrar a matriz M −1 que retornar o sistema a sua forma
inicial.

Devemos, inicialmente, encontrar as matrizes E−1

1 , E−1

2

e E−1

3 . Para isso, podemos
1 , E−1

2

utilizar a operação inversa das transformações elementares utilizadas para gerar E−1
e E−1
3 .

Temos que e1 : L2 →

1 devemos somar a linha
2, duas vezes a linha 1, pois inicialmente tiramos duas vezes a linha 1 da linha dois. Logo,
e−1
1

:L2→L2+2L1 que nos dá a matriz

2L1 gerou E1 para termos E−1

L2 −

1 = e−1
E−1

1 I3 = e−1

1 

1 0 0

1 0 0

0 1 0



= 

2 1 0



.

Para E2 tivemos a seguinte transformação elementar e2 : L3 →
somar a linha 3 a linha 1, ou seja, e−1
2

L3 + L1 que nos dá

: L3 →

0 0 1













0 0 1




L3 −

L1. Assim, devemos

2 = e−1
E−1

2 I3 = e−1

2 

1 0 0

1 0 0

0 1 0



= 

0 1 0



.

Para achar E3 tivemos a seguinte transformação elementar e3 : L3 →

L3 −

6L2. Logo,





0 0 1









1 0 1





60

para achar E−1

3 , devemos utilizar e−1

3

: L3 →

L3 + 6L2

3 = e−1
E−1

3 I3 = e−1

3 

1 0 0

1 0 0

0 1 0



= 

0 1 0



.

Como temos

ou ainda,





0 0 1









0 6 1





U~x = ~c,

M A~x = M~b

E−1
1

E−1
2

·

·

E−1
3

·

E3 ·
E3 ·

E2 ·
E2 ·

E1 ·
E1 ·

A~x = E3 ·
A~x = E−1
1

A~x = ~b.

~b

E3 ·

E2 ·
E−1
2

·

E−1
3

·

E3 ·

E2 ·

E1 ·

·

~b

Devemos cuidar com a ordem na multiplicação, pois na multiplicação de matrizes não

vale a comutatividade.

1 0 0

1 0 0

1 0 0

1 0 0

M −1 = E−1

1 E−1

2 E−1

1 = 

2 1 0





0 1 0





0 1 0



= 

2 1 0



.

·

·

0 0 1













1 0 1









0 6 1









1 6 1





No exemplo anterior, chegamos ao seguinte resultado

1

3

4

u



0

0

1

−
0

7



·

−
41




que representa a seguinte equação matricial







v



= 

w













2

1

−
9







U~x = ~c.

Agora, multiplicando à esquerda os dois lados dessa equação, pela matriz M −1,

temos:

1 0 0

1

3



2 1 0







1 6 1





·



0

0





1

−
0

4

7

−
41

·







u

1 0 0



v



= 

2 1 0



w













1 6 1





2

1

−
9







·







61

que nos fornece

1



2

1





3

5

4

1



5 3

−





·

u

2



v



= 

3



.

w













5





Temos, exatamente, a equação (2.9), que era a equação inicialmente abordada no
exemplo anterior. De fato, temos que U = M A e ~c = M~b, como M −1M = I3 temos que

e multiplicando à esquerda por M −1, chegamos ao resultado procurado

M A~x = M~b

M −1M A~x = M −1M~b

A~x = ~b.

2.7 UTILIZANDO A MATRIZ INVERSA NA RESOLUÇÃO DE SISTEMAS DE EQUA-

ÇÕES

Seja o sistema

2u + 3v + w = 7

v + w = 2

u

−

2u

2v

−

−

2w =

4.

−

Vimos que podemos encontrar a solução do sistema se conseguirmos resolver a equação
matricial ~x = A−1~b. O valor de ~b já sabemos, basta encontrar a matriz inversa de A.

Temos que se A−1 existe, ela deve satisfazer a igualdade A

C = I, onde I é a

matriz identidade e C é a inversa de A. De fato, se multiplicarmos a esquerda das duas
igualdades por A−1 temos que

·

A−1AC = A−1I

IC = A−1

e chegamos que a matriz C é a inversa de A, desde que ela seja invertível.

62

Tomemos a matriz A dos coeﬁcientes do sistema.

A = 

1

2

3

1

2

−

−

2





1

1

.



2

−





Vamos buscar um método que permita-nos encontrar a matriz inversa. Iniciemos com

2

3

A

·

C = 

1





2

2

= 

1





2

2

1

2

−

−
3

2

−

−
3

+ 

1

2





1

2

−

−

1

1

2

−
1











2

−
1

1



−

2





c11
c21
c31

c12
c22
c32

c11 0 0
c21 0 0
c31 0 0

0 0 c13
0 0 c23
0 0 c33

·

·

·



















c13
c23
c33







2

3



+ 

1

2









−

1

2

−
1 0 0

0 c12 0
0 c22 0
0 c32 0

1

1

2

−

·





















= 

0 1 0



.









0 0 1





1

1



Logo, temos que cada coluna em C corresponde a uma coluna em I.

1



= 

0



,





0




0

= 

1







0




0

2

3



1

2





2

3

c11
c21
c31




c12
c22
c32







·













1

1

2

−

1

1







2

−

1

1

2

−



·







·




c13
c23
c33







1

2

−

−

1

2

−

−

3

1

2

−

−

2













1





e



1

2




2



1



= 

0



.

(2.12)

Desse modo, já sabemos operar, podemos representá-los em suas formas matriciais

e aplicarmos o método de eliminação de Gauss para deixar a matriz A na forma da

identidade.

(2.10)

(2.11)

63

... 1
... 1
... 0















1

−
1
... 1
1
...
5
... 0

3

1

2

−

−

1

1

2

−

2

1

2








... 1
... 0
... 0








∼

∼

2 3

1

2 3

1

2 3

1

0 5

0 5

1

−
3

2 3 1

0 5 0

0 0 1

2 0 0

0 1 0

















... 1
... 1
... 1
... 1
... 1
... 0




2
...
5
1
...
5
... 0












∼

∼










0 5

0 0





2 3 1

0 1 0

0 0 1

1 0 0



0 1 0

∼

1

−

4
−
... 1
1
...
5
... 0
...
...
... 0

1
5

1
5

... 1
... 1
... 0








∼



0 5

0 0






2 3 0








0 1 0

0 0 1

∼










.

∼





Para a equação (2.11) podemos utilizar a mesma sequência de transformações

0 0 1

0 0 1
















elementares sobre A

3

1

2

−

−

1

1

2

−

2

1

2








... 0
... 1
... 0








∼

∼

∼























...
...
...

0

2

2

−

−

0
3
10
−
1
2

2 3

1

∼










0 5

0 0





2 3 0

∼








0 1 0

0 0 1









1

−
1
...
...
...

...
...
...

0

2
−
1
2








−

1
2
3
10
−
1
2









2 3

1

0 5

0 5

1

−
3

...
...
...

0

2

−
0

2 3 1

0 5 0

0 0 1

2 0 0

0 1 0

0 0 1

...
...
...
...
...
...

2 3

1

∼










0 5

0 0





2 3 1

0 1 0

0 0 1

∼








1

−

4
−
...
...
...

1 0 0

0 1 0

0 0 1









∼















0
3
2
−
1
2
2
5
3
10
−
1
2

...
...
...

1
5

3
10
−
1
2








e para a equação (2.12) chegamos por um processo semelhante a

3

1

2

−

−

1

1

2

−

2

1

2








1 0 0

0 1 0

0 0 1

...
...
...

... 0
... 0
... 1








∼








o que nos permite concluir que

1
5



,

1
20

−

−

1
4






64

e



c11
c21
c31



= 









1
5
1
5
0

,






1
5




c12
c22
c32






c13
c23
c33









= 









3
10
−
1
2







1
5



= 

−









−

1
20
1
4

.







(2.13)

(2.14)

(2.15)

Concluímos de (2.13), (2.14) e (2.15) que a matriz inversa de A é

A−1 = 

1
5

1
5

1
5
1
3
10 −
5 −
1
0
2

1
20
1
4

−

.











Ainda poderíamos ter feito o escalonamento da seguinte forma

2

1



3

1

−

1

1

... 1 0 0
... 0 1 0
... 0 0 1

1 0 0



0 1 0



∼

1
5

...
...
... 0

1
5

1
5



,

1
20

1
3
10 −
5 −
1
2

2





pois quando operamos entre linhas uma coluna não interfere na outra, ou seja, operamos

0 0 1
















−

−

−

1
4

2

2

sempre elementos de uma mesma coluna. Ainda quando operamos as colunas da identi-

dade separadamente, é possível notar que a sequência de transformações elementares que

altera a matriz A, na identidade, pode ser repetida em cada caso. O que nos mostra que

podemos resolver os três casos em uma única matriz estendida.

Construímos a matriz A−1 para ser a inversa de A, vamos fazer a multiplicação e

constatar o resultado.

A−1 = 

1

A

×

2

3

−

1

2





= 





2

·

1

2

−
1
5 + 3
1
1
5 −
1
5 −
1 0 0

2

2

·

·

·

·

·

1

1

−

1
5

1
5

1
5
1
3
5 −
10 −
1
0
2

1
20
1
4

−
1
5 + 3
1
1
5 −
1
5 −

2

0 2

0 1

0 2

·

·

·






(
·

−
(

−

(

−

·

·





·

2







1
5 + 1
·
1
5 + 1
1
2
5 −

·

·

65

1
4 )
1
4 )
1
4 )







1
20 ) + 1
1
20 ) + 1
1
2
20 )

−

·

·

·

(

−
(

−
(

−

3
10 ) + 1
3
10 ) + 1
3
2
10 )

−

·

·

·

1
2 2
1
2 1
1
2 2

1
5 + 3
1
1
5 −
1
5 −

2

·

·

·

·

·

·

(

−
(

−

(

−

= 

0 1 0



.





0 0 1





Agora que temos a inversa de A, podemos resolver o sistema.

ou de forma equivalente,

~x = A−1~b,

1
5

1
5

1
5
3
1
5 −
10 −
1
0
2

1
20
1
4

−

7

2

1



= 

1



.

−

4





2









·













~x = 





Nesse capítulo, quando buscou-se resolver um sistema linear, os temas relacionados,

com matrizes, acabaram por aparecer naturalmente. Acreditamos que uma abordagem

utilizando essa ordem de conteúdos, pode tornar-se mais signiﬁcativa para os alunos no

Ensino Médio. Sobre os teoremas, podemos abordá-los como propriedades e demonstrar

alguns casos mais simples. A forma como foram feitas as demonstrações, em sua grande
maioria, podem ter adaptações para R2 ou R3 sem muita diﬁculdade. Não podemos

esquecer ainda do uso de matrizes para representação de dados. Não foi abordado o

tema, mas não podemos deixar de apresentar esse uso em sala de aula.

Sugiro ainda, para saber mais sobre o tema tratado neste capítulo, a leitura das

obras: Geometria Analítica (Delgado. Jorge; Frensel. Katia; Crissaﬀ. Lhaylla, 2013), Introdução

à Álgebra Linear (Hefez. Abramo; Fernandez. Cecília S, 2016), Álgebra Linear (Lima. Elon

Lages, 2003) e Álgebra Linear e suas Aplicações (Strang. Gilbert, 2010) que serviram como

base teórica.

66

67

3 ESPAÇOS VETORIAIS

No capítulo 2 vimos que um sistema linear pode ser representado por colunas. Essa

representação nos remete ao estudo dos vetores. Neste capítulo estudaremos vetores, seus

conceitos e propriedades. Abordaremos o espaço vetorial, o subespaço vetorial, o espaço-

coluna e o espaço nulo. Veremos a importância desses conceitos para o estudo de sistemas

lineares.

Abordaremos, também, a forma escalonada de uma matriz, pivôs, variáveis pivôs e

variáveis livres. Ainda neste capítulo, deﬁniremos quando um sistema linear tem solução

e se é única. Faremos uma breve abordagem a respeito de independência linear, base e

dimensão.

No capítulo anterior, vimos que um sistema linear

y + 4z + w =

−
2y + 3z + 2w = 3

1

pode ser representado em sua forma matricial

3y + z

−

3w = 2,

1 4



2 3

1

2

ou em uma representação vetorial

3 1

3

−





1

4

y



z



= 

1

−
3

,



w













2





·









2



+ z



3



+ w



= 

.



y

·

3









·





1





1

2

3

−



·









1

−
3

2









Buscamos algumas formas de encontrar o valor das incógnitas quando o sistema estava

na forma matricial. Agora, buscaremos saber quando esses sistemas terão soluções e se

serão únicas. Além disso, vamos veriﬁcar, neste capítulo, que tipo de informações a forma

vetorial nos fornece. Para isso, vamos estudar um pouco sobre vetores.

3.1 VETORES

Deﬁnição. Vetor é o conjunto de todos os segmentos que têm o mesmo comprimento,

sentido e são paralelos ou colineares. Esse conjunto pode ser representado por um único

68

desses segmentos.

Figura 10: Representação de ~v.

Fonte: Elaborado pelo autor.

Podemos, ainda, deﬁnir vetores como um segmento orientado deﬁnido por dois

pontos.

Sejam A = (a1, . . . , an) e B = (b1, . . . , bn) dois pontos, temos que o vetor ~v será:

~v =

#    »
AB = (b1 −

a1, . . . , bn

an).

−

Com os bi

−

ai sendo as coordenadas do vetor.

Exemplo 1: Temos que os pontos A = (1,

1) e B = (3, 1) deﬁnem o vetor ~v, com

−

#    »
AB = (3

~v =

1, 1

(

−

−

−

1)) = (2, 2).

Esse mesmo vetor pode ser deﬁnido pelos pontos C = (2, 1) e D = (4, 3). Assim,

#    »
CD = (4

~v =

2, 3

−

−

1) = (2, 2).

Adição

Deﬁnimos a adição de vetores como a soma um a um de cada termo do vetor. Seja

~v = (v1, ..., vn) e ~u = (u1, ..., un), então:

~v + ~u = (v1 + u1, ..., vn + un).

Multiplicação

Deﬁnimos a multiplicação de um vetor por um escalar como

~v = α(v1, ..., vn) = (αv1, ..., αvn),

α

·

69

onde o escalar multiplica cada termo do vetor. Agora, podemos deﬁnir um espaço vetorial.

Deﬁnição: Um conjunto será chamado de espaço vetorial sobre um corpo 1 K se possuir

uma adição (+) e uma multiplicação por escalar (

) tal que vale as seguintes propriedades:

·

A1 (~u + ~v) + ~w = ~u + (~v + ~w) para todos ~u, ~v, ~w

~V (Associatividade).

∈

A2 ~u + ~v = ~v + ~u para todos ~u, ~v

~V (Comutatividade).

∈

A3 Existe ~0

∈

~V , tal que ~v + ~0 = ~v, para todo ~v

~V (Elemento Neutro).

A4 Para todo ~v

~V , existe ~
v
−

∈

∈

∈
~V tal que ~v + (

−

~v) = ~0 (Simétrico).

ME1 a

·

(~u + ~v) = a

ME2 (a + b)

~v = a

·

·

·

~u + a

·

~v, para todos a

K e ~u, ~v

∈

~v + b

·

~v, para todos a, b

K e ~v

∈

∈

~V .

∈
~V .

ME3 (ab)

~v = a(b

·

·

~v), para todos a, b

K e ~v

∈

~V .

∈

ME4 1

·

~v = ~v, para todo ~v

~V .

∈

Temos que R1, R2, R3, ... satisfazem as propriedades citadas anteriormente e, por-
tanto, são espaços vetoriais 2 . É importante ressaltar que, mesmo em casos em que não
conseguimos representar os vetores em um plano cartesiano (R4 ou R5 por exemplo), a

ideia intuitiva continua a mesma, temos um segmento orientado que representa o vetor.
Diremos que R1 é o espaço de uma dimensão, R2 de duas dimensões e, assim, Rn possui

n dimensões.

Deﬁnição: Deﬁnimos um subespaço vetorial como um subconjunto não vazio que satisfaz

as propriedades de um espaço vetorial.

Teorema 3.1 Seja A um espaço vetorial e B um subconjunto não-vazio de A. Então B

será um subespaço vetorial , se e somente se, as seguintes propriedades forem satisfeitas:

I Se somarmos quaisquer vetores ~u e ~v do subespaço, a soma ~u + ~v continua perten-

cendo ao subespaço;

II Se multiplicarmos qualquer vetor ~v no subespaço por qualquer escalar a

R, a~v

∈

continua no subespaço.

1Ver apêndice A.
2Nos referimos a R como o corpo dos números reais e Rn, com n

ordenados (a1, ..., an), com a1, ..., an

R.

∈

N, como o conjunto dos pares

∈

70

Demonstração: Suponhamos que B seja um subespaço vetorial de A. Então, vale a pro-

priedade (I), pois a adição está deﬁnida no subespaço vetorial e vale (II) porque a multi-

plicação por escalar também está deﬁna no subespaço vetorial.

Agora, suponhamos que valem as propriedades (I) e (II), devemos provar que valem

as propriedades A1, A2, A3, A4, ME1, ME2, ME3 e ME4.

A1 Está garantida pela propriedade (I) e pelo fato que os elementos de B pertencem ao

espaço vetorial A e herdam a associatividade.

A2 O argumento é semelhante ao de A1.

∈

B, temos que B é não-vazio por deﬁnição. Da propriedade (II) temos a~v

∈
R. Logo vale para a = 0 e temos a~v = 0~v = ~0 o que nos garante que ~0

B e temos que a propriedade (A3) está garantida.

B. Da propriedade (II) temos a~v

B para todo a

R. Logo vale para

1~v =

−

−

~v o que nos garante que

B e temos que a propriedade

∈

∈

~v
−

∈

A3 Seja ~v

B para todo a

∈

∈
A4 Seja ~u

a =

−

∈
1 e temos a~v =

(A4) está garantida.

As propriedades ME1, ME2, ME3 e ME4 estão garantidas pela propriedade (II)

e pelo fato que os elementos de B pertencem ao espaço vetorial A e herdam a propriedades

de multiplicação por escalar de A.

Uma característica importante dos subespaços vetoriais é que as combinações li-

neares dos vetores do subespaços permanecem no subespaço vetorial. Temos, ainda, que

o vetor nulo sempre pertencerá ao subespaço vetorial. Para constatar isso, basta tomar

c = 0 e temos ~v

0 = ~0.

·

3.1.1 Espaço-coluna de A

O espaço-coluna contém todas as combinações lineares das colunas de A, ou seja,

todos as combinações possíveis com os vetores coluna e escalares. Vamos agora analisar

um exemplo:

u

· "

v#

2 1



3 5



4 3









b1
b2
b3







= 





⇒

2

1

u 

3



+ v 

5



= 





4









3









b1
b2
b3

,







é possível notar que o sistema só terá solução se existirem u e v tais que a combinação

linear gerem b1, b2 e b3.

Então a questão se resume a encontrar valores para u e v tal que ~b seja uma
combinação das colunas de A. Se ~b = ~0 basta tomar u = v = 0 e portanto para ~b = ~0
sempre haverá solução. Se pensarmos geometricamente o sistema tem solução sempre que

~b pertencer ao plano gerado pelos vetores (2, 3, 4)T e (1, 5, 3)T .

Figura 11: O vetor ~b pertence ao plano formado pelos vetores (1, 5, 3)T e (2, 3, 4)T .

71

Fonte: Elaborado pelo autor.

Figura 12: O vetor ~b não pertence ao plano formado pelos vetores (1, 5, 3)T e (2, 3, 4)T .

Fonte: Elaborado pelo autor.

Logo, temos o seguinte teorema:

Teorema 3.2 O sistema A~x = ~b tem solução, se e somente se, o vetor ~b possa ser
expresso como uma combinação das colunas de A. Então, ~b pertence ao espaço-coluna.

Demonstração: Suponhamos que o sistema A~x = ~b tenha solução, então existe ~x tal que

A~x = 

a11
...
am1

. . . a1n
...
...
. . . amn



·

x1
...
xn







b1
...
bn

.









= 












Utilizando a representação por colunas, temos:





72

x1 



+ x2 



+ . . . + xn 



= 

a11
...
am1









a12
...
am2









a1n
...
amn









b1
...
bn











e como o sistema tem solução, temos que ~b pode ser representado como uma combinação
das colunas de A.

Agora suponhamos que o sistema possa ser expresso como uma combinação das

colunas de A.

y1 



+ y2 



+ . . . + yn 



= 

.



a11
...
am1









a12
...
am2









a1n
...
amn

b1
...
bn

















Assim, existe pelo menos um ~y tal que a igualdade é verdadeira. E, portanto, o sistema

A~y = 

a11
...
am1

. . . a1n
...
...
. . . amn



= 

y1
...
ym









·









b1
...
bm















tem solução que é ~y. Assim, ~b pertence ao espaço coluna.

Chamaremos o espaço coluna de A por C(A).

Exemplo 2: Veriﬁcaremos, pois, se o sistema a seguir tem solução.

2

1

u 

3



+ v 

5



= 





4









3









1

2

−
1

.







Para que esse sistema tenha solução, devemos ter, pelo Teorema 3.2, que existem

valores para u e v tal que vale essa igualdade. De fato para u = 1 e v =

1 temos a

igualdade satisfeita. Podemos conﬁrmar esse fato através da Figura 11, pois temos que o
2, 1)T pertence ao plano gerado pelos vetores (2, 3, 4)T e (1, 5, 3)T .

vetor (1,

−

−

Exemplo 3: Vejamos, agora, se o sistema a seguir tem solução:

2

1

1




Não importa os valores que escolhermos para u ou v sempre teremos o terceiro





















0

7

u 

1



+ v 

3



= 

2



.

−
0

termo do vetor resultante igual a 0. Assim, o vetor (1, 2, 7)T não pode ser gerado como
1, 0)T e (1, 3, 0)T . Logo, pelo Teorema 3.2 esse
uma combinação linear dos vetores (2,
sistema não tem solução. Podemos veriﬁcar que o vetor (1, 2, 7)T não pertence ao plano
1, 0)T e (1, 3, 0)T , conforme Figura 13.

gerado pelos vetores (2,

−

−

73

Figura 13: O vetor (1, 2, 7)T não pertence ao espaço coluna gerado pelos vetores (2,
e (1, 3, 0)T .

−

1, 0)T

Fonte: Elaborado pelo autor.

3.1.2 Espaço Nulo de A

O espaço nulo de uma matriz Am×n, ou núcleo de A, é o conjunto de todos os
vetores ~x tal que A~x = ~0. Ele é representado por N (A). Trata-se de um subespaço de
Rn.

De fato, temos de A~x = ~0 que ~x
Seja ~x1 e ~x2 dois vetores quaisquer, pertencentes ao espaço nulo de A. Devemos

Rn para que exista a operação A~x.

∈

mostrar que ~x1 + ~x2 ∈

N (A), temos, então, que

A ~x1 = ~0 e A ~x2 = ~0.

Logo, utilizando a distributividade, temos

A( ~x1 + ~x2) = A ~x1 + A ~x2 = ~0 + ~0 = ~0.

Portanto,

~x1 + ~x2 ∈

N (A).

Agora devemos mostrar que se ~x

N (A) então α~x

∈

∈

N (A), para qualquer α

R

∈

74

De fato, temos que

A(α~x) = 

a11
...
am1

. . . a1n
...
...
. . . amn

αx1
...
αxn





·



= 

a11αx1
...
am1αx1

. . . a1nαxn
...
. . . amnαx1

...

.









Podemos, então, utilizar a comutatividade em cada termo dentro da matriz.

















a11αx1
...
am1αx1

. . . a1nαxn
...
. . . amnαx1

...













= 





= α

αa11x1
...
αam1x1

. . . αa1nxn
...
. . . αamnx1

...



= α

a11x1
...
am1x1

. . . a1nxn
...
. . . amnx1

...







·







a11
...
am1

·







. . . a1n
...
...
. . . amn

·










x1
...
xn







= α

·

A~x = α

~0 = ~0.

·







Logo, α~x

∈

N (A) para qualquer α

∈

Rn e portanto N (A) é um subespaço de Rn.

3.2 RESOLUÇÃO DE AX = 0 E AX = B

No capítulo anterior estudamos a resolução de sistemas de equações lineares na
qual A era uma matriz quadrada. Se A fosse invertível, o sistema A~x = ~b teria apenas
uma solução ~x = A−1~b. Essa solução poderia ser encontrada pelo método de eliminação
de Gauss ou pelo uso da matriz inversa. Se analisarmos uma matriz retangular, nem

sempre temos todos os pivôs diferentes de zero. Transformando uma matriz escalonada

(chamaremos de matriz U ) em uma matriz reduzida (chamaremos de matriz R) que é

a matriz mais simples que a eliminação pode fornecer. Essa matriz R fornece todas as

soluções possíveis de forma simples. Quando a matriz A é invertível, o espaço nulo contém
apenas ~x = ~0, pois

A~x = ~0

⇒

~x = A−1~0 = ~0.

Já, o espaço coluna é o espaço inteiro, claro se ~x = A−1~b temos que ~x sempre tem solução
para todo ~b uma vez que A−1 existe e desde que a multiplicação seja possível. Como
~x sempre existirá, temos que existe uma combinação linear com os termos de ~x e as
colunas de A que geram ~b. Mas, e se A não for invertível ou o espaço nulo tiver mais
do que o vetor nulo ou o espaço coluna tiver uma quantidade menor do que todos os

vetores? Chamaremos de ~xn o vetor que está no espaço nulo e ~xp uma solução particular
para o sistema A~x = ~b. Logo, a solução para todas as equações lineares têm essa forma

75

~x = ~xp + ~xn. De fato A~xp = ~b e A~xn = ~0, temos que

A~xp + A~xn = A(~xp + ~xn) = ~b + ~0
A(~xp + ~xn) = ~b.

Quando o espaço coluna não contiver todos os ~b em Rm, precisaremos estipular condições
para ~b, para tornar o sistema A~x = ~b solúvel.

Vamos analisar o sistema 0x = b, onde o sistema é 1 por 1. Para 0x = b o espaço

coluna da matriz nula contém apenas b = 0. Assim, o sistema só admite solução para

b=0. Para 0x = 0 temos que o espaço nulo permite qualquer valor para x. Portanto, o

sistema Ax = 0 admite qualquer valor para x, ou seja, inﬁnitas soluções. Logo, a solução

ﬁca

x = xp + xn = 0 + x,

onde x pode ser qualquer número. Portanto, o sistema apresenta inﬁnitas soluções. Va-

mos agora analisar um caso de uma matriz 2 por 2. A matriz

1 1

"

3 3#

não é invertível. E

o sistema A~x = ~b não tem solução para qualquer ~b. O espaço coluna de A contém apenas
os valores de ~b que são múltiplos do vetor (1, 3)T , teremos solução apenas se 3b1 = b2 onde
b = (b1, b2). Quando b2 = 3b1 temos inﬁnitas soluções.

Exemplo 4:

a

1

"

3#

+ b

1

"

3#

=

2

"

6#

.

Temos que os pares (1,1), (2,0), (3,-1), (4,-2),... são todos soluções. Já para o

espaço nulo, temos

a

1

"

3#

+ b

1

"

3#

=

0

"

0#

e concluímos que a=-b. Logo, a solução do espaço nulo será ~xn = (

solução geral será dada por

b, b). Portanto, a

−

~xp + ~xn =

1

"

1#

+ b

1

−
1 #

"

=

"

para todo b

R.

∈

1

b

,

−
1 + b#

76

3.3 FORMA ESCALONADA U E FORMA REDUZIDA R

Vamos simpliﬁcar a seguinte matriz 3 por 4, primeiro para U e depois para R

1

2



2

4

2 3

6 5



.

(3.1)

Após algumas operações elementares em (3.1) chegamos á matriz





2

−

−

4 6 0





1

2



2

4

2 3

L2→2L1−L2

1 2

2

3

6 5



∼
L3→2L1+L3



0 0

0 0





2 1

−
10 6











2

−

−

4 6 0





e temos um problema, o pivô da segunda coluna é zero e como abaixo dele também só

há zeros, não conseguiremos trocar linhas e gerar um pivô diferente de zero. Todavia,

como a matriz é retangular devemos esperar por problemas, vamos continuar. Após mais

algumas operações elementares, chegamos à

1 2

2

3

L3→5L2+L3

1 2

2

3



0 0

0 0







∼

2 1

−
10 6





2

−
0



0 0

0 0





11





1



= U

(3.2)

que é a matriz escalonada. Temos que U é uma matriz triangular superior, entretanto os

pivôs não se encontram na diagonal principal. Os elementos de U estão em forma de uma

“escada” ou forma escalonada. Sempre é possível chegar à forma escalonada de U , para

isso temos que:

1o Os pivôs são os primeiros termos não nulos em sua linha.

2o Abaixo dos pivôs só há zeros.

3o O pivô seguinte deve localizar-se a direita e em uma linha abaixo. Formando, assim,

a forma de escada.

Vamos agora transformar U em R.

1 2

2

3

Dividindo todas as linhas por seus pivôs de forma que seus pivôs virem o 1, temos:

U = 

0 0

0 0





2

−
0

1



.

11





77

,



1 2 2



0 0 1

0 0 0

3
1
2
−
1









em seguida utilizamos os pivôs para eliminar os números acima deles.



0 0 1 0





0 0 1 0



= R.

(3.3)

1 2 2 0

1 2 0 0

0 0 0 1

0 0 0 1





∼













Essa nova matriz (3.3) é a forma escalonada reduzida por linhas. A partir de R
podemos achar o espaço nulo, pois R~x = ~0, U~x = ~0 e A~x = ~0 apresentam a mesma
solução. Na próxima seção abordar-se-á como encontrar, de forma detalhada, o espaço

nulo .

Teorema 3.3 A forma escalonada reduzida por linha de uma matriz quadrada invertível

é a matriz identidade.

Demonstração: Suponhamos que a matriz An é invertível. Pelo Teorema 2.4 a forma

escalonada dessa matriz possui n pivôs. Assim, basta dividir cada linha pelo seu respectivo

pivô, o que só é possível, pois os pivôs são diferentes de zero. Em seguida, é só utilizar

esses novos pivôs unitários para zerar os elementos acima deles. O que temos após esse

processo será a matriz identidade.

3.4 VARIÁVEIS PIVÔS E VARIÁVEIS LIVRES

Queremos encontrar todas as soluções para R~x = ~0. Vamos analisar os pivôs.

1 2 0 0

R~x = 

0 0 1 0







0 0 0 1





·

0

= 

0



.





0





(3.4)

u



v



w

y















Temos y = 0, w = 0 e u + 2v = 0. Como temos os pivôs deﬁnindo os valores de

w e y, vamos deﬁnir as variáveis em estar relacionada com um pivô ou não ter um pivô

deﬁnindo-a. Temos, então, y, w e u como varáveis relacionadas com os pivôs (variáveis

não livres) e v que não está deﬁnida segundo um pivô, será uma variável livre, isto é, ela

poderá assumir vários valores. Temos, então, que u + 2v = 0 o que resulta em u =

2v.

−

78

Portanto, temos o valor de u deﬁnido (dependendo de v). Logo temos:

u



v



2v

−
v





~x =

=

= v

2

−
1





.

w

0

0

y

0




























Se aplicarmos essas soluções no sistema inicial (3.4), podemos conﬁrmar que elas
satisfazem o sistema A~x = ~0. Podemos notar que o valor de ~x vai depender do valor v,
portanto, para cada valor de v que assumirmos, teremos um valor de ~x que pertence ao
espaço nulo. Qualquer valor de u, v, w e y que satisfaz a igualdade R~x = ~0 vai ser uma
combinação linear dos vetores que geram o espaço nulo.















0

Exemplo 5: Para v = 1 temos x =

ou para v = 2 temos x =

2

−
1












0

0








6

−
3





.








0

0








Chamaremos essas respostas de “soluções especiais”. Uma ótima forma de encontrar

essas soluções é seguir a seguinte sequência de passos:

1o Identiﬁque em R as variáveis pivôs e as variáveis livres

2o Coloque o valor de 1 para uma das variáveis livres e 0 para as outras variáveis livres,

encontre o valor de ~x em R~x = ~0. Esse ~x é uma solução especial.

3o Cada variável livre produz uma solução especial. A combinação dessas soluções

forma o espaço nulo, ou seja, todas as soluções de A~x = ~0

Exemplo 6: Seja o sistema na forma escalonada reduzida.

u



v



·

w















1 2 0 1

R~x = 

0 0 1 1



0

= 

0



.




1o As variáveis pivôs são u e w. Já as variáveis livres são v e y.













y

0 0 0 0

0

2o Temos que

e

u + 2v + y = 0

u =

2v

−

−

y

⇒

w + y = 0

w =

y.

−

⇒

2 e w = 0 e para y = 1 e v = 0 temos u =

−

79

1 e

−

Para y = 0 e v = 1 temos u =

w =

1.

−

3o Logo, chegamos a

~x = v

2

−
1

0

0



















+ y

1

−
0

1

−
1










.










Temos que o número de colunas menos o número de pivôs nos dá o número de

variáveis livres. Portanto, deve existir n

colunas e m o número de linhas com pivôs.

−

m variáveis livres, onde n é o número de

Teorema 3.4 Se A~x = ~0 possui mais incógnitas (colunas) do que equações (linhas), então
o sistema possui pelo menos uma solução especial, ou seja, há mais soluções que a trivial
~x = ~0.

Demonstração: Seja a matriz Am×n com n > m. Após o escalonamento de A, encontra-

remos uma matriz U com no máximo m pivôs, onde m é o número de linhas ou equações.

−

Como cada pivô nos fornece uma variável não-livre, ﬁcamos com n

m variáveis livres,

n é a quantidade de incógnitas. Além disso, cada variável livre nos fornece uma solução

especial. Portanto, como n > m o sistema possui pelo menos uma solução especial.

O espaço nulo terá dimensão igual ao número de variáveis livres e soluções especiais.

Vamos agora ver a relação dos pivôs com o espaço-coluna.

3.4.1 Resolução de A~x = ~b, U ~x = ~c e R~x = ~d

Quando ~b = ~0 não precisamos nos preocupar com o que acontece no lado direito
= ~0 as operações nas linhas alterarão os valores das

da equação A~x = ~b, mas quando ~b
linhas de ~b. Retornando ao sistema

1

2

2

4

2 3

6 5



2

−

−

4 4 1











u

·



v



w

y















b1
b2
b3







= 





(3.5)

6
80

que é equivalente a

1

2



2

4

2 3

6 5

Fazendo algumas operações elementares, temos

2

−

−

4 4 1






...
...
...

b1

b2

b3



.






L2→2L1−L2

1 2

2

3

1

2

2

4

2 3

6 5

2

−

−

4 4 1








...
...
...

b1

b2

b3








∼
L3→2L1+L3

0 0

0 0








1 2

2

3

2 1

7

−
8

0 0

0 0








b1

...
... 2b1 −
b2
... 2b1 + b3








L3→4L2+L3

1 2

2

∼

0 0

0 0

2

−
0








b1

...
... 2b1 −
b2
... 2b1 + b3








...
b1
...
2b1 −
... 10b1 −

b2

4b2 + b3

2 1

−
8

7

3

1

11

que nos fornece

1 2

2

0 0

0 0

2

−
0

3

1

11








...
b1
...
2b1 −
... 10b1 −

b2

4b2 + b3



.













(3.6)

Agora temos um sistema triangular superior U~x = ~c. O sistema só terá solução
se tivermos que ~b pertença ao espaço-coluna de A, ou seja, ~b deverá ser uma combinação
4)T , (2, 6, 4)T e (3, 5, 1)T . Esse espaço surge de A e
linear dos vetores (1, 2,

2)T , (2, 4,

−
não de U . As colunas de A geram o espaço-coluna,

−

1

2



, 

2

4

2

3



, 

6



e 

5



,

−

2









−

4









4









1











pois o sistema pode ser representado por

81

1

2

u 



+ v 

2

4

2

3



+ w 

6



+ y 

5



= 





−

2









−

4









4









1









b1
b2
b3

.







Podemos notar que a segunda coluna é um múltiplo da primeira. Logo, ela pode ser

escrita como uma combinação das outras três colunas.

1

2

2

−

2 









2

3



+ 0 

6



+ 0 

5



= 

2

4

.







4









1









4

−





Além disso, a segunda coluna de (3.6) não tem um pivô. Assim, os vetores colunas

de A que geram o espaço coluna são aqueles que possuem um pivô após o processo de

escalonamento e o espaço coluna será gerado pelas colunas 1, 3 e 4 de (3.5). Tomaremos
~b = (1, 0, 1)T como exemplo. Temos

1 2

2

0 0

0 0

2

−
0

3

1

11

U~x = ~c ou 





1

...
...
2
... 11








o que nos dá por retrossubstituição:

2w + y = 2

−

11y = 11

y = 1

→
2w = y

2

→

→
u + 2v + 2w + 3y = 1.

−

w =

1
2

−

Temos que o valor de u vai depender do valor de v, portanto escolhamos v=0, por como-

didade.

u + 2

0 + 2

·

1
2

(

−

·

) + 3y = 1

u =

1.

−

→

Logo, uma solução particular é ~xp = (

1, 0,

−

−

1
2 , 1) e a solução completa ﬁca

~x = ~xp + ~xn =

1

−
0
1
2
−
1



















+ v

2

−
1

0

0










.










82

Então, para qualquer valor que escolhermos para v encontraremos uma solução

para o sistema. Logo, o sistema admite inﬁnitas soluções. Um bom método para resolver

um sistema é:

1o Transformar A~x = ~b para U~x = ~c.

2o Faça as variáveis livres iguais a 0, encontre uma solução particular para A~xp = ~b e

U~xp = ~c.

3o Encontre as soluções especiais de A~x = ~0 ou U~x = ~0 ou R~x = ~0. Assuma em
cada caso uma varável livre igual a 1 e as outras iguais a 0. Encontre todas as

soluções especiais repetindo esse processo para cada variável livre. Então aplique

em ~x = ~xp + ~xn. Onde ~xp é qualquer solução particular e ~xn é a combinação das

soluções especiais.

3.5 INDEPENDÊNCIA LINEAR, BASE E DIMENSÃO

Os números m e n não fornecem uma imagem completa de um sistema linear. Po-

demos ter um sistema com linhas nulas após o escalonamento, essa linha não tem nenhuma
inﬂuência na resolução do sistema homogêneo A~x = ~0 e, além disso, acaba reduzindo a
dimensão do espaço coluna. Abaixo, a deﬁnição que vai nos auxiliar nessa questão.

Deﬁnição. O posto p de uma matriz A é igual ao número de linhas não nulas da matriz

escalonada (U ).

Teorema 3.5 3 Considere um sistema linear com m equações e n incógnitas A~x = ~b.
Sejam PAB o posto da matriz ampliada 4 do sistema e PA o posto da matriz dos coeﬁcientes

do sistema. Então:

I O sistema é possível se, e somente se, PAB = PA.

II O sistema é possível e determinado se PAB = PA = n.

III O sistema é possível e indeterminado se PAB = PA < n. Neste caso n

PA é o

−

número de variáveis livres do sistema, ou seja, a variável pode assumir qualquer

valor real.

3Esse teorema pode ser encontrado em sua versão original no livro Introdução à Álgebra Linear. (Hefez.

Abramo; Fernandez. Cecília S, 2016) pg 43.

4Seja o sistema linear A~x = ~b, a matriz ampliada desse sistema será a matriz dos coeﬁcientes de A

acrescida de uma última coluna com os elementos do ~b.

83

B] a matriz

IV O sistema é impossível se, e somente se, PA < PAB.

Demonstração: Seja A~x = ~b um sistema linear com n variáveis. Seja C = [A
ampliada do sistema e U = [UA

UB] a forma escalonada de C. Temos que UA é a forma

|

escalonada de A e como A está a esquerda de B. Temos PA = PUA < PU = PAB se UB

|

tiver algum pivô ou PA = PUA = PU = PAB se UB não tiver nenhum pivô. Vamos analisar

por casos.

Se PA < PAB então U tem pelo menos uma linha da forma

0 . . . 0

pois a matriz escalonada terá uma forma parecida com

h

... cl

,

i

p11










pkn

0

. . .

0

...
c1
...
...
... ck
...
cl

,










onde k < l e l = PAB.

Assim, o sistema é impossível, pois quando multiplicarmos uma incógnita por zero, não vai

existir número real que torne a operação possível, ou seja, acharmos um número diferente

de zero.

Se PA = PAB então U e UA tem o mesmo número de linhas não nulas. E se

PA = PAB = n temos que U será da forma

p11

. . .

pnn

0

. . .

0










c1

...
...
... cn
...
0

,










m.

para n

≤

Logo, por retrossubstituição, será possível encontrar o valor para cada variável. Essa

solução será única, pois se analisarmos os termos diferentes de zero na forma escalonada
teremos uma matriz U ′ que é quadrada e o Teorema 2.4 garante que ela é invertível.
Portanto, tem apenas uma solução.

Se PA = PAB < n temos que após o escalonamento de C chegamos a uma matriz

U na qual haverá mais incógnitas do que linhas. Como cada linha tem um pivô e esse

deﬁne uma variável como não-livre, sendo k o número de pivôs, teremos n
livres. Desse modo, o sistema A~x = ~b também terá n

−
= 0 variáveis livres.

k

k variáveis

−

O posto da matriz vai nos mostrar a verdadeira dimensão da mesma, quantos pivôs

terá e o número de linhas independentes.

6
84

Deﬁniremos, agora, independência linear.

Deﬁnição: Um conjunto de vetores v1, ..., vk é linearmente independente se c1v1 + ... +
ckvk = 0 só ocorre se c1 = ... = ck = 0. Se existir algum desses termos diferentes de zero
tal que c1v1 + ... + ckvk = 0, então eles serão linearmente dependentes.

Exemplo 7: Temos que os vetores (1,2,-2), (2,4,-4),(2,6,4) e (3,5,1) são linearmente de-

pendentes, pois o segundo é um múltiplo do primeiro.

(1, 2,

2

·

2) + (

1)

−

·

−

(2, 4,

−

4) + 0

·

(2, 6, 4) + 0

·

(3, 5, 1) = 0.

Temos c1 e c2 diferentes de zero.

Exemplo 8: Os vetores (2,1,3), (3,1,1) e (1,0,-2) são linearmente dependentes. Porque

temos

1

·

(2, 1, 3) + (

1)

−

·

(3, 1, 1) + 1

(1, 0,

·

−

2) = 0.

Aqui nenhum vetor é um múltiplo direto de outro, mas o 2o é uma combinação linear do
1o e do 3o.

Exemplo 9: Os vetores (2,0,0), (0,3,0) e (0,0,4) são linearmente independentes. Porque

temos que a única solução possível será

(2, 0, 0) + 0

0

·

·

(0, 3, 0) + 0

·

(0, 0, 4) = 0.

Se pegarmos algum dos escalares diferentes de zero, não teremos o lado esquerdo da
igualdade igual a zero. Repare que o 1o e o 2o vetores não têm como gerar o terceiro,

pois a terceira coordenada desses é igual a zero, consequentemente não conseguem gerar
o 3o vetor que tem a terceira coordenada igual a 4. Por um motivo semelhante o 1o
e o 3o não conseguem gerar o 2o vetor, pois o segundo termo deles é zero. Já o 2o e
o 3o não conseguem gerar o 1o vetor por motivo análogo. Mais a frente veremos que

existem conjuntos de vetores com todos os termos diferentes de zero e, mesmo assim, são

linearmente independentes.

Teorema 3.6 As colunas de uma matriz A serão independentes quando o núcleo de A é
o vetor nulo, ou de forma equivalente quando a única solução do sistema linear A~x = ~0 é
x = ~0

Demonstração: Temos que o núcleo de uma matriz Am×n é A~x = ~0 ou

85

x1 



+ x2 



+ . . . + xn 



= 0.

a11
...
am1









a12
...
am2





≤





≤

a1n
...
amn









Se tivermos algum xi

= 0, com 1

i

n, então o espaço coluna será linearmente

dependente. Desse modo, para que o espaço seja linearmente independente devemos ter

x1 = . . . = xn = 0 e logo o núcleo A é o vetor nulo.

Teorema 3.7 As r linhas não nulas de uma matriz escalonada U e uma matriz reduzida

R são linearmente independentes. Então as r colunas que contêm os pivôs também são.

Demonstração: Vamos dividir essa demonstração em partes:

1o O número de pivôs é igual ao número de colunas.

Relembrando que a matriz reduzida R tem o número 1 na posição dos pivôs e zeros

acima dos deles. Então, cada coluna terá apenas o número 1 na posição do pivô e

zero nas demais posições de sua coluna.

R =

111

0

. . .

0

0
...
0
...
0

122
...
0
...
0

. . .
0
...
...
. . . 1nn
...
...
0
0
















.
















Analisando a equação matricial R~x = ~0, temos

111

0

0













0
...
0
...
0

122
...
0
...
0

+ x2

= ~0.

R~x = x1

+ . . . + xn


























Temos que a única forma de zerar a 1a coluna é tendo x1 = 0, pois nas outras
colunas o 1o termo é igual a zero. Para zerar a 2a coluna teremos x2 = 0, porque
apenas 2a coluna terá o 2o termo diferente de zero. Esse processo vai repetir-se até





















































0
...
1nn
...
0

6
86

xn = 0, pois é a única forma de zerar a última coluna. Portanto as colunas são

linearmente independentes.

É importante ressaltar que a solução de ~x para R~x = ~0 é a mesma que para U~x = ~0.

2o O número de pivôs é menor que o número de colunas.

Suponha, como suporte, que temos a seguinte matriz reduzida R.

R =

111

0

122
...
0
...
0
...
0

0
...
0
...
0
...
0





















0

. . .

a1
. . .
a2
0
...
...
...
. . . 1kk ak
...
...
...
0
0
0
...
...
...
0
0
0

. . .

. . .
...
. . .
...
0
...
0

.

0

0
...
0
...
1mn
...
0





















Agora, assuma que a primeira coluna que aparece e não tem um pivô é a coluna

k + 1. Temos que a coluna k + 1 pode ser escrita como uma combinação linear das

k‘s colunas, com pivôs, anteriores.

a1

111





















0
...
0
...
0
...
0





















+ a2

0

122
...
0
...
0
...
0









































+ . . . + ak

=

0

0
...
1kk
...
0
...
0









































.

a1
a2
...
ak
...
0
...
0









































Temos, pois, que a coluna k + 1 é uma combinação linear das anteriores. É impor-

tante notar que essa coluna não tem pivô.

Podemos proceder de modo análogo para cada coluna que não tem pivô e que vai

aparecer na sequência. Utilizamos as colunas com pivô para mostrar que essas geram

qualquer coluna sem pivô que vier a aparecer. O que nos garante que esse raciocínio

sempre funcionará é que os pivôs não pulam uma linha, ou seja, não há uma linha

sem pivô e uma logo abaixo com pivô. Além disso, temos também que se os pivôs

87

vão da linha 1 até a linha k, não haverá um termo diferente de zero em uma linha

t, com t > k.

Utilizando um raciocínio análogo ao 1o caso, podemos mostrar que as colunas com

pivô são linearmente independentes. Devemos nos lembrar de que é uma matriz

reduzida e portanto haverá apenas o pivô de valor 1 e o restante dos termos da

coluna serão zero.

3o O terceiro caso não se aplica, uma vez que não há a possibilidade de haver uma

quantidade de pivôs maior do que a quantidade de colunas. Teríamos que ter mais

do que um pivô em alguma coluna e isto não é possível.

Exemplo 10: As colunas da matriz identidade 3 por 3 são independentes.

1 0 0



0 1 0



.




Essas colunas e1, e2 e e3 representam os vetores unitários na direção dos eixos das





0 0 1

coordenadas do R3

1

0

0

e1 = 

0



, e2 = 

1



e e3 = 

0



.





0









0





1









Figura 14: Vetores linearmente independentes.

Fonte: Elaborado pelo autor.

Fica claro que dois vetores não conseguem gerar o terceiro, pois cada dois vetores

gera um plano e o terceiro ﬁca fora desse plano.

88

Exemplo 11: Seja a seguinte matriz na forma reduzida R,

1 0 2 0



0 1 3 0



.

Temos pelo Teorema 3.7 que a 1a, 2a e 4a colunas são linearmente independentes,
pois os pivôs estão nessas colunas. Repare ainda que a 3a pode ser gerada pela 1a e 2a





0 0 0 1





colunas.

1

0

2




Teorema 3.8 Um conjunto de m vetores em Rn com m > n será linearmente dependente.





















0



0



+ 3



1



= 

3



.

2

·

0

·

0

Demonstração: Seja vi = (vi1, . . . , vin) com 1

esses vetores como linha, teremos:

i

≤

≤

m. Se construirmos uma matriz com

v11
...
vm1

. . .
v1n
...
...
. . . vmn







.







Mas, ao escalonarmos essa matriz teremos no máximo n pivôs (caso contrário, teríamos

um pivô em baixo de outro) e, portanto, teremos pelo menos uma linha nula, pois se

m > n, teremos, ao menos, um vetor que é uma combinação linear dos demais. Portanto,

o conjunto de vetores é linearmente dependente.

Exemplo 12: Seja os vetores (1, 2, 1), (3, 1, 1), (4, 3, 2) e (1, 2, 2), pelo Teorema 3.8 es-
ses vetores são linearmente dependentes, pois eles pertencem ao R3 e há 4 vetores. Vamos

escalonar a matriz gerada por esses vetores

1 2 1

L2→3L1−L2

1 2



3 1 1



L3→4L1−L3



0 5

1

2



L3→L2−L3

1 2



0 5

1

2

L3→L4

1 2



L4→L3



0 5

1

2



.

0 5

4 3 2

1 2 2

∼
L4→L1−L4







De fato encontramos uma linha nula, entretanto na segunda matriz da esquerda


















































0 0

0 0

0 0

−
0

0 0

0 0

−

∼

∼

−

1

0

1

2

1

à direita, já podemos notar que há duas linhas iguais. Assim, a terceira linha é uma

combinação linear das restantes. Temos

89

Logo ,

(1, 2, 1) + 1

1

·

·

(3, 1, 1) = (4, 3, 2).

1

·

(1, 2, 1) + 1

(3, 1, 1)

1

·

−

·

(4, 3, 2) + 0

·

(1, 2, 2) = 0

e assim sendo, esses vetores são linearmente dependentes.

3.5.1 Base de um Espaço Vetorial

Deﬁniremos, agora, o que signiﬁca que um conjunto de vetores gerar um espaço

vetorial.

Deﬁnição: Se um espaço vetorial V tiver todos os seus vetores ~v formados por com-

binações lineares de ~w1, ..., ~wk, então esses vetores ~w1, ..., ~wk geram o espaço V . Logo,
todo ~v = c1 ~w1 + ... + ck ~wk aparece de alguma sequência de c1, ..., ck.

Mas, esse conjunto será o menor possível? Devemos ter uma segunda condição para

termos um conjunto gerador mais reduzido quanto for possível. Esses vetores deveram

ser linearmente independentes.

Para sabermos se o sistema A~x = ~b tem solução possível temos que veriﬁcar se
o espaço coluna gera ~b, para veriﬁcarmos se as colunas são independentes, resolvemos
A~x = ~0. Logo, a geração está relacionada com o espaço coluna e a independência está
relacionada com o espaço nulo.

Agora podemos deﬁnir uma base.

Deﬁnição5: Uma base gerada por vetores possui duas propriedades,

I Os vetores são linearmente independentes. (Não há vetores demais)

II Eles geram o espaço V . (Não faltam vetores)

3.5.2 Dimensão de um Espaço Vetorial

Deﬁnição A dimensão de um espaço vetorial de dimensão ﬁnita e não nulo é o número

de elementos da base desse espaço vetorial.

5Deﬁnição disponível no livro de Álgebra linear e suas aplicações de (Strang. Gilbert, 2010)

90

Por convenção, a dimensão do espaço nulo será 0. Utilizaremos a notação dimV

para representar a dimensão do espaço vetorial V .

Um espaço vetorial possui inﬁnitas bases, porém a algo em comum entre elas.

Teorema 3.9 Se ~w1, ..., ~wn e ~v1, ..., ~vm são bases do mesmo espaço vetorial, então m = n.

Demonstração: Sejam w = ( ~w1, ..., ~wn) e v = (~v1, ..., ~vm) bases de U . Suponha que n > m.
Como v e w geram U temos que

~w1 = a11~v1 + . . . + am1~vm

...

~wn = a1n~v1 + . . . + amn~vm.

Representando W como uma matriz, onde os ~wi são colunas da matriz, temos:

W =

~w1

. . . ~wn

=

h

i

~v1 . . . ~vm
h

i

a11
...
am1

. . . a1n
...
...
. . . amn



·











= V A.

Analisando o sistema A~x = ~0 temos que a matriz A tem mais colunas do que linhas e pelo
Teorema 3.4 teremos pelo menos uma solução especial (diferente do vetor nulo). Como
podemos multiplicar a equação matricial A~x = ~0 por V à esquerda, pois A tem m linhas,
temos:

A~x = ~0.

V A~x = V ~0 = ~0.

Logo, V A~x = ~0 terá uma solução especial (diferente do vetor nulo). Assim, como W =
V A, temos que W ~x = 0 tem uma solução não nula e pode ser representado por x1 ~w1+. . .+
= 0. Portanto, temos que ~w1, . . . , ~wn é linearmente dependente,
xn ~wn = 0 com algum x1 6
n.
m. Utilizando um raciocínio análogo concluímos que m
uma contradição. Logo n

≤

O que nos mostra que n = m.

≤

Esse teorema vai nos garantir que independente da base a dimensão do espaço

vetorial é a mesma.

Exemplo 13: O R3, por exemplo, pode ser formado por duas bases distintas conforme

Figura 15 .

Figura 15: O R3 formado por duas bases diferentes.

91

Fonte: Elaborado pelo autor.

Temos que a dimensão será 3, de ambas as bases, igual à do R3, pois são gerados

por três vetores.

Teorema 3.10 Qualquer conjunto linearmente independente em V pode ser estendido a

uma base, adicionando-se vetores, se necessário.

Demonstração: Suponhamos que a dimensão de V seja n. Seja agora α = ( ~w1, . . . , ~wr)
n, pois caso
um conjunto de vetores linearmente independentes de V . Temos que r

contrário teríamos uma base de V com dimensão maior que n. Se α gera V então r = n
e já temos uma base. Se α não gera V , existe um vetor ~wr+1 ∈
ao espaço gerado por α. Logo, ele é linearmente independente com os vetores da base.

V que não pertence

≤

Portanto temos um novo conjunto de vetores ( ~w1, . . . , ~wr, ~wr+1) que podem ser uma base
para V . Caso esse novo conjunto tenha dimensão n chegamos ao resultado pelo Teorema

3.9. Caso contrário, prosseguimos com o raciocínio até construir a base procurada. Como

a base é ﬁnita, tem n elementos, esse raciocínio é possível.

Esse teorema vai nos dizer que uma base é um conjunto linearmente independente

máximo, ou seja, se esse conjunto é uma base do espaço vetorial V , não conseguimos

colocar nenhum outro vetor de V nessa base e continuar com a independência.

Teorema 3.11 Qualquer conjunto de geradores em V pode se reduzido a uma base,

descartando-se vetores se necessário.

Demonstração: Seja (~v1, . . . , ~vm) geradores de V , com ~v1, . . . , ~vm
V . Então todo ~v
∈
R. Se de a1~v1 + . . . +
pode ser escrito como ~v = a1~v1 + . . . + am~vm, com a1, . . . , am
am~vm = 0 implicar que a1 = a2 = . . . = am = 0, temos que os vetores são linearmente

∈

∈

V

92

independentes e, portanto, formam uma base. Caso contrário teremos que os vetores são

linearmente dependentes. No segundo caso, podemos representar a1~v1 + . . . + am~vm = 0

como

a1 

v11
...
v1n




que podemos representar como um sistema de equações













vm1
...
vmn



+ . . . + am 



= 0



v11
...
v1n

. . . vm1
...
...
. . . vmn

a1
...
am





·



= 

.



0
...
0




Pelo Teorema 3.7 ao escalonarmos a matriz da esquerda encontraremos os pivôs e também





















os vetores linearmente independentes. Temos, também pelo, Teorema 3.9 que essa base

terá exatamente a quantidade de vetores procurados.

Esse teorema nos diz que um conjunto de vetores geradores que formam uma base

é mínimo. Assim, se retirarmos algum vetor, esse novo conjunto não gera mais o espaço

vetorial inicial.

Esse capítulo é muito importante para termos uma compreensão a respeito de siste-

mas lineares com mais de três equações e mais de três incógnitas. Mesmo não conseguindo
representar a ideia de um vetor no R4, a ideia intuitiva continua a mesma.

Aqui temos dois problemas no que diz respeito à abordagem do tema no Ensino

Médio. O primeiro é o tempo, como não faz parte da grade de conteúdos de matemática,

não há como trabalhar por um período muito longo, pois faltaria tempo para abordar

outros temas da grade. O segundo é a complexidade de alguns temas para alunos do

Ensino Médio, teríamos que conhecer a turma previamente para poder avaliar o nível de

aprofundamento do tema.

No capítulo 6 discutiremos um pouco mais a respeito dessas questões.

Fica, ainda, como sugestão a leitura das seguintes obras: Introdução à Álgebra

Linear (Delgado. Jorge; Frensel. Katia; Crissaﬀ. Lhaylla, 2013), Álgebra Linear (Lima. Elon

Lages, 2003) e Álgebra Linear e suas Aplicações (Strang. Gilbert, 2010) que abordam os

temas tratado aqui e serviram como referencial teórico do capítulo.

93

4 DETERMINANTES

Neste capítulo buscaremos resolver um sistema linear de duas equações com duas

incógnitas e encontraremos que as soluções procuradas podem ser representadas como

algo que parece a divisão entre duas “matrizes”. Essas “matrizes” são deﬁnidas como de-

terminantes; assim, iniciamos o estudo dos determinantes, seus conceitos e propriedades.

Descreveremos algumas formas de calcular o determinante e a ideia utilizada no desen-

volvimento de Laplace. Comentaremos sobre algumas aplicações e encerraremos com a

Regra de Cramer que é abordada no início do capítulo.

Retornando a solução dos sistemas A~x = ~b. Buscaremos encontrar a solução do

seguinte sistema:

au + bv = c

du + ev = f.

(4.1)

Podemos resolver o sistema utilizando escalonamento.

a b

d e

D





...
c
... f 


D

∼





da

db

ad

−

ae

−

...
...

dc
af 


−

D

∼





da

0

db

db

−

ae

...
... dc

dc

−

.

af 


Logo, temos

v = −
−
Por retrossubstituição na primeira equação do sistema (4.1), encontramos:

−
−

=

.

v(db

ae) = dc

af

−
af + cd
ae + db

−
af
ae

cd
db

a(db

−

ae)u + bdc

−

abf = c(db

ae)

−

a(db

Se deﬁnirmos que

ae)u =

bdc + abf + cdb

−
u = −

ace + abf
ae)db

a(db

−

−

−
ce + bf
ae + db

cae =
ce
ae

=

ace + abf
bf
db

.

−
−
−

= −
−

D

D

a b

"

d e#

c

b

"

f e#

= ae

bd,

−

= ce

bf

−

(4.2)

(4.3)

94

e

Temos que

D

a c

"

d f #

= af

cd.

−

(4.4)

u =

D

D

c

b

"

f e#

a b

"

d e#

e v =

D

D

a c

"

d f #

.

a b

"

d e#

Se multiplicarmos os elementos da diagonal principal e subtrairmos a multiplicação

dos elementos da outra diagonal chegaremos as igualdades em (4.2), (4.3) e (4.4). Veremos

ao longo do texto que esse é o cálculo do determinante de uma matriz quadrada 2 por 2. Se

analisarmos as soluções u e v, podemos constatar que no denominador das soluções temos

a matriz dos coeﬁcientes do sistema. Já no numerador da solução, temos novamente a
matriz dos coeﬁcientes com uma coluna sendo substituída pela coluna b do sistema A~x = ~b.
Logo, se quisermos achar o valor de u devemos trocar a coluna (a, d) dos coeﬁcientes de

u por (c, f ) e se quisermos encontrar v basta trocar os coeﬁcientes de v (b, e) por (c, f ).

Mas, esse raciocínio sempre funcionará? E o cálculo será sempre uma diagonal menos a

outra? Que condições devemos ter para que se possa utilizar esse método para sistemas

maiores? Para encontrar essas respostas devemos estudar determinantes.

4.1 CONCEITO

Determinantes são funções deﬁnidas com o domínio nas matrizes quadradas e con-

tradomínio nos valores do corpo onde estão deﬁnidos os coeﬁcientes da matriz. Para o

nosso estudo utilizaremos o corpo dos reais. Logo, o determinante transforma uma matriz

quadrada de coeﬁcientes reais em um número real. Porém, quais são os critérios para se

achar esse número real?

Essa função que transforma uma matriz quadrada em um número real deve satis-

fazer três propriedades:

D1 A função D é linear como função de cada linha separadamente.

Exemplo 1:

1 5 1

1

5

1

D 

3 3 5



= D 

1 + 2





1 2 3





1





·

1 1 + 2

2

·

1 1 + 2

3

2



·





1 5 1

1

5

1

1 5 1

1 5 1

95

·
1

·
2

·
3

= D 

1 1 1



+ D 

2

1 2

1 2

2



= D 

1 1 1



+ 2

D 

1 1 2



,

·

1 2 3












ou de forma equivalente, se A1,A2,...,An representam as linhas (vetores linhas) da
matriz A e Ak = A′

n. Então





















k

k + tA′′

k, com 1

1 2 3

1 2 3

≤

≤

= D

A1
A2
A3







D 

















A′

A1
...
k + tA′′
...
A3

k

A1
...
A′
k
...
A3

























= D













+ t

D

·

.

A1
...
A′′
k
...
A3

























D2 Se duas linhas adjacentes de A são iguais, então D(A) = 0.

Exemplo 2:

2 3 4

D 

2 3 4



= 0, pois A1 = A2.





5 6 7





D3 D(In) = 1 onde In é a matriz identidade.

4.2 PROPRIEDADES DOS DETERMINANTES

Teorema 4.1 O determinante muda de sinal quando duas linhas consecutivas são troca-

das.

Demonstração: Seja as matrizes A e A′, tal que







A =

e A′ =













onde os Ai são as linhas das matrizes A e A′, com 1



























A1
...
Ak
Ak+1
...
An

A1
...
Ak+1
Ak
...
An

,
















k < n. Temos que

≤

96

D

Porque

A1
...
Ak
Ak+1
...
An































+ D

A1
...
Ak+1
Ak
...
An































= D

A1
...
Ak

Ak
...
An































+ D

A1
...
Ak
Ak+1
...
An































+ D

A1
...
Ak+1
Ak
...
An































+ D

A1
...
Ak+1
Ak+1
...
An
















.




















D

= 0 e D

= 0,

A1
...
Ak

Ak
...
An





























A1
...
Ak+1
Ak+1
...
An





























pois essas matrizes têm duas linhas iguais. Utilizando a propriedade D1 para uniﬁcar as

duas primeiras matrizes e as duas últimas, temos

D

A1
...
Ak

Ak
...
An































+ D

A1
...
Ak
Ak+1
...
An































+ D

A1
...
Ak+1
Ak
...
An































+ D

A1
...
Ak+1
Ak+1
...
An































+ D

A1
...
Ak+1
Ak + Ak+1
...
An































= D

A + A′

.

h

i

= D

= D

A1
...
Ak
Ak + Ak+1
...
An

A1
...
Ak + Ak+1
Ak + Ak+1
...
An





























































Temos duas linhas iguais e podemos concluir pela propriedade D2 que D

0 , ou de forma equivalente que D

A

=

h

i

−

D

A′

.

h

i

A + A′

=

h

i

Teorema 4.2 Se a matriz A possui duas linhas iguais, então D

A

= 0.

97

Demonstração: Basta fazer trocas entre linhas consecutivas até que as duas linhas iguais
sejam adjacentes. A nova matriz A′ terá D

. Mas, como duas linhas

D

=

A′

A

adjacentes são iguais, dá propriedade D2 temos que D

h

i

h

i

= 0 e portanto, D

A

= 0.

±
A′

h

i

h
Teorema 4.3 O determinante muda de sinal quando duas linhas são trocadas.

i

h

i

Demonstração: Suponhamos que queremos trocar a linha 2 com a linha 5. E vamos
fazendo trocas consecutivas. Trocamos L2 ↔
seguintes trocas:

L4 e L2 ↔

L3, L2 ↔

L5. Temos as

















L1
L2
L3
L4
L5
L6
...
Ln

L1
L3
L2
L4
L5
L6
...
Ln

L1
L3
L4
L2
L5
L6
...
Ln

L1
L3
L4
L5
L2
L6
...
Ln


















Agora colocamos a linha L5 na posição antiga da linha 2. Trocamos L5 ↔































































































































→

→

→

.

L4 e L5 ↔

L3.









→

→

L1
L3
L5
L4
L2
L6
...
Ln





































.

L1
L5
L3
L4
L2
L6
...
Ln







































L1
L3
L4
L5
L2
L6
...
Ln







































−

É importante observar que se utilizarmos n movimentos, no exemplo n = 3, para descer

a primeira linha, vamos utilizar n

1 movimentos para subir a linha que estávamos

trocando. No exemplo utilizamos 2 movimentos para colocar a linha 5 na posição da linha

2, além disso, as outras linhas retornam aos seus lugares. Teremos um número ímpar de

movimentos, 2n

1 movimentos. Temos que cada vez que ﬁzermos um movimento, troca

de linha, o sinal do determinante vai alterar, logo após um número ímpar de troca de
linhas teremos que o determinante da nova matriz A′ será D

D

=

.

A′

A

−

−

h

i

h

i

98

Teorema 4.4 Se somarmos ou subtrairmos o múltiplo de uma linha de outra linha,

obtém-se o mesmo determinante.

Seja

D

A

= D

h

i

A1
A2
A3
...
An

























e D

A′

= D

h

i

A1
A2 + tA3
A3
...
An













.













Mas, de D1 temos

A′

D

= D










Porém, o segundo termo tem duas linhas iguais e portanto,































i

h

+ tD

.









A1
A2
A3
...
An

A1
A3
A3
...
An

logo,

tD

A1
A3
A3
...
An

























0 = 0,

= t

·

D

A′

= D

h

i

A1
A2
A3
...
An

























= D

A

.

h

i

Teorema 4.5 Se A possui uma linha nula, então D

A

= 0.

h

i

Demonstração: Temos que o determinante de A é

99





A1
A2
A3
...
0
...
An

.

D















Se somarmos uma linha qualquer com a linha de valor 0, teremos uma nova matriz
















A′ que possui duas linhas iguais e portanto, D

A′

= 0 pelo Teorema 4.2. Além disso,

teremos que D

A′

= D

A

, pois somamos inicialmente uma linha e o Teorema 4.4

h

i

i
garante que o valor do determinante não se altera. Assim, D

i

h

h

A

= 0.

h

i

Teorema 4.6 Se A for triangular, então o determinante de A é o produto dos elementos

da diagonal principal. Se a matriz triangular A possuir números 1 ao longo da diagonal

principal então D

A

= 1.

h

i

Demonstração: Suponhamos que os elementos da diagonal principal sejam diferentes de
zero, podemos reduzir a matriz A a uma matriz A′ que tem apenas os elementos da
diagonal principal diferentes de zero. Se utilizarmos apenas a soma ou subtração de

múltiplos de outras linhas para fazer essa redução, o Teorema 4.4 nos garante que o valor

do determinante não se altera. Agora podemos utilizar a propriedade D1 e D3 para

encontrarmos o valor do determinante.

a11

a22

. . .

D

A

= D

h

i










= a11a22 · · ·

annD










ann

. . .

= a11D

1










a22

. . .










ann

= a11a22 · · ·

annD

In

h

i

= a11a22 · · ·

ann.










1

1

1










Se tivermos algum elemento da diagonal nulo, acabamos por ter o D

A

= 0 e se

forem todos os elementos da diagonal igual a 1 teremos D

A

= 1.

h

i

h

i

100

Esse teorema nos ensina como calcular o determinante de uma matriz, pois sempre

podemos transformar uma matriz quadrada em uma matriz escalonada U e a partir dessa

matriz U encontrar o valor do determinante de A. Devemos ter cuidado com as trocas de

linhas, pois essas mudam o sinal do determinante.

Teorema 4.7 A matriz A é invertível, se e somente se, o determinante de A é diferente

de zero.

Demonstração: Se a matriz A é invertível, pelo Teorema 2.4, então ela pode ser escalonada

em uma matriz U , triangular, e sua diagonal principal não possui zeros. Consequente-

mente, pelo Teorema 4.6 temos que seu determinante é o produto dos elementos de sua

diagonal principal e portanto o determinante é diferente de zero.

Agora vamos assumir que o determinante de A é diferente de zero. Podemos trans-

formar a matriz A em uma matriz triangular U pelo escalonamento. E, além disso, temos

pelo Teorema 4.6, desde que não sejam trocadas linhas, que os elementos da diagonal de

U são o determinante de A. Logo, D

A

= D

U

ann

= 0 que implica que

= a11a22 · · ·

todos os elementos da diagonal são diferentes de zero e pelo Teorema 2.4 é invertível,

h

i

h

i

portanto A é invertível. Caso seja necessário realizarmos a troca de linhas durante o

escalonamento, teremos D

A

=

o teorema.

h

i

±

D

U

=

h

i

a11a22 · · ·

±

ann

= 0 o que ainda nos garante

Esse teorema nos permite veriﬁcar se uma matriz é invertível sem que haja a

necessidade de fazer o escalonamento. Para isso, basta calcular o determinante.

Teorema 4.8 Se E é uma matriz elementar, então D

EA

= D

E

D

A

.

h

i

h

i

h

i

Demonstração: Dividiremos em três casos:

1o) Seja E1 a matriz elementar obtida a partir de uma troca de linhas sobre a matriz
1 pelo Teorema 4.3 e por E1 ser

Lj). Temos que D

identidade (Li

=

E1

↔

−

h

i

originalmente a identidade. Temos, também, que D

, pois E1 vai
realizar uma troca de linhas sobre A e pelo Teorema 4.3 vamos ter a troca de sinal

E1A
i

D

−

=

A

i

h

h

do determinante. Portanto, D

E1A

=

D

A

=

1D

A

= D

E1

D

A

.

−

−

i
2o) Seja E2 a matriz obtida através da operação elementar Li

i

h

h

i

h

i

h
h
Li + tLj sobre a

i

→

identidade. Temos do Teorema 4.4 que a operação Li

Li + tLj não altera o valor
= 1, porque E2 era originalmente a identidade.

→

do determinante. Assim, D

E2

Temos ainda que D

E2A
i

h

h
i
= D

A

, uma vez que E2 vai somar um múltiplo de

h

i

6
6
uma linha a outra e pelo Teorema 4.4 não altera o valor do determinante. Logo,

D

E2A

= D

A

= 1D

A

= D

E2

D

A

.

101

i

i

h

i

h

h

i

h
3o) Seja E3 uma matriz elementar correspondente a operação elementar Li
In

bLi.
= b, pois E3 era a matriz identidade ini-
cialmente. Temos, também, que E3 é semelhante a uma multiplicação por b na
. Logo, de 1o, 2o e 3o temos que
= bD
linha i e por D1 temos que D

Temos de D1 que D

= bD

E3

→

h

i

i

h

i

h

A

D

EA

= D

E

D

A

.

h

h

i

h

i

h

i

E3A
i

h

i

Teorema 4.9 O determinante de AB é igual ao produto do determinante de A pelo

determinante de B.

D

AB

= D

A

h

i

h

i

·

D

B

.

h

i

Desmonstração: Se A não é invertível, pelo Teorema 4.7 temos D

A

= 0 e D

AB

= 0,

pois AB não é invertível. Portanto D

AB

= D

A

D

B

= 0.

h

i

h

Se A é invertível, temos do Teorema 2.5 que A = E1 . . . Ek onde Ei, com 1
i

h

h

h

i

i

são matrizes elementares. E do Teorema 4.8 temos que

i

i

≤

k,

≤

D

AB

= D

E1 . . . EkB

= D

E1

D

E2 . . . EkB

= D

E1

. . . D

Ek

D

B

h

i

h

= D

E1 . . . Ek

i
D

B

i
h
= D

h

D

A

B

.

i

h

i

h

i

h

i

i
Corolário 4.1 O determinante da inversa de A é igual ao inverso do determinante de

h

h

i

i

i

h

h

A.

D

A−1

=

h

i

1

.

D

A

h

i

Demonstração: Temos pelo Teorema 4.9 que

Consequentemente,

D

A−1

h

·

i

D

A

= D

A−1

h

i

h

·

A

= D

In

= 1.

i

h

i

D

A−1

=

h

i

1

.

D

A

h

i

Teorema 4.10 Seja E uma matriz elementar. Então D

E

= D

ET

.

h
Demonstração: Dividiremos a demonstração em três casos:
1o) Seja E1 a matriz gerada pela troca de duas linhas da matriz identidade. Logo Li

i

i

h

Lj

↔

102

nos dá E1.

. . .

111

















= E1.

1ii = a

. . .

1jj = b

. . .

1nn

111

. . .


















→


















1ij = b

. . .

1ji = a


















. . .

1nn

Temos que ET

1 é

111

. . .

ET

1 =


















1ij = a

. . .

1ji = b

.


















. . .

1nn

Logo, ET

1 é equivalente a uma matriz identidade após uma troca de linhas ( Li

Lj),

↔

pois a = b = 1. Portanto, D

E1

=

1 devido a troca de linhas e pelo Teorema 4.6.

1, pois também é equivalente a uma troca de linhas sobre a matriz

Temos que D

ET
1

=

−

i
identidade. Assim chegamos que D

h

−

h

i

E1

=

h

i

−

1 = D

ET
1

.

h

i

2o) Seja E2 uma matriz elementar na qual ﬁzemos a operação Li
identidade. Logo,

→

Li + tLj sobre a

111

. . .


















1ii

. . .

1jj

. . .

111

. . .


















→


















1nn

1ii

. . .
. . .

t1jj

1jj

= E2


















. . .

1nn

103

.

e temos que ET

2 é

111



. . .



ET

2 =
















1ii
...
1jj

. . .

1jj

. . .

1nn
















E2 e ET
cipais. Pelo Teorema 4.6 temos que D

2 são matrizes triangulares e, assim, seus determinantes são suas diagonais prin-
= 1 o que nos dá que

= 1 e D

E2

ET
2

D

E2

= D

ET
2

.

h

i

h

i

h

i

h

i

3o) Seja E3 uma matriz elementar equivalente a matriz identidade que sofreu a seguinte
operação elementar Li

bLi.

→

111



. . .



1ii










Temos que sua matriz transposta será











. . .

1nn

111

. . .

→













b1ii

. . .

= E3.













1nn

111

. . .

ET

3 =













b1ii

. . .

.













1nn

Logo, E3 = ET

3 o que implica que D

E3

= D

ET
3

. Assim, por 1o, 2o e 3o temos

D

E

= D

ET

.

h

i

h

i

h

i

h

i

Teorema 4.11 A matriz A possui o mesmo determinante que sua matriz transposta.

D

A

= D

AT

.

h

i

h

i

Demonstração: Se A for invertível, temos que A pode ser escrita como um produto de ma-
trizes elementares, A = E1 . . . EK, conforme o Teorema 2.5. Logo, AT = (E1 . . . EK)T =

104

ET

k . . . ET

1 . Pelo teorema anterior temos que D

ET
k

= D

Ek

, . . . , D

ET
1

= D

E1

.

Logo, D

AT

= D

ET
k

. . . D

ET
1

= D

Ek

h
i
. . . D

E1

h
i
e como o determinante é um

i

i

h

h

i
número, vale a propriedade comutativa. Temos, então, que

h

h

i

i

h

h

i

i

h

D

AT

= D

Ek

. . . D

E1

= D

E1

. . . D

Ek

= D

A

.

i
Se a A não for invertível, teremos D

h

i

h

h

i

i

h
= 0 e que após o escalonamento terá uma

h

i

i

h

A

h
linha nula. Como o número de pivôs nos dizem quantas linhas e colunas são linearmente

i

independentes, temos n linhas e n colunas, teremos, pelo menos, que A terá uma coluna
que é combinação das outras. Logo AT terá uma linha nula quando escalonada, portanto

seu determinante será D

AT

= 0.

h

i

Teorema 4.12 O determinante muda de sinal quando duas colunas são trocadas.

Demonstração: Seja a matriz An e seu determinante

D

A

= D

C1

. . . Ci

. . . Cj

. . . Cn

h

i

h

,

i

com 1

i < j

n.

≤
Pelo Teorema 4.11, temos que D

≤

A

= D

AT

, então

h



h



i
C1
...
Ci
...
Cj
...
Cn





i
C1
...
Cj
...
Ci
...
Cn

T

A

D

=D















Como trocamos a linha Cj pela linha Ci, temos que o determinante muda de sinal pelo














































D

−

=

i

h

.

Teorema 4.3. Logo, temos que

D

A

= D

AT

= D

h

i

h

i

C1
...
Ci
...
Cj
...
Cn



































=

D

−

T

=

−

C1
...
Cj
...
Ci
...
Cn



































D

C1

. . . Cj

. . . Ci

. . . Cn

h

i

que é o que queríamos demonstrar.

4.3 MÉTODOS PARA CALCULAR O VALOR DO DETERMINANTE

Agora que já temos uma ideia de como comporta-se o determinante, devemos bus-

105

car meios de calcular o seu valor.

1o Método - Escalonamento

Se A for invertível então pelo Teorema 4.6, se transformarmos A em U , teremos

que o determinante será a diagonal principal de U . Claro que devemos tomar cuidado

quando ﬁzermos uma troca entre linhas, pois isso alterará o sinal do determinante. Se A

não for invertível D

A

= 0.

i
2o Método - Desenvolvimento de Laplace

h

Matriz 2 por 2

Poderíamos utilizar o escalonamento para encontrar uma outra forma para calcular

o determinante de uma matriz 2 por 2. Mas, vamos utilizar nosso conhecimento sobre

matrizes e propriedades dos determinantes para encontrar o valor procurado. Buscaremos,

ainda, outro método que possa ser aplicado para matrizes, independente da ordem.

Vamos começar transformando a matriz 2 por 2 em uma soma de duas outras

matrizes. Utilizando a propriedade D1 na primeira linha temos:

D

a b

"

c d#

= D

a 0

"

c d#

+ D

0 b

"

c d#

.

O nosso objetivo foi transformar a matriz em uma soma de matrizes triangulares. Sa-

bemos, pois, que a diagonal principal de uma matriz triangular nos fornece o valor do

determinante pelo Teorema 4.6. Portanto, podemos encontrar o valor do determinante

assim que ﬁzermos uma alteração na segunda matriz da soma. Temos que

D

a 0

"

c d#

= ad e D

0 b

"

c d#

=

D

−

c d

"

0 b#

=

cb.

−

Quando trocamos a posição das linhas da segunda matriz, trocamos também o sinal do

106

determinante. Assim, chegamos que

D

a b

"

c d#

= ad

cb.

−

Matriz 3 por 3

Podemos, também, fazer um raciocínio semelhante para encontrar o determinante

de uma matriz 3 por 3. Vamos inicialmente aplicar a propriedade D1 na primeira linha:

D 

a11 a12 a13
a21 a22 a23
a31 a32 a33



= D 



+ D 



+ D 

0

0

a11
a21 a22 a23
a31 a32 a33

0

0

a12
a21 a22 a23
a31 a32 a33

0

0

a13
a21 a22 a23
a31 a32 a33

.













Agora vamos analisar cada uma das três novas determinantes que devemos calcular.





















0

0

a11
a21 a22 a23
a31 a32 a33

.







D 





Podemos utilizar a11 para zerar os elementos que estão abaixo dele. Pelo Teorema 4.4 o

valor do determinante não se altera.

0

0

a11
a21 a22 a23
a31 a32 a33

a11

0

0

0

0

a22 a23
a32 a33



= a11D 









1

0

0

0 a22 a23
0 a32 a33

.









= D 









D 





Utilizamos a propriedade D1 para tirar a11 para fora do determinante. Como devemos

escalonar a segunda e terceira linhas, temos que

1

0

0

0 a22 a23
0 a32 a33





D 







= D

a22 a23
a32 a33#

,

"

pois o fator 1 no primeiro pivô não alterará o valor do determinante. Logo,

a11

0

0

0

0

a22 a23
a32 a33







D 





= a11D

a22 a23
a32 a33#

"

= a11(a22a33 −

a23a32) = a11a22a33 −

a11a23a32.

107

a22 a23
a32 a33#

"

= a11a22a33 −

a11a23a32.

(4.5)

Consequentemente, temos que

0

0

a11
a21 a22 a23
a31 a32 a33





D 







= a11D

Agora, analisando o segundo termo da soma, temos:

0

0

a12
a21 a22 a23
a31 a32 a33

C2↔C1



=

D 

−

0

0

a12
a22 a21 a23
a32 a31 a33















D 





que pelo Teorema 4.12 ao trocarmos duas colunas de posições alteramos apenas o sinal

do determinante. Utilizando um raciocínio semelhante ao anterior temos:



=

D 

−

a12

0

0

0

0

a21 a23
a31 a33

a12

0

0

0

0

a21 a23
a31 a33









=

D 

−













0

0

a12
a21 a22 a23
a33 a32 a33

D 











=

D 

−





0

0

a12
a22 a21 a23
a33 a31 a33




0

1

0

0 a21 a23
0 a31 a33





=

=

−

−

a12D 




a12(a21a3 −

a12D



−

a21 a23
a31 a33#

"

a23a31) =

a12a21a33 + a12a23a31.

−

Assim,

D 

0

0

a12
a21 a22 a23
a31 a32 a33









Analisando, agora, o último termo, temos:



=

a12D

−

a21 a23
a31 a33#

"

=

−

a12a21a33 + a12a23a31.

(4.6)

0

0

a13
a21 a22 a23
a31 a32 a33

C3↔C1



=

D 

−

0

0

a13
a23 a22 a21
a33 a32 a31









C3↔C2



= D 









0

0

a13
a23 a21 a22
a33 a31 a32

.







D 





Como trocamos duas colunas de posições, duas vezes, alternamos o sinal do deter-

minante duas vezes também. O que nos deixou com o sinal inicial. Procedendo como nos

casos anteriores, temos:

108

D 





Logo,

0

0

a13
a23 a21 a22
a33 a31 a32







= D 

0



= a13D 



= a13D

a13

0

0

a21 a22
a31 a32





0



= a13(a21a32 −

1

0

0

0 a21 a22
0 a31 a32









a31a22) = a13a21a32 −

a13a31a2.

a21 a22
a31 a32#

"

0

0

a13
a21 a22 a23
a31 a32 a33





D 





De (4.5), (4.6) e (4.7) temos que



= a13D

a21 a22
a31 a32#

"

= a13a21a32 −

a13a31a2.

(4.7)

a11 a12 a13
a21 a22 a23
a31 a32 a33







D 





0

0

a11
a21 a22 a23
a31 a32 a33



+ D 









= D 




= a11D

a22 a23
a32 a33# −

a21 a23
a31 a33#
= a11a22a33 + a12a23a31 + a13a21a32 −

a12D

"

"

0

0

a12
a21 a22 a23
a31 a32 a33

0

0

a13
a21 a22 a23
a31 a32 a33









+ D 




+ a13D




a21 a22
a31 a32#

"

a13a22a31 −

a11a23a32 −

a12a21a33.

O que nos dá a regra ensinada no Ensino Médio,

+
a11



+
a12

+
a13

a11

a12



D

a21

a22

a21

a23

a22

a31

a32

a31

a33





















= a11a22a33 + a12a23a31 + a13a21a32 −

a32

−

−

−

a13a22a31 −

a11a23a32 −

a12a21a33.

Adicionamos a multiplicação dos elementos das diagonais que partem da parte su-

perior para a direita e subtraímos a multiplicação dos elementos das diagonais que partem

da parte superior para a esquerda, sempre com três elementos. Essa regra é chamada de

Regra de Sarrus.

Matriz n por n

O método para matrizes 3 por 3 sugere que podemos transformar o cálculo do

determinante de uma matriz n por n em uma soma de determinantes de matrizes n

por n

1. Vamos, então, analisar uma matriz n por n.

Seja a matriz An, aplicando a propriedade D1, temos:

−

109

1

−



D

a11
a21
...
an1

. . . a1n
. . . a2n
...
...
. . . ann







Para a primeira matriz temos:








D1



=D

D

a11
a21
...
an1










. . .

0

. . . a2n
...
...
. . . ann










= D

0

0

0










= a11D 

a11
a21
...
an1










. . .

0

. . . a2n
...
...
. . . ann










+ . . . + D

0

a21
...
an1










. . . a1n
. . . a2n
...
...
. . . ann

.










a11

0

. . .

0

1

0

. . .

0

a22
...
an2

. . . a2n
...
...
. . . ann










= a11D

0 a22
...
0 an2

0










. . . a2n
...
...
. . . ann










a22
...
an2

. . . a2n
...
...
. . . ann

.











Utilizamos a11 para zerar os termos abaixo dele. Ficamos com a11 multiplicando

uma matriz quadrada n

1 por n

1, pois tiramos a primeira linha e a primeira coluna,

uma vez que não inﬂuenciaram no resultado do determinante.

−

−

Vamos, agora, dividir em dois casos, colunas de índice par ou colunas de índice

ímpar. Utilizaremos a seguinte notação: A(i

j) para representar a matriz (n

|

obtida de A suprimindo-se a i-ésima linha e a j-ésima coluna.

1)

−

×

(n

−

1),

Caso par j = 2k

Seja a matriz A′

n conforme abaixo

110

. . . a1j
...
...
. . . ajj
...
...
. . . anj

D

0
...
aj1
...
an1













0

. . .
...
. . . ajn
...
. . . ann













= D

C1

. . . Cj

. . . Cn

h

i

0

. . .
...
. . . ajn
...
. . . ann













0
...
aj1
...
an1

. . . a1j
...
...
. . .
0
...
...
. . .
0

C1
...
Cj
...
Cn

.













= D

T

= D

























Como não queremos alterar a ordem das demais linhas, vamos permutando a linha

Cj pela linha adjacente, até que ela esteja na primeira linha. Lembrando que cada vez

que permutarmos uma linha, vamos trocar o sinal do determinante. Como vamos fazer

j

1 permutações, que é um número ímpar, já que j é par, o determinante trocará de

−

sinal. Logo, temos:

D

C1
...
Cj
...
Cn

























=

D

−

=

D

−

































Cj
C1
...
Cj−1
Cj+1
...
Cn

a1j



T

=















0

D

−

h

Cj C1

. . . Cj−1 Cj+1

. . . Cn

i

. . .

0

0

. . .

0

0
...
0
...
0

a21
...
aj1
...
an1

...

. . . a2(j−1) a2(j+1)
...
...
. . . aj(j−1) aj(j+1)
...
...
. . . an(j−1) an(j+1)

...

. . . a2n
...
. . . ajn
...
. . . ann
















=

−

a1jD

A(1

h

.

j)

|

i

Como A(1

|

j) não tem a linha 1 e nem a coluna j, temos que ela é uma matriz n

1 por n

1.

−

−

111

0

. . .
...
. . . ajn
...
. . . ann













= D

C1

. . . Cj

. . . Cn

h

i

Caso ímpar j = 2k + 1

Seja a matriz A′

n conforme abaixo

. . . a1j
...
...
. . . ajj
...
...
. . . anj

D

0
...
aj1
...
an1













0

. . .
...
. . . ajn
...
. . . ann













= D

T

= D

0
...
aj1
...
an1

. . . a1j
...
...
. . .
0
...
...
. . .
0

























C1
...
Cj
...
Cn

.













Novamente não queremos alterar a ordem das demais linhas. Assim, permutaremos

a linha Cj pela sua adjacente até que ela esteja na primeira posição. Como vamos fazer

j

1 permutações, que é um número par, já que j é ímpar, o determinante não trocará

−

de sinal. Logo, temos:

D

C1
...
Cj
...
Cn

























= D

= D

Cj
C1
...
Cj−1
Cj+1
...
Cn

a1j



D















0

0
...
0
...
0

a21
...
aj1
...
an1

































T

=D

h

Cj C1

. . . Cj−1 Cj+1

. . . Cn

i

. . .

0

0

. . .

0

...

. . . a2(j−1) a2(j+1)
...
...
. . . aj(j−1) aj(j+1)
...
...
. . . an(j−1) an(j+1)

...

. . . a2n
...
. . . ajn
...
. . . ann
















= a1jD

A(1

h

.

j)

|

i

j) não tem a linha 1 e nem a coluna j, temos que ela é uma matriz n

1 por

−

Como A(1

1.

n

−

|

112

Podemos, ainda, representar essas situações por meio de uma linguagem mais

reduzida. Temos

que quando j for par teremos

onde A(1

|

j) é uma matriz n

−

−

1)1+ja1jD

(

−

A(1

j)

|

h

i

a1jD
1 por n

h

|
1. Assim

i

−

A(1

j)

e quando j for ímpar teremos que a1jD

A(1

j)

|

,

i

h

n

D

A

=

h

i

j=1
X

1)1+ja1jD

(

−

A(1

j)

|

.

i

h

Caso quisermos em vez de separar pela primeira linha, separar pela primeira coluna.

Será que é possível? A resposta é sim, pois temos que D

A

= D

AT

. Logo,

h

i

h

i

a11
...
an1

a11
...
a1n

D 





T

= D 





= a11A(1

= a11A(1

|

|

. . . a1n
...
...
. . . ann

. . . an1
...
...
. . . ann









D1

=D



a11
a12
...



a1n



2)T + . . .




a21A(1

1)T

1)

−

−
a21A(2

|
1) + . . .

|

±

+ . . . + D

. . .

0



. . . an2
...
...
. . . ann







an1A(1
|
1).

±
an1A(n

|

n)T

0

a12
...
a1n










. . . an1
. . . an2
...
...
. . . ann










Assim, o resultado será o mesmo, independente de escolhermos utilizar a 1a linha ou a 1a

coluna. Mas, será que podemos escolher qualquer linha ou qualquer coluna? Novamente

a resposta é sim. O próximo teorema vai nos garantir isso.

Teorema 4.13 O determinante de uma matriz quadrada A, será igual a

n

D

A

=

h

i

j=1
X

1)i+jaijD

(

−

quando ﬁxarmos uma linha ou

n

D

A

=

h

i

i=1
X

1)i+jaijD

(

−

quando ﬁxarmos uma coluna.

A(i

j)

|

A(i

j)

|

h

h

i

i

Demonstração: Seja A uma matriz quadrada. Logo, temos que seu determinante será

113

D

A

= D

h

i

. . . a1j
...
...
. . . aij
...
...
. . . anj

a11
...
ai1
...
an1













. . . a1n
...
...
. . . ain
...
...
. . . ann













1)(i−1)D

= (

−

ai1
a11
...
a(i−1)1
a(i+1)1
...
an1

. . .

aij
a1j
...

. . .
...
. . . a(i−1)j
. . . a(i+1)j
...
. . .

...
anj

. . .

ain
a1n
...

. . .
...
. . . a(i−1)n
. . . a(i+1)n
...
. . .

...
ann


















.


















1 mudanças no
−
1)(i−1). Aplicando a propriedade

Como colocamos a i-ésima linha na posição da primeira linha tivemos i

sinal do determinante que pode ser representado por (

D1 na nova primeira linha, temos

−

j)

A(i
|

n

=

i

j=1
X

1)(i−1)(

(

−

−

1)1+jaijD

A(i

j)

|

h

i

1)(i−1)

n

(

−

j=1
X
1)i+jaijD

1)1+jaijD

h

,

A(i

j)

|

h

i

D

A

= (

h

i

−

n

=

(

−

j=1
X

logo,

pois já vimos que

n

D

A

=

h

i

j=1
X

1)i+jaijD

(

−

A(i

j)

|

,

i

h

ai1
a11
...
a(i−1)1
a(i+1)1
...
an1

. . .

aij
a1j
...

. . .
...
. . . a(i−1)j
. . . a(i+1)j
...
. . .

...
anj

. . .

ain
a1n
...

. . .
...
. . . a(i−1)n
. . . a(i+1)n
...
. . .

...
ann


















D


















n

=

j=1
X

1)1+jaijD

(

−

j)

A(i
|

.

i

h

De modo análogo, ﬁxando-se uma coluna, demonstra-se que

n

D

A

=

h

i

i=1
X

1)i+jaijD

(

−

A(i

j)

|

.

i

h

114

Exemplo 3:

D

A

= D

h

i

2

1



3 0

2 0

1

3



2 4 3

1 0

−
3








1

−
5








2 3 1

= 3D 

1 2 3



= 3





3 1 5





21 = 63.

·

Foi escolhida, a terceira coluna para aplicar o teorema tendo em vista a quantidade

de zeros. Assim, os outros três determinantes que deveriam aparecer são multiplicados

pelos zeros da terceira coluna, fazendo com que não inﬂuenciem no valor do determinante.

Deﬁnição: Deﬁne-se o cofator do termo aij de uma matriz quadrada A como

∆ij(A) = (

1)i+jD

−

A(i

j)

|

.

i

h

A matriz formada por esses cofatores será chamada de matriz dos cofatores de A.

E sua transposta será chamada de matriz adjunta de A.

4.3.1 Algumas Aplicações

Colinearidade

Podemos utilizar o determinante para veriﬁcar se três pontos no plano são coline-

ares.

Seja A = (x0, y0), B = (x1, y1) e C = (x2, y2). Vamos construir a seguinte matriz

e assumir que seu determinante é zero.

x0 y0 1
x1 y1 1
x2 y2 1

D 





Calculando seu determinante, encontramos:

= 0.







(4.8)

x0y1 + x1y2 + x2y0 −

x2y1 −

x1y0 −

x0y2 = 0.

Reorganizando a equação, chegamos a:

x1y2 −

x1y0 −

x0y2 = x2y1 −

x2y0 −

x0y1.

115

Acrescentando x0y0 aos dois lados da igualdade, ﬁcamos com:

x1y2 −

x1y0 −

x0y2 + x0y0 = x2y1 −

x2y0 −

x0y1 + x0y0,

que é equivalente a

(x1 −
= x0, chegamos a

x0)(y2 −

y0) = (x2 −

x0)(y1 −

y0).

Para x1 6

= x0 e x2 6

y0
x0
x1−x0 representa a inclinação da reta que passa pelos pontos A e B e y2−y0
x2−x0
representa a inclinação da reta que passa pelos pontos A e C. Como temos o ponto A em

Temos y1−y0

y2 −
x2 −

y1 −
x1 −

y0
x0

=

.

comum, podemos aﬁrmar que os pontos são colineares.

Dados três pontos colineares. Se montarmos o determinante conforma (4.8), te-

remos que o determinante será zero, ou seja, o determinante de três pontos colineares é
x1−x0 = y2−y0
igual a zero. Para chegar a esse resultado devemos assumir a igualdade y1−y0
x2−x0 ,
com x1 6

= x0, que nos fornece após algumas operações que

= x0 e x2 6

x0y1 + x1y2 + x2y0 −

x2y1 −

x1y0 −

x0y2 = 0,

que é o determinante da matriz

D 



= 0.

x0 y0 1
x1 y1 1
x2 y2 1




Exemplo 4: Vamos veriﬁcar se os pontos (1, 2), (2, 3) e (3, 4) são colineares.





Solução: Basta veriﬁcar se o determinante da matriz

1 2 1

D 

2 3 1



,





3 4 1





é igual a zero. Temos que

1 2 1

D 

2 3 1



= 3 + 6 + 8

Logo, os pontos são colineares.





3 4 1





4

9

−

−

−

4 = 0.

116

Exemplo 5: Podemos utilizar o determinante para encontrar a reta que passa por dois

pontos no plano. Vamos encontrar a reta que passa pelos pontos A = (1,

1) e B =

(

3, 4). Para isso vamos utilizar um terceiro ponto C = (x, y) e utilizar o fato de que eles

−
são colineares. Assim, basta calcularmos o determinante abaixo:

−

1

3

−
x

D 





1 1

−
4

y

1





1



= 4

x

3y

4x

y

−

−

−

−

−

3 =

5x

−

−

4y + 1 = 0.

Portanto, a equação da reta procurada é

4y + 1 = 0. Mas e se trocarmos alguma

5x

−

−

linha do determinante. Será que teremos o mesmo resultado? Quando trocamos alguma

linha no determinante, alteramos apenas o sinal. Vamos encontrar como solução a equa-

ção 5x + 4y

−

1 = 0 que representa a mesma reta.

Cálculo da Área de um Triângulo no Plano Cartesiano

Vamos encontrar uma fórmula para calcular a área de um triângulo representado

no plano cartesiano.

Figura 16: Triângulo representado no plano cartesiano.

Fonte: Elaborado pelo autor.

Para encontrarmos a área do triângulo representado na Figura 16, vamos utilizar

a seguinte fórmula:

AT =

d(A, C)

2

h

,

·

com d(A, C) sendo a distância entre os pontos A e C.

Temos que h é a distância do ponto B até a reta r que passa por A e C. Dado por

d(B, r) = |

ax0 + by0 −
√a2 + b2

c

.

|

Vamos encontrar a equação da reta r, utilizando determinante.

117

D 

a1 a2 1
c1
c2 1
y
x

1








Logo, r : (a2 −



= a1c2+c1y+a2x

c2x

a1y

c1a2 = (a2−

c2)x+(c1−

a1)y+a1c2−

−

−

−

a2c1 = 0.

c2)x + (c1 −

a1)y + a1c2 −
(a2 −

h = d(P, r) = |

a2c1 = 0. Temos, então:

c2)b1 + (c1 −
(a2 −

c2)2 + (c1 −

a1)2

a1)b2 + a1c2 −

a2c1|

.

Como

p

d(A, C) =

(c2 −

a2)2 + (c1 −

a1)2 =

(a2 −

c2)2 + (c1 −

a1)2.

Temos que

p

p

a1)b2 + a1c2 −

a2c1|

AT =

d(A, C)

h

d(A, C)

·

=

(a2 −

· |

2
(a2 −
a2b1 −

= |

= |

=

D

"

1
2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

c2)b1 + (c1 −
d(A, C)
·
a2c1|
a2c1|

2
a1)b2 + a1c2 −
c2)b1 + (c1 −
2
a1b2 + a1c2 −
b1c2 + b2c1 −
2
a2
a2# (cid:12)
(cid:12)
(cid:12)
#    »
(cid:12)
(cid:12)
AC = ~v que nos dá:

b1 −
b2 −
c1 −
c2 −
#    »
AB = ~u e

a1
a1

.

Aqui podemos pensar em

com ~u = (u1, u2) e ~v = (v1, v2)

AT =

,

D

"

1
2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

u1 u2
v1

v2# (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Exemplo 6: Calcule a área do triângulo de vértices A = (1, 1), B = (3, 2) e C = (2, 5).

Solução: Vamos primeiro representar os vetores:

e

#    »
AB = ~u = (3

1, 2

−

−

1) = (2, 1),

#    »
AC = ~v = (2

1, 5

−

−

1) = (1, 4).

118

Agora só basta calcular o determinante e encontrar a área procurada.

AT =

D

"

1
2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 1

1 4# (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

do paralelogramo.

=

1
2 · |

2

·

4

1

1

|

·

−

=

1
2 · |

8

=

1

|

−

7
2

.

Podemos utilizar a fórmula da área do triângulo para encontrar a fórmula da área

Figura 17: Paralelogramo dividido em dois triângulos congruentes.

Fonte: Elaborado pelo autor.

Repare que a área do paralelogramo é igual a duas vezes a área do triângulo

ABC. Pois os triângulos ABC e BDC são congruentes pelo caso LLL. Assim a área do

paralelogramo será:

com ~u = (b1 −

a1, b2 −

·

D

AP = 2

1
2 · (cid:12)
(cid:12)
(cid:12)
a2) e ~v = (c1 −
(cid:12)
(cid:12)

=

u1 u2
v1
"
a1, c2 −

v2# (cid:12)
(cid:12)
(cid:12)
a2).
(cid:12)
(cid:12)

,

u1 u2
v1

v2# (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

D

"

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Volume do Paralelepípedo

Também podemos utilizar o determinante para calcular o volume do paralelepípedo

P que tem os segmentos AB, AC e AD como arestas adjacentes.

Sejam A = (x1, y1, z1), B = (x2, y2, z2), C = (x3, y3, z3) e D = (x4, y4, z4). Temos

que

~u =

~v =

~w =

#    »
AB = (x2 −
#    »
AC = (x3 −
#    »
AB = (x4 −

x1, y2 −
x1, y3 −
x1, y4 −

y1, z2 −
y1, z3 −
y1, z4 −

z1) = (u1, u2, u3),

z1) = (v1, v2, v3),

z1) = (w1, w2, w3).

119

.

O volume1 pode ser calculado por

V ol(P ) =

D 

u1 u2 u3
v1
v3
v2
w1 w2 w3



(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)




Exemplo 7: Calcule o volume do paralelepípedo que tem os segmentos AB, AC e AD





como arestas adjacentes. Com A = (1, 0, 0), B = (2, 0, 2), C = (3, 1, 0) e D = (4, 1, 2).

Solução: Vamos começar encontrando os vetores ~u, ~v e ~w. Logo,

~u = (2

~v = (3

~w = (4

1, 0

1, 1

1, 1

−

−

−

−

−

−

0, 2

0, 0

0, 2

−

−

−

0) = (1, 0, 2),

0) = (2, 1, 0),

0) = (3, 1, 2).

Vamos agora calcular o determinante gerado por esses vetores

1 0 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Podemos aplicar o desenvolvimento de Laplane na segunda coluna que nos fornece

3 1 0









(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

V ol(P ) =

D 

2 1 0



.

V ol(P ) =

=

D

0

·

6 + 4

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
| −
(cid:12)

4.4 REGRA DE CRAMER

2 0

3 0#
"
=

| −

|

+ 1

D

·

= 2.

2

|

1 2
3 0# −

"

D

1

·

1 2

"

2 0# (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Retornemos, agora, ao início do capítulo. Uma vez que já sabemos como se com-

portam os determinantes, somos capazes de demonstrar o seguinte teorema.

Teorema 4.14 Seja A~x = ~b um sistema linear n por n. Seja D
tem solução única dada por

A

= 0, então o sistema

h

i

xj =

,

D
Bj
h
iD
A
i
h

1A demonstração da fórmula do volume do paralelepípedo pode ser encontrado no anexo B.

6
120

com

D

Bj

= D 

h

i





a11
...
an1

. . . a1(j−1)
...
. . . an(j−1)

...

b1 a1(j+1)
...
bn an(j+1)

...

. . . a1n
...
...
. . . ann







e b substituindo a coluna j de A.

Demonstração: Como D
= 0, a matriz A é invertível pelo Teorema 4.7. Logo, o
sistema A~x = ~b tem uma única solução que é dada por ~x = A−1~b, uma vez que a matriz
A−1 é única pelo Teorema 2.2. Temos do sistema A~x = ~b que

A

i

h

~b = A~x =

. . . ~vn

~v1
h

x1
...
xn













·

i

= ~v1x1 + . . . + ~vnxn,

onde ~vi, com 1

i

≤

≤

n, são os vetores coluna de A. Logo D

Bj

h

i

a11
...
an1

. . . a1(j−1)
...
. . . an(j−1)

...

b1 a1(j+1)
...
bn an(j+1)

...

. . . a1n
...
...
. . . ann

= D 





como ~b = ~v1x1 + . . . + ~vnxn, temos

= D

~v1
h







. . . ~vj−1

~b ~vj+1

. . . ~vn

,

i

D

Bj

= D

h

i

= D

~v1
h
~v1
h

. . . ~vj−1

~b ~vj+1

. . . ~vn

. . . ~vj−1 ~v1x1 + . . . + ~vnxn ~vj+1

i

. . . ~vn

i

que pela propriedade D1 pode ser reescrito como

D

Bj

= x1D

. . . ~vj−1 ~v1 ~vj+1

. . . ~vn

h

i

+ . . . + xjD

~v1
h

+ . . . + xnD

. . . ~vj−1 ~vj ~vj+1

. . . ~vj−1 ~vn ~vj+1

~v1
h

~v1
h

i

. . . ~vn

i
. . . ~vn

.

i

Todo determinante que tiver duas colunas iguais, terá seu determinante igual a

zero, pois sua matriz transposta terá duas linhas iguais e, pelo Teorema 4.2, terá seu

determinante igual a zero. Logo, o que nos resta é

D

Bj

= xjD

h

i

~vj
h

. . . ~vj−1 ~vj ~vj+1

. . . ~vn

= xjD

A

.

i

h

i

6
121

que nos fornece

que é a igualdade que buscávamos.

xj =

.

D
Bj
iD
h
A
i
h

Nesse capítulo, novamente, iniciamos com a busca por uma solução para um sis-

tema linear. A partir dessa necessidade de encontrar a solução, conseguimos mostrar a

importância do estudo sobre determinantes. Para o Ensino Médio torna-se mais interes-

sante praticar o cálculo do determinante em si, mas também podemos abordar alguns

teoremas como propriedades e utilizar estas propriedades para chegar-se a outras. Abor-

dando, assim, o raciocínio lógico sem se aprofundar demais no tema.

Fica como sugestão a leitura das obras: Introdução à Álgebra Linear (Hefez. Abramo;

Fernandez. Cecília S, 2016), Álgebra Linear (Lima. Elon Lages, 2003) e Álgebra Linear e suas

Aplicações (Strang. Gilbert, 2010) que serviram como referencial teórico deste capítulo.

122

123

5 APLICAÇÕES

Neste capítulo apresentaremos aplicações para os temas: sistemas lineares e ma-

trizes. Abordaremos sobre resolução de sistemas lineares na economia e na nutrição. Em

seguida comentaremos sobre a importância da teoria de matrizes aplicada na computação

gráﬁca e em imagens digitais.

5.1 SISTEMAS LINEARES NA ECONOMIA

Na introdução desta dissertação comentamos a respeito do sistema de 500 equações

com 500 incógnitas ganhador do Prêmio Nobel em Economia. Esse método é conhecido

como modelo de “entrada e saída” de Leontief. Vejamos agora uma versão simpliﬁcada,

chamada de “modelo de troca”.

Seja uma economia dividida em diversos setores. Suponhamos que sabemos a

produção total de cada setor em um ano e a troca dessa produção com outros setores. O

preço é o valor total dessa produção, de um setor. Temos o seguinte teorema atribuído

a Leontief: “Existem preços de equilíbrio que podem ser atribuídos às produções totais

dos diversos setores de modo que a receita de cada setor equilibre exatamente as suas

despesas.” (LAY, 2007, P.49).

Suponhamos que o setor de energia sofra um aumento em sua mão de obra. Assim,

esse setor repassará esse aumento para seus clientes. Para alguns setores esse aumento

gerará uma gasto signiﬁcativo para produzir seus produtos, pois utilizam o setor de energia

na produção de seus produtos. O teorema "modelo de troca" de Leontief nos diz que é

possível, com base no aumento no setor de energia, por exemplo, encontrar preços de

equilibrio em que cada setor não terá prejuízo.

Vejamos agora um exemplo a respeito desse teorema: Seja a economia de uma

nação dividida conforme a tabela abaixo.

Tabela 1: Uma economia simples.
Química e Metalurgia Combustíveis e Energia Máquinas

0,2
0,3
0,5

0,6
0,2
0,2

0,3
0,5
0,2
Fonte: Elaborado pelo autor.
Notas: Tabela hipotética.

Adquirido por:
Química e Metalurgia
Combustíveis e Energia
Máquinas

Temos a economia dividida em 3 setores. A produção do setor de química e meta-

124

lurgia, por exemplo, está dividida em 50% para o setor de máquinas, 30% para o setor de

combustíveis e energia e o restante para o próprio setor de química e metalurgia. Temos

sempre 100% em cada setor, pois conhecemos a produção total de cada setor.

Temos que as colunas representam a produção e as linhas a necessidade de insu-

mos1. Logo, temos da primeira linha que

PQ = 0, 2PQ + 0, 6PC + 0, 3PM =

⇒

0, 8PQ

0, 6PC

−

−

0, 3PM = 0.

(5.1)

Ou, em outras palavras, o setor de química e metalurgia utiliza 20% de sua produção mais

60% da produção do setor de combustíveis e 30% do setor de máquinas para gerar 100%

de sua produção. A segunda linha nos fornece

PC = 0, 3PQ + 0, 2PC + 0, 5PM =

⇒ −

0, 3PQ + 0, 8PC

−

0, 5PM = 0.

(5.2)

Da terceira linha temos:

PM = 0, 5PQ + 0, 2PC + 0, 5PM =

⇒ −

0, 5PQ

−

0, 2PC + 0, 8PM = 0.

(5.3)

Assim, de (5.1), (5.2) e (5.3) temos o seguinte sistema linear:

0, 8PQ

0, 6PC

−
0, 3PQ + 0, 8PC

0, 3PM = 0

0, 5PM = 0

−

−

0, 2PC + 0, 8PM = 0

−

−

0, 5PQ

−

que pode ser representado pelo sistema matricial A~p = 0 onde ~p = (PQ, PC, PM ). Logo,

podemos utilizar escalonamento para resolver esse sistema.

0, 8

0, 3

0, 5

0, 6

−
0, 8

0, 2

−

0, 75

−
0, 575

0, 575

−

A~p = 

−

−




1



0

0





∼



∼

0, 3

−

0, 5

−
0, 8




0, 375

−

0, 6125

−
0, 6125

1

0, 3

0, 5







−

−

0, 75

−

0, 8

0, 2

−

0, 375

−

0, 5

−
0, 8







1

0, 75

−
0 0, 575

0

0

∼













0, 375

0, 6125

−

−

0







o que nos dá por retrossubstituição que

0, 575PE

−

0, 6125PM = 0

−→

PE = 1, 0652PM

1Outro bem ou serviço utilizado na produção de seu produto.

125

e

PQ

−

0, 75PE

−

0, 375PM = 0

0, 75

PQ

−

·

−→

1, 0652PM

−

0, 375PM = 0

−→

PQ = 1, 1739PM

que nos dá a solução geral PQ = 1, 1739PM , PE = 1, 0652PM e PM é uma variável livre.

O vetor que gera o preço de equilíbrio é

PQ

1, 1739PM

1, 1739

~p = 

PE



= 

1, 0652PM



= PM 

1, 0652



.







Temos, agora, que qualquer valor para PM









PM

PM





1





= 0 resulta em preços de equilíbrio. Por

exemplo, se tivermos PM = 1 milhão de reais, teremos PQ = 1, 17 e PE = 1, 06 milhões

de reais para manter os preços de equilíbrio, por exemplo. Logo, pelo teorema Leontief,

temos que a receita de cada setor está em equilíbrio com suas despesas.

Mas, se tivermos um setor que não produz serviços ou bens, chamaremos esse se-

tor de “setor aberto”. Como podemos chegar aos preços de equilíbrio? Para isso Leontief

desenvolveu o modelo de entrada/saída.

Modelo de entrada/saída ou Equação de Produção

~x

=

C~x

+

Quantidade

Demanda

~d
.
Demanda

produzida

intermedi´aria

f inal

(5.4)

Onde ~x é o vetor que representa a produção de cada setor em um ano, C é a matriz de
consumo e ~d é o vetor que representa a demanda do setor aberto, ou seja, setores que não
produzem para a economia.

Temos da equação (5.4) que

que nos fornece

C~x = ~d,

I~x

−

C)~x = ~d

(I

−

gerando um sistema linear. Portanto, podemos utilizar qualquer um dos métodos desen-

volvidos nos primeiros capítulos.

Esse modelo que comentamos de forma bem superﬁcial é a base de modelos utili-

zados em diversos países.

Essa aplicação nos fornece um exemplo bem rico para ser apresentado para os alu-

6
126

nos. Mostra que o conteúdo referente a sistemas lineares aparece até como ferramenta para

auxiliar na compreensão de como comporta-se uma economia. Também, nesse exemplo,

podemos comentar a necessidade de computadores para fazer esses cálculos.

Para saber mais sobre o tema comentado nesta seção sugiro a leitura das obras:

Elementary linear algebra- applications version (Anton. Howard; Rorres. Chris, 1994) e Álge-

bra linear e suas aplicações (Lay. David C, 2007) que serviram como referencial teórico.

5.2 SISTEMAS LINEARES E NUTRIÇÃO

A Dieta de Cambridge foi construída a partir de anos de pesquisa. Uma equipe da

Universidade de Cambridge a desenvolveu após 8 anos de trabalhos clínicos com pessoas

obesas. Essa dieta, que foi popular nos anos 80, buscava equilibrar o consumo de proteínas,

carboidratos, gorduras e outros nutrientes de forma que se chegasse a perda de peso.

Para conseguir o equilíbrio entre diversos nutrientes, a equipe de Cambridge utili-

zou sistemas lineares para calcular a quantidade de cada tipo de alimento. Por exemplo,

tínhamos o leite desnatado como fonte de proteínas, porém tinha muita cálcio. Já a fa-

rinha de soja tinha bastante proteína e pouco cálcio, mas a farinha de soja tem muita

gordura. Logo, era muito importante distribuir os alimentos de forma que buscasse o

equilíbrio necessário entre as quantidades dos nutrientes. Não poderia ser muito pouco,

como não poderia ultrapassar a quantidade desejada.

Vejamos um exemplo baseado na tabela a seguir.

Desnatado de Soja de Leite

Tabela 2: Quantidade (gramas) fornecidas por 100g de ingredientes.
Soro

Farinha

Leite

Nutriente

Proteína
Carboidratos
Gordura

13
74
1,1
Fonte: Dados extraídos do livro Álgebra linear e suas aplicações pg 81 (Lay. David C,
2007).

36
52
0

51
34
7

Quantidades Fornecida pela Dieta
de Cambridge em um dia
33
45
3

Calcularemos a quantidade que devemos ter de cada alimento de forma que tenha-

mos os valores sugeridos pela Dieta de Cambridge.

Da primeira linha da tabela temos que a quantidade de proteínas depende da

seguinte fórmula.

p = 36l + 51f + 13s = 33.

(5.5)

Onde, temos a quantidade de proteínas representada por p, de leite desnatado por l, de

127

(5.6)

(5.7)

farinha de soja por f e de soro de leite por s. Da segunda linha temos:

c = 52l + 34f + 74s = 45,

onde c representa a quantidade de carboidratos. E da terceira linha chegamos a

g = 7f + 1, 1s = 3,

com g representado a quantidade de gordura.

Das equações (5.5), (5.6) e (5.7), temos:

36l + 51f + 13s = 33

52l + 34f + 74s = 45

7f + 1, 1s = 3

que é equivalente a:

36 51

13

l

33

Assim, podemos utilizar um dos métodos que estudamos nos primeiros capítulos, resolve-



52 34

74





f



= 

45



.

0

7

1, 1





·









s









3





remos usando o método de Cramer.

33 51

13

D 

45 34

74



l =





3

7

1, 1

36 51

13





4293, 3
15486, 8 ≈

= −
−

0, 2772,

D 

52 34

74



0





7

1, 1





33 33

13

D 

52 45

74



f =





0

3

1, 1

36 51

13





6069, 6
15486, 8 ≈

= −
−

0, 3919

D 

52 34

74



0





7

1, 1





e

128

s =

36 51 33

D 

52 34 45



0

7




36 51





3

13

D 

52 34

74



3612

15486, 8 ≈

= −
−

0, 2332.

0

7

1, 1




Portanto, devemos ter 0,2772 unidades de leite desnatado, 0,3919 unidades de





farinha de soja e 0,2332 unidades de soro de soja de modo a satisfazer as quantidades

sugeridas pela dieta de Cambridge.

É importante reparar que as soluções do sistema só farão sentido quando forem

positivas. Caso contrário, teremos que alterar ou acrescentar alimentos de forma que

tenhamos uma solução positiva.

A Dieta de Cambridge, na época, fornecia de forma equilibrada 31 nutrientes,

utilizando 33 ingredientes.

É claro que podemos aplicar esse raciocínio utilizando as informações nutricio-

nais fornecidas nos alimentos que adquirimos no comércio hoje em dia. Para isso, basta

organizarmos essas informações em uma tabela e formarmos o sistema linear.

Tabela 3: Informação nutricional.

Nutrientes

Arroz Integral
* (50g)

Valor Energético
Carboidratos
Proteínas
Gorduras Totais,
das quais:
Gorduras Saturadas
Gorduras Trans
Fibra Alimentar
Sódio

0,8
11
4
2

2
**
21
0

Feijão-preto

Filé de Peito

Suco de
Cozido * (60g) de Frango (124g) Laranja
(248ml)
5,6
9,6
2,4
0,8

8
0
48
3

5
3
3
12

4
**
11
40

0
**
0
4

0,3
**
0,2
0,1

Fonte: Valores extraídos das embalagens dos alimentos.
Notas: * Valores diários com base em uma dieta de 2.000 kcal.
**Valores diários não estabelecidos.

Suponhamos agora que queremos encontrar a quantidade de arroz integral, feijão-

preto, ﬁlé de peito de frango e suco de laranja para uma refeição que seja equivalente a

40% do valor energético, 40% dos carboidratos , 40% das proteínas e 50% das gorduras.

Logo, devemos resolver o seguinte sistema linear:

- valor energético = 0, 08a + 0, 05f e + 0, 08f i + 0, 056s = 0, 4;

- carboidratos = 0, 11a + 0, 03f e + 0f i + 0, 96s = 0, 4;

- proteínas = 0, 04a + 0, 03f e + 0, 48f i + 0, 024s = 0, 4;

- gorduras = 0, 02a + 0, 12f e + 0, 03f i + 0, 008s = 0, 5.

O que nos fornece o seguinte sistema matricial.

0, 08 0, 05 0, 08 0, 056

a



0, 11 0, 03

0

0, 096





f e



0, 04 0, 03 0, 48 0, 024

0, 02 0, 12 0, 03

0, 08








=

0, 4



0, 4










0, 4

0, 5








·















f i

s








Resolveremos esse sistema utilizando o método de eliminação de Gauss. Temos que

129

.

0, 08 0, 05 0, 08 0, 056 0, 4

80

50

80

56 400



0, 11 0, 03

0

0, 096 0, 4





110 30

0

96 400



0, 04 0, 03 0, 48 0, 024 0, 4

0, 02 0, 12 0, 03

0, 08

0, 5















∼

∼








40

30 480 24 400

2

12

3

8

50

1 0 0 0 1, 9783










0 1 0 0 3, 1117



.

0 0 1 0 0, 4276

0 0 0 1 0, 9273














0, 9273. Portanto,

O que nos dá que a

1, 9783, f e

3, 1117, f i

0, 4276 e s

≈

≈

≈

≈

devemos ter 98,91g de arroz, 186,7g de feijão, 53,02g de ﬁlé de peito de frango e 229,97ml

de suco de laranja. Claro que uma dieta vai levar muitos outros fatores em consideração,

mas esse exemplo nos faz perceber como sistemas lineares aparecem no nosso dia a dia.

Enquanto a aplicação que foi comentada anteriormente aborda a economia de um

país; a aplicação sobre nutrição remete-nos ao nosso dia a dia. Esses dois exemplos nos

fornecem aplicações opostas no que dizem respeito ao convívio dos alunos. O que os torna

muito interessantes.

5.3 COMPUTAÇÃO GRÁFICA

Projetos assistidos por computador geram uma grande economia na indústria au-

tomobilística. Hoje, os projetos são feitos com o uso de computação gráﬁca e da álgebra

linear.

Primeiro constroem-se um modelo de carro matemático.

130

Figura 18: Modelo matemático de um carro

Fonte: https://www.autodesk.com.br/solutions/3d-modeling-software em 23/04/2020.

Os engenheiros utilizam esse modelo para que se possam fazer aprimoramentos,

com ele é possível fazer testes como de suspensão, colisão, aerodinâmica.

Esse modelo matemático é armazenado em forma de muitas matrizes que podem

ser alteradas quantas vezes for necessário. Pode-se alterar o projeto inicial, sem custo de

materiais, até se encontrar o molde desejado. Esse modelo matemático permite que se-

jam realizadas diversas operações básicas, como ampliação, redução, alterar a orientação,

alternar entre visões 2D e 3D, entre outras.

A álgebra é fundamental não só para o setor da indústria automobilística, é também

fundamental para todo setor que trabalha com programas gráﬁcos, tendo em vista que

todas as operações feitas na tela são feitas através de técnicas da álgebra linear.

5.3.1 Aplicações à Computação Gráﬁca

A computação gráﬁca diz respeito às imagens que aparecem na tela de um compu-

tador. Podem ser estáticas ou animadas. Ela atende a uma grande variedade de setores,

como: o da indústria, o do cinema, o de jogos, o de aplicativos de celulares e muitos

outros.

Analisaremos alguns efeitos sobre uma letra que é uma representação gráﬁca 2D

mais simples. A letra maiúscula L, na Figura 19, pode ser bem deﬁnida por 6 vértices.

Podemos utilizar as coordenadas do vértices para construir uma matriz para representá-la.

Para facilitar a compreensão do processo, não trataremos a respeito da ligação entre os

vértices.

1 2

0 5

3

5

4

5

6

0, 5 0, 5 0

Coordenada x

0 0 0, 5 0, 5

"

8

8#

Coordenada y.

L =

Figura 19: Representação gráﬁca do L.

131

Fonte: Elaborado pelo autor.

Com esses pontos basta ligar os vértices que temos a letra L.

Analisaremos, agora, o efeito gerado pela multiplicação da matriz

A =

1 0, 25

0

"

1 #

,

sobre a matriz L. Temos ~v

−→

A~v, ou seja, L sendo transformada em AL.

AL =

1 0, 25

0 5

5

0, 5 0, 5 0

0

"

1 # · "

0 0 0, 5 0, 5

8

8#

=

0 5 5, 125 0, 625 2, 5 2

0 0

"

0, 5

0, 5

8

8#

.

Analisando a Figura 20, construída pela nova matriz, temos um L inclinado. Pode-

mos utilizar essa matriz para construir as letras em itálico, mas e se quisermos aumentar

ou reduzir as letras? Podemos utilizar a matriz

S =

2 0

"

0 2#

que vai dobrar o tamanho da letra L.

132

Figura 20: Representação gráﬁca do L inclinado.

Fonte: Elaborado pelo autor.

SAL =

2 0
0 2# · "

"

0 5 5, 125 0, 625 2, 5 2

0 0

0, 5

0, 5

8

8#

=

0 10 10, 25 1, 25

5

4

0

"

0

1

1

16 16#

.

Poderíamos ter feito uma única operação sobre a matriz L. Bastava que fosse feito,

a multiplicação de matrizes no início.

SA =

2 0
0 2# · "

"

1 0, 25

0

1 #

=

2 0, 5

0

"

2 #

.

Figura 21: Comparação entre as três formas do L.

Fonte: Elaborado pelo autor.

A computação gráﬁca está diretamente relacionada com a multiplicação de matri-

zes. Mas, através de multiplicação de matrizes, não conseguimos uma translação; logo,

devemos buscar outro método que nos forneça, também, essa possibilidade. As coordena-

das homogêneas satisfazem essa necessidade e outras.

5.3.2 Coordenadas Homogêneas

133

Cada ponto (x, y) do R2 pode ser representado no R3. Podemos, em particular,
R3. Falamos que (x, y) tem

R2 como um ponto (x, y, 1)

representar todo ponto (x, y)

∈
coordenada homogênea (x, y, 1).

∈

Com as coordenadas homogêneas podemos fazer a translação,

(x, y, 1)

→

(x + h, y + v, 1), que pode ser representada pela multiplicação de matriz

1 0 h

x

x + h



0 1 v





y



= 

y + v



.

0 0 1





·









1









1





Ainda podemos representar as matrizes de rotação, reﬂexão e contração/dilatação

como coordenadas homogêneas. São elas:

sen α 0

−
cos α

0

Rotação anti-horária em torno da origem.

0



1





cos α



sen α

0





0 1 0

(y, x).

−→



1 0 0



Reﬂexão (x, y)





0 0 1





a 0 0



0 b 0



Contração/Dilatação por a em x e b em y.





0 0 1





A matriz rotação nos permite girar a ﬁgura em torno da origem. Já, na reﬂexão, te-

mos uma troca da primeira linha pela segunda, portanto temos uma matriz elementar que

vai trocar x por y e y por x em qualquer ponto que ﬁzermos a multiplicação. Por último,

temos a contração/dilatação que vai nos permitir ampliar ou reduzir uma ﬁgura, para isso

basta fazer a=b. Mas, não se perde nada com as coordenadas homogêneas? A resposta é

perde-se. Não podemos realizar multiplicações por escalares, pois ao multiplicarmos, por

exemplo, uma coordenada por um escalar temos 2(x, y, 1) = (2x, 2y, 2)

= (x′, y′, 1).

6
134

O conceito de coordenadas homogêneas2 pode ser expandido para o R3 (3D). Para

isso basta transformar um ponto (x, y, z)

R3 em (X, Y, Z, H)

R4, tal que H

= 0 e

x =

, y =

e z =

. Se H = 1 temos (X, Y, Z, H) = (x, y, z, 1).

∈

∈

X
H

Y
H

Z
H

Para operarmos com ﬁguras mais complexas do que o L, teremos uma matriz maior,

pois teremos uma quantidade superior de vértices. Quando tivermos uma curva, também

poderemos aproximar por segmentos de reta. Logo, o raciocínio não será diferente do

utilizado pela letra L .

Essa aplicação é muito interessante no sentido didático, pois vai mostrar um em-

prego de matrizes em algo que os alunos sequer sabem que faz uso da matemática. Res-

pondendo a famosa pergunta, “Onde vou utilizar isso?”. Demonstrando, assim, que ma-

temática vai muito além dos cálculos.

5.4 MATRIZES E IMAGENS DIGITAIS

As imagens que vemos na internet, as fotograﬁas que tiramos com o celular ou

câmera digital são exemplos de imagens digitais. Essas imagens são armazenadas na

forma de matrizes, onde cada elemento dessa matriz tem um pixel. O pixel é o menor

elemento gráﬁco de uma imagem, ele pode ter apenas uma cor.

Vejamos um exemplo de uma imagem digital representada apenas pelas cores

branca ou preta, Figura 223.

Figura 22: Imagem do Gato Félix

Fonte: https://gazeta.spm.pt/getArtigo?gid=407 em 24/05/2020.

Podemos transformar a imagem do Gato Félix em uma matriz, onde cada elemento

é representado por zero (preto) ou por um (branco), conforme Figura 23.

2Para saber mais sobre o tema sugiro a leitura dos livros Álgebra Linear e suas aplicações (Lay. David

C, 2007) e Elementary Linear Algebra - Applications Version (Anton. Howard; Rorres. Chris, 1994)

3Esta seção terá como base o artigo publicado na revista Gazeta de Matemática (Pesco. Dirce Uesu;

Bertolossi. Humberto José, 2013) edição 169.

6
135

Figura 23: Imagem do Gato Félix com as cores representadas por 0 e 1

Fonte: https://gazeta.spm.pt/getArtigo?gid=407 em 24/05/2020.

As imagens que apresentam apenas essas duas possibilidades de cores, são chama-

das de imagens binárias ou imagens booleanas. Mas, como funcionam as imagens colori-

das? Existem vários sistemas para representar as cores em uma imagem, abordaremos na

sequência um deles.

O sistema de cores RGB ou red, green e blue utiliza três matrizes para formar

uma imagem. Uma matriz pode utilizar até 256 tons de vermelho (red) para formar a cor

da imagem, outra matriz vai ter novamente 256 tons, só que de verde (green) e a última

matriz terá até 256 tons de azul (blue). A ideia não é diferente daquela utilizada para o

Gato Félix, a diferença será que cada matriz vai formar um Gato Félix utilizando uma

variação de uma cor. No ﬁnal, juntando essas três matrizes teremos uma imagem com as

cores desejadas.

Figura 24: Três matrizes vão representar as três imagens.

Fonte: https://gazeta.spm.pt/getArtigo?gid=407 em 24/05/2020.

136

Figura 25: Imagem formada pela composição de três matrizes RGB.

Fonte: https://gazeta.spm.pt/getArtigo?gid=407 em 24/05/2020.

Para cada pixel da primeira matriz teremos 256 possibilidades de tons para o ver-

melho, na segunda 256 possibilidades de tons para o verde e por último 256 possibilidades
256 = 2563 = 224 = 16.777.216

para os tons de azul. Assim, temos um total de 256

256

cores para cada pixel. O que nos fornece uma variação muito grande na quantidade de

·

·

cores possíveis. Essa aplicação é muito interessante para ser abordada com os alunos do

Ensino Médio. Ela mostra como o computador reconhece as imagens que vemos e como

ele as armazena utilizando a matemática como intermediária.

137

6 SISTEMA DE EQUAÇÕES LINEARES E O ENSINO MÉDIO

Neste capítulo será feita uma abordagem de como o conteúdo que vimos ao longo

dessa dissertação pode ser e é visto no Ensino Médio. Comecemos, pois, por fazer uma

análise de como os conteúdos são apresentados aos alunos. O objetivo aqui não é dizer

qual ordem cronológica de conteúdos é a melhor, mas buscar outra possibilidade de ensino

desse rico tema.

Os conteúdos de sistemas lineares e matrizes têm como sugestão o seu ensino para

as turmas de 2o ano do Ensino Médio. Conforme proposta curricular de SC - 2014.

Figura 26: Sugestão de ensino de sistemas lineares.

Fonte: http://www.sed.sc.gov.br/documentos/ensino-89/proposta-curricular-156/1998-
158/disciplinas-curriculares-232 em
26/05/2020.

Determinantes não estão descritos como conteúdo obrigatório, mas subentende-se

que devem ser vistos junto ao conteúdo de matrizes. Já, vetores não fazem parte da grade

de conteúdos de matemática para o Ensino Médio. Vamos analisar o livro Matemática

- ciência e aplicações (Iezzi. Gelson et al., 2019) que é o livro utilizado na rede de Ensino

Médio do estado de Santa Catarina.

O livro inicia com matrizes, para depois abordar sistemas lineares e termina com

determinantes. Não há uma abordagem sobre vetores. Aﬁrma que matrizes são tabe-

las com informações numéricas organizadas através de colunas e linhas; comenta sobre

sua parte histórica e reconhece que matrizes originaram-se a partir de sistema lineares,

conforme citado abaixo:

“Como surgiram as matrizes

As matrizes teriam surgido com a escola inglesa Trinity College, em

um artigo do matemático Arthur Cayley (1821-1895), datado de 1858. Vale

138

lembrar, no entanto, que, bem antes, no século III a.C., os chineses já de-

senvolviam um processo de resolução de sistemas lineares em que aparecida a

ideia das matrizes”. (IEZZI, 2019, p. 67).

Em seguida, comenta a respeito dos tipos de matrizes (identidade, transposta,...)

e suas propriedades. Aborda algumas aplicações como computação gráﬁca, representação

de imagens com matrizes (pixel) e também comenta a respeito do uso de matrizes na

rotação, translação e ampliação/redução de imagens.

Sobre sistemas lineares, inicia com um sistema com duas equações de duas incóg-

nitas. Utiliza a interpretação geométrica para abordar a respeito de quando o sistema

tem solução e se essa solução é única ou não. Em seguida, comenta sobre a existência

de sistemas com m equações com n incógnitas. Trata, de forma superﬁcial, a notação
matricial A~x = ~b dos sistemas lineares.

Na sequência faz uma explanação sobre escalonamento e determinantes. E termina

apresentando os sistemas homogêneos.

Nossa sugestão, acerca da ordem em que poderiam ser apresentadas os conteúdos é

baseada em como eles foram apresentados ao longo dos capítulos 2, 3 e 4, e será detalhada

na Seção 6.1. Claro que é necessário fazer adaptações, como apresentar alguns teoremas

como propriedades e simpliﬁcar alguns temas e enunciados conforme a necessidade da

turma. Vejamos agora uma possível abordagem desses temas.

6.1 ENSINO MÉDIO E UMA ABORDAGEM SOBRE O TEMA SISTEMAS LINEARES

Iniciaríamos o tema convidando os alunos a trazerem embalagens de alimentos

conforme Figura 27.

Figura 27: Informações nutricionais de feijões-pretos e arroz integral

Fonte: Imagens retiradas de embalagens de produtos adquiridos no comércio.

139

Com essas embalagens montaríamos alguns sistemas lineares como o exemplo da

tabela 3. Nesse momento, não importa se os sistemas têm solução ou se os alunos con-

seguem resolver os mesmos. Importa que eles percebam que o tema já aparace em seu

dia a dia. Complementaríamos com perguntas do tipo: Será que há solução para esses

sistemas? Sempre haverá? Ou podemos ter um sistema que não tem solução? Também

será lembrado que, como trata-se de alimentação, o ideal é procurar uma especialista no

assunto.

Será muito provável que os alunos sugerirão que é muito mais fácil ﬁcar escolhendo

valores por tentativa e erro, em vez de resolver o sistema. Nesse momento, podemos incluir

na discussão o modelo de Leontief. Seria comentado sobre a importância Wassily Leontief

para economia e como é praticamente impossível equilibrar uma economia representada

por 500 equações com 500 incógnitas na tentativa e erro.

Começaríamos com essa introdução e os alunos seriam convidados a conhecer algu-

mas formas de resolver um sistema linear e os conteúdos que estão relacionados ao tema.

Falaríamos sobre os temas na seguinte ordem:

1. Equações Lineares: Revisando o Ensino Fundamental;

2. Geometria das Equações;

3. Eliminação de Gauss;

4. Notação Matricial;

5. Matrizes:

(a) Deﬁnição;

(b) Matriz Identidade;

(c) Matriz Elementar;

(d) Matriz Transposta;

(e) Matriz Inversa;

(f) Matriz Simétrica;

(g) Adição de Matrizes;

(h) Multiplicação de Matrizes;

(i) Forma Matricial: A~x por linhas e A~x por colunas;

(j) Utilizando a Matriz Inversa na resolução de sistemas de equações.

6. Vetores:

140

(a) Deﬁnição;

(b) Soma;

(c) Multiplicação por Escalar;

(d) Espaço-coluna;

(e) Espaço Nulo;

(f) Independência Linear;

(g) Teorema 12.

7. Determinantes:

(a) Propriedades;

(b) Formas para calcular o determinante de uma matriz;

(c) Regra de Cramer.

A respeito de matrizes, mostraríamos que o tema surge a partir da necessidade de

resolver-se um sistema linear.

Sobre vetores faríamos uma breve abordagem falando a respeito do básico, pois

fornece uma visão importante sobre sistema lineares, mesmo não fazendo parte do crono-

grama de matemática para o Ensino Médio.

A respeito de determinantes iniciaríamos mostrando que a partir de um sistema

2 por 2 podemos chegar a Regra de Cramer. Faríamos algumas perguntas introdutórias

como: Será que podemos ter uma forma semelhante para encontrarmos x, y e z em um

sistema de 3 equações com 3 incógnitas? A partir deste questionamento iniciaríamos o

tema determinantes.

6.2 SEQUÊNCIA DIDÁTICA E O ENSINO DE MULTIPLICAÇÃO DE MATRIZES

Vejamos agora como podemos abordar uma das aplicações comentadas no capítulo

5, com a ﬁnalidade de aprofundar e melhorar a compreensão sobre multiplicação de ma-

trizes. Faremos isso através de uma sequência didática.

Tema: Multiplicação de Matrizes e Computação Gráﬁca.

Objetivos:

— reconhecer a importância que a multiplicação de matrizes desempenha na compu-

tação gráﬁca;

141

— compreender o processo de multiplicação de matrizes.

Conteúdos:

— multiplicação de matrizes;

— plano cartesiano;

— pontos e segmentos de reta no plano cartesiano.

Tempo Estimado: 6 aulas.

Desenvolvimento

Os alunos serão convidados a sentarem em duplas e a representar uma letra do alfa-

beto por meio de segmentos de reta. Deverão, em seguida, montar uma matriz utilizando

as coordenadas dos vértices da letra escolhida representada no plano cartesiano.

Com esses dados em mãos, será solicitado que as duplas façam um desenho da letra

no geogebra. Que pode ser acessado pelo site:

https://www.geogebra.org/graphing?lang=pt

Em um segundo momento será solicitado que eles criem uma planilha no Excel/Calc

para fazer os cálculos de uma multiplicação entre matrizes. Nesse momento devemos ter

situações semelhantes a abordada no ﬁnal do capítulo anterior, conforme Figura 28.

Em seguida eles devem multiplicar a matriz que representa a letra escolhida por

A =

1 0, 25

0

"

1 #

.

Logo,

AL =

1 0, 25

0 5

5

0, 5 0, 5 0

0

"

1 # · "

0 0 0, 5 0, 5

8

8#

=

0 5 5, 125 0, 625 2, 5 2

0 0

"

0, 5

0, 5

8

8#

.

Eles devem chegar a conclusão que a letra sofreu uma inclinação, Figura 29.

Em seguida farão uma nova multiplicação pela matriz

S =

2 0

"

0 2#

142

Figura 28: Representação gráﬁca do L.

Fonte: Elaborado pelo autor.

Figura 29: Representação gráﬁca do L inclinado.

Fonte: Elaborado pelo autor.

que dará

SAL =

2 0
0 2# · "

"

0 5 5, 125 0, 625 2, 5 2

0 0

0, 5

0, 5

8

8#

=

0 10 10, 25 1, 25

5

4

0

"

0

1

1

16 16#

.

Chegando a nova matriz e a Figura 30. Neste momento far-se-á a socialização dos resul-

tados obtidos.

Na sequência comentaremos a respeito de matrizes de rotação, reﬂexão e contra-

ção/dilatação.

Será proposto como atividade, a aplicação do mesmo conceito em uma ﬁgura sim-

ples. Como uma casa vista de frente.

Figura 30: A letra L após sofrer uma inclinação e ampliação.

143

Fonte: Elaborado pelo autor.

Avaliação:

— Será avaliada a participação durante a atividade e se conseguiram chegar ao resul-

tado almejado.

Também podemos fazer uma abordagem um pouco diferenciada sobre esse tema.

Uma outra forma de trabalhar o tema seria.

Tema: Multiplicação de Matrizes e Computação Gráﬁca.

Objetivos:

— reconhecer a importância que a multiplicação de matrizes desempenha na compu-

tação gráﬁca;

— compreender o processo de multiplicação de matrizes.

Conteúdos:

— multiplicação de matrizes;

— plano cartesiano;

— tipos de gráﬁcos.

Tempo Estimado: 2 a 4 aulas.

144

Desenvolvimento

Os alunos serão convidados a sentarem em duplas e a representar uma imagem

através de pontos no plano cartesiano. Temos como exemplo a Figura 31.

Figura 31: A letra T representada por alguns pontos.

Fonte: Elaborado pelo autor.

Repare que quanto mais pontos colocamos, melhor ﬁca representada a letra T.

Após deﬁnir a imagem, eles deverão montar duas tabelas em programas como o

calc ou o excel. Ambas organizadas para utilizar coordenadas homogêneas.

A primeira será:

Tabela 4: Primeira tabela da multiplicação de matrizes.

A=

a b c
f
d e
1
0
0

Fonte: Elaborado pelo autor.

Por comodidade faremos com os seguintes números preenchidos.

Tabela 5: Primeira tabela da multiplicação de matrizes com valores preenchidos.

A=

1
0
0

0
1
0

0
0
1

Fonte: Elaborado pelo autor.

A segunda terá o seguinte formato:

Tabela 6: Segunda tabela da multiplicação de matrizes.

B=

x1 x2
y2
y1
1
1

. . . xn
yn
. . .
. . .
1

Fonte: Elaborado pelo autor.

Em seguida eles criarão uma terceira tabela que será o resultado da multiplicação

da matriz A pela matriz B:

B=

A

×

ax1 + by1 + c
dx1 + ey1 + f
0x1 + 0y1 + 1

Tabela 7: Resultado da multiplicação de A

B.
. . .
axn + byn + c
ax2 + by2 + c
1
. . . dxn + eyn + f
1 dx2 + ey2 + f
0xn + 0yn + 1
. . .
0x2 + 0y2 + 1
1
Fonte: Elaborado pelo autor.

1
1
1

·
·
·

·
·
·

×

145

1
1
1

·
·
·

Após concluída a tabela 7 eles utilizaram as duas primeiras linhas dessa tabela,

para construir um gráﬁco de dispersão, conforme Figura 31.

Depois de concluído esses passos, eles serão convidados a alterarem os valores de a e

e na tabela 4. Veriﬁcando que se alterarmos o valor de a a imagem sofre uma ampliação/-

redução na horizontal e se alterarmos o valor de e a imagem sofre uma ampliação/redução

na vertical. Conforme imagem abaixo.

Figura 32: A letra T representada com a ou e alterados.

Fonte: Elaborado pelo autor.

Na imagem da esquerda ﬁzemos a = 2, repare que todos os pontos da letra T

tiveram seus valores das coordenadas da horizontal, eixo x, dobrados. Já, na imagem da

direita, ﬁzemos e = 3 e tivemos os valores das coordenadas da vertical, eixo y, triplicados.

Se alterarmos os valores de b ou d a imagem vai sofre uma inclinação. Conforme ﬁgura

abaixo:

Figura 33: A letra T representada com b ou d alterados.

Fonte: Elaborado pelo autor.

Já se alterarmos a letra c, vamos deslocar toda a imagem na horizontal e se alte-

rarmos a letra f , vamos deslocar toda a imagem na vertical.

146

Figura 34: A letra T representada com c ou f alterados.

Fonte: Elaborado pelo autor.

A imagem da esquerda temos c = 10 e portanto, todos os pontos foram deslocados

em 10 unidades para a direita. Já, na segunda imagem, temos f = 20 e logo, todos os

pontos foram deslocados 20 unidades para cima.

No ﬁnal será solicitado que eles realizem alterações na tabela e tentem visualizar

o que está acontecendo. Como na imagem abaixo.

Figura 35: A letra T representada com várias alterações.

Fonte: Elaborado pelo autor.

Avaliação:

— Será avaliada a participação durante a atividade e se conseguiram chegar ao resul-

tado almejado.

Claro que haverá a necessidade de fazer adaptações em ambas as sequências, de-

pendendo da turma, mas acreditamos que seja viável a aplicação destas sequências desde

que haja a estrutura necessária, ou seja, o laboratório de informática.

147

7 CONCLUSÃO

Os conteúdos de matemática ensinados no Ensino Médio muitas vezes são aborda-

dos de forma isolada ou com simplicidade excessiva. Fazendo-se que se perca a beleza e

riqueza que os temas podem oferecer.

Com a abordagem proposta, espera-se que o aluno seja capaz de constatar que os

conteúdos estão interligados. Partindo da problemática da resolução de um problema que

é transformado em um sistema de equações, espera-se que o aluno(a) reconheça que há

diversas possibilidades de encontrar a solução. Ampliando, assim, a sua forma de analisar

e compreender o problema.

Portanto, é interessante aplicar essa ordem de conteúdos em uma turma do Ensino

Médio, buscando o equilíbrio entre o nível que deve-se abordar, de forma que não preju-

dique a aprendizagem, mas que não se subestime a capacidade dos alunos em aprender o

tema em um nível mais aprofundado.

148

149

REFERÊNCIAS

Anton. Howard; Rorres. Chris. ELEMENTARY LINEAR ALGEBRA-APPLICATIONS
VERSION. [S.l.]: JOHN WILEY SONS, INC, 1994.

Delgado. Jorge; Frensel. Katia; Crissaﬀ. Lhaylla. GEOMETRIA ANALÍTICA. [S.l.]:
SBM, 2013.

Hefez. Abramo; Fernandez. Cecília S. INTRODUÇÃO À ÁLGEBRA LINEAR. [S.l.]:
SBM, 2016.

Iezzi. Gelson et al. Matemática - Ciência e aplicações. [S.l.]: Editora Saraiva, 2019.

Lay. David C. Álgebra linear e suas aplicações. [S.l.]: LTC, 2007.

Lima. Elon Lages. Álgebra linear. [S.l.]: IMPA, 2003.

Pesco. Dirce Uesu; Bertolossi. Humberto José. Imagens digitais e matrizes. Gazeta de
Matemática, Março, n. 169, p. 44–48, 2013.

Strang. Gilbert. Álgebra linear e suas aplicações. [S.l.]: CENGAGE Learning, 2010.

150

ANEXO A -- Corpos

153

Um Conjunto K será chamado de corpo 1 se for munido de uma operação de adição

(+) e uma operação de multiplicação (×), na qual vale as propriedades a seguir:

A1 A adição é associativa: (a + b) + c = a + (b + c), para todo a, b, c ∈ K.

A2 A adição é comutativa: a + b = b + a, para todo a, b ∈ K.

A3 A adição possui o elemento neutro: existe 0 ∈ K tal que a + 0 = a, para todo a

∈ K.

A4 A adição possui simétricos: existe −a ∈ K tal que a+(−a) = 0 para todo a ∈ K.

M1 A multiplicação é associativa: (a × b) × c = a × (b × c), para todo a, b, c ∈ K.

M2 A multiplicação é comutativa: a × b = b × a, para todo a, b ∈ K.

A3 A multiplicação possui o elemento neutro: existe 1 ∈ K \ {0} tal que a × 1 = a,

para todo a ∈ K.

A4 A multiplicação possui inverso: existe a−1 ∈ K tal que a × (a−1) = 1 para todo

a ∈ K.

AM A multiplicação é distributiva com relação à adição: a × (b + c) = a × b + a × c,

para todo a, b, c ∈ K.

Exemplos:

a) O conjunto dos Números Racionais (Q) é um corpo com as operações de adição e
multiplicação usuais.

b) O conjunto dos Números Naturais (N) não é um corpo com as operações de adição e
multiplicação usuais. Temos que não há o inverso de 2 em N, logo não vale a propriedade
A4.

1Para saber mais sobre o tema consulte Introdução à Álgebra Linear (Hefez. Abramo; Fernandez. Cecília

S, 2016)

154

ANEXO B -- Produto Vetorial e Produto Misto

157

Deﬁnimos o produto vetorial de ~u por ~v como o vetor

~u × ~v = (y1z2 − y2z1, −(x1z2 − x2z1), x1y2 − x2y1)

que pode ser calculado por:

~u × ~v = D

~e1 ~e2 ~e3
x1 y1 z1
x2 y2 z2





= D

y1 z1
y2 z2

(cid:20)

(cid:21)

~e1 − D

x1 z1
x2 z2

(cid:20)

(cid:21)

~e2 + D

x1 y1
x2 y2

(cid:20)

~e3.

(cid:21)

Com ~u = (x1, y1, z1), ~v = (x2, y2, z2), ~e1 = (1, 0, 0), ~e2 = (0, 1, 0) e ~e3 = (0, 0, 1).





Interpretação Geométrica da Norma do Produto Vetorial1

Figura 36: Paralelogramo P = OACB de altura h.

Fonte: Elaborado pelo autor.

Sejam ~u =

#     »
OA 6= ~0 e ~v =

#     »
OB 6= ~0 vetores não colineares, e seja C o quarto

vértice do paralelogramo P = OACB.

A altura de P em relação a base ~u é

h = ||

#     »
OB||sen∠(

#     »
OA,

#     »
OB).

Assim,

´Area(P ) = ||
= ||

#     »
OA|| · ||
#»
#»
v ||sen∠(
u|| · ||

#     »
#     »
OB||sen∠(
OA,
#»
v ).

#»
u,

#     »
OB)

Utilizando a propriedade do produto vetorial que nos diz que

#»
u ×

||

#»
v || = ||

#»
u|| · ||

#»
v ||sen∠(

#»
u,

#»
v ),

chegamos que a área(P) é igual à norma do produto vetorial de ~u por ~v.

1Demonstrações da obra Geometria Analítica (Delgado. Jorge; Frensel. Katia; Crissaﬀ. Lhaylla, 2013)

158

´Area(P ) = ||

#»
u|| · ||

#»
v ||sen∠(

#»
u,

#»
v ) = ||~u × ~v||.

Produto Misto e Determinate

O produto misto dos vetores ~u, ~v e ~w é um número tal que

Utilizando uma propriedade do produto vetorial que nos diz que

[~u, ~v, ~w] =

~u × ~v, ~w
D

E

.

temos que

~u × ~v, ~w
D

E

= det(~u, ~v, ~w),

[~u, ~v, ~w] = det(~u, ~v, ~w).

Interpretação Geométrica do Produto Misto

Figura 37: Volume do paralelepípedo.

Fonte: Elaborado pelo autor.

Sejam A, B, C e D pontos não coplanares e T o paralelepípedo que tem os
segmentos AB, AC e AD como arestas adjacentes. Considerando o paralelogramo P
de lados adjacentes AB e AC como base de P , temos

V ol(T ) = ´Area(P ) · h,

Se ~u =

onde h é a altura de T relativa à base P .
#     »
#     »
AC e ~w =
AB, ~v =

#      »
AD, teremos que ´Area(P ) = ||~u × ~v|| e
h = || ~w|| · |cos∠( ~w, ~u × ~v)|, pois o produto vetorial de ~u por ~v é perpendicular ao
plano gerado por eles. Portanto,

V ol(T ) = ||~u × ~v|| · || ~w|| · |cos∠( ~w, ~u × ~v)|.

Utilizando a deﬁnição de produto interno que nos diz que

h ~m, ~ni = || ~m|| · ||~n|| · cos∠( ~m, ~n).

Temos que

159

V ol(T ) = ||~u × ~v|| · || ~w|| · |cos∠( ~w, ~u × ~v)|
= h~u × ~v, ~wi = det(~u, ~v, ~w).

ou, em termos dos vértices A, B, C e D,

V ol(T ) = det(

#     »
AB,

#     »
AC,

#      »
AD).


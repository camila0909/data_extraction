Tha´ıs Saes Giuliani Ribeiro

Processos de Markov discretos: exemplos voltados para o Ensino M´edio

Bauru

2017

Tha´ıs Saes Giuliani Ribeiro

Processos de Markov discretos: exemplos voltados para o Ensino M´edio

Disserta¸c˜ao apresentada como parte dos requisitos

para obten¸c˜ao do t´ıtulo de Mestre em Matem´atica,

junto ao Programa de Mestrado Proﬁssional em Ma-

tem´atica em Rede Nacional - PROFMAT, do Ins-

tituto de Biociˆencias, Letras e Ciˆencias Exatas da

Universidade Estadual Paulista “J´ulio de Mesquita

Filho”, Campus de S˜ao Jos´e do Rio Preto, Polo de

Bauru.

Financiadora: CAPES

Orientador: Prof. Dr. Fabiano Borges da Silva

Bauru

2017

Ribeiro, Thaís Saes Giuliani. 
      Processos de Markov discretos: exemplos voltados para o ensino 
médio / Thaís Saes Giuliani Ribeiro. -- São José do Rio Preto, 2017

73 f. : il.

Orientador: Fabiano Borges da Silva 
Dissertação (Mestrado profissional) – Universidade Estadual
Paulista “Júlio de Mesquita Filho”, Instituto de Biociências, Letras e 
Ciências Exatas 

       1. Matemática (Ensino Médio) - Estudo e ensino. 2. Markov, 
Processos de. 3. Processo estocástico. 4. Probabilidades. 5. Álgebra 
linear. 6. Matemática – Metodologia. I. Universidade Estadual Paulista 
"Júlio de Mesquita Filho". Instituto de Biociências, Letras e Ciências 
Exatas. II. Título.

CDU – 51(07)

Ficha catalográfica elaborada pela Biblioteca do IBILCE
UNESP - Câmpus de São José do Rio Preto 

 
 
Tha´ıs Saes Giuliani Ribeiro

Processos de Markov discretos: exemplos voltados para o Ensino M´edio

Disserta¸c˜ao apresentada como parte dos requisitos

para obten¸c˜ao do t´ıtulo de Mestre em Matem´atica,

junto ao Programa de Mestrado Proﬁssional em Ma-

tem´atica em Rede Nacional - PROFMAT, do Ins-

tituto de Biociˆencias, Letras e Ciˆencias Exatas da

Universidade Estadual Paulista “J´ulio de Mesquita

Filho”, Campus de S˜ao Jos´e do Rio Preto, Polo de

Bauru.

Financiadora: CAPES

Comiss˜ao Examinadora

Prof. Dr. Fabiano Borges da Silva

UNESP Bauru

Orientador

Profa. Dra. Tatiana Miguel Rodrigues de Souza

UNESP Bauru

Prof. Dr. Leandro Batista Morgado

Universidade Federal de Santa Catarina

Bauru

30 de novembro de 2017

Agradecimentos

Agrade¸co `a Deus, primeiramente, por me propiciar a oportunidade de concluir este

trabalho.

`A minha fam´ılia que, mesmo de longe, acredita e torce muito por mim.

Ao meu marido Oct´avio, que me apoiou, compreendendo minhas ausˆencias e me tran-

quilizou nos momentos dif´ıceis.

Aos professores do PROFMAT de Bauru , por transmitirem todo conhecimento e

incentivo a cada etapa, nos motivando a sempre prosseguir.

Aos colegas do PROFMAT 2015, pelo conv´ıvio, amizade e companheirismo.

Ao meu orientador Prof. Dr. Fabiano Borges da Silva, pela dedica¸c˜ao e incentivo na

execu¸c˜ao deste trabalho.

`A CAPES, pelo apoio ﬁnanceiro.

Resumo

Neste trabalho, mostramos como construir um processo estoc´astico de Markov e seu

espa¸co de probabilidade a partir das probabilidades de transi¸c˜ao e da distribui¸c˜ao ini-

cial. Al´em disso, mostramos a convergˆencia das matrizes de transi¸c˜ao utilizando como
ferramenta conhecimentos de ´Algebra Linear. A aplica¸c˜ao das cadeias de Markov num

contexto voltado para o Ensino M´edio ´e mostrado no ´ultimo cap´ıtulo, onde procuramos

oferecer aos alunos a oportunidade de ter uma vis˜ao mais ampla de como a Matem´atica

pode ser aplicada em outras ´areas do conhecimento.

Palavras-chave: Cadeia de Markov, processos estoc´asticos, espa¸co de probabilidade,

convergˆencia, probabilidade condicional.

Abstract

In this work, we show how to construct a stochastic Markov process and its probability

space from the transition probabilities and the initial distribution. In addition, we show

to investigate the convergence of the transition matrices using Linear Algebra knowledge

as a tool. Application of Markov chains in a context focused on High School, it is shown

in the last chapter, where we try to oﬀer the students the opportunity to have a view of

how mathematics can be applied in other areas of knowledge.

Keywords: Markov chain, stochastic processes, probability space, convergence, con-

ditional probability.

Sum´ario

Introdu¸c˜ao

1 Uma introdu¸c˜ao `a teoria de probabilidade

8

10

1.1 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

1.1.1 Propriedades da probabilidade . . . . . . . . . . . . . . . . . . . . . 14

1.2 Vari´avel aleat´oria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2 Espa¸co de probabilidade para cadeias de Markov

19

2.1 Processo estoc´astico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.2 Probabilidade no espa¸co das sequˆencias . . . . . . . . . . . . . . . . . . . . 22

3 Cadeias de Markov

24

3.1 Probabilidade de transi¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

3.2 Cadeias de Markov . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

4 Matrizes de transi¸c˜ao agindo em vetores de distribui¸c˜ao

35

4.1 Matrizes estoc´asticas de transi¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . 36

4.1.1 Convergˆencia de matrizes de transi¸c˜ao diagonaliz´aveis . . . . . . . . 47

4.1.2 Convergˆencia de matrizes de transi¸c˜ao regulares . . . . . . . . . . . 52

5 Aplica¸c˜ao das cadeias de Markov no Ensino M´edio

59

5.1 Plano de aula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68

5.2 Aplica¸c˜ao dos problemas propostos nesta disserta¸c˜ao . . . . . . . . . . . . 69

7

Introdu¸c˜ao

Um dos maiores desaﬁos no ensino de matem´atica ´e a contextualiza¸c˜ao dos conte´udos,

isto ´e, trabalhar a matem´atica de maneira pr´atica e com aplica¸c˜oes em situa¸c˜oes co-

tidianas. Muitas vezes, n´os professores, enfrentamos certa diﬁculdade em trabalhar os

conte´udos de matem´atica, principalmente conceitos do Ensino M´edio, mostrando aos alu-

nos uma aplica¸c˜ao pr´atica sobre aquele assunto.

A grosso modo, cadeia de Markov ´e um processo estoc´astico sem mem´oria, caracteri-

zado por seu estado futuro depender apenas do seu estado no presente, sabendo que os

estados passados n˜ao inﬂuenciam no estado futuro. Para o estudo das cadeias de Markov,

em geral utilizamos como ferramenta matrizes e probabilidades de transi¸c˜ao, que nos per-

mite, com certa precis˜ao, prever acontecimentos futuros de certos fenˆomenos, e com isso

tomarmos decis˜oes para atingirmos os resultados desejados. Assim, a cadeia de Markov ´e

um instrumento que propicia ao professor uma abordem do conte´udo de matrizes, sistemas

lineares e probabilidade de maneira contextualizada e de forma eﬁcaz, pois dessa maneira,

os alunos poder˜ao assimilar os conceitos de forma pr´atica e constatar que o conte´udo que

se aprende na escola pode ser utilizado de forma efetiva em problemas reais.

Este trabalho busca oferecer ao leitor um embasamento te´orico sobre espa¸co de pro-

babilidade para cadeias de Markov e dar exemplos que possam ser utilizados no Ensino

M´edio.

No Cap´ıtulo 1, buscamos retomar os principais conceitos da teoria de probabilidade

que ser˜ao de grande importˆancia para o desenvolvimento posterior deste trabalho, espe-

cialmente as deﬁni¸c˜oes de ´algebra, σ-´algebra, probabilidade e vari´avel aleat´oria.

No segundo cap´ıtulo, ﬁzemos uma introdu¸c˜ao ao espa¸co amostral de um processo

estoc´astico discreto e sua interpreta¸c˜ao como espa¸co das sequˆencias, deﬁnimos a ´algebra

8

9

de eventos nesse espa¸co e probabilidade para o espa¸co das sequˆencias.

No Cap´ıtulo 3, apresentamos o conceito de cadeias de Markov, a partir da deﬁni¸c˜ao

das probabilidades de transi¸c˜ao pij. Fizemos um exemplo onde buscamos estudar a con-

vergˆencia das distribui¸c˜oes de probabilidade via recorrˆencia linear n˜ao-homogˆenea de pri-

meira ordem para sequˆencias. Ainda, para este exemplo, veriﬁcamos que ele ´e de fato

uma cadeia de Markov.

Uma cadeia de Markov ´e um processo que est´a completamente deﬁnido a partir do

momento em que se conhece as probabilidades de transi¸c˜ao e a distribui¸c˜ao inicial de

probabilidades dos estados. Veremos no Cap´ıtulo 4 que associamos ao processo de Markov

uma matriz de probabilidades de transi¸c˜ao T , onde as entradas dessa matriz s˜ao dadas

pelas probabilidades de transi¸c˜ao pij. Como nosso objetivo ´e obter previs˜oes a longo

prazo, veremos que, com base na aproxima¸c˜ao dos elementos da matriz T n quando T

´e regular, podemos encontrar uma convergˆencia a uma matriz ﬁxa M a medida que os

valores de n aumentam. Portanto, iremos veriﬁcar sob quais condi¸c˜oes uma matriz de

probabilidades de transi¸c˜ao se aproximar´a de uma determinada matriz ﬁxa M . Para

isso, utilizaremos como ferramenta conhecimentos de ´algebra linear a ﬁm de estudarmos

a convergˆencia das matrizes de transi¸c˜ao via autovetores e autovalores at´e chegarmos no

importante Teorema de Perron - Frobenius que nos d´a uma condi¸c˜ao de convergˆencia para

matrizes de transi¸c˜ao.

No ´ultimo cap´ıtulo, buscamos apresentar alguns exemplos do contexto de cadeias de

Markov para serem trabalhados com alunos do Ensino M´edio. Inicialmente, apresentamos

ao leitor uma vers˜ao do Teorema de Perron - Frobenius, no qual n˜ao utiliza conhecimentos

avan¸cados de ´algebra linear para determinar previs˜oes a longo prazo. Fazendo uso deste

Teorema, poderemos encontrar tais previs˜oes utilizando apenas conceitos trabalhados no

Ensino M´edio: matrizes, probabilidade e sistemas lineares. Em seguida, oferecemos uma

proposta de plano de aula para a aplica¸c˜ao dos problemas apresentados anteriormente.

Cap´ıtulo 1

Uma introdu¸c˜ao `a teoria de

probabilidade

Neste cap´ıtulo, apresentamos ao leitor uma abordagem de alguns t´opicos da teoria de

probabilidade, especialmente as deﬁni¸c˜oes de ´algebra, σ-´algebra, probabilidade e vari´avel

aleat´oria. Estes t´opicos ser˜ao necess´arios para o desenvolvimento do conceito de cadeias

de Markov que veremos adiante. Aqui, seguimos como referˆencia o livro [1].

Deﬁni¸c˜ao 1.0.1. O conjunto de todos os resultados poss´ıveis de um experimento aleat´orio

ser´a chamado espa¸co amostral e denotado por Ω. Todo subconjunto A ⊂ Ω ser´a cha-

mado evento. Um evento A ao qual atribu´ımos uma probabilidade ser´a chamado evento

aleat´orio.

No lan¸camento de um dado, temos por exemplo

Ω = {1, 2, 3, 4, 5, 6}.

E o evento: “a face voltada para cima ´e uma n´umero par”´e dado por

A = {2, 4, 6}.

Note que, pela deﬁni¸c˜ao acima, Ω ´e o evento certo e ∅ o evento imposs´ıvel.

Iremos supor que os eventos aleat´orios possuem certas propriedades b´asicas e intui-

tivas, que ser˜ao essenciais para o desenvolvimento posterior da teoria e do c´alculo de

probabilidades.

10

Deﬁni¸c˜ao 1.0.2. Seja A um conjunto de eventos aleat´orios de Ω (cid:54)= ∅ , satisfazendo as

11

seguintes propriedades :

P 1. Ω ∈ A.

P 2. Se A ∈ A, ent˜ao Ac ∈ A.

P 3. Se A ∈ A e B ∈ A, ent˜ao A ∪ B ∈ A .

O conjunto A ´e chamado ´algebra de subconjuntos de Ω.

Proposi¸c˜ao 1.0.3. Seja A uma ´algebra de subconjuntos de Ω. Ent˜ao valem as seguintes

propriedades:

P 4. ∅ ∈ A ;
P 5. Para todo n ∈ N e para toda sequˆencia de subconjuntos A1, A2, ..., An ∈ A, temos
Ai ∈ A e

Ai ∈ A.

n
(cid:92)

i=1

n
(cid:91)

i=1

Demonstra¸c˜ao. Por P 1 temos que Ω ∈ A e por P 2 Ωc = ∅ ∈ A, mostrando a validade

de P 4.

Pelo princ´ıpio da indu¸c˜ao ﬁnita, mostraremos que

n
(cid:91)

i=1

Ai ∈ A.

Para n=2, temos por P 3 que A1 ∪ A2 ∈ A.
n
(cid:91)

Suponhamos a validade para n, ou seja,

Ai ∈ A e mostremos a validade pra n+1.

Novamente, por P 3, como

i=1

n
(cid:91)

Ai ∈ A e An+1 ∈ A segue que

Agora, para mostrar que

i=1

n
(cid:92)

Ai ∈ A, observemos que

n+1
(cid:91)

i=1

Ai ∈ A.

i=1

n
(cid:92)

i=1

(cid:18) n
(cid:91)

(cid:19)c

.

Ac
i

Ai =

i=1

Como Ai ∈ A, i = 1, 2, ..., n, segue que Ac

i ∈ A, i = 1, 2, ..., n. Logo,

parte j´a provada de P 5 e assim,

n
(cid:92)

i=1

(cid:18) n
(cid:91)

(cid:19)c

Ac
i

∈ A.

Ai =

i=1

n
(cid:91)

i=1

Ac

i ∈ A pela

(cid:3)

Esta proposi¸c˜ao diz que uma ´algebra ´e fechada para um n´umero ﬁnito de aplica¸c˜oes

das opera¸c˜oes ∪, ∩ e c.

Considere a seguinte propriedade para eventos aleat´orios:

12

P 3(cid:48). Se An ∈ A para n = 1,2,3,..., ent˜ao

∞
(cid:91)

n=1

An ∈ A.

Deﬁni¸c˜ao 1.0.4. Uma classe A de subconjuntos de um conjunto n˜ao vazio Ω satisfazendo

P 1, P 2 e P 3(cid:48) ´e chamada σ-´algebra de subconjuntos de Ω.

Observa¸c˜ao 1.0.5. Uma σ-´algebra ´e sempre uma ´algebra, pois P 3 ´e consequˆencia de

P 3(cid:48), j´a que A ∪ B = A ∪ B ∪ B ∪ B... ∈ A se A ´e σ-´algebra.

Proposi¸c˜ao 1.0.6. Seja A uma σ-´algebra de subconjuntos de Ω. Se A1, A2, ... ∈ A, ent˜ao
∞
(cid:92)

An ∈ A.

n=1

Demonstra¸c˜ao. Basta observar que

∞
(cid:92)

n=1

(cid:18) ∞
(cid:91)

(cid:19)c

Ac
n

An =

n=1

e aplicar P 2 e P 3(cid:48).

(cid:3)

Podemos dizer, ent˜ao, que uma σ-´algebra ´e fechada para um n´umero enumer´avel de

aplica¸c˜oes com as opera¸c˜oes ∪, ∩ e c.

Por exemplo, se A = 2Ω ´e o conjunto das partes de Ω. Temos que 2Ω ´e uma σ-´algebra

de subconjuntos de Ω. De fato, pela pr´opria deﬁni¸c˜ao de conjunto das partes segue que

as propriedades P 1, P 2 e P 3(cid:48) s˜ao satisfeitas, isto ´e

• Ω ∈ 2Ω;

• Se A ∈ 2Ω ent˜ao Ac ∈ 2Ω;

• Se An ∈ 2Ω para n = 1, 2, 3, ..., ent˜ao

∞
(cid:91)

n=1

An ∈ 2Ω.

1.1 Probabilidade

Uma maneira de deﬁnir uma probabilidade P no conjunto dos eventos aleat´orios ´e

a chamada “frequentista”ou “estat´ıstica”. Neste contexto, deﬁnimos a probabilidade de

13

um evento aleat´orio A, P (A), como o limite da frequˆencia relativa da ocorrˆencia de A em

n repeti¸c˜oes independentes do experimento, com n tendendo ao inﬁnito, isto ´e,

P (A) = lim
n→∞

1
n

× {n´umero de ocorrˆencias de A em n “ensaios”independentes}.

Esta maneira “frequentista”n˜ao ´e ´unica para se deﬁnir probabilidade. Em nosso traba-

lho, usaremos uma deﬁni¸c˜ao axiom´atica para a probabilidade que se deve a Kolmogorov.

Iremos tomar as probabilidades na σ-´algebra A de eventos, com isso, iremos associar a

todo A ∈ A um n´umero real P (A). Mais precisamente temos:

Deﬁni¸c˜ao 1.1.1. Uma fun¸c˜ao P : A → R satisfazendo os axiomas 1,2 e 3 a seguir ´e

chamada probabilidade ﬁnitamente aditiva.

Axioma 1 P (A) ≥ 0;

Axioma 2 P (Ω) = 1;

Axioma 3 Se A1, ..., An ∈ A s˜ao disjuntos dois a dois, ent˜ao

(cid:16) n
(cid:91)

P

(cid:17)

Ak

=

k=1

n
(cid:88)

k=1

P (Ak).

Se ainda a fun¸c˜ao P satisfaz,

Axioma 3’ Se A1, A2, ... ∈ A s˜ao disjuntos, ent˜ao

(cid:16) ∞
(cid:91)

P

(cid:17)

An

=

n=1

∞
(cid:88)

n=1

P (An),

ent˜ao P ´e chamada de medida de probabilidade ou simplesmente uma probabilidade.

Quando P n˜ao satisfaz apenas o Axioma 2 dizemos apenas que P ´e uma medida em

A.

Deﬁni¸c˜ao 1.1.2. Um espa¸co de probabilidade ´e uma tripla (Ω, A, P ), onde

i) Ω ´e um conjunto n˜ao-vazio;

ii) A ´e uma σ-´algebra de subconjuntos de Ω;

iii) P ´e uma probabilidade em A.

Exemplo 1. Temos a seguir alguns exemplos de espa¸cos de medida (de probabilidade):

i) Seja Ω um conjunto qualquer e tome A = {Ø, Ω}. Deﬁna P (Ø) = 0 e P (Ω) = 1.

Ent˜ao (Ω, A, P ) ´e um espa¸co de probabilidade trivial.

ii) Considere Ω sendo um conjunto dos 6 poss´ıveis resultados no lan¸camento de um

14

dado. Escolhe-se peso de

para cada um dos 6 pontos, e para qualquer subconjunto

de Ω escolhe-se como medida a soma dos pesos dos pontos do conjunto. Ent˜ao A ´e

1
6

a fam´ılia de todos os subconjuntos de Ω, e (Ω, A, P ) ´e um espa¸co de probabilidade.

iii) Seja Ω = {0, 1, 2, 3, ...} e π um vetor da forma π = (π0, π1, π2, ...) com πi (cid:62) 0. E

deﬁna o peso de cada elemento i de Ω como m(i) = πi. Para cada subconjunto

de Ω escolha como peso deste conjunto a soma de todos os pesos dos pontos neste

conjunto. Ent˜ao A ´e a fam´ılia de todos os subconjuntos de Ω e (Ω, A, m) ´e um

∞
(cid:88)

espa¸co de medida com m(Ω) =

πi. Quando m(Ω) = 1, m ´e uma medida de

probabilidade.

i=0

1.1.1 Propriedades da probabilidade

Seja P uma probabilidade em uma σ-´algebra A. Suponhamos que todo conjunto A

abaixo perten¸ca a A. Ent˜ao as seguintes propriedades s˜ao consequˆencias dos axiomas

acima:

Propriedade 1: P (Ac) = 1 − P (A).

De fato, pelo Axioma 2, P (Ω) = 1 e Ω = A ∪ Ac.

Como A e Ac s˜ao disjuntos, segue do Axioma 3 que

1 = P (Ω) = P (A ∪ Ac) = P (A) + P (Ac).

Logo, P (Ac) = 1 − P (A).

Em particular, P (∅) = 1 − P (Ω) = 0.

Propriedade 2: 0 ≤ P (A) ≤ 1.

Esta propriedade ´e uma consequˆencia do Axioma 1 e da Propriedade 1.

Propriedade 3: Se A1 ⊂ A2 ent˜ao P (A1) ≤ P (A2).

Note que, A2 = A1 ∪(A2 −A1). Pelo Axioma 3, P (A2) = P (A1)+P (A2 −A1) (cid:62) P (A1).

Propriedade 4: P

(cid:16) n
(cid:91)

(cid:17)

Ai

≤

n
(cid:88)

P (Ai).

15

Vamos utilizar o princ´ıpio da indu¸c˜ao ﬁnita para veriﬁcar a desigualdade acima.

i=1

i=1

Para n = 2, temos:

Pelo Axioma 3, P (A1 ∪ A2) = P (A1) + P (A2 ∩ Ac

1) ≤ P (A1) + P (A2), por P3, j´a que
(cid:16) n
(cid:91)

n
(cid:88)

(cid:17)

Ai

≤

P (Ai)

(A2 ∩ Ac

1) ⊂ A2. Agora, suponhamos a validade para n, ou seja, P

e mostremos a validade para n + 1.

Observe que

i=1

i=1

(cid:16) n+1
(cid:91)

P

(cid:17)

Ai

= P

(cid:16)(cid:16) n
(cid:91)

(cid:17)

Ai

∪ An+1

(cid:17)

.

i=1

i=1

Pelo caso n = 2 e pela hip´otese de indu¸c˜ao segue que:

(cid:16) n+1
(cid:91)

P

(cid:17)

Ai

(cid:16)(cid:16) n
(cid:91)

(cid:17)

Ai

(cid:17)

∪ An+1

= P

i=1

≤ P

i=1

(cid:16) n
(cid:91)

(cid:17)

Ai

i=1

+ P (An+1)

≤

=

n
(cid:88)

i=1
n+1
(cid:88)

i=1

P (Ai) + P (An+1)

P (Ai).

Assim, pelo princ´ıpio da indu¸c˜ao ﬁnita temos a validade para todo n.

Propriedade 5: P

Note que

(cid:16) ∞
(cid:91)

(cid:17)

Ai

≤

i=1

∞
(cid:88)

i=1

P (Ai).

A1 ∪ A2 ∪ A3 ∪ ... = A1 ∪ (A2 \ A1) ∪ (A3 \ (A1 ∪ A2)) ∪ (A4 \ (A1 ∪ A2 ∪ A3)) ∪ ...,

onde A1, (A2 \ A1), (A3 \ (A1 ∪ A2)), (A4 \ (A1 ∪ A2 ∪ A3)),... s˜ao disjuntos.

16

Assim,

(cid:16) ∞
(cid:91)

P

(cid:17)

Ai

i=1

=

=

=
(cid:124)(cid:123)(cid:122)(cid:125)
Axioma3(cid:48)
≤

=

P (A1 ∪ A2 ∪ A3 ∪ ...)

P (A1 ∪ (A2 \ A1) ∪ (A3 \ (A1 ∪ A2)) ∪ ...)

P (A1) + P (A2 \ A1) + P (A3 \ (A1 ∪ A2)) + ...

P (A1) + P (A2) + P (A3) + ...
∞
(cid:88)

P (Ai).

i=1

Onde a desigualdade se deve ao fato de que (A2 \ A1) ⊂ A2, (A3 \ (A1 ∪ A2)) ⊂ A3... e

pela Propriedade 3.

Como iremos trabalhar com cadeias de Markov, a deﬁni¸c˜ao a seguir ser´a bastante

utilizada nos demais cap´ıtulos.

Deﬁni¸c˜ao 1.1.3. Seja (Ω, A, P ) um espa¸co de probabilidade. Se B ∈ A e P (B) > 0, a

probabilidade condicional de A dado B ´e deﬁnida por

P (A|B) =

P (A ∩ B)
P (B)

, A ∈ A.

Teorema 1.1.4 (Probabilidade total). Se a sequˆencia (ﬁnita ou enumer´avel) de eventos

aleat´orios A1, A2, ... formar uma parti¸c˜ao de Ω, ent˜ao

P (B) =

(cid:88)

i

P (Ai)P (B|Ai),

para todo B ∈ A.

Demonstra¸c˜ao. Suponhamos que A1,A2,... formam uma parti¸c˜ao de Ω, isto ´e, os Ai s˜ao

disjuntos e

Ai = Ω.

∞
(cid:91)

i=1

Para todo evento B ∈ A, temos B =

B ∩ Ai s˜ao disjuntos e

(cid:91)

i

(B ∩ Ai). Como os Ai s˜ao disjuntos, ent˜ao os

P (B) = P

(cid:17)

(B ∩ Ai)

(cid:16) (cid:91)

i

(cid:88)

=

i

P (B ∩ Ai) =

(cid:88)

i

P (Ai)P (B|Ai).

(cid:3)

17

1.2 Vari´avel aleat´oria

Deﬁni¸c˜ao 1.2.1. Uma fun¸c˜ao X : Ω −→ R ´e denominada vari´avel aleat´oria, se o con-

junto {X ≤ x} = {ω ∈ Ω : X(ω) ≤ x} ´e um evento aleat´orio (isto ´e, pertence a σ-´algebra

A de eventos de Ω), para todo x ∈ R.

Note que se X ´e uma vari´avel aleat´oria, ent˜ao {X = x} = {ω ∈ Ω : X(ω) = x}

pertence a σ-´algebra A de eventos em Ω, para todo x ∈ R. De fato,

se X ´e uma vari´avel aleat´oria, ent˜ao

(cid:110)

X ≤ x +

(cid:111)

1
n

∈ A e

(cid:110)

X ≤ x −

(cid:111)

1
n

∈ A; n ∈ N.

Assim, como A ´e uma σ-´algebra de eventos,

(cid:110)

X ≤ x −

(cid:111)c

(cid:110)

=

1
n

X > x −

(cid:111)

1
n

∈ A

e

Logo,

(cid:110)

X > x −

(cid:111)

1
n

∩

(cid:110)

X ≤ x +

(cid:110)

x −

=

(cid:111)

1
n

1
n

< X ≤ x +

(cid:111)

1
n

∈ A.

∞
(cid:92)

n=1

(cid:110)

x −

1
n

< X ≤ x +

(cid:111)

1
n

= {X = x} ∈ A.

Al´em disso, se Ω ´e um conjunto ﬁnito, vale notar que pela pr´opria deﬁni¸c˜ao de vari´avel

aleat´oria, se a σ−´algebra de eventos em Ω for o conjunto das partes de Ω, ent˜ao qualquer

fun¸c˜ao em Ω ´e uma vari´avel aleat´oria, pois {X ≤ x} ∈ 2Ω (conjunto das partes de Ω),

para todo x ∈ R.

Exemplo 2. Considere que uma moeda ´e lan¸cada duas vezes sucessivamente.

Seja C cara e K coroa. O espa¸co amostral deste experimento ´e:

Ω = {(C, C); (C, K); (K, C); (K, K)}.

Tomemos a σ−´algebra deste exemplo como sendo o conjunto das partes 2Ω. Podemos

deﬁnir a fun¸c˜ao X como sendo o “n´umero de caras obtidas nos dois lan¸camentos”. Por

exemplo, temos que X((C,C)) = 2 e X((K,C))=1. Note que, X(ω) ∈ {0, 1, 2}, ∀ω ∈ Ω.

18

A fun¸c˜ao X : Ω −→ {0, 1, 2} ´e tal que {ω : X(ω) ≤ x} ∈ 2Ω para todo x ∈ R. Por

exemplo, se x = 1 temos que {ω : X(ω) ≤ 1} = {(C, K), (K, C), (K, K)} ∈ 2Ω e se x =

-2, temos {ω : X(ω) ≤ −2} = ∅ ∈ 2Ω.

Logo, X ´e uma vari´avel aleat´oria.

Deﬁni¸c˜ao 1.2.2. Seja X uma vari´avel aleat´oria. Se o n´umero de valores poss´ıveis de X

for enumer´avel (ﬁnito ou inﬁnito), dizemos que X ´e uma vari´avel aleat´oria discreta. Ou
seja, a imagem da fun¸c˜ao ´e Im(X) = {x1, x2, ...} ⊆ R.

O exemplo anterior ´e um caso de vari´avel aleat´oria discreta. Vejamos a seguir outro

exemplo.

Exemplo 3. Ap´os um exame m´edico, as pessoas podem ser diagnosticadas com zika v´ırus

(Z) ou n˜ao (N). Admita que trˆes pessoas sejam escolhidas ao acaso e classiﬁcadas de

acordo com esse esquema. Temos que o espa¸co amostral ´e dado por:

Ω = {ZZZ, ZZN, ZN N, ZN Z, N ZN, N ZZ, N N Z, N N N }.

Considere a σ−´algebra deste exemplo como sendo o conjunto das partes 2Ω. Ent˜ao a

fun¸c˜ao X, sendo o “n´umero de pessoas diagnosticadas com o zika v´ırus”, ´e uma vari´avel

aleat´oria. O conjunto dos poss´ıveis valores de X ´e {0, 1, 2, 3}, ou seja, X ´e uma vari´avel

aleat´oria discreta.

Deﬁni¸c˜ao 1.2.3. Seja X uma vari´avel aleat´oria. Suponha que os valores poss´ıveis de

X seja qualquer valor num´erico em um determinado intervalo, ou, cole¸c˜ao de intervalos.

Ent˜ao, diremos que X ´e uma vari´avel aleat´oria cont´ınua.

Exemplo 4. Escolher um ponto ao acaso em [0, 1], e seja X o valor do resultado.

Ent˜ao Ω = [0, 1] e X(ω) = ω. Note que os valores poss´ıveis (resultados) para X n˜ao ´e

enumer´avel, pois ´e o intervalo [0, 1]. No caso cont´ınuo, em geral, usa-se a σ−´algebra de

Borel. A grosso modo, a σ-´algebra de Borel na reta ´e a menor σ-´algebra contendo todos
os intervalos, que s˜ao gerados pelas opera¸c˜oes ∪, ∩ e c de intervalos abertos da reta. ´E

poss´ıvel mostrar, mas foge dos objetivos dessa disserta¸c˜ao, que a fun¸c˜ao X ´e uma vari´avel

aleat´oria cont´ınua com a σ-´algebra de Borel, que toma valores em [0, 1].

Cap´ıtulo 2

Espa¸co de probabilidade para

cadeias de Markov

Neste cap´ıtulo, buscamos construir um espa¸co de probabilidade para uma sequˆencia

de vari´aveis aleat´orias em tempo discreto, que ser´a ´util para o c´alculo de probabilidades

envolvendo cadeias de Markov. Esta sequˆencia de vari´aveis aleat´orias ser´a denominada

como processo estoc´astico discreto.

Considere o lan¸camento de uma moeda n˜ao viciada no tempo n = 1, 2, 3, ...T . As faces

da moeda s˜ao: cara(C) ou coroa(K). Denotando por Ω o conjunto de todos os poss´ıveis

resultados dos lan¸camentos at´e o tempo T , temos:

Ω = {ω : ω = (e1, e2, e3, ..., eT )} onde, en = C ou K, para n = 1, 2, ..., T.

O conjunto E = {C, K} que representa os poss´ıveis estados da moeda (poss´ıveis resultados

em cada lan¸camento) ser´a chamado de espa¸co de estados.

Para modelar incertezas sobre os resultados, n´os listamos todos os resultados poss´ıveis,

e o chamamos de estados poss´ıveis. Conforme o tempo passa, mais e mais informa¸c˜oes

s˜ao reveladas sobre os estados que j´a ocorreram. No tempo n = 2, por exemplo, n´os

conhecemos os resultados e1 e e2. Ent˜ao, a informa¸c˜ao que temos ´e

A = {(e1, e2, ∗, ..., ∗)} ⊂ Ω,

onde “*” indica os estados que ainda poder˜ao ocorrer com o decorrer do tempo.

19

20

Esta ideia de informa¸c˜ao dispon´ıvel no tempo n, iremos denotar por Fn, que consiste

nos resultados que ocorreram antes e no tempo n. Fn ´e chamada ´Algebra de Eventos.

Voltando ao exemplo anterior, para T = 2, temos que no tempo n = 0, antes de

realizarmos o experimento, n´os n˜ao temos informa¸c˜oes sobre e1 e e2, e portanto F0 =

{∅, Ω}. Tudo que n´os sabemos ´e que os estados poss´ıveis de ocorrer est˜ao em Ω. Considere

agora o caso n = 1. Suponha que em n = 1 o resultado obtido foi cara (C). Ent˜ao sabemos

que os estados poss´ıveis de ocorrer (nossa informa¸c˜ao) est˜ao em A, e n˜ao est˜ao no seu

complementar Ac, onde

A = {(C, e2), e2 = C ou K} = {(C, C), (C, K)}.

Assim, no tempo n = 1, temos a seguinte ´algebra de eventos

F1 = {∅, Ω, A, Ac}.

Note que F0 ⊂ F1.

Observa¸c˜ao 2.0.1. Fn ´e uma ´algebra de subconjuntos de Ω, ou seja, tem as seguintes

propriedades:

P 1. Ω ∈ F0 ⊂ Fn, para n = 1, 2, ...T.

P 2. Se A ∈ Fn, ent˜ao Ac ∈ Fn .

P 3. Se A ∈ Fn e B ∈ Fn, ent˜ao A ∪ B ∈ Fn.

Exemplo 5. A seguir temos alguns exemplos de ´algebras de eventos:

1. F0 = {Ω, ∅} ´e chamada ´algebra trivial.

2. {∅, Ω, A, Ac} ´e chamada ´algebra gerada por A e denotada por FA.

3. {A : A ∈ Ω} ´e chamada a ´algebra de todos os subconjuntos de Ω e ´e denotada por

2Ω.

Se F ´e uma ´algebra de eventos, ent˜ao todo conjunto de F ´e chamado de conjunto

mensur´avel. Se F = 2Ω, por exemplo, ent˜ao todo subconjunto de Ω ´e mensur´avel.

Deﬁni¸c˜ao 2.0.2. Uma ﬁltra¸c˜ao F ´e a cole¸c˜ao de ´algebras de eventos Fn, com

F = {F0, F1, ..., Fn, ..., FT }; Fn ⊂ Fn+1.

21

A ﬁltra¸c˜ao F ´e utilizada para modelar um ﬂuxo de informa¸c˜oes que s˜ao obtidas com

o decorrer dos experimentos. Conforme o tempo passa, teremos as informa¸c˜oes mais

detalhadas, isto ´e, parti¸c˜oes de Ω cada vez mais ﬁnas.

Exemplo 6. Temos que F = {F0, FA, 2Ω} ´e uma ﬁltra¸c˜ao, pois F0, FA e 2Ω s˜ao ´algebras
de eventos, e ainda F0 ⊂ FA ⊂ 2Ω.

2.1 Processo estoc´astico

Como vimos no cap´ıtulo anterior, se a fun¸c˜ao X ´e uma vari´avel aleat´oria em (Ω, F ),

com Ω sendo um conjunto ﬁnito, ent˜ao todos os conjuntos {X = xi} = {ω ∈ Ω : X(ω) =

xi}, i = 1,...,k pertencem a F . Isto signiﬁca que, se temos a informa¸c˜ao descrita por F ,

isto ´e, conhecemos qual evento da forma {X = xi} ocorreu em F , ent˜ao sabemos qual

valor de X ocorreu. Lembramos que se F = 2Ω, ent˜ao qualquer fun¸c˜ao em Ω ´e uma

vari´avel aleat´oria.

A ﬁm de deﬁnir processo estoc´astico, daremos o seguinte exemplo.

Exemplo 7. Considere o exemplo do lan¸camento de uma moeda n˜ao viciada, para n =

1, 2. Ent˜ao Ω = {ω1 = (C, C), ω2 = (C, K), ω3 = (K, C), ω4 = (K, K)}.

Tome A = {ω1, ω2}, o qual representa o evento em que no tempo n = 1 o resultado

obtido foi cara. Assim, F1 = {∅, Ω, A, Ac} e tome F2 = 2Ω.

Considere as seguintes fun¸c˜oes em Ω:

a) X(ω1) = X(ω2) = 15 e X(ω3) = X(ω4) = 5.

X ´e uma vari´avel aleat´oria em F1, j´a que {ω : X(ω) = 15} = {ω1, ω2} = A ∈ F1 e

{ω : X(ω) = 5} = {ω3, ω4} = Ac ∈ F1.

b) Y (ω1) = 15, Y (ω2) = 75, Y (ω3) = 75, e Y (ω4) = 5.

Y n˜ao ´e uma vari´avel aleat´oria em F1, pois {ω : Y (ω) = 75} = {ω2, ω3} /∈ F1. Por

outro lado, ´e claro que Y ´e uma vari´avel aleat´oria em F2.

Deﬁni¸c˜ao 2.1.1. Um processo estoc´astico adaptado a ﬁltra¸c˜ao F = {F0, F1, ..., FT } ´e uma

sequˆencia de vari´aveis aleat´orias (Xn) em (Ω, Fn), para qualquer n ﬁxado, n = 0, 1, ..., T .

Note que, em particular, para cada n, Xn ´e uma vari´avel aleat´oria em (Ω, FT ).

22

Exemplo 8. Seja X1 = X e X2 = Y como apresentados no Exemplo 7. A sequˆencia {X,
Y} ´e um processo estoc´astico adaptado a ﬁltra¸c˜ao F = {F1, F2}.

Deﬁni¸c˜ao 2.1.2. Seja (Ω, 2Ω) um espa¸co amostral com a ´algebra de todos os eventos, e

X uma vari´avel aleat´oria com valores xi, i = 1,2,...k. Considere os conjuntos

Ai = {ω : X(ω) = xi} ⊆ Ω.

Esses conjuntos formam uma parti¸c˜ao de Ω, e a ´algebra gerada por essa parti¸c˜ao ´e cha-

mada ´algebra gerada por X. Esta ´e a menor ´algebra que cont´em todos os conjuntos da

forma Ai = {X = xi} e ´e denotada por FX. A ´algebra gerada por X representa a in-

forma¸c˜ao que podemos extrair observando X.

Exemplo 9. Considerando o Exemplo 7, temos {ω : X(ω) = 15} = {ω1, ω2} = A e

{ω : X(ω) = 5} = {ω3, ω4} = Ac. Logo, FX = F1 = {∅, Ω, A, Ac}.

2.2 Probabilidade no espa¸co das sequˆencias

Para uma sequˆencia inﬁnita (enumer´avel) de vari´aveis aleat´orias, podemos construir

o espa¸co de probabilidade da seguinte forma: seja Ω o conjunto de todas as sequˆencias

formadas de elementos do espa¸co de estados E (ﬁnito). Um elemento ω ∈ Ω pode ent˜ao

ser escrito da forma

ω = (e0, e1, e2, . . . ),

onde cada ei ∈ E. Os pontos ω ∈ Ω s˜ao chamados de caminhos, o espa¸co Ω ´e chamado

de espa¸co das sequˆencias, e o valor en em um caminho ´e chamado n-´esimo “resultado”em

ω. Por exemplo, se E = {1, 2}, ent˜ao Ω = {(e0, e1, e2, e3, . . . ); ei = 1 ou 2} e o elemento

(1, 2, 1, 1, 1, 2, . . . ) ∈ Ω ´e um caminho ou realiza¸c˜ao de experimentos.

A fun¸c˜ao Xn : Ω → E, dada por

Xn(e0, e1, e2, . . . ) = en,

´e chamada de fun¸c˜ao sa´ıda ou avalia¸c˜ao da trajet´oria ω.

Fixado n, seja Fn a fam´ılia de todas as uni˜oes de Ω da forma

{ω ∈ Ω : X0(ω) ∈ E0, X1(ω) ∈ E1, , . . . Xn(ω) ∈ En},

23

onde E0, E1, . . . En s˜ao subconjuntos do espa¸co de estados E. ´E poss´ıvel veriﬁcar que cada

Fn ´e uma σ-´algebra, mas foge dos objetivos deste trabalho. Al´em disso, Fn ⊂ Fn+1 forma

uma ﬁltra¸c˜ao natural na qual o processo Xn ´e adaptado. Considere agora F a fam´ılia de

conjuntos deﬁnida por

∞
(cid:91)

Fn.

F =

n=0
Cada elemento em F ´e um conjunto de trajet´orias para as quais um n´umero ﬁnito de

entradas da sequˆencia s˜ao restritas a pertencer a certos subconjuntos de E, e as demais

inﬁnitas entradas s˜ao irrestritas. Um conjunto de F ´e chamado de cilindro. Apesar de

F ser uma ´algebra, n˜ao ´e uma σ-´algebra. Por´em, existe a menor σ-´algebra G, tal que

F ⊂ G. Associado a G existe uma ´unica medida de propabilidade µ, tal que

µ(C n

i ) = µ{ω ∈ Ω : X0(ω) = e0, X1(ω) = e1, , . . . Xn(ω) = en}

´e dado pelo produto das probabilidades condicionais entre os estados e0, e1, . . . , en. Cada

conjunto C n
(cid:91)

C =

C n

i ´e chamado de cilindro b´asico de F e vale notar que cada C ∈ Fn ´e da forma

i . Ou seja, constru´ımos um espa¸co de probabilidade (Ω, G, µ), onde µ ´e dada

i

por

µ(e0, e1, . . . , en, ∗, ∗, ∗, . . . ) = p0p10p21 . . . pn(n−1),

onde p0 ´e a probabilidade do processo iniciar no estado e0 e pij = µ{ω ∈ Ω : Xi = ei|Xj =

ej} s˜ao probabilidades condicionais. Para maiores detalhes ver por exemplo, [2, p.43].

Cap´ıtulo 3

Cadeias de Markov

Uma cadeia de Markov ´e um processo estoc´astico (Xn)n∈N, associado a um espa¸co de
probabilidade (Ω, A, P ) que satisfaz uma determinada propriedade (ver equa¸c˜ao 3.2.0.1)

que iremos apresentar mais adiante neste cap´ıtulo. Daremos a seguir algumas deﬁni¸c˜oes e

propriedades b´asicas das probabilidades de transi¸c˜ao que ser˜ao ´uteis para a compreens˜ao

de tal propriedade markoviana.

3.1 Probabilidade de transi¸c˜ao

Deﬁni¸c˜ao 3.1.1. A probabilidade de transi¸c˜ao em um passo, denotada por pij(k), ´e de-

ﬁnida como a seguinte probabilidade condicional:

pij(k) = P (Xk+1 = i|Xk = j).

Isto ´e, a probabilidade de estar no estado i no tempo k + 1, dado que estava no estado

j no momento anterior k, para i, j = 1, 2, ....

Se a probabilidade de transi¸c˜ao pij(k) numa cadeia n˜ao depende do tempo k, dizemos

que ela ´e homogˆenea. Neste caso, usaremos a nota¸c˜ao pij. Se as probabilidades de transi¸c˜ao

dependem do tempo k, dizemos que elas s˜ao n˜ao-estacion´arias ou n˜ao homogˆeneas. Neste

trabalho, estamos interessados em estudar somente os casos homogˆeneos.

Para uma cadeia de Markov com um n´umero ﬁnito de estados, associa-se uma matriz

24

25

de transi¸c˜ao T , que ser´a dada pelas probabilidades de transi¸c˜ao, isto ´e,

T = (pij).

Deﬁni¸c˜ao 3.1.2. A probabilidade de transi¸c˜ao em n-passos (n ≥ 0), denotada por p(n)

ij , ´e

a probabilidade de transferˆencia do estado j para o estado i em n etapas de tempo discreto,

isto ´e,

p(n)
ij = P {Xn = i|X0 = j}.

Novamente, para uma quantidade de estados ﬁnitos, podemos associar uma matriz

T (n), onde a ij-´esima posi¸c˜ao ´e dada por p(n)
vez que p(0)

ij = 0 quando i (cid:54)= j.

ii = 1 e p(0)

ij . Note que T (0) ´e a matriz identidade, uma

Existe uma rela¸c˜ao entre as probabilidades de transi¸c˜ao em n-passos, s-passos e (n−s)-

passos. Essas rela¸c˜oes s˜ao conhecidas como as equa¸c˜oes de Chapman-Kolmogorov :

p(n)
ij =

∞
(cid:88)

k=1

p(n−s)
ik

p(s)
kj ,

0 < s < n.

Em termos matriciais, essas equa¸c˜oes podem ser escritas da forma

T (n) = T (n−s)T (s).

Como T (1) = T , segue-se ent˜ao que

T (2) = T (2−1)T (1)

= T (1)T (1)

= T T

= T 2.

E repetindo este processo sucessivamente tem-se que T (n) = T n, para todo n ≥ 0.

Portanto, uma maneira f´acil de se obter as probabilidades p(n)

ij ´e por meio da matriz T n.
Al´em disso, um outro aspecto interessante em conhecer T n, ´e que o vetor vn de distri-

bui¸c˜ao de probabilidade do processo, no tempo n, ´e igual ao produto matricial T nv0, com

a distribui¸c˜ao inicial v0 escrita de forma transposta. No pr´oximo cap´ıtulo iremos explorar

a rela¸c˜ao entre a distribui¸c˜ao vn e T nv0 com mais detalhes.

26

3.2 Cadeias de Markov

Vejamos alguns exemplos, que se encontram em [3] e [4], que servir˜ao de ilustra¸c˜ao para

compreendermos o contexto de cadeia de Markov.

Considere um interruptor com dois estados:

ligado e desligado. No come¸co do ex-

perimento, o interruptor est´a ligado. A cada minuto depois, jogamos um dado. Se o

resultado do dado mostrar 6, mudamos o estado do interruptor, caso contr´ario, deixamos

como est´a. O estado do interruptor em fun¸c˜ao do tempo ´e um processo de Markov. Este

simples exemplo nos permite explicar o signiﬁcado: “n˜ao tem nenhuma mem´oria”. Se

conhecemos o estado do interruptor no tempo n, n´os podemos prever sua evolu¸c˜ao (em

termos de vari´avel aleat´oria) para todos os tempos futuros, sem requerer conhecimento

sobre o estado do interruptor em tempos menores que n. Em outras palavras, o futuro

do processo depende do presente, mas independe do passado.

Denote por x(n)

1

a probabilidade do interruptor estar ligado no tempo n. Similar-

mente, seja x(n)

2

a probabilidade do interruptor estar desligado no tempo n. A partir das

informa¸c˜oes anteriores, temos a seguinte rela¸c˜ao de recorrˆencia:

x(n+1)
1

=

5
6

x(n)
1 +

1
6

x(n)
2 ,

x(n+1)
2

=

1
6

x(n)
1 +

5
6

x(n)
2 ,

com x(0)

1 = 1 e x(0)

2 = 0. A primeira igualdade vem do fato de que o interruptor ﬁcar´a

ligado no tempo n + 1, se ele estava ligado no tempo n e o dado n˜ao mostrou um 6, ou

ele estava desligado no tempo n e o dado mostrou o n´umero 6. A segunda igualdade ´e

an´aloga.

A equa¸c˜ao anterior pode ser escrita na forma matricial:

x(n+1) =





x(n+1)
1
x(n+2)
2





 =



5

6x(n)
6x(n)

1 + 1
1 + 5

6x(n)
6x(n)

2

2

1





 =







 .





 =





1
6

5 1

1 5

x(n)
1
x(n)
2

5
6

1
6

1
6

5
6


 . x(n).

Considere novamente o interruptor que tem dois estados e no come¸co do experimento

est´a ligado. E vamos supor que ´e jogado um dado a todo minuto. Contudo, desta vez,

n´os mudamos o estado do interruptor somente se o dado mostrar o n´umero 6 e n˜ao ter

ocorrido o n´umero 6 no tempo anterior. Assim, o futuro do processo depende do que

ocorreu no passado.

27

A cadeia de Markov ´e um processo estoc´astico caracterizado por seu estado futuro

depender apenas do seu estado no presente, sendo que os estados passados n˜ao inﬂuen-

ciam no estado futuro. Dizemos ent˜ao que um processo de Markov “n˜ao tem nenhuma

mem´oria”. Analisando os exemplos anteriores, podemos dizer que o primeiro exemplo,

onde o estado do interruptor depende apenas do resultado do dado lan¸cado naquele mi-

nuto, ´e uma cadeia de Markov, enquanto que o segundo exemplo n˜ao ´e uma cadeia de

Markov, pois o estado do interruptor depende do resultado do dado nos tempos anteriores.

Formalmente temos o seguinte:

Deﬁni¸c˜ao 3.2.1. Considere um espa¸co de estados com um n´umero ﬁnito (ou enumer´avel)

de elementos E = {e1, ..., en}. Um processo estoc´astico discreto (Xn)n∈N ´e uma cadeia (ou

processo) de Markov se a probabilidade condicional satisﬁzer

P (Xn+1 = xn+1|X0 = x0, ..., Xn = xn) = P (Xn+1 = xn+1|Xn = xn),

(3.2.0.1)

para todo n ≥ 1 e para toda sequˆencia x0, x1, ..., xn+1 de elementos do espa¸co de estados E.

Essa condi¸c˜ao (3.2.0.1) signiﬁca, em linguagem natural, pensando que n indica o tempo,

que o futuro do processo, uma vez conhecido o estado presente, ´e independente do passado.

As probabilidades condicionais, como j´a mencionamos anteriormente,

pij = P (Xn+1 = ei|Xn = ej),

s˜ao as chamadas probabilidades de transi¸c˜ao. E se para cada i, j

P (Xn+1 = ei|Xn = ej) = P (X1 = ei|X0 = ej),

para todo natural n, a cadeia de Markov ´e dita estacion´aria.

Um processo de Markov est´a completamente deﬁnido a partir do momento em que

se especiﬁca as probabilidades de transi¸c˜ao e a distribui¸c˜ao inicial de probabilidades dos

estados.

A propriedade (3.2.0.1) ser´a geralmente referida como a propriedade da cadeia de

Markov. A mesma propriedade tamb´em pode ser estendida para processos de Markov

com tempo cont´ınuo e espa¸co de estados sendo um intervalo da reta real, como pode ser

visto, por exemplo, em [5].

28

Agora, iremos estudar convergˆencia das distribui¸c˜oes de probabilidade para uma cadeia

ﬁnita, cujas probabilidades de transi¸c˜ao s˜ao todas positivas. Para tal estudo usaremos

t´ecnicas de resolu¸c˜ao de recorrˆencias lineares n˜ao-homogˆeneas (ver [6, p.73]).

Para tal estudo, apresentamos um modelo que descreve a dinˆamica de um telefone que

possui dois estados: livre e ocupado. Neste modelo ´e dado as probabilidades de transi¸c˜ao

e a distribui¸c˜ao inicial do telefone. Apesar de simples, ele ´e suﬁciente e interessante para

os prop´ositos deste cap´ıtulo.

Exemplo 10. Em alguns casos o uso do telefone pode se tornar uma quest˜ao bastante

interessante. Suponha que se o telefone est´a livre em um per´ıodo de tempo, digamos no

n-´esimo minuto, com probabilidade p, onde 0 < p < 1, ele estar´a ocupado no pr´oximo

minuto. Se o telefone est´a ocupado no n-´esimo minuto, ele estar´a livre no pr´oximo minuto

com probabilidade q, onde 0 < q < 1. Assuma que o telefone est´a livre no minuto inicial

(n = 0). Estamos interessados em responder as seguintes quest˜oes:

a)Qual ´e a probabilidade xn do telefone estar livre no n-´esimo minuto?

b) Qual ´e o lim
n→∞

xn, se existir?

Aﬁm de responder as perguntas acima, denotemos por An o evento em que o telefone

est´a livre no n-´esimo minuto e seja Bn= Ω - An o seu complementar, isto ´e, o evento em

que o telefone est´a ocupado no n-´esimo minuto. As condi¸c˜oes do exemplo nos d´a:

P (Bn+1|An) = p

e

P (An+1|Bn) = q.

Assumimos tamb´em que P (A0) = 1, isto ´e x0 = 1. Utilizando esta nota¸c˜ao, temos que

P (An) = xn. Logo,

xn+1 = P (An+1)

= P (An+1|An)P (An) + P (An+1|Bn)P (Bn)

(3.2.0.2)

= (1 − p)xn + q(1 − xn)

= q + (1 − p − q)xn

(3.2.0.3)

A igualdade (3.2.0.2) segue do Teorema 1.1.4.

Note que a igualdade (3.2.0.3) ´e uma recorrˆencia linear n˜ao-homogˆenea de primeira

ordem, ou seja, ´e uma recorrˆencia do tipo xn+1 = g(n)xn + h(n). Vamos resolvˆe-la

utilizando o seguinte fato.

As recorrˆencias lineares n˜ao-homogˆeneas de primeira ordem que mais facilmente se

resolvem, s˜ao da forma xn+1 = xn + f (n).

Com efeito, temos

29

x1 = x0 + f (0)

x2 = x1 + f (1)

x3 = x2 + f (2)

x4 = x3 + f (3)
...

Somando ambos os membros, obtemos xn = x0 +

xn = xn−1 + f (n − 1)
n−1
(cid:88)

f (k).

Considere an uma solu¸c˜ao n˜ao nula da recorrˆencia xn+1 = g(n)xn. A substitui¸c˜ao

k=0

xn = anyn transforma

em

xn+1 = g(n)xn + h(n)

an+1yn+1 = g(n)anyn + h(n).

Mas, an+1 = g(n)an, pois an ´e solu¸c˜ao de xn+1 = g(n)xn. Portanto, a equa¸c˜ao se

transforma em

ou seja,

g(n)anyn+1 = g(n)anyn + h(n),

yn+1 = yn + h(n)[g(n)an]−1.

Agora, resolvendo a equa¸c˜ao yn+1 = yn + h(n)[g(n)an]−1, que est´a na forma yn+1 =

yn + f (n), como mencionado anteriormente, basta depois tomar xn = anyn.

Voltando `a recorrˆencia

xn+1 = q + (1 − p − q)xn

encontrada em nosso problema , vamos resolvˆe-la utilizando os coment´arios anteriores.

Inicialmente, vamos encontrar uma solu¸c˜ao n˜ao nula da recorrˆencia

xn+1 = (1 − p − q)xn.

(3.2.0.4)

Temos:

30

x1 = (1 − p − q)x0

x2 = (1 − p − q)x1

x3 = (1 − p − q)x2
...

xn = (1 − p − q)xn−1

Multiplicando todos os termos de cada lado das igualdades, resulta

xn = (1 − p − q)nx0.

Logo, tomando uma condi¸c˜ao inicial x0 = 1 temos que an = (1 − p − q)n ´e uma solu¸c˜ao

n˜ao nula da recorrˆencia (3.2.0.4). Fa¸camos a substitui¸c˜ao de xn = (1 − p − q)nyn em

(3.2.0.3). Obtemos ent˜ao que

(1 − p − q)n+1yn+1 = q + (1 − p − q)(1 − p − q)nyn,

e assim

yn+1 =

q

(1 − p − q)n+1 + yn,

onde x0 = (1 − p − q)0y0 e, portanto, y0 = x0 = 1. Temos ent˜ao que

y1 =

y2 =

y3 =

q

(1 − p − q)1 + y0

q

(1 − p − q)2 + y1

q

(1 − p − q)3 + y2

...

yn =

q

(1 − p − q)n + yn−1.

Somando os termos de cada lado das igualdades, resulta em

yn = y0 +

q
(1 − p − q)

+

q
(1 − p − q)2 +

q

(1 − p − q)3 + . . . +

q
(1 − p − q)n

yn = 1 +

q
(1 − p − q)
(cid:124)

+

q
(1 − p − q)2 +

q

(1 − p − q)3 + . . . +
(cid:123)(cid:122)

q
(1 − p − q)n
(cid:125)

soma dos n primeiros termos de uma P.G. de raz˜ao

1
1−p−q

31

yn = 1 +

q
1 − p − q

yn = 1 +

q
1 − p − q

(cid:35)

(cid:34) (

1

1

1−p−q )n − 1
1−p−q − 1
(cid:34) 1−(1−p−q)n
(1−p−q)n
p+q
1−p−q

(cid:35)

yn = 1 +

q(1 − (1 − p − q)n)
(p + q)(1 − p − q)n .

Substituindo em xn = (1 − p − q)nyn, temos

xn = (1 − p − q)n +

(1 − p − q)nq(1 − (1 − p − q)n)
(p + q)(1 − p − q)n

= (1 − p − q)n +

= (1 − p − q)n +

q(1 − (1 − p − q)n)
p + q
q − q(1 − p − q)n
p + q

=

q
p + q

+

(p + q)(1 − p − q)n − q(1 − p − q)n
p + q
p(1 − p − q)n
q + p

q
q + p

+

.

=

Logo, a probabilidade xn para que o telefone esteja livre no n-´esimo minuto ´e dada por

xn =

q
q + p

+

p(1 − p − q)n
q + p

.

Agora, como 0 < p <1 e 0 < q <1 segue que |1 − p − q|<1, e assim (1 − p − q)n → 0,

quando n → ∞. Isto nos d´a a resposta do item (b) deste exemplo, isto ´e, lim
n→∞

xn =

q
p + q

.

Uma abordagem diferente da demonstra¸c˜ao acima, poder´a ser vista mais adiante no

Exemplo 20 do Cap´ıtulo 5, na qual utiliza uma vers˜ao do Teorema de Perron-Frobenius

para estudar a existˆencia do limite (convergˆencia da matriz de transi¸c˜ao). Al´em disso,

caso o leitor tenha curiosidade, em [4, p.86], tamb´em h´a uma outra demonstra¸c˜ao em que

n˜ao se usa solu¸c˜oes de recorrˆencias lineares n˜ao-homogˆeneas (como apresentamos neste

trabalho), nem Perron-Frobenius.

32

O objetivo principal agora, ´e mostrar que de fato o modelo apresentado no Exemplo

10 ´e uma cadeia de Markov. Para isto, considere o processo estoc´astico (Xn) como visto

no Cap´ıtulo 2.

Proposi¸c˜ao 3.2.2. O modelo apresentado no Exemplo 10 ´e uma cadeia de Markov, isto

´e, veriﬁca (3.2.0.1).

Demonstra¸c˜ao.

Considere o espa¸co de estados E = {1, 2}, sendo 1 o estado livre e 2 o estado ocupado.

Tomaremos Ω como sendo o conjunto de todas as sequˆencias.

Figura 3.1: Diagrama do Exemplo 10

A ﬁm de construir a probabilidade nos cilindros, tomemos ν0 como sendo alguma

probabilidade em E. Pelas informa¸c˜oes do problema temos que ν0(1) = 1 e ν0(2) = 0,

pois o telefone est´a livre no minuto inicial. A medida de probabilidade ν0 escolhida,

corresponde a distribui¸c˜ao inicial do processo estoc´astico que iremos deﬁnir. Podemos

ent˜ao deﬁnir a probabilidade P da seguinte forma.

Se ω = (e0, e1, ...) ∈ Ω, tomemos

P ({ω ∈ Ω : ω0 = e0}) = ν0({e0});

P ({ω ∈ Ω : ωi = ei, i = 0, ..., n + 1}) = p(en+1|en)P ({ω ∈ Ω : ωi = ei, i = 0, ..., n}),

(3.2.0.5)

onde p(en+1|en) ´e a probabilidade de transi¸c˜ao do estado en para en+1, podendo ser

p(1|1) = 1 − p, p(1|2) = q, p(2|1) = p ou p(2|2) = 1 − q.

Notemos que P est´a deﬁnida por meio de um processo indutivo que s´o depende da

distribui¸c˜ao inicial e das probabilidades de transi¸c˜ao. Por exemplo, a medida para o

 Livre Ocupado 1 2 p q 1- q 1- p 33

conjunto das sequˆencias em que restringimos os dois primeiros estados, e0 e e1, ´e dada

pelo produto da probabilidade inicial de e0 pela probabilidade de transi¸c˜ao de e0 para e1,

isto ´e:

P ({ω ∈ Ω : ω0 = e0, ω1 = e1}) = p(e1|e0)ν0({e0}).

Analogamente, para o caso em que restringimos aos estados e0, e1 e e2, temos

P ({ω ∈ Ω : ω0 = e0, ω1 = e1, ω2 = e2}) = p(e2|e1)P ({ω ∈ Ω : ω0 = e0, ω1 = e1})

= p(e2|e1)p(e1|e0)ν0({e0}).

E fazendo isso, sucessivamente, para mais estados, nota-se que de fato a f´ormula

(3.2.0.5) s´o depende das probabilidades de transi¸c˜ao e da distribui¸c˜ao inicial. Al´em disso,

como

Ω = {ω ∈ Ω : ω0 = 1} ∪ {ω ∈ Ω : ω0 = 2},

segue que P (Ω) = ν0(Ω) = 1.

Como no Cap´ıtulo 2, considere o processo estoc´astico Xn : Ω −→ R, n ∈ IN , dado

por

Xn(ω) = ωn,

onde ω = (ω0, ω1, ..., ωn, ...). Primeiro vamos mostrar que as probabilidades de transi¸c˜ao

de Xn s˜ao o que deveriam ser, isto ´e,

P (Xn+1 = 2|Xn = 1) = p,

P (Xn+1 = 1|Xn = 2) = q.

(3.2.0.6)

(3.2.0.7)

Da deﬁni¸c˜ao de P temos que

P (Xn+1 = 2, Xn = 1) = P ({ω ∈ Ω : ωn = 1, ωn+1 = 2})

=

=

(cid:88)

e0,...,en−1∈E
(cid:88)

e0,...,en−1∈E

= p

(cid:88)

P ({ω ∈ Ω : ωi = ei, i = 0, ..., n − 1, ωn = 1, ωn+1 = 2})

p(2|1)P ({ω ∈ Ω : ωi = ei, i = 0, ..., n − 1, ωn = 1})

P ({ω ∈ Ω : ωi = ei, i = 0, ..., n − 1, ωn = 1})

e0,...,en−1∈E

= pP (Xn = 1).

(3.2.0.8)

34

A segunda igualdade, em que aparece a soma sobre os estados, segue da Proposi¸c˜ao

(1.1.4) tomando uma parti¸c˜ao em Ω, por meio de conjuntos formados de trajet´orias em

que se ﬁxa os primeiros n estados e0, e1, . . . , en−1.

Pela deﬁni¸c˜ao de probabilidade condicional e da igualdade (3.2.0.8) segue que

P (Xn+1 = 2|Xn = 1) =

P (Xn+1 = 2, Xn = 1)
P (Xn = 1)

= p.

Pelos mesmos argumentos segue que P (Xn+1 = 1|Xn = 2) = q.

Vamos agora veriﬁcar que

P (Xn+1 = en+1|X0 = e0, ..., Xn = en) = P (Xn+1 = en+1|Xn = en).

De fato,

P (Xn+1 = en+1|X0 = e0, ..., Xn = en) =

=

=

P (X0 = e0, ..., Xn = en, Xn+1 = en+1)
P (X0 = e0, ..., Xn = en)
P ({ω ∈ Ω : ωi = ei, i = 0, ..., n + 1})
P ({ω ∈ Ω : ωi = ei, i = 0, ..., n})

p(en+1|en)P ({ω ∈ Ω : ωi = ei, i = 0, ..., n})
P ({ω ∈ Ω : ωi = ei, i = 0, ..., n})

Por outro lado, de (3.2.0.6) e (3.2.0.7) temos que

= p(en+1|en).

P (Xn+1 = en+1|Xn = en) = p(en+1|en).

(cid:3)

Apesar de trabalhosa, a demonstra¸c˜ao acima poderia ser adaptada para um processo

com mais de dois estados, desde que E seja ﬁnito. Boa parte da demonstra¸c˜ao acima foi

baseada em t´ecnicas que aparecem em [4, p.88].

Cap´ıtulo 4

Matrizes de transi¸c˜ao agindo em

vetores de distribui¸c˜ao

A ﬁm de introduzir as propriedades de vetor de probabilidade, matrizes de transi¸c˜ao

e suas rela¸c˜oes, iniciaremos com o seguinte exemplo.

Considere que em um habitat natural existem 1000 passarinhos e que este habitat foi

dividido em quatro regi˜oes denotadas por R1, R2, R3 e R4. Vamos supor ainda que, a cada

dia, um pesquisador anota as informa¸c˜oes sobre as posi¸c˜oes dos p´assaros em cada regi˜ao,

com o intuito de observar a migra¸c˜ao em busca de alimento. N˜ao estando interessados

em entender o comportamento de cada passarinho, mas a distribui¸c˜ao deles nas regi˜oes

R1, R2, R3 e R4, podemos considerar um vetor com 4 coordenadas indicando a quantidade

de passarinhos em cada regi˜ao em um determinado dia. Por exemplo, se em um determi-

nado dia temos R1 com 150 passarinhos, R2 com 225 passarinhos, R3 com 250 passarinhos

e R4 com 375 passarinhos podemos escrever esta informa¸c˜ao como











150

225

250

375











.

Podemos tamb´em escrever este vetor indicando a porcentagem de p´assaros em cada

regi˜ao, se n˜ao estivermos interessados na quantidade total de passarinhos por regi˜ao.

A partir dos n´umeros acima, temos que 15% dos passarinhos est˜ao em R1, 22,5% dos

35

passarinhos est˜ao em R2, 25% dos passarinhos est˜ao em R3 e 37,5% dos passarinhos est˜ao

36

em R4. Podemos escrever esta informa¸c˜ao como














15%

22, 5%

25%

37, 5%

ou



























.

0, 15

0, 225

0, 25

0, 375

Se para cada dia associarmos um vetor como este ´ultimo, descrevendo a porcentagem

de passarinhos de cada regi˜ao, podemos observar que todos estes vetores possuem quatro

coordenadas n˜ao negativas cuja soma resulta em 1.

Deﬁni¸c˜ao 4.0.1. Dizemos que v ∈ Rn ´e um vetor de probabilidade se suas coordenadas

v1, ..., vn satisfazem:

a) vi ≥ 0, i ∈ {1, ..., n};

b) v1 + v2 + ... + vn = 1.

4.1 Matrizes estoc´asticas de transi¸c˜ao

Suponhamos agora que para este modelo, independente da informa¸c˜ao conhecida a

mais de um dia e da quantidade de dias j´a observados, as porcentagens pij’s de passarinhos

que migram para a regi˜ao Ri saindo da regi˜ao Rj , ao compararmos dias consecutivos,

seja estabelecida em T = (pij)4×4, onde

T =











p11 p12 p13 p14

p21 p22 p23 p24

p31 p32 p33 p34

p41 p42 p43 p44











=











0, 2 0, 1 0, 1 0, 15

0, 3 0, 3 0, 3 0, 25

0, 2 0, 4 0, 5

0, 2

0, 3 0, 2 0, 1

0, 4











.

Assim, observando por exemplo a terceira coluna desta matriz, temos como previs˜ao:

- 10% dos passarinhos em R3 na fotograﬁa atual estar˜ao em R1 na pr´oxima fotograﬁa.

- 30% dos passarinhos em R3 na fotograﬁa atual estar˜ao em R2 na pr´oxima fotograﬁa.

- 50% dos passarinhos em R3 na fotograﬁa atual estar˜ao em R3 na pr´oxima fotograﬁa.

- 10% dos passarinhos em R3 na fotograﬁa atual estar˜ao em R4 na pr´oxima fotograﬁa.

37

As entradas da matriz dada acima s˜ao n˜ao negativas e a soma dos elementos de cada

coluna resulta em 1. Assim, as colunas da matriz s˜ao vetores de probabilidade.

Deﬁni¸c˜ao 4.1.1. Dizemos que uma matriz quadrada Tn×n com entradas {pij}, 1 ≤ i, j ≤

n ´e (coluna) estoc´astica se satisfaz:

a) pij ≥ 0, para quaisquer i, j ∈ {1, ..., n};

b) p1j + ... + pnj = 1 para qualquer j ∈ {1, ..., n}.

Denotemos por Xn a vari´avel aleat´oria que assume valores em {1, 2, 3, 4}, que indica a

regi˜ao onde se localiza um determinado passarinho no n-´esimo dia. Ou seja, o processo Xn

indica a trajet´oria realizada por um determinado passarinho (escolhido pelo pesquisador)

ao longo do tempo n. As probabilidades de deslocamento entre as regi˜oes podem ser

descritas como uma probabilidade condicional:

P (Xn+1 = i|Xn = j) = pij.

Como j´a vimos anteriormente, denota-se por T (n) = (p(n)

ij ) a matriz de probabilidades

de sair do estado j e chegar em i em n etapas. Para n = 0 e n = 1,

ij = pij e p(0)
p(1)

ij = δij =




1, i = j



0, i (cid:54)= j

Isto ´e, T (1) = T e T (0) = I, onde I ´e a matriz identidade. Al´em disso, vimos que

T (n) = T n.

Obtemos uma matriz das probabilidades de transi¸c˜ao T a partir da tabela de proba-

bilidades, onde o elemento na i-´esima linha e j-´esima coluna indica a probabilidade de

transi¸c˜ao do j-´esimo estado para o i-´esimo estado. Notemos que, desta maneira, a soma

dos elementos de cada coluna ser´a sempre igual a 1, pois essa soma representa a probabi-

lidade do espa¸co amostral, em que cada entrada ´e a probabilidade de um evento disjunto

deste espa¸co amostral. Podemos obter as probabilidades de transi¸c˜ao pij em cada passo

de forma matricial, representada da seguinte forma para uma matriz 2 × 2:





T =



 .

p11 p12

p21 p22

38

Neste caso, por exemplo, a probabilidade de sair do estado 1 e continuar no estado 1

ap´os um passo ´e:

p(1)
11 = P (X1 = 1|X0 = 1) = p11.

Da mesma forma, a probabilidade de sair do estado 1 e chegar no estado 2 ap´os um

passo ´e:

E assim sucessivamente.

p(1)
21 = P (X1 = 2|X0 = 1) = p21.

Notemos ent˜ao que a matriz T = (pij)4×4 do exemplo dos passarinhos ´e uma matriz

de transi¸c˜ao.

Para calcular as probabilidades de transi¸c˜ao em mais de um passo, basta elevarmos a

matriz ao passo desejado. Por exemplo, para sabermos a possibilidade de sair do estado

1 e continuar no estado 1 em 2 passos fazemos:





T 2 =

p11 p12

p21 p22





 .



p11 p12

p21 p22





 =



p11p11 + p12p21 p11p12 + p11p22

p21p11 + p22p21 p21p12 + p22p22



 ,

onde o elemento a11 de T 2 nos dar´a o resultado desejado.

Pode-se observar esse resultado de outra forma, conhecida como ´arvore das probabili-

dades.

Figura 4.1: ´Arvore das Probabilidades

Para encontrarmos a probabilidade de sair do estado 1 e continuar no estado 1 em 2

121212p11p21p11p21p12p22139

passos atrav´es da ´arvore, basta multiplicar os “ramos da ´arvore”para obter:

p11p11 + p21p12,

onde este resultado nada mais ´e que p(2)

11 , como esperado.

Observe que em ambos os m´etodos, tanto o m´etodo da ´arvore quanto o da multiplica¸c˜ao

de matrizes, obtemos o mesmo resultado. O mesmo vale para p(2)

12 , p(2)

21 e p(2)
22 .

Podemos concluir ent˜ao que o en´esimo-passo da matriz de transi¸c˜ao T ´e apenas a

en´esima potˆencia de T .

Tendo em conta a distribui¸c˜ao da probabilidade associada com Xn, veremos mais

adiante que a distribui¸c˜ao da probabilidade associada com Xn+1 pode ser obtida multi-

plicando a matriz de transi¸c˜ao T por vn.

Exemplo 11. Considerando o vetor de probabilidade encontrado no exemplo dos passa-

rinhos





















0, 15

0, 225

0, 25

0, 375

para o dia atual, qual previs˜ao podemos fazer para o vetor associado ao dia seguinte?

Denotemos por v0 o vetor que indica a distribui¸c˜ao dos passarinhos no tempo 0 (dia

atual) e buscamos uma previs˜ao de v1, que indica a distribui¸c˜ao dos passarinhos no tempo

1 (dia seguinte). Qual a probabilidade de um dado passarinho estar em R1 no tempo 1?

Pelas informa¸c˜oes acima, temos que

v0 =











0, 15

0, 225

0, 25

0, 375











.

Assim, observando os “ramos da ´arvore”da Figura 4.2 temos que

40

Figura 4.2: ´Arvore de probabilidade.

P (X1 = 1) = P (X1 = 1|X0 = 1)P (X0 = 1) + P (X1 = 1|X0 = 2)P (X0 = 2) +

P (X1 = 1|X0 = 3)P (X0 = 3) + P (X1 = 1|X0 = 4)P (X0 = 4) =

= (0, 2)(0, 15) + (0, 1)(0, 225) + (0, 1)(0, 25) + (0, 15)(0, 375) =

= 0, 03 + 0, 0225 + 0, 025 + 0, 05625 =

= 0, 13375.

R1R2R3R4R1R1R1R1R2R2R2R2R3R3R3R3R3R4R4R4R40,150,2250,250,3750,20,30,20,30,10,30,40,20,10,30,50,10,150,250,20,441

Analogamente temos,

P (X1 = 2) = (0, 3)(0, 15) + (0, 3)(0, 225) + (0, 3)(0, 25) + (0, 25)(0, 375) =

= 0, 045 + 0, 0675 + 0, 075 + 0, 09375 = 0, 28125.

P (X1 = 3) = (0, 2)(0, 15) + (0, 4)(0, 225) + (0, 5)(0, 25) + (0, 2)(0, 375) =

= 0, 03 + 0, 09 + 0, 125 + 0, 075 = 0, 32.

P (X1 = 4) = (0, 3)(0, 15) + (0, 2)(0, 225) + (0, 1)(0, 25) + (0, 4)(0, 375) =

= 0, 045 + 0, 045 + 0, 025 + 0, 15 = 0, 265.

Assim, nossa previs˜ao v1 ´e dada por

v1 =











0, 13375

0, 28125

0, 32

0, 265











.

Note que esses c´alculos podem ser obtidos de maneira mais “f´acil”:

v1 =











0, 13375

0, 28125

0, 32

0, 265





















=

0, 2 0, 1 0, 1 0, 15

0, 3 0, 3 0, 3 0, 25

0, 2 0, 4 0, 5

0, 2

0, 3 0, 2 0, 1

0, 4













.



















0, 15

0, 225

0, 25

0, 375

= T.v0

Para a previs˜ao de v1 podemos, como visto acima, calcular o produto da matriz coluna

estoc´astica T, pelo vetor de probabilidade v0. Note que neste exemplo o produto de uma

matriz coluna estoc´astica por um vetor de probabilidade resultou em um novo vetor de

probabilidade.

Proposi¸c˜ao 4.1.2. Se Tn×n ´e uma matriz estoc´astica e v ∈ R ´e um vetor de probabilidade,

ent˜ao T v ´e um vetor de probabilidade.

Demonstra¸c˜ao. Seja w = T v. Temos que T = (pi,j)1≤i,j≤n, v = (vi)1≤i≤n e w = (wi)1≤i≤n.

Assim,

42

w =











w1

w2
...
wn











Assim,

= T v =











p11 p12

p21 p22
...
...
pn1 pn2

· · ·

· · ·
. . .

· · ·































v1

v2
...
vn

p1n

p2n
...
pnn











=

p11v1 + p12v2 + · · · + p1nvn

p21v1 + p22v2 + · · · + p2nvn
...
pn1v1 + pn2v2 + · · · + pnnvn











wi =

n
(cid:88)

k=1

pikvk,

i = 1, 2, ..., n.

Como T ´e coluna estoc´astica, segue que:

n
(cid:88)

i=1

pik = 1, k = 1, 2, ..., n e pik ≥ 0, para todo i, k = 1, 2, ..., n.

Como v ´e um vetor de probabilidade segue que:

Logo,

n
(cid:88)

k=1

vk = 1 e

vk ≥ 0, ∀k = 1, 2, ..., n.

n
(cid:88)

wi =

pikvk ≥ 0, ∀i = 1, 2, ..., n e

w1+w2+...+wn =

n
(cid:88)

i=1

wi =

k=1
(cid:18) n

(cid:88)

n
(cid:88)

(cid:19)

pikvk

=

n
(cid:88)

n
(cid:88)

pikvk =

n
(cid:88)

(cid:18) n

(cid:88)

(cid:19)

pik

=

vk

i=1

k=1

k=1

i=1

k=1

i=1

Portanto, w = T v ´e um vetor de probabilidade.

n
(cid:88)

k=1

vk = 1.

(cid:3)

Proposi¸c˜ao 4.1.3. Se An×n e Bn×n s˜ao matrizes estoc´asticas, ent˜ao AB ´e uma matriz

estoc´astica.

Demonstra¸c˜ao.

Basta mostrar que se A = (aij)r×r e B = (bij)r×r s˜ao matrizes es-

toc´asticas, ent˜ao a matriz AB tamb´em ´e estoc´astica.

Cada entrada ij da matriz AB ´e dada por

(AB)ij =

r
(cid:88)

k=1

aikbkj.

E somando os elementos da j-´esima coluna, temos que:

r
(cid:88)

(AB)ij =

r
(cid:88)

(cid:16) r
(cid:88)

(cid:17)

aikbkj

i=1

i=1
r
(cid:88)

k=1
(cid:16) r
(cid:88)

(cid:17)

bkj

aik

i=1
(cid:124) (cid:123)(cid:122) (cid:125)
1

bkj

k=1

r
(cid:88)

k=1

=

=

= 1.

43

(cid:3)

A ﬁm de mostrar que vn = T nv0, iniciamos com o seguinte exemplo.

Exemplo 12. Retomando o exemplo dos passarinhos, seja vn o vetor da previs˜ao no

tempo n. Qual ser´a o vetor vn+1 previsto no tempo n + 1?

Temos

vn =











.











vn
1
vn
2
vn
3
vn
4

Seja P (Xn+1 = i|Xn = j) = pij, onde

T = (pij) =











0, 2 0, 1 0, 1 0, 15

0, 3 0, 3 0, 3 0, 25

0, 2 0, 4 0, 5

0, 2

0, 3 0, 2 0, 1

0, 4











.

Ent˜ao,

vn+1 =











P (Xn+1 = 1)

P (Xn+1 = 2)

P (Xn+1 = 3)

P (Xn+1 = 4)











44











(cid:80)4

(cid:80)4

(cid:80)4

(cid:80)4

j=1 P (Xn+1 = 1|Xn = j)P (Xn = j)
j=1 P (Xn+1 = 2|Xn = j)P (Xn = j)
j=1 P (Xn+1 = 3|Xn = j)P (Xn = j)
j=1 P (Xn+1 = 4|Xn = j)P (Xn = j)


0, 2vn

0, 3vn

0, 2vn

0, 3vn

1 + 0, 1vn
1 + 0, 3vn
1 + 0, 4vn
1 + 0, 2vn

3 + 0, 15vn
2 + 0, 1vn
4
3 + 0, 25vn
2 + 0, 3vn
4
3 + 0, 2vn
2 + 0, 5vn
4
3 + 0, 4vn
2 + 0, 1vn
4
























0, 2 0, 1 0, 1 0, 15

0, 3 0, 3 0, 3 0, 25

0, 2 0, 4 0, 5

0, 2

0, 3 0, 2 0, 1

0, 4

















vn
1
vn
2
vn
3
vn
4

= T vn.



















=

=











=

Por outro lado, como v1 = T v0, segue que

e, portanto,

v2 = T v1 = T (T v0) = T 2v0,

v3 = T v2 = T (T 2v0) = T 3v0,

e, assim por diante. Temos ent˜ao que vn = T nv0.

Com base neste racioc´ınio, conhecida uma matriz estoc´astica (transi¸c˜ao) Tn×n e um
vetor de probabilidade v0 ∈ Rn, podemos tentar estimar o comportamento do vetor vn “a

longo prazo”. Sendo assim, queremos veriﬁcar se as coordenadas de vn se aproximam das

coordenadas de algum vetor w, quando n → ∞.

Daremos agora um exemplo, utilizando o fato que vn+1 = T vn, para estudar uma

convergˆencia dos vetores de probabilidade conforme o valor de n (tempo) aumenta.

Exemplo 13. Em uma determinada regi˜ao, veriﬁca-se que se chover em um dia, a pro-

babilidade de que chova no dia seguinte ´e 1

chover (seca) tamb´em ´e 1

2, e por consequˆencia a probabilidade de n˜ao
2. Se, no entanto, tivermos seca em um dia, temos que a pro-
4 e de seca, 3
4. Suponhamos que estas

babilidade de chuva para o pr´oximo dia ser´a de 1

probabilidades n˜ao mudar˜ao ao decorrer do tempo e que no dia atual choveu.

45

Assim, temos dois poss´ıveis estados a cada dia: Chuva (C) e Seca (S).

O vetor de probabilidade inicial v0 ´e dado por:

v0 =



 .





1

0

A partir das informa¸c˜oes fornecidas pelo problema, cujas possibilidades s˜ao chuva e

seca, compomos uma tabela de probabilidades de transi¸c˜ao:

Chuva Seca

Chuva

Seca

1
2

1
2

1
4

3
4

Utilizando os dados acima, temos a seguinte matriz de transi¸c˜ao:

T =





1
2

1
2



 .

1
4

3
4

Qual ser´a a probabilidade de chuva e seca ap´os um longo per´ıodo?

Vamos veriﬁcar, por exemplo, a probabilidade ap´os um per´ıodo de n = 5 dias.

Temos:

v1 = T v0 =





1
2

1
2





 ·



1

0

1
4

3
4





 =







 =





 ;

0, 5

0, 5

1
2

1
2

v2 = T v1 =

v3 = T v2 =









1
2

1
2

1
2

1
2





 ·







 ·



1
4

3
4

1
4

3
4

1
2

1
2

3
8

5
8





 =







 =



3
8

5
8

11
32

21
32





 =







 =



0, 375000000000000

0, 625000000000000

0, 343750000000000

0, 656250000000000



 ;



 ;

v4 = T v3 =

v5 = T v4 =









1
2

1
2

1
2

1
2

1
4

3
4

1
4

3
4





 ·







 ·



11
32

21
32

43
128

85
128





 =







 =



43
128

85
128

171
512

341
512





 =



0, 335937500000000

0, 664062500000000





 =



0, 333984375000000

0, 666015625000000



 ;



 .

46

A partir dos c´alculos acima, podemos perceber que, ap´os um per´ıodo de 5 dias, a

probabilidade de chuva ser´a, aproximadamente, 0, 334 = 33, 4% e de fazer seca ser´a

0, 666 = 66, 6%.

Al´em disso, podemos usar o fato de que vn = T nv0 e o software “calculadora de

matrizes”, dispon´ıvel em [7], no qual ´e uma ferramenta para c´alculos envolvendo matrizes,

para calcular as distribui¸c˜oes vn para valores de n cada vez maiores.

Considerando uma aproxima¸c˜ao com 15 casas decimais, temos,

Para n = 10:

v10 = T 10v0 =

Para n = 50:

v50 = T 50v0 =

Para n = 100:

v100 = T 100v0 =

Para n = 200:

v200 = T 200v0 =

















1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
2

1
4

3
4

1
4

3
4

1
4

3
4

1
4

3
4



10





·





50





·







 =







 =



1

0

1

0

0, 333333969116211

0, 666666030883789

0, 333333333333333

0, 666666666666667



 .



 .



100





·





200





·







 =







 =



1

0

1

0

0, 333333333333333

0, 666666666666667

0, 333333333333333

0, 666666666666667



 .



 .

Podemos notar que parece haver uma convergˆencia nas probabilidades conforme o valor

de n aumenta ou seja,





vn −→

0, 333333333333333

0, 666666666666667



 , quando n −→ ∞.

Veremos mais adiante que, a longo prazo, o comportamento do clima desta dada regi˜ao

poder´a ser previsto com base na aproxima¸c˜ao dos elementos das matrizes T n(n = 1, 2, ...)

a uma matriz ﬁxa M , quando os valores de n aumentam (n −→ ∞).

Se T n se aproxima de uma matriz M , ent˜ao haver´a previs˜ao concisa a longo prazo,

n˜ao sofrendo mudan¸cas signiﬁcativas a cada passo do processo. Portanto, faz-se necess´ario

identiﬁcar sob quais condi¸c˜oes uma matriz das probabilidades de transi¸c˜ao se aproximar´a

de uma determinada matriz ﬁxa M .

47

4.1.1 Convergˆencia de matrizes de transi¸c˜ao diagonaliz´aveis

Como vimos anteriormente, estamos interessados em estudar sob quais condi¸c˜oes uma

matriz estoc´astica se aproximar´a de uma determinada matriz M . Mostraremos nesta se¸c˜ao

um caso especial de convergˆencia de matrizes estoc´asticas diagonaliz´aveis.

Seja T = [f ]can

can, onde can representa a base canˆonica de Rk, uma matriz de transi¸c˜ao.
Da ´algebra linear, sabemos que podemos associar a matriz T a uma transforma¸c˜ao linear

f : Rk −→ Rk. Se a matriz T ´e diagonaliz´avel, signiﬁca que existe uma base β =
{v1, v2, ..., vk} de autovetores para Rk, tais que:

[f ]β

β =











λ1

0

· · ·

0

0 λ2
...
...
0
0

· · ·
. . .

0
...
· · · λk











,

onde λ1, λ2, ..., λk s˜ao os autovalores. Lembrando que, um vetor n˜ao nulo vi ∈ Rk ´e
um autovetor de Rk se existe um n´umero real λi, tal que f (vi) = λivi. O escalar λi ´e
denominado um autovalor de f associado a Rk. Para maiores detalhes sobre autovalores

e autovetores ver, por exemplo, [8].

´E conhecido da ´algebra linear que existe uma matriz de mudan¸ca de base [I]β

can, tal

que

[f ]can

can = [I]β

can · [f ]β

β · [I]can

β , onde [I]can

β = ([I]β

can)−1.

Note que a multiplica¸c˜ao das matrizes acima pode ser interpretada como uma com-

posi¸c˜ao de transforma¸c˜oes lineares: I ◦ f ◦ I : Rk(can) −→ Rk(can).

Considerando {e1, e2, ..., ek}, a base canˆonica para Rk, temos

I(v1) = v1 = v11e1 + v21e2 + ... + vk1ek

I(v2) = v2 = v12e1 + v22e2 + ... + vk2ek
...

I(vk) = vk = v1ke1 + v2ke2 + ... + vkkek

48

ou seja,

[I]β

can =











v11 v12

v21 v22
...
...
vk1 vk2

· · ·

· · ·
. . .

· · ·











,

v1k

v2k
...
vkk

onde em cada coluna de [I]β

can temos as coordenadas do vetores vi, para i = 1, 2, ..., k.

Note que B = [I]β

can ´e uma matriz formada a partir dos autovetores de [f ]can

can e [f ]β

β ´e a

matriz diagonal dos autovalores.

Al´em disso,

([f ]can

can)2 = ([I]β

can · [f ]β

β · [I]can
(cid:124)

β ) · ([I]β
(cid:123)(cid:122)
β =[I]β
[I◦I]β

β

can
(cid:125)

·[f ]β

β · [I]can

β ) =

= [I]β

can · [f ]β

β · [I]β

β · [f ]β

β · [I]can

β = [I]β

can · ([f ]β

β)2 · [I]can
β .

A ´ultima igualdade se deve ao fato de que :

I(v1) = 1v1 + 0v2 + · · · + 0vk

I(v2) = 0v1 + 1v2 + · · · + 0vk
...

I(v1) = 0v1 + 0v2 + · · · + 1vk

Assim,

[I]β

β =











1 0 · · ·

0 1 · · ·
...
...
. . .
0 0 · · ·











0

0
...
1

(matriz identidade).

Seguindo este racioc´ınio sucessivamente para n, temos

([f ]can

can)n = [I]β

can · ([f ]β

β)n · [I]can

β

, onde [I]can

β = ([I]β

can)−1

e dependendo dos autovalores de [f ]can

can, ([f ]β

β)n pode possuir um limite ﬁnito ou n˜ao.

Exemplo 14. Considere que a nossa matriz de transi¸c˜ao seja a matriz encontrada no

exemplo do interruptor visto no Cap´ıtulo 3:

49

T = [f ]can

can =





5
6

1
6



 .

1
6

5
6

Esta matriz est´a associada `a transforma¸c˜ao linear f : R2 −→ R2 dada por

f (x, y) =

(cid:16) 5
6

x +

1
6

y,

1
6

x +

(cid:17)

.

y

5
6

Inicialmente, vamos encontrar os autovalores e autovetores de f . Para o c´alculo dos

autovalores resolvemos a equa¸c˜ao caracter´ıstica det(T − λI) = 0.

det(T − λI) =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

5
6 − λ
1
6

1
6
5
6 − λ

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= 0.

Temos que,

(cid:16) 5
6
(cid:16)5
6
5
6

(cid:17)2

− λ

−

1
36

= 0

(cid:17)2

=

− λ

− λ = ±

−λ = ±

1
6

−

1
36
1
6
5
6

−2
3
Logo, os autovalores s˜ao λ1 = 1 e λ2 = 2
3.

−λ =

ou − λ = −1.

Para cada autovalor λ encontrado, resolvemos o sistema linear (T − λI)v = 0 para

encontrar os autovetores v1 e v2.





Para λ1 = 1 e v1 =



, temos

x1

y1

(T − λ1I)v1 =





5
6 − 1
1
6

1
6
5
6 − 1





 ·



x1

y1



 = 0.

Obtemos ent˜ao o seguinte sistema linear






−1

6 x1 + 1
6x1 + −1

6y1 = 0
6 y1 = 0

1

Assim, 1

6x1 = 1

6y1 ⇒ x1 = y1. Ent˜ao, v1 = (y1, y1) e um de seus representantes ´e o vetor

50

v1 = (1, 1).

Para λ2 = 2

3 e v2 =



, temos





x2

y2

(T − λ2I)v2 =





5

6 − 2

3

1
6

1
6

5

6 − 2

3





 ·



x2

y2



 = 0.

Obtemos ent˜ao o seguinte sistema linear






1

6x2 + 1
6x2 + 1

6y2 = 0
6y2 = 0

1

Assim, 1

6x2 = −1

6 y2 ⇒ x2 = −y2. Ent˜ao, v2 = (−y2, y2) e um de seus representantes ´e o

vetor v2 = (−1, 1).

Logo, β = {(1, 1), (−1, 1)} ´e uma base de autovetores para R2. Portanto, f ´e diago-

naliz´avel. Desse modo, temos que

[f ]β

β =





1 0

0 2
3


 e [I]β

can =







 .

1 −1

1

1

Queremos encontrar agora a matriz [I]can

β . Temos

I(1, 0) = (1, 0) = a(1, 1) + b(−1, 1).

Obtemos o sistema linear

Assim, a = 1

2 e b = −1
2 .

Obtemos o sistema linear

Assim, c = 1

2 e d = 1
2.




a − b = 1



a + b = 0

I(0, 1) = (0, 1) = c(1, 1) + d(−1, 1).




c − d = 0



c + d = 1

Logo,

[I]can

β =





1
2

−1
2

1
2

1
2



 .

Uma outra maneira de encontrar [I]can

β

´e atrav´es do c´alculo da inversa de [I]β

can.

51

Assim, se v0 = (v0

1, v0

2) ´e a distribui¸c˜ao inicial, ent˜ao

vn = T nv0 = ([f ]can

can)nv0 =





1 −1

1

1





 ·



1 0

0 2
3


n





·



1
2

−1
2

1
2

1
2


 v0.

Como nosso objetivo ´e estudar o que ir´a acontecer em um experimento a longo prazo,

vamos discutir a existˆencia do limite lim
n→∞

([f ]can

can)n.

Note que

lim
n→∞

([f ]can

can)n = lim
n→∞

{[I]β

can · ([f ]β

β)n · [I]can

β } = [I]β

can · { lim
n→∞

([f ]β

β)n} · [I]can

β =





=

1 −1

1

1



 · lim
n→∞





1 0

0 2
3


n





·



1
2

−1
2

1
2

1
2



 =





=

1 −1

1

1



 · lim
n→∞





1n

0





=

1 −1

1

1





=





 ·



1 0

0 0





 ·



1 0

1 0



 =

1
2

1
2



 =

1
2

−1
2

1
2

1
2



 ·





1
2

−1
2


 =

0

( 2
3)n



 ·



1
2

1
2

1
2

−1
2


 .





=

1
2

1
2

1
2

1
2

Desse modo, podemos concluir que:

52

lim
n→∞

vn = lim
n→∞

T nv0 =

(cid:16)



lim
n→∞

can)n(cid:17)
v0
([f ]can




=

=

=

=

1
2



1
2
(cid:16) 1
2
(cid:16) 1
2
(cid:16) 1
2

,

v0
1
v0
2
1
2
1
2

1
2

1
2







v0
1 +

v0
2,

v0
1 +

v0
2

1
2
1 + v0
2)

(cid:17)

(cid:17)

2),

(v0

(v0

1
2
1 + v0
(cid:17)
1
.
2

A ´ultima igualdade se deve ao fato de v0

1 + v0

2 = 1.

Ou seja, a medida que n aumenta, a distribui¸c˜ao vn se aproxima de ( 1

2), inde-
pendente da distribui¸c˜ao inicial v0. Logo, a probabilidade do interruptor estar ligado ou

2, 1

desligado, a longo prazo, ser´a a mesma: 1

2, independente do estado anterior.

4.1.2 Convergˆencia de matrizes de transi¸c˜ao regulares

Deﬁni¸c˜ao 4.1.4. Uma matriz das probabilidades de transi¸c˜ao ´e regular se alguma de suas

potˆencias tem todos os elementos n˜ao nulos.

Note, por exemplo, que a matriz das probabilidades de transi¸c˜ao dada por

´e regular, visto que





T =



 ,

0 0, 4

1 0, 6





T 2 =



 .

0, 4 0, 24

0, 6 0, 76

Vale ressaltar que nem toda matriz de transi¸c˜ao ´e regular. As matrizes diagonais s˜ao

exemplos imediatos. A matriz de transi¸c˜ao:





1 0

0 1





signiﬁca que h´a probabilidade nula de mudan¸ca de estado ou seja, a probabilidade de

transi¸c˜ao do j-´esimo estado para o i-´esimo estado ´e igual a 1 (100%), se i = j e ´e igual

53

a 0 (0%), se i (cid:54)= j. Neste caso, dizemos que a matriz das probabilidades de transi¸c˜ao ´e

absorvente, ou seja, se em determinado passo, caindo em um estado, seja “imposs´ıvel”sair

dele.

Agora iremos apresentar o Teorema de Perron-Frobenius, que nos fornece uma ferra-

menta para o c´alculo de previs˜oes a longo prazo, para os casos onde a matriz de transi¸c˜ao

´e regular.

Teorema 4.1.5. (Perron - Frobenius) Seja T uma matriz estoc´astica com a seguinte

propriedade: existe um inteiro m ≥ 1, tal que (T m)i,j > 0, para todo i, j, ou seja, T ´e

regular. Ent˜ao:

1. T possui o autovalor λ = 1 e qualquer outro autovalor λ(cid:48) de T satisfaz |λ(cid:48)| < λ.

Al´em disso, λ ´e n˜ao-degenerado: existe um ´unico autovetor w associado, T w = w, que

pode ser escolhido, tal que

(cid:88)

wi = 1, com wi ≥ 0, para todo i.

i
2. Para qualquer distribui¸c˜ao inicial v, T nv −→ w.

Exemplo 15. Podemos resolver o Exemplo 14 atrav´es do Teorema de Perron - Frobenius.

Como a matriz

T = [f ]can

can =





5
6

1
6

1
6





´e regular, pelo Teorema de Perron - Frobenius, [f ]can

5
6
can possui λ = 1 como autovalor e

existe um ´unico autovetor w = (w1, w2) associado, T w = w, que pode ser escolhido tal

que w1 + w2 = 1.

Como vimos acima, v1 = (y1, y1) ´e um autovetor para λ = 1. Assim, temos que

w = (w1, w1) ´e tal que w1 + w1 = 1. Logo, w = ( 1

2, 1

2).

Podemos concluir ent˜ao que

([f ]can

can)nv0 −→



 ,





1
2

1
2

quando n −→ ∞.

Reescreveremos o Teorema 4.1.5 (Perron - Frobenius), numa vers˜ao que n˜ao utiliza

conhecimentos avan¸cados de ´algebra linear. A aplica¸c˜ao deste teorema, nesta vers˜ao,

nos possibilitar´a encontrar tais previs˜oes fazendo apenas o uso de conceitos estudados no

54

Ensino M´edio: matrizes e resolu¸c˜ao de sistemas lineares. As ferramentas que aparecem

na demonstra¸c˜ao deste resultado, que apresentaremos em seguida, n˜ao ser˜ao utilizados

em nossos problemas de aplica¸c˜oes voltados para o Ensino M´edio. Por´em a prova ´e

interessante para estudantes de ´algebra linear.

Teorema 4.1.6. Se T ´e uma matriz estoc´astica regular r × r ent˜ao:

i) T n se aproxima de uma matriz M , no sentido de que cada entrada da matriz T n

aproxima-se da entrada correspondente em M ;

ii) Todas as colunas de M s˜ao iguais, sendo dadas por um vetor coluna

w =








,








w1
...
wr

com wi > 0, para i = 1, . . . r.

iii) Para qualquer vetor de probabilidades inicial

v =








,








v1
...
vr

o vetor de probabilidades T nv aproxima-se de w, quando n → ∞;

iv) O vetor w ´e o ´unico que satisfaz T w = w e ´e chamado vetor estacion´ario.

Demonstra¸c˜ao.

Faremos aqui a prova para matrizes 2 × 2. A mesma ideia pode ser

aplicada para matrizes r × r.

a. Vamos supor inicialmente que T ´e uma matriz com entradas todas n˜ao nulas e que

ε > 0 seja uma entrada da matriz, cujo valor ´e menor ou igual que outras entradas.

Assim, podemos supor que:





T =

α

ε

1 − α 1 − ε



 ,

55

com α > 0.

Seja x um vetor linha tendo m´ınima componente m0 e m´axima componente M0, ou

seja, m0 = min(x) e M0 = max(x). E seja m1 e M1 a m´ınima e m´axima componente

da xT .

Supondo que x = [m0 M0], temos que xT = [m0α + M0(1 − α) m0ε + M0(1 − ε)] =

[M0 − α(M0 − m0) M0 − ε(M0 − m0)], e desta forma, temos M1 = M0 − ε(M0 − m0).

O mesmo ocorre se x = [M0 m0]. A express˜ao xT tamb´em pode ser escrita como:

xT = [m0 + (1 − α)(M0 − m0) m0 + (1 − ε)(M0 − m0)].

Como, por hip´otese, 1 − α ≥ ε, segue que m1 = m0 + (1 − α)(M0 − m0) ≥ m0 +

ε(M0 − m0) e, portanto,

−m1 ≤ −m0 − ε(M0 − m0).

Desta forma, como M1 = M0 − ε(M0 − m0), somando ambos os membros com a

express˜ao anterior, temos

M1 − m1 ≤ M0 − m0 − 2ε(M0 − m0)

M1 − m1 ≤ (1 − 2ε)(M0 − m0).

Seja ej o vetor linha com o n´umero 1 na j-´esima entrada (no nosso caso 1 ≤ j ≤ 2).

E sejam Mn e mn os valores m´aximo e m´ınimo das componentes do vetor ejT n,

ou seja, Mn = max(ejT n) e mn = min(ejT n), para n = 1, 2, 3, ...

. Note que,

M1 ≥ M2 ≥ M3 ≥ . . . e m1 ≤ m2 ≤ m3 ≤ . . . .

Vamos considerar aqui T 0 = I e, portanto, M0 = max(ejT 0) = max(ej) = 1 e

m0 = min(ejT 0) = min(ej) = 0. Como M1 = max(ejT ) e m1 = min(ejT ), pelo

resultado obtido acima segue que:

M1 − m1 ≤ (1 − 2ε)(M0 − m0) = (1 − 2ε)(1 − 0) = (1 − 2ε).

Analogamente, podemos escrever M2 = max(ejT 2) = max((ejT )T ) e m2 = min(ejT 2) =

min((ejT )T ), e aplicando novamente o resultado acima, chegamos a

M2 − m2 ≤ (1 − 2ε)(M1 − m1) ≤ (1 − 2ε)(1 − 2ε),

56

ou seja,

M2 − m2 ≤ (1 − 2ε)2.

Para um n qualquer podemos escrever Mn = max(ejT n) = max((ejT n−1)T ) e mn =

min(ejT n) = min((ejT n−1)T ), aplicando o procedimento descrito anteriormente

sucessivas vezes obtemos que

Mn − mn ≤ (1 − 2ε)n,

para n ≥ 1.

Assim, Mn − mn → 0, quando n → ∞ e Mn e mn se aproximam para um limite
comum, digamos wj. ´E claro que mn ≤ wj ≤ Mn. Em particular, como 0 < m1 e
M1 < 1, temos que 0 < wj < 1. Portanto, ejT n tende a um vetor em que a maior e

a menor componente se aproximam, ou seja, um vetor onde todas as componentes

tendem a wj. Logo, a j-´esima linha de M ´e dada por um vetor de entradas wj. E

portanto, as colunas de M s˜ao iguais a um vetor

w =



 .





w1

w2

Com w1 + w2 = 1 j´a que T n ´e uma matriz estoc´astica pra cada n, e portanto, o

mesmo deve valer para o limite M .

b. Vamos supor que T ´e regular e que n˜ao necessariamente todas as entradas de T sejam

diferentes de zero. Seja N , tal que T N ´e a matriz cujas entradas s˜ao n˜ao nulas. Seja

ε(cid:48) o menor valor das entradas de T N . Aplicando o mesmo racioc´ınio do item a. para

T N , temos MN K = max(ej(T N )K) e mN K = min(ej(T N )K). Logo,

MN K − mN K ≤ (1 − 2ε(cid:48))K.

Portanto, a sequˆencia n˜ao-crescente (Mn−mn) tem uma subsequˆencia (MN K −mN K)

tendendo a zero. Logo, (Mn − mn) tende a zero e o resto da prova ´e an´alogo ao item

a..

Isto prova os itens (i) e (ii).

Prova do item (iii): Temos que T nv se aproxima de M v, quando n → ∞. Al´em disso,

57

uma vez que v1 + v2 = 1, segue que:







w1 w1

w2 w2

v1

v2





 =





w1(v1 + v2)

w2(v1 + v2)





 =



w1

w2



 = w.

M v =



Portanto,

T nv → w.

Prova do item (iv): Temos que T nT → M T . Por outro lado, T n+1 → M . Como

T n+1 = T nT , pela unicidade do limite, M T = M . Analogamente, T M = M . E

assim temos:





p11 p12

p21 p22









w1 w1

w2 w2





 =



w1 w1

w2 w2



 .

E desta equa¸c˜ao matricial extra´ımos





p11 p12

p21 p22









w1

w2





 =





 .

w1

w2

Ou seja,

T w = w.

Vamos agora mostrar a unicidade de w. Suponha que ˜w seja outro vetor de proba-

bilidade com T˜w = ˜w. Logo, T n ˜w = ˜w, para todo n.

E assim, T n ˜w → ˜w. Mas por (iii) sabemos que T n ˜w → w. Logo, pela unicidade do

limite, segue que ˜w = w.

(cid:3)

A demonstra¸c˜ao completa do Teorema 4.1.6 para T uma matriz r × r se encontra em [9].

Observa¸c˜ao 4.1.7. Com esse teorema percebe-se que a previs˜ao a longo prazo n˜ao de-

pender´a do vetor de probabilidade inicial.

Observa¸c˜ao 4.1.8. Note que o Teorema acima, ´e de fato o pr´oprio Teorema de Perron

- Frobenius, visto que, se T ´e uma matriz estoc´astica regular, ent˜ao λ = 1 ´e um autovalor

de T e assim, w ´e tal que T w = 1 · w.

Assim, para encontrarmos uma previs˜ao w a longo prazo, basta conhecermos a matriz

das probabilidades de transi¸c˜ao T e resolvermos o sistema linear T w = w, o que torna

poss´ıvel explorarmos este assunto com alunos do Ensino M´edio, visto que o conte´udo de

matrizes, probabilidade e sistemas lineares ´e trabalhado com os alunos nesta etapa.

58

Cap´ıtulo 5

Aplica¸c˜ao das cadeias de Markov no

Ensino M´edio

Para ilustrarmos como o Teorema 4.1.6 pode ser aplicado no contexto de cadeias de

Markov no Ensino M´edio, veremos a seguir exemplos, onde alguns foram retirados de [8]

e [10].

Exemplo 16. Duas substˆancias distintas est˜ao em contato e trocam ´ıons de s´odio entre

si. Sabe-se (por dedu¸c˜ao te´orica, ou experimenta¸c˜ao) que um ´ıon de s´odio do meio (1)

tem probabilidade 0,7 de passar ao meio (2), enquanto que um ´ıon de s´odio que esteja no

meio (2) tem probabilidade 0,1 de passar ao meio (1).

Figura 5.1: Trocas de ´ıons de s´odio.

Colocando-se dois moles de s´odio no meio (1), quais ser˜ao as concentra¸c˜oes de s´odio

em cada um dos meios, ap´os um longo per´ıodo de tempo?

Os estados deste processo s˜ao: o ´ıon est´a no meio (1) e o ´ıon est´a no meio (2).

Considerando que um ´ıon de s´odio do meio (1) tem probabilidade 0,7 de passar ao meio

59

(2), segue que ele tem probabilidade 0,3 de permanecer onde est´a e se um ´ıon de s´odio

do meio (2) tem probabilidade 0,1 de passar ao meio (1), ele ter´a probabilidade 0,9 de

permanecer onde est´a.

Podemos representar esta situa¸c˜ao atrav´es do seguinte diagrama de transi¸c˜ao:

60

Figura 5.2: Probabilidades de transi¸c˜ao dos ´ıon de s´odio.

A matriz de probabilidades de transi¸c˜ao ser´a dada por:

meio (1) meio (2)

meio (1)

meio (2)

0, 3

0, 7

0, 1

0, 9

⇒ T =





0, 3 0, 1

0, 7 0, 9



 .

Sejam p1 e p2 as probabilidades de estar no meio (1) e (2), respectivamente. Como

T ´e regular, a longo prazo as probabilidades n˜ao dependem das probabilidades iniciais e

podemos aplicar o Teorema 4.1.6. Logo,





0, 3 0, 1

0, 7 0, 9





 ·







 =





 .

p1

p2

p1

p2

O que nos leva a resolver o sistema linear:




0, 3p1 + 0, 1p2 = p1



0, 7p1 + 0, 9p2 = p2






⇒

−0, 7p1 + 0, 1p2 = 0

0, 7p1 + −0, 1p2 = 0

Conclu´ımos ent˜ao que 0, 7p1 = 0, 1p2 ⇒ p2 = 7p1. Como p1 + p2 = 1 segue que:

p1 + 7p1 = 1 ⇒ p1 =

1
8

e p2 =

7
8

.

Logo, as concentra¸c˜oes ﬁnais, depois de um longo per´ıodo, em cada meio s˜ao: 1

8 · 2 = 0, 25

moles no meio (1) e 7

8 · 2 = 0, 75 moles no meio (2).

 Meio (1) Meio (2)  0,7 0,1 0,9 0,3 61

Exemplo 17. Num polo industrial de uma cidade, os dados sobre a qualidade do ar s˜ao

classiﬁcados como satisfat´orio (S) e insatisfat´orio (I). Assuma que, se num dia ´e registrado

(S), a probabilidade de se ter (S) no dia seguinte ´e de 2

5 e que, uma vez registrado (I),

tem-se 1

5 de probabilidade de ocorrer (S) no dia seguinte.

a) Qual ´e a probabilidade do quarto dia ser satisfat´orio (S), se o primeiro dia foi

insatisfat´orio (I)?

b) O que se pode dizer a longo prazo sobre a probabilidade de termos dias (S) ou (I)?

Os estados deste processo s˜ao: a qualidade do ar est´a satisfat´oria (S) e a qualidade do

ar est´a insatisfat´oria (I). Considerando que se num dia ´e registrado (S), a probabilidade

de se ter (S) no dia seguinte ´e de 2

(I) no dia seguinte e se registrado (I), tem-se 1

5 = 0, 4, segue que ele tem probabilidade 3

5 = 0, 6 de ser
5 = 0, 2 de probabilidade de ocorrer (S) no

dia seguinte, ele ter´a 4

5 = 0, 8 de probabilidade de ocorrer (I) no dia seguinte.

A matriz de probabilidades de transi¸c˜ao ser´a dada por:

S

I

S 0, 4

0, 2

⇒ T =

I

0, 6

0, 8





0, 4 0, 2

0, 6 0, 8



 .

Veja que T representa a matriz de probabilidades para o segundo dia. Podemos representar

esta situa¸c˜ao atrav´es do seguinte diagrama de transi¸c˜ao:

Figura 5.3: Probabilidades de transi¸c˜ao da qualidade do ar.

Para o item a), a probabilidade de ocorrer (S) no quarto dia tendo ocorrido (I) no

primeiro dia pode ser obtida calculando o elemento a12 da matriz T 3. Temos





T 3 =

0, 4 0, 2

0, 6 0, 8





 ·







 ·



0, 4 0, 2

0, 6 0, 8

0, 4 0, 2

0, 6 0, 8





 =



0, 256 0, 248

0, 744 0, 752



 .

 Satisfatória Insatisfatória  0,6 0,2 0,8 0,4 62

Assim, a probabilidade do quarto dia ser satisfat´orio (S), se o primeiro dia foi insa-

tisfat´orio (I) ´e 0, 248 = 24, 8%.

Para o item b), sejam p1 e p2 as probabilidades de o ar ser classiﬁcado como satis-

fat´orio (S) e insatisfat´orio (I), respectivamente. Como T ´e regular, a longo prazo as

probabilidades n˜ao dependem das probabilidades iniciais e podemos aplicar o Teorema

4.1.6. Logo,





0, 4 0, 2

0, 6 0, 8





 ·







 =





 .

p1

p2

p1

p2

O que nos leva a resolver o sistema linear:




0, 4p1 + 0, 2p2 = p1



0, 6p1 + 0, 8p2 = p2






⇒

−0, 6p1 + 0, 2p2 = 0

0, 6p1 + −0, 2p2 = 0

Conclu´ımos ent˜ao que 0, 6p1 = 0, 2p2 ⇒ p2 = 3p1. Como p1 + p2 = 1 segue que:

p1 + 3p1 = 1 ⇒ p1 =

1
4

= 0, 25 e p2 = 0, 75.

Logo, a longo prazo, a probabilidade de termos dias satisfat´orios ´e 0, 25 = 25% e

insatisfat´orios 0, 75 = 75%.

perder (P) e empatar (E) uma partida depois de conseguir uma vit´oria s˜ao 1

Exemplo 18. ´E observado que as probabilidades de um time de futebol ganhar (G),
5, e 3
10
10, e 2
5, respectivamente; e depois de
5, respectivamente. Se o time n˜ao melhorar e nem piorar, conseguir´a

respectivamente; e depois de ser derrotado s˜ao 3

empatar s˜ao 1

5, e 2

10, 3

2, 1

5, 2

mais vit´orias que derrotas a longo prazo?

A partir das informa¸c˜oes fornecidas no enunciado podemos construir sua matriz de

transi¸c˜ao:

G P E

G 1
2
P 1
5
E 3
10

3
10

3
10

2
5

1
5

2
5

2
5

⇒ T =








0, 5 0, 3 0, 2

0, 2 0, 3 0, 4

0, 3 0, 4 0, 4








.

Sejam pG, pP e pE as probabilidades de um time de futebol ganhar (G), perder (P)

e empatar (E), respectivamente. Como T ´e regular, a longo prazo as probabilidades n˜ao

63

dependem das probabilidades iniciais e podemos aplicar o Teorema 4.1.6. Logo,








0, 5 0, 3 0, 2

0, 2 0, 3 0, 4

0, 3 0, 4 0, 4








·















pG

pP

pE

=








.








pG

pP

pE

O que nos leva a resolver o sistema linear:





0, 5pG + 0, 3pP + 0, 2pE = pG

0, 2pG + 0, 3pP + 0, 4pE = pP

⇒

0, 3pG + 0, 4pP + 0, 4pE = pE





Escalonando este sistema linear, obtemos:

−0, 5pG + 0, 3pP + 0, 2pE = 0

0, 2pG + −0, 7pP + 0, 4pE = 0

0, 3pG + 0, 4pP + −0, 6pE = 0






−0, 5pG + 0, 3pP

+ 0, 2pE = 0

−0, 29pP + 0, 24pE = 0

Conclu´ımos ent˜ao que 0, 29pP = 0, 24pE ⇒ pP = 24

29pE.

Assim,

−0, 5pG + 0, 3pP + 0, 2pE = 0

−

pG +

pE +

pE = 0

3
10

·

24
29

pG +

72
290

pE +

pE = 0

5
10
5
10

−

2
10
2
10

−

pG +

pE = 0

5
10
5
10

130
290
13
29

−

pG +

pE = 0

13
29

pE =

5
10

pG =

1
2

pG

pG = 2 ·

13
29

pE

pG =

26
29

pE.

Como pG + pP + pE = 1 segue que:

26
29

pE +

24
29

pE + pE = 1

26 + 24 + 29
29

pE = 1

64

Desse modo,

e

79
29

pE = 1

pE =

29
79

.

pG =

26
29

pE =

26
29

·

29
79

=

26
79

pP =

24
29

pE =

24
29

·

29
79

=

24
79

.

Assim, a longo prazo, a probabilidade de um time de futebol ganhar uma partida ser´a

26

79, perder 24
79 Ou seja, a probabilidade ser´a de aproximadamente 32, 9% de
ganhar, 30, 4% de perder e 36, 7% de empatar. Logo, o time conseguir´a mais vit´orias que

79 e empatar 29

derrotas a longo prazo.

Exemplo 19. Insetos da ordem blattodea, quando submetidos a altas temperaturas, se

deslocam de maneira aleat´oria. Considere o seguinte modelo: uma barata (periplaneta

americana) se desloca em um tabuleiro 3 × 3 de maneira aleat´oria, e de acordo com a

seguinte regra: a probabilidade do inseto se deslocar, a cada passo, para uma das casas

vizinhas (inclusive na diagonal), ´e idˆentica. Considere que o inseto n˜ao permanece na

casa em que estava no instante anterior.

Construa a matriz de transi¸c˜ao correspondente e mostre que depois de um tempo su-

ﬁcientemente grande, a probabilidade do inseto se encontrar na casa do meio ´e de 1/5.

Na ﬁgura a seguir temos um modelo do tabuleiro, onde as casas foram numeradas de

1 a 9. Note que, por exemplo, a probabilidade do inseto sair da casa 4 e ir para uma de

suas casas vizinhas (1, 2, 5, 7 e 8) ser´a de 1

5 e para as demais casas (3, 6 e 9) temos

probabilidade 0.

65

Figura 5.4: Probabilidades de transi¸c˜ao da casa 4 para as casas vizinhas.

Temos que a matriz de transi¸c˜ao ser´a dada por:


























T =

5 0 1

5

1

0 1
3 0 1
0 1

3

1
5

5 0 0 1
5 0 0 1

8

1

1
3

1
1
3
5
0 1
5

1
3

1

5 0 1

5

1

3 0 1

0 0 0 1
5
0 0 0 1
5

1
8
0 0 0 0 1
8

1
8 0 0 0 0
1
1
5 0 0 0
8
1
5 0 0 0
1
5 0
1
1
3
5

8 0 1

1
3

3

8 0 0 1
8 0 0 1

1

1
5
3
5 0
3 0 1
3
5 0

1

1

5 0 1

1
5


























.

Para os c´alculos deste problema, utilizamos o software “caculadora de matrizes”[7], no

qual ´e uma ferramenta para c´alculos envolvendo matrizes e resolu¸c˜ao de sistemas lineares.

 1 2 3 4 5 6 7 8 9 15  15 15 15 15 Assim, T 2 ´e dada por:

66

T 2 =


























7
40

13
120

13
120

13
120

2
15

13
120

13
120

13
120

1
24

13
200

143
600

13
200

11
120

16
75

11
120

13
200

21
200

13
200

13
120

13
120

7
40

13
120

2
15

13
120

1
24

13
120

13
120

13
200

11
120

13
200

143
600

16
75

21
200

13
200

11
120

13
200

1
20

2
15

1
20

2
15

4
15

2
15

1
20

2
15

1
20

13
200

11
120

13
200

21
200

16
75

143
600

13
200

11
120

13
200

13
120

13
120

1
24

13
120

2
15

13
120

7
40

13
120

13
120

13
200

21
200

13
200

11
120

16
75

11
120

13
200

143
600

13
200


























.

1
24

13
120

13
120

13
120

2
15

13
120

13
120

13
120

7
40

Logo, T ´e regular e podemos aplicar o Teorema 4.1.6.

Sejam p1, p2, p3, p4, p5, p6, p7, p8 e p9 as probabilidades do inseto estar, depois de um

longo per´ıodo de tempo (n −→ ∞), nas casas 1, 2, 3, 4, 5, 6, 7, 8 e 9, respectivamente.

Logo, aplicando o Teorema, item (iv), temos


























5 0 1

5

1

0 1
3 0 1
0 1

3

1
5

5 0 0 1
5 0 0 1

1

1
3

1
1
3
5
0 1
5

1
3

1

5 0 1

5

1

3 0 1

1

0 0 0 1
5
0 0 0 1
5

1
8
0 0 0 0 1
8

1
8 0 0 0 0
1
1
5 0 0 0
8
1
5 0 0 0
1
5 0
1
1
3
5

8 0 1

1
3

8

3

8 0 0 1
8 0 0 1

1
5
3
5 0
3 0 1
3
5 0

1

1

5 0 1

1
5



















































·


























p1

p2

p3

p4

p5

p6

p7

p8

p9


























.


























p1

p2

p3

p4

p5

p6

p7

p8

p9

=

O que nos leva a resolver o sistema linear:

67










1

5p4 + 1
5p2 + 0p3 + 1
0p1 + 1
1
5p4 + 1
3p3 + 1
3p1 + 0p2 + 1
5p2 + 0p3 + 0p4 + 1
0p1 + 1
1
5p2 + 0p3 + 0p4 + 1
3p1 + 1
3p3 + 1
5p2 + 1
3p1 + 1
3p3 + 0p4 + 1
5p2 + 1
0p1 + 1
0p1 + 0p2 + 0p3 + 1
5p4 + 1
5p4 + 1
0p1 + 0p2 + 0p3 + 1
0p1 + 0p2 + 0p3 + 0p4 + 1

8p5 + 0p6 + 0p7 + 0p8 + 0p9 = p1
8p5 + 1
5p6 + 0p7 + 0p8 + 0p9 = p2
8p5 + 1
5p6 + 0p7 + 0p8 + 0p9 = p3
3p7 + 1
8p5 + 0p6 + 1
5p8 + 0p9 = p4
5p8 + 1
3p7 + 1
5p6 + 1
3p9 = p5
5p8 + 1
8p5 + 0p6 + 0p7 + 1
3p9 = p6
8p5 + 0p6 + 0p7 + 1
5p8 + 0p9 = p7
5p6 + 1
8p5 + 1
3p9 = p8
5p6 + 0p7 + 1
8p5 + 1
5p8 + 0p9 = p9

3p7 + 0p8 + 1

5p4 + 0p5 + 1

⇒

1

−1p1 + 1
5p4 + 1
5p2 + 0p3 + 1
3p1 − 1p2 + 1
5p4 + 1
3p3 + 1
1
0p1 + 1
5p2 − 1p3 + 0p4 + 1
3p1 + 1
1
5p2 + 0p3 − 1p4 + 1
3p3 + 1
3p1 + 1
5p2 + 1
3p3 + 0p4 + 1
5p2 + 1
0p1 + 1
0p1 + 0p2 + 0p3 + 1
5p4 + 1
5p4 + 1
0p1 + 0p2 + 0p3 + 1
0p1 + 0p2 + 0p3 + 0p4 + 1
Resolvendo este sistema obtemos: p1 = p9, p2 = 5

8p5 + 0p6 + 0p7 + 0p8 + 0p9 = 0
8p5 + 1
5p6 + 0p7 + 0p8 + 0p9 = 0
8p5 + 1
5p6 + 0p7 + 0p8 + 0p9 = 0
3p7 + 1
8p5 + 0p6 + 1
5p8 + 0p9 = 0
5p8 + 1
3p7 + 1
5p6 + 1
3p9 = 0
5p8 + 1
8p5 − 1p6 + 0p7 + 1
3p9 = 0
8p5 + 0p6 − 1p7 + 1
5p8 + 0p9 = 0
5p6 + 1
8p5 + 1
3p9 = 0
5p6 + 0p7 + 1
8p5 + 1
5p8 − 1p9 = 0
3p9,

3p9, p3 = p9, p4 = 5

5p4 − 1p5 + 1

3p7 − 1p8 + 1

3p9, p5 = 8

p6 = 5

3p9, p7 = p9, p8 = 5

3p9 e p9 = p9.

Como p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 1. Segue que:

p9 +

5
3

p9 + p9 +

5
3

p9 +

8
3

p9 +

5
3

p9 + p9 +

5
3

p9 + p9 = 1 =⇒ p9 =

3
40

.

Como estamos interessados em encontrar a probabilidade do inseto se encontrar na

casa do meio, estamos procurando o valor de p5. Logo,

p5 =

8
3

p9 =

8
3

·

3
40

=

1
5

.

Note ainda que: p1 = 0, 075, p2 = 0, 125, p3 = 0, 075, p4 = 0, 125, p5 = 0, 2, p6 =

0, 125, p7 = 0, 075, p8 = 0, 125 e p9 = 0, 075. Assim, podemos concluir tamb´em que a

casa do meio tem maior chance da barata ser encontrada.

Exemplo 20. Podemos resolver o item b do Exemplo10 utilizando matriz de transi¸c˜ao e

o Teorema 4.1.6. Para isto, denotemos por 1 o estado livre e por 2 o estado ocupado. Os

68

elementos da matriz de transi¸c˜ao s˜ao dados por

a11 = P (An+1|An) = 1 − p;

a12 = P (An+1|Bn) = q;

a21 = P (Bn+1|An) = p;

a22 = P (Bn+1|Bn) = 1 − q.

Logo,





T =

1 − p

q

p

1 − q



 .

Pelo Teorema 4.1.6, para encontrarmos lim
n→∞

xn, basta resolvermos o sistema





1 − p

q

p

1 − q





 .



x

1 − x





 =





 ,

x

1 − x

onde x= lim
n→∞
ocupado a longo prazo.

xn ´e a probabilidade do telefone estar livre e 1−x ´e a probabilidade dele estar

Temos



(1 − p)x +

q(1 − x)

=

x



px

+ (1 − q)(1 − x) = 1 − x

=⇒






(−p − q)x + q = 0

(p + q)x − q = 0

Obtemos ent˜ao

x =

q
p + q

.

5.1 Plano de aula

O conte´udo de matrizes, sistemas lineares e probabilidade ´e trabalhado nas turmas

do 2o ano do Ensino M´edio de acordo com o Curr´ıculo do Estado de S˜ao Paulo [11].

Apresentamos a seguir uma sugest˜ao de plano de aula para aplica¸c˜ao dos problemas

propostos anteriormente sobre cadeias de Markov para alunos do Ensino M´edio.

Plano de Aula:

Tema: Uma abordagem matricial sobre cadeias de Markov.

Objetivos Gerais:

- Utilizar elementos de matrizes para organizar e justiﬁcar a resolu¸c˜ao de situa¸c˜oes-

problema envolvendo cadeias de Markov.

69

Objetivos Espec´ıﬁcos:

- Compreender o signiﬁcado das cadeias de Markov;

- Adquirir conhecimentos b´asicos sobre probabilidade;

- Saber expressar, por meio de matrizes, situa¸c˜oes relativas a cadeias de Markov;

- Saber resolver sistemas de equa¸c˜oes lineares.

Conte´udo:

- Matrizes: Representa¸c˜ao de uma matriz, opera¸c˜oes com matrizes, representa¸c˜ao

matricial de sistemas lineares, matrizes estoc´asticas;

- No¸c˜oes de probabilidade;

- Cadeias de Markov: processos estoc´asticos, processos de Markov, matriz das proba-

bilidades de transi¸c˜ao, matrizes regulares, vetor de probabilidade a longo prazo.

Metodologia:

- Aula expositiva do conte´udo proposto;

- Apresenta¸c˜ao das situa¸c˜oes-problema propostas neste trabalho para a resolu¸c˜ao em

sala de aula;

- Observar os recursos utilizados pelos alunos no desenvolvimento dos problemas su-

geridos utilizando a “calculadora de matrizes”;

- Apresentar a resolu¸c˜ao dos problemas envolvendo cadeias de Markov utilizando o

Teorema 4.1.6.

Recursos Did´aticos:

- Quadro, giz e sala de inform´atica.

Avalia¸c˜ao:

- Observa¸c˜ao da participa¸c˜ao do aluno na resolu¸c˜ao dos problemas sugeridos;

- Entrega da atividade escrita desenvolvida em sala de aula.

5.2 Aplica¸c˜ao dos problemas propostos nesta disserta¸c˜ao

Relatos da experiˆencia em sala de aula

Para a aplica¸c˜ao dos exemplos deste trabalho foi selecionada uma escola estadual da

cidade de Bauru e foi trabalhado o assunto com os alunos de uma turma do 2o ano do

70

Ensino M´edio. Como leciono nesta escola, j´a tinha a informa¸c˜ao sobre os conhecimentos

pr´evios de meus alunos.

Inicialmente, foram trabalhados os seguintes conte´udos que

comp˜oem o Curr´ıculo do Estado de S˜ao Paulo para alunos nesta s´erie:

• Matrizes: deﬁni¸c˜ao, opera¸c˜oes com matrizes, matriz inversa e determinantes.

• Sistemas lineares: equa¸c˜oes lineares, resolu¸c˜ao de sistemas lineares: m´etodo de

Cramer e escalonamento.

• An´alise combinat´oria e probabilidade: m´etodos de contagem, probabilidade, proba-

bilidade condicional.

O conte´udo que envolve matrizes e sistemas lineares foi trabalhado durante o 2o bimes-

tre e o conte´udo de an´alise combinat´oria e probabilidade foi trabalhado no 3o bimestre.

Em seguida, foi apresentado o contexto de cadeias de Markov: processos estoc´asticos,

processos de Markov, matriz das probabilidades de transi¸c˜ao, matrizes regulares, vetor

de probabilidade a longo prazo. Ao tomar conhecimento sobre o assunto, foi proposto

a resolu¸c˜ao do Exemplo 17 apresentado neste trabalho atrav´es das aproxima¸c˜oes do ve-

tor vn = T nv0 para valores de n cada vez maiores. Para isto, os alunos foram levados

para uma sala de inform´atica e foi utilizado o software “calculatora de matrizes”a ﬁm de

facilitar os c´alculos das potˆencias da matriz de transi¸c˜ao encontrada. Assim, os alunos

puderam perceber que havia uma poss´ıvel convergˆencia da matriz de transi¸c˜ao a medida

que os valores de n aumentavam.

Em seguida, foi apresentado aos alunos o Teorema 4.1.6 a ﬁm de mostrar uma ferra-

menta que facilite os c´alculos e nos dˆe uma previs˜ao concisa a longo prazo para matrizes

estoc´asticas regulares. Com isso, foi sugerido a resolu¸c˜ao do problema anterior, utilizando

agora, o Teorema apresentado.

A aplica¸c˜ao da atividade envolvendo cadeias de Markov levou uma semana, ocupando

5 aulas de 50 minutos.

Embora sabemos que em uma sala de aula h´a muitos alunos desinteressados e com

grande defasagem de conte´udos envolvendo os conhecimentos pr´evios sobre os assuntos

trabalhados no Ensino Fundamental, alguns alunos conseguiram desenvolver toda a ati-

71

vidade proposta corretamente e relataram gostar da atividade diferenciada em sala de

aula.

O tema cadeias de Markov, permite ao professor, desenvolver assuntos que, muitas

vezes, ´e de dif´ıcil compreens˜ao por parte dos alunos e assim, despertar a curiosidade

dos mesmos. Conclu´ımos assim que, n´os professores, devemos estimular nossos alunos a

buscar novos conhecimentos e mostrar como a matem´atica pode ser aplicada na resolu¸c˜ao

de alguns problemas cotidianos.

Referˆencias Bibliogr´aﬁcas

[1] JAMES, B. R. Probabilidade: um curso em n´ıvel intermedi´ario. 2. ed. Rio de

Janeiro: IMPA, 1996.

[2] KEMENY, J. G.; SNELL, J. L.; KNAPP, A. W. Denumerable Markov

chains. New York: Springer- Verlag, 1976.

[3] HAIRER, M. Ergodic properties of Markov processes. Warwick: 2006. Lec-

ture notes. Dispon´ıvel em: <http://www.hairer.org/notes/Markov.pdf>. Acesso em:

9 dez. 2017.

[4] BRZEZNIAK, Z.; ZASTAWNIAK, T. Basic stochastic processes: a course

through exercises. London: Springer, 1999. (Springer undergraduate mathematics

series).

[5] RUFFINO, P. R. C. Uma inicia¸c˜ao aos sistemas dinˆamicos estoc´asticos. 2.

ed. Rio de Janeiro: IMPA, 2009.

[6] MORGADO,A. C.; CARVALHO, P. C. P. Matem´atica discreta. Rio de Ja-

neiro: SBM, 2013.

[7] MATRIX CALCULATOR. Dispon´ıvel em: <https://matrixcalc.org/pt/>.

Acesso em: 5 dez. 2017.

[8] BOLDRINI, J. L. et al. ´Algebra linear. 3. ed. Campinas: Universidade Estadual

de Campinas, Departamento de Matem´atica, 1980.

[9] SILVA, F. B.; ROTA, I. S. Convergˆencia de matrizes estoc´asticas regulares. C.Q.D:

revista eletrˆonica paulista de matem´atica, Bauru, v. 8, p. 4-14, dez. 2016.

72

73

[10] MALAJOVICH, G. ´Algebra linear. Rio de Janeiro: Universidade Federal do

Rio de Janeiro, Departamento de Matem´atica Aplicada, 2010. Dispon´ıvel em:

<http://www.labma.ufrj.br/ gregorio/livro/al2.pdf>. Acesso em: 9 dez. 2017.

[11] S˜ao Paulo (Estado). Secretaria da Educa¸c˜ao. Curr´ıculo do Estado de S˜ao Paulo:

matem´atica e suas tecnologias. S˜ao Paulo, 2011.


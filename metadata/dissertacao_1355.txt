Universidade Federal da Bahia - UFBA
Instituto de Matem´atica e Estat´ıstica - IME
Sociedade Brasileira de Matematica - SBM
Mestrado Profissional em Matem´atica em Rede Nacional - PROFMAT

Dissertac¸˜ao de Mestrado

Cadeias de Markov Absorventes: Uma aplicac¸˜ao
para o Ensino M´edio

Thiago Emmanoel Amaral Nascimento

Salvador - Bahia
Abril de 2019

Cadeias de Markov Absorventes: Uma aplicac¸˜ao
para o Ensino M´edio

Thiago Emmanoel Amaral Nascimento

Disserta¸c˜ao de Mestrado apresentada `a Comiss˜ao
Acadˆemica Institucional do PROFMAT-UFBA
como requisito parcial para obten¸c˜ao do t´ıtulo de
Mestre em Matem´atica.

Orientador: Prof. Dr. Joseph Nee Anyah Yartey

Salvador - Bahia
Abril de 2019

Ficha catalográfica elaborada pelo Sistema Universitário de Bibliotecas (SIBI/UFBA), com os dados fornecidos pelo(a) autor(a). Nascimento, Thiago Emmanoel Amaral   Cadeias de Markov Absorventes: Uma aplicação para oensino / Thiago Emmanoel Amaral Nascimento. --Salvador, 2019.   91 f. : il   Orientador: Prof. Dr. Joseph Nee Anyah Yartey.    Dissertação (Mestrado - Mestrado Profissional emMatemática em Rede Nacional - PROFMAT) --Universidade Federal da Bahia, Instituto deMatemática e Estatística - IME, 2019.   1. Cadeias de Markov. 2. Cadeias de MarkovAbsorventes. 3. Ensino Médio. I. Nee Anyah Yartey,Prof. Dr. Joseph. II. Título. `A minha fam´ılia

Agradecimentos

Agrade¸co a Deus pela minha vida e por me assegurar for¸ca neste caminho que

apenas eu e ele sabemos o quanto foi duro e ´arduo caminhar. Agrade¸co a minha esposa e

ﬁlha por compreender os momentos ausentes e pelo amor a mim dedicado que me fazem

superar as horas de medo e ang´ustia. Agrade¸co aos meus pais o ensinamento de que a

educa¸c˜ao ´e um bem valioso e por todo o sacrif´ıcio que ﬁzeram para me garantir a mesma.

Agrade¸co a todos os colegas de curso pelas horas de estudos e pela uni˜ao que fez de

nossa turma um grupo de agrad´avel e alegre convivˆencia. Agrade¸co a todos os professores

que nos cederam um pouco de sua sabedoria e paciˆencia, que com certeza nos elevaram

a um outro patamar de conhecimento. Em especial, agrade¸co ao professor Joseph, meu

orientador, um grande mestre, que impressiona pela sua humildade e inteligˆencia.

Agrade¸co a todos os meus colegas das escolas onde trabalho por acreditar e persistir

na dif´ıcil miss˜ao de educar nossos jovens. Agrade¸co ainda ao Instituto de Matem´atica

e Estat´ıstica da UFBA por adotar e manter o Programa de Mestrado Proﬁssional em

Matem´atica em Rede Nacional - PROFMAT como local de aprimoramento dos professores

de matem´atica do estado da Bahia. Por ﬁm, gostaria de agradecer a Sociedade Brasileira

de Matem´atica - SBM e ao Instituto de Matem´atica Pura e Aplicada - IMPA pela cria¸c˜ao

e empenho na manuten¸c˜ao do mestrado proﬁssional que com certeza ajuda, e muito, a

melhorar o ensino de matem´atica em nosso pa´ıs.

”Ensinar a resolver problemas ´e
educar a vontade”.
George Polya

Resumo

No in´ıcio do s´eculo XX, Andrei Markov come¸cou um importante estudo de um
novo tipo de processo onde em um experimento, o resultado atual inﬂuencia o resultado
que ocorrer´a naquele imediatamente posterior a ele. A este tipo de processo chamamos
de Cadeias de Markov. Estas cadeias s˜ao melhores estudadas quando s˜ao consideradas
alguns tipos especiais da mesma.

Neste trabalho vamos estudar as Cadeias de Markov Absorventes, fazendo uma fun-
damenta¸c˜ao te´orica e dando alguns exemplos que mostram o funcionamento matem´atico
destas cadeias. Iremos ainda criar algumas atividades e materiais pedag´ogicos que au-
xiliem as aulas do professor que deseje ensinar as Cadeias de Markov Absorventes em
turmas de matem´atica do ensino m´edio.

Palavra-Chave: Cadeias de Markov; Cadeias de Markov. Absorventes

Abstract

In the early twentieth century, Andrei Markov began an important study of a new
kind of process where in an experiment, the current result inﬂuences the outcome that
will occur in that immediately after it. To this type of process we call Markov chains.
These chains are best studied when considering some special types of them.

In this work we will study the Absorbent Markov Chains making a theoretical
basis and giving some examples that show the mathematical functioning of these chains.
We will also create some activities and teaching materials that will support the teacher’s
classes that wish to teach the Absorbent Markov Chains in high school math classes.

Keyword: Markov Chains; Absorbing Markov Chains.

Lista de Figuras

1.1 Andrei Andreyevich Markov . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Diagrama de estados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Labirinto do Rato
1.4 Diagrama de estados - Labirinto do Rato
1.5 Diagrama de estados - Lealdade do consumidor

3
7
9
. . . . . . . . . . . . . . . . . . . . 10
. . . . . . . . . . . . . . . . . 17

2.1 Diagrama de estados - Ru´ına do Jogador
. . . . . . . . . . . . . . . . . . . . 28
2.2 Diagrama de estados - Pedra na Ves´ıcula . . . . . . . . . . . . . . . . . . . . 32

5.1 Labirinto . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

Lista de Tabelas

7
1.1 Distribui¸c˜ao de Probabilidades . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Registro do Tempo ao longo de um mˆes
. . . . . . . . . . . . . . . . . . . 15
1.3 Vetor de probabilidade - Lealdade do Consumidor . . . . . . . . . . . . . . 17

5.1 Tendˆencias Educacionais . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
5.2 Gen´etica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

6.1 N´umero de invers˜oes

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72

Sum´ario

Introdu¸c˜ao

1

1 Cadeias de Markov

3
1.1 Andrei Andreyevich Markov . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2 No¸c˜oes B´asicas
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
8
1.3 Deﬁni¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4 Equa¸c˜ao de Chapman-Kolmogorov . . . . . . . . . . . . . . . . . . . . . . 11
1.5 O vetor de probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.6 Exemplos
1.6.1 Tempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
1.6.2 Lealdade do consumidor . . . . . . . . . . . . . . . . . . . . . . . . 16
1.6.3 N´ıvel econˆomico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2 Cadeias de Markov Absorventes

20
2.1 Classiﬁca¸c˜ao de Estados
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.2 A Forma Canˆonica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.3 A matriz fundamental
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.4 Exemplos
2.4.1 A ru´ına do jogador . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.4.2 Pedra na ves´ıcula . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

3 Materiais Pedag´ogicos

34
3.1 Listas de Exerc´ıcios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.2 O Beamer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.3 O site

4 Considera¸c˜oes ﬁnais

43

5 Apˆendices

45
5.1 Apˆendice 1 - C´alculos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
5.1.1 Lealdade do Consumidor . . . . . . . . . . . . . . . . . . . . . . . . 45
5.1.2 Forma Canˆonica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

5.2.1
5.2.2
5.2.3

. . . . . . . . . . . . . . . . . . . . . . . 49
5.2 Apˆendice 2 - Listas de Exerc´ıcios
1o Bloco - No¸c˜oes B´asicas
. . . . . . . . . . . . . . . . . . . . . . . 49
2o Bloco - Vetor de probabilidade . . . . . . . . . . . . . . . . . . . 52
3o Bloco - Cadeias de Markov Absorventes . . . . . . . . . . . . . . 54
5.3 Apˆendice 3 - Probabilidades Carros de Combate . . . . . . . . . . . . . . . 58
5.4 Apˆendice 4 - Solu¸c˜oes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
1o Bloco - No¸c˜oes B´asicas
. . . . . . . . . . . . . . . . . . . . . . . 60
2o Bloco - Vetor de probabilidade . . . . . . . . . . . . . . . . . . . 61
3o Bloco - Cadeias de Markov Absorventes . . . . . . . . . . . . . . 62

5.4.1
5.4.2
5.4.3

6 Anexos
65
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
6.1
6.2 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

´Algebra Linear

Referˆencias Bibliogr´aﬁcas

79

Introdu¸c˜ao

Um processo estoc´astico ´e um modelo matem´atico que evolui ao longo do tempo
de forma probabil´ıstica. Quando a probabilidade que governa esta evolu¸c˜ao n˜ao depende
dos resultados anteriores ao atual, ou seja, o processo n˜ao possui mem´oria, dizemos que
este processo possui a propriedade markoviana.

Um processo estoc´astico que possui a propriedade markoviana e tem o seu espa¸co
de estados discreto ´e denominado cadeia de Markov. Assim para que um dado processo
estoc´astico seja considerado uma cadeia de Markov deve ter as seguintes caracter´ısticas:
ter a propriedade markoviana; o conjunto de estados poss´ıveis ao processo ´e discreto e
que ele ir´a ocupar algum desses estados a cada etapa do processo; o estado inicial em que
ele se encontra seja conhecido e as probabilidades de transi¸c˜ao entre os estados tamb´em
estejam deﬁnidas.

Indexando os poss´ıveis estados de uma cadeia de Markov podemos associar a ela
uma matriz de transi¸c˜ao quadrada de ordem i, onde i ´e a quantidade de estados da cadeia.
Assim, cada componente da matriz, representa a probabilidade de que a cadeia estar´a
no estado associado ao n´umero da coluna dado que na etapa, imediatemente anterior,
encontrava-se no estado associado ao n´umero da linha.

Com esta matriz de transi¸c˜ao e a imposi¸c˜ao de algumas restri¸c˜oes podemos estudar
tipos caracter´ısticos de cadeias de Markov que possuem aplica¸c˜oes nas mais diversas si-
tua¸c˜oes. Particularmente neste trabalho iremos focar nas cadeias de Markov com estados
absorventes. Dizemos que um estado ´e absorvente se ao adentrar nele ´e imposs´ıvel sair.
Um estado absorvente est´a para o processo, assim como, um buraco negro est´a para a
vida de uma estrela ou a morte est´a para um ser vivo.

As cadeias de Markov, em geral, podem ser aplicadas a uma ampla quantidade de
problemas, como podemos ver facilmente ao fazer uma breve pesquisa na internet. S˜ao
aplica¸c˜oes na ´area da termodinˆamica, Qu´ımica, reconhecimento de fala, teoria das ﬁlas,
ciˆencias da informa¸c˜ao, aplica¸c˜oes de internet, estat´ıstica, economia e ﬁnan¸cas, ciˆencias
sociais, Biologia, estrat´egias militares, gen´etica e at´e mesmo na m´usica.

Iremos estruturar este trabalho da seguinte maneira. No cap´ıtulo 1 faremos uma
breve biograﬁa de Andrei Andreyevich Markov (1856-1922) um jovem matem´atico russo
que foi o criador das cadeias que levam o seu nome. Markov tem uma hist´oria de vida
e acadˆemica muito peculiar. Acreditamos que seja v´alido e relevante conhecer o homem

1

2

por tr´as da teoria, para melhor entender sua obra. Em seguida, iremos tratar de alguns
conceitos b´asicos associados as cadeias de Markov, como o conjunto de estados de uma
cadeia e as probabilidades de transi¸c˜ao da mesma. Ainda neste cap´ıtulo introduzimos
as deﬁni¸c˜oes e teoremas que nos permitem explorar as propriedades mais gen´ericas das
cadeias de Markov. Finalizando este cap´ıtulo damos alguns exemplos que nos parecem
pertinentes e que esclarecem os conceitos e deﬁni¸c˜oes dadas neste cap´ıtulo.

Come¸camos o cap´ıtulo 2 com a classiﬁca¸c˜ao dos estados de uma cadeia de Markov.
Um estado de uma cadeia de Markov ser´a chamado de absorvente quando ao entrar
naquele estado o processo n˜ao ir´a mais sair dele. Da´ı temos que uma cadeia de Markov
´e absorvente se possui um estado absorvente e, al´em disso, este estado ´e acess´ıvel a
qualquer outro estado n˜ao absorvente. Em seguida deﬁnimos a forma canˆonica de uma
cadeia absorvente, bem como a matriz fundamental associada a ela.

Com essa matriz fundamental podemos extrair v´arias informa¸c˜oes relevantes sobre
a cadeia que nos permite prever muitos resultados interessantes sobre as mesmas. Dentre
eles est˜ao o n´umero de vezes que o processo ir´a ter at´e que seja absorvido e ainda a pro-
babilidade de que seja absorvido dado que iniciou o processo num estado n˜ao absorvente.
No ﬁnal do cap´ıtulo tamb´em damos alguns exemplos que servem para consolidar e ilustrar
os conceitos associados as cadeias de Markov absorventes.

O ´ultimo cap´ıtulo ´e dedicado a comentar os exerc´ıcios e atividades propostas no
site. S˜ao diretrizes que ir˜ao ajudar o professor na condu¸c˜ao das aulas e os estudantes
na resolu¸c˜ao das quest˜oes. Acreditamos que o p´ublico ideal para a aplica¸c˜ao exitosa do
material produzido sejam alunos do 2o ou 3o ano do ensino m´edio. Porque nestes casos
eles j´a estudaram matrizes, determinantes e sistemas lineares, assim como os conceitos
b´asicos de probabilidade.

Nos apˆendices est˜ao as listas de exerc´ıcios, suas respectivas solu¸c˜oes e alguns
c´alculos efetuados, nos exemplos dos cap´ıtulos anteriores, que achamos necess´ario dei-
xar expl´ıcitos. Nos anexos temos um breve resumo com conceitos b´asicos sobre matrizes,
determinantes e probabilidade, que caso o leitor precise estar´a dispon´ıvel para consulta.
Esperamos que aproveite a leitura.

Cap´ıtulo 1

Cadeias de Markov

Em 1907, Andrei Markov come¸cou um importante estudo de um novo tipo de
processo onde o resultado de um experimento atual ´e afetado pelo resultado que ocor-
reu no resultado imediatamente anterior a ele. A este tipo de processo chamamos de
Cadeias de Markov. No entanto antes de deﬁnir o que ´e uma Cadeia de Markov,
vejamos uma breve biograﬁa de Andrei Markov que tem como base as informa¸c˜oes en-
contradas nos artigos de J J O’Connor and E F Robertson na url www-groups.dcs.st-
and.ac.uk/history/Biographies/Markov.html acessado em 24 de fevereiro de 2019 e o ar-
tigo de Brian Hayes acessado na url www.americanscientist.org/article /ﬁrst-links-in-the-
markov-chain em 06 de mar¸co de 2019.

Figura 1.1: Andrei Andreyevich Markov

1.1 Andrei Andreyevich Markov

Andrei Andreyevich Markov ﬁlho de Nadezhda Petrovna e Andrei Grigorievich
Markov, foi um grande matem´atico russo nascido na cidade de Riazan em 14 de junho
de 1856. Teve muitas irm˜as e um irm˜ao mais novo chamado Vladimir, que tamb´em era
um matem´atico conhecido na ´epoca que morreu muito jovem aos 25 anos, de tuberculose.
Andrei Markov foi um jovem tamb´em de sa´ude fr´agil que at´e os dez anos andava com
ajuda de muletas.

Desde o gin´asio, Andrei Markov, j´a revelara seu talento para matem´atica e nesta
mesma ´epoca escreveu seu primeiro artigo matem´atico, cujo tema era a integra¸c˜ao de

3

4

equa¸c˜oes diferenciais. Apesar de n˜ao ser um artigo original, lhe rendeu um encontro com os
professores universit´arios Aleksandr Korkin(1837-1908) e Yegor Ivanovich Zolotarev(1847-
1878) da universidade de S˜ao Petersburgo, onde ele ingressou, em 1874, na Faculdade de
F´ısica e Matem´atica.

Na universidade ele se matriculou nos semin´arios de Korkin e Zolotarev, mas se
encantou mesmo com as aulas do grande matem´atico Pafnuti Chebyshev(1821-1894), que
eram estimulantes para Markov, pois nelas os alunos eram imersos em uma atmosfera de
pesquisa, tendo sempre novas quest˜oes e problemas para que os estudantes investigassem.
Markov graduou-se em 1878, quando ganhou uma medalha de ouro por submeter o
melhor artigo de sua faculdade naquele ano, cujo t´ıtulo era - Sobre a integra¸c˜ao de equa¸c˜oes
diferenciais por meio de fra¸c˜oes cont´ınuas. Ap´os sua gradua¸c˜ao ele come¸cou seu mestrado
com o desejo de se tornar professor universit´ario. Conseguiu concluir seu mestrado em
apenas dois anos e em 1880 apresentou sua disserta¸c˜ao cujo t´ıtulo foi - Sobre as formas
quadr´aticas bin´arias com determinante positivo. Ainda neste mesmo ano Markov come¸cou
a ensinar na Universidade de S˜ao Petersburgo e iniciou seu doutoramento que concluiu
em 1884 com sua tese Sobre algumas aplica¸c˜oes das fra¸c˜oes cont´ınuas.

Maria Ivanova Valvatyeva, sua futura esposa, era uma amiga de infˆancia, mas
apesar disso, a m˜ae de Ivanova n˜ao era a favor do casamento entre eles. Visto que,
Markov era ﬁlho do gerente de sua propriedade e portanto, para ela, n˜ao possu´ıa o status
social necess´ario para casar com sua ﬁlha. Por´em em 1883 a m˜ae de Ivanova concorda
com o casamento, talvez pela trajet´oria de sucesso que Markov vinha tra¸cando e eles se
casam neste mesmo ano.

Andrei Markov tornou-se professor titular da Universidade de S˜ao Petersburgo em
1893. Chebyshev propˆos que Markov fosse membro da Academia Russa de Ciˆencias em
1886. Ele foi eleito como um membro extraordin´ario em 1890 e acadˆemico em 1896.
Aposentou-se formalmente em 1905, mas continuou a ensinar durante `a maior parte de
sua vida.

O trabalho inicial de Markov foi em an´alise e teoria dos n´umeros, fra¸c˜oes alg´ebricas
cont´ınuas, limites de integrais, teoria de aproxima¸c˜ao e convergˆencia de s´eries. Depois de
1900 ele aplicou o m´etodo das fra¸c˜oes cont´ınuas, de Chebyshev, a teoria da probablidade.
Entretanto Markov ´e particularmente lembrado por seu estudo das cadeias de Mar-
kov, este trabalho fundou um ramo completamente novo da teoria da probabilidade e
lan¸cou a teoria dos processos estoc´asticos. Em 1923, Norbert Wiener(1894-1964) tornou-
se o primeiro a tratar rigorosamente um processo cont´ınuo de Markov. A funda¸c˜ao de uma
teoria geral foi fornecida a partir dos anos de 1930 por Andrei Kolmogorov(1903-1987) e
Sergei Bernstein(1880-1968).

O curso cl´assico de Markov sobre o c´alculo de probabilidades e suas notas originais,
s˜ao lembrados por sua exatid˜ao e clareza de exposi¸c˜ao. Contribu´ıram muito para a trans-
forma¸c˜ao da teoria da probabilidade em uma das ´areas mais estudadas da matem´atica,

5

e para a ampla dissemina¸c˜ao dos m´etodos e das pesquisas de Chebyshev. Sua an´alise
profunda das dependˆencias entre os fenˆomenos aleat´orios observados, permitiu a Mar-
kov estender a teoria da probabilidade de uma maneira essencial atrav´es da introdu¸c˜ao e
investiga¸c˜ao de quantidades aleat´orias dependentes.

Suas palestras eram marcadas por um rigor irrepreens´ıvel de argumenta¸c˜ao e bus-
cava desenvolver em seus alunos um pensamento matem´atico cr´ıtico, que n˜ao toma nada
como garantido. Ele incluiu em seus cursos muitos resultados recentes de investiga¸c˜oes e
freq¨uentemente omitia quest˜oes tradicionais.

Conforme Hayes, segundo a maioria dos relatos, Markov era um personagem irri-
tante, abrasivo mesmo com amigos, ferozmente combativo com rivais, muitas vezes envol-
vido em protestos e brigas p´ublicas. Um fato que nos d´a um vislumbre de sua forte per-
sonalidade s˜ao suas correspondˆencias com o estat´ıstico Alexander Chuprov (1874-1926).
Suas cartas a Chuprov s˜ao repletas de coment´arios desdenhosos denegrindo o trabalho de
outros - inclusive o de Chuprov.

A combatividade de Markov se estendeu al´em da matem´atica, passando pela
pol´ıtica e pela vida p´ublica. Quando a igreja russa excomungou Leo Tolstoy, Markov
pediu que ele fosse expulso tamb´em, o que foi feito. Em 1902, o escritor de esquerda
Maxim Gorky foi eleito para a Academia, mas a elei¸c˜ao foi vetada pelo czar Nicolau II.
Em protesto, Markov anunciou que recusaria todas as honras futuras do czar. Em 1913,
quando o czar convocou celebra¸c˜oes de 300 anos de governo Romanov, Markov respondeu
organizando um simp´osio comemorando um anivers´ario diferente: a publica¸c˜ao de Ars
Conjectandi 200 anos antes, livro sobre combina¸c˜ao e probabilidade escrito por Jacob
Bernoulli.

Por´em o maior conﬂito de Markov foi reservado para outro matem´atico, Pavel
Nekrasov (1853–1924), cujo trabalho Markov descreveu como “um abuso da matem´atica”.
Nekrasov estava na faculdade da Universidade de Moscou, que era ent˜ao um reduto da
Igreja Ortodoxa Russa. Nekrasov havia come¸cado a estudar em um semin´ario teol´ogico
antes de se voltar para a matem´atica e aparentemente acreditava que as duas voca¸c˜oes
poderiam se apoiar mutuamente.

Em um artigo publicado em 1902, Nekrasov injetou a lei de grandes n´umeros no
debate teol´ogico centen´ario sobre o livre-arb´ıtrio versus a predestina¸c˜ao. Seu argumento
foi mais ou menos assim: Atos volunt´arios - express˜oes de livre arb´ıtrio - s˜ao como os
eventos independentes da teoria da probabilidade, sem liga¸c˜oes causais entre eles. A lei
dos grandes n´umeros aplica-se apenas a tais eventos independentes.

Markov e Nekrasov encontravam-se em p´olos opostos: um republicano secular de
Petersburgo confrontava um monarquista eclesi´astico de Moscou. Mas quando Markov
lan¸cou seu ataque a Nekrasov, ele n˜ao o fez com bases em suas diferen¸cas faccionais ou
ideol´ogicas. Ele se concentrou em um erro matem´atico. Nekrasov assumiu que a lei dos
grandes n´umeros requer o princ´ıpio da independˆencia. Embora essa no¸c˜ao tenha sido

6

um lugar comum da teoria da probabilidade desde o tempo de Jacob Bernoulli, Markov
come¸cou a mostrar que a suposi¸c˜ao ´e desnecess´aria. A lei dos grandes n´umeros aplica-se
perfeitamente aos sistemas de vari´aveis dependentes se satisﬁzerem certos crit´erios e assim
nasceram as cadeias de Markov.

A Revolu¸c˜ao Russa come¸cou no in´ıcio de 1917, quando os suprimentos de comida
se esgotaram. Em setembro daquele ano, Markov solicitou que a Academia o mandasse
para uma cidade desfavorecida no interior da R´ussia. Ele foi enviado para Zaraisk, uma
pequena cidade do interior, onde lecionava matem´atica na escola secund´aria sem receber
nenhuma remunera¸c˜ao.

Ele retornou a S˜ao Petersburgo, mas sua sa´ude j´a estava se deteriorando. Embora
em 1921 ele estivesse com um estado de sa´ude muito ruim, de forma que mal conseguia se
manter em p´e, ainda assim continuou a dar palestra sobre probabilidade na universidade.
Sua morte em julho de 1922 veio depois de meses de sofrimento muito grave. Markov
teve um ﬁlho (de mesmo nome) que nasceu em 9 de setembro de 1903 e seguiu seu pai
tamb´em tornando-se um renomado matem´atico.

1.2 No¸c˜oes B´asicas

A maioria dos estudos de probabilidade utiliza o Princ´ıpio de Independˆencia de
Eventos, ou seja, que em um experimento aleat´orio o resultado atual ou anterior n˜ao
tem inﬂuˆencia sobre um resultado futuro. Para ilustrar tal princ´ıpio, basta lembrar que
no lan¸camento de uma moeda honesta, a probabilidade de que a moeda dˆe cara ou co-
roa em um lan¸camento n˜ao se altera devido a ocorrˆencia de cara ou corˆoa em qualquer
um dos lan¸camentos anteriores. Por´em, existem estudos em que a probabilidade de um
determinado resultado ´e inﬂuenciada pela ocorrˆencia do resultado atual ou anteriores.

As Cadeias de Markov modelam processos onde o pr´oximo resultado ´e inﬂuenciado
pelo resultado atual obtido. Antes de formalizar uma deﬁni¸c˜ao matem´atica mais rigorosa
para uma Cadeia de Markov, vamos descrever quais os elementos que a formam e como
a mesma funciona. Considere um conjunto de estados poss´ıveis S = {s1, s2, . . . , sr} de
uma vari´avel aleat´oria. Uma Cadeia de Markov tem in´ıcio em um desses estados e a
probabilidade de que haja mudan¸ca neste estado depende do estado em que o processo se
encontra. Chamaremos cada uma dessas mudan¸cas de estado de passo ou etapa.

Se a cadeia encontra-se atualmente no estado si e se move para o estado sj no
pr´oximo passo, a probabilidade, indicada por pij, n˜ao depende dos resultados que ocorre-
ram em passos anteriores ao estado atual da cadeia. Por isso dizemos que uma Cadeia de
Markov ´e um processo que n˜ao possui mem´oria, ou seja, o que ocorrer´a no pr´oximo passo
depende apenas do estado atual da cadeia.

As probabilidades pij s˜ao chamadas de probabilidades de transi¸c˜ao. O processo
pode permanecer no mesmo estado em um passo qualquer e neste caso a probabilidade de

transi¸c˜ao ser´a indicada por pii. Uma distribui¸c˜ao inicial de probabilidade, deﬁnida sobre
S, e um estado inicial deﬁne uma cadeia de Markov, veja no diagrama abaixo uma cadeia
de Markov com quatro estados.

7

Estado

1

p12

p21

p22

Estado

2

p
1
4

p
3

1

p
2
3

4

2

p

p
1

3

Estado

4

p44

Estado

3

p33

Figura 1.2: Diagrama de estados

Na tabela 1.1 a seguir, est˜ao registradas as respectivas probabilidades de transi¸c˜ao

para cada mudan¸ca de estado.

Tabela 1.1: Distribui¸c˜ao de Probabilidades

Probabilidade de transi¸c˜ao Valor Probabilidade de transi¸c˜ao Valor

(pij)
Permanecer no Estado 1 (p11)
Ir do Estado 1 para o 2 (p12)
Ir do Estado 1 para o 3 (p13)
Ir do Estado 1 para o 4 (p14)
Ir do Estado 2 para o 1 (p21)
Permanecer no Estado 2 (p22)
Ir do Estado 2 para o 3 (p23)
Ir do Estado 2 para o 4 (p24)

(pij)
Ir do Estado 3 para o 1 (p31)
Ir do Estado 3 para o 2 (p32)
Permanecer no Estado 3 (p33)
Ir do Estado 3 para o 4 (p34)
Ir do Estado 4 para o 1 (p41)
Ir do Estado 4 para o 2 (p42)
Ir do Estado 4 para o 3 (p43)
Permanecer no Estado 4 (p44)

0
0,5
0,30
0,20
0,40
0,20
0,30
0,10

0,25
0,25
0,5
0
0
0
0
1

Vejamos agora como interpretar a Cadeia da ﬁgura 1.2 associada as probabilidades
de transi¸c˜ao dadas na tabela 1.1. Por exemplo, observe que se o processo encontra-
se no estado 2 ele pode ir no pr´oximo passo para o estado 3 (p23) e isso ocorre com
uma probabilidade de 30%. Temos ainda que se o processo encontra-se no estado 3 a
probabilidade dele permanecer neste estado (p33) ´e de 50%. Note tamb´em que do estado
1 podemos ir para qualquer um dos outros estados, mas nunca permaneceremos neste
mesmo estado no pr´oximo passo, pois a probabilidade de permanecer no estado 1 (p11) ´e
zero. Por´em, observe que ao chegar no estado 4 o processo se encerra, pois ir´a permanecer
neste estado para sempre j´a que a probabilidade de permanecer em 4 (p44) ´e de 100%,

8

no cap´ıtulo 2 chamaremos este tipo de estado de absorvente. Dado esses esclarecimentos
iniciais vejamos como deﬁnir formalmente uma Cadeia de Markov.

1.3 Deﬁni¸c˜oes

Nesta se¸c˜ao vamos deﬁnir formalmente alguns conceitos que s˜ao necess´arios para

caracterizar uma Cadeia de Markov.

Deﬁni¸c˜ao 1.3.1. Um processo estoc´astico {X(t) ∈ E | t ∈ U } ´e uma sequˆencia
de vari´aveis aleat´orias X(t) que descreve a evolu¸c˜ao de alguma caracter´ıstica X de um
processo sob an´alise ao longo do tempo t ∈ U , tal que U ⊂ R.

Para as deﬁni¸c˜oes a seguir, seja U o conjunto dos n´umeros naturais e a vari´avel
aleat´oria X, representa o estado do sistema no instante t. O conjunto E, chamado de
espa¸co de estados, ´e discreto e ﬁnito, ou seja, possui M elementos, com M ∈ N. Desta
forma o processo estoc´asticos {X(t)} fornece uma representa¸c˜ao matem´atica de como o
processo evolui ao longo do tempo.

Deﬁni¸c˜ao 1.3.2. Um processo estoc´astico ´e denominado processo markoviano de
parˆametro discreto, se dada uma sequˆencia de tempos t0 < t1 < t2 < · · · < tn < tn+1, a dis-
tribui¸c˜ao de probabilidade condicional de X(tn+1) para dados valores de X(t0), X(t1), . . . , X(tn)
depende unicamente de X(tn), ou seja,

P {X(tn+1) = j | X(t0) = k0, X(t1) = k1, . . . , X(tn−1) = kn−1, X(tn) = i}

=

P {X(tn+1) = j | X(tn) = i}

Um processo markoviano que possui espa¸co de estados E ﬁnito ´e denominado
cadeia de Markov. As probabilidades condicionais P {X(tn+1) = j | X(tn) = i} para
uma cadeia de Markov s˜ao chamadas probabilidades de transi¸c˜ao para um passo ou
etapa.

Para simpliﬁcar a escrita vamos utilizar as seguintes nota¸c˜oes:

pij = P {X(t + 1) = j | X(t) = i}

p(n)
ij = P {X(t + n) = j | X(t) = i}

Note que as p(n)
ij

s˜ao as probabilidades condicionais para que se esteja em um
estado i e se passe para um estado j em n passos. Al´em disso, como essas quantidades
representam probabilidades condicionais s˜ao n´umeros n˜ao negativos. Observe ainda que

o processo deve realizar sempre uma transi¸c˜ao para algum estado em cada passo, logo
elas devem satisfazer as seguintes propriedades:

9

p(n)
ij ≥ 0 para todo i e j; n ∈ N
e

M
(cid:88)

p(n)
ij = 1 para todo i e j; n ∈ N

j=0

Outro fato importante ´e que p(1)

ij = pij, e que p(0)

ij =

(cid:40)

1, se i = j
0, se i (cid:54)= j

.

O exemplo a seguir ´e uma adapta¸c˜ao daquele que se encontra em Poole (2004,
p. 206) e achamos importante cit´a-lo, pois esclarece e ilustra as deﬁni¸c˜oes dadas at´e o
presente momento.

Exemplo 1.3.1. Um psicol´ogo coloca um rato em uma gaiola de 5 compartimentos, como
mostra a ﬁgura abaixo. O rato foi treinado para selecionar uma porta aleatoriamente
sempre que tocarem um sinal, e dirigir-se atrav´es dela para o pr´oximo compartimento.

Figura 1.3: Labirinto do Rato

Esta situa¸c˜ao pode ser modelada por uma Cadeia de Markov, pois o compartimento
ao qual o rato ir´a acessar ap´os cada sinal depende, apenas, do compartimento onde ele se
encontra atualmente(propriedade markoviana). Ademais esta ´e uma cadeia com 5 estados,
onde o compartimento PQ(para´ıso do queijo) ´e um estado absorvente. As probabilidades
de transi¸c˜ao entre os compartimentos est˜ao representadas no diagrama 1.4.

Note que as setas em cada n´o do diagrama, representam a probabilidade de transi¸c˜ao
que o rato possui para que estando naquele compartimento acesse aquele que a seta est´a
indicando. Al´em disso, o somat´orio das probabilidades das setas que saem de cada n´o s˜ao

sempre iguais a 1, ou seja,

5
(cid:88)

j=1

pij = 1 para todo i ∈ 1, 2, 3, 4, 5.

Uma maneira mais conveniente e eﬁcaz de representar todas as probabilidades
de transi¸c˜ao em n etapas de uma cadeia de Markov ´e utilizar o formato matricial, que
deﬁnimos abaixo.

10

1
4

1
3

1
3

1
6

1
3

1

1
3

1
4

1
6

2

3

4

1
3

1
2

2
3

1
3

PQ

1

Figura 1.4: Diagrama de estados - Labirinto do Rato

Deﬁni¸c˜ao 1.3.3. A matriz de transi¸c˜ao em n-etapas de uma cadeia de Markov ´e
a matriz P (n) com entradas p(n)
ij .

Estado

1

2

· · ·

M














p(n)
11

p(n)
21
...

p(n)
M 1

1

2
...

M

p(n)
12

p(n)
22
...

p(n)
M 2

· · ·

· · ·
. . .

· · ·














p(n)
1M

p(n)
2M
...

p(n)
M M

P(n) =

A probabilidade de transi¸c˜ao se d´a do estado de linha para o estado de coluna.
Al´em disso, quando n = 1, eliminamos o superescrito (n) e neste caso temos a matriz de
transi¸c˜ao da cadeia de Markov.

Para o exemplo 1.3.1 podemos utilizar o diagrama 1.4 para construir a matriz de

transi¸c˜ao do experimento, que ﬁca da seguinte maneira.

1

0

1
4

1
6

1
3

0


















1

2

3

4

P Q

2

3

1
3

0

2
6

0

0

1
3

2
4

0

2
3

0

4

1
3

0

2
6

0

0

P Q


















0

1
4

1
6

0

1

P =

Vamos agora enunciar e provar o primeiro teorema relacionado as cadeias de Mar-

kov.

11

1.4 Equa¸c˜ao de Chapman-Kolmogorov

Um importante teorema que nos garante uma rela¸c˜ao entre as probabilidades de
transi¸c˜ao entre estados em n-etapas e as potˆencias da matriz de transi¸c˜ao de uma cadeia
de Markov ´e a equa¸c˜ao de Chapman-Kolmogorov.

A ﬁgura abaixo nos ajuda a compreender melhor o enunciado do teorema. Tome-
mos como exemplo uma cadeia de Markov com 3 estados poss´ıveis e observemos como se
comporta a probabilidade de transi¸c˜ao de passar do estado 3 para o estado 1 em 5 etapas,
vejamos:

E3

E2

E1

0

1

2

3

4

5

A equa¸c˜ao de Chapman-Kolmogrov aﬁrma que a probabilidade de que o processo
se encontre, por exemplo, no estado 1 dado que ele iniciou no estado 3 em 5 etapas ´e dada
pela soma do produto entre as probabilidades de ir do estado 3 para cada um dos estados
em 3 etapas e as probabilidades de ir de cada um dos estados at´e o estado 1 em duas
etapas. A parti¸c˜ao do exemplo foi de 3 para 2 etapas, mas poderia ser qualquer outra,
cujo resultado fosse igual a cinco.

Para ter uma boa intui¸c˜ao da veracidade dessa aﬁrma¸c˜ao basta perceber que a
ﬁgura acima ´e uma forma condensada do diagrama de ´arvores das probabilidades condi-
cionais do problema. Com isso ´e f´acil perceber que de fato a aﬁrma¸c˜ao parece verdadeira,
mas como em matem´atica apenas a intui¸c˜ao n˜ao basta, vejamos agora o enunciado e a
demonstra¸c˜ao deste teorema.

Teorema 1.4.1. Seja {X(t)} uma cadeia de Markov, com probabilidades de transi¸c˜ao
dada por pij. Para qualquer par de tempos r e n, tal que 0 ≤ r ≤ n e para todo k ∈ E
temos que:

p(n)
ij =

M
(cid:88)

k=1

ik · p(n−r)
p(r)

kj

Demonstra¸c˜ao. Por deﬁni¸c˜ao sabemos que para passar do estado atual i para o estado j
em n etapas, a probabilidade de transi¸c˜ao ser´a dada por:

p(n)
ij = P {X(n) = j|X(0) = i}

12

Usando a deﬁni¸c˜ao de probabilidade condicional, temos que:

P {X(n) = j|X(0) = i} =

P {X(n) = j ∩ X(0) = i}
P {X(0) = i}

Pelo teorema da probabilidade total, podemos aﬁrmar que:

P {X(n) = j ∩ X(0) = i}
P {X(0) = i}

=

M
(cid:88)

k=1

P {X(n) = j ∩ X(r) = k ∩ X(0) = i}
P {X(0) = i}

Novamente pela deﬁni¸c˜ao de probabilidade condicional podemos escrever que:

M
(cid:88)

k=1

P {X(n) = j ∩ X(r) = k ∩ X(0) = i}
P {X(0) = i}

=

M
(cid:88)

k=1

P {X(n) = j|X(r) = k ∩ X(0) = i} · P {X(r) = k ∩ X(0) = i}
P {X(0) = i}

Da´ı, como r ≥ 0 e aplicando a propriedade markoviana podemos aﬁrmar que:

P {X(n) = j|X(r) = k ∩ X(0) = i} = P {X(n) = j|X(r) = k}

Portanto:

M
(cid:88)

k=1

P {X(n) = j|X(r) = k ∩ X(0) = i} · P {X(r) = k ∩ X(0) = i}
P {X(0) = i}

=

M
(cid:88)

k=1

P {X(n) = j|X(r) = k} · P {X(r) = k|X(0) = i}

Para ﬁnalizar basta aplicar a deﬁni¸c˜ao da probabilidade de transi¸c˜ao as duas probabili-

dades condicionais encontradas para concluirmos que: p(n)

ij =

M
(cid:88)

k=1

ik · p(n−r)
p(r)

kj

(cid:4)

Uma importante consequˆencia da equa¸c˜ao de Chapman-Kolmogorov ´e o seguinte

corol´ario:

Corol´ario 1.4.1. Se P ´e a matriz de probabilidades de transi¸c˜ao do estado i para o estado
j em um passo, ent˜ao a matriz de probabilidades de transi¸c˜ao do estado i para o estado j
em n passos ´e dada pela potˆencia de P elevada a n, ou seja, P (n) = P n.

Demonstra¸c˜ao. Usaremos a indu¸c˜ao ﬁnita sobre n para provar a senten¸ca acima. Para
n = 1 temos que P (1) = P 1 = P que ´e verdade por deﬁni¸c˜ao. Suponha que a senten¸ca
seja verdadeira para n = m, com m ∈ N e m > 1, isto ´e, P (m) = P m, devemos mostrar
que a senten¸ca ´e verdadeira quando n = m + 1. De fato, usando a equa¸c˜ao de Chapman-
Komogorov, para r = 1, temos que:

13

P (m+1) = p(m+1)

ij

=

=

M
(cid:88)

k∈E

M
(cid:88)

k∈E

ik · p(m)
p(1)

kj

ik · pm
p1
kj

= P.P m = P m+1

Logo pelo princ´ıpio da indu¸c˜ao ﬁnita a senten¸ca ´e verdadeira para todo n ∈ N.

(cid:4)

Assim, a equa¸c˜ao de Chapman-Kolmogorov nos mostra que para saber qual a
probabilidade de se passar de um estado i para um estado j em n-etapas, basta que
calculemos as potˆencia da matriz de transi¸c˜ao elevada a n para obter a probabilidade
desejada.

Isso nem sempre ´e simples de se fazer, pois envolve multiplica¸c˜ao de matrizes
quadradas, de ordem M que ´e a quantidade de estados que a vari´avel pode assumir.
Quando a matriz de transi¸c˜ao for diagonaliz´avel o trabalho ´e razoavelmente facilitado,
quando n˜ao, podemos utilizar algum programa de computador para realizar essa tarefa e
para o caso de alunos do ensino m´edio essa segunda op¸c˜ao ´e a ´unica poss´ıvel.

Vejamos agora uma ´ultima deﬁni¸c˜ao que facilita o tratamento de uma cadeia de

Markov, o vetor de probabilidade.

1.5 O vetor de probabilidade

Deﬁni¸c˜ao 1.5.1. O vetor de probabilidade, indicado por π(n) ´e um vetor linha, cujo
i-´esimo componente xi ´e a probabilidade do sistema estar, naquela observa¸c˜ao, no i-´esimo
estado.

Deﬁni¸c˜ao 1.5.2. Chamamos de vetor de probabilidade inicial o vetor de probabili-
dade cujo n ´e igual a zero, ou seja, π(0).

Vale salientar que sendo um vetor de probabilidades suas entradas ser˜ao todas n˜ao
negativas e de soma igual a 1. Observe ainda que, cada uma das componentes xi do vetor
de probabilidade inicial π(0) representa a probabilidade da cadeia encontrar-se no estado
si, no in´ıcio do processo.

Agora note que com a deﬁni¸c˜ao do vetor de probabilidade e a matriz de transi¸c˜ao
P de uma cadeia de Markov, podemos escrever a equa¸c˜ao de Chapman-Kolmogorov para
n ≥ 1 na forma matricial da seguinte maneira:

π(n) = π(n−1) · P

14

O teorema que iremos enunciar e demonstrar abaixo, nos mostra que o vetor de
distribui¸c˜ao de probabilidade ap´os n-etapas, pode tamb´em ser calculado atrav´es do pro-
duto entre o vetor de probabilidade inicial π(0) e a n-´esima potˆencia da matriz de transi¸c˜ao
P , vejamos:

Teorema 1.5.1. Seja P a matriz de transi¸c˜ao da cadeia de Markov e π(0) o vetor de
probabilidade que representa sua distribui¸c˜ao inicial. Ent˜ao a probabilidade de que a
cadeia esteja no estado si depois de n passos, ´e a componente xi do vetor π(n) = π(0) · P n

Demonstra¸c˜ao. Sabemos que pela forma matricial da equa¸c˜ao de Chapman-Kolmogorov:

π(n) = π(n−1) · P

Aplicando a equa¸c˜ao de forma recursiva chegamos a:

π(n) = π(n−2) · P · P

...

π(n) = π(0) · P · P · P · · · P
(cid:125)
(cid:124)

(cid:123)(cid:122)
n vezes

Donde podemos concluir que: π(n) = π(0) · P n.

(cid:4)

Em particular, se quisermos observar o comportamento da cadeia para um estado
si espec´ıﬁco, basta fazer com que o vetor de probabilidade inicial tenha componentes
todas iguais a zero exceto `a componente xi, que ter´a valor igual a 1.

1.6 Exemplos

Podemos encontrar muitos exemplos de aplica¸c˜oes das Cadeias de Markov na li-
teratura. Dentre eles podemos citar: problemas da ´area de Administra¸c˜ao que envolvem
a Lealdade do Consumidor em rela¸c˜ao a determinados produtos ou a¸c˜oes do mercado
ﬁnanceiro. Encontramos ainda aplica¸c˜oes na ´area da Gen´etica onde a matriz de transi¸c˜ao
da cadeia representa a probabilidade de numa reprodu¸c˜ao a prole ter um gene do tipo
dominante, recessivo ou h´ıbrido. Ainda temos fenˆomenos f´ısicos que podem ser modelados
atrav´es de uma Cadeia de Markov, como ´e o caso do modelo de Ehrenfest que ´e usado
para explicar como a difus˜ao de gases ocorre num determinado ambiente.

No entanto escolhemos inicialmente um exemplo que envolve o estado do tempo em
uma cidade, pois este ´e mais eﬁciente para nos ajudar a compreender alguns dos conceitos
b´asicos apresentados.

15

1.6.1 Tempo

Considere uma sequˆencia de vari´aveis aleat´orias X(t) cujos elementos pertencem
ao espa¸co E = {Sem nuvens, N ublado, Chovendo}. A tabela 1.2 abaixo, nos mostra
como esteve o tempo a cada dia em um certo mˆes em Salvador, iremos considerar essa
nossa observa¸c˜ao inicial.

Tabela 1.2: Registro do Tempo ao longo de um mˆes

Sem nuvens Sem nuvens

Dia 1
Nublado
Dia 6

Dia 11
Nublado
Dia 16
Chovendo
Dia 21

Dia 26

Dia 4
Nublado
Dia 9

Dia 12
Chovendo
Dia 17

Dia 2
Sem nuvens
Dia 7

Dia 3
Nublado
Dia 8
Nublado
Dia 13
Chovendo
Dia 18

Dia 5
Chovendo
Dia 10
Sem nuvens Nublado
Dia 15
Chovendo
Dia 20
Sem nuvens Sem nuvens Sem nuvens Nublado
Dia 25
Chovendo
Dia 30
Sem nuvens Nublado

Dia 23
Nublado
Dia 28
Nublado

Dia 24
Nublado
Dia 29

Dia 14
Nublado
Dia 19

Dia 27

Dia 22

Sem nuvens Sem nuvens

Sem nuvens Sem nuvens

Pela tabela 1.2, segue que PSem nuvens = 12

30. Fazendo
corresponder o estado Sem nuvens a 1, o estado Nublado a 2 e o estado Chovendo a 3 temos
30, 6
que o vetor de probabilidade inicial para este fenˆomeno seria dado por π(0) = ( 12
30)
ou π(0) = (0, 40; 0, 40; 0, 20).

30 e PChovendo = 6

30, PN ublado = 12

30, 12

Suponha que o Instituto Nacional de Pesquisas Espaciais - INPE, tenha ao longo
de 20 anos de observa¸c˜ao gerado uma matriz de transi¸c˜ao do tempo para a cidade de
Salvador com as seguintes entradas:

Estado 1

2

3

P =






1
2
3

0, 40 0, 55 0, 05
0, 20 0, 60 0, 20
0, 10 0, 60 0, 30






Observando a matriz acima podemos ver que se hoje temos um tempo sem nuvens
(estado 1) no c´eu h´a uma probabilidade de 55% de que amanh˜a teremos um dia nublado
(estado 2), ou ainda, que se hoje est´a chovendo (estado 3) temos uma probabilidade de
30% que amanh˜a continue chovendo.

Como nossa vari´avel ´e mensal ao multiplicar o vetor de probabilidade inicial π(0)
pela matriz de transi¸c˜ao P teremos o vetor de probabilidade π(1) que representa a distri-
bui¸c˜ao de probabilidade para o pr´oximo mˆes e assim sucessivamente.

16

Este exemplo ´e importante para o aprendizado das cadeias de Markov por dois
motivos. O tempo em uma cidade ´e um fenˆomeno que de fato independe do seu estado
h´a um ano atr´as mas ´e inﬂuenciado pelo estado em que se encontra no dia anterior, ou
seja, este ´e um fenˆomeno que possui a propriedade markoviana. O outro motivo ´e que a
matriz de transi¸c˜ao neste caso ´e simples de ser interpretada e tem um tamanho reduzido
pois a quantidade de estados poss´ıveis da vari´avel ´e realmente pequeno.

A seguir iremos estudar o exemplo que envolve a Lealdade do consumidor sobre as

compras que fazem durante o mˆes.

1.6.2 Lealdade do consumidor

O enunciado abaixo ´e uma vers˜ao adaptada do problema que encontra-se em Sul-

livan e Mizrahi (2006, p. 502), vejamos:

Em um determinado bairro de uma cidade existem 4 supermercados em
que a popula¸c˜ao do bairro faz suas compras. Atrav´es de uma pesquisa feita em
1 de janeiro foi determinado que 25% da popula¸c˜ao compra no supermercado
1, 32% no supermercado 2, 23% no supermercado 3 e 20% no supermercado 4.
Al´em disso, sabe-se ainda que a cada mˆes o supermercado 1 mant´em 75% dos
seus clientes e perde 10% para o supermercado 2, 5% para o supermercado 3,
10% para o supermercado 4. O supermercado 2 mant´em 60% dos seus clientes
e perde 8% para o supermercado 1, 15% para o supermercado 3, 17% para o
supermercado 4. O supermercado 3 mant´em 50% dos seus clientes e perde 10%
para o supermercado 1, 20% para o supermercado 2, 20% para o supermercado
4. Por ﬁm o supermercado 4 mant´em 80% dos seus clientes e perde 10% para
o supermercado 2, 10% para o supermercado 3.

O vetor de probabilidade inicial neste caso ´e dado por π(0) = (0, 25; 0, 32; 0, 23; 0, 20)
e para facilitar a montagem da matriz de transi¸c˜ao P, fa¸camos inicialmente um diagrama
de estados com os dados do problema e em seguida sua matriz de transi¸c˜ao.

1

2

3

4

P =









1
2
3
4

0, 75 0, 10 0, 05 0, 10
0, 08 0, 60 0, 15 0, 17
0, 10 0, 20 0, 50 0, 20
0, 10 0, 10 0, 80

0









O processo descrito no problema ´e uma cadeia de Markov. Assim podemos saber
qual o vetor seguinte de distribui¸c˜ao de probabilidades de clientes em cada mercado ao
longo do tempo usando a equa¸c˜ao π(n+1) = π(n) · P . Na tabela abaixo podemos visualizar
esses c´alculos para os pr´oximos 31 meses, com aproxima¸c˜ao de 4 casas decimais:

17

0.75

0
.
1
0

0.80

1

4

0.10

7

0 . 1

0.10

0.08

0.10

0.20

0

0 . 1

0.05

0.60

2

0
.
2
0

0
.
1
5

3

0.50

Figura 1.5: Diagrama de estados - Lealdade do consumidor

Tabela 1.3: Vetor de probabilidade - Lealdade do Consumidor

Vetor Valor
π(0)
π(1)
π(2)
π(3)
π(4)
π(5)
π(6)
π(7)
π(8)
π(9)
π(10)
π(11)
π(12)
π(13)
π(14)
π(15)

(0,2500; 0,3200; 0,2300; 0,2000)

(0,1460; 0,2348; 0,1740; 0,4453)

(0,2361; 0,2830; 0,1955; 0,2854)

(0,1457; 0,2348; 0,1740; 0,4455)

(0,2193; 0,2611; 0,1805; 0,3391)

(0,1454; 0,2348; 0,1741; 0,4457)

(0,2034; 0,2486; 0,1743; 0,3737)

(0,1453; 0,2348; 0,1741; 0,4458)

(0,1899; 0,2417; 0,1720; 0,3964)

(0,1451; 0,2348; 0,1741; 0,4459)

(0,1789; 0,2381; 0,1714; 0,4116)

(0,1451; 0,2348; 0,1741; 0,4460)

(0,1704; 0,2362; 0,1715; 0,4219)

(0,1450; 0,2348; 0,1741; 0,4461)

(0,1638; 0,2352; 0,1719; 0,4290)

(0,1449; 0,2348; 0,1741; 0,4461)

(0,1589; 0,2348; 0,1723; 0,4340)

(0,1449; 0,2348; 0,1742; 0,4461)

(0,1552; 0,2346; 0,1727; 0,4375)

(0,1449; 0,2348; 0,1742; 0,4461)

(0,1524; 0,2346; 0,1731; 0,4399)

(0,1449; 0,2348; 0,1742; 0,4461)

(0,1504; 0,2346; 0,1733; 0,4417)

(0,1448; 0,2348; 0,1742; 0,4462)

(0,1489; 0,2346; 0,1735; 0,4429)

(0,1448; 0,2348; 0,1742; 0,4462)

(0,1478; 0,2347; 0,1737; 0,4438)

(0,1448; 0,2348; 0,1742; 0,4462)

(0,1470; 0,2347; 0,1738; 0,4445)

(0,1448; 0,2348; 0,1742; 0,4462)

(0,1464; 0,2347; 0,1739; 0,4449)

(0,1448; 0,2348; 0,1742; 0,4462)

Vetor Valor
π(16)
π(17)
π(18)
π(19)
π(20)
π(21)
π(22)
π(23)
π(24)
π(25)
π(26)
π(27)
π(28)
π(29)
π(30)
π(31)

Na tabela 1.3 destacamos em negrito o vetor π(27), pois a partir dele, para uma
aproxima¸c˜ao de 4 casas decimais, os vetores de distribui¸c˜ao de probabilidades continuam
iguais, ou seja, todo vetor π(n) tal que n > 27 ter´a a mesma distribui¸c˜ao de probabilidade
que ele.

Observe que podemos interpretar este fato da seguinte maneira: se as pessoas
deste bairro continuarem a frequentar os mercados segundo a matriz de transi¸c˜ao dada,
ap´os vinte e sete meses teremos: 14, 48% dos moradores comprando no supermercado 1,
23, 48% dos moradores comprando no supermercado 2, 17, 42% dos moradores comprando
no supermercado 3 e 44, 62% dos moradores comprando no supermercado 4. Este vetor ´e
chamado de vetor de probabilidade estacion´ario.

Fa¸camos agora o mesmo c´alculo utilizando o teorema 1.5.1, ou seja, encontraremos

18

π(n), multiplicando o vetor de probabilidade inicial π(0) pelas en´esimas potˆencias da matriz
de transi¸c˜ao P . Os c´alculos completos encontram-se no apˆendice 1.

No entanto, o que nos interessa neste momento ´e perceber que a partir da trig´esima
primeira potˆencia de P, com uma aproxima¸c˜ao de 4 casas decimais o vetor estacion´ario
aparece em cada linha da matriz de transi¸c˜ao, ou seja, podemos calcular o vetor de
distribui¸c˜ao estacion´ario apenas fazendo as potˆencias de P .

Essa ´e uma propriedade muito interessante de certos tipos de Cadeias de Markov
denominadas regulares. Essas cadeias possuem matriz de transi¸c˜ao que se caracterizam
por ter um ´unico vetor de probabilidade estacion´ario e, al´em disso, este independe do
vetor de distribui¸c˜ao inicial, porque como vimos podem ser calculados apenas utilizando
a matriz de transi¸c˜ao da cadeia. Formalmente deﬁnimos uma matriz de transi¸c˜ao como
regular da seguinte maneira.

Deﬁni¸c˜ao 1.6.1 (Cadeias de Markov Regulares). Seja P uma matriz de transi¸c˜ao de
uma cadeia de Markov. A matriz P ´e chamada regular se alguma potˆencia positiva de P
tem todas as suas entradas positivas.

Para maiores informa¸c˜oes sobre Cadeias de Markov regulares recomendamos a

leitura de Poole (2004).

1.6.3 N´ıvel econˆomico

O exemplo abaixo vem da sociologia. Segundo esta ´area do conhecimento o n´ıvel
econˆomico de uma pessoa ´e fortemente inﬂuenciado pela classe econˆomica dos seus pais.
Fa¸camos a classiﬁca¸c˜ao do n´ıvel econˆomico de um indiv´ıduo em trˆes categorias: rico (R),
classe m´edia (M), e pobre (P).

Supondo que cada homem tem um ﬁlho e que observando sucessivas gera¸c˜oes das
fam´ılias desses homens descobrimos que dos ﬁlhos de um homem rico 95% continuam
ricos e 5% se tornam classe m´edia. No caso de um indiv´ıduo de classe m´edia, 10% ﬁcam
ricos, 70% se mant´em na classe m´edia e 20% ﬁcam pobres. E, ﬁnalmente, no caso de um
homem pobre, 30% v˜ao para classe m´edia e 70% permanecem pobres. Ent˜ao a matriz de
transi¸c˜ao neste caso seria dada por:

R

M

P

P =






R
M
P

0

0, 95 0, 05
0, 10 0, 70 0, 20
0, 30 0, 70

0






Por´em na realidade nem todo homem, necessariamente, tem um ﬁlho. Vamos supor
que a probabilidade de que um homem venha a ter um ﬁlho seja de 90%. Podemos ent˜ao
formar uma nova cadeia de Markov com quatro estados, onde o estado delta representa o
estado de n˜ao ter ﬁlho.

19

R

M

P

∆

K =









R
M
P
∆

0, 855 0, 045
0, 63
0, 09
0, 27
0
0
0

0

0, 10
0, 18 0, 10
0, 63 0, 10

0

1









Note que o estado sem ﬁlhos ´e absorvente, ou seja, se um homem de uma gera¸c˜ao
para outra n˜ao tem ﬁlho, isso signiﬁca que n˜ao existe a possibilidade que chegando a
este estado ele saia do mesmo. Por isso a probabilidade de permanecer nesse estado ao
chegar nele ´e de 100%. S˜ao Cadeias de Markov que possuem essa caracter´ıstica que iremos
estudar no pr´oximo cap´ıtulo.

Cap´ıtulo 2

Cadeias de Markov Absorventes

De forma geral as Cadeias de Markov s˜ao estudadas a partir de caracter´ısticas
espec´ıﬁcas que elas possuem em seus estados ou em sua matriz de transi¸c˜ao. Como
se pode ver em Poole (2004, p.294) as Cadeias de Markov regulares possuem um vetor
de estado estacion´ario, pois sua matriz de transi¸c˜ao ´e regular. No caso das cadeias de
Markov Absorventes iremos nos ocupar em responder para um dado estado inicial si, n˜ao
absorvente, as seguintes quest˜oes:

• Em m´edia, quantas vezes o processo visitar´a cada um dos estados n˜ao absorventes?

• Qual o n´umero de etapas esperado antes da absor¸c˜ao?

• Qual ´e a probabilidade de que um estado absorvente seja alcan¸cado?

Para responder tais quest˜oes, iremos inicialmente deﬁnir formalmente as poss´ıveis
caracter´ısticas que um estado si ∈ E pode ter. As deﬁni¸c˜oes na pr´oxima se¸c˜ao s˜ao
baseadas naquelas encontradas no livro de Hillier e Lieberman (2013).

2.1 Classiﬁca¸c˜ao de Estados

Para todas as deﬁni¸c˜oes abaixo considere que si e sj ∈ E, onde E ´e o espa¸co de

estados de uma cadeia de Markov.

Deﬁni¸c˜ao 2.1.1. Dizemos que um estado sj ´e acess´ıvel a partir do estado si se p(n)
para algum n ≥ 1 e escrevemos si → sj.

ij > 0

Ou seja, o estado sj ser acess´ıvel a partir do estado si signiﬁca que ´e poss´ıvel ao

sistema entrar eventualmente no estado sj quando ele se encontra no estado si.

No exemplo do tempo na subse¸c˜ao 1.6.1 do cap´ıtulo anterior, temos que todos os
estados s˜ao acess´ıveis a partir de qualquer um dos outros, pois para todo si e sj, temos
pij > 0. No exemplo que envolve a Lealdade do Consumidor, para n ≥ 2, todos os estados

20

21

tamb´em s˜ao acess´ıveis a partir de todos os outros visto que para todo si e sj, temos que
p(2)
ij > 0. Entretanto, no exemplo do n´ıvel econˆomico com 4 estados, nenhum dos outros
estados, diferentes de ∆, s˜ao acess´ıveis a partir do estado Delta.

Deﬁni¸c˜ao 2.1.2. Se o estado sj for acess´ıvel a partir do estado si e o estado si for
acess´ıvel a partir do estado sj, ent˜ao dizemos que os estados si e sj se comunicam e
escrevemos si ↔ sj.

Observe que a rela¸c˜ao ↔ para estados que se comunicam, assim deﬁnida ´e uma

rela¸c˜ao de equivalˆencia, pois:

i ) Qualquer estado se comunica consigo mesmo; (Reﬂexiva)

ii ) Se o estado si se comunica com o estado sj, ent˜ao o estado sj se comunica com o

estado si;(Sim´etrica)

iii ) Se o estado si se comunica com o estado sj e o estado sj se comunica com o estado

sk, ent˜ao o estado si se comunica com o estado sk.(Transitiva)

O item 1 se justiﬁca pois p(0)

ii = P {X0 = i|X0 = i} = 1. O item 2 ´e veriﬁcado pela

pr´opria deﬁni¸c˜ao 2.1.2. O item 3 ´e demonstrado da seguinte maneira.

Demonstra¸c˜ao. Suponhamos que si → sj e sj → sk, isto signiﬁca que ∃n ≥ 1 e m ≥ 1,
tais que p(n)
jk > 0. Sabemos que pela equa¸c˜ao de Chapman-Kolmogorov que
existe um estado s, tal que:

ij > 0 e p(m)

p(n+m)
ik

=

M
(cid:88)

s=1

p(n)
is

· p(m)
sk

Mas,

Logo si ↔ sk.

M
(cid:88)

s=1

p(n)
is

· p(m)

sk ≥ p(n)

ij

· p(m)

jk > 0

(cid:4)

Por ser uma rela¸c˜ao de equivalˆencia os estados de uma cadeia de Markov podem
ser subdivididos em classes distintas, tais que aqueles estados que comunicam-se entre
si est˜ao na mesma classe. Uma classe pode ser formada por um ´unico estado. Se uma
cadeia de Markov posuir uma ´unica classe, isto ´e, todos os estados comunicarem-se, n˜ao
necessariamente em um ´unico passo, a cadeia de Markov ´e chamada irredut´ıvel ou
ergˆodica.

Um fato curioso de se notar ´e que por deﬁni¸c˜ao uma cadeia de Markov regular
´e irredut´ıvel, mas nem toda matriz irredut´ıvel ´e regular. Um exemplo cl´assico desta
ocorrˆencia ´e a cadeia cuja matriz de transi¸c˜ao ´e dada por:

22

1

0

1






1

2

2

1

0






P =

Observe que podemos acessar o estado 2 a partir do estado 1 e acessar o estado 1 a
partir do estado 2 portanto a matriz ´e irredut´ıvel. No entanto as entradas das potencias
de P nunca ser˜ao todas positivas. Se n for par a matriz ser´a igual a I2 e se n for ´ımpar a
matriz ser´a igual a P.

Deﬁni¸c˜ao 2.1.3. Um estado ´e dito transiente se, ap´os entrar nesse estado, existe a
possibilidade do processo jamais retornar a esse estado novamente.

Portanto o estado si ´e transiente se, e somente se, existir um estado sj(sj (cid:54)= si) que
seja acess´ıvel do estado si, mas n˜ao o contr´ario, isto ´e o estado si n˜ao ´e acess´ıvel a partir
do estado sj. Note que se um estado ´e transiente isto signiﬁca que ele ser´a visitado apenas
um n´umero ﬁnito de vezes, pois existe a possibilidade de que ele passe para o estado sj e
n˜ao retorne mais para o estado si.

´E o caso, por exemplo, dos compartimentos 1, 2, 3 e 4 do exemplo 1.3.1 do labirinto
do rato visto que ´e poss´ıvel que estes estados nunca mais sejam visitados pelo rato. Pois
ao adentrar no Para´ıso do Queijo ele n˜ao mais sair´a de l´a. Uma outra possibilidade para
um estado de uma cadeia de Markov ´e dado na pr´oxima deﬁni¸c˜ao.

Deﬁni¸c˜ao 2.1.4. Um estado ´e dito ser recorrente se, ap´os adentrar aquele estado, o
processo com certeza retornar a esse estado novamente. Portanto um estado ´e recorrente
se, e somente se, ele n˜ao for transiente.

J´a que um estado recorrente ser´a revisitado ap´os cada visita, ele retornar´a com
frequˆencia inﬁnita para esse estado caso o processo se mantenha eternamente. Os estados
no exemplo do clima e da lealdade do consumidor s˜ao recorrentes visto que eles sempre
ocorrer˜ao caso o processo seja inﬁnito.

Deﬁni¸c˜ao 2.1.5. Diz-se que um estado ´e absorvente caso, ap´os adentrar esse estado,
o processo jamais deixar´a esse estado novamente. Portanto o estado si ´e um estado
absorvente se, e somente se, pii = 1.

No exemplo do n´ıvel econˆomico como j´a t´ınhamos antecipado, o estado ∆(n˜ao ter
ﬁlhos) ´e um estado absorvente. Visto que ao adentrar neste estado o processo jamais o
deixar´a. Como podemos ver em Hillier e Lieberman (2013, p. 706), temos que:

23

A recorrˆencia ´e uma propriedade de classe, ou seja, todos os
estados em uma classe s˜ao recorrentes ou ent˜ao transientes.
Al´em disso, em uma cadeia de Markov de estados ﬁnitos,
nem todos os estados podem ser transientes. Assim, todos
os estados em uma cadeia de Markov de estados ﬁnitos irre-
dut´ıveis s˜ao recorrentes.

2.2 A Forma Canˆonica

Como j´a deﬁnimos o que s˜ao estados transientes e absorventes podemos deﬁnir o

que ´e uma cadeia de Markov Absorvente, vejamos:

Deﬁni¸c˜ao 2.2.1. Uma cadeia de Markov ´e chamada de absorvente se, e somente se,
ela contiver pelo menos um estado absorvente e se for poss´ıvel ir de qualquer estado n˜ao
absorvente para um estado absorvente em uma ou mais etapas.

Em outras palavras dizemos que uma cadeia de Markov ´e absorvente quando algum
dos seus estados ´e capaz de capturar o processo e n˜ao permitir que nenhum outro estado
seja acessado. Vale salientar que a exigˆencia de que os estados n˜ao absorventes acessem
os estados absorventes pode ocorrer em mais de uma etapa. Vejamos um exemplo para
esclarecer a deﬁni¸c˜ao acima.

Considere duas cadeias de Markov cujas matrizes de transi¸c˜ao s˜ao P1 e P2.

E1 E2 E3 E4

E1 E2 E3

P1 =









E1
E2
E3
E4

0
0, 3 0, 6 0, 1
0
1
0
0
0, 4 0, 4
0
0, 2
0, 3 0, 4
0
0, 3









P2 =









E1

E2

E3

1

0

0

0 0, 4 0, 6

0 0, 2 0, 8









A cadeia cuja matriz de transi¸c˜ao ´e P1 ´e absorvente, pois o estado E2 ´e absorvente
e ´e poss´ıvel atrav´es de E1 acessar E2. Observe ainda que E3 e E4 acessam E1 diretamente,
logo esses estados tamb´em acessam indiretamente E2. Podemos observar claramente que
isso ocorre com os c´alculos efetuados no apˆendice 1 se¸c˜ao 2.

No entanto, a cadeia cuja matriz de transi¸c˜ao ´e dada por P2 n˜ao ´e absorvente,
porque apesar do estado E1 ser absorvente n˜ao ´e poss´ıvel acess´a-lo nem a partir de E2
nem a partir de E3, ou seja estes estados ser˜ao recorrentes. Assim se o processo tiver
in´ıcio em algum desses estados nunca ocorrer´a a absor¸c˜ao.

Considere agora uma cadeia de Markov absorvente qualquer,

lembre-se que a
mesma ser´a composta de r estados absorventes e t estados transientes. Dessa forma

podemos reorganizar a matriz de transi¸c˜ao da cadeia de modo que os estados transien-
tes apare¸cam primeiro e depois os estados absorventes, fazendo isso teremos a seguinte
conﬁgura¸c˜ao.

24

T rans Absor

P =

T rans
Absor

(cid:34)

Q

0

(cid:35)

R
Ir

Note que Ir ´e uma matriz identidade de ordem r, a matriz 0 ´e uma matriz nula com
r linhas e t colunas, R ´e uma matriz n˜ao nula com t linhas e r colunas e Q ´e uma matriz
quadrada de ordem t. Os primeiros t estados ser˜ao transientes e os r estados restantes
ser˜ao absorventes.

´E importante perceber o papel de cada uma dessas matrizes para a dinˆamica
do processo. A matriz Q nos diz quais as probabilidades de transi¸c˜ao entre estados
transientes. A matriz R ´e respons´avel pelo acesso de estados transientes aos estados
absorventes. A matriz nula nos informa que ´e imposs´ıvel sair de um estado absorvente
para um estado transiente e a matriz identidade nos indica que ao chegar num estado
absorventes l´a iremos permanecer.

Agora vejamos o que ocorre com a probabilidade de transi¸c˜ao entre estados tran-
sientes a medida que `a cadeia passa para etapas seguintes. Sabemos que para isso basta
que elevemos a matriz P a potˆencia n, onde n representa a quantidade de etapas que
queremos avan¸car. Assim, temos que:

T rans Absor

P(n) =

(cid:34)

T rans
Absor

Qn
0

(cid:35)

∗
Ir

Lembre que Qn nos diz qual a probabilidade de se iniciar em um dos r estados
transientes e continuar em um desses estados transientes ap´os n etapas. Nosso primeiro
importante teorema da pr´oxima se¸c˜ao prova que se a cadeia inicia em um estado transiente
a probabilidade de permanecer em um estado transiente quando n tende ao inﬁnito ´e zero.
Assim todas as entradas de Qn se aproximam de zero quando n tende ao inﬁnito, o que
provaremos abaixo:

Teorema 2.2.1. Em uma cadeia de Markov absorvente, a probabilidade de que o processo
seja absorvido ´e igual a 1. (i.e. n → ∞ ⇒ Qn → 0)

Demonstra¸c˜ao. Por deﬁni¸c˜ao se a cadeia de Markov ´e absorvente ent˜ao ´e poss´ıvel a cada
estado transiente sj acessar um estado absorvente. Seja mj o n´umero m´ınimo de etapas
necess´arias para que se chegue a um estado absorvente partindo de sj. Seja pj a pro-
babilidade de que, partindo de sj, o processo n˜ao alcance um estado absorvente em mj
etapas, ou seja, pj ´e a probabilidade de que o processo permane¸ca num estado transiente

25

ap´os mj etapas. Note que pj ´e uma probabilidade logo pj < 1. Seja m o maior dos mj
e seja p o maior dos pj, isto ´e, m ´e a maior quantidade de etapas que s˜ao necess´arias
para que todos os estados acessem um estado absorvente e p ´e a maior probabilidade de
que um desses est´agios permane¸cam num estado transiente. Portanto a probabilidade de
n˜ao ser absorvido em m etapas ´e menor ou igual a p logo em 2m etapas ser´a menor ou
igual a p2, e assim sucessivamente. Como p < 1 esta probabilidade tende a 0. Portanto a
probabilidade de n˜ao ser absorvido em n etapas ´e monotonicamente decrescente, logo as
(cid:4)
probabilidades de todos os pj tamb´em tendem a 0, consequentemente lim
n→∞

Qn = 0.

J´a temos agora os elementos necess´arios para come¸car a responder as quest˜oes
propostas no in´ıcio do cap´ıtulo. Na pr´oxima se¸c˜ao iremos deﬁnir a matriz fundamental de
uma cadeia de Markov absorvente que ´e a chave para descobrir as respostas `as quest˜oes
feitas.

2.3 A matriz fundamental

Uma das quest˜oes que queremos responder ´e: Em m´edia, quantas vezes a cadeia
de Markov absorvente visitar´a cada um dos estados n˜ao absorventes? Para responder
a esta pergunta vamos deﬁnir o que ´e a matriz fundamental de uma cadeia de Markov
absorvente, vejamos:

Deﬁni¸c˜ao 2.3.1. Para uma cadeia de Markov absorvente chamamos de matriz funda-
mental F a matriz inversa de (It − Q).

O ´ındice t da matriz identidade corresponde a quantidade de estados transientes
do processo. As entradas dessa matriz F nos diz qual o n´umero esperado de vezes que a
cadeia estar´a num estado sj, dado que a cadeia partiu de um estado si. Para provar este
teorema iremos primeiro demonstrar o lema abaixo.

Lema 2.3.1. A matriz fundamental F existe e F = I +Q+Q2 +Q3 +· · · , quando n → ∞.

Demonstra¸c˜ao. Considere a igualdade:

(I − Q) · (I + Q + Q2 + Q3 + · · · + Qn−1) = I − Qn

Sabemos que pelo teorema 2.2.1 se n → ∞ ent˜ao Qn → 0 ent˜ao quando n → ∞ o segundo
membro da igualdade acima tende para a matriz identidade I. Logo se aplicarmos o
determinante a ambos os membros vemos que quando n → ∞ o determinante do primeiro
membro da igualdade tende a 1, ou seja,

|(I − Q) · (I + Q + Q2 + Q3 + · · · + Qn−1)| → 1

26

Ent˜ao para um n suﬁcientemente grande temos que o determinante de I − Qn ´e n˜ao-nulo.
Al´em disso, sabemos que o determinante do produto de duas matrizes ´e igual ao produto
dos determinantes da mesma, logo para n suﬁcientemente grande temos:

|(I − Q)| · |(I + Q + Q2 + Q3 + · · · + Qn−1)| (cid:54)= 0

Portanto o determinante da matriz (I − Q) ´e diferente de zero, consequentemente ela
possui uma matriz inversa desde que n seja suﬁcientemente grande. Implicando que a
matriz F = (I − Q)−1 existe para um n suﬁcientemente grande.

Como F = (I − Q)−1 existe, podemos multiplicar ambos os lados da igualdade por

F, fa¸camos isso:

F · (I − Q) · (I + Q + Q2 + Q3 + · · · + Qn−1) = F · (I − Qn)

Mas F · (I − Q) = I, portanto no primeiro membro da igualdade temos apenas
(I + Q + Q2 + Q3 + · · · + Qn−1). Quando n → ∞ temos Qn → 0, assim o segundo membro
da igualdade ﬁca F · I = F e portanto F = I + Q + Q2 + Q3 + · · · , quando n → ∞. (cid:4)

Teorema 2.3.1. A fij entrada da matriz F ´e igual ao n´umero de vezes que a cadeia
visitar´a o estado sj, dado que come¸ca no estado si.

Demonstra¸c˜ao. Sejam si e sj dois estados transientes de tal modo que os valores i e j
sejam ﬁxos. Seja X (k) uma vari´avel aleat´oria que ´e igual a 1 se `a cadeia est´a no estado sj
ap´os k etapas e igual a zero nos outros casos. Temos que:

P (X (k) = 1) = q(k)
ij

e P (X (k) = 0) = 1 − q(k)
ij

Onde q(k)
ij ´e a ij-´esima entrada de Qk. Para manter a coerˆencia nessas equa¸c˜oes basta deﬁnir
que para k = 0 temos Q0 = I. Assim sendo X (k) ´e uma vari´avel aleat´oria composta por
zeros e uns de modo que o valor esperado E(X (k)) = q(k)
ij .

O n´umero esperado de vezes que a cadeia visitar´a o estado sj em n etapas, dado

que iniciou no estado si ´e:

E(X (0) + X (1) + · · · + X (n)) = q(0)

ij + q(1)

ij + · · · + q(n)

ij

Fazendo n → ∞ temos que

E(X (0) + X (1) + · · · ) = q(0)

ij + q(1)

ij + · · · = fij

.

(cid:4)

Vamos considerar agora a segunda quest˜ao proposta no in´ıcio do cap´ıtulo: Dado

27

que a cadeia iniciou no estado si quantas etapas s˜ao necess´arias para que entre em um
estado absorvente? A resposta ser´a dada no teorema seguinte.

Teorema 2.3.2. Seja ti o n´umero de etapas antes que a cadeia seja absorvida, dado que a
cadeia iniciou no estado si e seja t um vetor coluna cujas entradas sejam ti ent˜ao t = F.c
onde c ´e um vetor coluna com todas as entradas iguais a 1.

Demonstra¸c˜ao. Se adicionarmos todas as entradas da i-´esima linha de F, n´os teremos o
n´umero esperado de vezes que o processo ir´a visitar qualquer um dos estados transientes,
visto que iniciou em si, isto ´e, o n´umero de vezes que o processo visitar´a aquele estado
antes da absor¸c˜ao. Assim ti ´e a soma das entradas da i-´esima linha de F. Se escrevermos
(cid:4)
esta aﬁrma¸c˜ao na forma matricial segue o teorema, ou seja, t = F.c.

Nosso ´ultimo teorema responde a ´ultima quest˜ao que ﬁzemos no in´ıcio do cap´ıtulo,
ou seja, nos diz qual a probabilidade de uma cadeia de Markov absorvente ser absorvida
por um dos seus estados absorventes sj dado que ela iniciou em um estado transiente si.
Segue abaixo o enunciado e demonstra¸c˜ao deste teorema.

Teorema 2.3.3. Seja bij a probabilidade de que uma cadeia de Markov absorvente seja
absorvida por um estado sj dado que ela iniciou num estado transiente si. Seja B a
matriz com entradas bij, ent˜ao B tem ordem t por r e B = F · R, onde t ´e a quantidade
de estados transientes, r ´e a quantidade de estados absorventes, F ´e a matriz fundamental
e R ´e matriz de liga¸c˜ao entre estados transientes e absorventes na forma canˆonica.

Demonstra¸c˜ao. Note que come¸cando o processo num estado transiente si ele pode ser
absorvido por sj em uma ou mais etapas. A probabilidade de ser absorvido em um ´unico
passo ´e dado rij. Se isso n˜ao acontece, o processo pode se mover para um outro estado
absorvente (e neste caso ´e imposs´ıvel a ele acessar o estado sj) ou se mover para um estado
transiente sk. Neste ´ultimo caso h´a uma probabilidade bkj de ser absorvido do estado sk
para o estado sj. Portanto temos que:

bij = rij +

(cid:88)

k

qik · bkj

A equa¸c˜ao acima pode ser escrita na forma matricial da seguinte maneira:

Da´ı,

B = R + QB

B − QB = R ⇒

B · (I − Q) = R ⇒

B = (I − Q)−1 · R ⇒

B = F · R

28

(cid:4)

Estas deﬁni¸c˜oes e teoremas nos fornecem as ferramentas necess´arias para traba-
lhar com cadeias de Markov absorventes, na pr´oxima se¸c˜ao daremos alguns exemplos do
funcionamento deste tipo de cadeia de Markov.

2.4 Exemplos

Usaremos como exemplos de cadeias de Markov absorventes duas situa¸c˜oes que nos
parecem esclarecer muito bem as deﬁni¸c˜oes e teoremas vistos na se¸c˜ao anterior, s˜ao eles:
A ru´ına do jogador e a gest˜ao m´edica em caso de pedras na ves´ıcula.

2.4.1 A ru´ına do jogador

Considere a seguinte situa¸c˜ao que descreve um jogo de apostas entre duas pessoas:

Maria tem R$ 3,00 e Jo˜ao tem R$ 4,00 eles ir˜ao jogar uma moeda honesta
e se der cara Maria perde R$ 1,00 para Jo˜ao e se der coroa Jo˜ao perde R$
1,00 para Maria. O jogo termina quando um deles n˜ao tiver mais dinheiro
para apostar.

Fa¸camos um diagrama para entender melhor como funciona o jogo entre estas duas
pessoas. Observe que nesta situa¸c˜ao o jogador pode ter de zero a sete reais e que cada
uma dessas possibilidades ir´a representar um poss´ıvel estado em que o jogador se encontra.
Al´em disso, a probabilidade de transi¸c˜ao entre estados ser´a de 50%, visto que a aposta
ser´a deﬁnida atrav´es do lan¸camento de uma moeda honesta. Assim nosso diagrama ter´a
8 n´os e vejamos como ﬁcar˜ao as liga¸c˜oes entre eles na ﬁgura abaixo:

1

R$
R$
0
0

1
2

1
2

R$
R$
2
2

1
2

1
2

R$
R$
3
3

1
2

1
2

R$
R$
4
4

1
2

1
2

R$
R$
5
5

1
2

1
2

R$
R$
1
1

1
2

1
2

R$
R$
6
6

R$
R$
7
7

1

Figura 2.1: Diagrama de estados - Ru´ına do Jogador

Olhando o diagrama ﬁca claro que os estados 0 e 7 s˜ao absorventes, visto que o jogo
termina quando um dos jogadores perde todo o seu dinheiro e obviamente se ele perdeu

todo o seu dinheiro a outra o ganhou e chegar´a ao estado 7 e da´ı n˜ao sair´a. Note ainda
que os estados 1, 2, 3, 4, 5, 6 s˜ao transientes, pois em algum momento nunca voltaremos
a eles. Tamb´em queremos deixar em evidˆencia, no diagrama, a ideia de classe a partir
das cores dos n´os. Fa¸camos agora a matriz de transi¸c˜ao para esta cadeia.

29

0

1

2

3

4

5

6

7



















1
0, 5
0
0
0
0
0
0

0
1
2
3
4
5
6
7

0
0
0, 5
0
0
0
0
0

0
0, 5
0
0, 5
0
0
0
0

0
0
0, 5
0
0, 5
0
0
0

0
0
0
0, 5
0
0, 5
0
0

0
0
0
0
0, 5
0
0, 5
0

0
0
0
0
0
0, 5
0
0



















0
0
0
0
0
0
0, 5
1

P =

Podemos veriﬁcar com a matriz de transi¸c˜ao P que os estados transientes adjacen-
tes se comunicam e que ´e poss´ıvel acessar os estados absorventes atrav´es dos estados 1
e 6. Logo a cadeia em quest˜ao ´e absorvente, pois possui estados absorventes e esses s˜ao
acess´ıveis a todos os estados transientes. Escrevamos agora P em sua forma canˆonica, isto
´e, vamos reorganizar a matriz de modo que os estados transientes apare¸cam a esquerda e
em cima.

1

2

3

4

5

6

0

7



















0
0, 5
0
0
0
0

0
0

1
2
3
4
5
6
0
7

0, 5
0
0, 5
0
0
0

0
0

0
0, 5
0
0, 5
0
0

0
0

0
0
0, 5
0
0, 5
0

0
0

0
0
0
0, 5
0
0, 5

0
0

0
0
0
0
0, 5
0

0
0

0, 5
0
0
0
0
0

1
0



















0
0
0
0
0
0, 5

0
1

P =

Com a forma canˆonica, podemos calcular a matriz fundamental F = (I6 − Q)−1,
onde I6 ´e a matriz identidade de ordem 6 e Q ´e a matriz quadrada cujas entradas s˜ao as
probabilidades de que um estado transiente permane¸ca em um estado transiente, ou seja,
a matriz quadrada de ordem 6 posicionada no canto esquerdo superior.

´E importante perceber que neste caso j´a n˜ao temos uma tarefa simples ao tentar
determinar a matriz F . Porque precisamos determinar a matriz inversa de uma matriz
quadrada de ordem 6. Contudo, com o uso do Geogebra isto pode ser feito sem maiores
diﬁculdades, ensinamos todo o processo de forma detalhada no v´ıdeo dedicado a esta

se¸c˜ao no site. Fazendo isso achamos ent˜ao que a matriz fundamental F tem as seguintes
entradas.

30

1

2

3

4

5

6

F =














1
2
3
4
5
6

1, 714 1, 429 1, 143 0, 857 0, 571 0, 286
1, 429 2, 857 2, 286 1, 714 1, 143 0, 571
1, 143 2, 286 3, 429 2, 571 1, 714 0, 857
0, 857 1, 714 2, 571 3, 429 2, 286 1, 143
0, 571 1, 143 1, 714 2, 286 2, 857 1, 429
0, 286 0, 571 0, 857 1, 143 1, 429 1, 714














Como vimos as entradas fij da matriz F representa a quantidade de vezes, em
m´edia, que iniciando no estado si a cadeia ir´a passar pelo estado sj antes de ser absorvido.
Na matriz F acima podemos ver, por exemplo, que se um jogador iniciar a partida com
R$ 2,00, ele deve ﬁcar com R$ 3,00 em 2,286 etapas antes de perder todo seu dinheiro ou
ganhar todo o dinheiro de seu advers´ario. Ainda podemos atrav´es da matriz fundamental
F saber quanto o jogo duraria a partir da quantia inicial de um jogador, para isto basta
somar as entradas em cada linha da matriz que obteremos esta quantidade, assim temos:

t =



























6
10
12
12
10
6

1
2
3
4
5
6

A matriz t nos informa que, em m´edia, se uma pessoa iniciar o jogo com R$ 5,00
deve jogar 10 rodadas at´e que o jogo se encerre. Ou ainda, no caso do jogo entre Jo˜ao e
Maria a partida deve ser encerrada ap´os 12 jogadas.

A ´ultima informa¸c˜ao que podemos obter sobre esta situa¸c˜ao, utilizando os teoremas
da se¸c˜ao anterior, ´e a probabilidade de perder ou ganhar o jogo quando iniciamos a mesma
com uma determinada quantia. Como vimos, podemos obter essa informa¸c˜ao fazendo o
produto entre a matriz fundamental F e a matriz R que ´e a matriz que na forma canˆonica
ocupa o canto superior direito, fazendo isso obtemos a matriz B igual a:

31

0

7














1
2
3
4
5
6

0, 857 0, 143
0, 714 0, 286
0, 571 0, 429
0, 429 0, 571
0, 286 0, 714
0, 143 0.857














B =

Observe que b27 vale 28,6 %, ou seja, essa ´e a probabilidade de se iniciar uma partida
com a quantia de R$ 2,00 e ser o vencedor da partida. Tamb´em podemos observar que
uma pessoa que inicie o jogo com R$ 6,00 tem uma probabilidade de apenas 14,3% de
sair perdedor.

Algumas observa¸c˜oes precisam ser feitas sobre os resultados encontrados. A pri-
meira ´e sobre a simetria desses resultados, isso s´o acontece devido a probabilidade de
transi¸c˜ao em todos os casos serem iguais a 1
2. Ademais o tamanho da matriz de transi¸c˜ao
da cadeia cresce muito a medida que os valores das apostas aumentam. Vamos agora a
outro exemplo interessante que pode ser modelado por uma cadeia de Markov absorvente.

2.4.2 Pedra na ves´ıcula

Este exemplo encontra-se em Lay (1999) e aborda um dilema de m´edicos que
tratam de pacientes com pedras na ves´ıcula. Os m´edicos que diagnosticam precocemente
esta doen¸ca vivem o dilema entre retirar imediatamente, atrav´es de uma cirurgia, as pedras
para prevenir poss´ıveis complica¸c˜oes que ameacem a vida do paciente ou de postergar esta
cirurgia at´e que as complica¸c˜oes ocorram para da´ı realiz´a-la. Na ausˆencia de um estudo
cl´ınico mais rigoroso, um m´edico poderia utilizar as cadeias de Markov para auxiliar a
avalia¸c˜ao de riscos e benef´ıcios para o paciente, se o cen´ario apresentado fosse como o
descrito no texto abaixo:

Suponha que o paciente continuar´a assintom´atico (estado A) em 95% dos
casos, durante um per´ıodo de 4 meses. Pode ocorrer grandes complica¸c˜oes
(estado C) no estado de sa´ude do paciente como uma colecistite, o que leva
a uma interven¸c˜ao cir´urgica em 4% dos casos, ou a morte (estado M), em
pacientes de idades espec´ıﬁcas, em 1% dos casos. Se a doen¸ca progride e se
torna sintom´atica o paciente tem um risco de morte, causado por complica¸c˜oes
cir´urgicas em 0,5% dos casos. Se a cirurgia ´e bem sucedida, o paciente entra
no estado recupera¸c˜ao(estado R). Ap´os 1 ano, noventa por cento dos pacientes
que se submeteram a cirurgia ﬁcam s˜aos(estado S), 9% permanecem no estado
de recupera¸c˜ao e 1% morrem por causas naturais. Quando o paciente ﬁca s˜ao
ele permanece nesse estado em 99% dos casos.

Observe que o estudo cl´ınico pode ser modelado por uma cadeia de Markov absor-
vente, pois temos um estado absorvente (estado M) e este ´e acess´ıvel por todos os outros
estados. Observe na ﬁgura 2.2 como ﬁca o diagrama de estados desta cadeia e a partir
dele sua correspondente matriz de transi¸c˜ao.

32

0.95

AA

SS

0.99

0
.
0

1

0.01

0.04

1

MM

0.90

0.005

0
.
0

1

CC

0.995

RR

0.09

Figura 2.2: Diagrama de estados - Pedra na Ves´ıcula

A

C

R

S M

P =











A
C
R
S
M

0, 95 0, 04

0
0
0

0

0
0
0

0

0
0, 995
0, 09
0

0

0
0
0, 90
0, 99

0











0, 01
0, 005
0, 01
0, 01

1

Observe que neste caso a matriz de transi¸c˜ao P acima j´a est´a em sua forma
canˆonica, portanto, podemos calcular a matriz fundamental F = (I4 − Q)−1, onde Q
´e a matriz quadrada de ordem 4 que cont´em as probabilidades de transi¸c˜ao entre os esta-
dos transientes e I4 ´e a matriz identidade de ordem 4. Calculando F chegamos a seguinte
matriz:

A C

R

S

F =









A
C
R
S

20 0, 8 0, 87 78, 73
1, 09 98, 41
0
1, 10 98, 90
0
100
0

1
0
0

0









Como sabemos as entradas fij da matriz fundamental nos informam qual o n´umero
de vezes que o processo ir´a visitar o estado sj visto que iniciou o processo no estado si.
Assim, neste caso, a interpreta¸c˜ao que podemos dar a matriz fundamental ´e a seguinte:
cada uma das entradas nos indica quantas vezes o paciente visitar´a algum dos estados

33

que o mant´em vivo (assintom´atico, cirurgia, recupera¸c˜ao ou s˜ao) antes de vir a ´obito.
Por exemplo, se um paciente est´a inicialmente assintom´atico ele continuar´a neste estado,
em m´edia, por 20 per´ıodos, antes de morrer. Como o per´ıodo ´e de 4 meses, isso signiﬁca
que um paciente assintom´atico pode continuar neste estado durante aproximadamente 6,7
anos.

Somando as linhas da matriz fundamental F chegamos aos seguintes valores para a
matriz t, que nos diz quantos per´ıodos o paciente permanecer´a vivo, se iniciar o processo
em qualquer um dos estados transientes.

t =









100, 4
100, 5
100
100









A
C
R
S

ou t =

















33, 4
33, 5
33, 3
33, 3

A
C
R
S

em anos.

Por ﬁm podemos calcular qual a probabilidade de que um paciente venha `a ´obito
dado que ele inicia o processo em algum estado transiente. Para isso calculamos o valor
da matriz B = Q · R, vejamos:









B =

20 0, 8 0, 87 78, 73
1, 09 98, 41
0
1, 10 98, 90
0
100
0

1
0
0

0









·

















0, 01
0.005
0.01
0.01

















1
1
1
1

=

Note que a probabilidade de que um paciente v´a morrer ´e de 100% para qualquer
um dos estados iniciais que ele possa ter. O que infelizmente, ´e lament´avel, mas comple-
tamente compat´ıvel com a realidade de qualquer ser humano, tendo ele pedras na ves´ıcula
ou n˜ao.

Aqui encerramos nossas considera¸c˜oes te´oricas sobre as cadeias de Markov ab-
sorventes. No pr´oximo cap´ıtulo, iremos fazer algumas observa¸c˜oes de como devem ser
aplicadas as atividades propostas no apˆendice e no site https://sites.google.com/view/
cadeiasdemarkovabsorventes/.

Cap´ıtulo 3

Materiais Pedag´ogicos

Neste cap´ıtulo iremos comentar e esclarecer algumas quest˜oes propostas nas ativi-
dades escritas e virtuais. Como j´a dito na introdu¸c˜ao, achamos que o ideal seja aplicar
estas atividades no 2o ou 3o ano do ensino m´edio, visto que desta forma os estudantes j´a
estudaram o conte´udo de matrizes e de probabilidade condicional.

O principal objetivo destas atividades ´e mostrar como funcionam as cadeias de
Markov Absorventes e em quais situa¸c˜oes do cotidiano elas podem ser usadas. ´E uma
tentativa de responder aos alunos a pergunta que sempre fazem nas aulas de matem´atica:
Pra que serve isso?

´E um conte´udo que n˜ao faz parte da grade curricular do ensino m´edio. O professor
que desejar aplicar o material, deve avaliar se o mesmo disp˜oe de tempo h´abil em suas
aulas para fazˆe-lo. Acreditamos que uma abordagem tradicional com aulas expositivas
seja suﬁciente para dar conta de um n´ıvel de aprendizagem satisfat´orio.

Dessa forma, pode-se usar uma aula para as no¸c˜oes b´asicas sobre as cadeias de
Markov e outra com os conceitos relativos as cadeias Absorventes. A partir da´ı pode-se
pedir que os estudantes visitem o site e fa¸cam as listas de exerc´ıcios.

´E importante destacar que este ´e um patamar m´ınimo de planejamento. Esta
ideia inicial pode ser expandida, at´e mesmo para um projeto interdisciplinar. Seja com a
´area de ciˆencias humanas, explorando exerc´ıcios como o do n´ıvel econˆomico, do n´ıvel de
escolaridade ou da produ¸c˜ao de uma safra de alimentos. Como podemos tamb´em utilizar
os exerc´ıcios sobre gen´etica, sa´ude e trˆansito para trabalhar com os professores de ciˆencias
da natureza.

Enﬁm, achamos que a dosagem, `a ˆenfase e a metodologia que ser´a usada para
trabalhar o assunto depende da inten¸c˜ao e do planejamento que o docente far´a para tratar
do tema. A seguir faremos alguns coment´arios que avaliamos pertinentes em rela¸c˜ao aos
materiais pedag´ogicos produzidos.

34

35

3.1 Listas de Exerc´ıcios

Produzimos trˆes listas de exerc´ıcios que seguem a mesma estrutura desta dis-
serta¸c˜ao. Na primeira exploramos quest˜oes relacionadas a conceitos b´asicos das cadeias
de Markov. Nessa lista, as duas primeiras quest˜oes exploram a constru¸c˜ao de diagrama
de estados e a deﬁni¸c˜ao de matriz de transi¸c˜ao de uma cadeia de Markov.

Os alunos devem perceber que nem toda matriz formada por decimais ou fra¸c˜oes ´e
uma matriz de transi¸c˜ao. ´E necess´ario enfatizar que as linhas de uma matriz de transi¸c˜ao
devem ser iguais a 1. Ademais o aluno dever´a ter a habilidade de intercambiar as re-
presenta¸c˜oes pict´orica(diagramas) e alg´ebrica(matrizes) para descrever uma cadeia de
Markov.

As quest˜oes seguintes at´e a s´etima est˜ao relacionadas ao reconhecimento do sig-
niﬁcado de cada componente de uma matriz de transi¸c˜ao e ao que ocorre com o vetor
de probabilidade de uma cadeia ap´os cada etapa do processo. Nas quest˜oes 3 e 4, por
exemplo, o aluno ter´a de perceber o que signiﬁca cada entrada da matriz de transi¸c˜ao,
em sua forma decimal ou de fra¸c˜ao.

Al´em disso, dever´a determinar a distribui¸c˜ao de probabilidades para uma etapa
dado que o processo iniciou em determinado estado. Um fato a ser destacado, novamente,
´e que se o processo tem in´ıcio em um determinado estado temos que o vetor de distribui¸c˜ao
inicial ser´a igual a 1 no estado em que o processo inicia e igual a zero nos demais.

Ademais o aluno dever´a ser capaz de efetuar a multiplica¸c˜ao entre o vetor de
probabilidade inicial e a matriz de transi¸c˜ao para determinar a pr´oxima distribui¸c˜ao de
probabilidade do processo, ou ainda, que isso pode ser feito atrav´es do produto entre uma
potˆencia da matriz de transi¸c˜ao e o vetor de probabilidade inicial utilizando o teorema
1.5.1.

Nas quest˜oes de 8 a 10 temos situa¸c˜oes problemas que podem ser modeladas por
uma cadeia de Markov. Os alunos dever˜ao ser capazes de extrair do texto o diagrama de
estados, a matriz de transi¸c˜ao e o vetor de probabilidade inicial e depois fazer algum tipo de
multiplica¸c˜ao para determinar o que se pede no problema. Apesar de serem basicamente
as mesmas habilidades requeridas nas quest˜oes anteriores, a leitura e interpreta¸c˜ao de
texto ser˜ao exigidas nestes casos, o que as elevam a um n´ıvel maior de diﬁculdade.

Vale lembrar que esta ´e a ´unica das trˆes listas que recomendamos que seja feita sem
nenhum aux´ılio computacional(Geogebra, calculadora...), pois de fato n˜ao ´e necess´ario o
uso do mesmo. Gostar´ıamos de enfatizar que apesar da simplicidade destas quest˜oes ´e
essencial que sejam feitas pelos alunos.

A segunda lista trata do comportamento a longo prazo do vetor de probabilidade
em cadeias de Markov que sejam regulares. O uso de um recurso computacional, como o
Geogebra, nos habilita a tratar as quest˜oes propostas sem maiores diﬁculdades.

A primeira quest˜ao apenas serve para que o aluno aplique a deﬁni¸c˜ao de matriz

36

regular, ou seja, ele dever´a ser capaz de avaliar se a matriz analisada ou alguma de suas
potˆencias tem todas as entradas positivas.

Na segunda quest˜ao o uso do Geogebra ´e indispens´avel visto que o aluno ter´a que
elevar as matrizes dadas a potˆencias cujo expoentes tem um valor muito grande para ser
feito a m˜ao.

Recomendamos o uso da janela planilhas no Geogebra, caso o computador seja
a ferramenta dispon´ıvel. Ou, o que nos parece ser mais vi´avel, principalmente no caso
das escolas p´ublicas estaduais, o uso do Geogebra na vers˜ao Android, na medida em que
uma grande quantidade dos alunos tem acesso ao dispositivo. Em ambos os casos temos
v´ıdeo-aulas de como utilizar o Geogebra para efetuar estes c´alculos na p´agina Cadeia de
Markov dispon´ıvel no site.

A terceira quest˜ao mais uma vez exige que o estudante seja capaz de escrever o
diagrama de estados para da´ı determinar a matriz de transi¸c˜ao e, nesta quest˜ao especiﬁ-
camente, ter´a apenas que elevar a matriz de transi¸c˜ao encontrada a um n suﬁcientemente
grande para que a distribui¸c˜ao estacion´aria apare¸ca.

As quest˜oes 4 e 5, apesar de matematicamente n˜ao acrescentarem muito pois con-
tinuam sendo resolvidas como as anteriores, mostra ao aluno como a ideia estacion´aria
tem sua relevˆancia no mundo f´ısico e social. Na quest˜ao 4 temos uma situa¸c˜ao onde a
gen´etica determina como uma popula¸c˜ao a longo prazo ser´a distribu´ıda se levarmos em
considera¸c˜ao apenas esse aspecto.

Na quest˜ao 5 temos uma matriz de transi¸c˜ao que nos mostra as tendˆencias de
qual o n´ıvel de instru¸c˜ao que a gera¸c˜ao seguinte ter´a levando em considera¸c˜ao o n´ıvel
de instru¸c˜ao da gera¸c˜ao atual. Podemos propor uma investiga¸c˜ao do que ocorre com
o vetor de probabilidade estacion´ario quando existem mudan¸cas na matriz de transi¸c˜ao
desta situa¸c˜ao. Ainda ´e poss´ıvel discutir com os alunos o impacto de pol´ıticas p´ublicas
educacionais para gera¸c˜oes futuras com base nas informa¸c˜oes encontradas e isto pode
ser feito de forma interdisciplinar com a ajuda de professores de hist´oria, sociologia e
geograﬁa.

A quest˜ao 6 ´e uma analogia da situa¸c˜ao do labirinto do rato proposta na apre-
senta¸c˜ao de slides. Pois nestas situa¸c˜oes as probabilidades de transi¸c˜ao entre os estados
n˜ao s˜ao dadas no texto da quest˜ao, ´e necess´ario que o aluno seja capaz de descobri-las
a partir da ﬁgura dada. Outro fato interessante nesta quest˜ao ´e que pela primeira vez
o aluno ter´a que quantiﬁcar a distribui¸c˜ao de probabilidade encontrada para determinar
quantos robˆos ﬁcar˜ao em cada posi¸c˜ao.

Para ﬁnalizar os coment´arios sobre a lista 2 ´e importante que seja destacado um fato
essencial sobre as cadeias de Markov com matriz de transi¸c˜ao regular. Este tipo de cadeia
nos mostra que o estado em que algo se encontra inicialmente(vetor de probabilidade
inicial) ´e irrelevante a longo prazo. O que verdadeiramente importa s˜ao as escolhas (matriz
de transi¸c˜ao) que iremos fazer ao longo do processo.

37

A terceira lista ´e dedicada a quest˜oes relacionadas `a cadeias de Markov absorventes.
Esta lista deve ser precedida da resolu¸c˜ao das anteriores, pois ´e necess´ario que os alunos j´a
tenham adquirido certas habilidades que s˜ao indispens´aveis para a resolu¸c˜ao dessa terceira
lista.

Uma dessas habilidades ´e saber escrever o diagrama de estados a partir de um
texto que descreva uma situa¸c˜ao problema que possa ser modelada por uma cadeia de
Markov. Outra habilidade necess´aria ´e a de determinar `a matriz de transi¸c˜ao associada a
um diagrama de estados. Ainda ´e essencial que nesta fase os discentes j´a consigam usar
sem maiores diﬁculdades o Geogebra para manipular matrizes.

Na primeira quest˜ao o aluno dever´a ser capaz de identiﬁcar os estados absorventes
de uma matriz de transi¸c˜ao. ´E muito importante que ele compreenda que n˜ao basta que
a probabilidade de transi¸c˜ao seja de 100%, mas sim que a probabilidade de permanecer
naquele estado seja de 100%. Al´em disso, na quest˜ao dois eles devem identiﬁcar quais das
matrizes da quest˜ao 1 representam uma matriz de transi¸c˜ao de uma cadeia de Markov
absorvente, ou seja, devem veriﬁcar se al´em de possuir estados absorventes, se estes estados
s˜ao acess´ıveis a todos os outros n˜ao absorventes.

A forma canˆonica e a matriz fundamental s˜ao exploradas na terceira quest˜ao. A
manipula¸c˜ao das matrizes neste caso deve ser feita com muito cuidado pois ao deslocar
linhas e colunas h´a o risco de que se altere a matriz de transi¸c˜ao, o que altera com-
pletamente as informa¸c˜oes. Na quest˜ao 4 a ideia ´e que os alunos consigam interpretar
corretamente a matriz de transi¸c˜ao F de uma cadeia de Markov absorvente, o problema
da ru´ına do jogador ´e um bom exemplo de como isto acontece, por isso retornamos a ele
nesta quest˜ao.

As quest˜oes 5 e 6 s˜ao situa¸c˜oes problema na ´area de educa¸c˜ao e sa´ude onde s˜ao
dadas a matriz de transi¸c˜ao em ambos os casos. Os itens propostos em cada quest˜ao s˜ao
todos eles facilmente respondidos contanto que os estudantes saibam interpretar correta-
mente a matriz fundamental F em cada situa¸c˜ao.

Nas quest˜oes 7 e 8 `as matrizes de transi¸c˜ao associadas a cada problema n˜ao s˜ao
dadas e o aluno dever´a constru´ı-las a partir da leitura e interpreta¸c˜ao do texto. Reco-
mendamos que o diagrama de estados preceda a escrita da matriz de transi¸c˜ao porque
geralmente ´e mais dinˆamico o processo de transformar a informa¸c˜ao textual em diagrama
para a partir da´ı construir a matriz de transi¸c˜ao, como feito nas listas anteriores.

A quest˜ao 9 ´e um problema sobre gen´etica e possui alguns aspectos in´editos no que
diz respeito a sua resolu¸c˜ao. O primeiro deles ´e que os estados do processo s˜ao formados a
partir da combina¸c˜ao dos poss´ıveis estados dos indiv´ıduos estas combina¸c˜oes s˜ao indicadas
pela tabela 5.2.

Situa¸c˜oes semelhantes a essa, s˜ao muito bem exploradas no livro do Hillier e Li-
eberman (2013), em problemas onde m´aquinas s˜ao usadas para fazer algum produto ou
servi¸co. Os estados de transi¸c˜ao neste caso tamb´em s˜ao obtidos a partir da combina¸c˜ao

38

entre estados individuais(funcionando, em manuten¸c˜ao) das m´aquinas que realizam o
processo.

Outro aspecto in´edito da solu¸c˜ao da quest˜ao 9 ´e que as probabilidades de transi¸c˜ao
entre estados apesar de serem dadas no item a, ´e pedido que o aluno veriﬁque se as mesmas
est˜ao corretas. Portanto ele dever´a calcular cada uma das probabilidades de transi¸c˜ao e
para isso ele precisar´a obedecer as Leis de Mendell, que s˜ao:

1. Cada caracter´ıstica ´e determinada por um par de fatores herdados um de cada

progenitor.

2. Os fatores para duas ou mais caracter´ısticas distribuem-se de maneira independente

para os descendentes e combinam-se ao acaso.

3. Cada fator puro para cada caracter´ıstica ´e transmitida `a gera¸c˜ao seguinte de forma

independente uma da outra seguindo as duas leis anteriores.

Aplicando estas leis temos que a matriz do item (a) ´e de fato a matriz de transi¸c˜ao
para o problema. A solu¸c˜ao dos outros itens seguem o mesmo padr˜ao que os das quest˜oes
anteriores.

Por ﬁm a quest˜ao 10 tamb´em n˜ao nos indica diretamente quais as probabilidades
de transi¸c˜ao entre estados. Elas tamb´em precisam ser calculadas. Neste caso existem duas
condi¸c˜oes que precisam ser destacadas. Primeiro os tiros acontecem de forma simultˆanea
a cada etapa e segundo ´e que cada um sempre atira no seu mais forte oponente vivo.
Observe ainda que o conjunto dos estados poss´ıveis ´e composto por E = {ABC, AC,
BC, A, B, C, Nenhum}, o estado AB nunca pode ocorrer por causa da segunda condi¸c˜ao.
Sendo assim a matriz de transi¸c˜ao para os carros de combate que sobrevivem a cada etapa
´e dada por:

ABC AC

BC

A

B

C

N

P =

ABC

AC

BC

A

B

C

N






















5
18

0

0

0

0

0

0

5
18

5
12

0

0

0

0

0

4
18

0

10
18

0

0

0

0

0

5
12

0

1

0

0

0

0

0

5
18

0

1

0

0

4
18

1
12

2
18

0

0

1

0






















0

1
12

1
18

0

0

0

1

´E muito prov´avel que os alunos tenham diﬁculdade em construir esta matriz. Por
isso recomendamos que a mesma seja feita sob orienta¸c˜ao do professor seguindo os passos

39

que constam no apˆendice 3. Os demais itens da quest˜ao podem ser facilmente respondidos
atrav´es do c´alculo da matriz fundamental F e da matriz B.

Finalizamos destacando a tentativa de colocar em todas as listas de exerc´ıcios um
grau de diﬁculdade crescente nas quest˜oes. Existem sempre aquelas que avaliam apenas
entendimento de teoremas e deﬁni¸c˜oes e outras que buscam aplicar em alguma situa¸c˜ao
problema estes conhecimentos. Ademais as listas ora propostas, podem ser complementa-
das ou ajustadas conforme o n´ıvel da turma ou o desejo do professor, visto que podemos
disponibilizar os arquivos .tex das listas pelo site.

3.2 O Beamer

O Beamer ´e uma classe de documentos LaTeX para criar slides para apresenta¸c˜oes.
´E uma ferramenta muito ´util principalmente quando as notas de aula que fazemos forem
criados no LaTeX, a produ¸c˜ao dos slides se torna basicamente um copiar e colar com
muito estilo.

Nas apresenta¸c˜oes que ﬁzemos, dispon´ıveis no site, usamos como base a funda-
menta¸c˜ao te´orica feita nesta disserta¸c˜ao. S˜ao duas apresenta¸c˜oes, a primeira com as
se¸c˜oes: Cadeias de Markov; Vetor de probabilidade e a segunda com Cadeias de Markov
Absorventes. Sugerimos que estes slides sejam usados pelo professor para auxili´a-lo em
suas explica¸c˜oes acerca das cadeias de Markov.

Na primeira apresenta¸c˜ao iniciamos com uma foto de Andrei Markov e um par´agrafo
introdut´orio sobre as suas cadeias. A seguir temos um slide onde ´e mostrado um diagrama
de estados para que os conceitos de estados e probabilidades de transi¸c˜ao sejam introdu-
zidos.

Como primeiro exemplo para a apresenta¸c˜ao, escolhemos `a situa¸c˜ao problema que
envolve o labirinto do rato, pois nos parece muito adequada para um primeiro contato
dos estudantes com as cadeias de Markov.

Podemos com este problema mostrar aos estudantes como se constr´oi um diagrama
de estados avan¸car para o slide sobre a matriz de transi¸c˜ao e da´ı transformar o diagrama
feito em uma matriz de transi¸c˜ao. O professor pode usar o quadro branco e piloto para
fazer isto juntamente com os estudantes.

A seguir temos alguns slides dedicados as equa¸c˜oes de Chapman-Kolmogorov que
devem ser mais ou menos aprofundado conforme a avalia¸c˜ao do docente. A segunda parte
da apresenta¸c˜ao introduz o conceito do vetor de probabilidade. O primeiro exemplo que
usa este conceito ´e o da previs˜ao do tempo na cidade de Salvador, no qual est´a ilustrado o
que ´e um vetor de probabilidade inicial e como podemos saber qual a previs˜ao do tempo
no mˆes seguinte a partir do produto entre o vetor inicial e sua matriz de transi¸c˜ao.

Com o exemplo da lealdade do consumidor ´e importante que o professor pe¸ca aos
alunos para constru´ırem o diagrama de estados e a matriz de transi¸c˜ao antes de mostr´a-los

40

no projetor. De modo que consiga avaliar como est´a a compreens˜ao dos conceitos vistos
anteriormente. Com este exemplo introduzimos o conceito de vetor de probabilidade
estacion´ario e de matriz de transi¸c˜ao regular.

Na segunda apresenta¸c˜ao utilizamos o exemplo do n´ıvel econˆomico para introdu-
zir o conceito de estado absorvente. Em seguida temos v´arios slides deﬁnindo todos os
elementos necess´arios para plena caracteriza¸c˜ao das cadeias de Markov absorventes.

Esta ´e uma parte cr´ıtica da apresenta¸c˜ao, porque s˜ao feitas muitas deﬁni¸c˜oes e os
estudantes podem se dispersar comprometendo o entendimento necess´ario para resolu¸c˜ao
de problemas futuros. Exempliﬁcar estas deﬁni¸c˜oes e tentar ser o mais breve poss´ıvel
pode ajudar neste processo. Finalizando esta parte, os resultados obtidos s˜ao aplicados
no exemplo do labirinto do rato.

Conclu´ımos a apresenta¸c˜ao com o problema da ru´ına do jogador, que apesar de ser
uma situa¸c˜ao simples e de f´acil interpreta¸c˜ao nos permite ilustrar bem todos os conceitos
necess´arios para resolu¸c˜ao dos problemas que envolvem cadeias de Markov absorventes.

3.3 O site

Constru´ımos o site (https://sites.google.com/view/cadeiasdemarkovabsorventes/) que ´e basica-
mente um local p´ublico para que os professores e alunos possam ter contato com o material
elaborado nesta disserta¸c˜ao. Usamos o Google sites como plataforma de cria¸c˜ao, optamos
por ela pois j´a t´ınhamos algum know-how de como us´a-la.

O site cont´em quatro p´aginas: Biograﬁa, Cadeias de Markov, Cadeias de Markov
Absorventes e Curiosidades. A p´agina que cont´em a biograﬁa ´e uma c´opia ﬁel da se¸c˜ao
1.1 desta disserta¸c˜ao, por que al´em de n˜ao ser um texto muito longo, n˜ao existe, pelo
menos n˜ao encontramos nas pesquisas realizadas, um artigo ou mesmo referˆencias, em
portuguˆes, sobre o assunto que possuam mais do que dois par´agrafos.

Em seguida temos a p´agina sobre as Cadeias de Markov onde temos nove link’s
que nos levam a alguns dos materiais que produzimos. No link No¸c˜oes B´asicas temos uma
pequena apostila onde introduzimos o conceito das cadeias de Markov da mesma forma
que ﬁzemos aqui.

Contudo omitimos as demonstra¸c˜oes dos teoremas pois avaliamos que o texto ﬁ-
caria um pouco rebuscado para um primeiro contato com o assunto numa apostila. No
entanto para o professor ou aluno mais curioso as demonstra¸c˜oes estar˜ao dispon´ıveis no
link disserta¸c˜ao nesta mesma p´agina.

No link Exemplos temos a discuss˜ao dos problemas sobre as cadeias de Markov
que aqui foram feitas onde tamb´em omitimos alguns trechos com coment´arios que s˜ao
pertinentes apenas para o contexto desta disserta¸c˜ao.

Logo depois est˜ao os links para as duas listas que possuem exerc´ıcios referentes
as cadeias de Markov e ainda um link para uma Apresenta¸c˜ao em Beamer que pode ser

41

usada por professores para guiar sua aula sobre o assunto seguindo o mesmo caminho que
ﬁzemos aqui.

Na segunda coluna de links, iniciamos com aquele que nos direciona a um v´ıdeo
com um tutorial passo a passo de como podemos utilizar a vers˜ao do Geogebra para
PC para efetuar os c´alculos matriciais necess´arios para resolver problemas que envolvem
cadeias de Markov.

O link seguinte nos leva a um pequeno v´ıdeo mostrando como podemos efetuar
esses mesmos c´alculos na vers˜ao para celular do Geogebra. Isto se faz necess´ario, porque
nestes dispositivos o programa Geogebra n˜ao disponibiliza o modo planilha utilizado no
v´ıdeo anterior para a constru¸c˜ao das matrizes. Tamb´em ´e bastante prov´avel que muitos
alunos n˜ao ir˜ao dispor de um PC para esta tarefa, mas com certeza ter˜ao acesso a algum
celular que os permitam efetuar estes c´alculos.

O pen´ultimo link utiliza uma ferramenta muito interessante do Google que s˜ao os
Formul´arios em seu modo teste. Criamos um pequeno quiz com alguns conceitos ligados as
Cadeias de Markov, onde o aluno ap´os responder as quest˜oes pode visualizar seu despenho
automaticamente.

Al´em disso, se o professor desejar poder´a adaptar este quiz de maneira que ele
possa ser armazenado em uma planilha e assim sirva como instrumento de avalia¸c˜ao no
processo de aprendizagem dos estudantes.

O processo de cria¸c˜ao dos formul´arios requer um certo esfor¸co mas as possibilidades
que s˜ao geradas com os mesmos compensam esse gasto inicial de energia. Ao atribuir
valores as quest˜oes ´e poss´ıvel quantiﬁcar e armazenar uma nota para cada estudante,
al´em do que s˜ao geradas estat´ısticas de erros e acertos de cada quest˜ao. Tudo isso ´e feito
de forma autom´atica, sem que seja necess´aria nenhuma interven¸c˜ao, ap´os a cria¸c˜ao do
formul´ario e preenchimento das respostas.

Chegando a p´agina cujo t´ıtulo ´e Cadeias de Markov Absorventes temos os mesmos
links gerados na p´agina anterior. Uma parte te´orica com Deﬁni¸c˜oes e Teoremas pertinen-
tes ao tema, onde desta vez mantivemos todos devidamente demonstrados, no primeiro
link. Em seguida temos os Exemplos, Lista de Exerc´ıcios, Apresenta¸c˜ao, Quiz e Tutorial
Geogebra todos com a mesma funcionalidade da p´agina anterior.

Na p´agina Curiosidades temos alguns links interessantes que encontramos na world
wide web na fase de pesquisa desta disserta¸c˜ao que achamos importante de serem com-
partilhados. O primeiro link est´a direcionado para a p´agina da wikip´edia sobre o assunto,
nessa p´agina podemos encontrar diversas aplica¸c˜oes das cadeias de Markov em ´areas dis-
tintas do conhecimento.

O segundo link ´e de um v´ıdeo da Khan Academy, em inglˆes, sobre as cadeias de
Markov onde podemos ver que elas foram o resultado da busca do seu criador para garantir
que a lei dos grandes n´umeros tamb´em era v´alida para eventos dependentes.

O link Processos Estoc´astico nos direciona para o canal do You Tube do professor

42

Lu´ıs Rincon do departamento de Matem´atica da Faculdade de Ciˆencias da Universidade
Nacional Autˆonoma do M´exico. Um curso que apesar de estar em espanhol ´e completa-
mente compreendido e de uma riqueza de detalhes que vale a pena conferir.

No link Simula¸c˜ao temos uma p´agina da internet que nos mostra diagramas de
estado de uma cadeia de Markov com dois ou trˆes estados. ´E poss´ıvel manipular as
probabilidades de transi¸c˜ao e perceber como isso modiﬁca o processo atrav´es de uma
anima¸c˜ao.

Seguindo temos um v´ıdeo, em inglˆes, onde as no¸c˜oes b´asicas das cadeias de Markov
s˜ao apresentadas de uma forma simples e r´apida que com certeza os estudantes ir˜ao gostar.
E pode at´e servir de ponte para um trabalho interdisciplinar com a disciplina de l´ıngua
estrangeira.

Por ﬁm temos os dois links ﬁnais, um para o excelente livro de probabilidade
de dom´ınio p´ublico, em inglˆes, de Grimstead e Snell (1997), que inclusive faz parte da
referˆencia bibliogr´aﬁca dessa disserta¸c˜ao. E o ´ultimo ´e o artigo de hist´oria da matem´atica,
aqui tamb´em usado, de Brian Hayes que fala sobre a vida e obra de Andrei Andreyevich
Markov.

Cap´ıtulo 4

Considera¸c˜oes ﬁnais

Ao ﬁnal desta disserta¸c˜ao ainda estamos fascinados pelas cadeias de Markov. Ape-
sar das cadeias absorventes terem grande relevˆancia te´orica, com a pesquisa desenvolvida,
vimos que s˜ao apenas a ponta do iceberg. Por isso desejamos continuar produzindo mate-
rial com este tema, para atualizar o site com aquilo que encontrarmos e puder ser adaptado
para alunos do ensino m´edio.

Al´em disso, constatamos que h´a uma escassez de material sobre as cadeias de
Markov em l´ıngua portuguesa, o que nos impulsiona a continuar pesquisando sobre as
mesmas. At´e existem apostilas e monograﬁas mas sempre com enfoque no ensino superior.
As disserta¸c˜oes do PROFMAT sobre o tema foi o ´unico lugar que encontramos materiais
em portuguˆes com o foco no ensino m´edio.

Outro desejo que possu´ımos ´e dar acesso aos estudantes do ensino m´edio a temas e
problemas que envolvam matem´atica aplicada com os assuntos que eles vˆem nesta fase de
ensino. Queremos criar oﬁcinas itinerantes que possam ser realizadas em escolas p´ublicas
de ensino m´edio no nosso estado, para que os estudantes tenham a´ı um outro est´ımulo
para fomentar o desejo de aprender ou at´e mesmo seguir carreira na ´area de exatas.

´E grande a satisfa¸c˜ao de chegar ao ﬁnal desse texto. Mais uma vez gostaria de
agradecer a existˆencia do Programa de Mestrado Proﬁssional em Matem´atica em Rede
Nacional - PROFMAT, que possibilita ao professor do ensino b´asico trabalhar com pes-
quisa e perceber que ´e capaz de fazˆe-lo. O professor-pesquisador, no n´ıvel b´asico, apesar
de teoricamente ser um objetivo do nosso sistema educacional, tem poucas iniciativas que
verdadeiramente fomentam esta pr´atica.

A cria¸c˜ao do site e o contato com novas tecnologias como o Geogebra, o LATEX
e os aplicativos Google, fez com que o interesse por metodologias de ensino mais ativas
crescesse e que busc´assemos pelo menos conhecer os meios necess´arios para implementa¸c˜ao
das mesmas em nossas aulas, isso tamb´em se deu gra¸cas a escrita desse texto e a este
programa.

O LATEX, em particular, foi uma ferramenta de grande ajuda para vislumbrar novos
horizontes para planejamento e execu¸c˜ao de aulas. Muitas horas foram necess´arias para

43

44

conseguir escrever o texto que agora se lˆe. Mas a qualidade do texto e mudan¸ca na l´ogica
do digitar para programar aquilo que se escreve ´e indescrit´ıvel. Ademais o Beamer e o
Tik’Z foram ambientes que nos ajudaram bastante e nos garantem inﬁnitas possibilidades
na cria¸c˜ao de apresenta¸c˜oes. Ainda em rela¸c˜ao ao LATEX, gostar´ıamos de destacar o canal
do You Tube do portuguˆes Antero Neves que possui v´arias v´ıdeo-aulas que muito nos
ajudaram.

Concluindo, acreditamos que o car´ater interdisciplinar do assunto aqui tratado
possibilita ao discente uma rela¸c˜ao de aproxima¸c˜ao entre o vivido e o estudado que tanto
buscamos atingir no dia a dia da sala de aula. ´E importante observar que trabalhos
com matem´atica aplicada d˜ao ao estudante uma vis˜ao n˜ao separatista e pragm´atica da
matem´atica, melhorando sua rela¸c˜ao com a mesma, que como sabemos nem sempre ´e
harmoniosa.

Por ﬁm deixamos uma cita¸c˜ao do livro A f´ormula preferida do professor (OGAWA,
2017), que tem como personagens uma cuidadora, seu ﬁlho e um matem´atico, que devido a
um acidente, tem um problema de mem´oria recente e s´o se lembra dos ´ultimos 80 minutos
de sua vida.

O trecho destacado nos traz uma vis˜ao platˆonica muito bela do que ´e a matem´atica
e como ela contribui na jornada humana sobre a Terra. A parte citada abaixo acontece
logo ap´os o professor pedir para a sua cuidadora desenhar numa folha de papel uma reta,
o que ela o faz com o aux´ılio de um hashi e em seguida ´e indagada por ele da seguinte
maneira:

- Muito bem, isso ´e uma reta. Vocˆe compreendeu bem a
deﬁni¸c˜ao de uma reta. Mas pense um pouco. A reta que
vocˆe tra¸cou tem come¸co e ﬁm, certo? Ent˜ao se trata de um
segmento de reta ... Ou seja, ´e imposs´ıvel desenhar uma reta
verdadeira em uma folha de papel.
Observei atentamente a ponta do l´apis.
- Ent˜ao, onde ´e poss´ıvel encontrar uma reta verdadeira. A
resposta ´e: s´o aqui!
O professor colocou a m˜ao sobre o peito. O mesmo gesto que
ele ﬁzera ao me ensinar sobre n´umeros imagin´arios.
- A verdade eterna, que n˜ao se deixa inﬂuenciar pela mat´eria
ou pelos fenˆomenos naturais, ´e invis´ıvel aos nossos olhos.
A matem´atica desvenda e revela a aparˆencia dessa verdade.
Nada pode detˆe-la.
A existˆencia dessa verdade eterna, `a qual o Professor se re-
feria, era necess´aria para mim, que esfregava o assoalho do
escrit´orio com o estˆomago vazio e sempre preocupada com o
meu ﬁlho. Precisava sentir que, de fato, esse mundo invis´ıvel
sustentava o mundo vis´ıvel. A reta verdadeira sem espessura
ou superf´ıcie, aquela que atravessava majestosamente as tre-
vas estendendo-se al´em de qualquer limite - s´o ela poderia
me trazer um pouco de tranquilidade.

Cap´ıtulo 5

Apˆendices

5.1 Apˆendice 1 - C´alculos

5.1.1 Lealdade do Consumidor

midor:









P =

P10 =

P20 =

P30 =

Abaixo temos algumas potˆencias da matriz P do exemplo da Lealdade do Consu-

0, 7500 0, 1000 0, 0500 0, 1000
0, 0800 0, 6000 0, 1500 0, 1700
0, 1000 0, 2000 0, 5000 0, 2000
0, 1000 0, 1000 0, 8000

0

















P5 =

0, 3040 0, 2155 0, 1448 0, 3357
0, 1558 0, 2594 0, 1803 0, 4044
0, 1599 0, 2448 0, 1829 0, 4124
0.0815 0, 2243 0, 1770 0, 5172

































P15 =

P25 =

P35 =

0, 1512 0, 2344 0, 1731 0, 4413
0, 1459 0, 2348 0, 1740 0, 4452
0, 1459 0, 2348 0, 1740 0, 4453
0.1417 0, 2350 0, 1747 0, 4486

0, 1451 0, 2348 0, 1741 0, 4460
0, 1449 0, 2348 0, 1742 0, 4461
0, 1449 0, 2348 0, 1742 0, 4461
0.1447 0, 2348 0, 1742 0, 4463

0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0.1448 0, 2348 0, 1742 0, 4462

















































0, 1765 0, 2322 0, 1688 0, 4225
0, 1496 0, 2357 0, 1739 0, 4408
0, 1496 0, 2352 0, 1737 0, 4414
0, 1302 0, 2351 0, 1762 0, 4586

0, 1461 0, 2347 0, 1740 0, 4452
0, 1450 0, 2348 0, 1741 0, 4460
0, 1450 0, 2348 0, 1741 0, 4460
0, 1442 0, 2349 0, 1743 0, 4467

0, 1449 0, 2348 0, 1742 0, 4461
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462

























45

46

P40 =









0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0.1448 0, 2348 0, 1742 0, 4462









P45 =









0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0.1448 0, 2348 0, 1742 0, 4462









Ent˜ao pelo teorema 2.5.1 temos que:

π(5) = π(0)·P 5 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

(cid:105)





·




0, 3040 0, 2155 0, 1448 0, 3357
0, 1558 0, 2594 0, 1803 0, 4044
0, 1599 0, 2448 0, 1829 0, 4124
0.0815 0, 2243 0, 1770 0, 5172









(cid:104)

π(5) =

0, 1789 0, 2381 0, 1714 0, 4116

(cid:105)

π(10) = π(0)·P 10 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

(cid:105)





·




0, 1765 0, 2322 0, 1688 0, 4225
0, 1496 0, 2357 0, 1739 0, 4408
0, 1496 0, 2352 0, 1737 0, 4414
0, 1302 0, 2351 0, 1762 0, 4586

(cid:104)

π(10) =

0, 1524 0, 2346 0, 1731 0, 4399

(cid:105)

π(15) = π(0)·P 15 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

(cid:105)





·




0, 1512 0, 2344 0, 1731 0, 4413
0, 1459 0, 2348 0, 1740 0, 4452
0, 1459 0, 2348 0, 1740 0, 4453
0.1417 0, 2350 0, 1747 0, 4486

(cid:104)

π(15) =

0, 1464 0, 2347 0, 1739 0, 4449

(cid:105)

π(20) = π(0)·P 20 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

(cid:105)





·




0, 1461 0, 2347 0, 1740 0, 4452
0, 1450 0, 2348 0, 1741 0, 4460
0, 1450 0, 2348 0, 1741 0, 4460
0, 1442 0, 2349 0, 1743 0, 4467

(cid:104)

π(20) =

0, 1451 0, 2348 0, 1741 0, 4459

(cid:105)

























π(25) = π(0)·P 25 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

47

(cid:105)





·




0, 1451 0, 2348 0, 1741 0, 4460
0, 1449 0, 2348 0, 1742 0, 4461
0, 1449 0, 2348 0, 1742 0, 4461
0.1447 0, 2348 0, 1742 0, 4463

(cid:104)

π(25) =

0, 1449 0, 2348 0, 1742 0, 4461

(cid:105)

π(30) = π(0)·P 30 =

(cid:104)

0, 2500 0, 3200 0, 2300 0, 2000

(cid:105)





·




0, 1449 0, 2348 0, 1742 0, 4461
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462
0, 1448 0, 2348 0, 1742 0, 4462

(cid:104)

π(30) =

0, 1448 0, 2348 0, 1742 0, 4462

(cid:105)

Observe que os valores encontrados correspondem aos achados na tabela 1.3.

















5.1.2 Forma Canˆonica

Segue abaixo as potˆencias de P1 do exemplo da se¸c˜ao 2.2.

E1

E2

E3

E4

E1

E2

E3

E4

48

P2

1 =

P10

1 =

















E1
E2
E3
E4

E1
E2
E3
E4

0, 11 0, 78 0, 07 0, 04

0

1

0
0, 32
0, 26 0, 12
0, 27 0, 18 0, 27 0, 28

0
0, 3

E1

E2

E3

E4

0, 01 0, 97 0, 01 0, 01

0

1

0

0

0, 05 0, 85 0, 05 0, 05
0, 05 0, 86 0, 05 0, 05

















P5

1 =









E1
E2
E3
E4

0, 03 0, 91 0, 03 0, 03

0

1

0

0

0, 16 0, 53 0, 16 0, 16
0, 14 0, 58 0, 14 0, 14









E1

E2

E3

E4









E1
E2
E3
E4

0
0

1
1

0
0

0
0

0, 02 0, 94 0, 02 0, 02
0, 02 0, 94 0, 02 0, 02

P15

1 =

E1

E2

E3

E4

E1

E2

E3

E4

P20

1 =









E1
E2
E3
E4

0
0

1
1

0
0

10
0

0, 01 0, 97 0, 01 0, 01

0

1

0

0









P25

1 =









0
0
0
0

E1
E2
E3
E4

1
1
1
1

0
0
0
0

0
0
0
0

















49

5.2 Apˆendice 2 - Listas de Exerc´ıcios

5.2.1

1o Bloco - No¸c˜oes B´asicas

1. Decida, utilizando a deﬁni¸c˜ao, quais das matrizes abaixo poderia ser uma matriz de
transi¸c˜ao para uma cadeia de Markov. Esboce um diagrama para estas matrizes.

(cid:34)

a)

(cid:35)

0, 5
0

0
0, 5

(cid:35)

(cid:34) 2
1
3
3
1 0

b)

c)

(cid:34) 1
4
1
2

(cid:35)

3
4
1
2






d)






3
1
4 0
4
2 0 1
1 2
3 0

2. Escreva uma matriz de transi¸c˜ao associada a cada um dos diagramas abaixo.

1
2

1
2

B

1
4

A

3
4

1
4

1
2

a)

C

1
4

0, 1

B

7
0,

5
0,

A

0

,

4

0

,

8

C

0, 3

b)

0, 2

0, 9

c)

0, 1

A

05
0,

6
0,

C

0

,

0

,

3

8

5

B

0, 15

0, 05

3. Considere uma cadeia de Markov com matriz de transi¸c˜ao:

Estado 1 Estado 2

Estado 1

Estado 2









1
3

1
4









2
3

3
4

a)

b)

O que representa a entrada 1

4 nesta matriz?

Supondo que o sistema esteja inicialmente no estado

1, determine a distribui¸c˜ao de probabilidade ap´os

uma observa¸c˜ao. Qual ser´a ap´os duas observa¸c˜oes?

c)

Supondo que o sistema esteja inicialmente no estado

2, determine a distribui¸c˜ao de probabilidade ap´os

uma observa¸c˜ao. Qual ser´a ap´os duas observa¸c˜oes?

4. Considere uma cadeia de Markov com matriz de transi¸c˜ao:

Estado 1 Estado 2









Estado 1

Estado 2

0, 1

0, 9

0, 5

0, 5









a)

b)

c)

O que representa a entrada 0, 7 nesta matriz?

Supondo que o sistema esteja inicialmente no estado

1, determine a distribui¸c˜ao de probabilidade ap´os

uma observa¸c˜ao. Qual ser´a ap´os duas observa¸c˜oes?

for
(cid:3), qual ser´a a probabilidade ap´os duas ob-

Se a distribui¸c˜ao de probabilidade inicial
(cid:2) 1
4 , 3
serva¸c˜oes?

4

5. Considere uma cadeia de Markov com matriz de transi¸c˜ao:

50

P =










0, 2 0, 7 0, 1

0, 6 0, 2 0, 2

0, 4 0, 1 0, 5










Se a distribui¸c˜ao inicial for [0, 25; 0, 25; 0, 50], qual ser´a a distribui¸c˜ao de probabili-
dade na pr´oxima observa¸c˜ao?

6. Determine os valores de a, b e c que far˜ao da matriz a seguir uma matriz de transi¸c˜ao

de uma cadeia de Markov.

P =






0, 2
b
0

a
0, 4
0, 6 0, 3
0
c






7. Ache as trˆes primeiras potˆencias de cada uma das matrizes abaixo. Para cada uma
das matrizes de transi¸c˜ao, determine a probabilidade de que iniciando o processo no
estado 1 ele esteja no estado 2 ap´os trˆes etapas.

(cid:34)






a)

d)

(cid:35)

1
0
0, 7 0, 3

0, 3 0, 5 0, 2
0
1
0
0, 6 0, 3 0, 1






b)

e)

(cid:34) 1
3
1

(cid:35)

2
3
0






0, 1 0, 1 0, 8
0, 2 0, 3 0, 5
0, 6 0, 3 0, 1






(cid:34)

c)

(cid:35)

0, 5
0, 5
0, 64 0, 36

8. Uma pequena e remota vila recebe transmiss˜oes de duas esta¸c˜oes de r´adio, uma
de not´ıcias e outra de m´usicas. Dos ouvintes que est˜ao sintonizados na esta¸c˜ao de
not´ıcias, 70% permanecer˜ao ouvindo notici´arios ap´os o intervalo que ocorre a cada
meia hora, enquanto 30% trocar˜ao de esta¸c˜ao durante o intervalo. Dos ouvintes
que est˜ao sintonizados na esta¸c˜ao de m´usica, 60% trocar˜ao de esta¸c˜ao durante o
intervalo, enquanto 40% permanecer˜ao ouvindo m´usica. Suponha que as 08:15 todos
est˜ao ouvindo o notici´ario.

a)

Desenhe um diagrama que represente o comportamento dos moradores dessa
cidade em rela¸c˜ao as esta¸c˜oes de r´adio.

b)

Escreva a matriz de transi¸c˜ao associada ao diagrama do item anterior.

c)

Determine o vetor de probabilidade inicial.

d)

Que percentual dos ouvintes estar˜ao sintonizados na esta¸c˜ao de m´usica `as
09:25 (ap´os os intervalos de programa¸c˜ao das 08:30 e das 09:00).

51

9. Um estudo das safras de nozes-de-pinha no sudoeste americano, de 1940 a 1947,
levantou `a hip´otese de a produ¸c˜ao de nozes seguir uma cadeia de Markov. Os dados
sugeriram que, se a safra de um ano fosse boa, as probabilidades de a safra do ano
seguinte ser boa, regular ou p´essima seria de. respectivamente, 0,08; 0,07 e 0,85; se
a safra do ano fosse regular as probabilidades de a safra do ano seguinte ser boa,
regular ou p´essima seria de respectivamente, 0,09; 0,11 e 0,80; se a safra do ano fosse
p´essima as probabilidades de a safra do ano seguinte ser boa, regular ou p´essima
seria de. respectivamente, 0,11; 0,05 e 0,84.

a)

Desenhe um diagrama que represente esta cadeia.

b)

Escreva a matriz de transi¸c˜ao associada ao diagrama do item anterior.

c)

Se a safra de 1940 foi boa, ache as probabilidades de uma boa safra ocorrer
em 1943.

10. Um estudo sobre a resposta do sistema imunol´ogico de coelhos os classiﬁcou em 4
grupos, de acordo com a for¸ca da resposta. De uma semana para outra, os coelhos
trocam de classiﬁca¸c˜ao de um grupo para outro de acordo com a seguinte matriz de
transi¸c˜ao:

1

5
7

0

0

0














1

2

3

4

2

2
7

1
2

0

0

3

0

1
3

1
2

1
4

4

0

1
6

1
2

3
4














a)

b)

Qual a propor¸c˜ao de coelhos do
grupo 1 que permanecem no grupo
1 ap´os 4 semanas?

Na primeira semana haviam 9 co-
elhos no grupo 1, 4 no grupo 2 e
nenhum coelho nos demais. Quan-
tos coelhos s˜ao esperados em cada
grupo ap´os 4 semanas?

Bons Estudos!!!

52

5.2.2

2o Bloco - Vetor de probabilidade

1. Quais das matrizes de transi¸c˜ao abaixo s˜ao regulares?

(cid:34)






a)

c)

(cid:35)

0, 3 0, 7
0, 1 0, 9






0 1 0
0 0 1
1 0 0

(cid:34)






b)

d)

(cid:35)

1
0
0, 2 0, 8

0, 3 0, 2 0, 5
1
0
0
0, 5 0, 1 0, 4






2. Ache o vetor de equil´ıbrio para cada uma das matrizes de transi¸c˜ao abaixo.

a)

c)

(cid:34) 1
4
1
2

(cid:35)

3
4
1
2






0, 1 0, 1 0, 8
0, 4 0, 4 0, 2
0, 1 0, 2 0, 7






(cid:34)






b)

d)

(cid:35)

0, 3 0, 7
0, 6 0, 4

0, 5 0, 2 0, 3
0, 1 0, 3 0, 6
0, 2 0, 2 0, 6






3. Uma comerciante abastece a sua loja com trˆes tipos de detergente das marcas A,
B e C. Quando a marca A ´e vendida, a probabilidade de que ela reabaste¸ca com a
marca A ´e de 0,7 e de 0,15 para cada uma das marcas B e C. Quando ela vende a
marca B, a probabilidade de reabastecimento com a marca B ´e de 0,8 e de 0,1 para
cada uma das marcas A e C. Por ﬁm, quando ela vende a marca C, a probabilidade
de que ela reabaste¸ca com a marca C ´e de 0,6 e de 0,2 para cada uma das marcas
A e B. Determine a matriz de transi¸c˜ao. A longo prazo, como ﬁcar´a distribu´ıdo o
estoque de detergentes.

4. As probabilidades de que uma m˜ae loira venha a ter uma ﬁlha loira, ou uma morena,
ou uma ruiva s˜ao de 0,6, 0,2 e 0,2, respectivamente. As probabilidades de que uma
m˜ae morena venha a ter uma ﬁlha loira, ou uma morena, ou uma ruiva s˜ao de 0,1,
0,7 e 0,2, respectivamente. E as probabilidades de que uma m˜ae ruiva venha a ter
uma ﬁlha loira, ou uma morena, ou uma ruiva s˜ao de 0,4, 0,2 e 0,4, respectivamente.

a) Qual ´e a probabilidade de que uma mulher loira seja av´o de uma morena?

b) Se a popula¸c˜ao atual de mulheres ´e de 50% de morenas, 30% de loiras e o

restante de ruivas, qual ser´a a distribui¸c˜ao:

i. Ap´os duas gera¸c˜oes?

ii. A longo prazo?

5. Use os dados da tabela abaixo e suponha que as tendˆencias indicadas se mantenham,

de modo a responder as quest˜oes a seguir:

53

Tabela 5.1: Tendˆencias Educacionais

Faculdade M´edio Fundamental

Faculdade
M´edio
Fundamental

80%
40%
20%

18%
50%
60%

2%
10%
20%

a) Qual ´e a matriz de transi¸c˜ao?

b) Qual a probabilidade de que um neto de um concluinte do ensino fundamental

complete a faculdade?

c) Qual a probabilidade de que um neto de um concluinte do ensino m´edio complete

o ensino m´edio?

d ) O n´ıvel mais elevado atingido por uma popula¸c˜ao em um determinado ano foi
de 13% para a faculdade, 62% para o ensino m´edio e 25% para o ensino funda-
mental. Qual ser´a a distribui¸c˜ao do n´ıvel de educa¸c˜ao para os seus bisnetos?

e) Qual ser´a a distribui¸c˜ao de longo prazo?

6. Robˆos foram programados para atravessar o labirinto mostrado na ﬁgura abaixo e

em cada jun¸c˜ao, escolher aleatoriamente um caminho para seguir.

1

3

2

4

Figura 5.1: Labirinto

a) Construa a matriz de transi¸c˜ao para a Cadeia

de Markov que modela a situa¸c˜ao.

b) Suponha que comecemos com 15 robˆos em cada
jun¸c˜ao. Ache a distribui¸c˜ao estacion´aria dos
robˆos.(Considere que os robˆos levam sempre o
mesmo tempo para ir de uma jun¸c˜ao a outra.)

Bons Estudos!!!

5.2.3

3o Bloco - Cadeias de Markov Absorventes

1. Identiﬁque todos os estados absorventes das matrizes de transi¸c˜ao abaixo.(Considere
que o n´umero de cada linha ou de cada coluna corresponde ao ´ındice de um dos
estados poss´ıveis do processo)

54














a)

c)

0, 15 0, 05 0, 8
0
1
0
0, 6

0
0, 4






0, 32 0, 41 0, 16 0, 11
0, 28
0, 42 0, 30
1
0

0
0
0

0
1

0
0














b)

d)









0, 4 0 0, 6
0
0
1
0, 9 0 0, 1






0, 2
0

0, 1
0

0, 5
1

0, 2
0
0, 9 0, 02 0, 04 0, 04
0

1

0

0









2. Quais das matrizes de transi¸c˜ao do item anterior representam uma cadeia de Markov

absorvente?

3. Escreva as matrizes na forma canˆonica e determine a matriz fundamental F das

cadeias de Markov absorventes abaixo.

a)

c)

e)





























0
0
1
0
1
0
0, 2 0, 2 0, 6


1 0 0 0
3 0 2
1
3 0
0 0 1 0
1
1
4
4

1
4

1
4







0
1

0
0

0
0
1
0
0
0
0, 1 0, 2 0, 3 0, 2 0, 2
0, 1
0, 3 0, 5 0, 1
1
0
0
0

0
0

b)

d)

f)







































1 0 0
0 1 0
1
1
1
3
3
3



2

1







1
2 0 1
4
4
0 1 0 0
0 0 1 0
2 0 0 1
1
0, 1
0, 4 0, 2 0, 3
0
0
1
0
0
1
0
0
0, 1 0, 5 0, 1 0, 1 0, 2
1
0
0

0
0
0

0

0











4. Suponha que para uma certa cadeia de Markov absorvente, a matriz fundamental

F seja dada por:

R$ 1 R$ 2 R$ 3










2, 5

2

1, 5

R$ 1

R$ 2

R$ 3










0, 5

1

1, 5

1

3

2

(a) Qual ´e o n´umero esperado de vezes que
uma pessoa ter´a R$ 3, dado que ela ini-
ciou com R$ 1? E com R$ 2?

(b) Se uma jogadora iniciar com R$ 3, de
quantas jogadas ela pode esperar par-
ticipar antes da absor¸c˜ao?E se iniciar
com R$ 1?

55

5. Dados foram coletados sobre a probabilidade de que um professor ou um estudante
com interesse declarado em ensino, continue nessa carreira no ano seguinte. Para
simpliﬁcar a an´alise, os dados originais foram classiﬁcados em quatro categorias:
estudantes de ensino m´edio ou faculdade (E), professores rec´em formados(RF), pro-
fessores veteranos (P) e aqueles que deixam a proﬁss˜ao (S). As probabilidades de
transi¸c˜ao est˜ao na matriz abaixo.

E

RF

0, 70

0, 11

0

0

0

0

0

0











E

RF

P

S

P

0

S

0, 19

0, 86

0, 14

0, 88

0, 12

0

1











(a) Encontre o n´umero de anos esperados para que um estudante com interesse em

ensinar levar´a sendo professor veterano;

(b) Determine o n´umero de anos esperados para que um professor rec´em-formado

ﬁcar´a como professor veterano;

(c) Encontre o n´umero adicional de anos que um professor veterano ir´a continuar

ensinando;

(d) Note que o n´umero de anos da letra b ´e muito maior do que o da letra a e
ainda porque o da letra c ´e ainda maior. Explique porque isso j´a era esperado;

6. Um estudo de pacientes do Hospital Universit´ario da Carolina do Norte usa um
modelo de cadeia de Markov com trˆes categorias de pacientes: 0 (morte), 1 (estado
desfavor´avel) e 2 (estado favor´avel). A matriz de transi¸c˜ao para um ciclo de 72
horas ´e a seguinte:

0

1

1

0

2

0

0, 085

0, 779

0, 136

0, 017

0, 017

0, 966















0

1

2

(a) Ache a matriz fundamental.

(b) Para um paciente com estado favor´avel, determine a expectativa do n´umero de

ciclos que o paciente vai continuar neste estado antes de morrer.

(c) Para um paciente com estado desfavor´avel, determine a expectativa do n´umero
de ciclos que o paciente vai ﬁcar em um estado favor´avel antes de morrer.

56

7. Os dados a seguir foram obtidos do setor de admiss˜ao para uma faculdade com um
curso de dois anos de dura¸c˜ao. Da classe do primeiro ano (P), 75% tornam-se no
ano seguinte estudantes do segundo ano (S) e 25% abandonam o curso (A). Dentre
aqueles que foram para o segundo, durante um certo ano, 90% se graduam (G) no
ano seguinte, e 10% abandonam o curso.

(a) Quantos e quais estados s˜ao absorventes?

(b) Escreva a matriz de transi¸c˜ao P na forma canˆonica.

(c) Determine a matriz F.

(d) Determine a probabilidade de que um estudante, ingressando no primeiro ano,

ir´a se formar no ﬁnal.

8. A cidade de Sacramento concluiu recentemente um novo sistema de trilhos para
ve´ıculos leves (VLT) para levar passageiros e compradores ao centro da cidade e
aliviar o congestionamento da rodovia. Os planejadores da cidade estimam que a
cada ano, 15% daqueles que dirigem ou andam de autom´ovel v˜ao mudar para o VLT;
80% ir˜ao continuar utilizando autom´oveis; e o restante n˜ao ir´a mais frequentar o
centro da cidade. Entre os usu´arios do VLT estima-se que 5% ir˜ao voltar a utilizar
autom´oveis e 80% ir˜ao continuar utilizando o VLT e o restante deixar´a de frequentar
o centro da cidade. Considere que as pessoas que deixam de ir ao centro nunca volta
a frequentar esta ´area da cidade.

(a) Escreva a matriz de transi¸c˜ao desta situa¸c˜ao.

(b) Qual a probabilidade de que uma pessoa que vai de carro para o centro deixe

de frequent´a-lo?

(c) Determine a matriz fundamental F e o produto FR.

(d) Encontre o n´umero esperado de anos que uma pessoa que v´a de autom´ovel

para o centro ir´a levar para n˜ao mais frequent´a-lo.

9. Realizou-se uma pesquisa onde dois animais de sexo opostos acasalavam, da sua
prole pegavam-se aleatoriamente descendentes de sexo opostos e os colocavam para
acasalar e assim por diante. Por uma quest˜ao de simplicidade admitiremos que
a caracter´ıstica em quest˜ao independe do sexo. Seja A um gene dominante para
alguma caracter´ıstica e a o gene recessivo. Os pais podem inicialmente carregar os
genes AA, Aa ou aa. H´a seis maneiras poss´ıveis para a combina¸c˜ao de pais, elas
est˜ao listados na tabela abaixo.

(a) Suponha que o acasalamento entre descendentes seja aleat´orio. Veriﬁque se a

matriz de transi¸c˜ao desta situa¸c˜ao corresponde a matriz abaixo:

Estado

1

2

3

4

5

Combina¸c˜ao AA e AA AA e Aa AA e aa Aa e Aa Aa e aa

6
aa e aa

57

Tabela 5.2: Gen´etica

1

1

1
4

0

1
16

0

0

















1

2

3

4

5

6

2

3

0

1
2

0

1
4

0

0

0

0

0

1
8

0

0

4

0

1
4

1

1
4

1
4

0

5

0

0

0

1
4

1
2

0

6

0

0

0

1
16

1
4

1

















(b) Identiﬁque os estados absorventes.

(c) Escreva a matriz na forma canˆonica.

(d) Determine a matriz fundamental e o produto FR.

(e) Se dois pais com os genes Aa acasalarem, encontre o n´umero de pares de des-
cendentes com esses genes que podem ser esperados antes que o gene dominante
ou o gene recessivo n˜ao apare¸ca mais.

(f) Se dois pais com genes Aa acasalarem, encontre a probabilidade de que o gene

recessivo eventualmente desapare¸ca.

2 de destruir o seu alvo, o B tem probabilidade de 1

10. Trˆes carros de combate A, B e C v˜ao batalhar. O carro de combate A tem pro-
babilidade de 1
3 de destruir o
seu alvo, e o C tem probabilidade de 1
6 de destruir seu alvo. Os carros de combate
atiram ao mesmo tempo e cada um atira sempre no seu mais forte oponente ainda
n˜ao destru´ıdo. Usando como estados os carros sobreviventes em qualquer assalto
(etapa), estabele¸ca uma cadeia de Markov e responda as seguintes quest˜oes:

(a) Quantos estados tem essa cadeia?

(b) Quantos estados s˜ao absorventes?

(c) Determine o n´umero esperado de assaltos.

(d) Determine a probabilidade de que A sobreviva.

(e) Determine a probabilidade de que n˜ao haja sobreviventes.

58

5.3 Apˆendice 3 - Probabilidades Carros de Combate

A seguir mostraremos como construir as probabilidades de transi¸c˜ao do exerc´ıcio

dos carros de combate.

Nomearemos os carros de A, B e C e o estado onde n˜ao h´a nenhum dos carros

sobrevivendo de N.

Na simbologia abaixo a letra ”v”entre as letras que representam os carros de com-
bate signiﬁca que o carro anterior sobrevive ao tiro de carro posterior e a letra ”m”entre
as letras que representam os carros de combate signiﬁca que o carro anterior morre com
o tiro do carro posterior.

Lembre que os tiros s˜ao simultˆaneos e o tiro acontece sempre no mais forte oponente

vivo.

Assim para calcular as probabilidades de transi¸c˜ao, tendo como estados os carros

que sobrevivem a cada etapa, temos:

• ABC → ABC =

·

5
2
·
3
6
(cid:124) (cid:123)(cid:122) (cid:125)
Av(B e C)

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BvA

· 1

=

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

5
18

• ABC → AC =

·

5
2
·
3
6
(cid:124) (cid:123)(cid:122) (cid:125)
Av(B e C)

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BmA

· 1

=

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

5
18

• ABC → BC =

2
3
(cid:124)(cid:123)(cid:122)(cid:125)
AvB

·

·

1
6
(cid:124)(cid:123)(cid:122)(cid:125)
AmC

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BvA

+

· 1

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

·

1
3
(cid:124)(cid:123)(cid:122)(cid:125)
AmB

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BvA

=

· 1

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

4
18

• ABC → C =

• AC → AC =

2
3
(cid:124)(cid:123)(cid:122)(cid:125)
AvB

5
6
(cid:124)(cid:123)(cid:122)(cid:125)
AvC

·

·

1
·
6
(cid:124)(cid:123)(cid:122)(cid:125)
AmC

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
CvA

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BmA

· 1

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

+

1
·
3
(cid:124)(cid:123)(cid:122)(cid:125)
AmB

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
BmA

· 1

(cid:124)(cid:123)(cid:122)(cid:125)
C vive

=

4
18

=

5
12

• AC → A =

• AC → C =

• AC → N =

·

·

·

5
6
(cid:124)(cid:123)(cid:122)(cid:125)
AvC

1
6
(cid:124)(cid:123)(cid:122)(cid:125)
AmC

5
6
(cid:124)(cid:123)(cid:122)(cid:125)
AmC

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
CmA

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
CvA

1
2
(cid:124)(cid:123)(cid:122)(cid:125)
CmA

=

5
12

=

1
12

=

5
12

• BC → BC =

5
6
(cid:124)(cid:123)(cid:122)(cid:125)
BvC

·

2
3
(cid:124)(cid:123)(cid:122)(cid:125)
CvB

=

10
18

59

• BC → C =

• BC → B =

• BC → N =

1
6
(cid:124)(cid:123)(cid:122)(cid:125)
BmC

5
6
(cid:124)(cid:123)(cid:122)(cid:125)
BvC

1
6
(cid:124)(cid:123)(cid:122)(cid:125)
BmC

·

·

·

2
3
(cid:124)(cid:123)(cid:122)(cid:125)
CvB

1
3
(cid:124)(cid:123)(cid:122)(cid:125)
CmB

1
3
(cid:124)(cid:123)(cid:122)(cid:125)
CmB

=

2
18

=

5
18

=

1
18

Os estados onde apenas um dos carros sobrevive ou onde nenhum dos carros de
combate sobrevivem s˜ao absorventes.

60

5.4 Apˆendice 4 - Solu¸c˜oes

5.4.1

1o Bloco - No¸c˜oes B´asicas

Usaremos (·) como separador decimal nas solu¸c˜oes abaixo.

1.

a)

N˜ao representa uma cadeia de Markov, pois apesar

b)

Sim.

das entradas da matriz serem maiores ou iguais a

zero e menores do que 1, o somat´orio das entradas

das linhas da matriz n˜ao ´e igual a 1.

2
3

A

1
3

1

B

c)

Sim.

d)

N˜ao representa uma cadeia de Markov, pois existe

entrada maior do que 1.

1
4

A

3
4

1
2

B

1
2

2. Fazendo A = estado1, B=estado2 e C=estado3






a)

0 1
2
1
1
2
4
0 3
4






1
2
1
4
1
4






b)

0.3 0.7
0
0.5 0.1 0.4
0.8 0.2
0











c)

0.3
0

0.1
0.85
0.05 0.05

0.6
0.15
0.9






3.

a)

A probabilidade de transi¸c˜ao

b)

1a observa¸c˜ao [ 1

3 , 2
3 ]

c)

1a observa¸c˜ao [ 1

4 , 3
4 ]

p21.

2a observa¸c˜ao [0.28, 0.72]

2a observa¸c˜ao [0.27, 0.73]

4.

a)

A probabilidade de transi¸c˜ao

b)

1a observa¸c˜ao [0.1, 0.9]

c)

1a observa¸c˜ao [0.5, 0.5]

p12.

2a observa¸c˜ao [0.46, 0.54]

2a observa¸c˜ao [0.3, 0.7]

5. [0.4, 0.275, 0.625]

6. a = 0.4, b = 0.1 e c = 1

7.

8.

0a)

a)

b)

0.5185

c)

0.4398

d)

0.279

e)

0.198

b)

P =

(cid:34)

(cid:35)

0.7 0.3
0.6 0.4

c)

π(0) = [1, 0]

0.7

N

0.3

0.6

M

0.4

61

d)

Basta determinar o valor

de π(2) = π(0) · P 2 = 1
3

9.

0.11

R

07
0,

0.09

B

0

,

0

,

0

.

8

0

0

5

P

0, 11

0, 85

0.84

0.08

a)

c)

π(3) = [0.1057, 0.0554, 0.8388], logo
a probabilidade de se ter uma safra
boa em 1943, dado que a safra foi
boa em 1940 ´e de 10,57%.

b)

P =






0.08 0.07 0.85
0.09 0.11 0.80
0.11 0.05 0.84






10.

a)

Elevando a matriz de transi¸c˜ao dada a quarta potˆencia podemos ver que 26,03%

dos coelhos permanecem no estado 1 ap´os 4 semanas.

b)

Tomando o vetor π(0) = [9, 4, 0, 0] e multiplicando pela matriz encontrada no
item a temos que ap´os 4 semanas teremos a seguinte distribui¸c˜ao dos coelhos
[2.34, 2.62, 3.07, 4, 96].

5.4.2 2o Bloco - Vetor de probabilidade

1. Apenas a matriz do item c) n˜ao ´e regular.

2.

a)

[0.4, 0.6]

b)

[0.4615, 0.5385]

c)

[0.1687, 0.2289, 0.6024]

d)

[0.2540, 0.2222, 0.5238]

3. Basta elevar a matriz de transi¸c˜ao at´e n ≥ 24 numa aproxima¸c˜ao de 4 casas decimais

para que se chegue a distribui¸c˜ao estacion´aria de 30,77% da marca A, 46,15% marca B e

23,08% da marca C.

4.

a)

O parentesco de av´o acontece na se-

b)

gunda gera¸c˜ao, portanto basta elevar a

matriz de transi¸c˜ao ao quadrado. As-

sim temos que a probabilidade de que

uma av´o loira tenha uma neta morena

´e de 30%

i) [0.377, 0.375, 0.248]
ii) [0.35, 0.40, 0.25]

5.

6.

a)

P =






0.8 0.18 0.02
0.1
0.5
0.4
0.2
0.6
0.2






62

b)

Observando P 2 vemos que a probabili-

dade de que um neto de um concluinte

do ensino fundamental terminar a fa-

culdade ´e de 44%.

c)

Novamente observando P 2 temos que

d)

[0.5993, 0.3358, 0.0649]

a probabilidade pedida ´e de 38,2%.

e)

[0.6489, 0.2877, 0.0534]









a)

P =

0 1
2
3 0 1
1

1
2 0
1
3

3

1

1
4
0 1
3

4 0 1
2
2
3 0









b)

Como o vetor estacion´ario da matriz P
´e igual a [ 1
4 ], temos que a dis-
tribui¸c˜ao ﬁnal dos robˆos ser´a da por

3 , 1

4 , 1

6 , 1

[10, 15, 20, 15]

5.4.3

3o Bloco - Cadeias de Markov Absorventes

1.

a)

Estado 2

c)

Nenhum

b)

Estado 2

d)

Estado 2 e Estado 4

2. Apenas as matrizes dos itens a) e d) representam uma cadeia de Markov Absorvente

3.

a)

P =

b)

P =

c)

P =

d)

P =



























0.6 0.2 0.2
0
1
0
1
0
0




 ; F =

(cid:104)

(cid:105)

2.5




 ; F =

(cid:104)

(cid:105)

1.5

1
1
1
3
3
3
0 1 0
0 0 1

1
1
1
1
4
4
4
4
1
0 0 1
4
4
0 0 1 0
0 0 0 1

1
1
2 0 0
2
1
1
1
2 0
4
4
0 0 1 0
0 0 0 1

















; F =

(cid:35)

(cid:34) 4
1
3
3
0 1

; F =

(cid:35)

(cid:34)

3 2
1 2

63

e)

P =

f)

P =





















0.3 0.2 0.1 0.2 0.2
0.3 0.5 0.1
0.1
0
0
1
0
0
1
0
0
1
0
0
0

0
0
0
0

0.3 0.2 0.1 0.2 0.2
0.3 0.5 0.1
0.1
0
0
1
0
0
1
0
0
1
0
0
0

0
0
0
0





















(cid:34)

; F =

(cid:35)

1.47059 0.29412
0.14706 1.02941

; F =

(cid:34) 10
9
0

(cid:35)

185
999
5
3

4.

a)

f13 = 0.5 e f23 = 1

b)

f31 + f32 + f33 = 5 e f11 + f12 + f13 = 4

5. A matriz fundamental neste caso ser´a dada por F =






10
3
0
0

33
90
1
0






2365
900
645
90
75
9

a)

c)

Aproximadamente 2.63 anos

Aproximadamente 8.33 anos

b)

d)

Aproximadamente 7.17 anos

Um estudante, por sua inexperiˆencia,

n˜ao sabe direito, ou ainda pode modi-

ﬁcar sua op¸c˜ao em sua carreira. En-

quanto que um rec´em formado apenas

ir´a mudar de proﬁss˜ao se, de fato, n˜ao

se identiﬁca de jeito nenhum com sua

escolha ou se arranjar melhor remu-

nera¸c˜ao em outra, o mesmo vale para

o professor veterano.

(cid:34)

a)

F =

(cid:35)

6.536 26.144
3.268 42.484

c)

26.144 ciclos ou 78.43 dias

6.

7.

a)

2 estados. Graduar-se e Abandonam

b)

P =

b)

42.484 ciclos ou 127.45 dias.









P
S
G
A

0 0.75
0
0
0

0
0
0

0
0.9
1
0









0.25
0.1
0
1

c)

F =

(cid:34)

(cid:35)

1 0.75
0

1

d)

Neste caso temos que B =

(cid:34)

(cid:35)

0.675 0.375

0.9

0.1

portanto a probabilidade pedida ´e 67,5%.

64

8. A - autom´ovel; DC - Deixa de ir ao centro

a)

P =






A
V LT
DC

0.8
0.05
0

0.15 0.05
0.15
0.8
1
0






c)

F =

(cid:34)

6.154 4.615
1.538 6.154

(cid:35)

; B =

(cid:34)

(cid:35)

1
1

b)

5% .

d)

10.769 anos.

9.

a)

Sim. Basta levar em considera¸c˜ao as

b)

Estado 1 e estado 6.

leis de Mendell e lembrar de considerar

os casos inversos em cada casal.

c)

d)

F =

2

3

4

5

















1
2

0

1
4

0

0

0

2

3

4

5

1

6

0

0

1
16

0

0

0

1
4

1

1
4

1
4

0

0

0

0

1
4

1
2

0

0

1

1
4

0

1
16

0

1

0

6

0

0

1
16

1
4

0

1

























8
3
4
3
4
3
2
3

1
6
4
3
1
3
1
6

4
3
8
3
8
3
4
3









;

2
3
4
3
4
3
8
3









1

6

0.75 0.25
0.5
0.5
0.5
0.5
0.25 0.75









2
3
4
5

B =

e)

17
3 ou 5.6 gera¸c˜oes.

10.

a)

7 estados.

c)

t =

ABC
AB
BC











2.7363
1.7143
2.25

e)

Soma de todas as poss´ıveis absor¸c˜oes
efetuadas pelo estado (N) nenhum
sobrevivente 36.13%.

f)

50%

b)

4 estados.

d)

Soma de todas as poss´ıveis absor¸c˜oes
efetuadas pelo estado A 81.73%.

Cap´ıtulo 6

Anexos

Nestes anexos temos algumas deﬁni¸c˜oes e teoremas que foram usados ao longo
do texto e que s˜ao necess´arias para deﬁnir e operar os objetos associados as cadeias de
Markov. ´E composto por duas se¸c˜oes, uma dedicada a deﬁni¸c˜oes e teoremas associados a
´algebra, mais especiﬁcamente a ´algebra linear, e um outro, a conceitos associados `a teoria
da probabilidade.

6.1

´Algebra Linear

Usaremos como referˆencia para as deﬁni¸c˜oes e teoremas abaixo (HEFEZ e FER-
NANDEZ, 2016), livro texto do PROFMAT para ´algebra linear. Vamos come¸car deﬁnindo
o que ´e uma matriz.

Deﬁni¸c˜ao 6.1.1. Dados m e n em N, deﬁnimos uma matriz de ordem m por n,
ou simplesmente uma matriz m por n(escreve-se m × n), como uma tabela formada por
elementos de R distribu´ıdos em m linhas e n colunas. Estes elementos de R s˜ao chamados
de entradas da matriz.

´E usual indicarmos as entradas de uma matriz arbitr´aria A por Aij ou por aij,
onde os ´ındices indicam, nessa ordem, a linha e a coluna onde o elemento se encontra.
Assim uma matriz A de ordem m × n ´e usualmente representada por

A =









a11
a12
a21
a22
...
...
am1 am2

· · · a1n
· · · a2n
...
. . .
· · · amn









.

A depender dos valores de m e n, uma matriz m × n recebe um nome especial. De
fato, toda matriz 1 × n ´e denominada uma matriz linha e toda matriz m × 1 ´e denominada
matriz coluna. Uma matriz n × n ´e chamada de matriz quadrada de ordem n. Se A ´e uma

65

66

matriz quadrada de ordem n, as entradas aii, com 1 ≤ i ≤ n ,formam a diagonal principal
de A. Uma matriz cujas entradas s˜ao todas iguais a zero ´e chamada matriz nula.

Deﬁni¸c˜ao 6.1.2. Uma matriz diagonal de ordem n ´e uma matriz quadrada de ordem
n em que os elementos que n˜ao pertencem a diagonal principal s˜ao iguais a zero.

Deﬁni¸c˜ao 6.1.3. A matriz diagonal de ordem n cujas entradas da diagonal principal s˜ao
iguais ao n´umero 1, ´e chamada matriz identidade de ordem n e usualmente denotada
por In.

Seja M (m, n) o s´ımbolo que denota o conjunto das matrizes de ordem m × n.

Deﬁni¸c˜ao 6.1.4. Dizemos que duas matrizes A = [aij]m×n e B = [bij]m×n, de mesma
ordem, s˜ao iguais escrevendo A = B, quando aij = bij para todo 1 ≤ i ≤ m e para todo
1 ≤ j ≤ n.

Deﬁni¸c˜ao 6.1.5. Se A = [aij]m×n e B = [bij]m×n s˜ao duas matrizes de mesma ordem
m × n, a soma de A e B, denotada por A + B, ´e a matriz C = [cij] de ordem m × n
tal que cij = aij + bij, para todo 1 ≤ i ≤ m e para todo 1 ≤ j ≤ n.

Deﬁni¸c˜ao 6.1.6. Dada uma matriz A = [aij], deﬁne-se a matriz oposta de A, como
a matriz −A = [−aij].

A adi¸c˜ao de matrizes tamb´em tem propriedades semelhantes `a adi¸c˜ao nos n´umeros

reais, ou seja, associatividade, comutatividade, elemento neutro e elemento oposto.

Proposi¸c˜ao 6.1.1. Se A, B e C s˜ao matrizes de mesma ordem m × n, ent˜ao:

i) A + (B + C) = (A + B) + C (associatividade da adi¸c˜ao);

ii) A + B = B + A (comutatividade da adi¸c˜ao);

iii) A + 0 = A, onde 0 ´e a matriz nula m × n;

iv) A + (-A) = 0.

Todas as proposi¸c˜oes acima decorrem das deﬁni¸c˜oes de igualdade e de adi¸c˜ao de
matrizes feitas anteriormente, combinada com as respectivas propriedades que s˜ao v´alidas
no corpo dos n´umeros reais para cada uma das entradas.

Deﬁni¸c˜ao 6.1.7. Dada a matriz A = [aij]m×n, deﬁnimos o produto de A pelo n´umero
real k, como sendo a matriz kA = [kaij]m×n.

Tendo deﬁnido a opera¸c˜ao de adi¸c˜ao sobre o conjunto M (m, n), podemos deﬁnir a
opera¸c˜ao de subtra¸c˜ao da maneira usual, isto ´e: dada duas matrizes A e B em M (m, n),

A − B = A + (−B)

Proposi¸c˜ao 6.1.2. Para quaisquer A e B ∈ M (m, n), e a e b em R, temos que:

67

i) a · (A + B) = aA + aB;

ii) (a + b) · A = aA + bA;

iii) a · (bA) = (ab) · A;

iv) 1A = A.

As proposi¸c˜oes acima podem ser demonstradas diretamente atrav´es da deﬁni¸c˜ao

6.1.7 e das propriedades da multiplica¸c˜ao de n´umeros reais.

A seguir temos `a deﬁni¸c˜ao cl´assica da multiplica¸c˜ao de matrizes conforme Artur
Cayley(1821-1895) o fez em seu trabalho ”A Memoir on the Theory of Matrices”publicada
em 1858 na revista Philosophical Transactions of the Royal Society of London. Cayley
neste trabalho j´a notara, que assim deﬁnida, a multiplica¸c˜ao de matrizes era uma opera¸c˜ao
que n˜ao obedecia a lei do corte, nem tinha a propriedade comutativa, e ainda que uma
matriz n˜ao nula nem sempre era invert´ıvel, vejamos a deﬁni¸c˜ao:

Deﬁni¸c˜ao 6.1.8. Sejam A = [aij]m×n e B = [bij]n×p duas matrizes. O produto AB, de
A por B, nesta ordem, ´e deﬁnido como a matriz C = [cij]m×p tal que

cij =

n
(cid:88)

k=1

aikbkj = ai1 + b1j + · · · + ainbnj

Para todo 1 ≤ i ≤ m e para todo 1 ≤ j ≤ p.

Note que, para o produto entre as matrizes A e B estar deﬁnido ´e necess´ario que

o n´umero de colunas de A seja igual ao n´umero de linhas de B.

Proposi¸c˜ao 6.1.3. Sejam A, B e C matrizes, desde que as opera¸c˜oes sejam poss´ıveis,
temos que:

i) A · (B + C) = AB + AC;

ii) (A + B) · C = AC + BC;

iii) (AB) · C = A · (BC);

iv) IA = AI = A, onde I ´e a matriz identidade.

Deﬁnida a multiplica¸c˜ao de matrizes, deﬁnimos a potencia¸c˜ao de matrizes da se-

guinte maneira. Sejam A ∈ M (n, n) e k ∈ N, com k ≥ 2 temos que:

A0 = In,

A1 = A

e

Ak = A · A · · · A
(cid:125)

(cid:123)(cid:122)
kf atores

(cid:124)

68

Deﬁni¸c˜ao 6.1.9. Dada uma matriz A = [aij]m×n chamamos de transposta de A, e
denotamos por At, matriz [bij]n×m, onde bij = aji, ∀i tal que 1 ≤ i ≤ n e ∀j tal que
1 ≤ j ≤ n.

Uma matriz quadrada A ´e chamada sim´etrica se At = A e antissim´etrica se At =

−A

Uma matriz A ´e chamada de uma matriz em blocos se A est´a subdividida em matri-
zes menores, chamadas blocos. Esta subdivis˜ao geralmente ´e feita por linhas horizontais
e verticais, vejamos um exemplo:

P =











2 −1
1 −2
0
0

3
9
1

2 0
1 1
6 7

1 −1 −1 9 1
0 1
0
0

0











Uma propriedade interessante da parti¸c˜ao de uma matriz em blocos ´e que o resul-
tado das opera¸c˜oes de adi¸c˜ao e multiplica¸c˜ao com matrizes em blocos, podem ser obtidos
efetuando o c´alculo com os blocos, como se os mesmos fossem elementos da matriz.

Deﬁni¸c˜ao 6.1.10. Dada uma matriz quadrada A de ordem n, chamamos de inversa de
A a uma matriz quadrada B de ordem n tal que AB = BA = In.

Note que nem toda matriz quadrada possui inversa. Basta observa que a matriz
quadrada nula de ordem n multiplicada por uma matriz quadrada X qualquer de ordem
n ser´a sempre diferente de In.

(cid:34)

A =

(cid:35)

Mesmo matrizes n˜ao nulas podem n˜ao ter inversa, como por exemplo a matriz
1 1
1 1

n˜ao possui inversa, pois n˜ao existe uma matriz quadrada B de ordem 2,

tal que AB = I2.

Uma matriz quadrada A ´e chamada invert´ıvel se A admite uma matriz inversa.

Teorema 6.1.1. Se uma matriz A possui uma inversa, ent˜ao essa inversa ´e ´unica.

Demonstra¸c˜ao. De fato, suponhamos que B e C s˜ao inversas de uma matriz A de ordem
n. Ent˜ao AB = In e AC = In pela proposi¸c˜ao 1.1.3, temos que:

C = C · In = C(AB) = (CA)B = In · B = B

(cid:4)

Como, se existir, a inversa de uma matriz A ´e ´unica, escrevemos A−1 para denotar

a inversa de A.

69

Deﬁni¸c˜ao 6.1.11. Equa¸c˜ao Linear nas inc´ognitas x1, x2, . . . , xn ´e toda equa¸c˜ao do tipo:
a1x1 + a2x2 + · · · + anxn = b em que a1, a2, . . . , an e b s˜ao coeﬁcientes reais. Chamamos
b de coeﬁciente(ou termo) independente da equa¸c˜ao.

Uma equa¸c˜ao linear ´e chamada de homogˆenea quando seu termo independente ´e

igual a zero.

Deﬁni¸c˜ao 6.1.12. Sistema Linear ´e o conjunto Sm×n formado por m equa¸c˜oes lineares
e n inc´ognitas, que pode ser indicado da seguinte maneira:

S =






a11x1 + a12x2 + a13x3 + · · · + a1nxn = b1
a21x1 + a22x2 + a23x3 + · · · + a2nxn = b2
a31x1 + a32x2 + a33x3 + · · · + a3nxn = b3
...
am1x1 + am2x2 + am3x3 + · · · + amnxn = bm

. . .

...

...

...

...

onde os aij’s e bi’s, para 1 ≤ i ≤ m e 1 ≤ j ≤ n, s˜ao n´umeros reais dados.

Deﬁni¸c˜ao 6.1.13. A solu¸c˜ao de um sistema linear m×n ´e toda ˆenupla (α1, α2, α2, . . . , αn) ∈
Rn que ´e solu¸c˜ao de cada uma das m equa¸c˜oes desse sistema.

Vale lembrar que um sistema linear pode ter conjunto solu¸c˜ao vazio e neste caso o
sistema linear ´e chamado de imposs´ıvel. No caso em que seu conjunto solu¸c˜ao ´e unit´ario
chama-se de poss´ıvel e determinado. Ou ainda, se o conjunto solu¸c˜ao tiver inﬁnitos ele-
mentos ´e chamado de poss´ıvel e indeterminado.

Determinar ou descrever o mais explicitamente poss´ıvel a solu¸c˜ao de um sistema
linear ´e a tarefa fundamental que temos quando nos deparamos com os mesmos. Desde
a antiguidade as mais diversas ´areas do conhecimento modelam problemas do cotidiano
atrav´es de sistemas lineares.

Para resolver um sistema linear utilizamos uma s´erie de transforma¸c˜oes elementares
para simpliﬁcar o sistema de modo que possamos explicitar sua solu¸c˜ao. Chamamos de
transforma¸c˜oes elementares as seguintes opera¸c˜oes:

i ) Trocar a posi¸c˜ao relativa de duas equa¸c˜oes do sistema;

ii ) Trocar uma equa¸c˜ao pela soma membro a membro da pr´opria equa¸c˜ao com um

m´ultiplo de outra;

iii ) Trocar uma equa¸c˜ao dada por um de seus m´ultiplos, ou seja, multiplicar ambos os

membros da equa¸c˜ao por um n´umero real n˜ao-nulo.

Dizemos que dois sistemas lineares s˜ao sistemas equivalentes, se pudermos obter
um sistema do outro a partir de uma sequˆencia ﬁnita de transforma¸c˜oes lineares. Observe

70

que esta rela¸c˜ao entre dois sistemas ´e uma rela¸c˜ao de equivalˆencia(reﬂexiva, transitiva e
sim´etrica), portanto sistemas lineares equivalentes possuem mesmo conjunto solu¸c˜ao.

´E importante salientar que estas transforma¸c˜oes elementares nos permitem de-
terminar, se existir, a solu¸c˜ao de um sistema linear qualquer, por´em a medida que `a
quantidade de equa¸c˜oes e inc´ognitas aumentam, este processo se torna muito trabalhoso.
O que h´a de essencial em um sistema de equa¸c˜oes lineares s˜ao os seus coeﬁcientes.
Sejam os vetores (am1, am2, . . . , amn, bm) ∈ Rn+1 que representam os coeﬁcientes de um
sistema S, acrescido do seu termo independente. Se os organizarmos em linhas, teremos
a matriz ampliada associada ao sistema S:












a13
a12
a11
a23
a22
a21
a33
a32
a31
...
...
...
am1 am2 am3

· · · a1n
· · · a2n
· · · a3n
...
. . .
· · · amn












b1
b2
b3
...
bm

Quando o sistema de equa¸c˜oes lineares ´e homogˆeneo, a matriz associada `a ele
cont´em apenas os seus coeﬁcientes, eliminando-se a coluna de zeros da direita da matriz.
Sendo assim podemos representar um sistema de equa¸c˜oes lineares, de modo per-

feito, atrav´es da equa¸c˜ao matricial AX = B, onde:

A =












a13
a12
a11
a23
a22
a21
a33
a32
a31
...
...
...
am1 am2 am3

· · · a1n
· · · a2n
· · · a3n
...
. . .
· · · amn












, X =























x1
x2
x3
...
xn

e B =























b1
b2
b3
...
bm

As matrizes A, X e B s˜ao chamadas, respectivamente, de matriz dos coeﬁcientes

do sistema, matriz das inc´ognitas, matriz dos termos independentes.

Note que com a forma matricial de um sistema linear, ganhamos mais uma maneira
de determinar sua solu¸c˜ao caso a matriz inversa da matriz dos coeﬁcientes exista, pois
pela deﬁni¸c˜ao de matriz inversa e pela proposi¸c˜ao 6.1.3, temos:

AX = B ⇒ X = (A−1A)X = A−1(AX) = A−1B

Um fato importante sobre a forma matricial de um sistema linear ´e que se tivermos
uma forma de caracterizar quando uma matriz ´e invert´ıvel, temos uma forma eﬁciente de
determinar quando um sistema linear possui ou n˜ao uma solu¸c˜ao, o que j´a ´e um avan¸co
na tentativa de solucionar o mesmo. Para isso precisamos do conceito do determinante
de uma matriz, que iremos deﬁnir a seguir.

71

Foi Colin Maclaurin(1698-1746) em seu trabalho de t´ıtulo Um Tratado sobre ´Algebra
em Trˆes Partes, publicado em 1748 quem pela primeira vez utilizou o que chamamos hoje
de Regra de Cramer, para resolver sistemas com at´e 4 inc´ognitas e 4 equa¸c˜oes. Entretanto
foi Gabriel Cramer(1704-1752) quem generalizou seu m´etodo, por isso a regra ´e chamada
de Cramer at´e os dias de hoje. Apenas a t´ıtulo de ilustra¸c˜ao e motiva¸c˜ao do conceito de
determinante, vejamos como ele extraiu seu teorema para os casos onde os sistemas s˜ao
2 × 2 e 3 × 3. Sejam

(cid:40)

S1 =

ax + by = e
cx + dy = f

e S2 =






ax + by + cz = m
dx + ey + f z = n
gx + hy + kz = p

Aplicando as transforma¸c˜oes lineares adequadas Maclaurin, descobriu que a solu¸c˜ao

de sistema S1, se ad − bc (cid:54)= 0 era igual a:

x =

ed − f b
ad − bc

,

y =

af − ce
ad − bc

E que se aek − ahf + dhc − dbk + gbf − gec (cid:54)= 0 a solu¸c˜ao de S2 seria dada por:

x =

mek − mf h + bf p − bnk + cnh − cep
aek − ahf + dhc − dbk + gbf − gec

,

y =

nak − ncg + mf g − mdk + pcd − paf
aek − ahf + dhc − dbk + gbf − gec

e

z =

aep − ahn + dhm − dbp + gbn − gem
aek − ahf + dhc − dbk + gbf − gec

.

Maclaurin notou que, tanto para S1 como para S2 o numerador que aparece nas
solu¸c˜oes s˜ao os mesmos e que consiste na soma alternada de v´arios produtos dos coeﬁcien-
tes das inc´ognitas do sistema. Outro fato que ele observou ´e que os numeradores tamb´em
s˜ao somas alternadas de produtos dos coeﬁcientes das demais inc´ognitas e dos termos
independentes do sistema. Os numeradores e denominadores nas solu¸c˜oes de Maclaurin
foi o que motivou o conceito de determinantes que temos hoje, termo introduzido por
Gauss em 1801. A deﬁni¸c˜ao formal para o determinante, ou melhor, para a fun¸c˜ao deter-
minante de uma matriz quadrada A de ordem n, ´e um pouco mais elaborada e depende
de outras deﬁni¸c˜oes que daremos a seguir seguindo os passos que podem ser encontrados
em (ANTON, 2001).

Deﬁni¸c˜ao 6.1.14. Dados n objetos distintos a1, . . . , an uma permuta¸c˜ao destes objetos
consiste em dispˆo-los em uma determinada ordem.

A quantidade de permuta¸c˜oes de n objetos distintos ´e dada por n!, que ´e lido como

n fatorial e n! = n · (n − 1) · (n − 2) . . . 3 · 2 · 1 se n > 0 e deﬁne-se ainda que 0! = 1.

72

Deﬁni¸c˜ao 6.1.15. Dada uma permuta¸c˜ao dos inteiros 1, 2, . . . , n existe uma invers˜ao
quando um inteiro precede outro menor do que ele.

Uma permuta¸c˜ao de n´umeros inteiros ser´a classiﬁcado como par se o seu n´umero
de invers˜oes for par e ser´a classiﬁcada como ´ımpar se o seu n´umero de invers˜oes for ´ımpar.
Para ilustrar a deﬁni¸c˜ao acima observe a tabela abaixo que nos mostra o n´umero

de invers˜oes e sua classiﬁca¸c˜ao para cada permuta¸c˜ao dos n´umeros 1,2 e 3.

Tabela 6.1: N´umero de invers˜oes

Permuta¸c˜ao Node invers˜oes Classiﬁca¸c˜ao
0
1
1
2
2
3

Par
´Impar
´Impar
Par
Par
´Impar

(123)
(132)
(213)
(231)
(312)
(321)

Deﬁni¸c˜ao 6.1.16. Seja a matriz quadrada A = [aij] de ordem n, dizemos que um produto
de n entradas de A, tais que n˜ao h´a duas entradas de mesma linha ou de mesma coluna
de A, de um produto elementar da matriz A.

Observe que a quantidade de produtos elementares de uma matriz quadrada de or-
dem n ser´a dado por n!, visto que pela deﬁni¸c˜ao acima cada uma das escolhas que ﬁzermos
para um produto elementar estar´a associada uma permuta¸c˜ao das n colunas (ou linhas)
da matriz. Assim esses produtos s˜ao da forma a1j1a2j2 . . . anjn, onde (j1, j2, j3, . . . , jn) ´e
uma permuta¸c˜ao do conjunto {1, 2, . . . , n}.

Um produto elementar a1j1a2j2 . . . anjn multiplicado por +1 ou −1 ´e chamado de
produto elementar com sinal. Usamos o sinal (+) se (j1, j2, j3, . . . , jn) ´e uma permuta¸c˜ao
par e o sinal de (−) no caso contr´ario.

Deﬁni¸c˜ao 6.1.17. Seja A uma matriz quadrada de ordem n. A fun¸c˜ao determinante
que associa a cada matriz A um n´umero chamado determinante de A, ´e denotada por
det(A) ou |A| e ´e deﬁnida como a soma de todos os produtos elementares com sinal de A.

Note que o c´alculo de determinantes para matrizes de ordem maiores que 3 n˜ao ´e
uma tarefa muito simples de computar dado que, por exemplo, para calcular o determi-
nante de uma matriz de ordem 6, pela deﬁni¸c˜ao, precisar´ıamos fazer 6!=720 produtos e
depois efetuar a soma dessas 720 parcelas. A seguir temos algumas propriedades sobre
o determinante de uma matriz que ir´a nos ajudar a provar alguns resultados sobre as
Cadeias de Markov.

73

Proposi¸c˜ao 6.1.4. Seja A uma matriz quadrada de ordem n, se todos os elementos de
uma linha (ou coluna) de A forem iguais `a zero ent˜ao det(A) = 0.

Demonstra¸c˜ao. Basta observar que se todos os elementos de uma linha (ou coluna) s˜ao
iguais a zero ent˜ao todos os produtos elementares sempre ter˜ao um fator igual a zero, logo
todos os produtos elementares ser˜ao iguais a zero e portanto pela deﬁni¸c˜ao do determi-
(cid:4)
nante temos det(A) = 0.

Proposi¸c˜ao 6.1.5. O determinante da matriz identidade In ´e igual a 1 para todo n.

Demonstra¸c˜ao. Lembre que a matriz identidade In tem todas as suas entradas iguais a
zero exceto `a sua diagonal principal, que tem entradas iguais a 1. Assim todos os produtos
elementares de In ser˜ao iguais a zero pois ter˜ao um fator igual a zero, exceto o produto
elementar formado pelos elementos de sua diagonal principal que neste caso ´e igual a 1.
Como na diagonal principal `a permuta¸c˜ao formada pelos n´umeros das suas colunas, tem
(cid:4)
zero invers˜oes, isto ´e, ´e uma permuta¸c˜ao par, temos det(In) = 1

Teorema 6.1.2. Sejam A e B matrizes de ordem n × n quaisquer, ent˜ao o determinante
do produto de A e B ´e igual ao produto entre os determinantes de A e de B, ou seja,
det(A · B) = det(A) · det(B).

A demonstra¸c˜ao desse teorema requer uma s´erie de resultados sobre matrizes ele-
mentares, al´em de resultados associados ao escalonamento de matrizes, ´e uma prova muito
bonita, por´em muito extensa e foge ao escopo desse trabalho. O leitor que tiver interesse
pode consultar (BOLDRINI, 1980, p. 84).

Teorema 6.1.3. Seja A uma matrizes de ordem n × n quaisquer, dizemos que A ´e uma
matriz invert´ıvel se det(A) (cid:54)= 0.

Demonstra¸c˜ao. Sabemos que por deﬁni¸c˜ao A.A−1 = In, aplicando o determinante a ambos
os membros dessa igualdade temos det(A.A−1) = det(In), como vimos na proposi¸c˜ao 6.1.5
det(In) = 1, para todo n. Pelo teorema 6.1.2 temos que det(A.A−1) = det(A).det(A−1),
logo det(A−1) = 1
det(A). Assim det(A−1), s´o existe, se det(A) (cid:54)= 0. Portanto A ´e invert´ıvel
(cid:4)
quando det(A) (cid:54)= 0

Com o teorema acima encerramos os resultados relacionados a ´algebra linear, que
s˜ao necess´arios para desenvolver os conceitos e resultados associados as Cadeias de Mar-
kov.

Vale salientar, que a resolu¸c˜ao de um sistema linear de equa¸c˜oes, ou a determina¸c˜ao
de uma matriz inversa, ou o c´alculo de determinantes s˜ao tarefas que para matrizes de
ordem muito grande, e muito grande nesse caso seria algo em torno de 6 ou 7, o uso de
alguma ferramenta computacional ´e indispens´avel para efetuar tais tarefas com sucesso.

74

No caso do c´alculo de determinantes a expans˜ao de Laplace ´e um m´etodo interes-
sante para trabalhar com matrizes de ordem 4, mas se torna invi´avel para matrizes de
ordem maiores que 4, pois seu custo computacional cresce muito. O mesmo vale para
a regra de Cramer na resolu¸c˜ao de sistemas, que apesar de ser uma f´ormula eﬁcaz para
resolver sistemas lineares tem um custo computacional tamb´em muito grande at´e mesmo
para computadores atuais. Vale o mesmo coment´ario para a determina¸c˜ao da matriz
inversa atrav´es do seu determinante e sua matriz adjunta, o custo computacional para
efetuar as contas ´e muito alto.

Por isso ´e necess´ario que ao trabalhar com as Cadeias de Markov, se tenha acesso ao
Geogebra para auxiliar os c´alculos. Pois a quantidade de contas necess´arias pode acabar
entediando os estudantes e prejudicando o foco nos resultados associados as cadeias. Na
pr´oxima se¸c˜ao deﬁniremos os conceitos e resultados b´asicos associados a probabilidade
que s˜ao essenciais para o desenvolvimento das Cadeias de Markov.

6.2 Probabilidade

Usaremos (DANTAS, 2013) e (MORGADO e CARVALHO, 2015) como fontes
bibliogr´aﬁcas para as deﬁni¸c˜oes e teoremas desta se¸c˜ao. Al´em disso, como j´a ﬁzemos no
caso da ´algebra linear, vamos apenas deﬁnir e mostrar aquilo que nos parece imprescind´ıvel
a compreens˜ao das cadeias de Markov. Comecemos ent˜ao com a deﬁni¸c˜ao de experimento
aleat´orio.

Deﬁni¸c˜ao 6.2.1. Experimentos que ao serem repetidos nas mesmas condi¸c˜oes, n˜ao pro-
duzem o mesmo resultado s˜ao denominados experimentos aleat´orios.

´E importante ao falar sobre experimentos aleat´orios nas aulas de matem´atica no
ensino m´edio, fazer a contraposi¸c˜ao dessa deﬁni¸c˜ao com a de experimento determin´ıstico
muito utilizada nas ciˆencias naturais e na maioria das vezes utilizando apenas o termo
experimento para design´a-lo, o que pode confundir os estudantes e j´a criar um obst´aculo
cognitivo na aprendizagem do assunto.

Deﬁni¸c˜ao 6.2.2. Chamamos de espa¸co amostral associado a um experimento o con-
junto de seus resultados poss´ıveis. Denotaremos com a letra grega Ω o espa¸co amostral.

Deﬁni¸c˜ao 6.2.3. Chamamos de evento a todo resultado ou subconjunto de resultados
de um experimento.

Vale lembrar que um evento ´e representado por um subconjunto do conjunto que
forma o espa¸co amostral. Os eventos representados por um conjunto unit´ario ser˜ao cha-
mados de eventos simples. Um evento que nunca ocorre ´e chamado de evento imposs´ıvel,
um evento que sempre ocorre ´e chamado de evento certo.

75

Sendo o espa¸co amostral um conjunto e os eventos associados a ele subconjuntos,

podemos fazer opera¸c˜oes entre os eventos.

Deﬁni¸c˜ao 6.2.4. A reuni˜ao de dois eventos A e B, denotada A ∪ B, ´e o evento que
ocorre se pelo menos um deles ocorre.

Deﬁni¸c˜ao 6.2.5. A intersec¸c˜ao de dois eventos A e B, denotada A ∩ B, ´e o evento que
ocorre se ambos ocorrem.

Deﬁni¸c˜ao 6.2.6. O complementar do evento A, denotado A, ´e o evento que ocorre
quando A n˜ao ocorre.

Deﬁni¸c˜ao 6.2.7. A diferen¸ca de dois eventos A e B, denotado A\B, ´e o evento em que
ocorre A e n˜ao ocorre B.

Deﬁni¸c˜ao 6.2.8. Dizemos que o evento A implica o evento B, que denotamos A ⊂ B,
se para todo a ∈ A tivermos que a ∈ B.

Dizer que o evento A implica o evento B signiﬁca dizer que a ocorrˆencia de A

garante `a ocorrˆencia de B.

Os eventos A e B s˜ao iguais se A ⊂ B e B ⊂ A.

Deﬁni¸c˜ao 6.2.9. Os eventos A e B s˜ao ditos mutuamente excludentes, se eles n˜ao
podem ocorrer simultaneamente, ou seja, se A ∩ B = ∅.

As opera¸c˜oes acima deﬁnidas, est˜ao relacionadas as an´alogas opera¸c˜oes com con-
juntos e gozam das mesmas propriedades. Podemos agora deﬁnir o que ´e a probabilidade
de evento num espa¸co amostral Ω.

Deﬁni¸c˜ao 6.2.10. Probabilidade ´e uma fun¸c˜ao deﬁnida numa classe F de eventos de
Ω que satisfaz as seguintes condi¸c˜oes:

a) P (A) ≥ 0 para todo A ∈ F;

b) Se (An)n≥1 ´e uma sequˆencia de eventos de (F ), que s˜ao mutuamente excludentes,

ent˜ao: P (∪k

n=1An) =

k
(cid:88)

n=1

P (An), com k ∈ N;

c) P (Ω) = 1

´E relevante dizer que a deﬁni¸c˜ao de probabilidade busca uma forma eﬁcaz de
associar n´umeros aos eventos(conjuntos). E as propriedades abaixo nos mostram como
ocorre a rela¸c˜ao entre as opera¸c˜oes dos eventos e a aritm´etica dos n´umeros associados a
eles, ou seja, suas probabilidades. Vejamos como isso acontece.

Proposi¸c˜ao 6.2.1. Denotemos por φ o evento imposs´ıvel. Temos P (φ) = 0.

76

Demonstra¸c˜ao. Note que P (Ω) = P (Ω ∪ φ), como o evento certo e o evento imposs´ıvel
s˜ao mutuamente excludentes, por deﬁni¸c˜ao temos que P (Ω ∪ φ) = P (Ω) + P (φ). Assim
(cid:4)
por transitividade P (Ω) = P (Ω) + P (φ), logo P (φ) = 0.

Proposi¸c˜ao 6.2.2. Seja A ⊂ Ω um evento e A seu evento complementar. Temos que
P (A) = 1 − P (A).

Demonstra¸c˜ao. Pelo item c) da deﬁni¸c˜ao 6.2.10 P (Ω) = 1, sabemos ainda que A ∪ A = Ω,
portanto P (Ω) = P (A ∪ A) = 1, como A e A s˜ao mutuamente excludentes, pelo item b)
(cid:4)
da deﬁni¸c˜ao de probabilidade temos P (A) + P (A) = 1, logo P (A) = 1 − P (A).

Proposi¸c˜ao 6.2.3. Sejam A e B dois eventos do espa¸co amostral Ω. Temos que P (A\B) =
P (A) − P (A ∩ B).

Demonstra¸c˜ao. Note que (A\B) ∪ (A ∩ B) = A. Assim P [(A\B) ∪ (A ∩ B)] = P (A). Mas
(A\B) e (A ∩ B) s˜ao eventos mutuamente excludentes, portanto P (A\B) + P (A ∩ B) =
(cid:4)
P (A) o que equivale a P (A\B) = P (A) − P (A ∩ B).

Proposi¸c˜ao 6.2.4. Se A e B ⊂ Ω ent˜ao P (A ∪ B) = P (A) + P (B) − P (A ∩ B).

Demonstra¸c˜ao. Temos que P (A ∪ B) = P [(A\B) ∪ B] = P (A\B) + P (B), pois A\B e
B, s˜ao mutuamente excludentes. Pela Proposi¸c˜ao 6.2.3 sabemos que P (A\B) = P (A) −
(cid:4)
P (A ∩ B), da´ı conclu´ımos que P (A ∪ B) = P (A) + P (B) − P (A ∩ B).

Proposi¸c˜ao 6.2.5. Se B ⊂ A ent˜ao P (B) ≤ P (A).

Demonstra¸c˜ao. Como P (A\B) = P (A) − P (A ∩ B), se B ⊂ A resulta que P (A\B) =
(cid:4)
P (A) − P (B). Como P (A\B) ≥ 0 temos P (B) ≤ P (A).

A seguir vamos deﬁnir o que ´e probabilidade condicional e enunciar dois teoremas

importantes usados nas Cadeias de Markov.

Deﬁni¸c˜ao 6.2.11. Sejam A e B dois eventos de Ω, supondo P (A) > 0, a probabilidade
condicional de B dado que a A acontece ´e deﬁnida por:

P (B|A) =

P (A ∩ B)
P (A)

. Observe que podemos reescrever a equa¸c˜ao da deﬁni¸c˜ao acima da seguinte maneira:
P (A ∩ B) = P (B|A) · P (A).

Teorema 6.2.1. Sejam A1, A2, . . . , An eventos do espa¸co amostral Ω, onde est´a deﬁnida
a probabilidade P , tem-se:

P (A1 ∩ A2, . . . An) = P (A1) · P (A2|A1) · P (A3|A1 ∩ A2) . . . P (An|A1 ∩ A2 . . . An−1) (6.1)

77

Demonstra¸c˜ao. Vamos demonstrar por indu¸c˜ao ﬁnita. Para n = 2 o teorema se reduz
a deﬁnic˜ao de probabilidade condicional que ´e verdadeira. Suponha que a senten¸ca seja
v´alida para n − 1 eventos, ou seja, P (A1 ∩ A2 . . . An−1) = P (A1) · P (A2|A1) · P (A3|A1 ∩
A2) . . . P (An−1|A1 ∩ A2 . . . An−2) devemos mostrar que ela vale para n eventos:
De fato, aplicando a deﬁni¸c˜ao 6.2.11 aos eventos A1 ∩ A2, . . . An−1 e An, temos:
P (A1 ∩ A2, . . . An) = P (A1 ∩ A2 . . . An−1) · P (An|A1 ∩ A2 . . . An−1), por ﬁm aplicamos a
(cid:4)
hip´otese de indu¸c˜ao e chegamos a equa¸c˜ao 6.1.

Teorema 6.2.2 (Teorema das Probabilidades Totais). Sejam B1, B2, . . . , Bn uma parti¸c˜ao
do espa¸co amostral Ω, isto ´e, esses eventos s˜ao mutuamente excludentes e sua reuni˜ao ´e
Ω, seja A um evento e P uma probabilidade deﬁnida nos eventos de Ω, temos:

P (A) =

n
(cid:88)

k=1

P (A|Bk)P (Bk).

Demonstra¸c˜ao. Como Ω = (cid:83)n

k=1 Bk e A = A ∩ Ω = A ∩ ((cid:83)n

Calculando-se a probabilidade A obtemos: P (A) =

k=1 Bk) = (cid:83)n
P (A ∩ Bk), para ﬁnalizar bastar

k=1 A ∩ Bk.

n
(cid:88)

aplicar a deﬁni¸c˜ao 6.2.11 em P (A ∩ Bk) e chegamos a igualdade desejada.

k=1

(cid:4)

Teorema 6.2.3 (Teorema de Bayes). Seja B um evento e A1 e A2 uma parti¸c˜ao do espa¸co
amostral Ω. Seja P uma probabilidade deﬁnida nos eventos de Ω. Temos para i = 1, 2:

P (Ai|B) =

P (Ai)P (B|Ai)
P (A1)P (B|A1) + P (A2)P (B|A2)

.

Demonstra¸c˜ao. Pela deﬁni¸c˜ao de probabilidade condicional temos:

P (Ai|B) =

P (Ai ∩ B)
P (B)

Da´ı, basta escrever P (Ai ∩ B) = P (Ai)P (B|Ai) e escrever P (B) utilizando o teorema das
(cid:4)
probabilidades totais 6.2.2 para concluir a demonstra¸c˜ao.

Vale lembrar que o teorema de Bayes continua v´alido quando se considera uma
parti¸c˜ao ﬁnita do espa¸co amostral Ω, isto ´e, se A1, A2, . . . , An ´e uma parti¸c˜ao de Ω e B ´e
um evento de Ω, ent˜ao, para todo i, tal que 1 ≤ i ≤ n e n ∈ N, tem-se:

P (Ai|B) =

P (B|Ai)P (Ai)
k=1 P (B|Ak)P (Ak)

(cid:80)n

Para ver a demonstra¸c˜ao dessa generaliza¸c˜ao o leitor pode consultar (DANTAS,
2013, p. 48). A seguir temos `a deﬁni¸c˜ao de quando dois eventos de uma espa¸co amostral
s˜ao independentes.

78

Deﬁni¸c˜ao 6.2.12. Sejam A e B dois eventos de espa¸co amostral Ω e suponha P (A) > 0.
O evento B ´e dito independente do evento A se P (B|A) = P (B).

Note que esta deﬁni¸c˜ao vem da ideia de que se os eventos A e B s˜ao independentes,
isto signiﬁca que a probabilidade de B n˜ao se altera com a ocorrˆencia de A. Temos ainda
que se os eventos A e B s˜ao independentes ent˜ao P (A ∩ B) = P (A) · P (B). Outro fato
importante sobre a independˆencia de eventos ´e sua simetria, ou seja, se B n˜ao depende de
A ent˜ao A n˜ao depende de B, para mostrar isso basta utilizar a deﬁni¸c˜ao 6.2.11, vejamos:

P (A|B) =

P (A ∩ B)
P (B)

=

P (A) · P (B)
P (B)

= P (A)

Observe que podemos aﬁrmar pelos resultados anteriores que A ´e independente
de B se, e somente se, P (A ∩ B) = P (A) · P (B). Para ﬁnalizar iremos deﬁnir quando
n eventos s˜ao independentes, para n igual a um inteiro positivo e o que s˜ao vari´aveis
aleat´orias discretas um dos conceitos necess´arios para a deﬁni¸c˜ao das Cadeias de Markov.

Deﬁni¸c˜ao 6.2.13. Os eventos A1, A2, . . . , An s˜ao independentes se: P (Ai1 ∩ Ai2 ∩
. . . ∩ Aik) = P (Ai1) · P (Ai2) . . . P (Aik) para todo k = 2, 3, . . . n e todo {i1, i2, . . . , ik} ⊂
{1, 2, . . . , n} tal que i1 ≤ i2 ≤ . . . ≤ ik.

Deﬁni¸c˜ao 6.2.14. Uma vari´avel aleat´oria ´e uma fun¸c˜ao deﬁnida num espa¸co amos-
tral, que assume valores reais.

Deﬁni¸c˜ao 6.2.15. As vari´aveis aleat´orias que assumem valores em um conjunto enu-
mer´avel ser˜ao denominadas discretas e aquelas que assumem valores num intervalo da
reta real ser˜ao denominadas cont´ınuas.

Referˆencias Bibliogr´aﬁcas

[1] Anton, H., e Rorres, C. ´Algebra Linear com aplica¸c˜oes, 8 ed. Porto Alegre,

Bookman, 2001.

[2] Boldrini, J. L., et al. ´Algebra Linear, 3 ed. S˜ao Paulo, Harper e Row do Brasil,

1980.

[3] Dantas, C. A. B. Probabilidade: Um curso introdut´orio, 3 ed. S˜ao Paulo, Edusp,

2013.

[4] Grimstead, C. M., e Snell, J. L. Introduction to Probability, 2 ed. Rhode Island,

AMS-American Matemathical Society, 1997.

[5] Hayes, B. First link in Markov Chain. www.americanscientist.org/article/ﬁrst-

links-in-the-markov-chain, Acessado em 06-03-2019.

[6] Hefez, A., e Fernandez, C. S. Introdu¸c˜ao `a ´algebra linear, 2 ed. Rio de Janeiro,

SBM - Sociedade Brasileira de Matem´atica, 2016.

[7] Hillier, F. S., e Lieberman, G. J. Introdu¸c˜ao `a pesquisa operacional, 9 ed. Porto

Alegre, AMGH Editora, 2013.

[8] Lay, D. C. ´Algebra Linear e sua aplica¸c˜oes, 2 ed. Rio de Janeiro, LTC, 1999.

[9] Morgado, A. C., e Carvalho, P. C. P. Matem´atica Discreta, 2 ed. Rio de

Janeiro, SBM - Sociedade Brasileira de Matem´atica, 2015.

[10] O’Connor, J. J., e Robertson, E. F. Andrei Andreyevich Markov. http://www-
history.mcs.st-andrews.ac.uk/Biographies/Markov.html, Acessado em 24-02-2019.

[11] Ogawa, Y. A f´ormula preferida do professsor, 1 ed. S˜ao Paulo, Esta¸c˜ao Liberdade,

2017.

[12] Poole, D. ´Algebra Linear, 1 ed. S˜ao Paulo, Pioneira Thomson Learning, 2004.

[13] Sullivan, M., e Mizrahi, A. Matem´atica Finita, 9 ed. Rio de Janeiro, LTC, 2006.

79


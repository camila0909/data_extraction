UNIVERSIDADE TECNOLÓGICA FEDERAL DO PARANÁ - UTFPR
MESTRADO PROFISSIONAL EM MATEMÁTICA EM REDE NACIONAL
PROFMAT

CHEIRUM MICHAAEL RIBEIRO

ESTUDO DE PROJEÇÕES COM UMA PROPOSTA DE ATIVIDADES PARA
APLICAÇÃO NO ENSINO MÉDIO

CURITIBA

2019

CHEIRUM MICHAAEL RIBEIRO

ESTUDO DE PROJEÇÕES COM UMA PROPOSTA DE ATIVIDADES PARA
APLICAÇÃO NO ENSINO MÉDIO

Dissertação apresentada ao Mestrado Proﬁssional em
Matemática em Rede Nacional da Universidade Tec-
nológica Federal do Paraná em Curitiba - PROFMAT-
UTCT como requisito parcial para obtenção do grau
de Mestre.
Orientador: Rodolfo Gotardi Begiato

CURITIBA

2019

Dados Internacionais de Catalogação na Publicação   Ribeiro, Chéirum Michaael Estudo de projeções com uma proposta de atividades para aplicação no ensino médio [recurso eletrônico] / Chéirum Michaael Ribeiro. -- 2019. 1 arquivo texto (120 f.): PDF; 22,9 MB.  Modo de acesso: World Wide Web Título extraído da tela de título (visualizado em 19 dez. 2019) Texto em português com resumo em inglês Dissertação (Mestrado em Matemá-tica) - Universidade Tecnológica Federal do Paraná. Mestrado Profissional em Ma-temática em Rede Nacional, Curitiba, 2019  Bibliografia: f. 119-120.  1. Matemática - Dissertações. 2. Geometria projetiva. 3. Planos projetivos. 4. Geometria - Estudo e ensino (Ensino médio). 5. Jogos no ensino de matemática. 6. Matemática - Estudo e ensino (Ensino médio). 7. Geometria analítica plana - Pro-blemas, exercícios, etc. 8. Inovação educacional. 9. Sistemas lineares. I. Begiato, Rodolfo Gotardi. II. Universidade Tecnológica Federal do Paraná. Programa de Mestrado Profissional em Matemática em Rede Nacional. III. Título.   CDD: Ed. 23 – 510 Biblioteca Central da UTFPR, Câmpus Curitiba Bibliotecário: Adriano Lopes CRB-9/1429   Ministério da Educação Universidade Tecnológica Federal do Paraná Diretoria de Pesquisa e Pós-Graduação     TERMO DE APROVAÇÃO DE DISSERTAÇÃO Nº 73  A Dissertação de Mestrado intitulada “Estudo de projeções com uma proposta de atividades para aplicação no ensino médio”, defendida em sessão pública pelo candidato Cheirum Michaael Ribeiro, no dia 12 de dezembro de 2019, foi julgada para a obtenção do título de Mestre, área de concentração Matemática, e aprovada em sua forma final, pelo Programa de Pós-Graduação em Matemática em Rede Nacional - PROFMAT.  BANCA EXAMINADORA:  Prof. Dr. Rodolfo Gotardi Begiato – UTFPR Prof. Dr. João Luis Gonçalves – UTFPR Prof. Dr. Lucas Garcia Pedroso – UFPR  A via original deste documento encontra-se arquivada na Secretaria do Programa, contendo a assinatura da Coordenação após a entrega da versão corrigida do trabalho.  Curitiba, 12 de dezembro de 2019.    Carimbo e Assinatura do(a) Coordenador(a) do Programa Dedico este trabalho a Deus, por ser essen-
cial em minha vida, autor de meu destino,
meu guia, meu socorro, minha paz.

AGRADECIMENTOS

A Deus, todo poderoso, que desde o início desta caminhada me ungiu e deu sabedoria

para vencer todos os desaﬁos que surgiram nestes três anos.

A minha família, em especial na pessoa da minha mãe Maria Aparecida Ribeiro, meu
pai Antonio Osni Ribeiro e irmãos Cheisum Micheel Ribeiro e Eduardo Antonio Ribeiro, pelo
apoio incondicional.

A minha esposa Grasiela Jung Ribeiro e meus ﬁlhos Isaque Jung Ribeiro e Rebeca Jung
Ribeiro pelo apoio. A compreensão deles foi essencial para que este trabalho pudesse ter sido
realizado.

Ao professor Dr Rodolfo Gotardi Begiato pela orientação e dedicação. Desde o início

dos trabalhos foi muito atencioso, paciente e zeloso.

A todos os professores do corpo docente do Profmat responsáveis pelas disciplinas que

cursei, pois com muito zelo deram sua contribuição à minha formação.

"Tudo posso naquele que me fortalece."
(Filipenses 4, 13)

RESUMO

RIBEIRO, Cheirum Michaael. Estudo de projeções com uma proposta de atividades para
aplicação no Ensino Médio. 122 f. Dissertação - Programa de Mestrado Proﬁssional em Mate-
mática em Rede Nacional - PROFMAT, Universidade Tecnológica Federal do Paraná. Curitiba,
2019.

O estudo de projeções é um assunto clássico e de extrema importância para diversas áreas da
Matemática. Neste contexto, o presente trabalho tem por objetivo evidenciar essa importância
trazendo inicialmente um estudo teórico aprofundado sobre projeções e algumas aplicações na
análise numérica, através da exposição dos métodos iterativos GMRES e Gradientes Conjugados,
baseados em projeção sobre subespaços de Krylov. Num segundo momento, procurou-se com o
conhecimento adquirido propor algumas atividades que podem ser utilizadas na educação básica.
Foram elaboradas atividades interdisciplinares envolvendo o conteúdo de Geometria Analítica
com as áreas de conhecimento Física e Educação Física, onde propõe-se trabalhar as projeções
no contexto de vetores no plano cartesiano e também nas regras de impedimento no futebol, sob
o contexto recente da tecnologia VAR (Video Assistant Referee) que vem sendo adotada pela
FIFA (Fédération Internationale de Football Association) na última década. Para realização das
atividades, a ﬁm de auxiliar na prática dos experimentos e de fornecer estímulo ao estudante foi
produzido um material concreto, denominado caixa octante. Tal material representa um octante
do R3, e é um recurso que pode ser utilizado para todo conteúdo de Geometria Analítica.

Palavras-chave: Projeções. Ensino Básico. Geometria Analítica. Sistemas Lineares.

ABSTRACT

RIBEIRO, Cheirum Michaael. Projections study with a proposal of activities for application
in High School. 106 f. Dissertation - Programa de Mestrado Proﬁssional em Matemática em
Rede Nacional - PROFMAT, Universidade Tecnológica Federal do Paraná. Curitiba, 2018.

The projections study is a classic subject of extreme importance for various Math´s ﬁelds. In this
context, the present thesis has the main goal to evidence its importance ﬁrstly bringing a depth
theoretical study about projections and some applications on the numeric analysis through the
exposure of interplay methods GMRES and Conjugates Gradients that are based on projections of
Krylov subspace. On the second moment with the knowledge acquired in this work it was sought
to propose some activities which can be apply on the basic education. It has been elaborated
interdisciplinary activities engaging the content of Analytic Geometry with the Physics and
Physical Education knowledge ﬁelds. It has proposed working the projections in the vectors
context in the cartesian plan and also in the rules of soccer offside under the currently context
of VAR (Video Assistant Referee) technology that has been assumed for FIFA (International
Federation of Association Football) in the last decade. It has been built a concrete material called
octant box to accomplish the activities as a result to assist the experiments practice as well as
giving encouragement to the students. Such material represents an octant of R3 and it is a source
that can be utilized for all Analytic Geometry content.

Keywords: Projections. Basic Education. Analytic Geometry. Linear Systems.

LISTA DE ILUSTRAÇÕES

Figura 1 – Rotação de vetores I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 2 – Rotação de vetores II
Figura 3 – Rotação de vetores III . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 4 – T : R3 → R3; Projeção ortogonal sobre plano xy
. . . . . . . . . . . . . .
Figura 5 – N (T ) = {(0, 0, z) ∈ R3 | z ∈ R} . . . . . . . . . . . . . . . . . . . . . . .
Figura 6 – Núcleo e imagem de uma transformação linear T : E → F . . . . . . . . .
Figura 7 – Transformação injetiva
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 8 – Transformação sobrejetiva . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 9 – Projeção de vetores
Figura 10 – Diferença v − u .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 11 – Projeção ortogonal .
Figura 12 – Projeção ortogonal do vetor v = (3, 4, 6) sobre o vetor u = (6, 8, 0) . . . . .
Figura 13 – v = projW (v) + projW ⊥(v) . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 14 – Projeção do resíduo inicial sobre o subespaço AKl(A, r0) . . . . . . . . . .
Figura 15 – Construção de uma base ortonormal {v1, v2, . . . , vl} do subspaço de Krylov
. . . . . . . . . . . . .
Figura 16 – Gráﬁco de f (x): o ponto mínimo dessa superfície é solução de As = b . . .
Figura 17 – Curvas de nível: interseção da superfície com hiperplanos . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 18 – Fluxograma das atividades
Figura 19 – Representação geométrica do vetor deﬁnido pelos pontos A e B . . . . . . .
(x2 − x1)2 + (y2 − y1)2 . . . . . . . . . . . . . . . .
Figura 20 –

do resíduo inicial (r0) sobre a matriz A por Arnoldi

−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13) = d(A, B) =
AB
(cid:13)

q

.

.

.

.

.

1 + y2
x2
1

ao eixo x .

Figura 21 – Vetor com extremidade na origem: kvk = d(0, A) =
. . . . . . .
Figura 22 – Representação geométrica da projeção do vetor (3, 2) sobre eixo x . . . . .
−→
AB sobre eixo x . . . . . .
Figura 23 – Representação geométrica da projeção do vetor
−→
AB sobre eixo y . . . . . .
Figura 24 – Representação geométrica da projeção do vetor
Figura 25 – Representação geométrica da projeção de vetor paralelo ao eixo y em relação
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 26 – Representação geométrica da projeção de vetor determinado pelos pontos
A(−1, 1) e B(4, 3) sobre reta y = 1 . . . . . . . . . . . . . . . . . . . . . .
Figura 27 – Representação geométrica da projeção de vetor deﬁnido pelos pontos A(3, 2)
1
3

x + 1 . . . . . . . . . . . . . . . . . . . . .
Figura 28 – Caixa octante
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 29 – Exemplo de atividade a ser realizada na caixa octante . . . . . . . . . . . .
Figura 30 – Caixa octante montada I . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 31 – Caixa octante montada II
. . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 32 – Representação geométrica do vetor deﬁnido pelos pontos A e B . . . . . . .

e B(1, 3) sobre a reta r : y =

.

.

.

q

23
24
24
27
27
29
30
30
36
42
46
47
52
58

59
77
77
84
86
87

87
88
88
88

89

89

90
93
93
94
94
95

Figura 33 –

−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13) = d(A, B) =
AB
(cid:13)

q

95

96
96
97
97
98

(x2 − x1)2 + (y2 − y1)2 . . . . . . . . . . . . . . . .

q

1 + y2
x2
1

Figura 34 – Vetor com extremidade na origem: kvk = d(0, A) =
. . . . . . .
Figura 35 – Representação dos pontos A, B, C e D . . . . . . . . . . . . . . . . . . . .
Figura 36 – Representação das coordenadas do paralelepípedo ABCDEFGH . . . . . .
Figura 37 – Coordenadas de pontos em R3 na caixa octante I . . . . . . . . . . . . . . .
Figura 38 – Coordenadas de pontos em R3 na caixa octante II
. . . . . . . . . . . . . .
Figura 39 – Coordenadas de pontos em R3 na caixa octante com adaptação para alunos
com deﬁciência visual . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(x2 − x1)2 + (y2 − y1)2 + (z2 − z1)2 . . . . . . . . .
(cid:13) = d(A, B) =
AB
(cid:13)

98
Figura 40 –
99
Figura 41 – Exemplo de atividade realizada na caixa octante com semelhança de triângulos100
Figura 42 – Sombra de um objeto projetada ortogonalmente por uma lâmpada puntiforme

q

.

.

.

.

.

.

ﬁxa .

.
.
Figura 43 – Projeção não ortogonal com θ < 90◦
Figura 44 – Projeção não ortogonal com θ > 90◦
Figura 45 – Obtendo comprimento da sombra de uma lapiseira posicionada no ponto

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
. . . . . . . . . . . . . . . . . . . . . 101
. . . . . . . . . . . . . . . . . . . . . 101

A(20, 3, 0) com inclinação de 45◦ com relação à base da caixa . . . . . . . . 102

Figura 46 – Sombra de um objeto qualquer posicionado em ponto arbitrário e com incli-

nação de θ com relação à base da caixa . . . . . . . . . . . . . . . . . . . . 103
. . . . . . . . . . . . . . . . . . . . . . . . . . 105
Figura 47 – Exemplo de impedimento I
Figura 48 – Exemplo de impedimento II . . . . . . . . . . . . . . . . . . . . . . . . . . 105
Figura 49 – Exemplo de impedimento III
. . . . . . . . . . . . . . . . . . . . . . . . . 106
Figura 50 – Exemplo de impedimento IV . . . . . . . . . . . . . . . . . . . . . . . . . 106
Figura 51 – Posicionamente de câmera para veriﬁcação de impedimento I . . . . . . . . 107
Figura 52 – Posicionamente de câmera para veriﬁcação de impedimento II
. . . . . . . 107
Figura 53 – Lance capturado por emissora de TV . . . . . . . . . . . . . . . . . . . . . 108
Figura 54 – Reação de torcedores
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Figura 55 – Reação de dirigentes de um dos clubes envolvidos . . . . . . . . . . . . . . 109
Figura 56 – Declaração do chefe de arbitragem . . . . . . . . . . . . . . . . . . . . . . 109
Figura 57 – Imagem capturada e analisada pelo VAR com projeções . . . . . . . . . . . 110
Figura 58 – Funcionamento do VAR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
Figura 59 – Experimento simulado do VAR . . . . . . . . . . . . . . . . . . . . . . . . 111
Figura 60 – Deﬁnição de vetores correspondentes a cada jogador envolvido na jogada . . 112
Figura 61 – Deﬁnição de triângulo retângulo correspondente a cada jogador com relação

à base da caixa (campo) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
Figura 62 – Veriﬁcação da não existência de impedimento . . . . . . . . . . . . . . . . 113
Figura 63 – Exemplo de deﬁnição de vetor correspondente a um jogador . . . . . . . . . 114
Figura 64 – Veriﬁcando se atacante está em posição de impedimento . . . . . . . . . . . 114
Figura 65 – Veriﬁcando projeção ortogonal do atacante . . . . . . . . . . . . . . . . . . 115
Figura 66 – Veriﬁcando projeção ortogonal do defensor . . . . . . . . . . . . . . . . . . 115

Figura 67 – Veriﬁcação da existência de impedimento . . . . . . . . . . . . . . . . . . 116

SUMÁRIO

INTRODUÇÃO .

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14

TÓPICOS INTRODUTÓRIOS . . . . . . . . . . . . . . . . . . . . . . .

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . .
Transformações Lineares
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
Propriedades .
. . . . . . . . . . . . . . . . . . . . .
Produto de Transformações Lineares
Núcleo e Imagem .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Soma Direta e Projeção . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Espaço Vetorial com Produto Interno . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
Produto interno .
. . . . . . . . . . . . . . . . . . . . .
Ortogonalidade e Projeção ortogonal

.

PROJEÇÕES E ANÁLISE NUMÉRICA . . . . . . . . . . . . . . . . . .

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Motivação .
Subespaços de Krylov . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Método GMRES .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Iteração de Arnoldi
Rotações de Givens
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Método dos Gradientes conjugados . . . . . . . . . . . . . . . . . . . . . .

.

18

18
20
25
26
34
38
38
43

54

54
55
57
58
65
75

PROPOSTAS DE ATIVIDADES PARA USO NO ENSINO MÉDIO . .

84

.

.

.

.

.

85
Modelagem matemática e interdisciplinaridade . . . . . . . . . . . . . . . .
86
Atividade 1: Projetando vetores em retas no plano . . . . . . . . . . . . . .
86
Objetivos .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
Desenvolvimento da proposta . . . . . . . . . . . . . . . . . . . . . . . . .
86
Linguagem vetorial
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
Projeção de vetores sobre eixos coordenados . . . . . . . . . . . . . . . . .
89
Projeção de vetores sobre retas no plano . . . . . . . . . . . . . . . . . . .
91
Avaliação . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
Atividade 2: Prática com Luz e Sombra . . . . . . . . . . . . . . . . . . . .
92
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
Objetivos .
92
Caixa octante .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
Desenvolvimento da proposta . . . . . . . . . . . . . . . . . . . . . . . . .
94
Linguagem vetorial
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Escolha de um objeto para experimento . . . . . . . . . . . . . . . . . . . .
99
Experimento com objeto . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

.
.

.
.

.
.

.

.

.

.

.

1

1.1
1.1.1
1.2
1.3
1.4
1.5
1.5.1
1.5.2

2

2.1
2.2
2.3
2.3.1
2.3.2
2.4

3

3.1
3.2
3.2.1
3.2.2
3.2.2.1
3.2.2.2
3.2.2.3
3.2.3
3.3
3.3.1
3.3.2
3.3.3
3.3.3.1
3.3.3.2
3.3.3.3

3.3.4
3.4
3.4.1
3.4.2
3.4.2.1
3.4.2.2
3.4.2.3
3.4.3

.

.

.

.

.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Avaliação .
. . . . . . . . . . . . . . 104
Atividade 3: Veriﬁcando impedimentos no futebol
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Objetivos .
Desenvolvimento da proposta . . . . . . . . . . . . . . . . . . . . . . . . . 104
Regra de Impedimento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Funcionamento da tecnologia VAR . . . . . . . . . . . . . . . . . . . . . . 106
Experimento com VAR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
Avaliação .

.

.

.

.

.

4

CONCLUSÃO .

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

REFERÊNCIAS .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

INTRODUÇÃO

14

Neste trabalho vamos tratar o tema projeção sob duas perspectivas. Na primeira perspec-
tiva, visando o aprofundamento do conhecimento matemático na área de Álgebra Linear, foi feito
um intenso estudo teórico sobre projeções e algumas de suas aplicações na Análise numérica.
Na segunda perspectiva, procurou-se com o conhecimento adquirido propor algumas atividades
que poderiam ser utilizadas na educação básica. Sob essa segunda perspectiva foram elaboradas
atividades interdisciplinares envolvendo a Geometria Analítica e as áreas de conhecimento Física
e Educação Física, onde propõe-se trabalhar as projeções com utilização de vetores no plano
cartesiano e também nas regras de impedimento no futebol, sob o contexto recente da tecnologia
VAR (Video Assistant Referee) que vem sendo adotada pela FIFA (Fédération Internationale de
Football Association) na última década.

Dentro dessas duas perspectivas produzimos o texto que segue, onde empenhamo-nos
para fornecer um trabalho que seja útil para professores de matemática, daí o cuidado de fornecer
uma redação didática e um grande número de exemplos.

O estudo de projeções é um assunto clássico no estudo de Álgebra Linear com muita
utilidade na área de Análise Numérica, onde projetores podem ser utilizados como ferramenta
para o desenvolvimento de métodos que podem ser utilizados para a resolução de diversos
problemas da área, tais como fatoração de matrizes, otimização linear, otimização não-linear,
resolução de sistemas lineares e não lineares, etc. Posteriormente, tais métodos desenvolvidos
podem ser empregados para aplicação nas mais diversas áreas de conhecimento, como, Física,
Engenharias, Economia, etc.

Considerando um espaço vetorial qualquer E, uma projeção é um operador linear P :
E → E que satisfaz a condição P 2 = P . O tipo de projeção mais estudado são as chamadas
projeções ortogonais, em que o operador linear deve satisfazer, adicionalmente, P = P T .

A noção de projeção está intimamente ligada à noção de Soma Direta. Se W1, W2 são
dois subespaços do espaço vetorial E, dizemos que E é soma direta de W1 e W2 se todo elemento
v ∈ E pode ser escrito, de maneira única, como v = w1 + w2, onde w1 ∈ W1 e w2 ∈ W2. Num
primeiro momento, considerando a projeção P : E → E, é possível mostrar que a condição
P 2 = P garante que E é a soma direta do núcleo da projeção com a sua imagem. Além disso,
se E pode ser escrito como soma direta dos subespaços W1 e W2, deﬁne-se o operador linear
P : E → E, projeção sobre W1, paralelamente a W2, do seguinte modo: todo vetor w ∈ V se
escreve, de modo único, como soma w = u + v de um vetor u ∈ W1 com um vetor v ∈ W2.
Põe-se então P (w) = u. Neste caso, pode-se perceber que a imagem da projeção é o espaço W1
e, além disso, o núcleo é o espaço W2.

No caso da projeção ortogonal, pode-se ainda veriﬁcar que o núcleo do operador será

15

complemento ortogonal da imagem. E que, sendo W subespaço de V , tem-se que V = W ⊕ W ⊥
e que, neste caso, a projeção sobre W , paralelamente a W ⊥ é uma projeção ortogonal.

Na área de Análise Numérica, as projeções têm papel importante no desenvolvimento de
métodos para resolução dos mais diversos tipos de problema. Para trabalhar com decomposição
de matrizes, pode ser aplicado o conceito de projeções para determinar a fatoração QR. Quando
se fala da resolução de sistemas lineares, podemos citar, por exemplo, métodos baseados em pro-
jeção sobre subespaços de Krylov (KELLEY, 1995). A resolução de sistemas sobredeterminados
(mais equações do que incógnitas) através dos métodos Quadrados Mínimos, que constantemente
aparecem na área de Otimização, são resolvidos através de projeções em subespaços. Entre os
métodos desenvolvidos para resolução de problemas de minimização (linear ou não, restrito ou
não) podemos encontrar uma série de métodos que utilizam o conceito de projeção em algumas
de suas etapas ou até em sua essência.

Neste trabalhos, vamos estudar dois dos principais métodos iterativos para resolução de
sistemas lineares: Método dos Gradientes Conjugados (Conjugate Gradient Method) e o GMRES
(Generalized Minimum Residual Method) que são baseados em projeções sobre subespaços de
Krylov.

Após o estudo teórico das projeções, foi possível elaborar algumas propostas para
trabalho em sala de aula no ensino básico, nas quais, partindo de algumas atividades teóricas,
desenvolve-se uma série de atividades práticas para as quais foi desenvolvido o material concreto
caixa octante.

As atividades propostas levam em consideração duas possibilidades advindas das ati-
vidades práticas e que constituem importantes fundamentos na aprendizagem qualitativa de
Matemática: a modelagem matemática e a interdisciplinaridade.

Sobre a modelagem matemática, as Orientações Curriculares para o Ensino Médio
discorrem que como estratégia de ensino, a modelagem apresenta fortes ligações com a ideia
de resolução de problema. Neste contexto, frente a situações práticas o aluno precisa mobilizar
e articular muitas competências, o que acaba contribuindo para sua aprendizagem, uma vez
que precisa selecionar variáveis, problematizar, formular hipóteses, recorrer ao conhecimento
matemático, confrontar as conclusões teóricas e eventualmente ainda, quando surge a necessidade,
modiﬁcar o modelo para que esse melhor corresponda à situação real, aqui se revelando o aspecto
dinâmico da construção do conhecimento (BRASIL, 2006a).

Já em relação à interdisciplinaridade, temos que segundo os Parâmetros Curriculares

Nacionais (PCN) para o Ensino Médio

Na perspectiva escolar, a interdisciplinaridade não tem a pretensão de criar
novas disciplinas ou saberes, mas de utilizar os conhecimentos de várias disci-
plinas para resolver um problema concreto ou compreender um determinado
fenômeno sob diferentes pontos de vista. Em suma, a interdisciplinaridade
tem uma função instrumental. Trata-se de recorrer a um saber diretamente útil
e utilizável para responder às questões e aos problemas sociais contemporâ-

16

neos. (...) A integração dos diferentes conhecimentos pode criar as condições
necessárias para uma aprendizagem motivadora, na medida em que ofereça
maior liberdade aos professores e alunos para a seleção de conteúdos mais
diretamente relacionados aos assuntos ou problemas que dizem respeito à vida
da comunidade. (BRASIL, 2000)

As propostas de atividades para o uso no ensino médio têm como objetivo central
promover um reforço e um estímulo na aprendizagem de conteúdos referente à Geometria
Analítica, de maneira interdisciplinar com as áreas de Física e Educação Física, trabalhando
com projeções em R2 e R3 e priorizando conhecimentos geométricos relacionados ao estudo
do triângulo retângulo, como as relações trigonométricas e Teorema de Pitágoras, com uma
introdução a linguagem vetorial, sobre o plano cartesiano.

Dentre as propostas, a primeira é de cunho teórico, onde se propõe um estudo sobre
projeções de vetores do R2 em retas quaisquer do plano. Já as outras duas propostas visam
trabalhar projeções por meio de dois experimentos práticos. Para tanto, foi desenvolvido um
material concreto, o qual chamamos de caixa octante. Tal material representa um octante do R3
e tem por objetivo não só auxiliar na prática dos experimentos, como também fornecer estímulo
ao estudante, a ponto de o mesmo poder visualizar alguns conceitos abstratos.

Uma das atividades a ser realizada com a caixa octante está relacionada com um experi-
mento de luz e sombra. Pretende-se trabalhar com a projeção ortogonal através do problema de
calcular o comprimento da sombra de um objeto projetada ortogonalmente por uma lâmpada
puntiforme presa ao teto. Nesta atividade, pretende-se sobretudo que o aluno entenda a impor-
tância da projeção ortogonal, considerando que ela é a que fornece a menor distância entre a
sombra e o objeto projetado.

A segunda atividade prática proposta com a caixa octante está relacionada a uma aplica-
ção da deﬁnição de projeção no esporte, mais precisamente a marcações de impedimentos em
partidas de futebol.

Conforme as regras da IFAB (The International Football Association Board), que é o
órgão responsável pela formulação e manutenção das regras que compõem o futebol, um jogador
estará em posição de impedimento quando qualquer parte de sua cabeça, corpo ou pés (exceto
mãos e braços, inclusive dos goleiros) estiver no campo adversário e mais próximo da linha de
meta adversária do que a bola e o penúltimo adversário. Ademais, um jogador em posição de
impedimento somente será punido se no momento em que a bola for jogada ou tocada por um
companheiro de equipe (considerando o momento do primeiro ponto de contato com a bola)
participar ativamente do jogo, seja interferindo no jogo, interferindo num adversário ou mesmo
ganhando vantagem de sua posição de impedimento (IFAB, 2019).

Tal atividade tem como motivação levar os estudantes a um pleno entendimento da
regra do impedimento por meio do estudo de projeções minimizando a proposição de críticas
e reclamações por vezes decorrentes do desentendimento dessa regra. Na prática, o professor

17

conduzirá um experimento com utilização de bonecos, onde os mesmos utilizarão conhecimentos
relacionados ao estudo de projeção para veriﬁcar a existência de impedimentos no experimento.

A ideia é simular a tecnologia VAR (Video Assistant Referre) recentemente aprovada pela
FIFA (do francês: Fédération Internationale de Football Association) em relação à marcação de
impedimento. Um árbitro assistente de vídeo (VAR) é um árbitro de partida que possui acesso
independente às imagens gravadas da partida, o qual poderá auxiliar o árbitro na eventualidade
de um “erro claro e óbvio”, como por exemplo a marcação de impedimento.

Quanto à organização da dissertação, no primeiro capítulo deste trabalho, descrevemos os
fundamentos teóricos estudados sob a primeira perspectiva (aprofundamendo do conhecimento).
Neste sentido, faremos um relato do conceito de projeção sob a ótica da Álgebra Linear. Para
tanto, é esperado que o leitor já tenha alguns conhecimentos prévios relacionados a deﬁnições e
propriedades de matrizes, vetores e espaços vetoriais.

No Capítulo 2, ainda sob a perspectiva de aprofundamento de conhecimento, apresenta-
mos uma aplicação do estudo de projeções no campo da Análise Numérica através dos métodos
iterativos para resolução de sistemas lineares: GMRES e Gradientes Conjugados.

O terceiro capítulo é dedicado à perspectiva de aplicações no Ensino Básico. Nele,
descrevemos as nossas propostas de atividades, o material concreto desenvolvido e algumas
possibilidades de utilização.

Por ﬁm, terminamos este texto com algumas conclusões que pudemos alcançar durante a

produção deste trabalho.

1 TÓPICOS INTRODUTÓRIOS

18

Neste capítulo estudamos conceitos importantes para a compreensão da deﬁnição de
projeção e aplicações relacionadas, dentre eles o de Transformação Linear e Ortogonalidade.
Para tanto, na composição deste capítulo utilizamos alternadamente um conjunto de autores
como base teórica, tais quais, (LIMA, 2014), (TEIXEIRA, 2015), (SANTOS, 2006), (HEFEZ;
FERNADEZ, 2016), (COELHO; LOURENÇO, 2013) e (NASCIMENTO, 2013).

1.1 TRANSFORMAÇÕES LINEARES

As chamadas transformações lineares, formam uma classe muito especial de funções que
têm muitas aplicações na Física, nas Engenharias e em vários ramos da Matemática. Tais funções
nas quais se está interessado na Álgebra Linear são as funções cujos domínios e contradomínios
são espaços vetoriais e que, além disso, preservam as operações de adição de vetores e de
multiplicação de um vetor por um escalar (HEFEZ; FERNADEZ, 2016).

Deﬁnição 1.1. Sejam E e F espaços vetoriais sobre R. Uma transformação linear é uma
correspondência que associa a cada vetor u ∈ E um vetor T (u) ∈ F de modo que valham, para
quaisquer u, v ∈ E e qualquer α ∈ R, as relações:

T (u + v) = T (u) + T (v)

T (αu) = αT (u)

(1.1)

(1.2)

Exemplo 1.2. A função T : R2 → R3, dada por T (x, y) = (2x, 0, x + y), é uma transformação
linear.

De fato, se u = (x1, y1) ∈ R2, v = (x2, y2) ∈ R2 e α ∈ R, temos que

T (u + v) = T ((x1, y1) + (x2, y2)) = T (x1 + x2, y1 + y2)

= (2(x1 + x2), 0, (x1 + x2) + (y1 + y2))

= (2x1 + 2x2, 0, (x1 + x2) + (y1 + y2))

= (2x1, 0, x1 + y1) + (2x2, 0, x2 + y2)

= T (u) + T (v)

e

T (αu) = T (α(x1, y1)) = T (αx1, αy1) = (2αx1, 0, αx1 + αy1)

= α(2x1, 0, x1 + y1)

= αT (u).

Exemplo 1.3. A aplicação





T









a b
c d

: M2 → M2

T

 =





a + b
b + c
c + d d + a

19





também é uma aplicação linear, pois, se u =





a1
b1
c1 d1


, v =





a2
b2
c2 d2


 e α ∈ R, então





T





a1
b1
c1 d1


 +





a2
b2
c2 d2






 = T









a1 + a2
b1 + b2
c1 + c2 d1 + d2









e


α





T

b1
a1
c1 d1






 = T

= T













49αa1 αb1
αd1
αc1









=

=





b1 + b2 + c1 + c2
a1 + a2 + b1 + b2
c1 + c2 + d1 + d2 d1 + d2 + a1 + a2

 +





b1 + c1
a1 + b1
c1 + d1 d1 + a1





b2 + c2
a2 + b2
c2 + d2 d2 + a2









 + T











a1
b1
c1 d1

a2
b2
c2 d2










 =





= α





αa1 + αb1 αb1 + αc1
αc1 + αd1 αd1 + αa1





a1 + b1
b1 + c1
c1 + d1 d1 + a1








 .



a1
b1
c1 d1

= αT





Exemplo 1.4. Seja P (R) o espaço vetorial dos polinômios sobre R e considere a função

D : P (R) −→ P (R)
7−→ p0(x)

p(x)

onde D é a função derivação restrita aos polinômios p(x) ∈ P (R), D(p(x)) = p0(x). Temos que
D é uma transformação linear pois, se p(x), q(x) ∈ P (R) e α ∈ R:

D((p + q)(x)) = (p + q)0(x) = p0(x) + q0(x) = D(p(x)) + D(q(x))

e

Exemplo 1.5. Seja:

D((αp)(x)) = (αp)0(x) = αp0(x) = αD(p(x)).

T : Mn −→

R

A 7−→ T (A) = det(A).

Esta aplicação não é uma transformação linear, pois em geral

det(A1 + A2) 6= det(A1) + det(A2).

De fato, considerando as matrizes A1, A2 e A1 + A2 (por exemplo), tais quais:

20

A1 =

A2 =

A1 + A2 =













1 2
−2 1

−3 0
5 2

−2 2
3 3


 ,


 ,


 .

Temos que det(A1) = 5, det(A2) = −6 e det(A1 + A2) = −12. No entanto, det(A1) +
det(A2) = 5 + (−6) = −1 6= −12 = det(A1 + A2).

Exemplo 1.6. Sejam E e F espaços vetoriais. A função O, que leva todo vetor de E no vetor
nulo de F , ou seja, O(v) = ~0, para todo v ∈ E, é uma transformação linear e é chamada a
transformação linear nula. De fato, se v1 e v2 são vetores quaisquer de E, temos que O(v1) +
O(v2) = ~0 + ~0 = ~0 = O(v1 + v2). Ademais, se α ∈ R, então αO(v1) = α~0 = ~0 = O(αv1).

Exemplo 1.7. A transformação identidade, I, de E em E que leva todo vetor de E nele mesmo,
ou seja, I(v) = v, para todo v ∈ E é uma transformação linear. Pois, se considerarmos v1, v2 ∈ E
e α ∈ R, I(v1) + I(v2) = v1 + v2 = I(v1 + v2) e αI(v1) = αv1 = I(αv1).

1.1.1 PROPRIEDADES

Proposição 1.8. Toda transformação linear T : E → F leva o vetor nulo de E no vetor nulo
de F .

Demonstração. Se x é um vetor qualquer de E, então

T (~0) = T (0 · x) = 0 · T (x) = ~0.

Deﬁnição 1.9. Sejam S : E → F e T : E → F transformações lineares. Para todo v ∈ E e
α ∈ R,

(i) Deﬁnimos a soma de S e T , denotada por S + T , como a função S + T : E → F dada por

(S + T )(v) = S(v) + T (v);

(1.3)

(ii) Deﬁnimos o produto de α por T , denotado por αT , como a função αT : E → F dada por

(αT )(v) = αT (v).

(1.4)

21

Teorema 1.10. A soma de duas transformações lineares S, T : E → F e o produto de uma
transformação linear T : E → F por um número α ∈ R são transformações lineares.

Demonstração. Sejam as transformações lineares S, T : E → F , e os escalares α, β ∈ R, com
as operações de soma de duas transformações lineares e produto de uma transformação linear
por um escalar, deﬁnidas respectivamente em (1.3) e (1.4) na Deﬁnição 1.9.

(a) Mostrando que S + T : E → F é uma transformação linear:

(S + T )(v1) + (S + T )(v2) = S(v1) + T (v1) + S(v2) + T (v2)

= S(v1 + v2) + T (v1 + v2)

= (S + T )(v1 + v2)

e,

β(S + T )(v1) = βS(v1) + βT (v1)

= S(βv1) + T (βv1)

= (S + T )(βv1).

(b) Mostrando que αT : E → F é uma transformação linear:

(αT )(v1) + (αT )(v2) = αT (v1) + αT (v2)

= α(T (v1) + T (v2))

= α(T (v1 + v2))

= (αT )(v1 + v2)

e,

β(αT )(v1) = βαT (v1) = (βα)T (v1)

= (αβ)T (v1)

= α(βT )(v1)

= αT (βv1)

= (αT )(βv1).

Denotemos L(E; F ) o conjunto das transformações lineares de E em F . Quando E = F ,
usaremos a notação L(E) em vez de L(E; E). As transformações lineares T : E → E do espaço
vetorial E em si mesmo são chamados operadores lineares em E. Por sua vez, as transformações
lineares ϕ : E → R, com valores numéricos, são chamadas funcionais lineares. Escreve-se E∗
em vez de L(E; R) e o conjunto E∗ dos funcionais lineares ϕ : E → R chama-se o espaço
vetorial dual de E.

22

Corolário 1.11. L(E; F ) é um Espaço Vetorial.

Demonstração. Pelo Teorema 1.10 temos que a soma de duas transformações lineares S, T :
E → F e o produto de uma transformação linear T : E → F por um número α ∈ R
também são transformações lineares, o que nos mostra que L(E; F ) é um subespaço vetorial e
consequentemente L(E; F ) é um Espaço Vetorial.

Uma função T : E → F é uma transformação linear se, e somente se, T (αv1 + βv2) =
αT (v1) + βT (v2), para todos os vetores v1, v2 ∈ E e todos os escalares α e β. Pois, se T é linear,
então T (αv1 + βv2) = T (αv1) + T (βv2) = αT (v1) + βT (v2). Por outro lado, se T é uma função
tal que T (αv1 + βv2) = αT (v1) + βT (v2), para todos os vetores v1, v2 ∈ E e todos os escalares
α e β, então fazendo α = 1, β = 1 e depois β = 0 segue-se que T é uma transformação linear.
Mais geralmente, T (α1v1 + . . . + αnvn) = α1T (v1) + . . . + αnT (vn), ∀αi ∈ R e vi ∈ E.

Teorema 1.12. Sejam E, F espaços vetoriais e B uma base de E. A cada vetor u ∈ B, façamos
corresponder (de maneira arbitrária) um vetor u0 ∈ F . Então existe uma única transformação
linear T : E → F tal que T (u) = u0 para cada u ∈ B.

Demonstração. Para cada vetor v ∈ E temos, de modo único, uma combinação linear v =
α1u1 + · · · + αmum de elementos u1, · · · , um da base B. Deﬁnimos T : E → F pondo

T (v) = α1u0

1 + · · · + αmu0

m.

Dados v, w ∈ E temos

e

v = α1u1 + · · · + αmum

w = β1u1 + · · · + βmum

(mesmo que a base B seja inﬁnita, podemos exprimir v e w como combinações lineares dos
mesmos elementos de B, completando com coeﬁcientes zero os múltiplos dos ui que aparecem
apenas numa das duas expressões). Então

v + w = (α1u1 + · · · + αmum) + (β1u1 + · · · + βmum) =

m
X

i=1

(αi + βi)ui.

Logo

T (v + w) =

m
X

(αi + βi)u0

i =

i=1

m
X

i=1

αiu0

1 +

m
X

i=1

βiu0

i = T (v) + T (w).

De maneira análoga se vê que T (αv) = αT (v), portanto T : E → F , assim deﬁnida, é uma
transformação linear, tal que T (u) = u0, para todo u ∈ B. Quanto à unicidade, seja S : E → F

outra transformação linear tal que S(u) = u0 para todo u ∈ B. Então, para cada v =

tem-se

S(v) = S

!

αiui

=

  m
X

i=1

m
X

i=1

αi · S(ui) =

m
X

i=1

αi · u0

1 = T (v).

Portanto S = T . Isto completa a demonstração.

23

m
X

i=1

αiui ∈ E

Em outras palavras, o Teorema 1.12 garante que uma transformação linear é totalmente

determinada se conhecermos seus valores nos vetores de uma base de seu domínio.

Exemplo 1.13. Vamos determinar a transformação linear T : R2 → R3 tal que T (1, 1) =
(0, 2, 1) e T (0, 2) = (1, 0, 1).

Como α = {(1, 1), (0, 2)} é linearmente independente e possui dimensão 2, temos que

α é uma base de R2. Além disso, se (x, y) ∈ R2, então

(x, y) = a1(1, 1) + a2(0, 2) = (a1, a1 + 2a2)

se, e somente se, a1 = x e a2 =

y − x
2

. Portanto, pelo Teorema 1.12,

T (x, y) = a1T (1, 1) + a2T (0, 2)
(cid:19)

= xT (1, 1) +

T (0, 2)

(cid:19)

(1, 0, 1)

(cid:18) y − x
2
(cid:18) y − x
2
x + y
2

(cid:19)

.

= x(0, 2, 1) +

=

(cid:18) y − x
2

, 2x,

Exemplo 1.14. (Rotação de ângulo θ em torno da origem em R2). Trata-se de uma transformação
linear T : R2 → R2, que leva cada vetor u no vetor T (u) que dele resulta pela rotação de ângulo
θ em torno da origem. As Figuras 1 e 2 mostram que T (u + v) = T (u) + T (u) e T (αu) = αT (u)
para u ∈ R2 e α ∈ R2, o que nos indica que T é uma transformação linear.

Figura 1 – Rotação de vetores I

Fonte – Autoria própria (2019)

Figura 2 – Rotação de vetores II

24

Fonte – Autoria própria (2019)

Considerando a base canônica de R2 formada pelos vetores unitários e1 = (1, 0) e
e2 = (0, 1) e as deﬁnições de seno e cosseno, o vetor unitário T (e1), que forma com e1 um
ângulo θ, tem coordenadas cos θ e senθ, ou seja, T (e1) = (cos θ, senθ). Além disso, como
e2 forma com e1 um ângulo reto, temos que T (e2) também forma com T (e1) um ângulo reto.
Logo T (e2) = (− senθ, cos θ) (Figura 3). Utilizando o mesmo raciocínio do Exemplo 1.13, se
(x, y) ∈ R2, então

(x, y) = a1e1 + a2e2 = a1(1, 0) + a2(0, 1) = (a1, a2).

Logo,

T (x, y) = a1T (e1) + a2T (e2)

= x(cos θ, senθ) + y(− senθ, cos θ)

= (x cos θ, x senθ) + (−y senθ, y cos θ)

= (x cos θ − y senθ, x senθ + y cos θ).

Figura 3 – Rotação de vetores III

Fonte – Autoria própria (2019)

25

1.2 PRODUTO DE TRANSFORMAÇÕES LINEARES

Deﬁnição 1.15. Dadas as transformações lineares T : E → F , S : F → G (note que o domínio
de S coincide com o contradomínio de T ), o produto de S por T é a função ST : E → G pondo,
para cada v ∈ E,

ST (v) = S(T (v)).

Observe que ST nada mais é do que a composta S ◦ T das funções S e T .

T

E

F

ST

S (cid:47)

G .

(1.5)

(1.6)

Proposição 1.16. Se T : E → F e S : F → G são transformações lineares, então a composição
ST : E → G é uma transformação linear.

Demonstração. Sejam v1, v2 ∈ E e α, β escalares

(ST )(αv1 + βv2) = S(T (αv1 + βv2))

= S(αT (v1) + βT (v2))

= αS(T (v1)) + βS(T (v2))

= α(ST )(v1) + β(ST )(v2).

Proposição 1.17. Sejam S, T e U transformações lineares com domínios e contradomínios
apropriados. Então

(a) Associatividade: S(T U ) = (ST )U ;

(b) Distributividade à direita: S(T + U ) = ST + SU ;

(c) Distributividade à esquerda: (S + T )U = SU + T U ;

(d) Homogeneidade: α(T U ) = (αT )U = T (αU ), para qualquer α ∈ R;

(e) IT = T I = T , onde I é a transformação identidade.

Demonstração. Seja v pertencente ao domínio de U e α ∈ R.

(a) S(T U )(v) = S((T U )(v)) = S(T (U (v))) = ST ((U (v));

(b) Pela linearidade de S temos que S(T + U )(v) = S((T + U )(v)) = S(T (v) + U (v)) =

S(T (v)) + S(U (v)) = ST (v) + SU (v) = (ST + SU )(v);

(cid:56)
(cid:56)
(cid:47)
(cid:47)
(cid:47)
26

(c) Da deﬁnição de S + T temos: (S + T )U (v) = S(U (v)) + T (U (v)) = SU (v) + T U (v);

(d) (1ª parte) α(T U )(v) = αT (U (v)) = (αT )(U (v)) = (αT )U (v);

(d) (2ª parte) α(T U )(v) = αT (U (v)) = T (αU (v)) = T (αU )(v);

(e) Seja I a transformação identidade, temos que IT (v) = I(T (v)) = T (v) = (T (v))I =

T (v)I = T I(v).

Observe que o produto ST só está deﬁnido quando T toma valores no domínio de S.
Esta restrição desaparece, naturalmente, quando se trata de operadores lineares no mesmo espaço
E: então o produto ST está deﬁnido quaisquer que sejam T1, T2 ∈ L(E). Neste contexto, há
diferenças notáveis entre o produto de transfomações lineares e o produto de números reais,
como as ausências da comutatividade, da lei do corte e da inversa multiplicativa para uma
transformação 6= ~0, além da presença de transformações nilpotentes, para as quais tem-se T n = ~0
com T1 6= ~0.

1.3 NÚCLEO E IMAGEM

Deﬁnição 1.18. Sejam E e F espaços vetoriais. Seja T : E → F uma transformação linear.

(a) O núcleo de T é o conjunto deﬁnido como:

N (T ) = {v ∈ E | T (v) = ~0}.

(1.7)

(b) A imagem de T é o conjunto deﬁnido como:

Im(T ) = {w ∈ F | w = T (v), para algum v ∈ E}.

(1.8)

Exemplo 1.19. Sejam T : E → F a transformação linear nula e I : E → E a transformação
identidade.

(a) N (T ) = E e Im(T ) = ~0, pois pela deﬁnição de transformação linear nula, para qualquer
v ∈ E, temos que T (v) = ~0, o que implica que o único elemento de Im(T ) é o vetor nulo
e todo elemento de E pertence ao N (T );

(b) N (I) = ~0 e Im(I) = E, pois pela deﬁnição de transformação identidade, T (v) = ~0
somente quando v = ~0 onde v ∈ E, da mesma forma que T (v) = v, onde v ∈ E.

Figura 4 – T : R3 → R3; Projeção ortogonal sobre plano xy

27

Fonte – Autoria própria (2019)

Exemplo 1.20. Seja T : R3 → R3 a projeção ortogonal sobre o plano xy (Figura 4).

Considerando a base canônica de R3, {~e1, ~e2, ~e3} = {(1, 0, 0), (0, 1, 0), (0, 0, 1)} perceba
que a transformação T : R3 → R3 deﬁnida como projeção ortogonal sobre o plano xy, sabendo
que T (~e1) = ~e1, T (~e2) = ~e2 e T (~e3) = ~0, algebricamente pode ser descrita como

T (x, y, z) = T (x~e1 + y~e2 + z~e3)

= xT (~e1) + yT (~e2) + zT (~e3)
= x~e1 + y~e2 + ~0

= (x, y, 0).

Se T (x, y, z) = (0, 0, 0) ⇒ (x, y, z) = (0, 0, 0) ⇒ x = 0 e y = 0. Como nada é dito sobre a
variável z, temos que z é qualquer, logo N (T ) = {(0, 0, z) ∈ R3 | z ∈ R}, ou seja o núcleo de
T são todos os vetores que estão sobre o eixo z (Figura 5).

Figura 5 – N (T ) = {(0, 0, z) ∈ R3 | z ∈ R}

Fonte – Autoria própria (2019)

A proposição a seguir mostra como podemos determinar geradores para a imagem de

uma transformação linear.

28

Proposição 1.21. Seja T : E → F uma transformação linear. Se {v1, . . . , vn} é uma base de E,
então a imagem de T é gerada por T (v1), . . . , T (vn).

Demonstração. Seja w ∈ Im(T ). Então, existe v ∈ E tal que T (v) = w. Como {v1, . . . , vn} é
uma base de E, existem escalares α1, . . . , αn tais que v = α1v1 + . . . + αnvn. Assim,

w = T (v) = T (α1v1 + . . . + αnvn) = T (α1v1) + . . . + T (αnvn)

= α1T (v1) + . . . + αnT (vn).

O que mostra que T (v1), . . . , T (vn) geram Im(T ).

Exemplo 1.22. Seja a transformação linear T : R3 → R3, T (x, y, z) = (2x − y − z, x − y −
z, x + y − z). Se w ∈ Im(T ) então w = T (x, y, z), ou seja,

w = (2x − y − z, x − y − z, x + y − z)

= x(2, 1, 1) + y(−1, −1, 1) + z(−1, −1, −1).

Logo todo vetor que pertence a imagem de T é gerado pelos vetores w1 = (2, 1, 1), w2 =
(−1, −1, 1) e w3 = (−1, −1, −1). Podemos então escrever que

Im(T ) = [(2, 1, 1), (−1, −1, 1), (−1, −1, −1)].

Exemplo 1.23. Considere a transformação linear

T

: R3 → M2



a + b
0

0
c − b


 .

T (a, b, c) =



Um elemento (a, b, c) ∈ R3 pertence ao núcleo de T se T (a, b, c) = 0. Então,





a + b
0

0
c − b


 =









0 0
0 0

se, e somente se, a = −b e c = b. Portanto,

N (T ) = {(−b, b, b)/b ∈ R}.

Por outro lado, a imagem de T é formada pelas matrizes de M2 da forma





a + b
0

0
c − b


 =


 +









a 0
0 0



 + b



1 0
0 0

0
b
0 −b



 +





0 0
0 c



 + c











0 0
0 1

0
1
0 −1

= a



com a, b, c ∈ R. Portanto,

β =










1 0
0 0


 ,





1
0
0 −1


 ,





0 0
0 1










é um conjunto gerador de Im(T ).

29

Teorema 1.24. Seja T : E → F uma transformação linear. Então:

(i) Im(T ) é um subespaço vetorial de F ;

(ii) N (T ) é um subespaço vetorial de E.

Demonstração. De fato, se u1, u2 ∈ Im(T ) e α ∈ R, temos u1 = T (v1) e u2 = T (v2),
onde v1, v2 ∈ E. Logo, u1 + u2 = T (v1) + T (v2) = T (v1 + v2) ∈ Im(T ) e αu1 = αT (v1) =
T (αv1) ∈ Im(T ), o que mostra que Im(T ) é um subespaço vetorial de F , pois v1 +v2, αv1 ∈ E
que é um espaço vetorial (provando (i)).

Por outro lado, se v1, v2 ∈ N (T ) e α ∈ R, logo T (v1) = T (v2) = ~0. Assim, T (v1 + v2) =
T (v1) + T (v2) = ~0 + ~0 = ~0 e T (αv1) = αT (v1) = α~0 = ~0, o que signiﬁca dizer que
v1 + v2, αv1 ∈ N (T ) e consequentemente N (T ) é um subespaço vetorial de E (provando
(ii)).

Figura 6 – Núcleo e imagem de uma transformação linear T : E → F

Fonte – Autoria própria (2019)

Deﬁnição 1.25. Seja T : E → F , quando Im(T ) = F , diz-se que a transformação T é
sobrejetiva. Isto signiﬁca que, para qualquer w ∈ F dado, pode-se achar v ∈ E tal que
T (v) = w.

Deﬁnição 1.26. Uma transformação linear T : E → F é dita injetiva quando tem-se u 6= v em
E ⇒ T (u) 6= T (v) em F . Equivalentemente: T (u) = T (v) ⇒ u = v.

Teorema 1.27. A ﬁm de que uma transformação linear T : E → F seja injetiva é necessário e
suﬁciente que seu núcleo N (T ) contenha apenas o vetor nulo.

Demonstração. Seja T injetiva. Então v ∈ N (T ) ⇒ T (v) = ~0 = T (~0) ⇒ v = ~0, logo
N (T ) = {~0}. Reciprocamente, seja N (T ) = {~0}. Então T (u) = T (v) ⇒ T (u − v) =
T (u) − T (v) = ~0 ⇒ u − v ∈ N (T ) ⇒ u − v = ~0 ⇒ u = v, logo T é injetiva.

Figura 7 – Transformação injetiva

Figura 8 – Transformação sobrejetiva

30

Fonte – Autoria própria (2019)

Fonte – Autoria própria (2019)

Exemplo 1.28. A transformação linear T : R3 → M2, onde T (a, b, c) =

Exemplo 1.23 não é injetiva, pois





a + b
0

0
c − b


 do

N (T ) = {(−b, b, b)/b ∈ R} 6= {(0, 0, 0)}.

Já a transformação linear S : R2 → R2 dada por T (x, y) = (x − y, x + y), é injetiva, pois

(x − y, x + y) = (0, 0) ⇔ (x, y) = (0, 0)

e, portanto, N (S) = {(0, 0)}.

Teorema 1.29. Uma transformação linear é injetiva se, e somente se, leva vetores linearmente
independentes em vetores linearmente independentes.

Demonstração. Seja T : E → F uma transformação linear injetiva. Se os vetores v1, . . . , vn ∈
E são linearmente independentes (LI), vamos provar que suas imagens T (v1), . . . , T (vn) são
vetores linearmente independentes em F . Com efeito,

α1T (v1) + . . . + αnT (vn) = ~0 ⇒ T (α1v1) + . . . + T (αnvn) = ~0

⇒ T (α1v1 + . . . + αnvn) = ~0
⇒ α1v1 + . . . + αnvn = ~0,

pois T é injetiva. Como v1, . . . , vn são LI, segue-se que α1 = . . . = αn = ~0, portanto
T (v1), . . . , T (vn) são LI.

Por outro lado, se a transformação linear T : E → F leva vetores LI em vetores
LI então, de qualquer conjunto LI de vetores v 6= ~0 em E, temos um conjunto de vetores
correspondente T (v) 6= ~0 em F também LI, o que signiﬁca dizer que N (T ) = {~0} e portanto,
pelo Teorema 1.27, T é injetiva.

31

Corolário 1.30. Seja T : E → F uma transformação linear. Seja {v1, . . . , vn} uma base de E,
T é sobrejetiva se, e somente se, T (v1), . . . , T (vn) geram F .

Demonstração. Como {v1, . . . , vn} é base de E, pela Proposição 1.21 temos que T (v1), . . . ,
T (vn) geram Im(T ). Mas T é sobrejetiva, logo T (v1), . . . , T (vn) geram F . Por outro lado, se
T (v1), . . . , T (vn) geram F , temos que qualquer w ∈ F é escrito como combinação linear de
T (v1), . . . , T (vn). Como, por hipótese, {v1, . . . , vn} é base de E, temos que T é sobrejetiva.

Segue-se do Teorema 1.29 que se E tem dimensão ﬁnita n e T : E → F é uma
transformação linear injetiva então dim F ≥ n, pois, considerando uma base {(v1, . . . , vn)} de
E, logo pelo Teorema 1.29 e pela Proposição 1.21 temos que {(T (v1), . . . , T (vn))} é linearmente
independente, mostrando consequentemente a impossibilidade de ocorrer em uma transformação
linear injetiva T : E → F , que a dim F < n. Por outro lado, do Corolário 1.30 temos que se E
tem dimensão ﬁnita n e T : E → F é uma transformação linear sobrejetiva então dim F ≤ n.

Neste contexto, por exemplo, não existe uma transformação linear injetiva de R3 em R2,

assim como também não existe uma transformação linear sobrejetiva de R2 em R3.

Exemplo 1.31. Considerando a transformação linear T : R2 → R3, onde T (x, y) = (−y, x, x +
y), temos que:

(i) é injetiva, pois

(−y, x, x + y) = (0, 0, 0) ⇔ (x, y) = (0, 0) ⇒ N (T ) = {(0, 0)}.

(ii) não é sobrejetiva, pois

(−y, x, x + y) = (0, x, x) + (−y, 0, y) = x(0, 1, 1) + y(−1, 0, 1)

com x, y ∈ R. O que signiﬁca dizer que α = {(0, 1, 1), (−1, 0, 1)} é um conjunto gerador
de Im(T ). Ademais, como os vetores (0, 1, 1) e (−1, 0, 1) são LI, temos que α é base e
consequentemente dim(Im(T )) = 2 < 3 = dim(R3).

Exemplo 1.32. Considerando a transformação linear T : R3 → R2 dada por T (x, y, z) =
(x + y, y + z), temos que:

(i) não é injetiva, pois

(x + y, y + z) = (0, 0) ⇔ (x, y, z) = (−y, y, −y) ⇒ N (T ) 6= {(0, 0, 0)}.

(ii) é sobrejetiva, pois

(x + y, y + z) = (x, 0) + (y, y) + (0, z) = x(1, 0) + y(1, 1) + z(0, 1)

32

com x, y, z ∈ R. O que signiﬁca dizer que α = {(1, 0), (1, 1), (0, 1)} é um conjunto
gerador de Im(T ). Porém, temos que o vetor (1, 1) = (1, 0) + (0, 1). Logo, os vetores
(1, 0) e (0, 1) são LI formando uma base para R2 (base canônica). Logo, dim(Im(T )) =
dim(R2).

Teorema 1.33. (Dimensão do núcleo e da imagem). Sejam E, F espaços vetoriais de dimensão
ﬁnita. Para toda transformação linear T : E → F tem-se

dim(N (T )) + dim(Im(T )) = dim(E).

(1.9)

Demonstração. Sejam E, F espaços vetoriais de dimensão ﬁnita e T : E → F onde N (T ) 6=
{~0} e Im(T ) 6= {~0}.

Dividiremos esta demonstração em duas etapas:

(a) Vamos mostrar inicialmente que se {T (u1), . . . , T (up)} é uma base de Im(T ) e {v1, . . . , vq}

é uma base do N (T ) então {u1, . . . , up, v1, . . . , vq} é uma base de E.

Com efeito, em primeiro lugar, se tivermos

α1u1 + . . . + αpup + β1v1 + . . . + βqvq = ~0

então, aplicando o operador T a ambos os membros desta igualdade e lembrando que
v1, . . . , vq pertencem ao núcleo de T , obtemos

T (α1u1 + . . . + αpup + β1v1 + . . . + βqvq) = T (~0)

α1T (u1) + . . . + αpT (up) + β1T (v1) + . . . + βpT (vq) = ~0
α1T (u1) + . . . + αpT (up) = ~0.

Como os vetores T (u1), . . . , T (up) são LI, resulta daí que α1 = . . . = αp = ~0. Portanto a
igualdade α1u1 + . . . + αpup + β1v1 + . . . + βqvq = ~0 se reduz a

β1v1 + . . . + βqvq = ~0.

Como v1, . . . , vq são LI, concluímos que β1 = . . . = βq = ~0. Isto mostra que os vetores
u1, . . . , up, v1, . . . , vq são LI.

Em seguida, consideremos um vetor arbitrário w ∈ E. Como T (w) ∈ Im(T ) e ademais
{T (u1), . . . , T (up)} é uma base da imagem de T , temos que

T (w) = α1T (u1) + . . . + αpT (up)

T (w) − (α1T (u1) + . . . + αpT (up)) = ~0
T (w − (α1u1 + . . . + αpup)) = ~0.

Assim, o vetor w − (α1u1 + . . . + αpup) pertence ao núcleo de T , logo pode ser expresso
como combinação linear dos elementos de sua base {v1, . . . , vq}. Temos então

w − (α1u1 + . . . + αpup) = β1v1 + . . . + βqvq,

33

ou seja, w = α1u1 + . . . + αpup + β1v1 + . . . + βqvq. Isto mostra que os vetores
u1, . . . , up, v1, . . . , vq geram E e portanto constituem uma base.

(b) Considerando {T (u1), . . . , T (up)} uma base de Im(T ), {v1, . . . , vq} uma base do N (T )
e {u1, . . . , up, v1, . . . , vq} uma base de E (provado em (a)), temos que dim(Im(T )) +
dim(N (T )) = p + q = dim(E), o que prova o resultado.

Exemplo 1.34. Seja O : E → F uma transformação linear nula, onde O(v) = ~0, para todo
vetor v ∈ E. O teorema é veriﬁcado, pois

Im(O) = {~0} ⇒ dim(Im(O)) = 0

e

N (O) = E ⇒ dim(N (O)) = dim(E).

Exemplo 1.35. Seja T : E → F uma transformação linear, onde N (T ) = {~0}. Perceba que se
N (T ) = {~0} então T é injetiva (Teorema 1.27). Além disso, pela Proposição 1.21 e pelo Teorema
1.29 temos que se {v1, . . . , vn} é uma base de E e T é injetiva, logo, {T (v1), . . . , T (vn)} é uma
base de Im(T ), Sendo assim, o resultado do teorema anterior também é veriﬁcado, pois, conclui-
se que dim(Im(T )) = dim(E).

Exemplo 1.36. (Retomando o Exemplo 1.23) Considerando a transformação linear

T

: R3 → M2



a + b
0

0
c − b


 .

T (a, b, c) =



Temos que se N (T ) = {(−b, b, b)/b ∈ R} então o conjunto {(−1, 1, 1)} é uma base do N (T ),
e consequentemente dim(N (T )) = 1.

Por outro lado, temos que o conjunto gerador da imagem de T é dado por

β =










1 0
0 0


 ,





1
0
0 −1


 ,





0 0
0 1










.

Como dim(N (T )) = 1 e dim(R3) = 3, pelo Teorema da dimensão do núcleo e da imagem,
temos que dim(Im(T )) = 2. Neste contexto, podemos concluir que β não é base para Im(T ).

Deﬁnição 1.37. Se uma transformação linear T : E → F é injetiva e sobrejetiva, então é
chamada isomorﬁsmo. Neste caso, dizemos que os espaços vetoriais E e F são isomorfos.

Teorema 1.38. Sejam E e F espaços vetoriais de dimensão ﬁnita n. Uma transformação linear
T : E → F é injetiva se, e somente se, é sobrejetiva e portanto é um isomorﬁsmo.

Demonstração. Com efeito, do Teorema da dimensão do núcleo e da imagem (1.33), temos que
n = dim(N (T )) + dim(Im(T )). Logo,

N (T ) = {~0} (T injetiva) ⇔ dim(Im(T )) = n ⇔ Im(T ) = F (T sobrejetiva).

34

Teorema 1.39. Sejam E e F espaços vetorias de dimensão ﬁnita. E é isomorfo a F se, e somente
se, dim(E) = dim(F ).

Demonstração. Diante do exposto no Teorema 1.38, basta mostrar que se dim(E) = dim(F ),
então E e F são isomorfos.

Sejam α = {u1, . . . , un} e β = {v1, . . . , vn} bases de E e F , respectivemente. Pelo
Teorema 1.12, existe uma única transformação linear T : E → F , tal que T (ui) = vi, para
i = 1, . . . , n. Pela Proposição 1.21, a imagem de T é gerada pelos vetores T (u1), . . . , T (un) e
assim

Im(T ) = [T (u1), . . . , T (un)] = [v1, . . . , vn] = F (T é sobrejetiva).

Pelo Teorema 1.33 (dimensão do núcleo e da imagem), T também é injetiva e portanto um
isomorﬁsmo.

1.4 SOMA DIRETA E PROJEÇÃO

Deﬁnição 1.40. Se W1, W2 são dois subespaços do espaço vetorial E. Dizemos que E é a soma
de W1 e W2 se todo elemento v ∈ E pode ser escrito como v = w1 + w2, onde w1 ∈ W1 e
w2 ∈ W2, no caso denotamos E = W1 + W2. Quando W1 ∩ W2 = {~0}, diremos que a soma
W1 + W2 é direta e, neste caso, escrevemos E = W1 ⊕ W2.

















 ; a, b, c ∈ R

e W2 =



a
0
0 −a






 ; a ∈ R

, dois



Exemplo 1.41. Sejam W1 =

a b
c a





subespaços vetoriais de M2.

1. M2 = W1 + W2. De fato, seja A =

Sendo A = B1 + B2, com B1 =





que






 ∈ M2.

a11 a12
a21 a22

 ∈ W1 e B2 =

a1
b1
c1 a1





0

a2
0 −a2


 ∈ W2, temos





a11 a12
a21 a22


 =

⇒











 +





a1
b1
c1 a1

0

a2
0 −a2

a1 + a2 = a11
= a12
b1
= a21
c1
a1 − a2 = a22

⇒










a1 = a11+a22
b1 =
c1 =
a2 = a11−a22

2
a12
a21

2

e portanto,





a11 a12
a21 a22


 =





|

a11+a22
2
a21

a12
a11+a22
2

{z
∈W1







+



}

|

a11−a22
2
0

0
a11−a22
2

{z
∈W2

35



.



}

2. W1 ∩ W2 = {~0}. De fato, se A ∈ W1 ∩ W2 então A ∈ W1 e, portanto,

(i) A ∈ W1 e, portanto, a11 = a22;

(ii) A ∈ W2 e, portanto, a12 = a21 = 0 e a11 = −a22.

Deste modo, por (i) e (ii) tem-se que a11 = a22 = 0.

Exemplo 1.42. Sejam W1 e W2 subespaços vetoriais de R2, gerados respectivamente pelos
vetores (1, 0) e (1, 1). Observe que R2 = W1 ⊕ W2. É claro que se (a, b) ∈ R2, então podemos
escrever (a, b) = (a−b)(1, 0)+b(1, 1). Por outro lado, W1∩W2 = {~0}, pois se (a, b) ∈ W1∩W2,
então (a, b) = c(1, 0) = d(1, 1), o que implica que c = d = 0.

Teorema 1.43. Sejam W1 e W2 subespaços de um espaço vetorial E. Temos que E = W1 ⊕ W2
se, e somente se, todo vetor v ∈ E se escreve, de modo único, como soma v = w1 + w2, onde
w1 ∈ W1 e w2 ∈ W2.

Demonstração. Suponhamos que E = W1 ⊕ W2. Logo, W1 ∩ W2 = {~0}. Sejam u1, w1 ∈ W1 e
u2, w2 ∈ W2 tais que

u1 + u2 = w1 + w2.

Somando-se −w1 − u2 em ambos os membros da igualdade acima, obtemos

u1 − w1
{z
}
|
∈W1

= w2 − u2
{z
}
∈W2

|

⇒ u1 − w1 = w2 − u2 ∈ W1 ∩ W2 = {~0},

o que implica que u1 = w1 e u2 = w2.

Por outro lado, suponhamos que todo elemento de v ∈ E se escreve, de modo único,
como soma v = w1 + w2, onde w1 ∈ W1 e w2 ∈ W2. Seja v ∈ W1 ∩ W2. Vamos mostrar que
v = ~0. Mas,

v = v
|{z}
∈W1

+ ~0
|{z}
∈W2

= v
|{z}
∈W2

.

+ ~0
|{z}
∈W1

Isto é, se v 6= ~0, teríamos duas formas de escrever v como uma soma de um elemento de W1 e
um de W2. Logo, v = ~0 e W1 ∩ W2 = {~0}. Portanto, como claramente E = W1 + W2, temos
que E = W1 ⊕ W2.

36

A noção de soma direta está intimamente ligada à noção de projeção. Se E = W1 ⊕ W2
é a decomposição do espaço vetorial E como soma direta dos subespaços W1 e W2, deﬁne-se o
operador linear P : E → E, projeção de E sobre W1, paralelamente a W2, do seguinte modo:
todo vetor w ∈ E se escreve, de modo único, como soma w = u + v de um vetor u ∈ W1 com
um vetor v ∈ W2. Põe-se, então, P (w) = u. Veja (Figura 9).

Figura 9 – Projeção de vetores

Fonte – Autoria própria (2019)

Observação 1: Perceba que o operador linear P : E → E deﬁnido acima é, de fato,
uma transformação linear, pois sendo W1, W2 subespaços vetoriais de E, com E = W1 ⊕ W2, e
considerando w1, w2 ∈ E tais quais w1 = u1+v1 e w2 = u2+v2, com u1, u2 ∈ W1 e v1, v2 ∈ W2.
Então, temos que P (w1) + P (w2) = u1 + u2 = P (w1 + w2) e P (αw1) = αu1 = αP (w1).

Observação 2: O operador linear P : E → E assim deﬁnido tem imagem W1 e núcleo
W2. Além disso, temos que sobre P vale a igualdade P 2 = P , pois, se w ∈ E, onde w = u + v,
sendo u ∈ W1 e v ∈ W2, logo

P 2(w) = (P ◦ P )(w) = P (P (w)) = P (u) = u = P (w).

(1.10)

O teorema a seguir (1.44) mostra que, reciprocamente, todo operador linear onde P 2 = P é uma
projeção.

Teorema 1.44. Seja P : E → E um operador linear. Se P 2 = P então E é a soma direta do
núcleo com a imagem de P . Ou seja, P é a projeção sobre Im(P ) paralelamente a N (P ).

Demonstração. Todo v ∈ E escreve-se como soma v = v−(P (v)−P (v)) = (v−P (v))+P (v),
onde P (v), evidentemente, pertence a Im(P ) e, como P (v − P (v)) = P (v) − P (P (v)) =
P (v)−P (v) = ~0, vemos que v−P (v) ∈ N (P ). Portanto E = N (P )+Im(P ). Se w ∈ N (P )∩
Im(P ), por um lado tem-se P (w) = ~0 e, por outro, P (w) = w (tendo em vista que estamos
supondo que w ∈ N (P ) e que w ∈ Im(P )); logo w = ~0. Assim N (P ) ∩ Im(P ) = {~0} e tem-
se a soma direta E = N (P ) ⊕ Im(P ). A última aﬁrmação do enunciado é uma consequência
direta da deﬁnição de P .

37

Exemplo 1.45. Considere os subconjuntos

W1 = {(x, y) ∈ R2; x + y = 0}
W2 = {(x, y) ∈ R2; x − y = 0}.

e

Temos que W1 + W2 = R2, pois se (x, y) ∈ R2, então

(x, y) =

(cid:18) x − y
2

,

y − x
2

(cid:19)

+

(cid:18) x + y
2

,

x + y
2

(cid:19)

,

,

(cid:19)

y − x
2

o que mostra que todo elemento de R2 se escreve como a soma de um elemento de W1 :
(cid:18) x − y
(cid:18) x + y
. Além disso, temos que W1 ∩ W2 =
2
2
{~0} e, portanto podemos deﬁnir o operador linear P , projeção de R2 sobre W1 paralelamente a
W2,

; e um elemento de W2 :

x + y
2

(cid:19)

,

P (x, y) =

(cid:18) x − y
2

,

y − x
2

(cid:19)

.

Cabe aqui mencionar que não podemos deﬁnir projeção se a soma não for direta, como

veremos abaixo.

Exemplo 1.46. Sejam W1 e W2 subespaços vetoriais de R3 sobre a base canônica, dados por

W1 = {(x1, 0, z1); x1, z1 ∈ R}
W2 = {(x2, y2, 0); x2, y2 ∈ R}

(plano y = 0)

e

(plano z = 0).

Note que, W1 + W2, pois

(a, b, c) ∈ R3 ⇒ (a, b, c) = (a, 0, c)
}

|

{z
∈W1

.

+ (0, b, 0)
{z
}
∈W2

|

Mas, a soma de W1 com W2 não é direta, pois

W1 ∩ W2 = {(x, 0, 0); x ∈ R} (eixo x).

Neste contexto, não podemos deﬁnir projeção, pois se considerarmos, por exemplo, o

vetor (3, 0, 0), temos que

(1, 0, 0)
}
{z
|
∈W1

+ (2, 0, 0)
}
{z
∈W2

|

= (3, 0, 0) = (1, 0, 0)
}

|

{z
∈W2

,
+ (2, 0, 0)
}
{z
∈W1

|

o que contraria o fato de que a decomposição deve ser única e o fato de a decomposição não ser
única faz com que uma possível função projeção não esteja bem deﬁnida, no exemplo em questão,
poderíamos projetar (3, 0, 0) tanto em (1, 0, 0) quanto em (2, 0, 0) (ou, ainda, em qualquer vetor
(α, 0, 0), com α ∈ R).

38

1.5 ESPAÇO VETORIAL COM PRODUTO INTERNO

1.5.1 PRODUTO INTERNO

Deﬁnição 1.47. Seja E um espaço vetorial. Um produto interno em E é uma função que a
cada par de vetores u e v em E associa um número real, denotado por hu, vi, que satisfaz, para
quaisquer vetores u, v, w de E e qualquer número real α, as seguintes propriedades:

P1 hv, vi ≥ 0;

P2 hv, vi = 0 se, e somente se, v = ~0;

P3 hu, vi = hv, ui;

P4 hu + v, wi = hu, wi + hv, wi;

P5 hαu, vi = αhu, vi.

Se está deﬁnido um produto interno em E, dizemos que E é um espaço vetorial com
produto interno. Vejamos a deﬁnição de um produto interno em Rn, chamado de produto
interno usual de Rn ou produto escalar de Rn, generalizando a noção de produto escalar de R2 e
de R3.

Exemplo 1.48. Sejam u = (x1, . . . , xn) e v = (y1, . . . , yn) vetores em Rn.

Deﬁnamos

Note que

e que

hu, vi = x1y1 + . . . + xnyn.

hu, ui = x1x1 + . . . + xnxn = x2

1 + . . . + x2

n ≥ 0,

hu, ui = x2

1 + . . . + x2

n = 0 ⇐⇒ x1 = . . . = xn = 0 ⇐⇒ u = ~0,

mostrando que as propriedades P1 e P2 da Deﬁnição 1.47 são satisfeitas. A propriedade P3
também é satisfeita já que

hu, vi = x1y1 + . . . + xnyn = y1x1 + . . . + ynxn = hv, ui.

Ademais, se w = (z1, . . . , zn) ∈ Rn e α ∈ R, perceba que as propriedades P4 e P5 também são
atendidas, pois

hu + v, wi = (x1 + y1)z1 + . . . + (xn + yn)zn

= x1z1 + y1z1 + . . . + xnzn + ynzn

= (x1z1 + . . . + xnzn) + (y1z1 + . . . + ynzn)

= hu, wi + hv, wi

39

e

hαu, vi = (αx1)y1 + . . . + (αxn)yn

= α(x1y1) + . . . + α(xnyn)

= α(x1y1 + . . . + xnyn)

= αhu, vi.

Proposição 1.49. Seja E um espaço com produto interno. Se u, v, w ∈ E e α ∈ R, então

(i)

h~0, ui = hu,~0i = 0;

(ii) hu, v + wi = hu, vi + hu, wi;

(iii) hu, αvi = αhu, vi;

(iv) hu, v − wi = hu, vi − hu, wi.

Demonstração. De fato, se E um espaço com produto interno, com u, v, w ∈ E e α ∈ R, diante
do exposto na Deﬁnição 1.47, temos que

(i) Das propriedades P3, P4 e P5 da deﬁnição de produto interno

hu,~0i = h~0, ui = hu + (−u), ui = hu, ui + h−u, ui

= hu, ui + (−1)hu, ui

= hu, ui − hu, ui

= 0;

(ii) Das propriedades P3 e P4

hu, v + wi = hv + w, ui = hv, ui + hw, ui

= hu, vi + hu, wi;

(iii) Das propriedades P3 e P5

hu, αvi = hαv, ui = αhv, ui = αhu, vi;

(iv) Dos itens (ii) e (iii) (colocando α = −1)

hu, v − wi = u, v + (−w)i = hu, vi + hu, −wi

= hu, vi + (−1)hu, wi

= hu, vi − hu, wi.

40

Considerando o exposto no Exemplo 1.48, note que podemos deﬁnir o produto interno
usual de Rn como multiplicação de matrizes (SANTOS, 2006). Sejam u = (x1, . . . , xn) e
v = (y1, . . . , yn) vetores em Rn. Escrevendo os vetores u e v como matrizes colunas, temos que
y1
...
yn

pode ser escrito em termos do produto entre

o produto interno de U =

x1
...
xn

e V =





























as matrizes como

hU, V i = U T V.

(1.11)

Deﬁnição 1.50. Seja E um espaço vetorial com produto interno. Para todo vetor v ∈ E,
deﬁnimos a norma de E denotada por kvk como sendo

kvk =

q

hv, vi.

(1.12)

Se kvk = 1, dizemos que v é um vetor unitário. Dado um vetor v, com kvk 6= 1, o vetor

u unitário com mesma direção e sentido de v é dado por

u =

1
kvk

v

(1.13)

pois,

kuk2 =

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
kvk

v

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

* 1
kvk

v,

1
kvk

v

+

=

1
kvk2 hv, vi =

kvk2
kvk2 = 1 =⇒ kuk = 1.

(1.14)

Neste caso, dizemos que o vetor u está normalizado, o que signiﬁca que seu compri-

mento é igual a 1 unidade.

Exemplo 1.51. Vamos determinar o vetor normalizado do vetor u = (1, −2, 3).

Como kuk =

q

hu, ui =

q

12 + (−2)2 + 32 =

√

14, o vetor normalizado de u é o vetor:

u1 =

u
kuk

=

1
√
14

(1, −2, 3) =

  1
√

14

,

−2
√
14

,

3
√
14

!

.

Proposição 1.52. Seja E um espaço com produto interno. Se u, v ∈ E e α ∈ R, então

(i)

kvk ≥ 0 e kvk = 0 se, e somente se, v = ~0;

(ii) kαvk = |α|kvk;

(iii) |hu, vi| ≤ kukkvk (Desigualdade de Cauchy-Schwarz);

(iv) ku + vk ≤ kuk + kvk (Desigualdade triangular).

41

Demonstração. Se E um espaço com produto interno, então dados u, v ∈ E e α ∈ R, temos
que

(i) Decorre das propriedades P1 e P2 da deﬁnição de produto interno (1.47);

(ii) kαvk =

q

hαv, αvi =

q

α2hv, vi =

√

α2

q

hv, vi = |α|kvk;

(iii) Se os vetores u e v são linearmente dependentes, então existe α ∈ R tal que u = αv, e

assim temos:

|hu, vi| = |hαv, vi| = |αhv, vi| = |α|hv, vi = |α|
q

q

q

hv, vi

hv, vi

q

q

α2hv, vi

hv, vi

q

q

hαv, αvi
q

hu, ui

hv, vi

hv, vi

=

=

=

Por outro lado, se u e v forem linearmente independentes (LI), então para todo α ∈ R
temos que hu + αv, u + αvi > 0 (propriedade P1 da deﬁnição de produto interno (1.47)).
Logo,

= kukkvk.

hu + αv, u + αvi = hu, ui + αhu, vi + αhv, ui + α2hv, vi

= hv, viα2 + 2hu, viα + hu, ui > 0

que é uma inequação do 2º grau na variável α. Neste contexto, temos que a equação
hv, viα2 + 2hu, viα + hu, ui = 0 não possui raízes reais, o que signiﬁca dizer que seu
discriminante é menor que zero. Logo,

4hu, vi2 − 4hv, vihu, ui < 0 ⇒ 4hu, vi2 < 4hv, vihu, ui

⇒ hu, vi2 < hv, vihu, ui

⇒ hu, vi2 < kuk2kvk2

⇒

q

hu, vi2 <

q

kuk2kvk2

⇒ |hu, vi| < kukkvk,

provando o resultado.

(iv) Temos,

ku + vk2 = hu + v, u + vi

= hu, ui + hu, vi + hv, ui + hv, vi

= kuk2 + 2hu, vi + kvk2

≤ kuk2 + 2|hu, vi| + kvk2

pois, x ≤ |x| para todo x ∈ R

≤ kuk2 + 2kukkvk + kvk2
= (kukkvk)2 .

pela desiguladade de Cauchy-Schwarz

Extraindo as raízes quadradas em ambos os lados da desigualdade acima obtemos a
desigualdade desejada.

42

Deﬁnição 1.53. Deﬁnimos o ângulo entre dois vetores não nulos u e v como sendo o numero
real θ entre 0 e π tal que

cos θ =

hu, vi
kukkvk

.

(1.15)

Perceba que pela desigualdade Cauchy-Schwarz o ângulo θ está bem deﬁnido, pois se

dividirmos a expressão |hu, vi| ≤ kukkvk por kukkvk obtemos

|hu, vi|
kukkvk

≤ 1 ⇔ −1 ≤

hu, vi
kukkvk

≤ 1.

(1.16)

Como cos θ assume, uma única vez, cada valor no intervalo [−1, 1] quando θ varia no intervalo

[0, π], segue de (1.15) que existe um único θ ∈ [0, π] tal que cos θ =

hu, vi
kukkvk

.

Exemplo 1.54. Vamos calcular o o ângulo θ entre os vetores u = (2, −2) e v = (6, −1). Como

kuk =

kvk =

q

q

22 + (−2)2 =

62 + (−1)2 =

√

√

√

2

8 = 2

37

hu, vi = 2 · 6 + (−2) · (−1) = 14,

segue que

e, portanto, θ ≈ 36◦.

cos θ =

hu, vi
kukkvk

=

14
√
2

√
2

37

=

7
√
74

≈ 0, 814

Exemplo 1.55. Sejam u = (x1, . . . , xn) e v = (y1, . . . , yn) vetores não nulos em Rn. Vamos
veriﬁcar geometricamente o ângulo θ entre u e v.

Figura 10 – Diferença v − u

Fonte – Autoria própria (2019)

Supondo que u e v não são múltiplos e aplicando Lei dos Cossenos ao triângulo determi-

nado pelos vetores u, v e v − u (Figura 10), obtemos:

kv − uk2 = kuk2 + kvk2 − 2kukkvk cos θ,

43

Daí:

2kukkvk cos θ

= kuk2 + kvk2 − kv − uk2

(cid:17)

(cid:16)

=

+

= x2

1 + . . . + x2
x2
n
n + y2
1 + . . . + x2
n + y2
1 + . . . + x2
= 2x1y1 + . . . + 2xnyn

= x2

(cid:16)

(cid:16)

(cid:17)

−

1 + . . . + y2
y2
n
(cid:16)
y2
1 − 2x1y1 + x2
n −
1 + 2x1y1 − x2
n − y2

(y1 − x1)2 + . . . + (yn − xn)2(cid:17)
1 + . . . + y2
1 − . . . − y2

1 + . . . + y2
1 + . . . + y2

n − 2xnyn + x2
n
n + 2xnyn − x2
n

(cid:17)

= 2(x1y1 + . . . + xnyn).

Portanto,

kukkvk cos θ = x1y1 + . . . + xnyn = hu, vi ⇔ cos θ =

hu, vi
kukkvk

.

No caso em que u e v são múltiplos, temos que, existe um número real λ 6= 0 tal que u = λv.
Logo, xi = λyi, para i = 1, . . . , n. Como cos ∠(λv, v) = 1 se λ > 0 e cos ∠(λv, v) = −1 se
λ < 0, segue que

hu, vi = kλvkkvk = kλvkkvk cos θ = kukkvk cos θ

comprovando o resultado.

1.5.2 ORTOGONALIDADE E PROJEÇÃO ORTOGONAL

Deﬁnição 1.56. Seja E um espaço vetorial com produto interno e sejam u, v ∈ E. Dizemos que
u e v são ortogonais se hu, vi = 0. Um subconjunto W de E é chamado de ortogonal se os
seus elementos são ortogonais dois a dois e dizemos que W é um conjunto ortonormal se for
um conjunto ortogonal e se kuk = 1, ∀u ∈ W .

Perceba que pela Equação (1.15) u e v são ortogonais se, e somente se, cos θ = 0, onde

θ é o ângulo entre u e v, e isto é verdade se, e somente se, θ =

π
2

.

Usaremos a notação u ⊥ v para indicar que os vetores u e v são ortogonais. Perceba
que a ortogonalidade depende do produto interno, isto é, dois vetores podem ser ortogonais em
relação a um produto interno mas não em relação a outro.

Exemplo 1.57. Seja E um espaço vetorial com produto interno. O vetor nulo ~0 é ortogonal a
todos os elementos de E, pois h0, vi = 0, para todo v ∈ E (item (i) da Proposição 1.49).

44

Exemplo 1.58. Considere o R3 com o produto interno usual e o conjunto

X = {w1 = (1, 1, 1), w2 = (−1, 1, 0), w3 = (−1, −1, 2)}.

(a) W é ortogonal, pois

hw1, w2i = h(1, 1, 1), (−1, 1, 0)i = −1 + 1 + 0 = 0,

hw1, w3i = h(1, 1, 1), (−1, −1, 2)i = −1 − 1 + 2 = 0,

hw2, w3i = h(−1, 1, 0), (−1, −1, 2)i = 1 − 1 + 0 = 0.

(b) Note que

kw1k = k(1, 1, 1)k =

q

kw2k = k(−1, 1, 0)k =

√

3,

h(1, 1, 1), (1, 1, 1)i =
q

h(−1, 1, 0), (−1, 1, 0)i =
q

√

2,

√

6.

kw3k = k(−1, −1, 2)k =

h(−1, −1, 2), (−1, −1, 2)i =

Assim, obtendo vetores u1, u2 e u3 unitários de mesma direção e sentido que os vetores
(1, 1, 1), (−1, 1, 0) e (−1, −1, 2), respectivamente, temos

u1 =

u2 =

u3 =

1
kw1k
1
kw2k
1
kw3k

w1 =

w2 =

w3 =

1
√
3
1
√
2
1
√
6

!

,

!

, 0

,

(1, 1, 1) =

  1
√
3

,

1
√
3

,

1
√
3

(−1, 1, 0) =

−

(−1, −1, 2) =

1
√
2

,

1
√
2
1
√
6

−

, −

1
√
6

,

2
√
6

!

.

Logo, {u1, u2, u3} é um conjunto ortonormal.

Teorema 1.59. Num espaço vetorial E com produto interno, todo conjunto ortogonal X de
vetores não-nulos é LI.

Demonstração. Sejam v1, . . . , vn ∈ X. Pela ortogonalidade de X, temos que hvi, vji = 0 se
i 6= j, ademais, da deﬁnição de norma hvi, vii = kvik2. Se α1v1 + . . . + αnvn = 0 é uma
combinação linear nula desses vetores então, para cada i = 1, 2, . . . , n, tomando o produto
interno de ambos os membros desta igualdade por vi temos que

hα1v1 + . . . + αnvn, vii = h0, vii ⇒ α1hv1, vii + . . . + αnhvn, vii = 0

⇒ αihvi, vii = αikvik2 = 0.

Como os vetores pertencentes ao conjunto X são todos não-nulos, temos

αikvik2 = 0 =⇒ αi = 0,

o que signiﬁca dizer que os coeﬁcientes da combinação linear α1v1 + . . . + αnvn = 0 são todos
iguais a zero e os vetores do conjunto X são, portanto, linearmente independentes.

 
 
A recíproca do resultado acima é falsa, pois, por exemplo, o conjunto {(1, 1), (1, 0)} de

vetores em R2 com o produto interno usual é linearmente independente, como se segue

45

a(1, 1) + b(1, 0) = ~0 =⇒ a = b = 0

mas não é um conjunto ortogonal, pois

h(1, 1), (1, 0)i = 1 6= 0.

Se α = {v1, . . . , vn} é um conjunto ortogonal de vetores não nulos de E, e além disso
dim(E) = n, segue do teorema anterior que α é uma base de E. Uma base de vetores ortogonais
é chamada base ortogonal e uma base de vetores ortonormais é chamada base ortonormal.

Teorema 1.60. Se α = {v1, . . . , vn} é uma base ortonormal de E, então, para todo v ∈ E,
podemos escrever

v = hv, v1iv1 + . . . + hv, vnivn.

(1.17)

Demonstração. Seja v = a1v1 + . . . + anvn a combinação linear de v com relação aos elementos
da base α. Fixe i, com 1 ≤ i ≤ n. Temos

hv, vii = ha1v1 + . . . + anvn, vii

= a1hv1, vii + . . . + anhvn, vii = ai

pois hvj, vii = 0 se j 6= i e hvi, vii = kvik2 = 1. Como i foi tomado de modo arbitrário, a
demostração está completa.

Se β = {v1, . . . , vn} é uma base ortogonal de E, normalizando cada um dos vetores de

β, obtemos a base ortonormal α de E, onde
( v1
kv1k

α =

, . . . ,

)

.

vn
kvnk

Pelo Teorema 1.60, para cada vetor v em E, temos que

*

v =

v,

v1
kv1k

+ v1
kv1k

*

+ . . . +

v,

vn
kvnk

+ vn
kvnk

=

hv, v1i
kv1k2 v1 + . . . +

hv, vni
kvnk2 vn.

O número real

ai =

hv, vii
kvik2

(1.18)

é chamado de coeﬁciente de Fourier de v em relação ao vetor vi. Este escalar admite uma
interpretação geométrica relacionada com a noção de projeção.

46

(1.19)

Proposição 1.61. Seja w um vetor não nulo de E. Se v ∈ E, então

k =

hv, wi
hw, wi

=

hv, wi
kwk2

é o único número real tal que v0 = v − kw é ortogonal a w.

Demonstração. Para que v0 seja ortogonal a w devemos ter

hv − kw, wi = 0 ⇒ hv, wi − hkw, wi = 0

⇒ hv, wi = khw, wi

⇒ k =

hv, wi
hw, wi

.

Reciprocamente, suponhamos que k =

hv, wi
hw, wi

· Então,

hv − kw, wi = hv, wi − khw, wi = hv, wi −

hv, wi
hw, wi

hw, wi = 0,

o que mostra que v − kw é ortogonal a w.

Deﬁnição 1.62. Considerando o escalar k da Proposição 1.61 (coeﬁciente de Fourier de v em
relação ao vetor w). A projeção ortogonal de v sobre w (Figura 11) é denotada por projw(v) e
é deﬁnida por

projw(v) = kw =

hv, wi
hw, wi

w =

hv, wi
kwk2 w.

(1.20)

Figura 11 – Projeção ortogonal

Fonte – Autoria própria (2019)

Exemplo 1.63. Seja o espaço vetorial R3 com o produto interno usual. Vamos determinar a
projeção ortogonal do vetor v = (3, 4, 6) sobre o vetor u = (6, 8, 0) (Figura 12).

proju(v) =

hv, ui
kuk2 u =

h(3, 4, 6), (6, 8, 0)i
h(6, 8, 0), (6, 8, 0)i

(6, 8, 0) =

1
2

(6, 8, 0) = (3, 4, 0).

Figura 12 – Projeção ortogonal do vetor v = (3, 4, 6) sobre o vetor u = (6, 8, 0)

47

Fonte – Autoria própria (2019)

Exemplo 1.64. Seja E = C0[−1, 1] o conjunto das funções contínuas do intervalo [−1, 1] em R
com o produto interno deﬁnido por

hf, gi =

Z 1

−1

f (t)g(t)dt.

Vamos determinar a projeção de t3 sobre t.

(cid:16)

(cid:17)
projt(t3)

(t) =

ht3, ti
ktk2 t =

ht3, ti
ht, ti

t =

R 1
−1 t4dt
R 1
−1 t2dt

t =

2/5
2/3

t =

3
5

t.

Proposição 1.65. (Generalização da Proposição 1.61) Suponhamos que {w1, . . . , wr} seja um
conjunto ortogonal de vetores não nulos de E. Se v ∈ E, então

ki =

hv, wii
hwi, wii

=

hv, wii
kwik2 ,

1 ≤ i ≤ r,

são os únicos números reais tais que o vetor

v0 = v − k1w1 − k2w2 − . . . − krwr

é ortogonal aos vetores w1, . . . , wr.

(1.21)

(1.22)

Demonstração. Considerando que {w1, . . . , wr} é ortogonal, temos que hwi, wji = 0 se i 6= j.
Neste contexto, para que v0 seja ortogonal ao vetor wi, 1 ≤ i ≤ r, devemos ter

hv − k1w1 − k2w2 − . . . − krwr, wii = 0

⇒ hv, wii − k1hw1, wii − . . . − krhwr, wii = 0

⇒

⇒

hv, wii − kihwi, wii

= 0

hv, wii = kihwi, wii,

mostrando que ki =

hv, wii
hwi, wii

hv, wii
kwik2 · Por outro lado, se ki =
hv − k1w1 − . . . − krwr, wii = hv, wii − k1hw1, wii − . . . − krhwr, wii

hv, wii
hwi, wii

, então

=

= hv, wii − kihwi, wii

= hv, wii −

hv, wii
hwi, wii

hwi, wii = 0,

o que mostra que v0 é ortogonal aos vetores w1, . . . , wr, completando a demonstração.

48

Veremos a seguir que todo espaço com produto interno, não nulo, de dimensão ﬁnita tem
uma base ortonormal. A construção dada na prova do resultado abaixo é chamada de processo de
ortogonalização de Gram-Schmidt, pois leva os nomes de Jorgen Pedersen Gram (Dinamarca,
1850 - 1916) e de Erhard Schmidt (Alemanha, 1876 - 1959).

Teorema 1.66. O espaço E possui uma base ortogonal.

Demonstração. Seja {v1, . . . , vn} uma base de E. Tomemos

w1 = v1,

w2 = v2 −

w3 = v3 −

hv2, w1i
kw1k2 w1,
hv3, w1i
kw1k2 w1 −

...

hv3, w2i
kw2k2 w2,

wn = vn −

hvn, w1i
kw1k2 w1 − . . . −

hvn, wn−1i
kwn−1k2 wn−1.

Pela Proposição 1.65, o conjunto {w1, . . . , wn} é um conjunto ortogonal. Além disso, como o
conjunto {v1, . . . , vn} é linearmente independente, cada vetor wi é não nulo. Assim, o conjunto
{w1, . . . , wn} é um conjunto ortogonal de vetores não nulos de E. Como, por deﬁnição, n =
dim(E), segue pelo Teorema 1.59 que {w1, . . . , wn} é uma base ortogonal de E.

Exemplo 1.67. Considere o espaço R3 com o produto interno usual. Apliquemos o processo de
Gram-Schmidt ao conjunto T = {(1, 0, 0), (1, 1, 1), (0, 0, 1)} para obtermos uma base ortogonal
{w1, w2, w3} de R3.

Primeiramente perceba que T é uma base de R3, já que dim(R3) = 3 e ademais T é

linearmente independentes, pois

a(1, 0, 0) + b(1, 1, 1) + c(0, 0, 1) = (a + b, b, b + c) = 0 =⇒ a = b = c = 0.

Façamos

w1 = (1, 0, 0),

w2 = (1, 1, 1) −

w3 = (0, 0, 1) −

−

h(1, 1, 1), (1, 0, 0)i
k(1, 0, 0)k2
h(0, 0, 1), (1, 0, 0)i
k(1, 0, 0)k2
h(0, 0, 1), (0, 1, 1)i
k(0, 1, 1)k2

(1, 0, 0) = (0, 1, 1),

(1, 0, 0)

(0, 1, 1) =

(cid:18)

0, −

(cid:19)

.

1
2

,

1
2

(cid:26)

Assim,

(1, 0, 0), (0, 1, 1),

(cid:19)(cid:27)

(cid:18)

0, −

1
2

,

1
2

é uma base ortogonal de R3.

Corolário 1.68. Qualquer espaço vetorial E possui uma base ortonormal.

Demonstração. Como E possui uma base ortogonal (Teorema 1.66), basta normalizar cada
vetor da respectiva base para obter uma base ortonormal.

Exemplo 1.69. Do Exemplo 1.67, segue que
gonal de R3. Como

(cid:26)

(1, 0, 0), (0, 1, 1),

(cid:19)(cid:27)

(cid:18)

0, −

1
2

,

1
2

é uma base orto-

49

k(1, 0, 0)k =

k(0, 1, 1)k =

q

q

h(1, 0, 0), (1, 0, 0)i = 1,
√

h(0, 1, 1), (0, 1, 1)i =

2,

(cid:18)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

0, −

1
2

,

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
2

=

s(cid:28)(cid:18)

0, −

1
2

,

1
2

(cid:19)

(cid:18)

,

0, −

(cid:19)(cid:29)

1
2

,

1
2

=

1
√
2

,

Normalizando os vetores, temos que

(1, 0, 0) = (1, 0, 0),

1
k(1, 0, 0)k
1
k(0, 1, 1)k

(0, 1, 1) =

1
0, − 1
2, 1

2

(cid:16)

(cid:13)
(cid:13)
(cid:13)

(cid:17)(cid:13)
(cid:13)
(cid:13)

(cid:18)

0, −

(cid:19)

1
2

,

1
2

=

1
√
2

√
2

(0, 1, 1) =

0,

(cid:18)

0, −

(cid:19)

1
2

,

1
2

=

1
√
2

,

0, −

!

1
√
2
√
2
2

0,

!

.

=
√
2
2

,

√

2
2

,

√

2
2

!

,

(

Logo,

(1, 0, 0),

0,

!

√
2
2

,

√
2
2

,

0, −

!)

√

2
2

,

√

2
2

é um base ortonormal de R3.

Deﬁnição 1.70. Seja E um espaço vetorial com produto interno, e seja W ⊆ E um subconjunto
de E. Chamamos de complemento ortogonal de W ao conjunto

W ⊥ = {v ∈ E : hv, ui = 0, ∀u ∈ W }.

(1.23)

Exemplo 1.71. Para R2 com o produto interno usual e W = {(1, 2)}, temos

W ⊥ = {(x, y) ∈ R2; h(x, y), (1, 2)i = 0}
= {(x, y) ∈ R2; x + 2y = 0}
= {(x, y) ∈ R2; x = −2y}
= {(−2y, y) ∈ R2; y ∈ R}.

Proposição 1.72. Seja W um subconjunto de um espaço com produto interno E. Então W ⊥ é
um subespaço de E.

Demonstração. ∀u ∈ W , α ∈ R e v1, v2 ∈ W ⊥, temos que

• ~0 ∈ W ⊥ pois h~0, ui = 0;

• hv1, ui = hv2, ui = 0. Logo, hv1 + v2, ui = hv1, ui + hv2, ui = 0, e então v1 + v2 ∈ W ⊥;

• hαv1, ui = αhv1, ui = 0.

 
 
 
 
 
50

O que garante que W ⊥ é um subespaço vetorial de E (mesmo que W não tenha estrutura de
espaço vetorial).

Proposição 1.73. Seja E um espaço vetorial sobre R com produto interno. Sejam W ⊆ E um
subconjunto e β = {w1, . . . , wk} um conjunto gerador para W . Então v ∈ W ⊥ se, e somente se,
hv, wii = 0, para cada i = 1, . . . , k.

Demonstração. Sejam w ∈ W e β = {w1, . . . , wk} um conjunto gerador para W . Então,
existem α1, . . . , αk ∈ R tais que w = α1w1 + . . . + αkwk. Logo,

hv, wi = hv, α1w1 + . . . + αkwki = α1hv, w1i + . . . + αkhv, wki.

Se assumirmos que hv, wii = 0 para cada i = 1, . . . , k, segue que hv, wi = 0, o que signiﬁca
dizer que, v ∈ W ⊥. Por outro lado, se v ∈ W ⊥, então hv, wi = 0, para cada v ∈ W . Em
particular, hv, wii = 0 para cada i = 1, . . . , k.

Exemplo 1.74. Seja M2 o espaço vetorial das matrizes de ordem 2, com o produto interno

hA, Bi = a11b11 + a12b12 + a21b21 + a22b22,

onde A = (aij)i,j e B = (bij)i,j, i, j = 1, 2. Seja

W =










x

y
x + y w


 ; x, y, w ∈ R






.

(i) Determinar uma base ortogonal de W .

Note que,





x

y
x + y w


 =


 +









x 0
x 0



 + y



1 0
1 0

0 y
y 0



 +





0
0
0 w



 + w











0 0
0 1

0 1
1 0

= x



é um conjunto gerador

o que signiﬁca dizer que β =










1 0
1 0


 ,





0 1
1 0


 ,





0 0
0 1

de W . Além disso, vê-se facilmente que β é LI, pois














a

b
a + b c


 =





0 0
0 0


 ⇒





a = 0
b = 0
c = 0

.

Assim, β é uma base de W . No entanto, β não é ortogonal, pois

*


1 0
1 0


 ,





0 1
1 0



+



= 1 6= 0.

51

Aplicando o processo de ortogonalização de Gram-Schmidt à base β, temos

w1 =





0 0
0 1


 ,

w2 =





0 1
1 0


 −

w3 =





1 0
1 0


 −

*


*


*


−



+





+





+



0 1
1 0
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)



1 0
1 0
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)



1 0
1 0
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)




 ,





0 0
0 1


 ,



0 0
0 1


 ,



0 1
1 0

0 0
0 1
(cid:13)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)



0 0
0 1
(cid:13)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)



0 1
1 0
(cid:13)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)







0 0
0 1


 =






 ,

0 1
1 0





0 0
0 1









0 1
1 0


 =






 .

1 − 1
2
1
0
2

Portanto uma base ortogonal para W é dada pelo conjunto










1 − 1
2
1
0
2


 ,





0 1
1 0


 ,





0 0
0 1

(ii) Determinar uma base ortogonal de W ⊥.

 ∈ W ⊥, com a, b, c, d ∈ R. Então

Seja v =





a b
c d










.






*


*


a b
c d

a b
c d


 ,


 ,









*


a b
c d


 ,





0 0
0 1

0 1
1 0
1 − 1
2
1
0
2



+



= 0



+



= 0

⇒



+



= 0





0
d =
c = −b
b
a =

.

Logo W ⊥ =










b
b
−b 0


 ; b ∈ R






e, portanto, uma base para W ⊥ é dada pelo conjunto










1 1
−1 0

Teorema 1.75. Se W é um subespaço de E , então










.

E = W ⊕ W ⊥.

(1.24)

52

Demonstração. Vamos provar inicialmente que W ∩ W ⊥ = {~0}. Para tanto, suponhamos por
absurdo que W ∩ W ⊥ 6= {~0}. Isto signiﬁca dizer que existe um vetor não nulo v ∈ W ∩ W ⊥ tal
que v ∈ W e v ∈ W ⊥. Como W ⊥ é complemento ortogonal de W temos que kvk2 = hv, vi = 0,
o que é um absurdo pois v 6= ~0. Portanto, W ∩ W ⊥ = {~0}.

Vejamos que E = W + W ⊥. Pelo processo de ortogonalização de Gram-Schmidt, existe

uma base ortonormal {v1, . . . , vn} de W . Tomemos v ∈ E. Deﬁna

w1 = hv, v1iv1 + . . . + hv, vnivn = projW (v),

w2 = v − w1.

Note que w1 + w2 = w1 + (v − w1) = v. Além disso, w1 ∈ W , pois w1 é uma combinação
linear dos vetores da base de W . Portanto, resta mostrar que w2 ∈ W ⊥, ou seja, w2 é ortogonal a
W . Para isto, pela Proposição 1.73, basta veriﬁcar que w2 é ortogonal a cada vetor vi da base de
W , com i = i, . . . , n, o que é verdade pelo exposto na Proposição 1.65, pois a base {v1, . . . , vn}
de W é ortonormal.

Do Teorema 1.75, acima demonstrado, temos que cada vetor v de E pode ser escrito de

modo único como

v = w1 + w2

(1.25)

onde w1 ∈ W e w2 ∈ W ⊥. O vetor w1 é chamado projeção ortogonal de v em W e é denotado por
projW (v). O vetor w2 é chamado componente de v ortogonal a W e é denotado por projW ⊥(v).
Assim, v = projW (v) + projW ⊥(v) (Figura 13).

Figura 13 – v = projW (v) + projW ⊥(v)

Fonte – Autoria própria (2019)

Exemplo 1.76. (Retomando o Exemplo 1.74) Considerando o espaço vetorial M2 com produto
interno deﬁnido,

W =










x

y
x + y w


 ; x, y, w ∈ R






e

W ⊥ =










b
b
−b 0


 ; b ∈ R






53

.

Pelo Teorema 1.75 temos que M2 = W ⊕ W ⊥.

Além disso, se supormos por absurso que W ∩ W ⊥ 6= {~0}, então existe um vetor
v ∈ W ∩ W ⊥ não nulo tal que v ∈ W e v ∈ W ⊥. Assim, como W ⊥ é complemento ortogonal
de W temos que hv, vi = kvk2 6= 0, o que é um absurdo. Portanto, W ∩ W ⊥ = {~0}.

2 PROJEÇÕES E ANÁLISE NUMÉRICA

54

O estudo de projeções é um assunto clássico no estudo de álgebra linear com muita
utilidade na área de Análise Numérica, onde desempenha importante papel no desenvolvimento
de métodos para resolução dos mais diversos tipos de problemas. Em se tratando da resolução de
sistemas lineares, podemos citar dois dos principais métodos iterativos baseados em projeção
sobre subespaços de Krylov: Métodos dos Gradientes Conjugados (Conjugate Gradient Method)
e o GMRES (Generalized Minimum Residual Method). Ambos serão trabalhados nas próximas
seções.

Vale mencionar que para a composição deste capítulo utilizamos alternadamente um
conjunto de autores como base teórica, tais quais, (KELLEY, 1995), (BEGIATO, 2007), (SAAD,
2003), (DEMMEL, 1997), (GREENBAUM, 1997), (TREFETHEN; BAU, 1997), (HESTENES;
STIEFEL, 1952) e (LAGO, 2010).

2.1 MOTIVAÇÃO

Considere o sistema linear

As = b,

(2.1)

em que b é um vetor de Rm e A é uma matriz m × n. Escolhendo arbitrariamente s0 ∈ Rm e
aplicando ao Sistema (2.1), temos duas possibilidades:

(i) s0 é solução do sistema, o que implica que As0 = b;

(ii) s0 não é solução do sistema, implicando As0 6= b.

Independente das situações distintas citadas acima, podemos reescrever o Sistema (2.1)

da forma

As + r = b

(2.2)

com r sendo denominado resíduo, o que acaba implicando que a solução do referido Sistema
(2.2) somente ocorre quando r = 0.

Exemplo 2.1. Considere o sistema linear





x + y + z
=
2x − y + z =

6
3
−x + 3y − 2z = −1

(2.3)

cuja forma matricial é dada por

55








|

1
1
2 −1

1
1
3 −2

−1

{z
A








}















x
y
z
| {z }
s

=








|

6
3
−1
{z
b

.








}

Tomando s0 =















−1
0
1

correspondente é

arbitrário como possível candidato a solução, temos que o resíduo

r0 = b − As0 =

implicando que s0 =





























6
3
−1

−1
0
1








−

1
1
2 −1

1
1
3 −2

−1






















−1
0
1

=















6
4
0








,








0
0
0

6=

não é solução do sistema (2.3). Por outro lado, tomando s1 =















1
2
3

, e o aplicando ao sistema (2.3) temos que o resíduo correspondente é

r1 = b − As1 =








o que signiﬁca dizer que s1 =















6
3
−1








1
2
3








−

1
1
2 −1

1
1
3 −2

−1






















1
2
3

=








,








0
0
0

é solução do sistema 2.3.

Neste contexto é que se desenvolvem os métodos iterativos Gradiente Conjugados e
GMRES, pois o objetivo (resguardado suas respectivas características) é minimizar r, de modo
que se possa explicitar ou estimar (com a precisão exigida) a solução do respectivo sistema linear
partindo de uma estimativa inicial qualquer, no caso s0.

A minimização de r = As − b é obtida a partir de uma sequência de aproximações
sucessivas x1, x2, . . . , xn partindo-se de uma aproximação inicial s0. No caso dos métodos
iterativos Gradientes Conjugados e GMRES, tais aproximações ocorrem nos subespaços de
Krylov.

2.2 SUBESPAÇOS DE KRYLOV

Deﬁnição 2.2. Dada uma matriz A : n × n, não singular, e um vetor v : n × 1, a sequên-
cia: v, Av, A2v, A3v, . . . é chamada sequência de Krylov de A com relação a v. O subespaço

Kl(A, v) = span{v, Av, A2v, A3v, . . . , Al−1v} é denominado subespaço de Krylov de ordem l
de A com relação a v.

Exemplo 2.3. Seja a matriz A =





1 0
0 3


 e o vetor v =






. Temos que

1
2

56

K3(A, v) = span

= span



















 ,






 ,





1
2

1
2

1 0
0 3









1
2


 ,





1 0
0 3



2 





1
2


 ,














1
18

1
6










é o subespaço de ordem 3 de A com relação ao vetor v.

Convém conhecermos algumas propriedades do suspaço de Krylov, a ﬁm de justiﬁcarmos

futuros resultados.

Proposição 2.4. O subespaço de Krylov é o subespaço de todos os vetores em Rn que podem
ser escritos como x = p(A)v, onde p é um polinômio de grau não superior a l − 1.

Demonstração. Seja x ∈ Kl(A, v) = span{v, Av, A2v, A3v, . . . , Al−1v}, logo x pode ser ex-
crito como combinação linear dos elementos do subespaço de Krylov. Desta forma, temos
que

x = α1v + α2Av + α3A2v + . . . + αlAl−1v

= (α1 + α2A + α3A2 + . . . + αlAl−1)v = p(A)v

onde p(A) = α1 + α2A + α3A2 + . . . + αlAl−1 é um polinômio de grau não superior a l − 1.

Deﬁnição 2.5. Um polinômio p(x) = α0 +α1x+. . .+αnxn, onde αn = 1, é chamado polinômio
mônico de grau n. O polinômio mônico não-nulo p de menor grau que satisfaz p(A)v = 0 é
conhecido como polinômio mínimo do vetor v com relação à matriz A.

Deﬁnição 2.6. Seja E um R-espaço vetorial de dimensão n e T : E → E um operador linear.
O subespaço vetorial S ⊆ E é denominado subespaço vetorial invariante pelo operador T ou
subespaço T-invariante quando T (S) ⊆ S, sendo T (S) = {T (s); s ∈ S}, ou seja, a imagem de
T restrito a S.

Exemplo 2.7. Seja T : R2 → R2 tal que T (x, y) = (3x, 8x − y).

O subespaço S = {(x, 2x); x ∈ R é T-invariante, já que T (x, 2x) = (3x, 6x) ∈ S.

Por outro lado, O subespaço W = {(x, 0); x ∈ R} não é T-invariante, já que T (1, 0) =

(3, 8) 6∈ W .

Proposição 2.8. Seja µ o grau do polinômio mínimo de v com relação a A. Então Kµ(A, v) é
um espaço invariante em relação à matriz A e Kl(A, v) = Kµ(A, v), para todo l ≥ µ.

57

Demonstração. Seja u ∈ Kµ(A, v), logo, u = α1v + α2Av + . . . + αµAµ−1v. Temos então que

Au = α1Av + α2A2v + . . . + αµAµv.

(2.4)

Mas, como µ é o grau do polinômio mínimo de v com relação a A, existe um polinômio
p(x) = β0 + β1x + . . . + βµxµ, com βµ 6= 0, tal que p(A)v = 0, o que nos dá:

Aµv = −

  β0
βµ

v +

β1
βµ

Av + . . . +

!

Aµ−1v

.

βµ−1
βµ

(2.5)

Substituindo-se (2.5) em (2.4), pode-se concluir que Au ∈ Kµ(A, v), para todo u ∈
Kµ(A, v) e, portanto, que Kµ(A, v) é invariante sobre A. Para prova a segunda parte, basta notar
que, como Kµ(A, v) é invariante sobre A, tem-se que Kµ(A, v) = Kµ+1(A, v) e um argumento
indutivo leva-nos à conclusão.

Proposição 2.9. Se µ é o grau do polinômio mínimo de v com relação à A, então dim(Kµ(A, v)) =
µ.

Demonstração. Suponha por absurdo que dim(Kµ(A, v)) < µ. Se v = 0 temos que o polinômio
mínimo tem grau 0 e a contradição é óbvia. Se v 6= 0, o conjunto {v, Av, A2v, . . . , Aµ−1v} não
seria linearmente independente e existiria (α1, α2, . . . , αµ) 6= 0 tal que α1v + α2Av + . . . +
αµAµ−1v = 0 e, neste caso, teríamos o grau do polinômio mínimo de v com relação a A menor
ou igual a µ − 1, o que contradiz a hipótese.

Corolário 2.10. Se o grau do polinômio mínimo de v com respeito a A é µ, então

dim(Kl(A, v)) = min{l, µ}.

(2.6)

Demonstração. Se l ≥ µ o resultado segue diretamente das Proposições 2.8 e 2.9. Agora se
l < µ o resultado segue da Proposição 2.9.

2.3 MÉTODO GMRES

O método GMRES (Generalized Minimal Residual), proposto em 1986 por Saad e

Schultz (SAAD, 2003), é um método iterativo para a resolução de sistemas lineares

onde A é uma matriz n × n, não-singular.

As = b,

Considerando s0 a aproximação inicial, cada iteração do método GMRES consiste na
minimização da norma do resíduo sobre o subespaço de Krylov determinado pela matriz A e o
resíduo inicial (r0 = b − As0), ou seja, se estivermos na l-ésima iteração do método de GMRES,
devemos encontrar o passo sl que minimiza a norma do resíduo r = b − As no subespaço aﬁm
s0 + Kl(A, r0) (KELLEY, 1995).

58

O problema de minimização que devemos resolver a cada iteração pode ser escrito como:

min kb − Ask
sujeito a s ∈ s0 + Kl(A, r0).

(2.7)

Figura 14 – Projeção do resíduo inicial sobre o subespaço AKl(A, r0)

Fonte – Adaptado de (BEGIATO, 2007)

Além disso, para que a norma do resíduo rl = b − Asl seja mínima é necessário que
a projeção de rl com o subespaço AKl(A, r0) seja ortogonal. Tal constatação pode ser facil-
mente veriﬁcada, admitindo-se, por absurdo, a existência de r∗
l não ortogonal com o subespaço
AKl(A, r0) com norma mínima (menor que a norma de rl). No entanto, nestas condições, seria
possível deﬁnir um triângulo retângulo com os vetores rl e r∗
l , o que implicaria em uma con-
tradição pelo Teorema de Pitágoras, o que signiﬁca dizer que o resíduo rl é mínimo quando a
projeção de rl com o subespaço AKl(A, r0) for ortogonal. Sendo assim, teremos um problema
de quadrados mínimos. Convém transformar a base atual do subespaço Kl(A, r0) em uma base
ortonormal e para isso usaremos o processo de Arnoldi, que é um processo de ortonormalização
de uma base do subespaço de Krylov.

2.3.1 ITERAÇÃO DE ARNOLDI

A iteração de Arnoldi consiste em um processo semelhante ao Gram-Schmidt, no sentido
que gera uma base ortonormal para o subespaço de Krylov. Considerando a matriz A, o resultado
do processo de Arnoldi é a obtenção de uma matriz unitária e semelhante à matriz A, tal que
A = V HV T (⇐⇒ AV = V H). Este processo fornecerá uma versão mais simples para o
Problema 2.7, como veremos a seguir.

Queremos uma base ortonormal {v1, v2, . . . , vl} do subspaço de Krylov do resíduo inicial
(r0) sobre a matriz A, tal que span{r0, Ar0, . . . , Al−1r0} = span{v1, v2, . . . , vl}. Sendo assim,
. O vetor v2 deve ser
iniciamos o processo com o vetor r0, e a partir dele obtemos v1 =

r0
kr0k

obtido de modo que span{v1, v2} = span{v1, Av1}. Além disso, v2 deve ter norma igual a 1 e
deve ser ortogonal a v1. Segue daí que:

Av1 = h11v1 + h21v2 ⇐⇒ Av1 =

(cid:16)

v1 v2

(cid:17)






 .

h11
h21

Impondo condição da ortogonalidade e aplicando produto interno em ambos os lados por

59

v1 obtemos

Além disso

Av1 = h11v1 + h21v2 ⇒ vT
⇒ vT
⇒ h11 = vT

1 Av1 = vT
1 Av1 = h11vT
1 Av1.

1 h11v1 + vT

1 h21v2
1 v2

1 v1 + h21vT

Av1 = h11v1 + h21v2 =⇒ h21v2 = Av1 − h11v1.

Como v2 deve ter norma igual a 1, temos ˆv = Av1 − h11v1 e fazendo h21 = kˆvk, decorre

que v2 =

ˆv
h21

.

Figura 15 – Construção de uma base ortonormal {v1, v2, . . . , vl} do subspaço de Krylov do

resíduo inicial (r0) sobre a matriz A por Arnoldi

Fonte – Autoria própria (2019)

Dado que o objetivo é construir uma base ortonormal para o subespaço, iniciamos a
etapa seguinte com o vetor v2 e calculamos Av2, uma vez que v2 ∈ K2(A, r0). Continuando este
processo, por indução temos que v1, v2, . . . , vj uma base ortonormal para o subespaço de Krylov
Kj(A, r0). Levando em consideração que cada subespaço de Krylov de dimensão j + 1 pode
ser obtido a partir da base ortogonal do subespaço de Krylov de dimensão j, usando o conjunto
gerador {v1, v2, . . . , vj, Avj}, temos que Kj+1(A, r0) = span{v1, v2, . . . , vj, Avj}.

Formalizamos agora um algoritmo para o procedimento de Arnoldi.

Algoritmo 2.11. Processo de Arnoldi para Ortonormalização sobre o subespaço de Krylov

1. v1 =

r0
kr0k

;

2. Para j = 1, 2, . . . , l, faça:

(a) ˆv = Avj;

(b) Para i = 1, 2, . . . , j faça:

60

hijvi;

• hij = vT

• ˆv = ˆv −

i ˆv;
j
X

i=1

(c) hj+1,j = kˆvk;

Se, hj+1,j = 0, então, o processo deve ser interrompido (pela

impossibilidade da realização do próximo passo).

(d) vj+1 =

ˆv
hj+1,j

.

Evidentemente pode-se concluir pelo Corolário 2.10 que, se o polinômio mínimo de r0
com relação à matriz A for de grau j < n não será possível construir uma base ortogonal com
dimensão maior que j.

Proposição 2.12. O Algoritmo 2.11 falha na j-ésima iteração (isto é, hj+1,j = 0 no passo 2d)
se, e somente se, o polinômio mínimo de r0 com respeito à matriz A tem grau j.

Demonstração. Se o Algoritmo 2.11 falha na j-ésima iteração, temos que:

hj+1,j = 0 ⇔ kˆvk = 0

⇔ kAvj −

j
X

hijvik = 0

⇔ Avj =

i=1
j
X

hijvi

i=1

⇔ Avj = h1jv1 + h2jv2 + . . . + hjjvj

O que signiﬁca dizer que Avj ∈ span{v1, v2, . . . , vj} e, consequentemente, o polinômio mínimo
de r0 com respeito à matriz A tem grau j.

Exemplo 2.13. Considere o sistema cuja forma matricial é dada por








|

0 −1
1
1

1
0 −1
0
1
{z
A








}















x
y
z
| {z }
s

=








|

−2
1
0
{z
b

.








}

(2.8)

Tomando s0 =








correspondente é








− 3
2
− 1
2
1
2

arbitrário como possível candidato a solução, temos que o resíduo

r0 = b − As0 =








−2
1
0















−

1
0 −1
0
1

0 −1
1
1















− 3
2
− 1
2
1
2








=








.








0
0
1

Queremos uma base ortonormal do subspaço de Krylov do resíduo inicial r0 =

61















0
0
1



sobre a matriz A =

1
0 −1
0
1
malização de Arnoldi), temos:

0 −1
1
1













. Assim, aplicando o Algoritmo 2.11 (processo de ortonor-





;










0
0
1

1. v1 =

r0
kr0k

=

2. Para j = 1








1
0 −1
0
1

0 −1
1
1















(a) ˆv = Av1 =

(b) Para i = 1:

• h11 = vT

1 ˆv =

(cid:16)

0 0 1

• ˆv = ˆv − h11v1 =








−1
1
1

(cid:17)








0
0
1















=








−1
1
1





;



−1
1
1


− 1













0
0
1

= 1;








=








−1
1
0





;



(c) h21 = kˆvk =








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

−1
1
0

√

2;

=








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)


(d) v2 =

ˆv
h21

=

1
√
2








−1
1
0








− 1√
2
1√
2
0





.








=

3. Para j = 2

(a) ˆv = Av2 =








1
0 −1
0
1

0 −1
1
1






















− 1√
2
1√
2
0

(b) Para i = 1, 2:

• h12 = vT

1 ˆv =

(cid:16)

0 0 1

(cid:17)








− 1√
2
− 1√
2
− 1√
2








− 1√
2
− 1√
2
− 1√
2



;






= −

1
√
2

;

=








• h22 = vT

2 ˆv =

(cid:16)

− 1√
2

1√
2

(cid:17)

0








• ˆv = ˆv − h12v1 − h22v2 =















− 1√
2
− 1√
2
0





;










= 0;

− 1√
2
− 1√
2
− 1√
2


− 1√
2
− 1√
2
− 1√
2






−

−

!

1
√
2

62















0
0
1

− 0








− 1√
2
1√
2
0








=

− 1√
2
− 1√
2
0








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 1;








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)






.



− 1√
2
− 1√
2
0

(c) h32 = kˆvk =

(d) v3 =

ˆv
h32

=






4. Para j = 3

(a) ˆv = Av3 =








1
0 −1
0
1

0 −1
1
1






















− 1√
2
− 1√
2
0

(b) Para i = 1, 2, 3:

• h13 = vT

1 ˆv =

• h23 = vT

2 ˆv =

• h33 = vT

3 ˆv =

(cid:16)

(cid:16)

(cid:16)

(cid:17)








0 0 1

− 1√
2
1√
2
− 1√
2


− 1√
2

1√
2

0

(cid:17)






− 1√
2

− 1√
2

(cid:17)

0








− 1√
2
1√
2
− 1√
2



;






= −

1
√
2

;

=















− 1√
2
1√
2
− 1√
2

− 1√
2
1√
2
− 1√
2






= 1;








= 0;








− 1√
2
1√
2
− 1√
2








−

−

!

1
√
2















0
0
1

−1








− 1√
2
1√
2
0








−

• ˆv = ˆv −h13v1 −h23v2 −h33v3 =








0

− 1√
2
− 1√
2
0








=





;










0
0
0

 
 
63















0
0
1

(c) h43 = kˆvk =

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(d) Não realizado.








0
0
0








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 0;

Portanto, uma base ortonormal do subspaço de Krylov do resíduo inicial r0 =

sobre a matriz A =








1
0 −1
0
1

0 −1
1
1








é dada pelo conjunto

α = {v1, v2, v3} =










0
0
1















,

− 1√
2
1√
2
0















,

− 1√
2
− 1√
2
0










.

Perceba que, de fato α é uma base, pois além de gerar o subespaço de Krylov do resíduo

inicial r0 sobre a matriz A, é linearmente independente, visto que








a








0
0
1

+ b








− 1√
2
1√
2
0








+ c








− 1√
2
− 1√
2
0






















0
0
0

=

⇒ a = b = c = 0.

Além disso, α é ortonormal, pois








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

0
0
1








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

− 1√
2
1√
2
0








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

− 1√
2
− 1√
2
0








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 1

e,

*








0
0
1








,








− 1√
2
1√
2
0

+








=



*






0
0
1















,

− 1√
2
− 1√
2
0



+






=



*






− 1√
2
1√
2
0















,



+






− 1√
2
− 1√
2
0

= 0.

Supondo que o algoritmo não apresentou falha de execução, após a l-ésima iteração,
temos os vetores ortonormais v1, v2, . . . , vl+1. Deﬁnimos então as matrizes Vl : n × l e Vl+1 :
n × (l + 1), cujas colunas são dadas por esses vetores. Além disso, também podemos deﬁnir a
matriz Hl : (l + 1) × l Hessenberg superior, onde:

hl(i, j) =






0,
hij,

se i > j + 1
se i ≤ j + 1

o que nos permite construir a seguinte relação:

AVl = Vl+1Hl

(2.9)

(2.10)

Exempliﬁcando,








A

|
|
v1 v2
|
|

|
. . . vl
|















=

|
|
v1 v2
|
|

|

|
. . . vl vl+1
|

|

64





















h11 h12
h21 h22
h32
0
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0














h1l
h2l
h3l
...
hl+1,l

Exemplo 2.14. Considere novamente o sistema (2.8) exposto no Exemplo 2.13, dado por








|

0 −1
1
1

1
0 −1
0
1
{z
A








}















x
y
z
| {z }
s

=








|

−2
1
0
{z
b

.








}

com s0 =








dente é r0 =

− 3
2
− 1
2
1
2
0
0
1















arbitrário como possível candidato a solução, onde seu resíduo correspon-





.



Pelo exposto no desenvolvimento do referido exemplo, podemos deﬁnir as matrizes
V2 : 3 × 2 e V3 : 3 × 3, cujas colunas são dadas pelos vetores ortonormais v1, v2, v3 obtidos por
Arnoldi. Além disso, conforme a Equação (2.9) vamos deﬁnir a matriz H2 : 3 × 2 Hessenberg
superior, de modo que vale a relação AV2 = V3H2 (2.10).

De fato, temos que

AV2 =








1
0 −1
0
1

0 −1
1
1















0 − 1√
2
1√
0
2
0

1






















=

=

−1 − 1√
2
1 − 1√
2
1 − 1√
2








0 − 1√
2
1√
0
2
0

1

− 1√
2
− 1√
2
0















1 − 1√
√
2
0
2
1
0








= V3H2.

Considerando a Equação (2.7) onde temos que s ∈ s0 + Kl(A, r0) e o fato de as colunas
de Vl formar uma base para o subespaço Kl(A, r0), então existe y ∈ Rl tal que s = s0 + Vly.
Assim, podemos escrever:

kb − Ask

=

=

kb − A(s0 + Vly)k

kb − As0 − AVlyk

=
Equação 2.10=

kr0 − AVlyk

kr0 − Vl+1Hlyk .

Mas, pelo Algoritmo 2.11, v1 =

r0
kr0k

e, considerando-se β = kr0k, teremos:

65

kb − Ask = kr0 − Vl+1Hlyk

= kβv1 − Vl+1Hlyk

= kVl+1βe1 − Vl+1Hlyk

= kVl+1(βe1 − Hly)k .

Contudo, temos que Vl+1 é uma matriz ortogonal, uma vez que as suas colunas são vetores
ortonormais, logo preserva norma e podemos então reescrever o problema (2.7) como:

min kβe1 − Hlyk
sujeito a : y ∈ Rl

(2.11)

o que nos permite deﬁnir o seguinte algoritmo:

Algoritmo 2.15. GMRES

1. Deﬁna r0 = b − As0 , p = kr0k , β = p , v1 =

r0
β

e k = 0;

2. Enquanto k ≤ kmax e p > εkbk, faça:

(a) k = k + 1;

(b) Executar o passo 2 do processo de Arnoldi (Algoritmo 2.11) com j = k;

(c) Deﬁna e1 = (1, 0, . . . , 0)T ∈ Rk+1;
(d) Encontre y ∈ Rk que minimiza kβe1 − Hkyk;

(e) p = kβe1 − Hkykk.

3. x∗ = s0 + Vkyk.

2.3.2 ROTAÇÕES DE GIVENS

Continuando com o objetivo de se obter um sistema computacionalmente mais simples de
se resolver com relação ao sistema original, dado que a matriz Hl é Hessenberg superior, podemos
encontrar facilmente a sua fatoração QR através de rotações de Givens. O nosso interesse para
aplicar as rotações de Givens é transformar a matriz de Hessenberg numa triangular superior,
anulando os elementos hi+1,i, para i = 1, . . . , l.

Iremos fatorar a matriz de Hessenberg da seguinte maneira:

Gl . . . G2G1Hl = Rl

(2.12)

onde Rl é a matriz triangular superior resultante e Gi é a matriz de rotação de Givens para
eliminar o elemento hi+1,i, que deverá ter a seguinte forma:

66

Gi =

























1

0

...

0

0
. . .
. . .

. . .

1

0

. . .

0

ci −si

si

. . .

ci

0

0

1
. . .

. . .
. . .
0

























0

...

0
1

← linha i
← linha i + 1

(2.13)

sendo ci = cos θ, si = − senθ e

si = −

q

hi+1,i

(h(i−1)
ii

)2 + (hi+1,i)2

e

ci =

q

h(i−1)
ii
)2 + (hi+1,i)2

(h(i−1)
ii

(2.14)

Essa multiplicação irá produzir uma rotação de ângulo −θ, com relação ao eixo x, no
, isso porque esse elemento já foi

vetor ao qual for aplicada. Note que usamos a notação h(i−1)
alterado, i − 1 vezes, pela aplicação das matrizes G1 . . . Gi−1.

ii

Exemplo 2.16. Vamos transformar a matriz de Hessenberg

Hl =














h11 h12
h21 h22
h32
0
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0














h1l
h2l
h3l
...
hl+1,l

numa triangular superior utilizando as rotações de Givens.

Primeiramente valor zerar o elemento h21 utilizando a matriz de rotação:

G1 =















c1 −s1
c1
s1

0

0
...
0

0
0

1
. . .
. . .















. . . 0

...
. . .
. . . 0
1
0

67

. . .
. . .
. . .
. . .
0














h1l
h2l
h3l
...
hl+1,l

q














(h11)2 + (h21)2 h(1)
12
h(1)
22
h32
. . .
. . .

0
0
...
0

. . .
. . .
. . .
. . .
0














h(1)
1l
h(1)
2l
h3l
...
hl+1,l

h11 h12
h21 h22
h32
0
...
. . .
. . .
0


h(1)
1l
h(1)
2l

h3l
...
hl+1,l














=

Assim, por (2.12)

G1Hl =

=

=











































c1 −s1
c1
s1

0

0
...
0

0
0

1
. . .
. . .

(h11)2+(h21)2
√

(h11)2+(h21)2
h11h21−h11h21
√
(h11)2+(h21)2
0
...
0
11 h(1)
h(1)
12
h(1)
0
22
h32
0
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0




























. . . 0

...
. . .
. . . 0
1
0

h(1)
12
h(1)
22

. . .

. . .

. . .
. . .
0


.












h32
. . .
. . .
h(1)
1l
h(1)
2l
h3l
...
hl+1,l

Vamos zerar agora o elemento h32 utilizando a matriz de rotação:















G2 =

0

0

1
. . .
0 c1 −s1
...

s1

c1
. . .
. . .















0

...
. . .
. . . 0
1
0

Utilizando procedimento análogo, temos

G2G1Hl =

=
































0

h(1)
11

0

0

...
0

0

1
. . .
0 c1 −s1
...

s1

c1
. . .
. . .




























0

...
. . .
. . . 0
1
0

11 h(1)
h(1)
12
h(1)
0
22
0
h32
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0














h(1)
1l
h(1)
2l
h3l
...
hl+1,l

(h(1)
q

h(1)
12
22 )2+(h32)2
(h(1)
h(1)
22 h32−h(1)
q
(h(1)

22 )2+(h32)2
22 h32

22 )2+(h32)2
. . .
. . .

. . .

. . .

. . .

. . .
0


















h(1)
1l
h(2)
2l

h(2)
3l

...
hl+1,l

=














11 h(1)
h(1)
12
h(2)
0
22
0
0
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0














h(1)
1l
h(2)
2l
h(2)
3l
...
hl+1,l

68

Continuando o processo l −2 vezes obteremos uma matriz triangular superior equivalente

à matriz de Hessenberg

Hl =














h11 h12
h21 h22
h32
0
...
. . .
. . .
0

. . .
. . .
. . .
. . .
0














h1l
h2l
h3l
...
hl+1,l

⇔















h11 h12
h22
0

0
...
0

0
. . .
. . .

. . . h1l
. . . h2l
...
. . .
. . .
hll
0
0















Exemplo 2.17. Seja a matriz:

= Gl . . . G2G1Hl = Rl.

A =











6 5 0
5 1 4
0 4 3
0 0 2











.

Vamos obter uma matriz triangular superior equivalente utilizando as rotações de Givens. Sendo
assim, primeiramente valor zerar o elemento (2, 1) utilizando a matriz de rotação:

Assim,

onde,

Substituindo , temos:

G1 =











c −s 0 0
0 0
s
1 0
0
0 1
0

c
0
0











.

G1A = A1 =











c −s 0 0
0 0
s
1 0
0
0 1
0

c
0
0































6 5 0
5 1 4
0 4 3
0 0 2

r =

√

62 + 52 ≈ 7, 8102,

c = cos θ =

6
r

s = senθ = −

≈ 0, 7682,

5
r

≈ −0, 6402.

A1 =











7, 8102
0
0
0

2, 5607
4, 4813
−2, 4327 3, 0729

4
0

3
2











.

Agora vamos zerar o elemento (3, 2) utilizando um pocesso análogo.

Com a matriz de rotação

69











G2 =

0

1 0
0
0 c −s 0
0
0 s
1
0 0

c
0











temos

com,

G2A1 = A2 =











0

0
1 0
0 c −s 0
0
0 s
1
0 0

c
0





















7, 8102
0
0
0

2, 5607
4, 4813
−2, 4327 3, 0729

4
0

3
2











q

r =

(−2, 4327)2 + 42 ≈ 4, 6817,

c = cos θ =

≈ −0, 5196,

−2, 4327
r

4
r

≈ −0, 8544.

s = senθ = −

Logo, sustituindo

A2 =











7, 8102 4, 4813
4, 6817
0
0

0
0
0

2, 5607
0, 9664
−4, 1843
2











.

Para ﬁnalizar o processo, vamos zerar o elemento (4, 3) utilizando um pocesso análogo.

Com a matriz de rotação

G3 =











0
1 0 0
0 1 0
0
0 0 c −s
c
0 0 s











temos

com,

G3A2 = A3 =











0
1 0 0
0 1 0
0
0 0 c −s
c
0 0 s





















7, 8102 4, 4813
4, 6817
0
0

0
0
0

2, 5607
0, 9664
−4, 1843
2











q

r =

(−4, 1843)2 + 22 ≈ 4, 6377,

c = cos θ =

≈ −0, 9022,

s = senθ = −

≈ −0, 4312.

−4, 1843
r

2
r

Logo, sustituindo











A3 =

7, 8102 4, 4813 2, 5607
4, 6817 0, 9664
4, 6377
0

0
0
0

0
0

70











.

Para facilitar a resolução do problema (2.11), vamos deﬁnir Ql = GT

1 GT

2 . . . GT

l . Perceba

que Gi é ortogonal para todo i, pois, sabendo que c2

i + s2

i = 1, temos que

























0

...

0
1

0

1
. . .

. . .
. . .
0










































1

0

...

0

1

0

...

0

0
. . .
. . .

. . .

1

0

0
i + s2
c2
i
sici − sici

. . .

sici − sici
i + s2
c2
i
0

0
. . .

. . .

. . .

1

. . .


















0

...

. . . 0
1
0

1
. . .

. . .

= I.

GiGT

i =

=

Além disso, temos que Ql = GT

1 GT

2 . . . GT
l

também é ortogonal. Para provarmos esta

aﬁrmação, basta lembrarmos que (AB)T = BT AT e que (AT )T = A. Assim, inicialmente

(GT

1 GT

2 )(GT

1 GT

2 )T (GT

1 )T

2 )T = GT
= GT

2 (GT
2 G2G1
2 G2)G1

1 GT
1 GT
1 (GT
1 G1 = I.

= GT

= GT

O que signiﬁca dizer que GT
também é ortogonal, pois

1 GT

2 é ortogonal. Continuando o processo, temos que GT

1 GT

2 GT
3

((GT

1 GT

2 )GT

3 )((GT

1 GT

2 )GT

3 )T = (GT
= (GT

2 )T

1 GT
1 GT
1 GT
1 GT

2 )GT
2 )GT
2 )(GT
2 )(GT

3 )T (GT
3 (GT
3 G3(GT
1 GT
3 G3)(GT
1 GT

1 GT
2 )T
1 GT
2 )T = I.

2 )T

= (GT

= (GT

Portanto, continuando este processo l − 2 vezes, temos que

71

QlQT

l = (GT

1 GT

2 . . . GT

l )(GT

1 GT

2 . . . GT

l )T = I

provando o resultado.

Neste contexto, considerando que QlHl = Rl e que Ql é ortogonal e também preserva

norma, o problema (2.11) pode ser escrito como

kb − Ask = kβe1 − Hlyk = kβQle1 − Rlyk.

(2.15)

Para compreender as vantagens proporcionadas pelas rotações de Givens, convém observar os
resultados do seguinte Teorema 2.18:

Teorema 2.18. Considere Rl = GlHl como deﬁnido anteriormente e g = βQle1. Denotemos
por ˆRl a matriz triangular superior l × l, obtida eliminando-se a última linha de Rl e ˆgl um
vetor de dimensão l encontrado eliminando-se o elemento gl+1,1 (a última linha) de g. Então
podemos dizer que:

1. O posto de AVl é igual ao posto de ˆRl. Em particular, se rll = 0 então A deve ser singular;

2. o vetor y∗ que é o minimizador da equação kβe1 − Hlyk é dado por

y∗ = ˆR−1

l ˆg;

3. a norma do resíduo no passo l será dada por gl+1,1.

Demonstração. Para provar a primeira parte considere que:

AVl = Vl+1Qt

lQlHl ⇒ AVl = Vl+1Qt

lRl.

(2.16)

(2.17)

Visto que tanto Ql quanto Vl+1 são unitárias (norma é igual a um), temos que posto de AVl é
igual ao posto de Rl, que é igual ao posto de ˆRl, já que a última linha de Rl é nula. Como Rl
é triangular superior, se rll então Rl é singular, e portanto A é singular. A segunda e a terceira
parte saem da Equação (2.10). Pois:

kβe1 − Hlyk = kβQle1 − Rlyk = |gl+1,1| + kˆg − Rlyk.

(2.18)

O resíduo mínimo é encontrado zerando o segundo elemento da parte esquerda da Equação 2.18.
Logo y∗ = ˆR−1

l ˆg e a norma do resíduo será dada por gl+1,1.

Esse resultado é um fator estimulante para a implementação pois, garantida a não-
singularidade da matriz A, a aproximação para a solução do sistema linear não precisaria ser
obtida a cada iteração do GMRES, mas somente quanto tivermos um resíduo suﬁcientemente
pequeno, já que a norma do resíduo será dada pelo módulo do último elemento do vetor
g = βQle1.

Ou seja, podemos reescrever o Algoritmo 2.15:

72

Algoritmo 2.19. GMRES com Rotações de Givens

1. Deﬁna r0 = b − Ax0 , p = kr0k , β = p , v1 =

r0
β

, Q = I : n × n e k = 0;

2. Enquanto k ≤ kmax e p > εkbk, faça:

(a) k = k + 1;

(b) Executar o passo 2 do processo de Arnoldi (Algoritmo 2.11) com j = k;

(c) Se k > 1, aplique Qk na k-ésima coluna de Hk;

(d) Faça: sk = −

hk+1,k
(hkk)2 + (hk+1,k)2

q

e ck =

hkk
(hkk)2 + (hk+1,k)2

q

;

(e) hkk = ckhkk − skhk+1,k e hk+1,k = 0;

(f) Deﬁna Gk como em (2.13) e faça g = Gkg;

(g) Faça Q = GkQ e deﬁna Qk a matriz quadrada correspondente às k primeiras linhas

de Q;

(h) p = |gk+1|.

3. Considere R a matriz quadrada correspondente às k primeiras linhas de H e w o vetor

correspondente às k primeiras linhas de g.

4. Encontre yk que resolve o sistema: Ry = w.

5. x∗ = x0 + Vkyk.

O Algoritmo 2.19 pode apresentar falha no passo 2b. Conforme a Corolário 2.10, isso
acontecerá se, e somente se, o polinômio mínimo de r0 em relação à matriz A tiver grau c < n.
A Proposição 2.20, citada a seguir, garante que, neste caso, teremos encontrado a solução exata
do sistema, é o que chamam na literatura de lucky breakdown.

Proposição 2.20. Seja A uma matriz não-singular, então o Algoritmo 2.19 irá falhar na l-ésima
iteração (isto é, hl+1,l = 0) se, e somente se, sk é a solução exata do sistema As = b.

Demonstração. Considere que hl+1,l = 0. Da não-singularidade de A temos, pela primeira parte
do Teorema 2.18 que ˆRll = hl−1
6= 0. Sendo assim por (2.14) temos que sl = 0. O vetor g atual
é obtido através do produto da matriz Gl pelo vetor g anterior aumentado em uma dimensão.
Chamando de ¯g = (¯g1, . . . , ¯gl, 0)T este vetor g anterior, temos que g = (¯g1, . . . , cl¯gl, sl¯gl). Pela
última parte do Teorema 2.18, tem-se que krlk = |gl+1| = |sl¯gl| = 0.

ll

Para provar que a condição é suﬁciente, devemos notar que se a solução exata é encontrada
no passo l e não no passo l − 1, logo vamos ter krlk e então |gl+1| = |sl¯gl| = 0, o que implica
que sl = 0 e, por (2.14), hl+1,l = 0.

73

Teorema 2.21. Seja A uma matriz n × n não-singular. Então o Algoritmo 2.19 encontrará a
solução para o problema linear As = b em no máximo n iterações.

Demonstração. Ver (KELLEY, 1995).

Exemplo 2.22. Considere novamente o Sistema (2.8) trabalhado nos Exemplos 2.13 e 2.14 ,
dado por








|

0 −1
1
1

1
0 −1
0
1
{z
A








}















x
y
z
| {z }
s

=








|

−2
1
0
{z
b





,



}

com s0 =








dente é r0 =

− 3
2
− 1
2
1
2
0
0
1















arbitrário como possível candidato a solução, onde seu resíduo correspon-





.



Nosso objetivo agora é aplicar o método GMRES a ﬁm de obter a solução desejada, com

a aplicação das rotações de Givens.

No Exemplo 2.13 aplicamos o algoritmo de Arnoldi e obtivemos uma base ortonormal
de r0 em relação a matriz A. Na ocasião, veriﬁcou-se uma falha no passo 2d da terceira iteração.
Consequentemente, ao aplicarmos o Algorítmo 2.19, haverá falha na terceira iteração no passo 2b,
o que signiﬁca dizer, pela Proposição 2.20 e Teorema 2.21, que nesta terceira iteração obteremos
a solução exata do sistema encontrando y ∈ R3 que minimiza kβQ2e1 − R3yk.

Diante do exposto, fazendo a terceira iteração do Algoritmo 2.19, a ﬁm de obter a solução

x∗, tal que








|

0 −1
1
1

1
0 −1
0
1
{z
A








}








0
0
1

,

p = kr0k =















x
y
z
| {z }
x∗

=








|

−2
1
0
{z
b





,



}








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

0
0
1








(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 1 , β = 1 ,

v1 =

r0
β

=








,








0
0
1

v3 =








− 1√
2
− 1√
2
0








e k = 2;

temos















1. Deﬁna r0 =

v2 =








− 1√
2
1√
2
0

2.

• Deﬁna a Matriz H3 : 4 × 3 de Hessenberg superior dada por

74











1 − 1√
√
2
0
2
1
0
0
0











− 1√
2
1
0
0

• Deﬁna a Matriz ¯H3, dada pelo produto G2G1H3, onde G2 e G1 são as matrizes de

rotação para zerar respectivamente os elementos h32 e h21 da matriz H3.

¯H3 = G2G1H3

0
1
2
√

=

1
0
3
0 −
2
0
0



















=

• Deﬁna

1√
3
√
2
√
3

−
2
√

2
2
0

0
√
3
2
1
2
0





















0
0
0
1

1√
3
√
2√
3

−

0
0

√
2√
3
1
√

2
3
− 1
2
0

0
√
3
2
1
2
0











=











0

0

0
1

√
2√
3
1√
3
0
0

3√
3
0

0
0





















0 0

0 0

1 0
0 1

− 1√
1√
6
6
2√
1√
3
3
0 −1
0
0

1 − 1√
√
2
0
2
1
0
0
0












− 1√
2
1
0
0

.









g = βG2G1e1



= 1









0
1
2
√

1
0
3
0 −
2
0
0

0
√
3
2
1
2
0





















0
0
0
1

1√
3
√
2√
3

−

0
0

√
2√
3
1√
3
0
0

0 0

0 0

1 0
0 1































1
0
0
0











−

1√
3
√
2
√
3√
2
2
2
0











.

=

3. Considerando R a matriz quadrada correspondente às 3 primeiras linhas de ¯H3 e w o vetor

correspondente às 3 primeiras linhas de g, temos

R =








3√
3
0

0

− 1√
1√
6
6
1√
2√
3
3
0 −1








e w =








−

1√
3
√
2
√
3√
2
2
2








.

4. Resolvendo o sistema Ry = w, com y ∈ R3, temos








3√
3
0

0

− 1√
1√
6
6
1√
2√
3
3
0 −1






















y1
y2
y3








=

−

1√
3
√
2
√
3√
2
2
2








⇒








y1
y2
y3















=

1
2
0
√
−

2
2








.

5. Por ﬁm, a solução do problema é dada pelo vetor

75

x∗ = x0 + V3y



=











+

− 3
2
− 1
2
1
2








0 − 1√
2
1√
0
2
0

1















− 1√
2
− 1√
2
0

1
2
0
√
−

2
2















=

− 3
2
− 1
2
1
2















−








=








−1
0
1








.

1
2
1
2
1
2

2.4 MÉTODO DOS GRADIENTES CONJUGADOS

O Método dos Gradientes Conjugados (Conjugate Gradient Method) foi criado na década
de 50 do século passado por Hestenes e Steifel (HESTENES; STIEFEL, 1952) para resolver
sistemas lineares As = b onde A é uma matriz simétrica e deﬁnida positiva, isto é,

A = AT e xT Ax > 0 para todo x 6= 0

(2.19)

Inicialmente desenvolvido como um método direto, posteriormente foi veriﬁcada uma forte
viabilidade de utilizá-lo também como um método iterativo, principalmente em problemas de
grande porte.

Considere o sistema

As = b,

(2.20)

onde A é uma matriz simétrica e deﬁnida positiva e x∗ = A−1b é solução. A k-ésima iteração do
Método dos Gradientes Conjugados consiste em minimizar a função

f (x) =

1
2

xT Ax − xT b.

Note que se f (¯x) é o valor mínimo (em Rn) então

5f (¯x) = A¯x − b = 0

e portanto ¯x = x∗.

(2.21)

(2.22)

Deﬁnição 2.23. Seja A uma matriz de ordem n simétrica e deﬁnida positiva e seja x um vetor
não nulo de Rn, a função k · kA, denominada A−norma em Rn, é deﬁnida como

kxkA =

√

xT Ax.

(2.23)

Lema 2.24. Seja S ⊂ Rn. Se xk minimiza f então xk também minimiza kx∗ − xkA = krkA−1
sobre S, onde r é o resíduo. (2.1).

76

Demonstração. Seja A simétrica e Ax∗ = b. temos que:

kx∗ − xk2

A = (x∗ − x)T A(x∗ − x)

= ((x∗)T − xT )A(x∗ − x)
= (x∗)T A(x∗ − x) − xT A(x∗ − x)
= (x∗)T Ax∗ − (x∗)T Ax − xT Ax∗ + xT Ax
= (x∗)T Ax∗ − 2xT Ax + xT Ax
= 2f (x) + (x∗)T Ax∗.

Perceba que (x∗)T Ax∗ independe de x, logo minimizar f é equivalente a minimizar kx∗ − xk2
A,
o que consequentemente equivale minimizar kx∗ − xkA. Ademais, chamando e = x∗ − x, temos
que

kek2

A = eT Ae = (x∗ − x)T A(x∗ − x)

= (x∗ − x)AT (A−1A)(x∗ − x)
= (A(x∗ − x))T A−1(A(x∗ − x))
= kA(x∗ − x)k2
= kb − Axk2

A−1
A−1 = krk2

A−1.

e, portanto a A-norma do erro é também a A−1-norma do resíduo.

Neste contexto, considerando o Sistema 2.20 com x∗ = A−1b como sendo a solução e
en = x∗ − xn o erro no passo n, temos que a iteração do gradiente conjugado pode ser descrita
como um sistema de fórmulas de recorrência que gera a sequência única de iteração {xn ∈ Kn}
com a propriedade que no passo n, kenkA é minimizado.

Exemplo 2.25. Considere o sistema As = b, onde

A =





3 2
2 6


 e b =









2
−8

Perceba que A é simétrica e deﬁnida positiva pois, se s =


 então





x
y

xT Ax =

(cid:16)

x y

(cid:17)





3 2
2 6









x
y


 = 3x2 + 4xy + 6y2

= 2x2 + (x + y)2 + 5y2 > 0.

Logo, obter a solução do sistema Ax = b é o mesmo que encontrar as coordenadas (x, y) que
minimizam a função

f (x) =

1
2

xT Ax − xT b =

=

1
2

3
2





(cid:16)

x y

(cid:17)





3 2
2 6









x
y






 −

(cid:16)

2 −8

(cid:17)









x
y

x2 + 2xy + 3y2 − 2x + 8y

Veja as ilustrações abaixo (Figura 16) e (Figura 17):

Figura 16 – Gráﬁco de f (x): o ponto mínimo dessa superfície é solução de As = b

77

Fonte – Autoria própria (2019)

Figura 17 – Curvas de nível: interseção da superfície com hiperplanos

Fonte – Autoria própria (2019)

A seguir vamos deduzir um conjunto de fómulas de recorrência que compreendem
o método dos gradientes conjugados. Para isto, seguiremos o mesmo raciocínio exposto por
(LAGO, 2010) e (SHEWCHUK, 1994).

Suponha que dispomos de um conjunto de vetores ortogonais S = {p0, p1, . . . , pn−1},
onde pi ∈ Rn. Chamaremos estes vetores de direções de busca. A princípio seria possível
escrever

e0 = x0 − x∗ = −

n−1
X

i=0

αipi.

(2.24)

Baseado nesta possibilidade e supondo que conhecemos os αj, a cada iteração k daremos “um
passo αk” na direção de busca pk, obtendo

xk+1 = x0 +

k
X

i=0

αipi = xk + αkpk.

(2.25)

78

Vamos encontrar agora o coeﬁciente αk, que deﬁne o tamanho do passo a ser dado na direção pk.
Das Equações (2.24) e (2.25), temos que

ek = xk − x∗ =

x0 +

!

αipi

− x∗ =

k−1
X

i=0

k−1
X

i=0

αipi −

n−1
X

i=0

αipi = −

n−1
X

i=k

αipi

(2.26)

e, devido à ortogonalidade de S, tem-se que ek ⊥ pj, para j < k. Para facilitar o cálculo de αj
vamos escrever o erro da seguinte forma:

ek+1 = e0 +

k
X

i=1

αipi = ek + αkpk.

(2.27)

Forçando a condição de ortogonalidade ek+1 ⊥ pk e aplicando produto interno a Equação (2.27)
teremos

0 = hpk, ek+1i = hpk, ek + αkpki = hpk, eki + αkhpk, pki,

e consequentemente

αk = −

hpk, eki
hpk, pki

.

(2.28)

Mas como não dispomos de ek, pois caso tivéssemos teríamos resolvido o problema fazendo
xk − ek = x∗. Uma solução seria exigir uma A-ortogonalidade das direções de busca, ou seja,

hpi, Apji = 0,

i 6= j.

(2.29)

Isto faz com que o erro seja A-ortogonal às direções de busca, ao invés da ortogonalidade que
mostramos em (2.26). Com isto, da Equação (2.28) e sabendo que Aek = Axk − b = −rk então
temos que

αk = −

hpk, Aeki
hpk, Apki

=

hpk, rki
hpk, Apki

.

(2.30)

O que pode ser calculado, pois podemos obter o resíduo fazendo

rk+1 = −Aek+1 = −A(ek + αkpk) = rk − αkApk = r0 −

k
X

i=0

αiApi.

(2.31)

Entretanto, cabe notar que, caso A seja não-singular, Apk pode ser zero o que impede o cálculo
de αk.

Vamos agora mostrar como encontrar o conjunto de direções de busca de modo que
sejam mutuamente A-ortogonais. Uma ideia intuitiva seria partir de um conjunto de vetores
ortogonais de fácil obtenção, como a base canônica, deﬁnir pk = en
k e então A-ortogonalizar pk
com os vetores anteriores. Entretanto, se tomarmos os resíduos ao invés da base canônica, ou
seja, se ﬁzermos

pk = rk +

k−1
X

β(k,i)pi

(2.32)

i=0
para algum conjunto de β(k,j), começando com p0 = r0, teremos uma facilidade muito grande
para o cálculo dos β(k,j), como mostraremos a seguir. Primeiramente, consideremos dois teoremas
do resíduo.

 
79

Teorema 2.26. No Gradiente Conjugado o resíduo é ortogonal às direções de busca anteriores.

Demonstração. Multiplicando (2.26) por −A teremos uma expressão para rk em função das
direções de busca pi:

rk =

n−1
X

i=k

αiApi.

(2.33)

Portanto, fazendo o produto interno entre rk e qualquer pj onde j < k teremos

*

hpj, rki =

pj,

+

αiApi

=

n−1
X

i=k

n−1
X

i=k

αihpj, Apii = 0

(2.34)

provando que o resíduo é ortogonal às direções de busca anteriores.

Teorema 2.27. Os resíduos são mutuamente ortogonais.

Demonstração. Vamos fazer o produto interno entre pj e rk, que já sabemos que é zero para
todo j < k

*

0 = hpj, rki =

rj +

j−1
X

i=0

+

β(j,i)pi, rk

= hrj, rki +

j−1
X

i=0

β(j,i)hpi, rki.

(2.35)

Do Teorema 2.26 eliminaremos os hpi, rki, e ﬁcaremos com

hrj, rki = 0.

(2.36)

Como hrj, rki = hrk, rji = 0, então temos que isto também será verdade para j > k, ou seja,
hrk, rji = 0 para j 6= k.

De posse dos Teoremas 2.26 e 2.27, nosso objetivo será calcular os β(k,j) da Equação

(2.32). Faremos o produto interno entre pk e Apj (com j < k). Da Equação (2.32) obtemos

*

hpk, Apji =

rk +

k−1
X

+

β(k,i)pi, Apj

= hrk, Apji +

i=0
0 = hrk, Apji + β(k,j)hpj, Apji

k−1
X

i=0

β(k,i)hpi, Apji

e, portanto

β(k,j) = −

hrk, Apji
hpj, Apji

.

(2.37)

Agora vamos ﬁnalmente mostrar que o cálculo dos β(k,j) pode ser signiﬁcativamente

simpliﬁcado. Aplicando produto interno por rk na Equação (2.31) temos

hrk, rj+1i = hrk, rji − αjhrk, Apji

αjhrk, Apji = hrk, rji − hrk, rj+1i.

Pela ortogonalidade mostrada no Teorema 2.26 concluímos que, se j = k

hrk, Apki =

hrk, rki − hrk, rk+1i
αk

=

hrk, rki
αk

,

e que caso j = k − 1, teremos

hrk, Apk−1i =

hrk, rk−1i − hrk, rki
αk−1

= −

hrk, rki
αk−1

80

(2.38)

(2.39)

e todos os demais hrk, Apji serão zero. Como o cálculo de β(k,j) só é efetuado para j < k, então
β(k,j) só será diferente de zero para j = k − 1. Para simpliﬁcar a notação faremos β(k,k−1) = βk.
Assim,

pk = rk + βkpk−1.

(2.40)

Com o objetivo de simpliﬁcar ainda mais o cálculo de βk, isolando βk e aplicando produto
interno por Apk−1 na Equação (2.40) temos

βkpk−1 = pk − rk

βkhpk−1, Apk−1i = hpk − rk, Apk−1i = hpk, Apk−1i − hrk, Apk−1i

βk = −

hrk, Apk−1i
hpk−1, Apk−1i

.

(2.41)

De posse das Equações (2.39) e (2.30), podemos sipliﬁcar a equação (2.41):

βk = −

hrk, Apk−1i
hpk−1, Apk−1i

= hrk, Apk−1i

−

!

1
hpk−1, Apk−1i

=

=

=

−

hrk, rki
αk−1

!  

−

1
hpk−1, Apk−1i

!

hrk, rki
hpk−1, Apk−1i

1
αk−1
hpk−1, Apk−1i
hpk−1, rk−1i

hrk, rki
hpk−1, Apk−1i

=

hrk, rki
hpk−1, rk−1i

.

Mas, aplicando produto interno por rk na Equação (2.40) temos

hpk, rki = hrk, rki + βkhpk−1, rki = hrk, rki,

(2.42)

portanto

e

βk =

hrk, rki
hrk−1, rk−1i

=

krkk2
2
krk−1k2
2

αk =

hrk, rki
hpk, Apki

=

krkk2
2
hpk, Apki

.

(2.43)

(2.44)

De modo mais geral, as etapas do método gradiente conjugado podem ser divididas em

duas partes:

 
 
• Passo inicial: Selecionar uma estimativa inicial arbitrária x0 e calcular o resíduo r0 e a

direção p0 pelas fórmulas (1.a) e (1.b).

• Rotina geral: Tendo determinado a estimativa si, o resíduo ri e a direção pi, calcular si+1,

ri+1 e pi+1 sucessivamente pelas fórmulas (2.c), (2.d), (2.e), (2.f) e (2.g).

81

Algoritmo 2.28. Gradiente Conjugado

1. Deﬁna A, b, s0

(a) r0 = b − As0;

(b) p0 = r0.

2. Para i = 0, 1, 2, . . . faça:

(c) αi =

krik2
hpi, Apii

;

(d) si+1 = xi + αipi;

(e) ri+1 = ri − αiApi;

(f) βi+1 =

kri+1k2
krik2

;

(g) pi+1 = ri+1 + βi+1pi.

Exemplo 2.29. Considere o sistema








|

2 −1

−1

0
2 −1
2

0 −1
{z
A








}















x
y
z
| {z }
s

=








|

−3
3
−1
{z
b

.








}

(2.45)

Nosso objetivo é obter a solução do sistema através da aplicação do método dos Gradientes
Conjugados.

Perceba inicialmente que A é simétrica (visto facilmente que A = AT ) e deﬁnida positiva

pois, se x =










x
y
z






então

xT Ax =

(cid:16)

x y z

(cid:17)








2 −1

−1

0 −1

0
2 −1
2






















x
y
z

= 2x2 − xy − xy + 2y2 − yz − yz + 2z2

= x2 + x2 − 2xy + y2 + y2 − 2yz + z2 + z2

= x2 + (x − y)2 + (y − z)2 + z2 > 0.

Logo, aplicando o Algoritmo 2.28,

1. Deﬁna A =








2 −1

−1

0 −1

0
2 −1
2



, b =













−3
3
−1








, s0 =








82



.













=





;










0
1
0

− 3
2
0
− 1
2

− 3
2
0
− 1
2

2 −1

−1

0 −1















0
2 −1
2















−

−3
3
−1










.






(a) r0 = b − As0 =








0
1
0

(b) p0 = r0 =

2. Para i = 0:

(c) α0 =

kr0k2
hp0, Ap0i

=



*






0
1
0















,

(d) s1 = s0 + α0p0 =















− 3
2
0
− 1
2


(e) r1 = r0 − α0Ap0 =













−








1
2

0
1
0

2 −1

−1

0 −1

0
2 −1
2

2
1

=

1
2

;















(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2 =
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)


(f) β1 =

kr1k2
kr0k2 =















(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(g) p1 = r1 + β1p0 =

3. Para i = 1:

1
2
0
1
2

0
1
0







1
2
0
1
2






+

1
2















0
1
0








=



.






1
2
1
2
1
2

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)















0
1
0

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2 −1

0
2 −1
2
















0
1
0


−1

0 −1



+

1
2











=






0
1
0

− 3
2
1
2
− 1
2

=

1
2

;



+








;
























0
1
0

=










;






1
2
0
1
2

(c) α1 =

kr1k2
hp1, Ap1i

=



*






1
2
1
2
1
2

(d) s2 = s1 + α1p1 =

(e) r2 = r1 − α1Ap1 =






(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)















(cid:13)
1
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
0
(cid:13)
(cid:13)
1
(cid:13)
(cid:13)
2
1 −1








,

+ 1

− 1






















−1
0














1
2
1
2
1
2

0
1 −1
1
1








=






−1
1
0

1 −1

0
1 −1
1
1

−1
0








− 3
2
1
2
− 1
2


1
2
0
1
2

83

= 1;

















+






1
2
1
2
1
2





;
























=



.













0
0
0

1
2
1
2
1
2

E portanto, temos que a solução do Sistema (2.45) é dado pelo vetor








−1
1
0





.



3 PROPOSTAS DE ATIVIDADES PARA USO NO ENSINO MÉDIO

84

Com base nas Orientações Curriculares para o Ensino Médio (BRASIL, 2006a), a forma
do professor trabalhar os conteúdos da disciplina de matemática deve sempre agregar um valor
formativo no que diz respeito ao desenvolvimento do pensamento matemático. Isto signiﬁca dizer
que além do estudante estar envolvido diretamente em sua aprendizagem, é dever do professor
colocar os alunos em um processo de aprendizagem que valorize o raciocínio matemático em
todos os seus aspectos, seja na formulação de questões e hipóteses, ou mesmo na explicação e
dedução de fórmulas utilizadas.

Nexte contexto, pretende-se propor atividades para o uso no ensino médio, durante o
conteúdo referente à Geometria Analítica, em que o tema Projeção seja tratado em diferentes
momentos, com o intuito de enriquecer a formação dos alunos. As atividades visam trabalhar
projeção em R2 e R3, onde serão priorizados conhecimentos geométricos relacionados ao estudo
do triângulo retângulo, como as relações trigonométricas e Teorema de Pitágoras, com uma
introdução a linguagem vetorial, sobre o plano cartesiano.

São três as atividades a serem propostas (Figura 18): Uma teórica, onde a intenção é
veriﬁcar a projeção de vetores em retas no R2, e duas práticas, sendo a primeira relacionada ao
problema de calcular o comprimento da sombra de um objeto projetada ortogonalmente por uma
lâmpada puntiforme presa ao teto e a segunda relacionda com um exemplo de aplicação real
utilizado no esporte, mais precisamente no futebol, através da marcação de impedimentos, onde
é utilizada a tecnologia VAR (video assistant referee) ou árbitro assistente de vídeo.

Figura 18 – Fluxograma das atividades

Fonte – Autoria própria (2019)

Pelo exposto no ﬂuxograma acima, percebe-se que duas atividades são independentes,
isto é, o professor pode escolher a ordem que lhe seja conveniente para o trabalho com sua turma.

85

3.1 MODELAGEM MATEMÁTICA E INTERDISCIPLINARIDADE

Duas características importantes advindas das atividades práticas que constituem impor-
tante fundamento na aprendizagem qualitativa são a modelagem matemática e a interdisciplinari-
dade.

Levando em consideração as propostas de atividades, a modelagem matemática se aplica
muito bem a este trabalho, uma vez que para todo problema proposto é nossa intenção fazer
o aluno pensar sobre formas de resolvê-lo. Sobre a modelagem matemática as Orientações
Curriculares para o Ensino Médio discorrem que

A modelagem matemática, percebida como estratégia de ensino, apresenta
fortes conexões com a idéia de resolução de problemas (...). Ante uma situação
problema ligada ao “mundo real”, com sua inerente complexidade, o aluno
precisa mobilizar um leque variado de competências: selecionar variáveis que
serão relevantes para o modelo a construir; problematizar, ou seja, formular
o problema teórico na linguagem do campo matemático envolvido; formular
hipóteses explicativas do fenômeno em causa; recorrer ao conhecimento ma-
temático acumulado para a resolução do problema formulado, o que, muitas
vezes, requer um trabalho de simpliﬁcação quando o modelo originalmente
pensado é matematicamente muito complexo; validar, isto é, confrontar as
conclusões teóricas com os dados empíricos existentes; e eventualmente ainda,
quando surge a necessidade, modiﬁcar o modelo para que esse melhor corres-
ponda à situação real, aqui se revelando o aspecto dinâmico da construção do
conhecimento. (BRASIL, 2006a)

A interdisciplinaridade também constitui um elemento muito importante que pode ser
agregado a este trabalho. Conforme os Parâmentros Curriculares Nacionais (BRASIL, 2000)
"Na perspectiva escolar, a interdisciplinaridade não tem a pretensão de criar novas disciplinas
ou saberes, mas de utilizar os conhecimentos de várias disciplinas para resolver um problema
concreto ou compreender um determinado fenômeno sob diferentes pontos de vista".

Neste contexto, as atividades podem ser organizadas na forma de projeto interdisciplinar.
Por exemplo, considerando a terceira atividade relacionada a prática com VAR (veriﬁcação de
impedimentos), pode-se desenvolver uma proposta interdisciplinar envolvendo as disciplinas de
Matemática, Física e Educação Física.

Na disciplina de Física os alunos trabalham com aspectos vetoriais no que diz respeito a
deﬁnição e propriedades; na discipina de Matemática o professor trabalha aspectos relacionados
a projeção; enquanto na disciplina de Educação Física os alunos buscam entender e veriﬁcar a
deﬁnição de impedimento numa perspectiva prática. No somátório desta atividade, o problema
de se veriﬁcar corretamente impedimento acaba sendo compreendido pelo aluno de forma muito
mais completa, ao mesmo tempo em que uma atividade conjunta acaba sendo muito mais atrativa
para o estudante.

86

3.2 ATIVIDADE 1: PROJETANDO VETORES EM RETAS NO PLANO

Público alvo: 3º ano do Ensino Médio
Tempo previsto: 2 aulas
Pré-requisitos: Congruênca de triângulos; Teorema de Pitágoras; Equação de
retas no plano cartesiano
Recursos: Material de escrita

3.2.1 OBJETIVOS

• Deﬁnir vetores em R2;

• Relacionar uma reta no plano cartesiano com um vetor dado;

• Utilizar propriedades relacionadas ao triângulo retângulo na resolução dos problemas

propostos, com o intuito de compreender a deﬁnição de projeção ortogonal.

3.2.2 DESENVOLVIMENTO DA PROPOSTA

3.2.2.1 LINGUAGEM VETORIAL

Inicialmente faz-se necessário que o professor dê uma noção introdutória sobre a deﬁni-
ção de vetores. Para tanto, é sugerido que o professor trabalhe primeiramente com a ideia de
segmento orientado para vetores. Tal abordagem é mais simples de ser absorvida pelo aluno,
uma vez que os mesmos tem maior familiaridade com o termo "segmento", e a noção de vetores
vai sendo construída ao longo da atividade. Ao ﬁnal o professor pode concretizar a deﬁnição de
vetores, como o conjunto segmentos orientados equipolentes.

Exemplo 3.1. Dados os pontos A = (−5, 1) e B = (−2, 3), vamos deﬁnir o segmento orientado
que tem A como ponto de partida e B como ponto de chegada. Segue que

−→
AB = B − A = (−2, 3) − (−5, 1) = (−2 − (−5), 3 − 1) = (3, 2).

Figura 19 – Representação geométrica do vetor deﬁnido pelos pontos A e B

Fonte – Autoria própria (2019)

87

Com a representação geométrica o professor pode mostrar ao aluno que

−−→
OE,
através da congruência dos triângulos ABC com OED, e justiﬁcar a vantagem do trabalho com
vetores. Em seguida, sugere-se que o professor repita a atividade, variando os pontos, de modo
que os estudantes consigam deﬁnir um vetor tendo dois pontos quaisquer.

−→
AB =

Como estamos trabalhando basicamente com triângulo retângulo e levando em conside-
ração a abordagem de segmento orientado para vetores, o professor tem condições de mostrar
que o comprimento de um vetor (norma) é dado basicamente pela aplicação do teorema de
Pitágoras, o que se resume ao cálculo da distância entre dois pontos (os pontos que deﬁnem o
vetor em estudo).

Figura 20 –

−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13) = d(A, B) =
AB
(cid:13)

q

(x2 − x1)2 + (y2 − y1)2

Fonte – Autoria própria (2019)

Figura 21 – Vetor com extremidade na origem: kvk = d(0, A) =

q

1 + y2
x2
1

Fonte – Autoria própria (2019)

3.2.2.2 PROJEÇÃO DE VETORES SOBRE EIXOS COORDENADOS

Neste momento, no qual os estudantes estão familiarizados com a ideia de vetores, o
professor conduzirá um estudo sobre como projetar vetores nos eixos coordenados. Para tanto,
após a deﬁnição do vetor que se quer trabalhar e o eixo coordenado, é deﬁnido um triângulo
retângulo, e a partir deste triângulo o professor construirá a ideia de projeção com utilização de
propriedades geométricas.

A seguir, alguns exemplos de exercícios que o professor pode realizar com seus alunos.

Exemplo 3.2. A projeção do vetor (3, 2) no eixo x é dada pelo vetor (3, 0). Note que, como a
projeção ortogonal é sobre o eixo x, temos que a componente y da coordenada da projeção é
zero. Logo, a projeção é deﬁnida pela componente x da coordenada do vetor escolhido.

Figura 22 – Representação geométrica da projeção do vetor (3, 2) sobre eixo x

88

Fonte – Autoria própria (2019)

Exemplo 3.3. Vamos obter a projeção ortogonal do vetor deﬁnido pelos pontos A = (2, 0) e
B = (5, 4) sobre o eixo x. Neste caso, temos que a projeção desejada é o vetor deﬁnido pelos
pontos A = (2, 0) e C = (5, 0), isto é,

−→
AC = C − A = (5, 0) − (2, 0) = (3, 0).

Figura 23 – Representação geométrica da projeção do vetor

−→
AB sobre eixo x

Fonte – Autoria própria (2019)

Exemplo 3.4. A projeção do vetor
eixo y é dada pelo vetor

−→
AC = C − A = (0, 2) − (0, 1) = (0, 1).

−→
AB deﬁnido pelos pontos A = (0, 1) e B = (−4, 2) sobre o

Figura 24 – Representação geométrica da projeção do vetor

−→
AB sobre eixo y

Fonte – Autoria própria (2019)

Exemplo 3.5. A projeção ortogonal de qualquer vetor peralelo ao eixo y em relação ao eixo x é
o vetor nulo, isto é, apenas um ponto.

Figura 25 – Representação geométrica da projeção de vetor paralelo ao eixo y em relação ao

eixo x

89

Fonte – Autoria própria (2019)

3.2.2.3 PROJEÇÃO DE VETORES SOBRE RETAS NO PLANO

A ideia aqui é similar à anterior, no entanto agora a intenção é projetar um determinado
vetor sobre uma reta qualquer no plano. Para isso, sugerimos que inicialmente se trabalhe
alguns exemplos de projeções de vetores sobre retas paralelas aos eixos coordenados, para em
seguida formalizar projeções sobre as demais situações de retas. A seguir alguns exemplos desta
aplicação.

Exemplo 3.6. Vamos projetar o vetor determinado pelos pontos A(−1, 1) e B(4, 3) sobre a reta
y = 1. Neste caso, conforme Figura 26 temos que a projeção desejada é o vetor deﬁnido pelos
pontos A(−1, 1) e C(4, 1), ou seja,

−→
AC = C − A = (4, 1) − (−1, 1) = (5, 0).

Figura 26 – Representação geométrica da projeção de vetor determinado pelos pontos A(−1, 1)

e B(4, 3) sobre reta y = 1

Fonte – Autoria própria (2019)

Note que em todos os exemplos acima, podemos mostrar que o resultado obtido pela
análise da representação geométrica é válida através da aplicação do Teorema de Pitágoras.
Esta é uma observação importante a ser feita, pois mostra uma relação direta do quanto uma
represantação geométrica (quando possível) contribui no entendimento de algumas deﬁnições
importantes na matemática, em especial a deﬁnição de projeção que é nosso objeto de estudo.

−→
AC = C − A =
Exemplo 3.7. (Retomando o Exemplo 3.6) Vamos mostrar que o vetor
(4, 1) − (−1, 1) = (5, 0) deﬁnido pelos pontos A(−1, 1) e C(4, 1) é projeção ortogonal do vetor
determinado pelos pontos A(−1, 1) e B(4, 3) sobre a reta y = 1.

Se o ponto C(4, 1) é tal que

−→
AC é ortogonal a

−−→
BC. Logo, aplicando o Teorema de

Pitágoras ao triângulo ABC, temos

90

−→
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
AB
(cid:13)
(cid:13)

−→
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
AC
(cid:13)
(cid:13)
⇔ d(A, B)2 = d(A, C)2 + d(B, C)2
(cid:16)√
(cid:16)√

−−→
(cid:13)
(cid:13)
BC
(cid:13)

(cid:16)√

(cid:13)
2
(cid:13)
(cid:13)

=

+

52 + 22(cid:17)2

=

52 + 02(cid:17)2

+

02 + 22(cid:17)2

⇒ 29 = 29,

⇒

provando o resultado.

Vamos agora trabalhar com um exemplo onde se quer projetar um vetor v sobre uma reta

oblíqua aos eixos coordenados.

Exemplo 3.8. Como projetar o vetor deﬁnido pelos pontos A(3, 2) e B(1, 3) sobre a reta

r : y =

x + 1?

1
3
Geometricamente, temos a seguinte situação:

Figura 27 – Representação geométrica da projeção de vetor deﬁnido pelos pontos A(3, 2) e

B(1, 3) sobre a reta r : y =

x + 1

1
3

Fonte – Autoria própria (2019)

Nosso objetivo é determinar (a, b) tal que

−−→
BC seja ortogonal ao vetor

−→
AC. Assim, pelo

Teorema de Pitágoras, temos

−→
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
AB
(cid:13)
(cid:13)

−→
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
AC
(cid:13)
(cid:13)
⇔ d(A, B)2 = d(C, A)2 + d(B, C)2

−−→
(cid:13)
(cid:13)
BC
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+

=

⇒ 5 = (3 − a)2 + (2 − b)2 + (a − 1)2 + (b − 3)2.

(3.1)

Mas, (a, b) pertence a reta r, logo

b =

1
3

a + 1.

(3.2)

91

(cid:19)2

a + 1 − 3

Substituindo a equação 3.2 em 3.1, obtemos

(cid:18)

(cid:19)2

2 −

= (3 − a)2 +

5 = (3 − a)2 + (2 − b)2 + (a − 1)2 + (b − 3)2
1
3
1
3
= 9 − 6a + a2 + 1 −

= (3 − a)2 +

+ (a − 1)2 +

+ (a − 1)2 +

(cid:18) 1
3

a − 1

a +

1 −

(cid:19)2

a

(cid:18)

(cid:18) 1
3

a2 + a2 − 2a + 1 +

(cid:19)2

a − 2

2
3

1
9

=

20
9

a2 − 10a + 15.

1
9

a2 −

4
3

a + 4

Logo, basta veriﬁcar as raízes da equação

20
9

a2 − 10a + 10 = 0

⇔ 20a2 − 90a + 90 = 0

⇔ 2a2 − 9a + 9 = 0.

Assim, pelo teorema de Pitágoras,

q

9 ±

(−9)2 − 4 · 2 · 9

2 · 2

√

9 ±
4

=

9

=

9 ± 3
4

,

a =

e, consequentemente segue que a = 3 ou a =

. Mas, a = 3 contraria nossa hipótese inicial de

3
2
, obtemos, b =

1
3

·

3
2

+ 1 =

3
2

, e portanto obtemos que

ortogonalidade. Então, tomando a =

C

(cid:18) 3
2

,

3
2

(cid:19)

.

3
2

Neste contexto, o vetor correspondente a projeção de
−→
AC = C − A =

− (3, 2) =

, −

−

(cid:19)

(cid:18)

(cid:19)

,

.

o vetor

(cid:18) 3
2

3
2

3
2

1
2

−→
AB sobre a reta r : y =

1
3

x + 1 é

3.2.3 AVALIAÇÃO

Acreditando que o processo avaliativo se dá como um todo e acontece processualmente
durante as aulas, a avaliação da presente proposta de atividade se dará por participação e
envolvimento dos alunos com questionamentos e contribuições e o envolvimento da turma na
resolução dos problemas propostos durante toda a atividade, podendo o professor avaliar também
todo o material produzido pela turma neste processo. Contudo, muito além dos registros feitos
pelos estudantes, está a compreensão de cada etapa do processo que foi desenvolvido com a
aplicação das etapas desta atividade. Essa compreensão, ainda que não apareça nos registros, é o
que deve determinar a conclusão do processo avaliativo.

92

3.3 ATIVIDADE 2: PRÁTICA COM LUZ E SOMBRA

Público alvo: 3º ano do Ensino Médio
Tempo previsto: 3 aulas
Pré-requisitos: Semelhança de triângulos; Trigonometria no triângulo retân-
gulo; Teorema de Pitágoras
Recursos: Caixa octante, régua, transferidor e material de escrita

3.3.1 OBJETIVOS

• Deﬁnir vetores em R2 e introduzir noção de vetores em R3;

• Utilizar propriedades relacionadas ao triângulo retângulo na resolução dos problemas

propostos, com o intuito de compreender a deﬁnição de projeção ortogonal;

• Diferenciar projeções ortogonais e não ortogonais.

3.3.2 CAIXA OCTANTE

Com o objetivo de tornar prático a visualização dos conceitos preliminares relacionados
a vetores, assim como a construção da deﬁnição de projeção com os estudantes, foi produzido
um material concreto para ser utilizado, a qual a chamamos de "caixa octante". Tal material
também será útil na aplicação da 3º atividade que veremos mais adiante. Além disso, espera-se
que este material forneça um estímulo maior aos estudantes, uma vez que os mesmos podem
experimentar uma situação prática e interativa de aprendizagem.

Tal material representa um octante do R3 (para ﬁns de cálculos, utilizaremos a caixa
octante para representar especiﬁcamente o 1º octante). Uma vantegem desse material concreto
é que sua construção leva materiais de fácil acesso e de baixo custo, viabilizando reprodução.
Ademais, a montagem desse objeto leva em consideração aspectos práticos de transporte e
manejo, facilitando o trabalho de locomoção do professor bem como de armazenagem de tal
objeto. Veja (Figura 28).

Uma característica muito importante da caixa octante é que ela pode ser adaptada (com
inclusão de acessórios) para que qualquer atividade a ser realizada na mesma possa também ser
aplicada a alunos com deﬁciência visual. Tal adaptação favorece a inclusão de qualquer aluno,
independente de sua condição.

Materiais estruturais básicos utilizados:

• 3 paineis de metal: 2 peças de 50cm × 35cm × 2cm e 1 peça de 50cm × 52cm × 0,001cm;

• 1 placa de mdf (expositor com furação): 50cm × 52cm × 0,5cm.

• 1 metro de cano pvc com 4 "joelhos" e 2 "T" compatíveis;

• 1,2 m de mdf de 2cm × 2cm;

• 25 parafusos com porca e arruela compatíveis e uma lanterna pequena com laser.

Figura 28 – Caixa octante

93

Fonte – Autoria própria (2019)

Figura 29 – Exemplo de atividade a ser realizada na caixa octante

Fonte – Autoria própria (2019)

Conforme podemos visualizar na (Figura 29), além da caixa octante possibilitar ao
professor trabalhar características de pontos e principalmente de vetores no espaço R3, ela
permitirá o trabalho de calcular o comprimento da sombra de uma luz projetada ortogonalmente
sobre um objeto (que é o objetivo desta 2ª atividade). A seguir algumas fotos da caixa octante
montada:

Figura 30 – Caixa octante montada I

94

Fonte – Autoria própria (2019)

Figura 31 – Caixa octante montada II

Fonte – Autoria própria (2019)

3.3.3 DESENVOLVIMENTO DA PROPOSTA

3.3.3.1 LINGUAGEM VETORIAL

Assim como na primeira atividade, faz-se necessário que o professor inicie o trabalho
inserindo uma linguagem vetorial básica, através da deﬁnição de vetores. No entanto, caso o
professor já tenha desenvolvido a 1ª atividade (levando em consideração que as atividades são
independentes, e que o professor tem a liberdade para aplicar as atividades na ordem que lhe for
conveniente), basta que o mesmo complemente tal etapa inserindo uma noção introdutória do
R3, que abordaremos em seguida.

Sobre a construção da deﬁnição de vetores em R2, o desenvolvimento é análogo ao
exposto na primeira atividade. Inicialmente, é sugerido que o professor trabalhe com a ideia de
segmento orientado para vetores. Tal abordagem é mais simples de ser absorvida pelo aluno,
uma vez que os mesmos têm maior familiaridade com a deﬁnição de segmento. Neste contexto,

95

a noção de vetores vai sendo construída à medida que a atividade vai se desenvolvendo. Ao ﬁnal
da atividade o professor pode concretizar a deﬁnição de vetores como o conjunto segmentos
orientados equipolentes.

Exemplo 3.9. Dados os pontos A = (−5, 1) e B = (−2, 3), vamos deﬁnir o segmento orientado
que tem A como ponto de partida e B como ponto de chegada. Segue que

−→
AB = B − A = (−2, 3) − (−5, 1) = (−2 − (−5), 3 − 1) = (3, 2).

Figura 32 – Representação geométrica do vetor deﬁnido pelos pontos A e B

Fonte – Autoria própria (2019)

Com esta representação geométrica o professor pode mostrar ao aluno que

−−→
OE,
através da congruência dos triângulos ABC com OED e justiﬁcar a vantagem do trabalho com
vetores. Em seguida, sugere-se que o professor repita a atividade exposta no exemplo anterior,
variando os pontos, de modo que os estudantes consigam deﬁnir um vetor tendo dois pontos
quaisquer.

−→
AB =

Como estamos trabalhando basicamente com triângulo retângulo e levando em conside-
ração a abordagem de segmento orientado para vetores, o professor tem condições de mostrar
que o comprimento de um vetor (norma) é dado basicamente pela aplicação do teorema de
Pitágoras, o que se resume ao cálculo da distância entre dois pontos (os pontos que deﬁnem o
vetor em estudo).

Figura 33 –

−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
AB
(cid:13) = d(A, B) =
(cid:13)

q

(x2 − x1)2 + (y2 − y1)2

Fonte – Autoria própria (2019)

Figura 34 – Vetor com extremidade na origem: kvk = d(0, A) =

q

1 + y2
x2
1

96

Fonte – Autoria própria (2019)

Para introduzir a deﬁnição de vetores no espaço em R3, inicialmente é necessário
que o professor contextualize ao estudante o que vem a ser o R3, inserindo principalmente sua
composição e noção de coordenadas. Para tanto, o professor pode fazer uso da caixa octante, tanto
na exposição das principais características e deﬁnição quanto no entendimento da composição das
coordenadas no espaço. Isso permitirá ao estudante uma melhor visualização e contextualização
do conteúdo.

Exemplo 3.10. Segue na Figura 35 a representação na caixa octante dos pontos:

A(13, 14, 0), B(20, 10, 15), C(0, 45, 5) e D(40, 35, 20)

Figura 35 – Representação dos pontos A, B, C e D

Fonte – Autoria própria (2019)

Outra forma interessante de abordar as coordenadas no R3 é sob o ponto de vista de
geometria espacial. O professor pode inserir algum sólido geométrico (caixa de leite, caixa
de cereal entre outros) na caixa octante e instigar seus alunos a expor as coordenadas de seus
vértices. Mesmo que o professor não tenha trabalhado com a turma os sólidos geométricos a

97

atividade ainda é viável, levando em consideração que o objetivo é mostrar a localização do
sólido escolhido com base nas coordenadas de seus vértices.

Exemplo 3.11. Veja na Figura 36 as coordenadas de um paralelepípedo posicionado de forma
arbitrária na caixa octante.

Figura 36 – Representação das coordenadas do paralelepípedo ABCDEFGH

Fonte – Autoria própria (2019)

A seguir algumas fotos de exemplos práticos para ilustrar a marcação de pontos com a
utilização da caixa octante. Para a marcação de pontos foram utilizados alguns acessórios, dentre
eles, massinha de modelar, palito de churrasco e ima.

Figura 37 – Coordenadas de pontos em R3 na caixa octante I

Fonte – Autoria própria (2019)

Figura 38 – Coordenadas de pontos em R3 na caixa octante II

98

Fonte – Autoria própria (2019)

Figura 39 – Coordenadas de pontos em R3 na caixa octante com adaptação para alunos com

deﬁciência visual

Fonte – Autoria própria (2019)

Sobre a construção da deﬁnição de vetores em R3, o desenvolvimento é análogo ao
exposto em R2. Continuaremos com a ideia de segmento orientado para vetores, de modo que
no decorrer da atividade a noção de vetores vai sendo construída.

Exemplo 3.12. Dados os pontos A = (26, 4, 5) e B = (5, 32, 20), vamos deﬁnir o segmento
orientado que tem A como ponto de partida e B como ponto de chegada. Segue que

−→
AB = B − A

= (5, 32, 20) − (26, 4, 5)

= (5 − 26, 32 − 4, 20 − 5)

= (−21, 28, 15).

99

Em seguida, sugere-se que o professor repita a atividade exposta no exemplo anterior,
variando os pontos, de modo que os estudantes consigam deﬁnir um vetor tendo dois pontos
quaisquer.

Perceba que como estamos trabalhando basicamente com triângulo retângulo também
em R3 e levando em consideração a abordagem de segmento orientado para vetores, o professor
também tem condições de mostrar que o comprimento de um vetor (norma) é dado basicamente
pela aplicação do teorema de Pitágoras (duas vezes), o que se resume ao cálculo da distância
entre dois (os pontos que deﬁnem o vetor em estudo).

Figura 40 –

−→
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13) = d(A, B) =
AB
(cid:13)

q

(x2 − x1)2 + (y2 − y1)2 + (z2 − z1)2

Fonte – Autoria própria (2019)

3.3.3.2 ESCOLHA DE UM OBJETO PARA EXPERIMENTO

Como nosso objetivo é obter o comprimento da sombra de um objeto projetada ortogo-
nalmente por uma lâmpada puntiforme presa ao teto, precisamos inicialmente deﬁnir um objeto
de trabalho. Para isso, pedir para turma, em geral, selecionar um objeto, como por exemplo
lápis, caneta, régua, entre outros. A ideia é que sejam selecionados objetos que caibam na caixa
octante, tendo em vista que é de interesse utilizar esse material concreto.

Neste instante cabe ao professor mostrar à turma que o experimento pode ser ampli-
ado para um objeto de qualquer tamanho simplesmente utilizando semelhança de triângulo
envolvendo algum objeto "pequeno" com o objeto escolhido pelos alunos (Figura 41).

Figura 41 – Exemplo de atividade realizada na caixa octante com semelhança de triângulos

100

Fonte – Autoria própria (2019)

3.3.3.3 EXPERIMENTO COM OBJETO

De posse do objeto, pedir para algum estudante primeiramente posicionar o objeto na
caixa octante de modo que o mesmo possua alguma inclinação em relação a base da caixa. Em
seguida, ligar a lanterna (com laser) de modo que a mesma esteja ortogonal à base da caixa, em
relação à extremidade do objeto escolhido, conforme Figura 42. Para ﬁns de cálculo, nesta 2ª
atividade todos os objetos dos exemplos foram posicionados na caixa paralelos a um dos planos
laterais.

Figura 42 – Sombra de um objeto projetada ortogonalmente por uma lâmpada puntiforme ﬁxa

Fonte – Autoria própria (2019)

Como estamos interessados em fazer um estudo de projeção ortogonal, vamos modelar o
experimento de calcular o comprimento da sombra como um triângulo retângulo. Neste contexto,

101

precisamos garantir a existência de um ângulo reto, que é dado pelo correto posicionamento da
lanterna em relação ao objeto (Figuras 43 e 42). Para isso, basta o professor mostrar ao aluno
que a medida do comprimento da sombra do objeto varia conforme posicionamento da luz e
que para garantir a ortogonalidade precisamos utilizar algum instrumento de medição de ângulo,
como por exemplo o transferidor.

Figura 43 – Projeção não ortogonal com θ < 90◦

Fonte – Autoria própria (2019)

Figura 44 – Projeção não ortogonal com θ > 90◦

Fonte – Autoria própria (2019)

Em seguida, propor aos estudantes que pensem em formas para se calcular a medida do
comprimento da sombra projetada ortogonalmente pela luz ﬁxa em relação a base da caixa pelo
objeto posicionado. Apesar de parecer natural a ideia de medir com uma régua o comprimento
solicitado, a intenção desta proposta é que os alunos utilizem algum argumento matemático para

102

obter a medida solicitada, ou mesmo provar o resultado obtido pela simples medição com uma
régua.

Contudo, valem algums considerações sobre as hipóteses deste nosso problema. Primei-
ramente, a partir do momento que um objeto foi escolhido pelos alunos e consequentemente
posicionado de forma arbitrária na caixa octante, partimos da ideia de que "conhecemos" este
objeto e sua localização, ou seja, é de nosso conhecimento o comprimento deste objeto, o ângulo
de inclinação deste objeto com relação a base da caixa (medido com transferidor), assim como
sua localização em termos das coordenadas do ponto onde tal objeto foi ﬁxado.

Exemplo 3.13. Vamos obter o comprimento da sombra de uma lapiseira de 14 cm posicionada no
ponto A(20, 3, 0) e projetada ortogonalmente com relação à base da caixa octante com inclinação
de 45◦ (Figura 45).

Figura 45 – Obtendo comprimento da sombra de uma lapiseira posicionada no ponto A(20, 3, 0)

com inclinação de 45◦ com relação à base da caixa

Fonte – Autoria própria (2019)

Do triângulo retângulo modelado pelo problema, temos que:

cos 45◦ =

Comprimento da sombra
Comprimento da lapiseira

=

Comprimento da sombra
14

e, portanto, o comprimento da sombra é de aproximadamente 9,9 cm.

Neste momento, sugere-se que o professor repita a atividade exposta no exemplo anterior,
variando o objeto, sua localização e inclinação, de modo que os estudantes consigam ao ﬁnal
veriﬁcar a relação entre a deﬁnição de projeção ortogonal com o simples exercício de calcular a
sombra de objetos.

Em seguida, a partir da inserção de uma linguagem vetorial apropriada, vamos obter o
vetor que corresponde à sombra de tal objeto em função das coordenadas do ponto onde o objeto

103

escolhido foi posicionado, além do ângulo de inclinação e comprimento do objeto escolhido.
Contudo, consideraremos que o objeto foi posicionado paralelamente a uma das laterais da caixa
octante, no caso, paralelo ao plano x = 0. Nos demais casos, o desenvolvimento é análogo ao
que será exposto a seguir. Tal exercício será útil na realização da 3ª atividade que será discutida
na próxima seção.

−→
AB correspondente ao objeto escolhido, onde A(x, y1, 0) e B(x, y2, z) com
Exemplo 3.14. Seja
x, y1, y2, z ∈ R (sendo A o ponto de contato deste objeto com a caixa octante). Considere ainda
−→
ABk = k e que o ângulo de inclinação deste objeto com relação a base da caixa é θ (Figura
que k
46).

Figura 46 – Sombra de um objeto qualquer posicionado em ponto arbitrário e com inclinação de

θ com relação à base da caixa

Fonte – Autoria própria (2019)

Queremos obter C(x, y2, 0) em função das coordenadas de A, do comprimento do objeto
−−→
BC. Desta forma, aplicando

−→
AC seja ortogonal a

e do ângulo de inclinação de tal objeto, tal que o
deﬁnição de cosseno ao triângulo retângulo ABC, temos que

cos θ =

−→
ACk
k
−→
ABk

k

=

q

(x − x)2 + (y2 − y1)2 + (0 − 0)2
k

=

y2 − y1
k

e, portanto

y1 = y2 − k cos θ.

(3.3)

−→
AC correspondente à sombra
Exemplo 3.15. Retomando o exemplo 3.13, vamos obter o vetor
de uma lapiseira de 14 cm posicionada no ponto A(20, 3, 0) e projetada ortogonalmente com
relação à base da caixa octante com inclinação de 45◦ (Figura 45).

Desta forma, aplicando a equação 3.3, temos que y = 3 + 14 · cos 45◦ ≈ 3 + 9, 9 = 12, 9.
−→
AC = C − A = (20; 12, 9; 0) −

Consequentemente, temos que C(20; 12, 9; 0), e portanto,
(20, 3, 0) = (0; 9, 9; 0).

Em seguida, como forma de ﬁxação e formalização da deﬁnição de projeção ortogonal,
proporcionado pelo exemplo anterior, é sugerido que o professor repita a atividade exposta acima,
variando o objeto, sua localização e inclinação.

104

3.3.4 AVALIAÇÃO

Acreditando que o processo avaliativo se dá como um todo e acontece processualmente
durante as aulas, a avaliação da presente proposta de atividade se dará por participação e
envolvimento dos alunos com questionamentos e contribuições e o envolvimento da turma na
resolução dos problemas propostos durante toda a atividade, podendo o professor avaliar também
todo o material produzido pela turma neste processo. Contudo, muito além dos registros feitos
pelos estudantes, está a compreensão de cada etapa do processo que foi desenvolvido com a
aplicação das etapas desta atividade. Essa compreensão, ainda que não apareça nos registros, é o
que deve determinar a conclusão do processo avaliativo.

3.4 ATIVIDADE 3: VERIFICANDO IMPEDIMENTOS NO FUTEBOL

Público alvo: 3º ano do Ensino Médio
Tempo previsto: 3 aulas
Pré-requisitos: 2ª atividade
Recursos: Caixa octante, régua, transferidor e material de escrita

3.4.1 OBJETIVOS

• Fixar deﬁnições de vetores em R2 e R3;

• Veriﬁcar aplicação direta da deﬁnição de projeção ortogonal no futebol, mais precisamente

no que diz respeito a avaliação de uma das regras de jogo: o impedimento.

A ideia geral desta atividade tem como motivação levar os estudantes a um pleno enten-
dimento da regra do impedimento por meio do estudo de projeções minimizando a proposição
de críticas e reclamações por vezes decorrentes do desentendimento dessa regra. Além disso,
esta atividade lúdica também objetiva instigar e motivar o aluno no estudo da disciplina de
Matemática, ao mesmo tempo em que busca aproximar teoria e prática de tópicos relacionados
com geometria analítica através de uma aplicação bem popular no esporte.

3.4.2 DESENVOLVIMENTO DA PROPOSTA

3.4.2.1 REGRA DE IMPEDIMENTO

Conforme as regras da IFAB (The international football association board), que é o
órgão responsável pela formulação e manutenção das regras que compõem o futebol, um jogador
estará em posição de impedimento quando qualquer parte de sua cabeça, corpo ou pés (exceto
mãos e braços, inclusive dos goleiros) estiver no campo adversário e mais próximo da linha de
meta adversária do que a bola e o penúltimo adversário. Ademais, um jogador em posição de
impedimento somente será punido se no momento em que a bola for jogada ou tocada por um

105

companheiro de equipe (considerando o momento do primeiro ponto de contato com a bola)
participar ativamente do jogo, seja interferindo no jogo, interferindo num adversário ou mesmo
ganhando vantagem de sua posição de impedimento (IFAB, 2019).

O responsável por esta observação simultânea (observação do jogador e da bola no
momento do passe, para quaisquer posições da bola e do jogador no campo de futebol) é o
árbitro (juiz) assistente, também conhecido como “bandeirinha”. Este árbitro se locomove em
uma das laterais do campo de futebol procurando sempre a melhor posição para marcar, entre
outras infrações do futebol, o impedimento (DELFIM; JESUS, 2011).

Vejamos alguns exemplos.

Figura 47 – Exemplo de impedimento I

Fonte – Adaptado de (IFAB, 2019)

Figura 48 – Exemplo de impedimento II

Fonte – Adaptado de (IFAB, 2019)

Figura 49 – Exemplo de impedimento III

106

Fonte – Adaptado de (IFAB, 2019)

Figura 50 – Exemplo de impedimento IV

Fonte – Adaptado de (IFAB, 2019)

Apesar da popularidade do futebol, não são todos os alunos que conhecem a regra
do impedimento numa partida de futebol. Sendo assim, num primeiro momento o professor
conduzirá um trabalho (simples) a ﬁm de que todos os alunos entendam a regra. Neste momento,
caso haja necessidade de maior compreensão e disponibilidade de computador, sugere-se que o
professor exiba a sua turma alguns vídeos de situações de impedimentos.

3.4.2.2 FUNCIONAMENTO DA TECNOLOGIA VAR

Por muito tempo a forma como esta regra foi "avaliada" durante uma partida de futebol
foi tema de longos debates por especialistas devido a erros cometidos pela equipe de arbitragem,
seja na marcação equivocada de um impedimento, ou mesmo na não marcação de lances

107

claros de impedimentos, os quais interferiam diretamente nos resultados das partidas. Uma das
principais causas destes erros de marcação está relacionado com o fato de o árbitro assistente ser
humano, sujeito a erros. Nem todos os lances de impedimentos são claros (visualmente), o que
consequentemente diﬁculta o trabalho dos árbitros.

Muitas críticas a marcações de impedimentos aos árbitros assistentes, por parte das
pessoas que assistem ao jogo (seja num estádio de futebol ou mesmo numa televisão), têm como
referência imagens diferentes das que um árbitro assistente (bem posicionado) tem num jogo, e
acabam tirando conclusões precipitadas sem levar em conta seu ponto de visão (Figuras 51 e 52).

Figura 51 – Posicionamente de câmera para veriﬁcação de impedimento I

Fonte – Adaptado de (IFAB, 2019)

Figura 52 – Posicionamente de câmera para veriﬁcação de impedimento II

Fonte – Adaptado de (IFAB, 2019)

108

Para tanto, recentemente foi aprovada pela FIFA (do francês: Fédération Internationale
de Football Association) a tecnologia VAR, (video assistant referee) ou árbitro assistente de
vídeo, com o objetivo de extinguir estes erros de arbitragem. Aqui não estamos fazendo nenhuma
crítica à forma como era avaliada situações de impedimento, mas mostrar as vantagens advindas
com esta tecnologia no que diz respeito à marcação de impedimentos, relacionando com o estudo
de projeções.

Um árbitro assistente de vídeo (VAR) é um árbitro de partida que possui acesso indepen-
dente às imagens gravadas da partida, o qual poderá auxiliar o árbitro na eventualidade de um
“erro claro e óbvio”, como por exemplo a marcação de impedimento (IFAB, 2019).

Para análise de um lance de impedimento, levando em conta que a regra do impedimento
(mencionada na etapa anterior) leva em consideração a menor distância entre o atacante e o
defensor rival mais próximos em relação à linha de meta, o sistema primeiramente traça a
projeção ortogonal da parte do corpo mais próxima da linha de meta destes dois jogadores em
questão (exceto mãos e braços, inclusive dos goleiros) em relação ao campo. Em seguida é
deﬁnido uma reta paralela à linha de gol para cada projeção, isto é, para cada jogador, para por
ﬁm ser analisada a menor distância entre as retas paralelas e a linha de gol. A visualização destas
retas paralelas para cada jogador torna este sistema prático para a arbitragem e ao mesmo tempo
didático. Vejamos um exemplo de participação do VAR (Figura 53):

Figura 53 – Lance capturado por emissora de TV

Fonte – (O DOCUMENTO, 2019)

Tal aplicação ocorreu numa partida de futebol no dia 12/06/2019 válida pela série A
do campeonato brasileiro de futebol, entre Internacional e Bahia. Na ocasião houve muitas
reclamações por conta da não marcação de um suposto impedimento no 1º gol do internacional
(Figuras 54 e 55).

Figura 54 – Reação de torcedores

109

Fonte – (TORCEDORES, 2019)

Figura 55 – Reação de dirigentes de um dos clubes envolvidos

Fonte – (GLOBOESPORTE, 2019)

Com o objetivo de minimizar as críticas, o chefe de arbitragem da CBF (Confederação
Brasileira de Futebol) divulgou as imagens analisadas pelo VAR e explicou o funcionamento do
VAR, justiﬁcando a correta decisão tomada pelos árbitros (Figuras 56, 57 e 58).

Figura 56 – Declaração do chefe de arbitragem

Fonte – (SPORTV, 2019)

Figura 57 – Imagem capturada e analisada pelo VAR com projeções

110

Fonte – (SPORTV, 2019)

Figura 58 – Funcionamento do VAR

Fonte – (SPORTV, 2019)

É muito importante que os estudantes realmente entendam a regra e o funcionamento da
VAR, principalmente no que diz respeito à "distância" do jogador com a linha do gol, que está
relacionado à distância da projeção da parte do corpo do jogador mais próximo da linha de gol
com relação ao campo até a linha do gol.

111

3.4.2.3 EXPERIMENTO COM VAR

A ideia desta atividade é fazer os alunos experimentarem na prática o funcionamento
do VAR por meio de um experimento controlado, e mostrar a relação direta com o estudo de
projeção que propomos. Resumidamante, a ideia é simular situações de impedimento na caixa
octante com base em análise de projeções.

Primeiramente utilizando a caixa octante, pedir para os estudantes selecionarem dois
(ou mais) objetos, que representarão os jogadores, e posicionarem lado a lado na base da caixa
voltados para um dos planos que compõe os lados da caixa octante. Deﬁna a reta de interseção
da base da caixa com o plano escolhido como lado como sendo a linha de meta.

Para que a atividade seja mais atrativa para os estudantes, o professor pode sugerir
a utilização de bonecos em miniaturas de jogadores de diversos formatos, ﬁcando a critério
dos estudantes a escolha. A utilização de bonecos em miniatura também é interessante para
mostrar aos alunos as vantagens do VAR em relação à avaliação de um lance apenas pelo árbitro
assistente, principalmente no que se refere às partes do corpo analisadas nestes lances. Para um
maior realismo do experimento é interessante que também seja feito uma escolha entre qual
objeto será o atacante e qual o defensor adversário (Figura 59).

Figura 59 – Experimento simulado do VAR

Fonte – Autoria própria (2019)

Após os objetos serem posicionados pelos estudantes, inicia-se o processo de análise de
existência ou não de impedimento. O processo que buscaremos desenvolver é análogo ao exposto
no Exemplo 3.14. Vale mencionar que como estamos buscando ver o jogador mais próximo da
linha do gol (meta) por meio da análise das suas respectivas projeções, vamos trabalhar com
vetores ortogonais à linha de gol.

112

Inicialmente vamos deﬁnir um vetor correspondente para cada jogador envolvido com
norma ﬁxada inicialmente. Estes vetores deverão ser deﬁnidos de modo que seus pontos iniciais
devem pertencer ao plano da base e seus pontos ﬁnais deverão ser respectivamente o ponto do
corpo de cada jogador mais próximo da linha de gol (lembrando que devem ser excluídos mãos e
braços) (Figura 60).

Figura 60 – Deﬁnição de vetores correspondentes a cada jogador envolvido na jogada

Fonte – Autoria própria (2019)

Como a deﬁnição da regra de impedimento está vinculada à deﬁnição de projeção
ortogonal do ponto do corpo de cada jogador mais próximo da linha de gol, vamos veriﬁcar a
projeção ortogonal desses vetores correspondente aos jogadores envolvidos. Para isso, deﬁnamos
um triângulo retângulo para cada vetor (Figura 61).

Figura 61 – Deﬁnição de triângulo retângulo correspondente a cada jogador com relação à base

da caixa (campo)

Fonte – Autoria própria (2019)

113

Analisando a ilustração acima, perceba que pela forma como deﬁnimos a linha de
gol (eixo x) e vetores correspondentes aos jogadores (ortogonais à linha de gol), basta que
−→
veriﬁquemos a componente y dos pontos C e C 0, que deﬁnem respectivamente os vetores
AC e
−−→
A0C 0 que são as projeções ortogonais dos vetores de cada jogador envolvido.

Além disso, como inicialmente ﬁxamos a norma de cada vetor bem como os posicionamos
na caixa octante em nosso experimento, temos que é de nosso conhecimento as coordenadas
dos pontos onde tais vetores foram ﬁxados na caixa, o ângulo de inclinação desses vetores com
relação a base da caixa (veriﬁcado com auxílio de transferidor) além da norma de cada vetor.

Seguindo desenvolvimento análogo ao realizado no Exemplo 3.14, temos que nosso
objetivo é obter C(x1, y1, 0) em função das coordenadas de A, da norma do vetor deﬁnido e do
−−→
BC e C 0(x2, y3, 0) em função
ângulo de inclinação de tal vetor, tal que o
das coordenadas de A0, da norma do vetor deﬁnido e do ângulo de inclinação de tal vetor, tal
−−→
B0C 0. Desta forma, aplicando deﬁnição de cosseno aos triângulos
que o
retângulos ABC e A0B0C 0, temos que as componentes y dos pontos C e C 0 são respectivamente

−−→
A0C 0 seja ortogonal a

−→
AC seja ortogonal a

y1 = y2 − k

−→
ABk cos θ

e

y3 = y4 − k

−−→
A0B0k cos θ0.

(3.4)

Assim, a veriﬁcação da existência de impedimento pode ser feita com base na análise das retas
da base paralelas a linha do gol passando pelos pontos y1 e y3 (Figura 62).

Figura 62 – Veriﬁcação da não existência de impedimento

Fonte – Autoria própria (2019)

Tendo o entendimento do processo, é sugerido ao professor que estimule sua turma
a variar o posicionamento dos bonecos de jogadores com intuito de que os alunos consigam
comprovar analiticamente a existência ou não de impedimentos.

A seguir uma foto relacionada a um exemplo de deﬁnição do vetor correspondente a um

jogador em estudo na caixa octante.

114

Figura 63 – Exemplo de deﬁnição de vetor correspondente a um jogador

Fonte – Autoria própria (2019)

Exemplo 3.16. Vamos veriﬁcar se o atacante da Figura 64 está em posição de impedimento.

Figura 64 – Veriﬁcando se atacante está em posição de impedimento

Fonte – Autoria própria (2019)

Inicialmente precisamos deﬁnir os vetores que corresponderão ao atacante e ao defensor,
assim como as informações de norma, localização na base da caixa em termos das coordenadas
do ponto de cada vetor pertencente ao plano da base, assim como suas respectivas inclinações

(com utilização de régua para medição do comprimento do vetor e de transferidor para medição
do ângulo de inclinação dos vetores). Em seguida, modelamos o problema como um triângulo
retângulo correspondente para cada jogador deﬁnido pelo vetor do jogador com sua respectiva
projeção ortogonal em relação à base da caixa octante para assim aplicar deﬁnição de cosseno
em ambos os triângulos (Figuras 65 e 66).

115

Figura 65 – Veriﬁcando projeção ortogonal do atacante

Fonte – Autoria própria (2019)

Neste caso, da equação 3.4, segue que y1 = 22 − 18 · cos 60◦ = 22 − 9 = 13.

Por outro lado, analisando o defensor temos que y3 = 31 − 18 · cos 45◦ ≈ 18, 27 (Figura

66).

Figura 66 – Veriﬁcando projeção ortogonal do defensor

Fonte – Autoria própria (2019)

Portanto, como y1 = 13 < 18, 27 ≈ y3 concluímos que o atacante está em posição de
impedimento. Neste caso, podemos dizer que o atacante está aproximadamente 5,27 cm mais
adiantado que o último defensor (Figura 67).

Figura 67 – Veriﬁcação da existência de impedimento

116

Fonte – Autoria própria (2019)

3.4.3 AVALIAÇÃO

Acreditando que o processo avaliativo se dá como um todo e acontece processualmente
durante as aulas, a avaliação da presente proposta de atividade se dará por participação e
envolvimento dos alunos com questionamentos e contribuições e o envolvimento da turma na
resolução dos problemas propostos durante toda a atividade, podendo o professor avaliar também
todo o material produzido pela turma neste processo. Contudo, muito além dos registros feitos
pelos estudantes, está a compreensão de cada etapa do processo que foi desenvolvido com a
aplicação das etapas desta atividade. Essa compreensão, ainda que não apareça nos registros, é o
que deve determinar a conclusão do processo avaliativo.

4 CONCLUSÃO

117

Este trabalho propôs uma série de atividades para o Ensino Médio onde através do estudo
de projeções pretende-se reforçar tópicos de Geometria Analítica, principalmente, Trigonometria.
Ademais, desenvolveu-se um material concreto para o trabalho (caixa octante) cujo custo é
altamente compatível com a realidade das escolas nacionais, podendo inclusive ser produzido na
própria escola e pelos próprios alunos se houver material e espaço para este ﬁm. Cabe destacar
que devido a suas características, a utilização do material concreto elaborado neste trabalho é
bem ampla, não restrigindo às atividades aqui propostas, podendo atender também alunos com
deﬁciência visual.

Embora o fato do tema proposto (projeções) não estar no currículo, ele permite trabalhar
com conteúdos curriculares, nomeadamente Trigonometria e Geometria Analítica, além de
conteúdos de outras disciplinas de maneira interdisciplinar. Dessa maneira, pode-se aﬁrmar que
o que se propôs neste texto é a utilização do tema projeções de maneira motivacional para a
aprendizagem de outros temas, estes sim curriculares.

Ao propor as atividades para o Ensino Médio, buscamos ter um cuidado especial em
mostrar ao aluno de forma concreta e estimulante um conteúdo essencialmente abstrato com
utilização de recursos concretos e dinâmicos, sem deixar de lado importantes fundamentos
teóricos. Neste contexto, o estudante não só tem um envolvimento com o estudo de projeções
como também o faz de forma lúdica, propiciando um ambiente que julgamos favorecer o processo
de ensino-aprendizagem.

Sobre a proposta de trazer atividades diversiﬁcadas neste trabalho, com possibilidade
de serem aplicadas de forma interdisciplinar, vamos ao encontro das Orientações Educacionais
Complementares aos Parâmetros Curriculares Nacionais.

É importante uma preocupação consciente e explícita para atender adequa-
damente todos os alunos de uma classe heterogênea, propondo o trabalho
diversiﬁcado na sala de aula e o trabalho coletivo dos diversos professores de
um mesmo aluno. O trabalho diversiﬁcado pressupõe o reconhecimento de que
a situação normal em uma sala de aula é a diferença de ritmo, de motivação
e de formação, e de que queremos respeitar o direito de todos de acesso ao
conhecimento. Finalmente, é importante lembrar que o desaﬁo de fazer com
que todos aprendam não é tarefa para um só professor, mas pressupõe o tra-
balho coletivo dos diferentes professores desses alunos e do envolvimento da
escola em um projeto pedagógico comum. A Matemática tem papel relevante
nessa ação coletiva porque frequentemente ela é mitiﬁcada por sua pretensa
diﬁculdade. É importante deixar claro que todos podem aprendê-la (BRASIL,
2006b).

Esperamos que esta proposta possa ser uma ferramenta útil, para professores e alunos,
no complemento do estudo de Geometria Analítica. Que os alunos possam perceber que mesmo
conteúdos abstratos, como o de projeções por exemplo, possuem aplicações diversas, inclusive no

esporte, e que o correto entendimento dos conceitos matemáticos envolvidos acabam permitindo
uma melhor compreensão do problema e contribuindo no desenvolvimento de uma solução
adequada.

118

REFERÊNCIAS

119

BEGIATO, R. G. Um método Newton-inexato com estratégia híbrida para globalização.
Dissertação (Mestrado) — Universidade Estadual de Campinas, 2007. 54, 58

BRASIL. Secretaria de Educação Básica. Parâmetros curriculares nacionais: Ensino médio.
Brasília: Ministério da Educação, Secretaria de Educação Básica, 2000. 16, 85

BRASIL. Secretaria de Educação Básica. Orientações curriculares para o Ensino Médio:
Ciências da natureza, matemática e suas tecnologias. Brasília: Ministério da Educação,
Secretaria de Educação Básica, 2006. 15, 84, 85

BRASIL. Secretaria de Educação Básica. Orientações educacionais complementares
aos parâmetros curriculares nacionais (PCN+: Ciências da natureza, matemática e suas
tecnologias. Brasília: Ministério da Educação, Secretaria de Educação Básica, 2006. 117

COELHO, F. U.; LOURENÇO, M. L. Um curso de álgebra linear. São Paulo, SP: EDUSP,
2013. 18

DELFIM, T. F.; JESUS, V. L. B. de. O problema da simultaneidade na lei do impedimento do
futebol. Revista Brasileira de Ensino de Física, Rio de Janeiro, v. 33, n. 4, 4308, dez. 2011.
105

DEMMEL, J. W. Applied numerical linear algebra. Philadelphia: SIAM, 1997. 54

GLOBOESPORTE. Após gol polêmico do Inter, Bellintani pede imagens do VAR
e descarta anulação da partida. 2019. Publicado: 13 de jun. 2019 por Por GloboEs-
porte.com. Disponível em: <https://globoesporte.globo.com/ba/futebol/times/bahia/noticia/
apos-gol-polemico-do-inter-bellintani-pede-imagens-do-var-e-descarta-anulacao-da-partida.
ghtml>. Acesso em: 23 jul. 2019. 109

GREENBAUM, A. Iterative methods for solving linear systems. Philadelphia: SIAM, 1997.
54

HEFEZ, A.; FERNADEZ, C. d. S. Introdução à álgebra linear. Rio de Janeiro: SBM, 2016.
(Coleção PROFMAT). 18

HESTENES, M. R.; STIEFEL, E. Methods of conjugate gradients for solving linear systems.
Journal of Research of the National Bureau of Standards, Los Angeles, v. 49, n. 6, 2379, p.
409–436, dec. 1952. 54, 75

IFAB. Laws of the game: 2019/20. Zurich: The International Football Association Board, 2019.
16, 105, 106, 107, 108

KELLEY, C. T. Iterative methods for linear and Nonlinear Equations. Philadelphia: SIAM,
1995. 15, 54, 57, 73

LAGO, R. F. Estudos sobre os métodos iterativos de Krylov para solução de sistemas de
equações lineares. Dissertação (Mestrado) — Universidade Federal do Rio de Janeiro, 2010.
54, 77

120

LIMA, E. L. Álgebra linear. 8. ed. Rio de Janeiro: IMPA, 2014. (Coleção matemática
universitária). 18

NASCIMENTO, M. C. Álgebra linear. Bauru: UNESP, 2013. 18

O DOCUMENTO. Presidente do Bahia critica VAR, mas descarta anulação de jogo contra
o Inter. 2019. Publicado: 13 de jun. 2019 por Da Redação. Disponível em: <https://odocumento.
com.br/presidente-do-bahia-critica-var-mas-descarta-anulacao-de-jogo-contra-o-inter/>.
Acesso em: 23 jul. 2019. 108

SAAD, Y. Iterative methods for sparse Linear Sistems. [S.l.]: SIAM, 2003. 54, 57

SANTOS, R. d. J. Álgebra linear e aplicações. Belo Horizonte: Imprensa universitária da
UFMG, 2006. 18, 40

SHEWCHUK, J. R. An introduction to the conjugate gradient method without the agonizing pain.
School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213, Pensilvânia,
p. 2–3, aug. 1994. 77

SPORTV. Chefe de arbitragem da CBF divulga imagem e explica lance
polêmico do VAR em Inter x Bahia. 2019. Publicado: 13 de jun. 2019 por Por
SporTV.com. Disponível em: <https://sportv.globo.com/site/programas/redacao-sportv/noticia/
chefe-de-arbitragem-da-cbf-divulga-imagem-e-explica-lance-polemico-do-var-em-inter-x-bahia.
ghtml>. Acesso em: 23 jul. 2019. 109, 110

TEIXEIRA, R. C. Álgebra linear: exercícios e soluções. 3. ed. Rio de Janeiro: IMPA, 2015.
(Coleção matemática universitária). Soluções dos exercícios do livro Álgebra Linear de Elon
Lages Lima. 18

TORCEDORES. Internautas questionam uso polêmico do VAR na vitória do Inter
sobre o Bahia. 2019. Publicado: 13 de jun. 2019 por Andressa Fischer. Disponível em:
<https://www.torcedores.com/noticias/2019/06/internautas-questionam-var-inter-x-bahia>.
Acesso em: 23 jul. 2019. 109

TREFETHEN, L. N.; BAU, D. Numerical linear algebra. Philadelphia: SIAM, 1997. 54


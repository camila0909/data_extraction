1
2
0
2

s
o
m
e
L
e
d
s
o
l
r
a
C
o
n
a
i
c
u
L

P
O
F
U
/
T
A
M
E
D

Universidade Federal de Ouro Preto

Instituto de Ciências Exatas e Biológicas

Mestrado Profissional em Matemática em Rede Nacional  
PROFMAT                                                                                                                                                                                             

Dissertação

Números normais: uma 
aplicação da lei dos grandes 
números

Luciano  Carlos de Lemos

Ouro Preto
2021

 
 
 
UNIVERSIDADE FEDERAL DE OURO PRETO (UFOP)
INSTITUTO DE CIÊNCIAS EXATAS E BIOLÓGICAS (ICEB)
DEPARTAMENTO DE MATEMÁTICA (DEMAT)
MESTRADO PROFISSIONAL EM MATEMÁTICA EM REDE NACIONAL (PROFMAT)

LUCIANO CARLOS DE LEMOS

Números Normais: uma aplicação da Lei dos Grandes Números

OURO PRETO - MG, BRASIL
2021

LUCIANO CARLOS DE LEMOS

Números Normais: uma aplicação da Lei dos Grandes Números

Dissertação de mestrado apresentada
como parte dos requisitos para obten-
ção do título de Mestre pelo programa de
Mestrado Proﬁssional em Matemática em
Rede Nacional do Departamento de Ma-
temática do Instituto de Ciências Exatas
e Biológicas da Universidade Federal de
Ouro Preto.

Orientador: Sávio Ribas.

OURO PRETO - MG, BRASIL
2021

SISBIN - SISTEMA DE BIBLIOTECAS E INFORMAÇÃO

L556n

Lemos, Luciano Carlos de .
LemNúmeros normais [manuscrito]: uma aplicação da Lei dos Grandes
Números. / Luciano Carlos de Lemos. - 2021.
Lem87 f.: il.: color., tab..

LemOrientador: Prof. Dr. Sávio Ribas.
LemDissertação (Mestrado Profissional). Universidade Federal de Ouro
Preto. Departamento de Matemática. Programa de Pós-Graduação em
Matemática.
LemÁrea de Concentração: Matemática com Oferta Nacional.

Lem1. Matemática - Estudo e ensino. 2. Numeração. 3. Probabilidades. I.
Ribas, Sávio. II. Universidade Federal de Ouro Preto. III. Título.

Bibliotecário(a) Responsável: Flavia Reis - CRB6-2431

CDU 511:374

.

“Daria tudo que sei, pela metade do que ignoro.”
(René Descartes)

.

Agradecimentos

A Deus, pela dádiva da vida e por me permitir realizar tantos sonhos nesta exis-
tência. Obrigado por Sua voz “invisível” que não me permitiu desistir, por Sua eterna
compreensão e tolerância e principalmente por ter me dado uma família tão especial.
Ao Prof. Sávio, pela orientação, competência, proﬁssionalismo e dedicação tão im-
portantes. Tantas vezes que nos reunimos e, embora em algumas eu me apresentasse
desestimulado, bastavam alguns minutos de conversa para retomar o ânimo. Obri-
gado por acreditar em mim e ter aceitado essa empreitada. Tenho certeza que não
chegaria neste ponto sem o seu apoio.

Aos membros da banca examinadora, Prof. Danilo Vilela Avelar, Profª Luana
Amaral Gurgel e Prof. Rodrigo Geraldo do Couto, que tão gentilmente aceitaram
participar e colaborar com esta dissertação.

Aos Professores do PROFMAT-UFOP, pela dedicação, competência, apoio e todo
conhecimento compartilhado.Agradeço também aos meus colegas do PROFMAT, por
dividir comigo suas experiências, angústias e conhecimentos nas várias listas de exer-
cícios, revisões e discussões sempre muito produtivas.

À minha família, avós, tios(as), primos(as), cunhados(as), sobrinhos(as) e minha
sogra por apoiarem e compreenderem o meu distanciamento em vários momentos; em
especial à Denise, que me incentivou e foi companheira de caminhada.

À minha mãe Silvina e ao meu pai Carlos deixo um agradecimento especial, por
todas as lições de amor, companheirismo, amizade, caridade, dedicação, abnegação e
compreensão que vocês me dão todos os dias. Sinto-me orgulhoso e privilegiado por
ter pais tão especiais. E ao meu irmão Leandro, sempre pronto a me apoiar e incentivar
em tudo nesta vida.

À minha amada esposa Cláudia e ao meu ﬁlho Gabriel, por todo amor, incentivo,
apoio e compreensão. Obrigado por permanecerem ao meu lado, mesmo sem a atenção
devida e depois de tantos momentos de lazer perdidos. Nada disso teria sentido se
vocês não existissem na minha vida.

Por ﬁm, a todos aqueles que contribuíram, direta ou indiretamente, para a realiza-

ção desta dissertação, o meu sincero agradecimento.

iii

.

Resumo

Neste trabalho, estudamos os números normais e pseudoaleatórios como uma apli-
cação da Lei dos Grandes Números. Para isso, primeiramente construímos toda a base
teórica de probabilidade com o objetivo de fundamentar a Lei dos Grandes Números,
um teorema da teoria da probabilidade que estabelece, sob certas hipóteses, que a mé-
dia aritmética dos resultados observados através da realização da mesma experiência
muitas vezes aproxima-se da esperança da variável aleatória. Em seguida, vemos que
um problema fundamental na Matemática, na Estatística e na Computação é a geração
de números aleatórios, que possuem diversas aplicações práticas, e ainda, que os me-
lhores candidatos a números aleatórios são os números absolutamente normais, mas
ainda não os conhecemos. Sendo assim, devemos nos contentar com números pseu-
doaleatórios, que são números “aparentemente” aleatórios, mas que são gerados de
uma forma determinística. Na sequência apresentamos o problema de Monty-Hall,
também conhecido popularmente como problema dos bodes, que foi proposto pela
primeira vez em um programa de auditório nos EUA. Através de simulações e usando
a Lei dos Grandes Números conseguimos conjecturar um resultado correto para esse
problema. Atividades didáticas envolvendo tais resultados também foram abordadas
e sua aplicação em sala de aula, com estudantes de Ensino Médio de uma escola de
Manhumirim-MG e também de graduação em Matemática da UFOP, são descritas. Os
dados foram coletados por meio de observações durante a aplicação da atividade e
através das respostas dadas aos questionários. Os resultados mostram que os estu-
dantes podem, em muitos casos, ter uma visão intuitiva do problema que os conduza
ao erro na escolha da melhor estratégia de resolução. Daí percebemos que atividades
como essas podem contribuir signiﬁcativamente para o processo de aprendizagem dos
estudantes.

Palavras-chave: Probabilidade; Lei dos Grandes Números; Números Normais; Núme-
ros Aleatórios; Números Pseudoaleatórios; Problema de Monty-Hall.

iv

.

Abstract

In this work, we study the normal and pseudorandom numbers as an application
of the Law of Large Numbers. To do this, we ﬁrst construct the entire theoretical ba-
sis of probability in order to substantiate the Law of Large Numbers, a theorem of
probability theory that establishes, under certain hypotheses, that the arithmetic mean
of the observed results after performing the same experiment many times approaches
the expectation of the random variable. Next, we see that a fundamental problem in
Mathematics, Statistics and Computing is the generation of random numbers, which
has many practical applications, and further that the best candidates for random num-
bers are the absolutely normal numbers, but we do not know them yet. Therefore, we
must be content with pseudorandom numbers, which are “apparently” random num-
bers, but which are generated in a deterministic way. Next, we present the Monty-Hall
problem, also popularly known as the goat problem, which was ﬁrst proposed in a
talk show in the USA. Through simulations and using the Law of Large Numbers we
were able to conjecture a correct result for this problem. Didactic activities involving
such results have also been approached and their applications in the classroom, with
high school students from a school in Manhumirim-MG and also with undergraduate
students in Mathematics at UFOP, are described. Data were collected through obser-
vations during the application of the activity and through the answers given to the
questionnaires. The results show that students can, in several cases, have an intui-
tive view of the problem that leads them to error in choosing the best solution strategy.
Hence, we realized that activities like these can signiﬁcantly contribute to the students’
learning process.

Keywords: Probability; Law of Large Numbers; Normal Numbers; Random Numbers;
Pseudorandom Numbers; Monty-Hall Problem.

v

vi

Lista de Figuras

3.1 Gráﬁco de uma função convexa . . . . . . . . . . . . . . . . . . . . . . . .

4.1 Gráﬁco das funções f (x) = 1 − x e g(x) = e−x . . . . . . . . . . . . . . . .

31

47

vii

viii

LISTA DE FIGURAS

Lista de Tabelas

2.1

Imunização por doses

3.1 Distribuição conjunta .

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.1 Porta onde está o prêmio . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Porta que escolhemos inicialmente . . . . . . . . . . . . . . . . . . . . . .
5.3 Módulo da diferença entre as respectivas entradas das Tabelas 5.1 e 5.2 .
5.4 Compilação dos resultados das simulações . . . . . . . . . . . . . . . . .

12

38

62
62
63
63

ix

x

LISTA DE TABELAS

Sumário

Introdução

1 Preliminares sobre Probabilidade

1.1 Deﬁnição de Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Probabilidade Condicional e Independência . . . . . . . . . . . . . . . . .

2 Distribuição de variáveis aleatórias

.

.

2.1 Variáveis aleatórias .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Tipos de variáveis aleatórias . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Principais modelos de distribuição . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Vetores aleatórios .
Independência de variáveis aleatórias . . . . . . . . . . . . . . . . . . . .
2.5

.

.

.

3 Esperança e Variância de variáveis aleatórias

3.1 Esperança e suas propriedades . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Esperanças de funções de variáveis aleatórias . . . . . . . . . . . . . . . .

4 A Lei dos Grandes Números

4.1 A Lei Fraca dos Grandes Números . . . . . . . . . . . . . . . . . . . . . .
4.2 O Lema de Borel-Cantelli
. . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 A Lei Forte dos Grandes Números . . . . . . . . . . . . . . . . . . . . . .

5 Números Normais e pseudo-aleatoriedade

5.1 Números normais .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . .
5.2 Números aleatórios e pseudoaleatórios
5.3 Blocos de dígitos iguais . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 O problema de Monty-Hall

.

.

.

1

3
3
6

11
11
13
16
18
19

23
23
32

41
45
46
49

57
57
60
60
61

6 Aplicações em sala de aula

65
65
Justiﬁcativa e Relevância . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.1
66
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.2 Roteiro da atividade .
66
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
6.2.1 Objetivos . .
66
6.2.2 Metodologia .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
6.2.3 Descrição das Atividades . . . . . . . . . . . . . . . . . . . . . . .
68
6.3 Análise dos Questionários . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.3.1 Análise das respostas dos estudantes do Ensino Médio . . . . . .
69
6.3.2 Análise das respostas dos estudantes da Graduação em Matemática 71

xi

xii

7 Conclusões

A Generalizações da integral de Riemann

A.1 A integral de Lebesgue . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A.2 A integral de Stieltjes .

B A integral de uma função gaussiana

Referências Bibliográﬁcas

SUMÁRIO

75

77
78
80

85

87

SUMÁRIO

.

xiii

Introdução

A Teoria da Probabilidade é um ramo bastante conhecido da Matemática e que pos-
sui diversas interpretações, mesmo para leigos em Matemática. Frequentemente, ve-
mos na televisão notícias envolvendo probabilidades, como em assuntos relacionados
a pesquisas eleitorais, previsão do tempo, ou mesmo em assuntos esportivos. Alguns
indícios alegam que o surgimento da teoria das probabilidades teve início com os jogos
de azar disseminados na Idade Média. Esse tipo de jogo é comumente praticado atra-
vés de apostas, na ocasião também era utilizado no intuito de antecipar o futuro. Na
verdade, a teoria da probabilidade não prevê o futuro e sim tenta obter informações
sobre o futuro, com certa chance de ocorrer, baseado em eventos passados. Tal teoria
se sustenta rigorosamente através dos Axiomas de Kolmogorov, que serão vistos no
Capítulo 1. As bases da teoria das probabilidades e da análise combinatória foram es-
tabelecidas por Pascal e Fermat no século XVII e aplicadas a situações relacionadas a
apostas em jogos. Posteriormente, Bernoulli abordou a importância da Lei dos Gran-
des Números. Atualmente, a probabilidade é bastante usada também em Estatística
[11].

O objetivo deste trabalho é apresentar algumas versões da Lei dos Grandes Nú-
meros e, como aplicação, veremos os números normais e pseudoaleatórios. Para isso,
temos que construir toda a base teórica anterior. Em seguida, vamos usar a geração de
números pseudoaleatórios para simular o problema de Monty-Hall um número grande
de vezes. Usando a Lei dos Grandes Números, vamos inferir uma resposta para esse
problema. Vamos também apresentar essas aplicações em sala de aula para estudantes
do ensino médio e superior.

No Capítulo 1, vamos deﬁnir formalmente um espaço de probabilidade. Para isso,
em um “conjunto universo” que chamaremos de espaço amostral, vamos deﬁnir o con-
junto de eventos através da σ-álgebra, e vamos precisar de uma função de probabili-
dade, que atribui um valor entre 0 e 1 a todo evento. Essa função de probabilidade
satisfaz os axiomas de Kolmogorov e dela podemos extrair diversas propriedades. Va-
mos também deﬁnir probabilidade condicional e independência, além de apresentar
alguns teoremas clássicos da probabilidade, como o Teorema da Multiplicação e o Te-

1

2

orema de Bayes.

CAPÍTULO 0. INTRODUÇÃO

No Capítulo 2, vamos apresentar o conceito de variáveis aleatórias, que são funções
que determinam um característico numérico do resultado de um experimento. Vamos
apresentar também a função de distribuição de variáveis aleatórias (tanto discretas
quanto contínuas) e suas propriedades, além dos principais modelos de distribuição.

No Capítulo 3, deﬁnimos a esperança e a variância das variáveis aleatórias. Tam-
bém introduzimos o conceito de momentos, além das desigualdades clássicas de Mar-
kov e Tchebychev.

No Capítulo 4, vamos deﬁnir dois tipos de convergência de sequências de variáveis
aleatórias: convergência em probabilidade e convergência quase certa. A Lei Fraca
diz respeito à convergência em probabilidade e é provada usando a desigualdade de
Tchebychev com a hipótese das variáveis aleatórias serem não-correlacionadas (que é
uma hipótese mais fraca que usar independência), enquanto a Lei Forte diz respeito
à convergência quase certa. Daremos duas versões da Lei Forte, que são provadas
usando o Lema de Borel-Cantelli e outros resultados mais profundos, supondo que
as variáveis são independentes (em uma das versões necessitamos também que elas
sejam identicamente distribuídas). A Lei Forte necessita de hipóteses mais restritivas
que a Lei Fraca.

No Capítulo 5, ﬁnalmente vamos apresentar os números normais em uma base b
e os números absolutamente normais, que são fortes candidatos a números aleatórios.
Vamos mostrar que, embora tenham medida total (probabilidade 1), números absolu-
tamente normais são de certa forma desconhecidos. Por isso, o problema de geração
de números aleatórios é tratado somente com números pseudoaleatórios, isto é, deter-
minísticos porém se comportam como aleatórios para a maioria das aplicações. Além
disso, vamos apresentar o Problema de Monty-Hall e usar a Lei dos Grandes Números
juntamente com um número gerado pseudo-aleatoriamente para obter uma possível
resposta para o problema.

No Capítulo 6, exibimos dois problemas relacionados à Lei dos Grandes Números
e à geração de números aleatórios, para aplicação em sala de aula. Aplicamos uma
atividade em relação a esses problemas para estudantes de ensino médio e de ensino
superior em Matemática. Nessa parte, tivemos a aprovação do projeto pela Comissão
de Ética em Pesquisa da UFOP.

No Apêndice A, apresentamos outros tipos de integral (a saber: a Integral de Le-
besgue e a de Stieltjes), suas vantagens em relação à Integral de Riemann e suas propri-
edades, que são usadas ao longo de todo o texto a partir do momento em que falamos
sobre esperança de variáveis aleatórias.

No Apêndice B, calculamos a integral de uma função gaussiana.

Capítulo 1

Preliminares sobre Probabilidade

1.1 Deﬁnição de Probabilidade

Deﬁnição 1.1.1. Seja Ω um conjunto não-vazio. Uma classe A de subconjuntos de Ω é cha-
mada σ-álgebra, quando satisfaz as seguintes propriedades

1. ∅ ∈ A,

2. Se A ∈ A, então Ac ∈ A,

3. Se A1, A2, ... ∈ A, então

∞
(cid:83)
i=1

Ai ∈ A e

∞
(cid:84)
i=1

Ai ∈ A.

Exemplo 1.1.2. A1 = {∅, Ω} é uma σ-álgebra em Ω chamada de σ-álgebra trivial. O con-
junto das partes A2 = {A ⊂ Ω} é a σ-álgebra das partes de Ω.

Deﬁnição 1.1.3. Espaço amostral é o conjunto Ω sobre o qual está deﬁnida a σ-álgebra.

Deﬁnição 1.1.4. Evento é um elemento (que é um conjunto) da σ-álgebra. Todo subconjunto
A ∈ A será chamado evento. Por exemplo, Ω é o evento certo, ∅ o evento impossível. Um
evento aleatório é aquele em que não há como prever o resultado.

Exemplo 1.1.5. Jogar um dado honesto e observar o número da face voltada para cima. Temos
que o espaço amostral é Ω = {1, 2, 3, 4, 5, 6} e a σ-álgebra pode ser deﬁnida como a σ-álgebra
das partes de Ω. O evento elementar “sair o número 2”, signiﬁca o evento A1 = {2}. “Sair
número maior que 2”, é um evento que consiste de 4 resultados {3, 4, 5, 6}.

Deﬁnição 1.1.6. A σ-álgebra de Borel, deﬁnida sobre Ω = [0, 1], é a menor σ-álgebra que
contém todos os intervalos abertos, ou seja, um elemento de B é um conjunto formado por união
enumerável, interseção enumerável e diferença de intervalos. Observemos que o complementar
de conjuntos abertos é fechado e vice-versa, com isso não há perda de generalidade ao supor que

3

4

CAPÍTULO 1. PRELIMINARES SOBRE PROBABILIDADE

os intervalos abertos são apenas intervalos. Um elemento da σ-álgebra de Borel é chamado de
boreliano.

Notação: B[0,1] = {A ⊂ [0, 1] : A boreliano} é a σ-álgebra de Borel em [0, 1].

A seguir, vamos deﬁnir probabilidade de acordo com os Axiomas de Kolmogorov.

Axioma 1.1.7. Seja P : A → R.

1. P (A) ≥ 0.

2. P (Ω) = 1.

3. (Aditividade ﬁnita). Se A1, ..., An ∈ A são disjuntos 2 a 2, então

(cid:32) n
(cid:91)

P

k=1

(cid:33)

Ak

=

n
(cid:88)

k=1

P (Ak) .

3’. (σ-aditividade). Se A1, A2, ... ∈ A são disjuntos 2 a 2, então

(cid:32) ∞
(cid:91)

P

n=1

(cid:33)

An

=

∞
(cid:88)

n=1

P (An) .

É possível provar, mas não o faremos, algumas relações entre esses axiomas. Por

exemplo:

Proposição 1.1.8. O Axioma 3’ implica o Axioma 3, isto é, se P é σ-aditiva, então é ﬁnitamente
aditiva.

Deﬁnição 1.1.9. Uma função P deﬁnida numa σ-álgebra A e satisfazendo os Axiomas 1, 2 e
3’ chama-se uma medida de probabilidade em A ou simplesmente uma probabilidade em
A.

Deﬁnição 1.1.10. Considere a sequência de conjuntos (An)n≥1. Dizemos que tal sequência é

i) crescente se A1 ⊂ A2 ⊂ A3 ⊂ . . . . Nesse caso, deﬁnimos lim An = (cid:83)

k≥1 Ak e dizemos

que (An)n cresce para lim An. Notação: Ak ↑ lim An.

ii) decrescente se A1 ⊃ A2 ⊃ A3 ⊃ . . . . Nesse caso, deﬁnimos lim An = (cid:84)

k≥1 Ak e dizemos

que (An)n decresce para lim An. Notação: Ak ↓ lim An.

Deﬁnição 1.1.11. a) Se a sequência de números reais (an)n≥1 é crescente e lim an = a, dize-

mos que an cresce para a e escrevemos an ↑ a.

b) Se a sequência de números reais (an)n≥1 é decrescente e lim an = a, dizemos que an decresce

para a e escrevemos an ↓ a.

1.1. DEFINIÇÃO DE PROBABILIDADE

5

Proposição 1.1.12. Dados os Axiomas 1, 2, 3, o Axioma 3’ é equivalente à validade da conti-
nuidade no vazio, isto é, é equivalente à validade da seguinte aﬁrmação: se a sequência (An)n≥1,
onde An ∈ A ∀n decrescer para o vazio então P (An) ↓ 0 quando n → ∞. Com isso, podemos
concluir que uma probabilidade ﬁnitamente aditiva é uma probabilidade se, e só se, é contínua
no vazio.

Dados os Axiomas de Kolmogorov e suas equivalências, podemos extrair diversas

propriedades.

Proposição 1.1.13 (Propriedades de probabilidade). Seja P uma probabilidade em uma
σ-álgebra A deﬁnida sobre Ω. Então, para todo A, A1, A2, A3, · · · ∈ A, valem as seguintes
propriedades:

P1. P (Ac) = 1 − P (A). Em particular: P (∅) = 1 − P (Ω) = 0.

P2. 0 ≤ P (A) ≤ 1.

P3. Se A1 ⊂ A2 então P (A1) ≤ P (A2).

P4. P

P5. P

(cid:19)

Ai

≤

(cid:19)

Ai

≤

(cid:18) n
(cid:83)
i=1

(cid:18) ∞
(cid:83)
i=1

n
(cid:80)
i=1

∞
(cid:80)
i=1

P (Ai).

P (Ai).

P6. (Continuidade de probabilidade). Se An ↑ A, então P (An) ↑ P (A). Se An ↓ A, então

P (An) ↓ P (A).

Demonstração. Vejamos:

P 1. Segue dos Axiomas 2 e 3.

P 2. Isso segue do Axioma 1 e de P1.

P 3. Pela aditividade ﬁnita, P (A2) = P (A1) + P (A2 − A1) ≥ P (A1), pelo Axioma 1.

P 4. Pela aditividade ﬁnita, P (A1 ∪ A2) = P (A1) + P (A2 ∩ Ac

1) ≤ P (A1) + P (A2), por

P3, já que A2 ∩ Ac

1 ⊂ A2. Completa-se a prova por indução.

P 5. Deﬁna B1 = A1, B2 = A2−B1, B3 = A3−(B1 ∪ B2) , . . . , Bn = An−(B1 ∪ · · · ∪ Bn−1).
Temos que os Bn’s são disjuntos 2 a 2, (cid:83) Bn = (cid:83) An e Bn ⊂ An. Logo, pelo Axioma
3’ e por P3 temos que P ((cid:83) An) = P ((cid:83) Bn) = (cid:80) P (Bn) ≤ (cid:80) P (An).

6

CAPÍTULO 1. PRELIMINARES SOBRE PROBABILIDADE

P 6. Supondo que An ↓ A, ou seja, que An+1 ⊂ An∀n e (cid:84)

An = A. Assim, P (An) ≥
P (An+1), por P 3, e (An − A) ↓ ∅ ⇒ P (An − A) → 0, pela continuidade no vazio.
A aditividade ﬁnita implica P (An − A) = P (An) − P (A), pois A ⊂ An. Portanto,
temos P (An) − P (A) → 0 e {P (An)}n≥1 é decrescente, logo P (An) ↓ P (A).
Se An ↑ A (ou seja, An ⊂ An+1, ∀n e (cid:83)

An = A), então Ac

n ↓ Ac. Logo P (Ac

n) ↓

n≥1

n≥1

P (Ac), ou seja, 1 − P (An) ↓ 1 − P (A), portanto P (An) ↑ P (A) .

Proposição 1.1.14.

i) Se P(An) = 0 para n ∈ N, então P

ii) Se P(An) = 1 para n ∈ N, então P

(cid:18) ∞
(cid:84)
n=1

(cid:19)

An

= 1.

Demonstração.

i) Pela propriedade P5, temos que

(cid:18) ∞
(cid:83)
n=1

(cid:19)

An

= 0.

(cid:32) ∞
(cid:91)

P

n=1

(cid:33)

An

≤

∞
(cid:88)

n=1

P(An) =

∞
(cid:88)

n=1

0 = 0.

ii) Como P (Ac

n) = 0 segue que P

(cid:18) ∞
(cid:83)
n=1

(cid:19)

Ac
n

= 0 pelo item anterior. E, como

∞
(cid:92)

n=1

An = Ω −

∞
(cid:91)

n=1

Ac

n, temos que P

(cid:33)

An

= P(Ω) − P

(cid:32) ∞
(cid:92)

n=1

(cid:32) ∞
(cid:91)

(cid:33)

Ac
n

n=1

= 1 − 0 = 1.

Deﬁnição 1.1.15. Um espaço de probabilidade é um trio (Ω, A, P), formado por

(a) um conjunto Ω não vazio;

(b) uma σ-álgebra A de subconjuntos de Ω;

(c) uma probabilidade P em A.

A partir de agora, a menos que explicitemos o contrário, todos os espaços de pro-
babilidade serão dados pela tripla (Ω, A, P), e os eventos serão eventos aleatórios per-
tencentes a A.

1.2 Probabilidade Condicional e Independência

Nessa seção, vamos deﬁnir probabilidade condicional e com isso deﬁnir indepen-

dência. Vamos apresentar também alguns resultados básicos da probabilidade.

1.2. PROBABILIDADE CONDICIONAL E INDEPENDÊNCIA

7

Deﬁnição 1.2.1. Se B ∈ A e P (B) > 0, a probabilidade condicional de A ∈ A dado B, é
deﬁnida por

P (A | B) =

P (A ∩ B)
P (B)

.

Teorema 1.2.2 (Teorema da Multiplicação ou Teorema da Probabilidade Composta).
São válidos:

(i) P (A ∩ B) = P (A) P (B | A) = P (B) P (A | B) , ∀A, B ∈ A;

(ii) P (A1 ∩ A2 ∩ · · · ∩ An) = P (A1) P (A2 | A1) P (A3 | A1 ∩ A2) . . . P (An | A1 ∩ · · · ∩ An−1),

∀An ∈ A com n ∈ N.

Demonstração. O item (i) segue da deﬁnição e o item (ii) segue por indução.

Exemplo 1.2.3. Um lote contém 10 peças, sendo 7 boas e 3 defeituosas. Retiramos três peças,
ao acaso e sem reposição, para inspeção. Qual a probabilidade de se obter três peças defeituosas?
Seja Di o evento “retirar uma peça defeituosa na i-ésima extração”. Então (com D = “retirar

3 peças defeituosas”) temos:

P (D) = P (D1 ∩ D2 ∩ D3) = P (D1) P (D2 | D1) P (D3 | D1 ∩ D2) =

3
10

·

2
9

·

1
8

=

1
120

Teorema 1.2.4 (Teorema da Probabilidade Total). Se a sequência (ﬁnita ou enumerável) de
eventos aleatórios A1, A2, ... formar uma partição de Ω, isto é, se os An’s forem disjuntos 2 a 2
e (cid:83) An = Ω, então

P (B) =

P (An) P (B | An) , ∀B ∈ A.

(cid:88)

Teorema 1.2.5 (Teorema de Bayes). Nas mesmas hipóteses do teorema anterior, vale

n

P (Ai | B) =

P (Ai) P (B | Ai)
P (Aj) P (B | Aj)

(cid:80)
j

.

Demonstração. Da deﬁnição de probabilidade condicional temos

P (Ai | B) =

P (Ai ∩ B)
P (B)

.

O numerador dessa expressão pode ser reescrito pela regra do produto, condicionado
à An, isto é,

P (Ai ∩ B) = P (B ∩ Ai) = P (B | Ai) P (Ai) .

Para completar a demonstração, basta notar que

P (B) =

(cid:88)

j

P (B ∩ Aj) =

(cid:88)

j

P (B | Aj) P (Aj) .

8

CAPÍTULO 1. PRELIMINARES SOBRE PROBABILIDADE

Exemplo 1.2.6. Suponha que um jogador participa de um torneio de tênis onde sua probabili-
dade de vitória é 0,3 contra metade dos jogadores (chame-os de grupo 1), 0,4 contra um quarto
do jogadores (chame-os de grupo 2) e 0,5 contra o um quarto dos jogadores restantes (chame-os
de grupo 3). O jogador disputa uma partida contra um oponente selecionado aleatoriamente.
Supondo que o jogador venceu a partida disputada, qual a probabilidade dele ter jogado contra
um adversário do grupo 1?

Considere que Aj é o evento “ter um adversário do grupo j”. Temos P (A1) = 0, 5; P (A2) =
0, 25; P (A3) = 0, 25. Além disso, se B é o evento “vencer uma partida” então P (B | A1) =
0, 3; P (B | A2) = 0, 4; P (B | A3) = 0, 5. Usando o Teorema de Bayes, temos que

P (A1 | B) =

P (A1) P (B | A1)
P (A1) P (B | A1) + P (A2) P (B | A2) + P (A3) P (B | A3)

=

0, 5 · 0, 3
0, 5 · 0, 3 + 0, 25 · 0, 4 + 0, 25 · 0, 5

=

0, 15
0, 375

= 0, 4.

Ou seja, a probabilidade do jogador ter disputado uma partida contra o adversário do grupo 1,
dado que ele venceu a partida é de 40%.

Deﬁnição 1.2.7. Os eventos aleatórios A e B são independentes se

P (A ∩ B) = P (A) · P (B) .

Segue da deﬁnição de probabilidade condicional e de independência que se A e B
são independentes com P (B) > 0 então P (A | B) = P (A), isto é, a probabilidade de
A ocorrer não depende da ocorrência de B.

Eventos de probabilidade zero ou um são independentes de qualquer outro. De
fato, se P (A) = 0, então P (A ∩ B) = 0 pois A ∩ B ⊂ A e P (A) · P (B) = 0, logo A
e B são independentes ∀B ∈ A. Se P (B) = 1, então P (A ∩ B) = P (A − (A ∩ Bc)) =
P (A) − P (A ∩ Bc) e, como A ∩ Bc ⊂ Bc implica P (A ∩ Bc) ≤ P (Bc) = 0, temos
P (A ∩ Bc) = 0 e P (A ∩ B) = P (A) = P (A) · (B). Logo A e B são independentes
∀B ∈ A.

Proposição 1.2.8. O evento A é independente de si mesmo se, e só se, P (A) = 0 ou 1.

Demonstração. P (A) = P (A ∩ A) = P (A) · P (A) ⇔ P (A) = 0 ou 1.

Proposição 1.2.9. Se A e B são independentes, então A e Bc também são independentes, assim
como Ac e B e ainda Ac e Bc.

1.2. PROBABILIDADE CONDICIONAL E INDEPENDÊNCIA

9

Demonstração. Sejam A e B independentes. Então P (A ∩ Bc) = P (A − (A ∩ B)) =
P (A)−P (A ∩ B) = P (A)−P (A) P (B) = P (A) (1 − P (B)) = P (A)·P (Bc) . Análogo
para os demais casos.

Exemplo 1.2.10. Seja Ω = {1, 2, 3, 4, 5, 6} o espaço amostral ao jogar um dado uma vez e seja
A sua σ-álgebra das partes. Os eventos

A = {sair um número primo} e B = {sair um número par menor que 5}

são independentes, pois P (A) =

1
3
= P (A) · P (B) (uma vez que
(uma vez que 2, 4 são pares menores que 5) e P (A ∩ B) =
2 é o único primo par menor que 5). Por outro lado, o evento C = {sair um número par} não é

(uma vez que 2, 3, 5 são primos), P (B) =

1
6

3
6

2
6

1
2

=

=

independente de A, pois P (C) =

, P (A ∩ C) =

(cid:54)=

= P (A) · P (C).

1
2

1
6

1
2

·

1
2

A seguir, vamos generalizar o conceito de independência para mais eventos.

Deﬁnição 1.2.11. (a) Sejam I um conjunto de índices e Ai eventos aleatórios, com i ∈ I.
Dizemos que os Ai’s são independentes 2 a 2 se P (Ai ∩ Aj) = P (Ai) P (Aj) ∀i, j ∈ I,
i (cid:54)= j.

(b) Seja n ≥ 2 um inteiro. Dizemos que os eventos A1, . . . , An são coletivamente indepen-

dentes (ou simplesmente independentes) se

P (Ai1 ∩ Ai2 ∩ · · · ∩ Aim) = P (Ai1) P (Ai2) . . . P (Aim)

∀1 ≤ i1 < i2 < · · · < im ≤ n, ∀m = 2, 3, . . . , n.

(c) Dizemos que os eventos da família inﬁnita enumerável A1, A2, . . . são independentes se
∀n ≥ 2, A1, A2, . . . , An são independentes, isto é, se são independentes quando tomamos
apenas os n primeiros termos da sequência, para todo n.

(d) Seja I um conjunto (enumerável ou não) de índices com pelo menos dois elementos. Di-
zemos que os eventos Ai dessa família, com i ∈ I, são independentes se toda subfamília
ﬁnita deles é de eventos independentes, isto é, se Ai1, Ai2, Ai3, . . . , Aim são independentes
para todo subconjunto {i1, . . . , im} ⊂ I com pelo menos dois elementos.

É possível mostrar que independência 2 a 2 não implica independência coletiva (ver

[6, Exemplo 7]).

Proposição 1.2.12. Se os eventos Ai, i ∈ I, são independentes, então os eventos Bi, i ∈ I,
também são independentes para cada Bi ∈ {Ai, Ac

i }.

10

CAPÍTULO 1. PRELIMINARES SOBRE PROBABILIDADE

Não vamos demonstrar essa proposição, mas a prova pode ser encontrada em [6,
Proposição 1.7]. A ideia é passar para o caso ﬁnito e usar a mesma ideia da Proposição
1.2.9.

Capítulo 2

Distribuição de variáveis aleatórias

2.1 Variáveis aleatórias

De maneira informal, uma variável aleatória determina um característico numérico
do resultado de um experimento, isto é, é a função que “transfere” a ideia de que Ω é
um conjunto qualquer e passa a considerá-lo como um conjunto de números reais.

Observação: Por [X ≤ x] vamos entender o conjunto {ω ∈ Ω; X(ω) ≤ x}.

Deﬁnição 2.1.1. Uma variável aleatória X é uma função X : Ω → R tal que [X ≤ x] é
evento aleatório para todo x ∈ R, isto é, X é variável aleatória se [X ≤ x] ∈ A, ∀x ∈ R.

A seguir veremos alguns exemplos:

Exemplo 2.1.2. Ao lançar uma moeda n vezes e observar a sequência de caras (c) e coroas (k)
obtidas, os resultados possíveis são sequências de tamanho n de caras e coroas e podemos deﬁnir

Ω = {ω = (ω1, . . . , ωn) ; ωi ∈ {c, k}, i = 1, . . . , n}

e X (ω) = número de c(cid:48)s em ω = #{i : ωi = c, 1 ≤ i ≤ n}.

Com isso, o número de caras obtidas nos n lançamentos é um característico numérico da

sequência de caras e coroas.

Exemplo 2.1.3. Escolher um ponto ao acaso em [0, 1], ou seja, ω ∈ [0, 1]. Seja X o valor do
ponto escolhido. Então

Ω = [0, 1], X (ω) = ω.

Exemplo 2.1.4. Escolher um ponto ao acaso no quadrado unitário, ou seja, escolher um par
ordenado (x, y) ∈ [0, 1] × [0, 1]. Então Ω = [0, 1] × [0, 1] e sendo a variável aleatória X o valor
do produto das duas coordenadas, temos X (ω) = xy, para todo ω = (x, y) ∈ Ω.

11

12

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

Deﬁnição 2.1.5. Seja X uma variável aleatória. Deﬁnimos a função de distribuição como

FX(x) = P (X ≤ x), x ∈ R.

A função de distribuição descreve como probabilidades são associadas aos valores
ou aos intervalos de valores de uma variável aleatória. Ela representa a probabilidade
de uma variável aleatória ser menor ou igual a um valor real x. Desta forma, podemos
deﬁnir variáveis aleatórias através da sua função de distribuição.

Exemplo 2.1.6. Uma população de 1000 pessoas foi analisada num estudo para determinar
a efetividade de uma vacina contra a COVID-19. No estudo, as pessoas recebiam uma dose
da vacina e, após um mês, passavam por um novo teste. Caso ainda não tivessem completa-
mente imunizadas, recebiam outra dose da vacina. Ao ﬁm de 5 doses todas as pessoas foram
consideradas imunizadas. Os resultados completos estão na tabela a seguir.

Tabela 2.1: Imunização por doses

Doses Freq.
245
288
256
145
66

1
2
3
4
5

Suponha que uma pessoa dessa população é sorteada ao acaso. Qual será a probabilidade dela
ter ﬁcado imunizada ao receber até 2 doses? O que precisamos obter é a função de distribuição
no ponto 2, ou seja, calculamos a probabilidade acumulada de ocorrência de valores menores ou
iguais a 2. Assim,

F (2) = P (X ≤ 2) = P (X = 1) + P (X = 2) = 0, 245 + 0, 288 = 0, 533.

Logo, a probabilidade da pessoa sorteada ter ﬁcado imunizada com até duas doses é de 53, 3%.

Na sequência, vamos estudar propriedades da função de distribuição.

Proposição 2.1.7 (Propriedades). A função de distribuição F de uma variável aleatória X
tem três propriedades básicas:

F1. F é não decrescente.

F2. F é contínua à direita.

F3. 0 ≤ F (x) ≤ 1, limx→−∞ F (x) = 0 e limx→∞ F (x) = 1.

2.2. TIPOS DE VARIÁVEIS ALEATÓRIAS

13

Demonstração.

F 1. Se x ≤ y ⇒ [X ≤ x] ⊂ [X ≤ y] ⇒ F (x) = P (X ≤ x) ≤ P (X ≤ y) = F (y) .

F 2. Se xn ↓ x, então F (xn) ↓ F (x), isto é, [X ≤ xn] ↓ [X ≤ x] ⇒ F (xn) = P (X ≤ xn) ↓

P (X ≤ x) = F (x) .

F 3. Se x → −∞, então [X ≤ x] ↓ ∅, e assim F (x) = P (X ≤ x) ↓ 0. Se x → +∞, então

[X ≤ x] ↑ Ω, e assim F (x) = P (X ≤ x) ↑ 1.

Uma função de distribuição é monótona não-decrescente e portanto tem um nú-
mero ﬁnito ou enumerável de pontos de descontinuidade. Além disto, todas as des-
continuidades são do tipo salto. É possível provar que o tamanho do salto em certo
ponto x é igual a P (X = x). De fato,

P (X = x) = lim
n→∞

P

(cid:18)

x −

1
n

(cid:19)

< X ≤ x

= F (x) − F (cid:0)x−(cid:1) ,

onde x− denota o limite à esquerda. Daí segue que F é contínua em x se, e só se
P (X = x) = 0.

É possível provar usando conceitos da Teoria da Medida que toda função satisfa-
zendo F 1, F 2, F 3 é função de distribuição de alguma variável aleatória. Para saber
mais, veja [6, Seção 2.1].

Cada variável aleatória gera uma função de distribuição, mas uma função de distri-
buição pode corresponder a diversas variáveis aleatórias. Por exemplo, se X : Ω → R
é uma variável aleatória contínua cuja densidade é dada por uma função par então
FX = F−X, mas em geral X (cid:54)= −X.

2.2 Tipos de variáveis aleatórias

Deﬁnição 2.2.1 (Variável aleatória discreta). Seja X uma variável aleatória. Se o número
de valores possíveis de X for enumerável (ﬁnito ou inﬁnito), dizemos que X é uma variável
aleatória discreta. A função p (xi) = P (X = xi), i = 1, 2, . . . , é chamada função de proba-
bilidade da variável aleatória X e satisfaz as seguintes condições:

1. p (xi) ≥ 0 para todo i;

2.

∞
(cid:80)
i=1

p (xi) = 1.

Exemplo 2.2.2. Considere que uma moeda é lançada duas vezes, sendo que os possíveis resulta-
dos para cada lançamento são cara (c) e coroa (k), assim Ω = {cc, ck, kc, kk}. Seja X a variável

14

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

aleatória deﬁnida no espaço amostral que é igual ao número de coroas nos dois lançamentos. A
variável X é discreta e sua distribuição de probabilidade será dada por

p (0) = P (X = 0) = P ({cc}) =

1
4

,

p (1) = P (X = 1) = P ({ck}) + P ({kc}) =

p (2) = P (X = 2) = P ({kk}) =

1
4

,

1
4

+

1
4

=

1
2

,

que satisfaz as condições da Deﬁnição 2.2.1.

Deﬁnição 2.2.3 (Variável aleatória contínua). Dizemos que X é uma variável aleatória con-
tínua se existe uma função f : R → [0, ∞) denominada função de densidade de X tal
que

(cid:90) x

FX (x) =

f (t) dt,

∀x ∈ R.

Dessa forma, para quaisquer a, b ∈ R, com a < b temos

−∞

P (a < X ≤ b) = FX(b) − FX(a) =

(cid:90) b

a

f (t) dt.

Com isso, concluímos que quando X é uma variável aleatória contínua, a proba-
bilidade de ocorrer um valor especíﬁco é zero, pois P (X = a) = (cid:82) a
a f (x) dx = 0. Pelo
Teorema Fundamental do Cálculo, temos F (cid:48)
X (x) = f (x) para todo x. Além disso,
(cid:82) ∞
−∞ f (x)dx = 1, pela deﬁnição e pela propriedade F 3. Reciprocamente, uma função
g (x) ≥ 0 é densidade de alguma variável aleatória se, e só se, (cid:82) ∞
−∞ g (x) dx = 1, já que
neste caso, a função F deﬁnida por

F (x) =

(cid:90) x

−∞

g (t) dt

é função de distribuição, pois satisfaz F 1, F 2 e F 3.

Exemplo 2.2.4. Vamos escolher ao acaso um número no intervalo [0, 1]. A probabilidade de
ser o número 0, 27 é zero, pois como visto acima, todo ponto isolado em uma variável aleatória
contínua tem probabilidade zero. Pela aditividade, a probabilidade de qualquer conjunto enu-
merável também é 0. Em particular, a probabilidade de escolher os racionais (que é enumerável)
é 0.

Exemplo 2.2.5. Seja A = {x : −2 < x < 3} e seja X uma variável aleatória tal que sua
função densidade de probabilidade seja f (x) deﬁnida abaixo, com k sendo uma constante. Qual

2.2. TIPOS DE VARIÁVEIS ALEATÓRIAS

15

deve ser o valor da constante k?

f (x) =




k, x ∈ A;



0, x /∈ A.

Como f é uma função densidade de probabilidade ela deve satisfazer a condição que

(cid:90) ∞

−∞

f (x) dx = 1 ⇒

(cid:90) 3

−2

kdx = k · (3 − (−2)) = 5k = 1 ⇒ k =

1
5

.

Exemplo 2.2.6. Seja FX (x) =





0, x < 0,

x,

0 ≤ x ≤ 1,

1, x > 1.

Como FX é contínua, X tem densidade que é dada por f (x) = F (cid:48)

X (x) =




1, x ∈ (0, 1)



0, x /∈ [0, 1].

Proposição 2.2.7. Se X é variável aleatória em (Ω, A, P), então o evento

[X ∈ B] = {ω ∈ Ω : X (ω) ∈ B}

é evento aleatório para todo boreliano B, isto é,

[X ∈ B] ∈ A, ∀B ∈ B = σ-álgebra de Borel.

Demonstração. A prova se dá utilizando a Teoria da Medida, mas podemos intuitiva-
mente justiﬁcar a proposição: recordemos que a σ-álgebra B, dos borelianos, é a menor
σ-álgebra contendo os intervalos. Vamos, então, veriﬁcar a conclusão da proposição
para um intervalo B:

(i) Se B = (−∞, b], então [X ∈ B] ∈ A pela Deﬁnição 2.1.1.

(ii) Se B = (a, ∞), então B = (−∞, a]c e [X ∈ B] = [X ≤ a]c ∈ A, por (i). Neste caso,

P (X ∈ B) = P (X > a) = 1 − P (X ≤ a) = 1 − FX (a) .

(iii) Se B = (a, b], então [X ∈ B] = [a < X ≤ b] = [X ≤ b] − [X ≤ a] ∈ A, por (i).

P (X ∈ B) = P (X ≤ b) − P (X ≤ a) = FX (b) − FX (a) .

(iv) Se B = (a, b), então B =

Neste caso, P (X ∈ B) = lim
n→∞
FX (b−) − FX (a) .

∞
(cid:83)
n=1

(a, b− 1

n] e [X ∈ B] =
P(a < X ≤ b − 1

∞
(cid:83)
n=1
n ] = lim
n→∞

(a < X ≤ b− 1
(cid:0)b − 1

[FX

n

n] ∈ A, por (iii).
(cid:1) − FX (a)] =

16

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

Analogamente, podemos veriﬁcar que para todo intervalo B, [X ∈ B] ∈ A e P (X ∈ B)

é determinada pela função de distribuição FX. O mesmo resultado vale se B =

Bi,

n
(cid:83)
i=1

onde os Bi são intervalos disjuntos, uma vez que [X ∈ B] =

n
(cid:80)
i=1

P (X ∈ Bi) .

n
(cid:83)
i=1

[X ∈ Bi] e P (X ∈ B) =

Com isso, a proposição vale para uniões ﬁnitas de intervalos, portanto, usando o
Teorema de Extensão de Caratheodory [2, Capítulo 9], o resultado vale na σ-álgebra
B.

Teoricamente, para veriﬁcar se certa propriedade é válida para todo boreliano, é
suﬁciente veriﬁcar se é válida para toda união ﬁnita de intervalos e, se vale para Bn,
para todo n, e Bn ↓ B ou Bn ↑ B, então vale para B, ou seja, se continua válida
também para limites monótonos. Enfatizamos outra implicação desta demonstração:
as probabilidades P (X ∈ B) são determinadas pela função de distribuição FX.

Deﬁnição 2.2.8. A probabilidade PX, deﬁnida na σ-álgebra de Borel por PX (B) = P (X ∈ B),
é chamada distribuição de X.

Nos casos discreto e contínuo, podemos descrever a distribuição por meio da fun-

ção de probabilidade ou densidade, como veremos na próxima seção.

2.3 Principais modelos de distribuição

Nesta seção, vamos introduzir os principais modelos de distribuição, tanto no caso
discreto quanto no caso contínuo. Existem vários outros modelos que não serão trata-
dos aqui mas que também são tão importantes quanto os apresentados a seguir, como
o de Poisson, o modelo exponencial, o modelo gama, etc.

Deﬁnição 2.3.1 (Modelo Uniforme Discreto). Seja X uma variável aleatória discreta, cujos
possíveis valores são representados somente por x1, x2, . . . . Dizemos que X segue o modelo
Uniforme Discreto se atribui a mesma probabilidade a cada um desses valores, isto é,

P (X = xi) = P (X = xj) ou p (xi) = p (xj) para todo i, j.

Aqui, vale a pena ressaltar que {x1, x2, . . . } deve ser ﬁnito, não pode ser inﬁnito
enumerável. De fato, se fosse, teríamos 1 = P (Ω) = (cid:80) p (x1) . Mas essa última soma é
0 se p (x1) = 0 e é ∞ se p (x1) > 0, o que é um absurdo. Dessa forma, seja n o número

de elementos em tal conjunto ﬁnto. Temos PX (B) =

para todo B ∈ A.

Usaremos a notação X ∼ U {x1, . . . , xn} para indicar que X possui distribuição

|B|
n

Uniforme Discreto entre os n valores.

2.3. PRINCIPAIS MODELOS DE DISTRIBUIÇÃO

17

Deﬁnição 2.3.2 (Modelo Uniforme Contínuo). Uma variável aleatória X tem distribuição
Uniforme Contínua no intervalo B = [a, b], a < b, se sua função densidade de probabilidade
é dada por:

f (x) =




, a ≤ x ≤ b;

1
b − a
0, caso contrário.

Assim, a probabilidade de B é dada por



PX (B) =

(cid:90)

B

f (x) dx,

∀B ∈ B.

Usaremos a notação X ∼ U [a, b] para indicar que X possui distribuição Uniforme Contínua
no intervalo dado.

Deﬁnição 2.3.3 (Modelo Normal). Dizemos que uma variável aleatória contínua X tem
distribuição Normal com parâmetros µ e σ2 se sua função densidade é dada por

f (x) =

1
√
2π

σ

e− (x−µ)2

2σ2

, para − ∞ < x < ∞.

Posteriormente, vamos mostrar que µ é a média (ou esperança) de X e σ2 é a variância de
X. Para saber o valor da probabilidade de X estar em um intervalo [a, b], devemos resolver a
integral da função densidade em tal intervalo, ou seja,

P (a ≤ X ≤ b) =

(cid:90) b

σ

a

1
√
2π

e− (x−µ)2

2σ2 dx.

Notemos que essa integral é da forma (cid:82) β
α e−y2dy, que não possui primitiva em termos de funções
elementares. Mas ainda assim podemos mostrar que, no caso da integral deﬁnida em R, temos
P(−∞ < X < ∞) = 1 (ver Apêndice B). Para outros intervalos podemos usar métodos
numéricos e obter aproximações.

Usaremos a notação X ∼ N (µ, σ2) para indicar que X tem distribuição Normal com parâ-

metros µ e σ2.

Deﬁnição 2.3.4 (Modelo binomial). Dizemos que X tem distribuição binomial com parâ-
metros n e p, onde n é um inteiro positivo e 0 < p < 1, se

p (k) = P (X = k) =

(cid:33)

(cid:32)

n
k

pk (1 − p)n−k ,

k = 0, 1, . . . , n.

Notação: X ∼ b (n, p) .

Esta é a distribuição que atribuímos, por exemplo, ao número de caras obtidas em

18

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

n lançamentos de uma moeda tendo probabilidade p de dar cara.

Deﬁnição 2.3.5. Chamamos de ensaios de Bernoulli com parâmetro p os ensaios binomiais
cuja probabilidade de sucesso é a mesma p para todo ensaio.

Deﬁnição 2.3.6 (Modelo geométrico). Dizemos que X tem distribuição geométrica com
parâmetro p se sua função de probabilidade é dada por

p (k) = (1 − p)k−1 p,

k = 1, 2, . . . .

Notação: X ∼ geom (p) .

A distribuição geométrica indica a probabilidade de obter o primeiro sucesso em
uma sequência de ensaios de Bernoulli com probabilidade p de sucesso exatamente no
k-ésimo ensaio.

2.4 Vetores aleatórios

Deﬁnição 2.4.1. (a) Denomina-se vetor aleatório (ou variável aleatória n-dimensional), um
vetor ˜X = (X1, X2, . . . , Xn) cujas componentes são variáveis aleatórias deﬁnidas no mesmo
espaço de probabilidade (Ω, A, P) .

(b) A função de distribuição F = F ˜X = FX1,...,Xn de um vetor aleatório ˜X = (X1, . . . , Xn)

é dada por:

F (˜x) = F (x1, . . . , xn) = P (X1 ≤ x1, . . . , Xn ≤ xn) , ∀˜x = (x1, . . . , xn) ∈ Rn.

F é também chamada função de distribuição conjunta das variáveis aleatórias X1, . . . , Xn.

Quanto a função de distribuição de um vetor aleatório, podemos traçar proprieda-

des análogas àquelas da Proposição 2.1.7.

Proposição 2.4.2. Seja F a função de distribuição de um vetor aleatório (X1, . . . , Xn) . São
válidos:

F1. F (x1, . . . , xn) é não-decrescente em cada uma das variáveis.

F2. F (x1, . . . , xn) é contínua a direita em cada uma das variáveis.

F3. Para todo i,

lim
xi→−∞

F (x1, . . . , xi, . . . , xn) = 0 e

lim
xi→+∞

F (x1, . . . , xi, . . . , xn) = 1.

Dado um intervalo (a, b] e g : Rk → R uma função qualquer, o operador diferença é deﬁnido
por

∆a,bg (x1, . . . , xn) = g (x1, . . . , xn−1, b) − g (x1, . . . , xn−1, a) .

2.5. INDEPENDÊNCIA DE VARIÁVEIS ALEATÓRIAS

19

F4. ∆a1,b1, . . . , ∆an,bnF (x1, . . . , xn) ≥ 0, ∀ (ak, bk], ak < bk, k = 1, . . . , n.

Essa quarta propriedade é de fundamental importância, pois sem ela podemos en-
contrar uma função que satisfaz F 1, F 2 e F 3 porém apresenta probabilidade negativa
(ver [6, Exemplo 14]), não sendo portanto, uma função de distribuição de nenhum ve-
tor aleatório. Essa propriedade vale para cada componente do vetor. Por outro lado,
pode-se veriﬁcar (ver [4, parágrafo 2.5] ) que uma função que satisfaz as propriedades
F 1, F 2, F 3 e F 4 é uma função de distribuição de um vetor aleatório.

Deﬁnição 2.4.3. A probabilidade deﬁnida em Bn por P
˜X ou distribuição conjunta de X1, · · · , Xn.

Notação. P ˜X (B) = P

(cid:16) ˜X ∈ B

(cid:17)

, P ˜X é a distribuição de ˜X.

(cid:16) ˜X ∈ B

(cid:17)

é chamada distribuição de

Proposição 2.4.4. (a) Se o vetor aleatório ˜X é discreto, então

P ˜X (B) =

(cid:88)

(cid:16) ˜X = ˜xi

(cid:17)

P

, ∀B ∈ Bn.

i:xi∈B

(b) Se ˜X é contínuo com densidade f (x1, . . . , xn), então

P ˜X (B) = P

(cid:16) ˜X ∈ B

(cid:17)

=

(cid:90)

(cid:90)

· · ·

B

f (x1, . . . , xn) dx1 . . . dxn.

2.5

Independência de variáveis aleatórias

Vamos lembrar da Deﬁnição 1.2.11, que é equivalente à deﬁnição a seguir:

Deﬁnição 2.5.1. As variáveis aleatórias X1, . . . , Xn são (coletivamente) independentes se

P (X1 ∈ B1, X2 ∈ B2, . . . , Xn ∈ Bn) =

n
(cid:89)

i=1

P (Xi ∈ Bi) , ∀Bi ∈ B, i = 1, . . . , n.

A seguir, vamos obter critérios de independência em geral e um especíﬁco para o

caso contínuo.

Proposição 2.5.2 (Critério de independência). (a) Se X1, . . . , Xn são independentes, então

FX1,...,Xn (x1, . . . , xn) =

n
(cid:89)

i=1

FXi (xi) , ∀ (x1, . . . , xn) ∈ Rn.

(b) Por outro lado, se existem funções F1, . . . , Fn tais que

lim
xi→+∞

Fi (xi) = 1, ∀i

20

e

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

FX1,...,Xn (x1, . . . , xn) =

n
(cid:89)

i=1

Fi (xi) , ∀ (x1, . . . , xn) ∈ Rn,

então X1, . . . , Xn são independentes e Fi = FXi, ∀i = 1, . . . , n.

Demonstração. (a) Supondo X1, . . . , Xn independentes. Então

FX1,...,Xn (x1, . . . , xn) = P (X1 ≤ x1, . . . , Xn ≤ xn)

= P (X1 ∈ (−∞, x1], . . . , Xn ∈ (−∞, xn])

=

n
(cid:89)

i=1

P (Xi ∈ (−∞, xi]) =

n
(cid:89)

i=1

P (Xi ≤ xi) =

n
(cid:89)

i=1

FXi (xi) , ∀ (x1, . . . , xn) .

(b) A prova pode ser encontrada em [6, Proposição 2.4.b].

Proposição 2.5.3 (Critério para independência no caso contínuo). (a) Se X1, . . . , Xn são

independentes e possuem densidades fX1, . . . , fXn, então a função

f (x1, . . . , xn) =

n
(cid:89)

i=1

fXi (xi) , (x1, . . . , xn) ∈ Rn,

é densidade conjunta das variáveis aleatórias X1, . . . , Xn, isto é, f = fX1,··· ,Xn.

(b) Por outro lado, se X1, . . . , Xn têm densidade conjunta f satisfazendo

f (x1, . . . , xn) =

n
(cid:89)

i=1

fi (xi) , ∀ (xi, . . . , xn) ∈ Rn,

onde fi (x) ≥ 0 e (cid:82) ∞
densidade de Xi, para i = 1, . . . , n.

−∞ fi (x) dx = 1, ∀i, então X1, . . . , Xn são independentes e fi é a

Demonstração. (a) Se X1, . . . , Xn são independentes, então

FX1,...,Xn (x1, . . . , xn) =

n
(cid:89)

FXi (xi) =

n
(cid:89)

(cid:90) xi

i=1

−∞

fXi (ti) dti

i=1
(cid:90) xn

=

(cid:90) x1

· · ·

−∞

−∞

fX1 (t1) . . . fXn (tn) dt1 . . . dtn.

Logo (cid:81)n

i=1 fXi é densidade conjunta de X1, . . . , Xn.

2.5. INDEPENDÊNCIA DE VARIÁVEIS ALEATÓRIAS

21

(b)

FX1,...,Xn (x1, . . . , xn) =

=

=

(cid:90) xn

−∞
(cid:90) xn

· · ·

· · ·

−∞
n
(cid:89)

(cid:90) xi

(cid:90) x1

−∞
(cid:90) x1

−∞

f (t1, . . . , tn) dt1 . . . dtn

f1 (t1) . . . fn (tn) dt1 . . . dtn

fi (ti) dti.

i=1

−∞

Deﬁnindo Fi (xi) = (cid:82) xi

−∞ fi (ti) dti, temos, por hipótese,

lim
xi→+∞

Fi (xi) = 1.

A Proposição 2.5.2(b) implica que X1, . . . , Xn são independentes e Fi = Fxi, logo fi
é densidade de Xi.

22

CAPÍTULO 2. DISTRIBUIÇÃO DE VARIÁVEIS ALEATÓRIAS

Capítulo 3

Esperança e Variância de variáveis
aleatórias

3.1 Esperança e suas propriedades

Deﬁnição 3.1.1. Seja X uma variável aleatória discreta, cujos valores possíveis são x1, x2, x3, . . .
e com função de probabilidade dada por p(xi). A esperança de X é deﬁnida por

E(X) =

(cid:88)

i

xip(xi) =

(cid:88)

i

xiP(X = xi).

Este valor está bem deﬁnido quando a soma não depende da ordem dos termos,
|xi|p(xi) < ∞, isto é, quando a série converge absolutamente.

em particular quando (cid:80)
A esperança de X também é chamada de média de X, ou valor esperado de X, ou expec-
tância de X. De fato, E(X) é uma média ponderada, onde os pesos são as probabilidades
p(xi), isto é, E(X) é uma média dos valores possíveis de X, ponderada conforme a
distribuição de X.

i

Intuitivamente, uma explicação desta deﬁnição se encontra na interpretação de pro-
babilidade como limite de frequências relativas, ou seja, interpretando novamente X
como um característico numérico do resultado de um experimento, e admitindo que
vamos repetir o experimento n vezes, independentemente, e observar os valores desse
característico numérico. Nesses n experimentos, se n é grande, as observações toma-
rão o valor xi com frequência relativa de aproximadamente p(xi), ∀i, isto é, xi aparecerá
mais ou menos np(xi) vezes nas n observações. Portanto, o valor médio observado nes-
ses n ensaios do experimento, isto é, a média aritmética dos n valores observados, será

23

24

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

aproximadamente igual a

[xi · np(xi)]

(cid:80)
i

n

(cid:88)

=

xip(xi).

i

Este valor será o limite quando n → ∞, isto é, o valor médio obtido em n ensaios
do experimento convergirá para E(X) quando n → ∞. Logo, podemos dizer que
“esperamos” obter a longo prazo um valor médio E(X).

Vamos apresentar através de exemplos, os cálculos da esperança de alguns dos mo-

delos teóricos discretos que foram deﬁnidos na Seção 2.3 do capítulo anterior.

Exemplo 3.1.2. Considere a variável aleatória X com modelo Uniforme Discreto (ver Deﬁnição
2.3.1) entre os valores 1 e n. Aplicando a deﬁnição de esperança matemática e a expressão para
a soma dos termos de uma progressão aritmética temos

E(X) =

n
(cid:88)

i=1

xiP(X = xi) =

n
(cid:88)

i=1

xi ·

1
n

=

1
n

n
(cid:88)

i=1

xi =

n + 1
2

.

Em particular, a esperança ao jogar um dado honesto é

(1 + 2 + 3 + 4 + 5 + 6)
6

= 3, 5.

Exemplo 3.1.3. Seja X a variável aleatória com distribuição Binomial de parâmetros n e p,
conforme Deﬁnição 2.3.4. Temos

E(X) =

=

=

n
(cid:88)

k=0
n
(cid:88)

k=1
n
(cid:88)

k=1

kP(X = k)

k

n!
(n − k)!k!

pk(1 − p)n−k

n!
(n − k)!(k − 1)!

pk(1 − p)n−k

= np

n
(cid:88)

k=1

(n − 1)!
(n − k)!(k − 1)!

pk−1(1 − p)n−k.

Substituindo nesta última expressão, k − 1 por j, obtemos

E(X) = np

(cid:32)

n−1
(cid:88)

j=0

(cid:33)

n − 1
j

pj(1 − p)n−1−j = np,

uma vez que a somatória é igual a 1, pois corresponde a somar todas as probabilidades de uma
variável Binomial com parâmetros n − 1 e p.

3.1. ESPERANÇA E SUAS PROPRIEDADES

25

Exemplo 3.1.4. Lembrando que chamamos de ensaios de Bernoulli, os ensaios Binomiais cuja
probabilidade de sucesso é a mesma p para todo o ensaio. Então para uma variável aleatória X
com distribuição Bernoulli de parâmetro p, temos

E(X) = 0 × (1 − p) + 1 × p = p.

Em particular, no caso de uma moeda honesta, se X denota a variável aleatória satisfazendo

X(c) = 0 e X(k) = 1, temos E(X) =

1
2

.

Na sequência vamos deﬁnir esperança para o caso contínuo.

Deﬁnição 3.1.5. Seja X uma variável aleatória qualquer e F sua função de distribuição. A
esperança de X é deﬁnida por

(cid:90) ∞

E(X) =

xdF (x),

quando a integral imprópria de Riemann-Stieltjes está bem deﬁnida. Se X tem densidade f ,
então a integral acima pode ser reescrita, pelo item 7 do Apêndice A, como

−∞

E(X) =

(cid:90) ∞

−∞

xf (x)dx.

Se a densidade f for integrável a Riemann então esta última integral também será
de Riemann [10, Teorema 6.17]. Em outras palavras, podemos continuar a trabalhar
com a integral de Riemann no caso contínuo.
No caso discreto, já vimos que E(X) = (cid:80)

xip(xi). Pelo item 6 do Apêndice A, esta

deﬁnição concorda com a Deﬁnição 3.1.5.

i

Vamos agora, apresentar através de exemplos, os cálculos da esperança de alguns

dos modelos contínuos que foram deﬁnidos anteriormente.

Exemplo 3.1.6. Sendo X uma variável aleatória com distribuição uniforme no intervalo [a, b],

para a ≤ x ≤ b e f (x) = 0 em caso contrário. A

ou seja, X ∼ U [a, b], então f (x) =
esperança de X ﬁca dada por

1
b − a

E(X) =

(cid:90) b

a

x

1
b − a

dx =

1
b − a

·

x2
2

(cid:12)
(cid:12)
(cid:12)

b

a

=

b2 − a2
2(b − a)

=

a + b
2

.

Exemplo 3.1.7. Seja X uma variável aleatória com distribuição normal com parâmetros µ e
σ2. A esperança de X é dada por

E(X) =

(cid:90) ∞

−∞

x

1
√
2π

σ

e

−(x−µ)2

2σ2 dx.

26

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

Fazendo a mudança de variáveis y =

x − µ
√
2
σ

, dy =

1
√

2

σ

dx, temos

E(X) =

=

(cid:90) ∞

−∞
(cid:90) ∞

√

2 + µ)

√

2 + µ)

(yσ

(yσ

e−y2σ

√

2dy

1
√
2π

σ
1
√
π

e−y2dy

−∞

(cid:114) 2
π

= σ

(cid:90) ∞

−∞

ye−y2dy +

µ
√
π

(cid:90) ∞

−∞

e−y2dy.

A primeira integral da linha anterior vale 0 pois é uma integral de função ímpar sobre um
intervalo simétrico. A segunda integral vale

π pelo Apêndice B. Logo, E(X) = µ.

√

Deﬁnição 3.1.8. Se E(X) é ﬁnita, dizemos que X é integrável.

Observações.

(A) Nesse texto, além das esperanças ﬁnitas, vamos admitir a existência de esperanças
inﬁnitas, desde que seu valor seja “bem comportado”, isto é, tome o valor +∞ ou
−∞.

(B) A esperança está bem deﬁnida se (cid:82) ∞

0 xdF (x) ou (cid:82) 0

−∞ xdF (x) for ﬁnita. De fato,

sendo

(cid:90) ∞

−∞

(cid:90) 0

xdFX(x) =

xdFX(x)

+

(cid:90) ∞

−∞

(cid:124)

(cid:123)(cid:122)
I

0

(cid:124)

(cid:125)

xdFX(x)
,

(cid:123)(cid:122)
II

(cid:125)

temos I ≤ 0, II ≥ 0 e

(i) se I e II são ﬁnitas, então E(X) = I + II, ou seja, X é integrável,

(ii) se I é ﬁnita e II = +∞, então E(X) = +∞,

(iii) se I = −∞ e II é ﬁnita, então E(X) = −∞,

(iv) se I = −∞ e II = +∞, então E(X) não está deﬁnida.

Dessa forma, X é integrável se, e só se, (cid:82) ∞

−∞ |x|dFX(x) < ∞. Mais adiante veremos

que essa última integral vale E|X|.
Proposição 3.1.9. E(X) = (cid:82) ∞
Demonstração. Vamos provar que (cid:82) ∞
mente análoga, é possível mostrar que (cid:82) 0
gração por partes com u = x e dv = dF (x), temos du = dx e v = F (x), logo

0 (1 − F (x))dx − (cid:82) 0

−∞ xdF (x) = − (cid:82) 0

0 xdF (x) = (cid:82) ∞

−∞ F (x)dx.

0 (1 − F (x))dx. De forma completa-
−∞ F (x)dx. Fazendo a inte-

∀b > 0,

(cid:90) b

0

xdF (x) = [xF (x)]b

0 −

(cid:90) b

0

F (x)dx = bF (b) −

(cid:90) b

0

F (x)dx =

(cid:90) b

0

[F (b) − F (x)]dx.

3.1. ESPERANÇA E SUAS PROPRIEDADES

27

A ideia agora é fazer b → ∞ e passar o limite para dentro da integral, obtendo F (b) →
1. Feito isso, obtemos o resultado desejado. Como F (b) ≤ 1 e 1 − F (x) ≥ 0, temos

(cid:90) b

0

[F (b) − F (x)]dx ≤

(cid:90) ∞

0

[1 − F (x)]dx, ∀b > 0,

de modo que

(cid:90) b

0

lim
b→∞

xdF (x) ≤

(cid:90) ∞

0

[1 − F (x)]dx.

Por outro lado, seja λ > 0. Se b > λ, então

(cid:90) ∞

0

[F (b) − F (x)]dx ≥

=

(cid:90) λ

0
(cid:90) λ

0

[F (b) − F (x)]dx

[F (b) − 1]dx +

(cid:90) λ

0

[1 − F (x)]dx

= λ[F (b) − 1] +

(cid:90) λ

0

[1 − F (x)]dx,

e portanto

(cid:90) b

0

lim
b→∞

[F (b) − F (x)]dx ≥

(cid:90) λ

0

[1 − F (x)]dx + lim
b→∞

λ[F (b) − 1] =

(cid:90) λ

0

[1 − F (x)]dx.

Já que isto vale para todo λ > 0, temos

(cid:90) ∞

0

xdF (x) ≥ lim
λ→∞

(cid:90) λ

0

[1 − F (x)]dx =

(cid:90) ∞

0

[1 − F (x)]dx.

Corolário 3.1.10. Se X tomar somente valores não-negativos, ou seja, X(ω) ≥ 0, ∀ω ∈ Ω,
então FX(x) = 0 para x < 0 e

E(X) =

(cid:90) ∞

0

[1 − FX(x)]dx =

(cid:90) ∞

0

P(X > x)dx.

Demonstração. A prova é imediata, pois 1 − FX(x) = P(X > x).

Corolário 3.1.11. Se a variável aleatória X assumir somente valores inteiros não-negativos,
então

∞
(cid:88)

∞
(cid:88)

E(X) =

P(X > n) =

P(X ≥ n).

n=0

n=1

28

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

Demonstração. Pela proposição temos

E(X) = 1 − F (0) + 1 − F (1) + 1 − F (2) + · · · =

∞
(cid:88)

[1 − F (n)] =

n=0

∞
(cid:88)

n=0

P[X > n].

Como X assume apenas valores inteiros, temos

P(X > n) = P(X ≥ n + 1),

logo

∞
(cid:88)

n=0

P(X > n) =

∞
(cid:88)

n=0

P(X ≥ n + 1) =

∞
(cid:88)

n=1

P(X ≥ n).

Corolário 3.1.12. Seja A ∈ A e seja

IA(Ω) =




1



0

se ω ∈ A,

se ω /∈ A,

a função indicadora do evento A. Então E(IA) = P(A).

Demonstração. Pelo corolário anterior e, como IA só assume os valores 0 e 1, segue que

E(IA) =

∞
(cid:88)

n=0

P(IA > n) = P(IA > 0) = P(IA = 1) = P(A).

Exemplo 3.1.13. Seja X o número de lançamentos necessários até obter a primeira cara ao se
lançar uma moeda independentemente várias vezes e p a probabilidade de obter cara em um dado
lançamento. Então X toma apenas os valores 1, 2, 3, . . . e P(X ≥ n) é a probabilidade de não
obter cara nos lançamentos 1, 2, . . . , n − 1, isto é, a probabilidade de sair coroa nos lançamentos
1 até n − 1, que vale (1 − p)n−1. Logo

E(X) =

∞
(cid:88)

n=1

P(X ≥ n) =

∞
(cid:88)

n=1

(1 − p)n−1 =

∞
(cid:88)

(1 − p)n =

n=0

1
1 − (1 − p)

=

1
p

.

Portanto, vemos que a esperança do tempo de espera até o primeiro sucesso em uma sequência

de ensaios de Bernoulli (ou seja, a esperança do modelo geométrico) é

, onde p é a probabilidade

1
p

de sucesso em cada ensaio. Para uma moeda honesta, essa esperança vale 2.

3.1. ESPERANÇA E SUAS PROPRIEDADES

29

Como |X| ≥ 0, o Corolário 3.1.10 implica que

E|X| =

=

(cid:90) ∞

0
(cid:90) ∞

0

P(|X| > x)dx =

(cid:90) ∞

0

[P(X > x) + P(X < −x)]dx

[1 − FX(x) + FX((−x)−)]dx.

Vale lembrar que FX((−x)−) é o limite da função FX(y) quando y ↑ (−x). Logo,
FX((−x)−) = FX(−x) quando −x é o ponto de continuidade de FX. Por isso, FX((−x)−)
e FX(−x) são funções monótonas (decrescentes em x) iguais, exceto em um número ﬁ-
nito ou enumerável de pontos. Com isso concluímos que

(cid:90) ∞

0

FX((−x)−)dx =

(cid:90) ∞

0

FX(−x)dx =

(cid:90) 0

−∞

FX(x)dx.

Resumindo, temos

E|X| =

(cid:90) ∞

0

[1 − FX(x)]dx +

(cid:90) 0

−∞

FX(x)dx.

Então, pela prova da Proposição 3.1.9,

E|X| =

=

(cid:90) ∞

0
(cid:90) ∞

0

xdFX(x) −

(cid:90) 0

xdFX(x)

|x|dFX(x) −

−∞
(cid:90) 0

−∞

|x|dFX(x) =

(cid:90) ∞

−∞

|x|dFX(x).

(3.1)

Assim provamos que E|X| = (cid:82) ∞

−∞ |x|dFX(x), e que X é integrável se, e somente se,

E|X| < ∞.

Proposição 3.1.14 (Propriedades da Esperança). Sejam X, Y variáveis aleatórias e a, b
números reais. São válidos:

E1. Se X = c, ou seja, X(ω) = c ∀ω ∈ Ω, então E(X) = c.

E2. Se X ≤ Y então E(X) ≤ E(Y ), se as esperanças estão bem deﬁnidas.

E3. Linearidade.

E3.i. Se E(X) está bem deﬁnida, então E(aX + b) = aE(X) + b para todo a, b ∈ R.

Aqui estamos convencionando que 0 · ∞ = 0.

E3.ii. E(aX + bY ) = aE(X) + bE(Y ), quando o termo à direita da igualdade tem

sentido, isto é, não temos um caso +∞ − ∞.

30

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

E4. Desigualdade de Jensen. Seja ϕ uma função convexa deﬁnida na reta, isto é, uma função
que satisfaz tϕ(a) + (1 − t)ϕ(b) ≥ ϕ(at + (1 − t)b). Se a variável aleatória X é integrável,
então

Eϕ(X) ≥ ϕ(E(X)).

Escreve-se: Eϕ(X) = E(ϕ(X)).

Demonstração. E1. Como X é uma variável aleatória discreta, então

E(X) = cP(X = c) = c · 1 = c.

E2. Se X ≤ Y , então Y ≤ z implica X ≤ z, logo [Y ≤ z] ⊂ [X ≤ z]. Portanto,

FY (z) ≤ FX(z) e 1 − FY (z) ≥ 1 − FX(z). Pela Proprosição 3.1.9,

E(Y ) =

(cid:90) ∞

0

(1−FY (z))dz−

(cid:90) 0

−∞

FY (z)dz ≥

(cid:90) ∞

0

(1−FX(z))dz−

(cid:90) 0

−∞

FX(z)dz = E(X).

E3. i. Se a = 0, então E(aX + b) = E(b) = b = aE(X) + b. Se a > 0, então

FaX+b(x) = P(aX + b ≤ x) = P

X ≤

(cid:18)

(cid:19)

x − b
a

= FX

(cid:18) x − b
a

(cid:19)

,

logo tomando y =

x − b
a

obtemos

E(aX + b) =

(cid:90) ∞

(1 − FaX+b(x))dx −

(cid:90) 0

FaX+b(x)dx

0
(cid:90) ∞

(cid:18)

=

1 − FX

(cid:19)(cid:19)

(cid:18) x − b
a

−∞

dx −

(cid:90) 0

−∞

FX

(cid:19)

(cid:18) x − b
a

dx

(1 − FX(y))dy − a

(cid:90) −b/a

−∞

FX(y)dy

(1 − FX(y))dy − a

(cid:90) 0

−∞

FX(y)dy + a

(cid:90) 0

−b/a

(1 − FX(y))dy

0
(cid:90) ∞

−b/a
(cid:90) ∞

= a

= a

+ a

0
(cid:90) 0

−b/a

FX(y)dy

= aE(X) + a

(cid:90) 0

−b/a

dy = aE(X) + b.

Analogamente, temos o caso a < 0, e E3. i. está provado. Para E3. ii., resta provar
E(X + Y ) = E(X) + E(Y ) se o termo à direita está bem deﬁnido. Veremos mais
tarde quando considerarmos esperanças de funções de vetores aleatórios.

3.1. ESPERANÇA E SUAS PROPRIEDADES

31

E4. Dado x0 e o ponto ϕ(x0) do gráﬁco de ϕ, pela convexidade, a reta L tangente ao
gráﬁco no ponto (x0, ϕ(x0)) ﬁca abaixo da curva ϕ, como na ﬁgura a seguir.

Figura 3.1: Gráﬁco de uma função convexa

Seja λ de forma que y − ϕ(x0) = λ(x − x0) é a equação desta reta L. Então

ϕ(x) ≥ L(x) = ϕ(x0) + λ(x − x0), ∀x.

Portanto, pelas propriedades anteriores, segue que

E(ϕ(X)) ≥ E(L(X)) = ϕ(x0) + λ(E(X) − x0).

Tomando-se E(X) = x0, vem E(ϕ(X)) ≥ ϕ(E(X)).

Proposição 3.1.15 (Critério para integrabilidade). Seja X uma variável aleatória qualquer.
Então

∞
(cid:88)

P(|X| ≥ n) ≤ E|X| ≤ 1 +

P(|X| ≥ n),

∞
(cid:88)

n=1

n=1

e portanto X é integrável se, e somente se,

∞
(cid:80)
n=1

P(|X| ≥ n) < ∞.

Demonstração. Seja (cid:98)x(cid:99) o maior inteiro menor ou igual a x, a função piso de x. Se x ≥ 0,
então a variável aleatória (cid:98)|X|(cid:99) assume o valor k quando k ≤ |X| < k + 1 e

0 ≤ (cid:98)|X|(cid:99) ≤ |X| ≤ (cid:98)|X|(cid:99) + 1,

32

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

logo, por (E2) e (E3),

Mas pelo Corolário 3.1.11,

0 ≤ E(cid:98)|X|(cid:99) ≤ E|X| ≤ 1 + E(cid:98)|X|(cid:99).

logo

E(cid:98)|X|(cid:99) =

∞
(cid:88)

n=1

P((cid:98)|X|(cid:99) ≥ n) =

∞
(cid:88)

n=1

P(|X| ≥ n) ≤ E|X| ≤ 1 +

∞
(cid:88)

n=1

∞
(cid:88)

n=1

P(|X| ≥ n),

P(|X| ≥ n).

3.2 Esperanças de funções de variáveis aleatórias

Sejam X uma variável aleatória, ϕ(x) uma função real mensurável (ver Deﬁnição

A.1.1) e Y = ϕ(X). Então Y é uma variável aleatória cuja esperança é dada por

(cid:90)

E(Y ) =

ydFϕ(X)(y) =

(cid:90) ∞

0

[1 − Fϕ(X)(y)]dy −

(cid:90) 0

−∞

Fϕ(X)(y)dy,

pela Proposição 3.1.9.

Teorema 3.2.1. Seja X uma variável aleatória, ϕ(x) uma função polinomial (que é mensurá-
vel). Então

(cid:90)

(cid:90)

E(ϕ(x)) =

ydFϕ(x)(y) =

ϕ(x)dFX(x),

onde a existência de uma das integrais implica a existência da outra e a igualdade das duas.

Demonstração. Prova-se o caso geral com a Teoria da Medida. Mas já provamos na
Equação (3.1) que para ϕ(x) = |x| tal resultado é válido, e podemos provar o teorema
para polinômios usando somente a integral de Riemann, baseando-nos na Proposição
3.1.9. Mostremos que

(cid:90)

E(X k) =

xkdFX(x), para k = 1, 2, ...

3.2. ESPERANÇAS DE FUNÇÕES DE VARIÁVEIS ALEATÓRIAS

33

Vamos abreviar F = FX e supor inicialmente k par. Então

E(X k) =

=

=

=

(cid:90) ∞

0
(cid:90) ∞

0
(cid:90) ∞

0
(cid:90) ∞

0

P(X k > t)dt (pois X k ≥ 0)

√
P(X > k

t)dt +

√
[1 − F ( k

t)]dt +

(cid:90) ∞

0
(cid:90) ∞

√
P(X < − k

t)dt

√
F ((− k

t)−)dt (fazendo t = sk)

0

[1 − F (s)]ksk−1ds +

(cid:90) ∞

0

F ((−s)−)ksk−1ds.

Observe que F ((−s)−) e F (−s) são iguais exceto em um número enumerável de
pontos, assim podemos desconsiderar o segundo sinal negativo. Fazendo u = −s na
segunda integral, temos

E(X k) =

(cid:90) ∞

0

[1 − F (s)]ksk−1ds −

(cid:90) 0

−∞

F (u)kuk−1du.

(3.2)

Por outro lado, de forma similar à prova da Proposição 3.1.9, é possível mostrar que

(cid:90) ∞

xkdF (x) =

[1 − F (x)]dxk −

(cid:90) ∞

−∞

(cid:90) 0

−∞

F (x)dxk

0
(cid:26)(cid:90) ∞

0

= k

[1 − F (x)]xk−1dx −

F (x)xk−1dx

(cid:27)

.

(cid:90) 0

−∞

Logo E(X k) = (cid:82) xkdFX(x) para k par. Para k ímpar, a prova é análoga. Para ϕ po-
linômio em geral, o resultado segue pela linearidade da esperança e da integral de
Stieltjes.

Vamos diferenciar os casos discreto e contínuo do teorema anterior.

Caso discreto. Se X tiver função de probabilidade p(xi), então

E(ϕ(X)) =

(cid:88)

i

ϕ(x)p(xi).

Caso contínuo. Se X tiver densidade f (x), então

(cid:90)

E(ϕ(X)) =

ϕ(x)f (x)dx.

De forma mais geral, é possível aﬁrmar o seguinte:

Teorema 3.2.2. Seja ˜X = (X1, . . . , Xn) um vetor aleatório e ϕ : Rn → R, B-mensurável.

34

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

Então

(cid:90)

Eϕ( ˜X) =

ydFϕ( ˜X)(y) =

(cid:90)

Rn

ϕdF ˜X =

(cid:90)

(cid:90)

· · ·

ϕ(x1, . . . , xn)dF ˜X(x1, . . . , xn),

onde a última integral é uma integral n-dimensional de Stieltjes, assim como a penúltima.
0 [1 − F (x)]xk−1dx − (cid:82) 0

−∞ F (x)xk−1dx

(cid:110)(cid:82) ∞

, para k = 1, 2, . . . .

(cid:111)

Corolário 3.2.3. E(X k) = k
Essa é a fórmula (3.2).

Exemplo 3.2.4. Suponha que X ∼ U [0, 1] e Y = min

X,

(cid:18)

(cid:19)

1
2

. Então Y = ϕ(X), onde

(cid:18)

ϕ(x) = min

x,

(cid:19)

1
2

=






x, se x < 1
2
2, se x ≥ 1
2.

1

Usando o Teorema 3.1.9 e o item e) do Apêndice A.2, segue que a esperança de Y vale

(cid:90)

E(Y ) =

ϕ(x)dFX(x) =

(cid:90)

ϕ(x)fX(x)dx =

(cid:90) 1

0

ϕ(x)dx

(cid:90) 1/2

=

0

xdx +

(cid:90) 1

1/2

1
2

dx =

1
8

+

1
4

=

3
8

.

O teorema anterior nos auxilia na deﬁnição de momentos a seguir:

Deﬁnição 3.2.5. Seja X uma variável aleatória. O valor E(X − b)k, se existe, é chamado
k-ésimo momento de X em torno de b, para b ∈ R, k ∈ Z∗
+.

O k-ésimo momento em torno de zero, E(X k), é chamado de k-ésimo momento de X ou

momento de ordem k de X.

Se X é integrável, então o k-ésimo momento em torno da média, E(X − E(X))k, se chama

k-ésimo momento central de X.

Notemos que o primeiro momento é a esperança e o primeiro momento central é

nulo, pois E(X − E(X)) = 0.

Deﬁnição 3.2.6. O segundo momento central é chamado variância de X.

Notação. V ar(X)

Da deﬁnição anterior, segue que

V ar(X) = E(X − E(X))2 = E(X 2 − 2XE(X) + (E(X))2)

= E(X 2) − 2E(X)E(X) + (E(X))2

= E(X 2) − (E(X))2.

3.2. ESPERANÇAS DE FUNÇÕES DE VARIÁVEIS ALEATÓRIAS

35

Além disso, se X = c, então V ar(X) = 0, pois sendo E(X) = c, temos V ar(X) =

E(X − c)2 = E(0) = 0.

Se a, b ∈ R então temos V ar(X + b) = V ar(X) e V ar(aX + b) = a2V ar(X), pois
sendo E(aX + b) = aE(X) + b, temos que V ar(aX + b) = E(aX + b − aE(X) − b)2 =
E(a2(X − E(X))2) = a2V ar(X).

Deﬁnição 3.2.7. A raiz quadrada da variância é chamada de desvio-padrão de X, ou seja,

σX = (cid:112)V ar(X).

A ideia do desvio-padrão é manter a mesma unidade da variável aleatória. Por
exemplo, se X denota uma variável aleatória medida em metros (m), então V ar(X)
terá a unidade em m2, e assim σX terá a unidade em m.

Deﬁnição 3.2.8. Seja t > 0. Deﬁnimos E(|X|t) como o t-ésimo momento absoluto de X.

Da deﬁnição anterior, segue que momentos absolutos possuem a seguinte proprie-

dade:

Proposição 3.2.9. Sejam X uma variável aleatória e t > 0. A função

f (t) = E1/t|X|t

é não decrescente em t. Notação: E1/t|X|t = [E(|X|t)]1/t.

Demonstração. Sejam 0 < s < t. Temos que a função ϕ(y) = |y|t/s é convexa, pois
t/s > 1. Se Y é integrável, a desigualdade de Jensen (Proposição 4 (E4)) implica que

E(|Y |t/s) ≥ |E(Y )|t/s.

Tomando Y = |X|s: segue que se |X|s é integrável, então

E(|X|t) ≥ Et/s|X|s,

isto é, E1/t|X|t ≥ E1/s|X|s.

Se |X|s não é integrável, então |X|t também não o é, pois s < t implica |X|s ≤

1 + |X|t e, portanto

E(|X|s) = +∞ ⇒ +∞ ≤ 1 + E(|X|t) ⇒ E(|X|t) = +∞.

De qualquer forma, segue que

E1/s|X|s ≤ E1/t|X|t para 0 < s < t.

36

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

Corolário 3.2.10. Se E(|X|t) é ﬁnita para algum 0 < t < ∞, então E(|X|s) é ﬁnito para todo
s tal que 0 < s < t.

Corolário 3.2.11. Se X e Y são variáveis aleatórias em (Ω, A, P) tais que E(|X|t) < ∞ e
E(|Y |t) < ∞, então E(|X + Y |t) < ∞.

Demonstração. Pela desigualdade triangular, |X + Y | ≤ |X| + |Y | ≤ 2 max(|X|, |Y |).
Portanto,

|X + Y |t ≤ 2t max(|X|t, |Y |t) ≤ 2t(|X|t + |Y |t),

logo

E(|X + Y |t) ≤ 2t(E(|X|t) + E(|Y |t)).

Exemplo 3.2.12. Se E(X 2) < ∞ então X é integrável. Além disso, se o k-ésimo momento é
ﬁnito, então todos os momentos de ordem menor que k também são ﬁnitos.

Proposição 3.2.13 (Desigualdade de Markov). Seja X uma variável aleatória não-negativa.
Para todo λ > 0, vale que

1
λ
Demonstração. Pelo Corolário 3.1.10, temos que

P(X ≥ λ) ≤

E(X).

E(X) =

∞
(cid:90)

0

P(X > x)dx =

≥

P(X > x)dx +

∞
(cid:90)

λ

P(X > x)dx

P(X ≥ λ)dx + 0 = λP(X ≥ λ),

λ
(cid:90)

0

λ
(cid:90)

0

uma vez que P(X > x) ≥ P(X ≥ λ) para x no intervalo [0, λ]. O resultado segue
dividindo ambos os lados por λ.

Proposição 3.2.14 (Desigualdade de Tchebychev). Se X é integrável, então para todo λ > 0
temos

P(|X − E(X)| ≥ λ) ≤

V ar(X)
λ2

.

Demonstração. Pela Desigualdade de Markov, como (X − E(X))2 é uma variável alea-
tória não-negativa, temos

P(|X − E(X)| ≥ λ) = P((X − E(X))2 ≥ λ2) ≤

1
λ2 E(X − E(X))2 =

V ar(X)
λ2

.

3.2. ESPERANÇAS DE FUNÇÕES DE VARIÁVEIS ALEATÓRIAS

37

Proposição 3.2.15 (Desigualdade de Markov generalizada). Seja X uma variável aleatória
qualquer. Então para todo t > 0,

P(|X| ≥ λ) ≤

E|X|t
λt

, ∀λ > 0.

Demonstração. Sendo |X| uma variável aleatória não-negativa, usamos o mesmo argu-
mento da demonstração da proposição anterior.

É importante salientar que se X é integrável então sua média µ minimiza o segundo

momento E(X − c)2, c ∈ R, isto é,

V ar(X) = E(X − µ)2 = min
c∈R

E(X − c)2.

Deﬁnição 3.2.16. Uma mediana de uma variável aleatória X é um valor m que satisfaz

P(X ≥ m) ≥

1
2

e P(X ≤ m) ≥

1
2

.

Da deﬁnição, segue que se m é mediana de X, então m minimiza E|X − c|, c ∈ R,

isto é,

E|X − m| = min
c∈R

E|X − c|.

Agora já temos todas as ferramentas necessárias para a demonstração da lineari-
dade da esperança (propriedade (E3)). Necessitamos provar que E(X + Y ) = E(X) +
E(Y ), supondo que o termo à direita seja bem-deﬁnido. Por isso, sejam ϕ(x, y) =
x + y, ϕ1(x, y) = x, ϕ2(x, y) = y. Pelo Teorema 3.2.1,

E(X + Y ) = Eϕ(X, Y ) =

(cid:90) (cid:90)

(x + y)dFX,Y (x, y).

Pela linearidade da integral múltipla de Stieltjes, obtemos

(cid:90) (cid:90)

E(X+Y ) =

xdFX,Y (x, y)+

(cid:90) (cid:90)

ydFX,Y (x, y) = Eϕ1(X, Y )+Eϕ2(X, Y ) = E(X)+E(Y ).

Proposição 3.2.17. Se X1, . . . , Xn são variáveis aleatórias independentes e integráveis, então
n
(cid:81)
i=1

Xi é integrável e E(X1X2 . . . Xn) =

E(Xi).

n
(cid:81)
i=1

Demonstração. Vamos provar o caso n = 2 e o restante segue por indução, uma vez que
E(X1 . . . Xn−1Xn) será igual a E(X1 . . . Xn−1)E(Xn). Seja ϕ(x, y) = xy. A independên-

38

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

cia de X e Y implica

E(XY ) = Eϕ(X, Y ) =

ϕ(x, y)dFX(x)dFY (y)

(cid:90) (cid:20)(cid:90)

=

xdFX(x)

ydFY (y) =

(cid:90)

(E(X))ydFY (y)

(cid:90) (cid:90)

(cid:21)

= E(X) · E(Y ).

É importante ressaltar que E(XY ) = E(X)·E(Y ) não implica X e Y independentes,

como vemos no seguinte exemplo.

Exemplo 3.2.18. Sejam X e Y variáveis aleatórias tomando os valores −1, 0, 1, com distri-
buição uniforme nos pontos (−1, −1), (−1, 1), (1, −1), (1, 1) e (0, 0), isto é, a probabilidade de

cada um desses pontos é

1
5

. A função de probabilidade é a da seguinte tabela.

(cid:72)(cid:72)

Y

(cid:72)(cid:72)(cid:72)

X
(cid:72)(cid:72)(cid:72)

−1

0

1

−1

1/5

0

0

1

1/5

0

1/5

0

1/5

0

1/5

Tabela 3.1: Distribuição conjunta

Então,

e

E(X) = (−1) ·

2
5

+ 0 ·

E(XY ) =

ijp(i, j) =

(cid:88)

i,j

1
5

1
5

+ 1 ·

2
5

= 0 = E(Y ),

(1 − 1 − 1 + 1 + 0) = 0.

Portanto, E(XY ) = E(X) · E(Y ), mas X e Y não são independentes. De fato, temos, por
exemplo,

P(X = 0, Y = 0) = p(0, 0) =

1
5

(cid:54)=

1
25

=

1
5

·

1
5

= P(X = 0) · P (Y = 0).

Deﬁnição 3.2.19. Sejam X e Y variáveis aleatórias integráveis. A covariância entre X e Y é
deﬁnida por

Cov(X, Y ) = E[(X − E(X))(Y − E(Y ))],

se esta esperança existe.

3.2. ESPERANÇAS DE FUNÇÕES DE VARIÁVEIS ALEATÓRIAS

39

Pela linearidade da esperança, temos

Cov(X, Y ) = E(XY − Y E(X) − XE(Y ) + E(X) · E(Y )) = E(XY ) − E(X) · E(Y ),

o que implica que a covariância entre duas variáveis integráveis existe se, e somente
se, existe a esperança E(XY ).

Deﬁnição 3.2.20. Se Cov(X, Y ) = 0, dizemos que X e Y são não-correlacionadas.

Se X e Y são independentes e integráveis, então são não-correlacionadas, pois neste
caso E(XY ) = E(X) · E(Y ) pela Proposição 3.2.17. Pelo Exemplo 3.2.18, covariância
zero não necessariamente implica independência.

Proposição 3.2.21. Sejam X1, . . . , Xn variáveis aleatórias integráveis tais que Cov(Xi, Xj) =
0 para i (cid:54)= j. Então

V ar(X1 + · · · + Xn) =

V arXi.

n
(cid:88)

Demonstração.

i=1

V ar(X1 + · · · + Xn) = E(X1 + · · · + Xn − E(X1 + · · · + Xn))2

= E((X1 − E(X1)) + · · · + (Xn − E(Xn)))2

(cid:34) n

(cid:88)

(Xi − E(Xi))2 + 2

(Xi − E(Xi))(Xj − E(Xj))

(cid:35)

(cid:88)

i<j

= E

=

=

n
(cid:88)

i=j
n
(cid:88)

i=1

i=1

V arXi + 2

(cid:88)

i<j

V arXi.

Cov(Xi, Xj)

Corolário 3.2.22. Se X1, . . . , Xn são independentes e integráveis, então

V ar(X1 + · · · + Xn) =

n
(cid:88)

i=1

V arXi.

40

CAPÍTULO 3. ESPERANÇA E VARIÂNCIA DE VARIÁVEIS ALEATÓRIAS

Capítulo 4

A Lei dos Grandes Números

Consideremos certo experimento básico, com a variável aleatória X representando
o valor de um característico numérico do resultado. Pensemos na realização deste
experimento n vezes, onde n é um número grande, de tal maneira que as realizações
sejam independentes. Suponhamos que depois de cada realização do experimento
registre-se o valor de X; este será o valor observado. Informalmente, os n observados
formam “uma amostra aleatória da variável aleatória X”. A Lei dos Grandes Números
aﬁrma que a média aritmética dos n valores observados é aproximadamente igual a
E(X) quando n é grande; de fato, ela aﬁrma que esta média aritmética das observações
converge, em certo sentido, para média E(X), quando n → ∞.

Um experimento composto consiste em realizar o experimento básico, de forma suces-
siva e independente, n vezes. Assim, um resultado possível do experimento composto
é uma sequência de n resultados possíveis do experimento básico. Portanto, se Ω0 é o
espaço amostral do experimento básico, então o espaço amostral para o experimento
composto é o conjunto de sequências de comprimento n de elementos de Ω0, isto é,

Ωn = Ωn

0 = {(ω1, . . . , ωn); ωi ∈ Ω0, i = 1, . . . , n}.

Na verdade, estamos interessados em passar o limite no espaço Ωn quando n → ∞
para aplicar a convergência aﬁrmada pela Lei dos Grandes Números. Por isso, o es-
paço amostral do experimento composto que vamos considerar consiste nas sequên-
cias inﬁnitas de elementos de Ω0, isto é,

Ω = {(ω1, ω2, . . . ); ωi ∈ Ω0, i = 1, 2, . . . } = Ω0 × Ω0 × · · · = Ω∞
0 .

Aqui, Ωn é o resultado das n primeiras realizações do experimento básico. É importante
registrar o resultado do n-ésimo experimento básico. Para isso, sendo ω = (ω1, ω2, . . . ),
os valores observados serão X(ω1), X(ω2), . . . . Assim, é conveniente representar por

41

42

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

Xn o valor observado do n-ésimo ensaio, isto é, Xn é função do resultado ω do experi-
mento global, com

Xn(ω) = X(ωn),

e no decorrer do experimento serão registrados os valores das variáveis aleatórias
X1, X2, . . . . Como estamos tratando de repetições do mesmo experimento, segue que
Xn tem a mesma distribuição de X. Além disso, as variáveis aleatórias Xn são inde-
pendentes, e portanto a sequência X1, X2, . . . é formada por variáveis aleatórias inde-
pendentes e identicamente distribuídas. Se X1 é integrável, então todas elas o são, e
E(Xn) = E(X1) para todo n. Neste caso, temos a seguinte versão da Lei dos Grandes
Números: Se X1, X2, . . . são independentes, identicamente distribuídas e integráveis,
então

X1 + · · · + Xn
n

→ E(X1).

A seguir, vamos deﬁnir o tipo de convergência a ser considerado. Sejam Y, Y1, Y2, . . .

variáveis aleatórias deﬁnidas em um mesmo espaço de probabilidade (Ω, A, P).

Deﬁnição 4.0.1. Yn converge para Y em probabilidade se para todo (cid:15) > 0,

P(|Yn − Y | ≥ (cid:15)) → 0 quando n → ∞.

Notação. Yn

P−→ Y.

Deﬁnição 4.0.2. Yn converge para Y quase certamente se

P(Yn → Y quando n → ∞) = 1,

isto é, se o evento A0 = {ω; Yn(ω) → Y (ω)} tem probabilidade 1.
Notação. Yn

qc
−→ Y.

Costuma-se dizer que Yn(ω) converge para Y (ω) para “quase todo” ω. Interpre-
tando ω ∈ Ω como um resultado possível de um experimento, a sequência Yn(ω) con-
verge para Y (ω) para quase todo ω quando Yn

qc
−→ Y .

Por outro lado, convergência em probabilidade apenas aﬁrma que para valores
grandes de n as variáveis Yn e Y são aproximadamente iguais com probabilidade bem
alta. Convergência em probabilidade é mais fraca que convergência quase certa, em
vista da proposição e do exemplo a seguir.
P−→ Y.

Proposição 4.0.3. Se Yn

qc
−→ Y , então Yn

Demonstração. Suponha que Yn

qc
−→ Y e seja (cid:15) > 0. Vamos provar que

P(|Yn − Y | ≥ (cid:15)) → 0.

43

Seja A0 = {ω; Yn(ω) → Y (ω)}, onde P(A0) = 1. Para todo ω ∈ A0, |Yn(ω) − Y (ω)| < (cid:15)
para todo n suﬁcientemente grande. Seja An o evento “para todo k ≥ n, |Yk − Y | < (cid:15)”,
isto é,

∞
(cid:92)

An =

(|Yk − Y | < (cid:15)).

Se ω ∈ A0, então ω ∈ An para algum n. Além disso, temos An ⊂ An+1, logo

k=n

A0 ⊂

(cid:91)

n≥1

An = lim
n→∞

An.

Portanto, 1 = P(A0) ≤ P( (cid:83)

An) e, por continuidade de probabilidade, P(An) ↑ 1.

n≥1

Mas An ⊂ [|Yn − Y | < (cid:15)], logo P(|Yn − Y | < (cid:15)) → 1 e P(|Yn − Y | ≥ (cid:15)) = 1 − P(|Yn − Y | <
(cid:15)) → 0.

A recíproca da proposição anterior não é necessariamente verdadeira.

Exemplo 4.0.4. Seja X ∼ U [0, 1]. Consideremos os seguintes intervalos:

I1 = [0, 1], I2 = [0, 1/2], I3 = [1/2, 1], I4 = [0, 1/4], . . . , I7 = [3/4, 1], I8 = [0, 1/8], . . .

isto é, para m = 0, 1, 2, . . . e i = 0, 1, . . . , 2m − 1, temos

I2m+i =

(cid:20) i
2m ,

i + 1
2m

(cid:21)

.

Então os 2m intervalos de comprimento 1
comprimento ﬁca cada vez menor.

2m cobrem o intervalo [0, 1], ao mesmo tempo que seu

Seja Yn o indicador do evento [X ∈ In], ou seja,

Yn =




1 se X ∈ In



0 se X /∈ In.

Aﬁrmamos que a sequência Y1, Y2, . . . converge em probabilidade para a variável aleatória

constante Y = 0. De fato, seja 0 < (cid:15) ≤ 1. Temos

P(|Yn − 0| ≥ (cid:15)) = P(Yn = 1) = P(X ∈ In),

e esta probabilidade, que é igual ao comprimento de In, converge para zero quando n → ∞. Se
(cid:15) > 1, é impossível que |Yn − 0| ≥ (cid:15), logo P(|Yn − 0| ≥ (cid:15)) = P(∅) = 0.

Aﬁrmamos agora que Yn não converge quase certamente para zero. De fato, não converge
em ponto algum, pois qualquer que seja o valor de X, este valor pertence a um ou dois dos 2n

44

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

intervalos de comprimento 1
2n , para todo n. Logo, se ω ∈ Ω, Yn(ω) assume o valor 1 para um
número inﬁnito de n(cid:48)s, assim como assume o valor 0 também para um número inﬁnito de n(cid:48)s e
isso implica que para cada ω ∈ Ω, Yn(ω) não converge.

Agora estamos aptos a formular a Lei dos Grandes Números de uma maneira mais
formal, separando em duas classes de lei: fraca e forte, de acordo com o tipo de con-
vergência.

Deﬁnição 4.0.5. Sejam X1, X2, . . . variáveis aleatórias integráveis em (Ω, A, P), e sejam
S1, S2, . . . as somas parciais, deﬁnidas por Sn = X1 + · · · + Xn. Observamos que S1, S2, . . .
também são variáveis aleatórias em (Ω, A, P).

Dizemos que X1, X2, . . . satisfazem a Lei Fraca dos Grandes Números se

Sn − E(Sn)
n

P−→ 0,

ou equivalentemente, se para todo (cid:15) > 0, vale

P

(cid:18)(cid:12)
(cid:12)
(cid:12)
(cid:12)

X1 + · · · + Xn − (E(X1) + · · · + E(Xn))
n

(cid:19)

≥ (cid:15)

→ 0.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Dizemos que X1, X2, . . . satisfazem a Lei Forte dos Grandes Números se

Sn − E(Sn)
n

qc
−→ 0,

ou equivalentemente, se

(X1 − E(Xn)) + (X2 − E(X2)) + · · · + (Xn − E(Xn))
n

qc
−→ 0.

Pela Proposição 4.0.3, se a sequência X1, X2, . . . satisfaz a Lei Forte, então satisfaz
a Lei Fraca, mas a recíproca não é necessariamente verdade pelo Exemplo 4.0.4. Com
isso, a Lei Forte é realmente mais “forte”.

Intuitivamente, este conceito mais geral da Lei dos Grandes Números pode ser ex-
presso assim: uma sequência de variáveis aleatórias satisfaz a Lei dos Grandes Núme-
ros se, quando n é grande, a média aritmética dos primeiros n observados é aproxima-

damente igual à média aritmética das suas esperanças, ou seja,

igual a

E(Sn)
n

=

E(X1) + · · · + E(Xn)
n

.

Sn
n

é aproximadamente

4.1. A LEI FRACA DOS GRANDES NÚMEROS

45

4.1 A Lei Fraca dos Grandes Números

Teorema 4.1.1 (Lei Fraca de Tchebychev). Sejam X1, X2, . . . variáveis aleatórias não corre-
lacionadas com variâncias ﬁnitas e uniformemente limitadas (isto é, existe c ﬁnito tal que para
todo n, V ar(Xn) ≤ c). Então X1, X2, . . . satisfazem a Lei Fraca dos Grandes Números:

Sn − E(Sn)
n

P−→ 0.

Demonstração. Seja (cid:15) > 0. Queremos mostrar que

(cid:18) |Sn − E(Sn)|
n

P

(cid:19)

≥ (cid:15)

→ 0 quando n → ∞.

Pela Proposição 3.2.21, temos V ar(Sn) = V ar(X1 + · · · + Xn) = (cid:80)n
Pela desigualdade de Tchebychev temos

i=1 V ar(Xi) ≤ nc.

P(|Sn − E(Sn)| ≥ (cid:15)n) ≤

V ar(Sn)

(cid:15)2n2 ≤

c
(cid:15)2n

→ 0.

Corolário 4.1.2 (Lei Fraca de Bernoulli). Consideremos uma sequência de ensaios binomiais
independentes, tendo a mesma probabilidade p de “sucesso” em cada ensaio. Se Sn é o número
de sucessos nos primeiros n ensaios, então

Demonstração. Seja

Sn
n

P−→ p.

Xn =




1 se o n-ésimo ensaio é sucesso,



0 se o n-ésimo ensaio é fracasso,

onde P(Xn = 1) = p e P(Xn = 0) = 1 − p. Então X1, X2, . . . são independentes,
identicamente distribuídas e integráveis, com média µ = p. Como V ar(Xn) = p(1 − p)
é uniformemente limitada, a Lei Fraca de Tchebychev implica que

ou, equivalentemente,

Sn − np
n

P−→ 0.

Sn
n

P−→ p.

46

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

4.2 O Lema de Borel-Cantelli

Vamos apresentar agora o Lema de Borel-Cantelli, que será uma peça importante
na prova da Lei Forte. Mas antes, precisamos deﬁnir os limites superior e inferior de
uma sequência de eventos.

Deﬁnição 4.2.1. Seja A1, A2, . . . uma sequência de eventos. O limite superior da sequência
é deﬁnido por

lim sup
n→∞

An =

o limite inferior é deﬁnido por

∞
(cid:92)

∞
(cid:91)

n=1

k=n

Ak;

lim inf
n→∞

An =

∞
(cid:91)

∞
(cid:92)

n=1

k=n

Ak.

Por conveniência, vamos abreviar a notação como lim sup An e lim inf An.

Intuitivamente, temos que o evento lim sup An é o evento “ocorrência de um nú-
mero inﬁnito dos An”, ou seja, ocorre An para inﬁnitos n(cid:48)s. O evento lim inf An também
tem uma interpretação intuitiva, é o evento “ocorrência de An para todo n suﬁciente-
mente grande”.

Como a ocorrência de An para todo n suﬁcientemente grande implica que An ocorre
inﬁnitas vezes, temos lim inf An ⊂ lim sup An. É comum deﬁnir o limite de An, lim An,
como lim inf An se lim inf An = lim sup An.

Por vezes, vamos denotar lim sup An = [An inﬁnitas vezes].

Proposição 4.2.2 (Lema de Borel-Cantelli). Considere a sequência de eventos A1, A2, . . .
deﬁnida em (Ω, A, P).

(a) Se

(b) Se

∞
(cid:80)
n=1

∞
(cid:80)
n=1

P(An) < ∞, então P(An inﬁnitas vezes) = 0.

P(An) = ∞, e os An são independentes, então P(An inﬁnitas vezes) = 1.

O item (b) pode não ser verdadeiro se a hipótese de independência for removida.
Por exemplo, seja An = A para todo n, onde 0 < P(A) < 1. Então (cid:80) P(An) = ∞, mas
o evento [An inﬁnitas vezes] = A e P(An inﬁnitas vezes) = P(A) < 1.

Demonstração. (a) Se (cid:80) P(An) < ∞, então

∞
(cid:80)
k=n

P(Ak) → 0 quando n → ∞. Mas

4.2. O LEMA DE BOREL-CANTELLI

47

[An inﬁnitas vezes] ⊂

∞
(cid:83)
k=n

Ak para todo n, logo

P(An inﬁnitas vezes) ≤ P

(cid:33)

Ak

≤

(cid:32) ∞
(cid:91)

k=n

∞
(cid:88)

k=n

P(Ak) → 0.

Portanto, P(An inﬁnitas vezes) = 0.

(b) Basta provar que P

(cid:18) ∞
(cid:83)
k=n

(cid:19)

Ak

= 1 ∀n pois [An inﬁnitas vezes] =

∞
(cid:84)
n=1

∞
(cid:83)
n=k

Ak e a

interseção de um número enumerável de eventos de probabilidade um, é também

de probabilidade um. Seja Bn =

∞
(cid:83)
k=n

Ak. Então Bn ⊃

n+m
(cid:83)
k=n

Ak para todo m, e

Bc

n ⊂

(cid:33)c

Ak

=

(cid:32)n+m
(cid:91)

k=n

n+m
(cid:92)

k=n

Ac
k.

Aplicando a probabilidade na expressão anterior, obtemos para todo m,

1 − P(Bn) = P(Bc

n) ≤ P

(cid:32)n+m
(cid:92)

(cid:33)

Ac
k

=

k=n

n+m
(cid:89)

k=n

P(Ac

k) =

n+m
(cid:89)

k=n

(1 − P(Ak)).

Figura 4.1: Gráﬁco das funções f (x) = 1 − x e g(x) = e−x

Pelo gráﬁco, temos 1 − p ≤ e−p para 0 ≤ p ≤ 1, logo

1 − P(Bn) ≤

n+m
(cid:89)

(cid:26)
e−P(Ak) = e

−

n+m
(cid:80)
k=n

(cid:27)

P(Ak)

→ 0

k=n

quando m → ∞, pois

n+m
(cid:80)
k=n

queríamos demonstrar.

P(Ak) → +∞ quando m → ∞. Logo P(Bn) = 1 ∀n, como

48

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

Corolário 4.2.3. Consideremos uma sequência de ensaios binomiais independentes com proba-
bilidade pn de sucesso no n-ésimo ensaio. Seja

Xn =




1 se o n-ésimo ensaio é sucesso



0 se é fracasso.

Então, vale o seguinte:

1. Se

2. Se

∞
(cid:80)
n=1

∞
(cid:80)
n=1

pn = +∞, então P

pn < +∞, então P

(cid:18) ∞
(cid:80)
n=1

(cid:18) ∞
(cid:80)
n=1

(cid:19)

Xn = ∞

= 1.

(cid:19)

Xn < ∞

= 1.

Em outras palavras,

(cid:88)

(cid:88)

pn < ∞ ⇒ um número ﬁnito de sucessos, quase certamente

pn = ∞ ⇒ um número inﬁnito de sucessos, quase certamente.

Demonstração. Seja An = [Xn = 1]. Então P(An) = pn e os An são independentes. Pelo
Lema de Borel-Cantelli,

(cid:88)

(cid:88)

pn < ∞ ⇒ P(An inﬁnitas vezes) = 0 (item (a))

pn = ∞ ⇒ P(An inﬁnitas vezes) = 1 (item (b)).

Mas [An inﬁnitas vezes]c = “apenas um número ﬁnito de sucessos entre todos os

ensaios”. Portanto,

[An inﬁnitas vezes] =

[An inﬁnitas vezes]c =

(cid:104)(cid:88)

(cid:105)
Xn = ∞

,

(cid:104)(cid:88)

(cid:105)
Xn < ∞

.

Exemplo 4.2.4. Ao colocar um macaco diante de um computador, é razoável supor que haja
uma probabilidade positiva, embora muito pequena, dele digitar as obras completas de Shakes-
peare sem erro. Vamos chamar o primeiro ensaio de sucesso se ele realizar essa façanha, e de
fracasso quando ele comete o primeiro erro. No ﬁnal do primeiro ensaio, que provavelmente
chegará logo, vamos alimentá-lo ou levá-lo para dar uma volta (para garantir a independên-
cia dos ensaios) e começar o segundo ensaio. O processo segue assim sucessivamente. Como
pn = p > 0 para todo n, temos (cid:80) pn = ∞. Pelo corolário anterior, há probabilidade 1 dele
escrever as obras completas de Shakespeare um número inﬁnito de vezes.

4.3. A LEI FORTE DOS GRANDES NÚMEROS

49

Exemplo 4.2.5. O exemplo anterior pode ser adaptado para loterias. Se jogarmos na loteria com
uma frequência determinada (não necessariamente os mesmos números), com probabilidade 1
vamos ganhar inﬁnitas vezes. O grande problema é o tempo que isso vai levar. Provavelmente,
seguindo esse processo, pode ser que a primeira vez que ganharmos já teríamos morrido ou fa-
lido, pois levaríamos milhares ou milhões de anos ou teríamos gastado todo o dinheiro disponível
no mundo.

4.3 A Lei Forte dos Grandes Números

Proposição 4.3.1 (Desigualdade de Kolmogorov). Sejam X1, . . . , Xn variáveis aleatórias
independentes tais que E(Xk) = 0 e V ar(Xk) < ∞, k = 1, . . . , n, e sejam Sk = X1 + · · · + Xk
e λ > 0. É válida a seguinte desigualdade:

(cid:18)

(cid:19)

P

max
1≤k≤n

|Sk| ≥ λ

≤

1
λ2 V ar(Sn) =

1
λ2

n
(cid:88)

k=1

V ar(Xk).

Demonstração. Seja A = [max S2

k ≥ λ2], e sejam

A1 = [S2
A2 = [S2

1 ≥ λ2],
1 < λ2, S2

2 ≥ λ2],

. . .
Ak = [S2

1 < λ2, . . . , S2

k−1 < λ2, S2

k ≥ λ2], para 2 ≤ k ≤ n,

de forma que A =

Ak e os Ak(cid:48)s são dois a dois disjuntos. Intuitivamente, Ak é o

evento que indica que a primeira vez que S2

j ≥ λ2 ocorre para j = k. Dessa forma,

n
(cid:83)
k=1

temos IA =

n
(cid:80)
k=1

IAk, logo

n ≥ S2
S2

nIA =

n
(cid:88)

k=1

nIAk ⇒ E(S2
S2

n) ≥

n
(cid:88)

k=1

E(S2

nIAk).

(4.1)

Além disso,

n = (Sn − Sk + Sk)2 = (Sn − Sk)2 + S2
S2

k + 2(Sn − Sk)Sk ≥ S2

k + 2(Sn − Sk)Sk.

Multiplicando por IAk e tomando a esperança na desigualdade acima, temos que

E(S2

nIAk) ≥ E(S2

kIAk) + 2E((Sn − Sk)SkIAk).

50

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

Notemos que SkIAk só depende de X1, . . . , Xk, enquanto Sn − Sk = Xk+1 + · · · + Xn
depende de Xk+1, . . . , Xn, logo SkIAk e Sn − Sk são independentes. Pela Proposição
3.2.17, segue que E((Sn − Sk)SkIAk) = E(Sn − Sk)E(SkIAk) = 0 pois E(Sn) = E(Sk).
Como S2

k ≥ λ2 em Ak e usando o Corolário 3.1.12 segue que

E(S2

nIAk) ≥ E(S2

kIAk) ≥ E(λ2IAk) = λ2E(IAk) = λ2P(Ak).

Pela desigualdade em (4.1), obtemos pela aditividade da probabilidade que

E(S2

n) ≥

n
(cid:88)

k=1

λ2P(Ak) = λ2P(A),

de onde segue a proposição.

Teorema 4.3.2 (Primeira Lei Forte de Kolmogorov). Sejam X1, X2, . . . variáveis aleatórias
independentes e integráveis, e suponha que

∞
(cid:88)

n=1

V ar(Xn)
n2

< +∞.

Então os Xn satisfazem a Lei Forte dos Grandes Números, isto é,

X1 + · · · + Xn
n

−

(E(X1) + · · · + E(Xn))
n

qc
−→ 0.

Demonstração. Se E(Xn) (cid:54)= 0 então tome Yn = Xn −E(Xn). Então E(Yn) = 0, V ar(Yn) =
V ar(Xn) e as Yn satisfazem as hipóteses do teorema. Se o teorema vale para o caso
E(Yn) = 0, então

Y1 + · · · + Yn
n

qc
−→ 0,

isto é,

(X1 − E(X1)) + · · · + (Xn − E(Xn))
n

qc
−→ 0.

Vamos supor, portanto E(Xn) = 0 para todo n. Queremos mostrar que

onde Sn = X1 + · · · + Xn. Basta mostrar que

Sn
n

qc
−→ 0,

Mn = max

2n<k≤2n+1

|Sk|
k

qc
−→ 0, quando n → ∞.

Usando a desigualdade de Kolmogorov e o Lema de Borel-Cantelli respectivamente,
vamos provar que

(i)

∞
(cid:80)
n=1

(cid:18)

P

Mn ≥

(cid:19)

1
m

< ∞, ∀m = 1, 2, . . . , e

4.3. A LEI FORTE DOS GRANDES NÚMEROS

51

(ii) Mn

qc
−→ 0.

Prova de (i). Seja m ﬁxo. Como

|Sk|
k

<

|Sk|
2n para k > 2n temos

(cid:18)

P

max
2n<k≤2n+1

|Sk|
k

≥

(cid:19)

1
m

(cid:18)

≤ P

max
2n<k≤2n+1

|Sk| ≥

(cid:19)

2n
m

(cid:18)

≤ P

max
1≤k≤2n+1

|Sk| ≥

(cid:19)

2n
m

≤

m2
4n

2n+1
(cid:88)

k=1

V ar(Xk),

pela desigualdade de Kolmogorov. Seja

(cid:20)

An =

max
2n<k≤2n+1

|Sk|
k

≥

1
m

(cid:21)

(cid:20)

=

Mn ≥

(cid:21)

.

1
m

Temos

Como

temos

P(An) ≤ m2

(cid:32)

∞
(cid:88)

(cid:33)

V ar(Xk)

∞
(cid:88)

n=1

1
4n

2n+1
(cid:88)

k=1

(cid:88)

n≥(cid:100)log2(k)(cid:101)−1


V ar(Xk)

= m2

= m2

n=1
∞
(cid:88)

k=1

∞
(cid:88)

k=1

(cid:18) 1
4n V ar(Xk)

(cid:19)



 .

1
4n

(cid:88)

n≥(cid:100)log2(k)(cid:101)−1

∞
(cid:88)

n=j

1
4n =

1
4j

(cid:32)

1 +

(cid:19)2

1
4

+

(cid:18) 1
4

(cid:33)

+ . . .

=

1
4j ·

4
3

(cid:88)

n≥(cid:100)log2(k)(cid:101)−1

1
4n =

4
3

·

1
4n≥(cid:100)log2(k)(cid:101)−1 ≤

4
3

·

1
4log2(k)−1 =

16
3k2 .

Portanto, por hipótese temos

∞
(cid:88)

n=1

P(An) ≤

16m2
3

∞
(cid:88)

k=1

V ar(Xk)
k2

< ∞.

Prova de (ii). Com a mesma notação de (i), temos P(An inﬁnitas vezes) = 0 por Borel-
Cantelli. Em outras palavras, para todo m ﬁxo, a probabilidade de que Mn assuma um
valor ≥ 1/m inﬁnitas vezes é 0. Isto signiﬁca que para todo m, a probabilidade de que
Mn assuma um valor ≥ 1/m para somente um número ﬁnito de n(cid:48)s é 1. Considere

52

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

Bn = “Mn assume um valor ≥ 1

m para somente um número ﬁnito de n(cid:48)s”.

Temos que P(Bm) = 1 ∀m e P

(cid:18) ∞
(cid:84)
m=1

Agora basta notar que o evento

temos Mn ≥ 0 e portanto:

(cid:19)

= 1.

Bm é equivalente ao evento [Mn → 0]. De fato,

Bm

∞
(cid:84)
m=1

ω ∈

∞
(cid:92)

m=1

Bm ⇔ ∀m, Mn(ω) ≥ 1/m para somente um número ﬁnito de n(cid:48)s

⇔ ∀m, 0 ≤ Mn(ω) < 1/m para todo n suﬁcientemente grande

⇔ Mn(ω) → 0 quando n → ∞.

Lema 4.3.3. Seja X uma variável aleatória integrável com função de distribuição F . Então,






∞
(cid:88)

n=1

1
n2

n
(cid:90)

−n




x2dF (x)



< ∞.

Lembramos aqui que

n
(cid:82)

−n

= (cid:82)

(−n,n] .

Demonstração. Vamos observar primeiramente, usando o teste da integral, que para
j = 1, 2, . . .

∞
(cid:88)

n=j

1
n2 ≤

1
j2 +

∞
(cid:90)

j

1
x2 dx =

1
j2 +

(cid:20)

−

1
x

(cid:21)∞

j

=

1
j2 +

1
j

≤

2
j

.

Como

n
(cid:90)

−n

x2dF (x) =

j

(cid:90)

n
(cid:88)

−n+1

j−1

x2dF (x),

temos






∞
(cid:88)

n=1

1
n2

n
(cid:90)

−n




x2dF (x)



∞
(cid:88)

n=1

∞
(cid:88)

=

=

n
(cid:88)

j=−n+1



∞
(cid:88)






1
n2

j

(cid:90)

j−1




x2dF (x)



1
n2

j

(cid:90)

j−1




x2dF (x)

0
(cid:88)

∞
(cid:88)

+



j=−∞

n=|j|+1






1
n2

j

(cid:90)

j−1




x2dF (x)



j=1

n=j



≤ 2

j

(cid:90)

∞
(cid:88)

j=1

j−1

x2
j

dF (x) + 2

j

(cid:90)

0
(cid:88)

j=−∞

j−1

x2
|j| + 1

dF (x).

4.3. A LEI FORTE DOS GRANDES NÚMEROS

53

Como

x2
j

≤ x em (j − 1, j], para j ≥ 1, e

x2
|j| + 1

≤ |x| em (j − 1, j], para j ≤ 0, temos






∞
(cid:88)

n=1

1
n2

n
(cid:90)

−n




x2dF (x)

j

(cid:90)

∞
(cid:88)

≤ 2

xdF (x) + 2



j=1

j=1

j

(cid:90)

∞
(cid:88)

j=−∞

j−1

= 2

|x|dF (x)

j

(cid:90)

0
(cid:88)

j=−∞

j−1

|x|dF (x)

∞
(cid:90)

= 2

−∞

|x|dF (x) = 2E(|X|) < ∞.

Lema 4.3.4. Seja (an)n∈N uma sequência de números reais. Se lim an = 0 então

lim

a1 + a2 + · · · + an
n

= 0.

Demonstração. Seja (cid:15) > 0 e tome n0 ∈ N de forma que se n > n0 então |an| < (cid:15). Pela
desigualdade triangular, se n > n0 temos

(cid:12)
(cid:12)
(cid:12)
(cid:12)

a1 + · · · + an
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

≤

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

a1 + · · · + an0
n
a1 + · · · + an0
n
a1 + · · · + an0
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
an0+1 + · · · + an
(cid:12)
(cid:12)
n
(cid:12)
(cid:15) + · · · + (cid:15)
n
n − n0
n

(cid:15)

+

+

+

Tomando n → ∞, segue que

(cid:12)
(cid:12)
(cid:12)
(cid:12)

a1 + · · · + an
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

→ 0.

Teorema 4.3.5 (A Lei Forte de Kolmogorov). Sejam X1, X2, . . . variáveis aleatórias inde-
pendentes, identicamente distribuídas e integráveis, com E(Xn) = µ. Então

X1 + · · · + Xn
n

qc
−→ µ.

Demonstração. Como no teorema anterior, basta supor µ = 0.

Deﬁnimos os truncamentos de Xn como

Yn = XnI[−n<Xn≤n] =




Xn se − n < Xn ≤ n



0 caso contrário,

54

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

isto é, Yn = XnI[−n<Xn≤n].

Deﬁnimos Zn = Xn − Yn, de modo que Xn = Yn + Zn e

X1 + · · · + Xn
n

=

Y1 + · · · + Yn
n

+

Z1 + · · · + Zn
n

.

Vamos dividir a demonstração em 3 partes:

(a)

(b)

(c)

Z1 + · · · + Zn
n

qc
−→ 0 (usaremos Borel-Cantelli),

Y1 + · · · + Yn
n

−

E(Y1) + · · · + E(Yn)
n

qc
−→ 0 (Lema 4.3.3 e Teorema 4.3.2),

E(Y1) + · · · + E(Yn)
n

→ 0 (pelo Teorema da Convergência Dominada).

Notemos que (a), (b) e (c) implicam o teorema, pois se

A =

(cid:20)Z1 + · · · + Zn
n

(cid:21)

→ 0

e B =

(cid:20) Y1 + · · · + Yn
n

−

E(Y1) + · · · + E(Yn)
n

(cid:21)

→ 0

,

então somando os três termos na interseção dos eventos quase certos de (a) e (b), segue
que

P(A) = 1, P(B) = 1, P(A ∩ B) = 1 e

→ 0 em A ∩ B.

X1 + · · · + Xn
n

Prova de (a). Notemos que Zn (cid:54)= 0 ⇔ Yn (cid:54)= Xn ⇔ Xn /∈ (−n, n]. Logo,

P(Zn (cid:54)= 0) = P(Xn /∈ (−n, n]) ≤ P(|Xn| ≥ n).

Seja, An = [Zn (cid:54)= 0]. Como as Xn(cid:48)s são identicamente distribuídas, temos pelo Corolário
3.1.11 que

∞
(cid:88)

n=1

P(An) ≤

∞
(cid:88)

(P|Xn| ≥ n) =

n=1

∞
(cid:88)

n=1

P(|X1| ≥ n) = E(|X1|) < ∞.

Pelo Lema de Borel-Cantelli segue que P(An inﬁnitas vezes) = P(Zn (cid:54)= 0 inﬁnitas vezes) =

0. Tomando o complementar, obtemos

P(Zn (cid:54)= 0 para apenas um número ﬁnito de n) = 1,

isto é,

P(Zn = 0 para todo n suﬁcientemente grande) = 1.

Pelo Lema de Borel-Cantelli, se Zn = 0 para n suﬁcientemente grande, então Zn → 0

e, pelo lema anterior,

Z1 + · · · + Zn
n

→ 0, logo P

(cid:18) Z1 + · · · + Zn
n

(cid:19)

→ 0

= 1.

4.3. A LEI FORTE DOS GRANDES NÚMEROS

55

Prova de (b). Seja F a função de distribuição de todos os Xn(cid:48)s, ou seja F = FXn. Va-
mos mostrar que valem as hipóteses da primeira Lei Forte de Kolmogorov para as
variáveis aleatórias Yn. Temos

V ar(Yn) ≤ E(Y 2

n ) = E(X 2

nI[−n<Xn≤n]) =

(cid:90)

x2I[−n,n](x)dF (x) =

n
(cid:90)

−n

x2dF (x),

logo

∞
(cid:88)

n=1

V ar(Yn)
n2

≤

∞
(cid:88)

n=1

1
n2

(cid:90) n

−n

x2dF (x) < ∞.

Daí segue que as Yn(cid:48)s satisfazem a primeira Lei Forte, o que prova (b).

Prova de (c). Pelo Lema 4.3.4 basta mostrar que E(Yn) → 0. Notemos que |X1I[−n<X1≤n]| ≤
|X1|, que é integrável por hipótese. Além disso, [−n < X1 ≤ n] = {ω; −n < X1(ω) ≤
n} ↑ Ω, de modo que I[−n<X1≤n] → 1 ∀ω, ou seja, X1I[−n<X1≤n] → X1. Como as Xn(cid:48)s são
identicamente distribuídas, segue pelo Teorema da Convergência Dominada que

E(Yn) = E(XnI[−n<Xn≤n]) = E(X1I[−n<X1≤n]) → E(X1) = 0.

Corolário 4.3.6 (Lei Forte de Borel, 1909). Sendo X1, X2, . . . variáveis aleatórias indepen-
dentes e identicamente distribuídas tais que P(Xn = 1) = p, P(Xn = 0) = 1 − p. Portanto
Sn
n

qc
−→ p, onde Sn = X1 + · · · + Xn.

56

CAPÍTULO 4. A LEI DOS GRANDES NÚMEROS

Capítulo 5

Números Normais e
pseudo-aleatoriedade

5.1 Números normais

Seja x ∈ [0, 1] escrito na base b ≥ 2 como x = 0, x1x2x3 . . . , isto é, x =

xn
bn .
Notemos que tal expansão pode não ser única: de fato, alguns racionais possuem duas
expansões. Por exemplo, na base 10, temos 0, 1999 · · · = 0, 2 = 0, 2000 . . . . Quando este
for o caso, tomemos a expansão que termina com 0(cid:48)s.

∞
(cid:80)
n=1

Seja A = (ak−1 . . . a0)b = ak−1bk−1 + · · · + a1b + a0 um número inteiro com no máximo
k dígitos na expansão em base b. Denotamos A como um bloco de tamanho k. Seja
N (A; n; x) o número de vezes em que o bloco A aparece entre os primeiros n dígitos do
número x.

Exemplo 5.1.1. Fixado b = 10, N (12; 20; 0, 123456789101112131415 . . . ) = 2.

Fixado b = 2, N (1; 10; 0, 101001000100001 . . . ) = 4.

lim
n→∞

Deﬁnição 5.1.2. Dizemos que x é normal na base b se para todo k ≥ 1 e todo bloco A de tama-
nho k, a frequência relativa de aparições de A na expansão de x é a mesma. Mais formalmente,
x é normal na base b se

N (A; n; x)
n
Exemplo 5.1.3. Números racionais não são normais em nenhuma base, pois: (i) a expansão
“termina” e a partir de um determinado ponto todos os algarismos são iguais a zero; (ii) a
expansão sendo uma dízima periódica, ela se repete, o que implica em convergência para 1
do bloco que se repete. Para outros blocos, a convergência pode ser para outros valores. Por
exemplo, no número racional 0, 123123123123123 . . . , a frequência dos blocos 123, 231 e 312
tende a 1, enquanto a frequência do bloco 1234 é 0; além disso, a frequência do bloco 23 tende a
1
3, enquanto a frequência do bloco 24 é 0.

1
bk .

=

57

58

CAPÍTULO 5. NÚMEROS NORMAIS E PSEUDO-ALEATORIEDADE

Foi provado em [5] que o número 0, 12345678910111213141516 . . . formado pela
concatenação dos números naturais após a vírgula é normal na base 10. Analoga-
mente, pode-se provar que números desse mesmo formato em outras bases também
são normais nessas bases.

O próximo resultado, devido a Borel, é dos principais teoremas desse trabalho.

Teorema 5.1.4 (Borel [3]). Fixada uma base b, “quase todos” os números reais são normais na
base b, onde usamos a expressão “quase todos” no sentido de Lebesgue.

Demonstração. Sejam Ω = [0, 1], A a σ-álgebra dos borelianos de [0, 1] e P a probabili-
dade uniforme em [0, 1], que coincide com a medida de Lebesgue (ver Apêndice A).
Por simplicidade, vamos provar somente alguns casos desse teorema, mas deixando
claro que o método funciona em qualquer caso, bastando poucas modiﬁcações no ar-
gumento. A primeira simpliﬁcação que faremos é considerar b = 2 (para outras bases,
o resultado é completamente análogo). Vamos considerar também blocos de tamanhos
1 e 2.

Para blocos de tamanho 1 na base 2, as únicas possibilidades são 0 e 1. Seja x =
xn
2n ∈ [0, 1], onde xi ∈ {0, 1}. Vamos deﬁnir a seguinte sequência de

0, x1x2x3 · · · =

∞
(cid:80)
n=1

variáveis aleatórias:








0 se x ∈ [0, 1/2),

1 se x ∈ [1/2, 1],

0 se x ∈ [0, 1/4) ∪ [1/2, 3/4),



1 se x ∈ [1/4, 1/2) ∪ [3/4, 1],

X1(x) =

X2(x) =

. . .

Notemos que Xn(x) = xn. Além disso, P(Xn = 0) = 1/2 = P(Xn = 1), logo as variá-
veis aleatórias Xn são identicamente distribuídas. Nesse caso, essas variáveis também
são independentes. De fato, por exemplo, P(X1 = 1 e X2 = 0) = P([1/2, 3/4)) =
1/4 = P(X1 = 1)P(X2 = 0) (para os demais caso é completamente análogo). Além
disso, E(Xn) = 1/2 para todo n, logo a Lei Forte (Corolário 4.3.6) nos garante que
X1+···+Xn
2 para quase todo x.
n
Para blocos de tamanhos maiores, só precisamos de uma pequena modiﬁcação no
argumento. Por exemplo, se queremos saber a frequência relativa do bloco 10, consi-
deramos a seguinte sequência:

2, isto é, x1+···+xn

n → 1

qc
−→ 1

yn =




1 se xn = 1 e xn+1 = 0,



0 caso contrário.

5.1. NÚMEROS NORMAIS

59

Por exemplo, se x = 0, 11100010110001 . . . então y1 = y2 = 0, y3 = 1, y4 = y5 = y6 =
0, y7 = 1, . . . . Para identiﬁcar a frequência relativa, basta calcular o valor de y1+···+yn
quando n é grande. Para isso, seja Yn = Xn(1−Xn+1) para n ≥ 1. Podemos veriﬁcar que
essa sequência de variáveis aleatórias é identicamente distribuída de forma análoga ao
caso anterior, mas elas não são independentes. De fato, temos P(Yn = 1) = P(Xn =
1 e Xn+1 = 0) = 1/4, logo P(Yn = 0) = 3
4. Por outro lado, P(Y1 = 1 e Y2 = 1) = P(x1 =
1 e x2 = 0 e x2 = 1 e x3 = 0) = 0 (cid:54)= 1
16 = P(Y1 = 1)P(Y2 = 1). Informalmente, podemos
pensar que xn inﬂuencia em Yn−1 e em Yn. Mas isso pode ser contornado tomando duas
subsequências de Yn: as de índice par (Y2n) e as de índice ímpar (Y2n+1). Similar ao
caso anterior, é possível mostrar que separadamente, cada uma dessas subsequências
são independentes. Pela Lei Forte, obtemos

n

Y1 + Y3 + · · · + Y2n−1
n

qc
−→

1
4

Y2 + Y4 + · · · + Y2n
n

qc
−→

1
4

.

O restante do argumento segue da seguinte forma: se calcularmos a frequência até um
índice par, teremos

Y1 + Y2 + · · · + Y2n
2n

=

(cid:18) Y1 + Y3 + · · · + Y2n−1
n

1
2

+

Y2 + Y4 + · · · + Y2n
n

(cid:19) qc
−→

1
4

.

Se calcularmos a frequência até um índice ímpar, usamos o índice par anterior para
mostrar que os limites são iguais. De fato, usando a desigualdade triangular, obtemos

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Y1 + · · · + Y2n+1
2n + 1

−

Y1 + · · · + Y2n
2n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

=

|2n(Y1 + · · · + Y2n+1) − (2n + 1)(Y1 + · · · + Y2n)|
2n(2n + 1)

|2nY2n+1 − (Y1 + · · · + Y2n)|
2n(2n + 1)

≤

1
2n + 1

→ 0.

Deﬁnição 5.1.5. Se x é normal na base b para todo b ≥ 2, então x é dito absolutamente
normal.

Corolário 5.1.6. Quase todos os números do intervalo [0, 1] são absolutamente normais.

Demonstração. Seja Ab = [x é normal na base b]. Pelo Teorema 5.1.4, temos P(Ab) = 1
para todo b ≥ 2. Pela Proposição 1.1.14, segue que P( (cid:84)

Ab) = 1.

b≥2

A noção contra intuitiva do último resultado vem do fato de que ninguém até hoje
consegue encontrar um exemplo de número absolutamente normal, apesar de quase

60

CAPÍTULO 5. NÚMEROS NORMAIS E PSEUDO-ALEATORIEDADE

todos os números reais serem dessa forma.

5.2 Números aleatórios e pseudoaleatórios

Um problema fundamental na Matemática, na Estatística e na Computação é a ge-
ração de números aleatórios, que possuem diversas aplicações práticas, dentre as quais
podemos destacar o Método de Monte-Carlo [8, 9], que é uma classe de métodos esta-
tísticos que se baseia em amostragens aleatórias muito grandes para obter resultados
numéricos. A princípio, podem ser utilizados para resolver quaisquer problemas com
interpretação probabilística . Números absolutamente normais são candidatos ideais a
serem números aleatórios, mas ainda não os conhecemos concretamente. Sendo assim,
devemos nos contentar com números pseudoaleatórios, que são números “aparente-
mente” aleatórios, mas que são gerados de uma forma determinística. Intuitivamente,
todos os números que conseguimos pensar são pseudoaleatórios.

5.3 Blocos de dígitos iguais

Nessa seção, usamos o website 4Devs Ferramentas Online [1] para gerar o seguinte

número binário com 200 dígitos:

00100011111001100011011000101101101101101111000100

11101001000110110001101010001111001010110010001000

01001000111001100010010101110100101111101000010001

10111100100110001100010011000001001011110000000101

Notemos que os 10 últimos dígitos são 0000000101, ou seja, no número gerado há
um bloco de tamanho 7 formado apenas por zeros. Parece contra-intuitivo que exista
um bloco tão grande formado pelo mesmo dígito, mas veremos a seguir que não é.
De fato, vamos dividir esse número em 40 blocos de 5 dígitos cada. Vamos chamar de
sucesso a ocorrência do bloco 00000 e fracasso a ocorrência de quaisquer dos 31 blocos
possíveis de tamanho 5 com pelo menos um dígito 1. Temos portanto um modelo de
Bernoulli com parâmetro 1
32, e a média de tempo até o primeiro sucesso é dado pelo
modelo geométrico: no caso, tal média é de 32 blocos pelo Exemplo 3.1.13. Como há
40 blocos, existe uma alta probabilidade do bloco 00000 aparecer pelo menos uma vez
no número gerado.

Fazendo um paralelo com os números normais na base 2, o bloco 00000 também
32 para quase todo número gerado aleatoriamente.

deve aparecer com uma frequência 1

5.4. O PROBLEMA DE MONTY-HALL

61

Por isso podemos pensar que os números (absolutamente) normais são os melhores
exemplos de números aleatórios.

No Capítulo 6, veremos uma atividade relacionada a esse problema contra-intuitivo

de encontrar blocos formados pelos mesmos dígitos.

5.4 O problema de Monty-Hall

Também conhecido popularmente como problema dos bodes, é um famoso jogo
que foi proposto pela primeira vez em um programa de auditório nos EUA. O jogo
consistia no seguinte: havia três portas numeradas de 1 a 3. Atrás de uma delas ha-
via um prêmio e atrás das outras duas havia bodes. Somente o apresentador do pro-
grama sabia onde estava o prêmio. Inicialmente, o jogador escolhe uma das portas,
mantendo-a fechada. Em seguida, o apresentador abre uma das outras duas portas
revelando um dos bodes. Posteriormente, o apresentador pergunta ao jogador se ele
escolhe manter a mesma porta ou trocar de porta, sendo que agora só há duas portas
disponíveis para o prêmio. A pergunta natural é: qual é a melhor estratégia? Trocar
ou não trocar? A probabilidade de ganhar o prêmio se altera de alguma forma?

Intuitivamente, podemos pensar que após a abertura da porta contendo um dos
bodes, teremos duas portas e chances iguais para cada uma delas, isto é, uma proba-
bilidade igual a 1
2 a partir desse momento. Com isso, não importaria se ﬁzéssemos ou
não a troca de porta. Mas essa resposta está errada, como veremos a seguir de duas
formas distintas: Na primeira, vamos simular o problema diversas vezes e tentar adi-
vinhar a resposta com base na lei dos grandes números. Na segunda, vamos de fato
resolver analiticamente o problema.

Para fazer a simulação do problema, usamos o website 4Devs Ferramentas Online
[1], que consegue gerar números pseudo-aleatórios de diversas formas. Para isso, ge-
ramos 100 números em {1, 2, 3} para designar onde está o prêmio, e posteriormente
geramos 100 números no mesmo conjunto para designar qual foi a porta escolhida
inicialmente. Os números gerados estão compilados nas tabelas a seguir:

62

CAPÍTULO 5. NÚMEROS NORMAIS E PSEUDO-ALEATORIEDADE

2

2

1

2

1

1

3

3

2

1

3

1

3

1

1

1

2

1

1

2

1 2

1 3

2 1

1 2

2 2

1 3

2 1

3 2

1 2

1 3

2

1

1

2

1

2

1

2

1

2

1

2

3

3

2

1

1

3

2

1

2

1

3

3

3

3

3

3

3

3

3 2

3 1

3 3

3 2

1 1

1 3

3 3

2 1

3 3

2 1

1

1

2

1

1

2

2

3

3

3

Tabela 5.1: Porta onde está o prêmio

2

2

3

3

3

2

3

1

1

3

1

1

1

1

3

2

3

2

3

3

3 3

1 2

1 2

2 2

3 1

3 2

1 2

3 3

2 1

2 3

2

1

2

3

2

1

1

2

1

2

2

3

3

1

1

2

1

1

2

2

3

2

2

1

1

2

2

1

2

3

1 2

3 3

2 2

2 2

1 3

2 1

2 3

2 2

3 3

3 1

1

1

2

3

3

1

3

3

2

3

Tabela 5.2: Porta que escolhemos inicialmente

A próxima tabela apresenta a diferença (em módulo) entre os respectivos valores
das duas tabelas anteriores. Notemos que se tal diferença for 0 na tabela a seguir e
trocarmos de porta, então perdemos o prêmio. Além disso, se tal diferença for distinta
de 0 e trocarmos de porta, então ganhamos o prêmio.

5.4. O PROBLEMA DE MONTY-HALL

63

0

0

2

1

2

1

0

2

1

2

2

0

2

0

2

1

1

1

2

1

2 1

0 1

1 1

1 0

1 1

2 1

1 1

0 1

1 1

1 0

0

0

1

1

1

1

0

0

0

0

1

1

0

2

1

1

0

2

0

1

1

1

1

2

2

1

1

2

1

0

2 0

0 2

1 1

1 0

0 2

1 2

1 0

0 1

0 0

1 0

0

0

0

2

2

1

1

0

1

0

Tabela 5.3: Módulo da diferença entre as respectivas entradas das Tabelas 5.1 e 5.2

Se der 0 aqui, quer dizer que escolhemos a porta certa inicialmente, e ao trocar de
porta vamos perder. Se der diferente de 0, quer dizer que escolhemos a porta errada
inicialmente, mas ao trocar vamos ganhar. Observemos que há 33 zeros e 67 uns e dois
na tabela anterior. Isso signiﬁca que ao trocar de porta vamos conseguir o prêmio em 67
das 100 simulações. Notemos também que se tivéssemos feito uma quantidade menor
de simulações, então os resultados poderiam se alterar um pouco, mas ainda assim os
números indicariam uma tendência a trocar de porta. Por exemplo, considerando os
10 primeiros números gerados (1ª linha), teríamos ganhado 6 vezes e perderíamos 4
vezes ao trocar de porta. Considerando os 30 primeiros números gerados (3 primeiras
linhas), teríamos ganhado 18 e perdido 12 vezes ao trocar de porta.

Tamanho da simulação

10 30 100

Ao trocar de porta, ganhamos o prêmio em

6

Não trocando de porta, ganhamos o prêmio em 4

18

12

67

33

Tabela 5.4: Compilação dos resultados das simulações

Com os resultado apresentados e pela garantia dada pela Lei dos Grandes Núme-
ros, parece razoável concluir que trocar de porta é mais vantajoso pois oferece uma
possibilidade maior de ganhar o prêmio; ao que tudo indica, trocar de porta apresenta
uma probabilidade de ganhar o prêmio em 2
3 das vezes a medida que o número de
simulações ﬁca grande o suﬁciente.

Agora vamos resolver analiticamente o problema. A melhor estratégia é trocar de
porta, pois nesse caso nossa chance de ganhar o prêmio seria de 2
3. De fato, se não tro-
carmos, a única chance de ganhar seria ter escolhido a porta certa no primeiro passo,
que corresponde a uma probabilidade igual a 1
3. Com isso, ao trocar de porta, nossa

64

CAPÍTULO 5. NÚMEROS NORMAIS E PSEUDO-ALEATORIEDADE

chance passa a ser o complementar: 2
3. Outra forma de analisar o problema é a se-
guinte: suponhamos que dizemos sempre “sim” à troca de portas. Vamos supor sem
perda de generalidade que o prêmio esteja na porta 1. Temos três possibilidades: Se
escolhermos a porta 1 inicialmente, então o apresentador irá abrir alguma das portas 2
e 3. Ao trocar de porta, perdemos o prêmio. Se escolhermos a porta 2 inicialmente, en-
tão o apresentador irá abrir a porta 3 obrigatoriamente. Ao trocar de porta, vencemos.
De forma análoga, se escolhermos a porta 3 inicialmente e trocarmos, então vencemos.
Logo respondendo “sim” à troca, vencemos em 2 das 3 possibilidades, que são equi-
prováveis. Ao dizer “não” à troca, temos o complementar de chances para vencer: 1
3.
Alternativamente, podemos analisar o problema com 50 portas: em 49 delas há bodes
e na restante há um prêmio. Inicialmente, escolhemos uma porta e dentre as 49 por-
tas restantes o apresentador abre 48, revelando bodes. Nesse momento, com apenas
duas portas disponíveis, ele nos dá a escolha de trocar ou manter a nossa porta inicial.
Agora sim ﬁca claro que a melhor estratégia é trocar de porta. No Capítulo 6, veremos
uma atividade relacionada ao problema de Monty-Hall.

Capítulo 6

Aplicações em sala de aula

Neste capítulo, apresentaremos as atividades práticas realizadas com estudantes
do Ensino Médio e com alunos da graduação em Matemática. Devido ao período de
pandemia do novo Coronavírus no ano de 2021, todas as orientações foram feitas de
modo não presencial, utilizando de ferramentas digitais de comunicação. O objetivo
principal foi apresentar a Lei dos Grandes Números para os estudantes, aplicar duas
atividades relacionadas aos números aleatórios e ao Problema de Monty-Hall e mos-
trar aos estudantes que esses são problemas com respostas altamente contra intuitivas.
Essa pesquisa só foi realizada após anuência da escola envolvida, do PROFMAT-UFOP,
dos coordenadores do Bacharelado e da Licenciatura em Matemática na UFOP, dos es-
tudantes e dos pais ou responsáveis pelos menores de idade (após obtenção do termo
de consentimento livre e esclarecido por parte dos participantes e dos pais ou respon-
sáveis pelos estudantes menores de idade) e só ocorreu após a aprovação do projeto
junto ao Comitê de Ética em Pesquisa da Universidade Federal de Ouro Preto.

A mesma atividade foi aplicada nos dois grupos de estudantes, com direcionamen-
tos de acordo com a escolaridade de cada um deles, e com o objetivo de observar suas
percepções. A atividade foi aplicada em um único encontro com cada grupo atra-
vés de videoconferência utilizando o Google Meet como aplicativo de comunicação, o
Power Point para apresentação, o website 4Devs: Ferramentas Online [1] para simulações
e geração de sequências de números aleatórios e o aplicativo Whiteboard, que funciona
como um quadro branco, para complementação das explicações e apoio.

6.1

Justiﬁcativa e Relevância

A Lei dos Grandes Números é um importante resultado em Teoria das Probabilida-
des, que possui diversas aplicações nas demais áreas do conhecimento. Nesse projeto,
apresentamos duas dessas aplicações: a primeira na identiﬁcação de números pseu-

65

66

CAPÍTULO 6. APLICAÇÕES EM SALA DE AULA

doaleatórios e a segunda para abordar o problema de Monty-Hall, com o objetivo de
instigar os estudantes a buscar soluções alternativas para problemas práticos; em par-
ticular, usando a Lei dos Grandes Números.

Gerar e identiﬁcar números aleatórios é um problema fundamental da Matemática,
Estatística e Computação, que possui inúmeras aplicações práticas, dentre as quais
citamos o Método de Monte Carlo [8, 9]. Por outro lado, o problema de Monty-Hall
é um problema que desperta a curiosidade dos alunos, visto que é um jogo de fácil
entendimento.

6.2 Roteiro da atividade

A pesquisa foi aplicada a 28 alunos do Ensino Médio de uma escola em Manhumirim-

MG, onde o mestrando Luciano Carlos de Lemos leciona a disciplina Matemática, e a
02 alunos do curso de Matemática (Bacharelado) da UFOP. Para cada um dos públicos-
alvo separadamente, foi suﬁciente um encontro com duração de cerca de 120 minutos
para a apresentação dos conceitos e dos problemas, para realização da atividade, pre-
enchimento dos questionários e para a apresentação da resolução.

6.2.1 Objetivos

• Introduzir conceitos de probabilidade a estudantes do Ensino Médio e Superior;

• Introduzir a Lei dos Grandes Números a esses estudantes;

• Apresentar os números normais e pseudoaleatórios, juntamente com sua impor-

tância;

• Veriﬁcar se um número dado pode ser considerado aleatório;

• Apresentar o problema de Monty-Hall e instigar as respostas dos estudantes;

• Exibir as soluções corretas aos estudantes.

6.2.2 Metodologia

A atividade foi conduzida pelo mestrando, que mediou as discussões de modo
a levar os alunos a concluírem que todos os números que conseguimos pensar são
pseudoaleatórios, isto é, números “aparentemente” aleatórios, mas que são gerados
de uma forma determinística; o que é uma noção contra intuitiva desse problema, já
que é possível provar (ver Corolário 5.1.6), que “quase todos” os números reais são

6.2. ROTEIRO DA ATIVIDADE

67

absolutamente normais, e que esses são os melhores candidatos a números aleatórios.
No caso do Problema de Monty-Hall, espera-se que os alunos concluam após as simu-
lações que a melhor estratégia é trocar de porta. Em seguida será apresentada uma
solução analítica para o problema. O registro das atividades foi feito através da plata-
forma Google Meet, tanto com a gravação quanto com o arquivo com as mensagens de
texto. As impressões dos alunos, algumas de suas falas e respostas a perguntas feitas
pelo mestrando também foram registradas através do Chat do Google Meet ou através
de manifestações durante as atividades. Também foram aplicados questionários com
o objetivo de obtermos informações sobre as impressões dos participantes acerca das
atividades.

6.2.3 Descrição das Atividades

Atividade 1: Números normais e pseudoaleatórios

Os alunos foram apresentados aos números normais e aos pseudoaleatórios, além
de suas propriedades e utilidades. Explicamos o problema de gerar e identiﬁcar nú-
meros aleatórios. Após isso, tentamos criar um número binário aleatório grande da
seguinte forma: No ensino médio, convidamos cada um dos 28 estudantes a escre-
ver uma sequência binária de 8 dígitos, e em seguida concatenamos as sequências de
todos os estudantes obtendo uma sequência com aproximadamente 200 dígitos. No
ensino superior, convidamos a única estudante presente no momento para que escre-
vesse uma sequência binária de 100 dígitos. A seguir, indicamos aos participantes que
respondessem à 1ª pergunta relativa a esse problema. Após isso, apresentamos um
cálculo de forma a mostrar que a sequência obtida possui propriedades que a tornam
provavelmente pseudoaleatória. Com isso, os participantes foram convidados a res-
ponder às demais perguntas relativas a esse problema.

Perguntas: Números normais e pseudoaleatórios

1. Você acha que o número obtido a partir da concatenação parece aleatório? Ou

você o classiﬁcaria como pseudoaleatório? Por quê?

2. Após os cálculos apresentados, você mantém a resposta da pergunta 1?

3. O que você achou dessa aplicação da matemática?

4. Você consegue pensar em outra aplicação da geração de números aleatórios?

Qual?

68

CAPÍTULO 6. APLICAÇÕES EM SALA DE AULA

Atividade 2: O Problema de Monty-Hall

Os alunos foram apresentados às regras do problema de Monty-Hall, também co-
nhecido popularmente como problema dos bodes, um famoso jogo que foi proposto
pela primeira vez em um programa de auditório nos EUA. O jogo consistia no seguinte:
havia três portas numeradas de 1 a 3. Atrás de uma delas havia um prêmio e atrás das
outras duas havia bodes. Somente o apresentador do programa sabia onde estava o
prêmio.
Inicialmente, o jogador escolhe uma das portas, mantendo-a fechada. Em
seguida, o apresentador abre uma das outras duas portas, revelando um dos bodes.
Posteriormente, o apresentador pergunta ao jogador se ele escolhe manter a mesma
porta ou trocar de porta, sendo que agora só há duas portas disponíveis para o prê-
mio. Neste momento, os estudantes são convidados a responder à 1ª pergunta relativa
a esse problema. Em seguida, apresentamos uma visão probabilística para o problema,
simulando computacionalmente o problema 100 vezes, daí os estudantes foram guia-
dos à 2ª e 3ª perguntas. Após discussão e a apresentação de uma solução analítica, os
estudantes responderam à 4ª pergunta.

Perguntas: O Problema de Monty-Hall

1. Qual seria a sua estratégia? Mudar de porta ou manter? Por quê?

2. Após ver o resultado gerado pela simulação, qual seria a sua estratégia?

3. Ao trocar de porta, qual é a probabilidade de ganhar o prêmio? Por quê?

4. Você consegue pensar em outra aplicação da Lei dos Grandes Números para

“prever” a solução de algum problema? Qual?

Durante toda a atividade os estudantes foram incentivados a fazerem perguntas, a

interagirem e a indicarem suas dúvidas.

6.3 Análise dos Questionários

Realizamos agora a análise dos questionários aplicados aos estudantes durante as
atividades. Tais questionários pretendiam nos permitir uma coleta das impressões e
opiniões dos estudantes em relação ao tema proposto.

A mesma atividade e os mesmos questionários foram aplicados aos estudantes do
Ensino Médio e da graduação em Matemática, com o objetivo de veriﬁcar as semelhan-
ças e diferenças na percepção que cada grupo teria a partir da aplicação das atividades.

6.3. ANÁLISE DOS QUESTIONÁRIOS

69

Na Atividade 1, o questionário teve como objetivo veriﬁcar se os estudantes te-
riam algum conhecimento sobre o conceito números aleatórios e pseudoaleatórios,
bem como da importância e aplicabilidade da geração de números aleatórios.

Na Atividade 2, o questionário pretendia na primeira pergunta registrar o solução
intuitiva dada pelos estudantes ao Problema de Monty-Hall, e nas outras perguntas,
após a simulação, registrar suas conclusões e outras aplicações para a Lei dos Grandes
Números.

6.3.1 Análise das respostas dos estudantes do Ensino Médio

Atividade 1: Números normais e pseudoaleatórios

A 1ª pergunta da Atividade 1 tinha por objetivo investigar se os estudantes apre-
sentavam algum conhecimento empírico sobre números aleatórios e pseudoaleatórios.

1. Você acha que o número obtido a partir da concatenação parece aleatório? Ou você

o classiﬁcaria com pseudoaleatório? Por quê?

Catorze estudantes responderam que parece aleatório, apresentando como justiﬁca-
tiva o fato de que “não existe uma ordem lógica na escolha dos números” ou ainda,
“porque foi formado por vários números intuitivos de cada aluno(a)”. Outros ca-
torze estudantes responderam que parece pseudoaleatório, sendo que uma aluna
justiﬁcou sua resposta dizendo: “Parece pseudoaleatório, porque apesar da escolha
ser individual, a maioria dos alunos podem optar por padrões de repetição como a
alternância dos números ou a repetição dos números em conjuntos pares”.

A 2ª pergunta pretendia, após a apresentação da deﬁnição de números aleatórios e
pseudoaleatórios e de alguns cálculos com o número formado anteriormente, veriﬁcar
se os estudantes mudariam a opinião expressa na pergunta 1.

2. Após os cálculos apresentados, você mantém a resposta da pergunta 1?

Dos 14 que responderam, na pergunta anterior, que o número parece aleatório, 6
mudariam a resposta e 8 manteriam. Dos que responderam se tratar de um número
pseudoaleatório, 10 manteriam a resposta e 4 mudariam.

As perguntas seguintes foram com objetivo de veriﬁcar qual a percepção dos estu-

dantes dessa aplicação e se conseguiam pensar em outras aplicações.

70

CAPÍTULO 6. APLICAÇÕES EM SALA DE AULA

3. O que você achou dessa aplicação da Matemática?

Algumas das respostas dos estudantes foram: “interessante”; “complicada de en-
tender”; “fora do comum”; “incrível ver com a matemática pode ser a base para
a resolução de problemas de diversas áreas”; “que apesar de certa aleatoriedade
ainda conseguimos achar sequências de padrões”; etc.

4. Você consegue pensar outra aplicação da geração de números aleatórios? Qual?

Treze alunos não conseguiram pensar em outra aplicação; mas quinze alunos disse-
ram que sim, principalmente para “criação de senhas e códigos”, “programação de
computador”, “jogos do tipo bingo”, etc.

Atividade 2: O Problema de Monty-Hall

A 1ª pergunta dessa atividade objetivava registrar a intuição dos estudantes em

relação à solução do problema.

1. Qual seria sua estratégia? Mudar de porta ou manter? Por quê?

Nove participantes mudariam, por achar que assim teriam mais chances. Cinco
acham que tanto faz (mudar ou manter), pois a chances são iguais. Catorze mante-
riam a 1ª escolha, pois “acreditam na intuição”, e alguns relataram que “o apresen-
tador poderia estar tentando induzí-los ao erro”.

A 2ª e a 3ª perguntas tinham como objetivo ver a percepção dos estudantes em rela-
ção ao problema após simularmos o mesmo 100 vezes. Cabe ressaltar que a simulação
gerou o seguinte resultado: ao trocar de porta, o jogador vence 67 vezes; não trocando,
vence 33 vezes.

2. Após a simulação, qual seria sua estratégia?

Três alunos responderam que permaneceriam com a sua escolha inicial, pois ainda
acham que as chances continuariam as mesmas. Mas 25 trocariam de porta, pois
viram na simulação que das 100 vezes em que trocassem de porta, ganhariam em
67 delas e perderiam em 33 vezes.

6.3. ANÁLISE DOS QUESTIONÁRIOS

71

3. Ao trocar de porta, qual é a probabilidade de ganhar o prêmio? Por quê?

Algumas das respostas foram: 67 vezes em 100; 2
simulação.

3; 66, 6%; pois foi o que viram na

Após uma apresentação analítica da resolução do problema, os estudantes foram
convidados a responder à 4ª pergunta, com o objetivo de veriﬁcarmos se eles conse-
guiam pensar outra aplicação da Lei dos Grandes Números na “previsão” da solução
de problemas.

4. Você consegue pensar outra aplicação da Lei dos Grandes Números para “prever”

a solução de algum problema? Qual?

Dez alunos não conseguiram pensar em outra aplicação, mas 18 responderam que
sim, principalmente, nas previsões do tempo e desastres naturais, jogos de loteria,
pesquisas de intenção de voto, estatísticas em geral.

Analisando as respostas dos questionários e a participação dos estudantes durante
as atividades, observamos que eles demonstraram uma satisfatória compreensão do
conteúdo e que as atividades despertaram neles a curiosidade para problemas com
soluções muito das vezes contra intuitivas.

6.3.2 Análise das respostas dos estudantes da Graduação em Mate-

mática

Todos os alunos da graduação em Matemática da UFOP foram convidados para
participar da pesquisa, porém somente dois alunos efetivamente aceitaram o convite,
sendo que a Atividade 1 foi realizada apenas por uma estudante. Os objetivos dos
questionários foram os mesmos citados para os alunos de Ensino Médio, porém com
uma expectativa de que as respostas fossem mais elaboradas, visto a maior experiência
desses alunos.

Atividade 1: Números normais e pseudoaleatórios

1. Você acha que o número obtido a partir da concatenação parece aleatório? Ou você

o classiﬁcaria com pseudoaleatório? Por quê?

A participante respondeu “aleatório. Pois os algarismos foram escolhidos aleatori-
amente”.

72

CAPÍTULO 6. APLICAÇÕES EM SALA DE AULA

2. Após os cálculos apresentados, você mantém a resposta da pergunta 1?

A participante disse que “não”.

3. O que você achou dessa aplicação da Matemática?

A estudante disse: “Achei curiosa, pois é contra intuitivo. À princípio se espera não
obter nenhuma relação do número descrito, uma vez que supôs ser aleatório”.

4. Você consegue pensar outra aplicação da geração de números aleatórios? Qual?

Segundo a participante, “talvez em corretor de código de erros”1.

Atividade 2: O Problema de Monty-Hall

Dessa atividade participaram dois estudantes.

1. Qual seria sua estratégia? Mudar de porta ou manter? Por quê?

Um respondeu que manteria, pois aparentemente não muda a probabilidade. Já o
outro respondeu que mudaria, pois a chance de escolher o bode na primeira escolha
é 2
3.

Aqui, simulamos o problema 100 vezes e o resultado foi: o participante ganha 66

vezes ao trocar de porta e ganha 34 vezes ao não trocar.

2. Após a simulação, qual seria sua estratégia?

Os dois responderam que mudariam de porta.

3. Ao trocar de porta, qual é a probabilidade de ganhar o prêmio? Por quê?

Um deles respondeu “ 2
3, pois você tem que ter errado a primeira escolha e acertar a
segunda escolha”; já o outro respondeu “66%, de acordo com a simulação a chance
é essa”.

1Códigos corretores de erros

6.3. ANÁLISE DOS QUESTIONÁRIOS

73

4. Você consegue pensar outra aplicação da Lei dos Grandes Números para “prever”

a solução de algum problema? Qual?

Segundo os participantes, pode ser aplicada em “jogos de baralho, como tapão, pifê,
truco, poker” e no “jogo de tampinhas, em que um objeto é colocado embaixo das
tampas e as tampas são embaralhadas rapidamente e uma determinada pessoa tem
que descobrir onde está o objeto”.

Analisando as respostas dos questionários e a participação dos estudantes, apesar
de uma amostra muito pequena, percebemos que o conteúdo abordado ainda traz uma
série de compreensões intuitivas que muito nos levam ao erro, e que mesmo os alunos
da graduação necessitam de um aprofundamento no estudo da Teoria das Probabili-
dades e de suas aplicações.

74

CAPÍTULO 6. APLICAÇÕES EM SALA DE AULA

Capítulo 7

Conclusões

Nesse estudo, ﬁzemos um compilado de resultados sobre a Teoria das Probabili-
dades, possibilitando assim demonstrar alguns teoremas mais complexos, como a Lei
dos Grandes Números. Desse modo, conseguimos mostrar também algumas aplica-
ções pouco conhecidas como os Números Normais e outras aplicações com resultados
bastante contra intuitivos, como o Problema de Monty-Hall.

Nas atividades aplicadas em sala de aula, pudemos perceber o quanto importante
é trabalhar atividades que estimulam os estudantes a procurar soluções não muito
óbvias. Assim, contribuímos com a formação desses estudantes e com suas percepções
sobre diversos conteúdos e aplicações.

Pessoalmente, pude retomar e aprofundar conteúdos vistos em várias disciplinas
do PROFMAT, que foram fundamentais para o desenvolvimento desse estudo. Em
minha prática proﬁssional, como professor de Matemática no Ensino Médio, esse es-
tudo contribuiu para um maior domínio de alguns conteúdos e principalmente por
acrescentar formas diferentes de abordá-los, sempre buscando um maior interesse e
melhor entendimento dos estudantes.

Assim, posso dizer que as experiências vivenciadas no decorrer desse estudo e du-
rante todo curso PROFMAT me proporcionaram um desenvolvimento pessoal e pro-
ﬁssional muito valioso.

75

76

CAPÍTULO 7. CONCLUSÕES

Apêndice A

Generalizações da integral de Riemann

No Cálculo, aprendemos a integral de Riemann, que é deﬁnida como o limite das
somas das áreas de diversos pequenos retângulos quando a maior das bases tende a
zero, caso esse limite exista. Em outras palavras, se f : [a, b] → R é uma função e
tomamos uma partição x0 = a < x1 < · · · < xn−1 < xn = b, então deﬁnimos

(cid:90) b

a

f (x)dx =

lim
max{xj+1−xj }→0

n−1
(cid:88)

i=0

f (x∗

i )(xi+1 − xi)

quando esse limite existir, onde x∗
i ∈ [xi, xi+1] é um ponto qualquer. É possível provar
[7, Teorema 6 do Capítulo IX] que se f é contínua então a integral de Riemann está bem
deﬁnida no intervalo [a, b]. Mais geralmente, é possível provar (ver [7, Teorema 20 do
Capítulo IX]) que a integral de Riemann está bem deﬁnida se f é limitada e o conjunto
dos seus pontos de descontinuidade tem medida nula. Além disso, dada a hipótese
f é limitada, vale a volta da aﬁrmação anterior. Posteriormente, usando o conceito
de limites, podemos estender a ideia de integrabilidade de funções para intervalos
inﬁnitos: [a, ∞), (−∞, b] e (−∞, ∞), que podem ser vistos como os limites do intervalo
[a, b] quando b → ∞ e a é deixado ﬁxo, quando a → −∞ e b é deixado ﬁxo, e quando
a → −∞ e b → ∞ simultaneamente.

Nesse apêndice, vamos apresentar duas generalizações das integrais de Riemann, a
saber, a integral de Lebesgue e a integral de Riemann-Stieltjes. Por ﬁm, poderemos mis-
turar as duas deﬁnições e considerar a integral de Stieltjes-Lebesgue, que será usada
nos Capítulos 3 e 4.

77

78

APÊNDICE A. GENERALIZAÇÕES DA INTEGRAL DE RIEMANN

A.1 A integral de Lebesgue

A integral de Lebesgue é uma generalização da integral de Riemann e apresenta al-
gumas vantagens com relação à esta. Existem funções que não são Riemann-integráveis,
como f : [0, 1] → R dada por

f (x) =




0



1

se x ∈ Q,
se x ∈ R − Q,

mas que terão um valor bem deﬁnido ao considerar a integral de Lebesgue (no caso
da função acima, a integral valerá 1, uma vez que “quase todos” os números em [0, 1]
são irracionais). A seguir, vamos construir a integral de Lebesgue sobre um espaço de
probabilidade (Ω, A, P).

Seja E ∈ A um evento. Uma função ϕ : E → R ∪ {±∞} é dita função simples se ϕ

assume apenas um conjunto ﬁnito de valores. Em outras palavras,

ϕ(x) =

n
(cid:88)

i=1

aiXEi(x),

onde ai ∈ R ∪ {±∞}, os Ei’s são eventos que podemos supor 2 a 2 disjuntos satisfa-
zendo (cid:83)n

i=1 Ei = E, e XEi é a função indicadora do evento Ei, ou seja,

XEi(x) =




1



0

se x ∈ Ei

se x (cid:54)∈ Ei

.

Convencionando que ±∞ · 0 = 0, deﬁnimos a integral de Lebesgue da função sim-

ples ϕ sobre E como

(cid:90)

E

ϕ(x)dP =

n
(cid:88)

i=1

aiP(Ei).

Deﬁnição A.1.1. Dizemos que uma função f : Ω → R é A-mensurável (ou apenas mensurá-
vel quando não houver dúvidas) se, para todo α ∈ R, o conjunto {x ∈ Ω; f (x) > α} pertence
à σ-álgebra A.

Usando as propriedades de A, é possível provar que o sinal > pode ser substituído

por <, ≥ ou ≤. Além disso, são exemplos de funções mensuráveis:

1. funções indicadoras de eventos,

2. funções simples,

3. funções contínuas sobre R são B-mensurável,

A.1. A INTEGRAL DE LEBESGUE

79

4. funções monótonas são B-mensurável sobre R,

5. combinações lineares de funções mensuráveis, quadrado, produto e módulo de

funções mensuráveis,

6. parte positiva f +(x) = max{f (x), 0} e parte negativa f −(x) = max{−f (x), 0} de

uma função mensurável f (x) = f +(x) − f −(x),

7. limites, supremos e ínﬁmos, limsups e liminfs de sequências de funções mensu-

ráveis, etc.

Seja f : Ω → [0, ∞) é uma função mensurável e não-negativa. Também é possível
provar que existe uma sequência de funções simples (ϕn)n∈N satisfazendo 0 ≤ ϕn(x) ≤
ϕn+1(x) para todo n ∈ N e todo x ∈ Ω de forma que f (x) = limn ϕn(x). Nesse caso, a
integral de Lebesgue de f é deﬁnida por

Se E ∈ A, deﬁnimos

(cid:90)

(cid:90)

f dP = lim

ϕn(x)dP.

(cid:90)

f dP = lim

(cid:90)

E

ϕn(x)XE(x)dP.

É possível provar que a integral deﬁnida dessa forma é linear e satisfaz que se 0 ≤ f ≤
g então (cid:82)

E f dP ≤ (cid:82)

E gdP.




Exemplo A.1.2. Seja f (x) =

se x ∈ Q,
se x ∈ R − Q,
[0, 1]. Notemos que [0, 1] = [Q∪(R−Q)]∩[0, 1], que P(Q∩[0, 1]) = 0 e P ((R − Q) ∩ [0, 1]) =
1, logo

que é uma função B-mensurável sobre



1

0

(cid:90)

(cid:90)

(cid:90)

f (x)dP =

0dP +

1dP = 1.

[0,1]

[0,1]∩Q

[0,1]∩(R−Q)

Deﬁnição A.1.3. Sejam f, f1, f2, · · · : Ω → R. Dizemos que a sequência (fn)n converge
pontualmente para f se, para todo x ∈ Ω, vale que fn(x) → f (x) quando n → ∞.

Um importante resultado sobre convergência de integrais de Lebesgue é o seguinte:

Teorema A.1.4 (da Convergência Monótona). Se (fn)n∈N é uma sequência monótona cres-
cente de funções mensuráveis não-negativas que converge pontualmente para f , então (cid:82) f dP =
lim (cid:82) fndP. Em outras palavras, podemos trocar a integral de posição com o limite se houver
uma “monotonicidade” da sequência.

Demonstração. Ver [6, Teorema 3.3].

80

APÊNDICE A. GENERALIZAÇÕES DA INTEGRAL DE RIEMANN

Para funções f : Ω → R em geral (não necessariamente não-negativas), basta con-
siderar a f = f + − f −, onde as partes positiva f + e negativa f − de f são função não-
negativas e estender a deﬁnição por linearidade, isto é, (cid:82) f dP = (cid:82) f +dP − (cid:82) f −dP.
Algumas propriedades que seguem diretamente são a linearidade da integral e a de-
sigualdade triangular. Dizemos que f é integrável se as integrais (cid:82) f +dP e (cid:82) f −dP são
ﬁnitas.

Nesse sentido, podemos enunciar o segundo resultado importante dessa seção:

Teorema A.1.5 (da Convergência Dominada). Seja (fn)n∈N uma sequência de funções que
converge quase certamente para uma função mensurável f . Se existe uma função integrável
g tal que |fn(x)| < g(x) para todo n e para todo x ∈ Ω, então f é integrável e (cid:82) f dP =
(cid:82) fndP. Em outras palavras, podemos trocar a integral de posição com o limite se houver
limn
uma “dominação” da sequência.

Demonstração. Ver [6, Teorema 3.4].

O Teorema da Convergência Dominada é usado algumas vezes no Capítulo 4.

É importante ressaltar que quando ambas estão deﬁnidas, as integrais de Lebesgue

e de Riemann de fato coincidem.

A.2 A integral de Stieltjes

Sejam ϕ : [a, b] → R uma função contínua e F : R → [0, 1] uma função de distribui-
ção. Deﬁne-se a integral de Riemann-Stieltjes de ϕ em relação a F (ou ponderada por F ),
como o limite de “somas ponderadas de Riemann” da forma

lim
max{xj+1−xj }→0

n−1
(cid:88)

i=0

ϕ(x∗

i )[F (xi+1) − F (xi)],

(A.1)

quando esse limite existe, onde a = x0 < x1 < x2 < · · · < xn = b, x∗
i é um ponto arbitrá-
rio de [xi, xi+1]. Tal limite existe e é ﬁnito sob as condições descritas, e é representado
por

b

(cid:90)

a

ϕ (x) dF (x).

A função ϕ é chamada de integrando, F de integrador.

A hipótese de que F é uma função de distribuição não é necessária: basta que F
seja uma função de variação limitada (ver [6, Seção 3.1]). Em particular, a deﬁnição da

A.2. A INTEGRAL DE STIELTJES

81

integral de Riemann-Stieltjes se estende para funções F monótonas, mas não usamos
isso nesse texto.

Por outro lado, a deﬁnição da integral de Riemann-Stieltjes pode ser estendida a

outras funções ϕ além das contínuas. Para uma função ϕ qualquer, deﬁne-se

b

(cid:90)

a

ϕ (x) dF (x)

de forma análoga ao que fazemos com a integral de Riemann. O problema desta de-
ﬁnição é que até funções bem simples deixam de possuir integrais, como vemos no
seguinte exemplo.

Exemplo A.2.1. Seja F a função de distribuição deﬁnida por

F (x) =




1, se x ≥ 0,



0, se x < 0,

e consideremos a integral (cid:82) 1
−1 F (x)dF (x), ou seja, F é ao mesmo tempo integrador e integrando.
Essa integral não está bem deﬁnida pois o limite (A.1) não existe. De fato, se xi (cid:54)= 0 para todo
i, teremos xj < 0 < xj+1 para algum j, logo F (xj+1) − F (xj) = 1. Assim, o somatório
assume como valor ou 0 ou 1, dependendo do valor escolhido para x∗
j ser negativo ou positivo,
respectivamente.

Dada essa deﬁciência da deﬁnição, a integral de Riemann-Stieltjes mostra-se insu-
ﬁciente para nossos propósitos, e temos que utilizar uma integral mais geral, a saber,
a integral de Lebesgue-Stieltjes, que, de agora em diante, será chamada simplesmente
integral de Stieltjes. A integral de Stieltjes será portanto a união das deﬁnições das in-
tegrais de Riemann-Stieltjes e de Lebesgue, isto é, será a integral de Riemann-Stieltjes
com a interpretação mais geral dos conjuntos e funções mensuráveis dada pela integral
de Lebesgue.

No que se segue, o integrando ϕ é uma função real mensurável, e o integrador F
a ϕ(x)dF (x). Quando não

a ϕdF signiﬁca (cid:82) b
é uma função de distribuição. A notação (cid:82) b
aparecem limites de integração, a integral é sobre toda a reta:

(cid:90)

ϕdF =

(cid:90) ∞

−∞

ϕdF =

lim
a→−∞,b→+∞

(cid:90) b

a

ϕdF.

Quando o integrando é contínuo em [a, b], a integral de Stieltjes torna-se uma sim-
ples integral de Riemann-Stieltjes, e podemos utilizar as propriedades desta. Em parti-
cular, isso facilita nossa discussão sobre as propriedades da esperança, já que ϕ(x) = x

82

APÊNDICE A. GENERALIZAÇÕES DA INTEGRAL DE RIEMANN

é contínua.

Proposição A.2.2. São válidos:

a) Teorema Fundamental do Cálculo: (cid:82) b

a dF (x) = F (b) − F (a).

b) A integral de Stieltjes é linear, tanto no integrando quanto no integrador. Em outras pala-

vras, para ϕ(x) = αf (x) + βg(x) temos

e

(cid:90) b

a

(cid:90)

ϕdF = α

(cid:90) b

f dF + β

(cid:90) b

a

gdF

a

(cid:90)

ϕdF = α

f dF + β

(cid:90)

gdF,

e para H(x) = αF (x) + βG(x) temos

e

(cid:90) b

a

(cid:90)

ϕdH = α

(cid:90) b

ϕdF + β

(cid:90) b

a

ϕdG

a

(cid:90)

ϕdH = α

ϕdF + β

(cid:90)

ϕdG,

onde valem as equações acima desde que as integrais estejam bem deﬁnidas e as somas te-
nham sentido.

c) A integral de Stieltjes é aditiva, isto é, se a < b < c então

(cid:90) c

a

ϕdF =

(cid:90) b

a

ϕdF +

(cid:90) c

b

ϕdF.

Isto vale também quando os intervalos são inﬁnitos. Por exemplo,

(cid:90)

ϕdF =

(cid:90) a

ϕdF +

(cid:90) ∞

ϕdF.

−∞

a

Novamente, estas equações são válidas quando as integrais estão bem deﬁnidas e as somas
têm sentido.

d) Quando F é a função de distribuição de uma variável aleatória discreta X, a integral de
p(xi) = 1, isto é, se p é a

Stieltjes reduz-se a uma série: se P(X = xi) = p(xi) > 0 e (cid:80)
i
função de probabilidade de X, então p(xi) é o salto de F em xi e

(cid:90)

ϕdF =

(cid:90) ∞

−∞

ϕ(x)dF (x) =

(cid:88)

i

ϕ(xi)p(xi).

A.2. A INTEGRAL DE STIELTJES

83

Observação: uma explicação intuitiva desta propriedade resulta da interpretação da dife-
rencial dF (x) como igual a p(xi) no ponto xi e zero nos pontos x que não são pontos de salto
de F (notemos que F cresce apenas em seus pontos de salto).

Quando a região de integração é um intervalo ﬁnito, temos

(cid:90) b

a

ϕdF =

(cid:88)

ϕ(xi)p(xi).

i:a<xi≤b

e) Quando F é a função de distribuição de uma variável aleatória contínua tendo densidade f ,

então f é a derivada de F (em quase toda parte). Temos dF (x) = f (x)dx logo,

(cid:90) b

a

ϕdF =

(cid:90) b

a

ϕ(x)f (x)dx e

(cid:90)

ϕdF =

(cid:90) ∞

−∞

ϕ(x)f (x)dx.

Já que F é contínua à direita, a integral de Riemann-Stieltjes em [a, b], se existe,
ignora um eventual salto de F no ponto a, mas leva em consideração um eventual
salto de F no ponto b. Por exemplo, seja

F1 (x) =





0, se x < a
1
2
1, se b ≤ x.

, se a ≤ x < b

Vemos que a função de distribuição F1, embora possua dois pontos de salto pertencen-
tes ao intervalo [a, b], salta somente uma vez no intervalo.

Se ϕ for uma função contínua em [a, b], a integral de Riemann-Stieltjes de ϕ em [a, b],

ponderada por F1, será

(cid:90) b

a

ϕdF1 =

1
2

ϕ(b).

Portanto, a integração leva em conta o salto em b e ignora o salto em a. Com isso,
utilizaremos o símbolo (cid:82) b

a para representar a integral sobre o intervalo (a, b], isto é,

(cid:90) b

a

ϕdF =

(cid:90)

(a,b]

ϕdF

(A.2)

onde o termo à direita é a integral de Stieltjes em (a, b].

Desta maneira, quando a integral de Riemann-Stieltjes existir, será igual à integral

de Stieltjes e o termo à esquerda indicará as duas integrais.

No caso da esperança, podemos refrasear os Teoremas A.1.4 e A.1.5 como a seguir:

84

APÊNDICE A. GENERALIZAÇÕES DA INTEGRAL DE RIEMANN

Corolário A.2.3 (Teorema da Convergência Monótona para esperanças). Sejam X, X1,
X2, . . . variáveis aleatórias em (Ω, A, P). Se 0 ≤ Xn ↑ X, isto é, Xn(ω) ≥ 0 e Xn(ω) ↑ X(ω)
para todo ω ∈ Ω, então E(Xn) ↑ E(X).

Corolário A.2.4 (Teorema da Convergência Dominada para esperanças). Sejam Y , X,
X1, X2, . . . variáveis aleatórias em (Ω, A, P) tais que Y é integrável, |Xn| ≤ Y ∀n, e Xn → X
(isto é, Xn(ω) → X(ω) ∀ω). Então X e Xn são integráveis e E(Xn) → E(X).

Apêndice B

A integral de uma função gaussiana

Uma função gaussiana é uma função da forma f (x) = ae−(x−b)2/c2

, onde a, b, c ∈ R
e ac (cid:54)= 0. É possível provar que a primitiva dessa função não pode ser explicitada em
termos de uma combinação ﬁnita de funções elementares. Por outro lado, podemos
usar a série de potências da função exponencial para calcular sua integral, e com isso
obter aproximações para o real valor da integral deﬁnida. Ainda assim, é possível
encontrar a integral de uma função gaussiana sobre R.

De fato, seja

I =

(cid:90) ∞

−∞

e−y2dy.

Vamos calcular I 2 usando duas integrais, o que se transforma em uma integral du-

pla, assim:

I 2 =

(cid:90) ∞

−∞

e−y2dy

(cid:90) ∞

−∞

e−x2dx =

(cid:90) ∞

(cid:90) ∞

−∞

−∞

e−y2e−x2dydx =

(cid:90) ∞

(cid:90) ∞

−∞

−∞

e−y2−x2dydx.

Usando as coordenadas polares e observando que x2 + y2 = r2, temos que a região
de integração é todo o plano xy, portanto 0 ≤ r < ∞ e o ângulo θ ∈ [0, 2π]. Assim a
integral

(cid:90) ∞

(cid:90) ∞

(cid:90) 2π

(cid:90) ∞

I 2 =

e−y2−x2dydx =

e−r2r dr dθ

−∞

−∞

0

0

pode ser calculada utilizando o método de substituição de variáveis. Fazendo u = −r2,

du = −2rdr, −

= dr e −∞ < u ≤ 0, temos

du
2r

(cid:90) ∞

0

e−r2r dr = −

1
2

(cid:90) 0

−∞

eudu = −

1
2

e−r2|0

−∞ = −

1
2

(0 − 1) =

1
2

.

85

86

APÊNDICE B. A INTEGRAL DE UMA FUNÇÃO GAUSSIANA

Teremos então:

(cid:90) 2π

(cid:90) ∞

0

0

e−r2r dr dθ =

(cid:90) 2π

0

1
2

dθ =

1
2

(2π − 0) = π.

Portanto, concluímos que I 2 = π, o que implica I =

√

π já que I > 0.

Referências Bibliográﬁcas

[1] 4DEVS, FERRAMENTAS ONLINE; Gerador de Números Aleatórios. https:
//www.4devs.com.br/gerador_de_numeros_aleatorios. Acesso em: 24 de set. de
2021.

[2] BARTLE, R.; Elements of integration and Lebesgue measure. John Wiley & Sons,

1995.

[3] BOREL, E.; Les probabilités dénombrales et leurs applications arithmétiques.

Supplemento di rend. circ. Mat. Palermo 27, 1909, p.247-271.

[4] BREIMAN, L.; Probability. Addison-Wesley, Reading, Massachusetts, 1968.

[5] CHAMPERNOWNE, D.G.; The construction of decimals normal in the sacle of

ten. J. London Math. Soc. s1-8 (4), 1933, p. 254-260.

[6] JAMES, B.R.; Probabilidade: um curso em nível intermediário. Projeto Euclides,

IMPA, 1981.

[7] LIMA, E.L.; Curso de Análise, vol. 1. 7ª edição, Projeto Euclides, Instituto de

Matemática Pura e Aplicada, CNPq, Rio de Janeiro, 1976.

[8] MAZHDRAKOV, M., BENOV, D., VALKANOV, N.; The Monte Carlo Method.

Engineering Applications. ACMO Academic Press, 2018.

[9] METROPOLIS, N.; The beginning of the Monte Carlo method. Los Alamos

Science (1987 Special Issue dedicated to Stanislaw Ulam), 1987, p. 125-130.

[10] RUDDIN, W.; Princípios de Análise Matemática. Ao Livro Técnico, Rio de Ja-
neiro, 1971. Traduzido por Eliana Rocha Henriques de Brito da 2ª edição ameri-
cana (1964).

[11] SILVA, M.N.P.; História da Probabilidade.

Brasil Escola. Disponível em:
https://brasilescola.uol.com.br/matematica/historia-probabilidade.htm.
Acesso em: 04 de outubro de 2021.

87


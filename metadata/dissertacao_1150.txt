UNIVERSIDADE DE BRAS√çLIA
Instituto de Ci√™ncias Exatas
Departamento de Matem√°tica
Mestrado ProÔ¨Åssional em Matem√°tica em Rede Nacional

Matrizes de Markov:
o Teorema de Perron-Frobenius; PageRank
e outras aplica√ß√µes

por
L√°zaro Sousa Pereira

Bras√≠lia-DF
2019

UNIVERSIDADE DE BRAS√çLIA
Instituto de Ci√™ncias Exatas
Departamento de Matem√°tica
Mestrado ProÔ¨Åssional em Matem√°tica em Rede Nacional

L√°zaro Sousa Pereira

Matrizes de Markov: o Teorema de Perron-Frobenius;
PageRank e outras aplica√ß√µes

Disserta√ß√£o de Mestrado apresentada ao De-
partamento de Matem√°tica da Universidade
Bras√≠lia como requisito parcial do Programa
de Mestrado ProÔ¨Åssional em Matem√°tica em
Rede Nacional - PROFMAT, para obten√ß√£o do
t√≠tulo de Mestre em Matem√°tica.

Orientador: Prof. Dr. Theo Allan Darn Zapata

Bras√≠lia-DF
2019

Ficha catalogr√°fica elaborada automaticamente, com os dados fornecidos pelo(a) autor(a)SSO725mSousa Pereira, L√°zaro    Matrizes de Markov: o Teorema de Perron-Frobenius;PageRank e outras aplica√ß√µes. / L√°zaro  Sousa Pereira;orientador Theo Allan Darn Zapata. -- Bras√≠lia, 2019.   68 p.   Disserta√ß√£o (Mestrado - Mestrado Profissional emMatem√°tica) -- Universidade de Bras√≠lia, 2019.   1. Matrizes de Markov. 2. Matrizes Irredut√≠veis. 3.Teorema de Perron-Frobenius. 4. PageRank. 5. Modelo deDifus√£o de Ehrenfest. I. Allan Darn Zapata, Theo, orient.II. T√≠tulo.Com amor, √† minha esposa e aos meus Ô¨Ålhos; aos meus pais, irm√£o e familiares.
Com respeito, a cada colega professor e professora da educa√ß√£o p√∫blica do nosso pa√≠s; em
especial, √† minha colega e irm√£ D. Marllene (Prof¬™ Allene Martins Rezende).
Em mem√≥ria, aos meus av√≥s: Jo√£o e Regino; ao colega e amigo Prof. Romeu(Antonio Vidal).
At√© algum dia!

Agradecimentos

As minhas experi√™ncias de vida revelam que devo ser grato at√© mesmo, por ter pelo
que agradecer. A realiza√ß√£o desse curso e desse trabalho tornou-se poss√≠vel gra√ßas a
Deus, a todo plano espiritual e, a toler√¢ncia e a cumplicidade direta ou indireta de
algumas pessoas. Registro ent√£o, meus sinceros agradecimentos a todas, ainda que eu
n√£o as mencione nessas linhas:

A todos os professores do MAT/UnB que empreenderam esfor√ßos no PROFMAT.
Pelas aulas, pelo tempo dedicado a cada conversa e a cada atendimento al√©m das aulas.
Em especial aos membros da banca examinadora, o Prof. Dr. Ary Vasconcelos Medino
pela aprecia√ß√£o cr√≠tica e valiosas sugest√µes e o Prof. Dr. Nilton Moura Barroso Neto
pela leitura atenta e considera√ß√µes. Ao Prof. Dr. Mauro Ribeiro de Oliveira Junior pela
leitura cr√≠tica e sugest√µes. Suas contribui√ß√µes foram inspiradoras e determinantes para
esta importante e conclusiva etapa de minha forma√ß√£o.

Em particular, agrade√ßo ao meu orientador Prof. Dr. Theo Allan Darn Zapata; ter
sido seu aluno e t√™-lo como orientador foi uma experi√™ncia muito signiÔ¨Åcativa, pelo
que aprendi, pela consci√™ncia da dimens√£o do que preciso aprender, e pelo sentido e
valoriza√ß√£o das buscas por entendimento, compreens√£o e aprendizagem signiÔ¨Åcativa.
Muito obrigado pela generosidade! O tenho tamb√©m como inspira√ß√£o e refer√™ncia a
partir de ent√£o.

A todos os colegas e amigos que encontrei durante os dois anos dessa jornada. Nos-
sas discuss√µes virtuais e presenciais foram muito importantes. Em particular, deixo
meus agradecimentos aos colegas de grupo em v√°rias aulas - Cesa Sabino, Marcelo
Carvalho, Edeilson Cavalcante e Roosevelt Bessoni - e em muitas horas de estudos, es-
pecialmente nos Ô¨Åns de semana e feriados - Rubens Cardoso, Ricardo Pinto e Michel.
Foi relevante compartilhar com voc√™s essa experi√™ncia.

A ag√™ncia de fomento √† pesquisa CAPES, pela bolsa concedida.
‚ô° Aos meus pais Antonia e Joel, pelo amor, pelo exemplo e pelas escolhas que Ô¨Å-
zeram em minha educa√ß√£o; ao meu irm√£o Leandro, pela torcida de sempre. Mesmo
distantes f√≠sica e geograÔ¨Åcamente, os tenho sempre aqui!

‚ô° √Ä minha esposa e companheira Em√≠lia Grazielle, pelo amor, pelo sacrif√≠cio e pela
reiterada resili√™ncia; aos meus Ô¨Ålhos Jo√£o Miguel e Bernardo pela paci√™ncia e compa-
nhia. Obrigado por jamais terem duvidado ou desacreditado, mesmo quando eu tive
d√∫vidas.

O correr da vida embrulha tudo, a vida √© assim: esquenta e esfria, aperta e da√≠ afrouxa,
sossega e depois desinquieta. O que ela quer da gente √© coragem.
Jo√£o Guimar√£es Rosa, Grande Sert√£o: Veredas, (p.448), Nova Aguilar, 1¬™ ed. 1994

Resumo

Nesta disserta√ß√£o de mestrado, discutiremos de forma b√°sica a Teoria da Probabilidade
e o c√°lculo de probabilidades al√©m de algumas de suas propriedades; mostraremos e
discutiremos as propriedades das Matrizes de Markov e apresentaremos uma demons-
tra√ß√£o do Teorema de Perron-Frobenius. Al√©m disso daremos exemplos com aplica√ß√µes
no contexto da Teoria da Probabilidade.

Palavras-chave: Probabilidade, matrizes de Markov, matrizes irredut√≠veis, Perron-
Frobenius, PageRank, modelo de Ehrenfest.

Abstract

In this master dissertation, we shall basically discuss Probability Theory and the calcu-
lation of probabilities in addition to some of its properties; we will show and discuss
the properties of the Markov Matrices and present a demonstration of the Perron-
Frobenius Theorem. At the end, we shall show you four examples with applications in
the context of Probability Theory.

Key words: Probability, Markov matrices, irreducible matrices, Perron-Frobenius, Pa-
geRank, Ehrenfest model.

Sum√°rio

Introdu√ß√£o .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

. 17

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

PRELIMINARES .
.
.
No√ß√µes B√°sicas de Probabilidade . . . . . . . . . . . . . . . . . . .
Probabilidade Condicional . . . . . . . . . . . . . . . . . . . . . . . .
Independ√™ncia de Eventos . . . . . . . . . . . . . . . . . . . . . . . .
Vari√°veis Aleat√≥rias e Processos Estoc√°sticos . . . . . . . . . . . .
Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opera√ß√µes com Matrizes . . . . . . . . . . . . . . . . . . . . . . . . .
Autovalor e Autovetor
. . . . . . . . . . . . . . . . . . . . . . . . . .

. 21
21

24
27
28
29

32
35

.

.

.

.

.

.

.

.

.

.

.

.

.

MATRIZES DE MARKOV .
.
.
DeÔ¨Åni√ß√£o e exemplos iniciais . . . . . . . . . . . . . . . . . . . . . .
Matrizes Irredut√≠veis . . . . . . . . . . . . . . . . . . . . . . . . . . .
Exemplos de matrizes redut√≠veis . . . . . . . . . . . . . . . . . . . .
Exemplos de matrizes irredut√≠veis . . . . . . . . . . . . . . . . . . .
Perron-Frobenius . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.

.

.

.

.

.

.

.

.

.

. 39
39
41

45
46
47

.

.

.

.

.

.

.

.

.

.

.

.

.

.
.
APLICA√á√ïES .
XXIII OBM - Olimp√≠ada Brasileira de Matem√°tica . . . . . . . . . .
O Problema dos ùëõ mentirosos . . . . . . . . . . . . . . . . . . . . . .
O PageRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
O Modelo de Difus√£o de Ehrenfest . . . . . . . . . . . . . . . . . . .

. 53
53
56
58
61

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

REFER√äNCIAS .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

. 67

1
1.1

1.1.1
1.1.2
1.1.3
1.2

1.2.1
1.3

2
2.1
2.2

2.2.1
2.2.2
2.3

3
3.1
3.2
3.3
3.4

Introdu√ß√£o

Estudar matem√°tica em nosso pa√≠s, ainda que n√£o seja o desejo inicial de muitos
dos estudantes de escolas p√∫blicas Brasil afora, vem sendo uma atividade cada vez
mais incentivada pelas universidades em seus cursos de gradua√ß√£o e por institui√ß√µes
como o IMPA - Instituto Nacional de Matem√°tica Pura e Aplicada. Como um profes-
sor de escola p√∫blica, a necessidade de atualiza√ß√£o e aperfei√ßoamento √© companheira
constante. Ainda que nossos incentivos e motiva√ß√µes sejam quase sempre pessoais, es-
tudar matem√°tica, compreender sua dimens√£o e relev√¢ncia para tantos outros ramos
das ci√™ncias, nos habilita continuamente a trabalhar em nossas salas de aula de forma
mais segura e honesta. Na √∫ltima etapa da educa√ß√£o b√°sica - no ensino m√©dio - onde
todos os conceitos matem√°ticos anteriormente estudados precisam ser consolidados,
ampliados e aprofundados, faz-se necess√°rio uma abordagem contextualizada com a
realidade e para isso, √© natural trabalharmos com aplica√ß√µes e modelos que deem sen-
tido √† teoria. Esse √© um dos principais motivos dessa jornada: estudar e aprender.

Nesta disserta√ß√£o √© apresentada e discutida uma parte interessante, por√©m, pouco
estudada em cursos de √Ålgebra Linear e Probabilidade em gradua√ß√µes de licenciatura
Matem√°tica: as matrizes de Markov. Esse tipo de matriz d√° suporte para ramiÔ¨Åca-
√ß√µes de estudos diversos da matem√°tica, como na teoria da probabilidade e na teoria
e representa√ß√£o de grupos, nas teorias de automorÔ¨Åsmos de grupos livres [BH12], no
estudo de sistemas din√¢micos e erg√≥dicos [PY98] e de categorias tensoriais [EGNO15].
Sua principal caracter√≠stica √© o fato de ser quadrada e ter cada vetor-coluna com en-
tradas ‚â• 0, e soma igual a 1. Esse tipo de vetor √© tamb√©m chamado de vetor de pro-
babilidade, ou simplesmente, vetor estoc√°stico. Essas matrizes resultam dos estudos
do matem√°tico russo Andrey Andreyevich Markov, que descreveu do ponto de vista
do produto matricial, o c√°lculo de probabilidades de ocorr√™ncia de certos eventos que
dependem apenas do estado em que o fen√¥meno se encontra para que seja calculada a
probabilidade de estar num estado seguinte. Essa caracter√≠stica de n√£o estar associada
a resultados de uma mem√≥ria mais extensa de repeti√ß√µes, √© o que deÔ¨Åne uma Cadeia
de Markov.

Utilizaremos ao longo de todo o trabalho a denomina√ß√£o matrizes de Markov para
nos referirmos √†s tradicionalmente conhecidas, matrizes de transi√ß√£o de probabilidades,
por√©m com uma interpreta√ß√£o distinta da tradicional, visto que, consideraremos os
vetores-coluna como os vetores estoc√°sticos. Com alguns recursos de √Ålgebra Linear
referentes √† propriedades e opera√ß√µes entre matrizes, obtemos o mesmo efeito do pro-
duto tradicionalmente conhecido.

Desde o in√≠cio do programa de mestrado PROFMAT em 2011, foram publicadas
at√© o momento mais de 4600 disserta√ß√µes. A cadeia de Markov foi objeto de estudo

18

INTRODU√á√ÉO

e discuss√£o em menos de duas dezenas de disserta√ß√µes, sendo 10 delas, com foco
numa discuss√£o que compreendesse o contexto do ensino m√©dio. Sendo um incen-
tivo e um desaÔ¨Åo a professores e estudantes desta etapa pois, a maioria dos recursos
matem√°ticos necess√°rios encontram-se nas obras e nos cursos de gradua√ß√£o e de p√≥s-
gradua√ß√£o. Destas disserta√ß√µes, destaco: Silva, C. E. V. da. Aplica√ß√µes da √Ålgebra
Linear nas Cadeias de Markov, UFG - Universidade Federal de Goi√°s, 2013, que ex-
plana e prop√µe exemplos explorando a resolu√ß√£o de sistemas lineares; Oliveira, J. C.
F. de, No√ß√µes de grafos dirigidos, cadeias de Markov e as buscas do Google, Univer-
sidade Federal de Sergipe, 2014, que prop√¥s uma aplica√ß√£o utilizando um exemplo
com o PageRank com estudantes do ensino m√©dio; Ribeiro, T. S. G. Processos de Mar-
kov discretos: exemplos voltados para o ensino m√©dio, UNESP - Universidade Esta-
dual Paulista J√∫lio de Mesquita Filho, 2017, que discorre sobre matrizes regulares e
utiliza o Teorema de Perron-Frobenius numa vers√£o que n√£o utiliza recursos conside-
rados avan√ßados de √Ålgebra Linear, demonstrando-o para matrizes de ordem 2. Em
todos esses trabalhos encontramos material pertinente acerca da cadeia de Markov e
aplica√ß√µes. Todo o acervo de disserta√ß√µes pode ser consultado livremente no ende-
re√ßo http://www.profmat-sbm.org.br/dissertacoes/. Com o Ô¨Årme prop√≥sito de
apresentar aspectos te√≥ricos e aplica√ß√µes das matrizes de Markov, o centro do nosso
trabalho est√° no Teorema de Perron-frobenius com √™nfase na a√ß√£o das matrizes irredu-
t√≠veis, e suas respectivas consequ√™ncias. Para tanto, lan√ßamos m√£o de recursos como
autovalores e autovetores em sua demonstra√ß√£o e nas resolu√ß√µes das aplica√ß√µes que
propomos.

No cap√≠tulo 1, apresentamos e discutimos de forma b√°sica o c√°lculo de probabili-
dade, da probabilidade condicional, al√©m de propriedades que tornam pr√°ticas as ite-
ra√ß√µes na resolu√ß√£o de certos problemas, como o problema dos ùëõ mentirosos [Fel67].
Apresentamos ainda deÔ¨Åni√ß√µes √∫teis no contexto das vari√°veis aleat√≥rias e dos proces-
sos estoc√°sticos; apresentamos e discutimos tamb√©m, t√≥picos sobre matrizes, opera√ß√µes
entre matrizes, autovalores e autovetores.

No cap√≠tulo 2 est√° o cerne da discuss√£o acerca das matrizes de Markov. Nele apre-
sentamos uma matriz de Markov e alguns resultados relevantes como por exemplo,
a exist√™ncia de um autovalor maximal igual a 1. Em seguida, deÔ¨Ånimos uma matriz
irredut√≠vel, exibimos resultados e exemplos que a caracterizam e apresentamos uma
demonstra√ß√£o do Teorema de Perron-Frobenius sugerida por Wielandt em sua obra
sobre matrizes irredut√≠veis.

No cap√≠tulo 3, apresentamos e discutimos a resolu√ß√£o de quatro problemas onde
aplicamos esse suporte te√≥rico. Iniciamos com um problema que foi proposto na 23¬™
Olimp√≠ada Brasileira de Matem√°tica, onde deseja-se calcular a probabilidade de um
ratinho estar numa certa gaiola, sob certas condi√ß√µes, ap√≥s 23 sinais sonoros. Em se-
guida, discutimos a resolu√ß√£o do problema dos ùëõ mentirosos, onde desejamos calcular

INTRODU√á√ÉO

19

a probabilidade de, num grupo com ùëõ pessoas, uma determinada pessoa estar dizendo
a verdade diante de um conjunto de aÔ¨Årma√ß√µes feitas pelas demais. Na edi√ß√£o de ja-
neiro / fevereiro de 2000 da Computing in Science and Engineering, Jack Dongarra e
Francis Sullivan selecionaram 10 algoritmos com a maior inÔ¨Çu√™ncia em ci√™ncia, an√°lise
num√©rica e engenharia no s√©culo XX. Em mar√ßo de 2016, Nick Higham (presidente do
SIAM, 2017-2018) apresentou uma lista ligeiramente revisada. Em nenhuma ordem
particular, a lista √©: (1) m√©todos Newton e quasi-Newton; (2) fatora√ß√µes matriciais (LU,
Cholesky, QR); (3) decomposi√ß√£o do valor singular, algoritmos QR e QZ; (4) m√©to-
dos de Monte-Carlo; (5) Transformada r√°pida de Fourier; (6) m√©todos do subespa√ßo
de Krylov; (7) JPEG; (8) PageRank; (9) m√©todo simplex; e (10) Ô¨Åltro de Kalman. No
terceiro problema deste cap√≠tulo, calcularemos o PageRank para uma rede formada
por s√≠tios da web. Desde 1998, quando da publica√ß√£o do resultado obtido por Brin e
Page, o PageRank √© assunto que vem sendo discutido e estudado em diversos institu-
tos de pesquisa mundo afora. Destacamos o Google Matrix: Fundamentals Applications
and Beyond, workshop organizado em outubro de 2018 pelo IHES - Institut des Hautes
√âtudes ScientiÔ¨Åques (Instituto de Altos Estudos Cient√≠Ô¨Åcos), que √© uma das principais
refer√™ncias - francesa e mundial - em estudos avan√ßados de matem√°tica, f√≠sica te√≥rica e
ci√™ncias aÔ¨Åns. Ao Ô¨Ånal, apresentamos e discutimos o modelo de difus√£o de Ehrenfest,
onde deseja-se calcular a probabilidade de retorno de cada mol√©cula para um recipi-
ente ocupado por elas inicialmente. Este modelo foi estudado pelos f√≠sicos Tatyana
e Paul Ehrenfest no in√≠cio do s√©culo XX, e nessa vers√£o b√°sica, descreve a origem da
irreversibilidade em sistemas f√≠sicos.

1 Preliminares

1.1 No√ß√µes B√°sicas de Probabilidade

Historicamente, a Teoria da Probabilidade surgiu a partir de problemas sobre a dis-
tribui√ß√£o das apostas em jogos de azar. Seu desenvolvimento subsequente trouxe n√£o
s√≥ para a Matem√°tica, mas, para a Estat√≠stica, as ci√™ncias da natureza e tamb√©m soci-
ais, uma poderosa ferramenta de investiga√ß√£o e an√°lise que subsidiaram importantes
resultados desde ent√£o. Nesta se√ß√£o, vamos deÔ¨Ånir e apresentar elementos b√°sicos e
propriedades elementares dessa rica teoria. Ao leitor que desejar veriÔ¨Åcar uma exposi-
√ß√£o mais detalhada e com bastante exemplos ilustrativos, recomendamos a leitura dos
cap√≠tulos 2, 3 e 5 de [MCCF06].

DeÔ¨Åni√ß√£o 1.1.1. Um experimento que n√£o apresenta exatamente o mesmo resultado, ainda
que repetido sob condi√ß√µes Ô¨Åxas, √© denominado experimento aleat√≥rio. Do contr√°rio, √©
denominado experimento determin√≠stico.

DeÔ¨Åni√ß√£o 1.1.2. Ao conjunto que coleciona todos os resultados poss√≠veis de um experimento
d√°-se o nome de espa√ßo amostral.

DeÔ¨Åni√ß√£o 1.1.3. Denomina-se evento, todo resultado ou subconjunto de resultados de um
experimento; quando o subconjunto √© unit√°rio, o evento √© chamado de evento simples.

Al√©m disso, um espa√ßo amostral √© chamado de discreto se contiver um n√∫mero
Ô¨Ånito de pontos ou se seus inÔ¨Ånitos pontos podem ser postos em correspond√™ncia biu-
n√≠voca com o conjunto dos n√∫meros naturais. Nesse contexto, vamos denotar o espa√ßo
amostral por ùíÆ e um evento qualquer por ‚Ñ∞. Para uma sequ√™ncia de eventos ‚Ñ∞
3, ...,
de ùíÆ, conforme seja Ô¨Ånita ou inÔ¨Ånita, temos

2, ‚Ñ∞

1, ‚Ñ∞

ùëõ‚ãÉÔ∏Å

‚Ñ∞

ùëñ = ùíÆ ou

ùëñ=1
Conv√©m ainda registrar que:

‚àû
‚ãÉÔ∏Å

ùëñ=1

‚Ñ∞

ùëñ = ùíÆ.

(i) a um ponto de ùíÆ corresponde um, e t√£o somente um, resultado poss√≠vel; e

(ii) cada resultado distinto corresponde a pontos distintos em ùíÆ.

Neste trabalho, consideraremos apenas espa√ßos amostrais discretos.

Exemplo 1.1.1. Uma linha de produ√ß√£o de uma industria metal√∫rgica, produz pe√ßas para
autom√≥veis que s√£o sempre inspecionadas e classiÔ¨Åcadas como B (boa), ou D (defeituosa).
Ap√≥s uma inspe√ß√£o, foram retiradas ao acaso, tr√™s dessas pe√ßas.

22

CAP√çTULO 1. PRELIMINARES

Note que o espa√ßo amostral associado a esse experimento √© o conjunto

ùíÆ = {ùêµùêµùêµ, ùê∑ùê∑ùê∑, ùê∑ùêµùêµ, ùêµùê∑ùêµ, ùêµùêµùê∑, ùê∑ùê∑ùêµ, ùê∑ùêµùê∑, ùêµùê∑ùê∑} .

O evento ‚Ñ∞

1 = {ùê∑ùêµùêµ, ùêµùê∑ùêµ, ùêµùêµùê∑}, por exemplo, re√∫ne as poss√≠veis amostras onde
exatamente uma pe√ßa √© classiÔ¨Åcada defeituosa; enquanto cada sequ√™ncia, como por
exemplo, {ùêµùê∑ùêµ}, √© um evento simples.

Quando n√£o mencionado de outra forma, tomaremos por refer√™ncia um experi-
mento com um n√∫mero Ô¨Ånito de elementos, e que cada um desses elementos t√™m a
mesma chance de ocorr√™ncia, isto √©, s√£o equiprov√°veis. Temos, dessa forma, elementos
suÔ¨Åcientes para uma deÔ¨Åni√ß√£o de probabilidade que atende nossas pretens√µes neste
trabalho. Para uma explana√ß√£o mais aprofundada ver [Jam15], e o cl√°ssico [Fel67].

DeÔ¨Åni√ß√£o 1.1.4. Dado um espa√ßo amostral discreto ùíÆ de ùëÅ elementos, seja ‚Ñ∞ um subcon-
junto de ùíÆ composto por ùëõ elementos. Ent√£o, a probabilidade de ‚Ñ∞, que denota-se por ùëÉ (‚Ñ∞) √©
o n√∫mero real n√£o-negativo obtido a partir da raz√£o:

ùëÉ (‚Ñ∞) =

ùëõ
ùëÅ

.

Tradicionalmente, interpretamos esse n√∫mero como a divis√£o do n√∫mero de casos
favor√°veis √† ocorr√™ncia do evento ‚Ñ∞ pelo n√∫mero total de casos poss√≠veis ùëÅ . Observamos
tamb√©m que se trata de uma fun√ß√£o deÔ¨Ånida para uma classe dos eventos (subconjun-
tos) de ùíÆ.

De forma axiom√°tica, para uma classe ùíû de eventos de ùíÆ, a probabilidade satisfaz:

I. ùëÉ (ùê¥) ‚â• 0 para todo ùê¥ ‚àà ùíû;

II. Se ùê¥1, . . . , ùê¥ùëö √© uma sequ√™ncia de eventos disjuntos dois a dois, de ùíû ent√£o,
‚éõ
ùëö‚ãÉÔ∏Å
‚éú‚éú‚éú‚éú‚éú‚éù

ùëÉ (ùê¥ùëò);

ùëö‚àëÔ∏Å

ùê¥ùëò

‚éü‚éü‚éü‚éü‚éü‚é†

=

ùëÉ

‚éû

ùëò=1

ùëò=1

III. ùëÉ (ùíÆ) = 1.

A partir da deÔ¨Åni√ß√£o e dos axiomas, veriÔ¨Åcamos que a probabilidade possui as propri-
edades:

(ùëñ) Para todo ‚Ñ∞ ‚äÇ ùíÆ, tem-se ùëÉ (‚Ñ∞) ‚â• 0;

(ùëñùëñ) Sendo ‚Ñ∞

1 e ‚Ñ∞

2 eventos distintos de ùíÆ, tais que, ‚Ñ∞

1

‚à© ‚Ñ∞

2 = ‚àÖ ent√£o:

ùëÉ (‚Ñ∞
1

‚à™ ‚Ñ∞

2) = ùëÉ (‚Ñ∞

1) + ùëÉ (‚Ñ∞

2).

De modo geral, para ‚Ñ∞

1 e ‚Ñ∞

2 arbitr√°rios, segue que,

ùëÉ (‚Ñ∞

1

‚à™ ‚Ñ∞

2) ‚â§ ùëÉ (‚Ñ∞

1) + ùëÉ (‚Ñ∞

2);

CAP√çTULO 1. PRELIMINARES

23

(ùëñùëñùëñ) Para ‚Ñ∞ùëê = ùíÆ ‚àí ‚Ñ∞, segue que ùëÉ (‚Ñ∞ùëê) = 1 ‚àí ùëÉ (‚Ñ∞).

De fato, para (ùëñ) basta veriÔ¨Åcarmos que como ùëÅ > 0 e ùëõ ‚â• 0 temos o suÔ¨Åciente para
ùëÉ (‚Ñ∞) ‚â• 0. Supondo que ‚Ñ∞
2 t√™m, respectivamente, ùëõ1 e ùëõ2 eventos simples, e sabendo
que eles n√£o t√™m eventos simples comuns, o n√∫mero de eventos simples de ‚Ñ∞
2 √©,
1
ent√£o, igual a ùëõ1 + ùëõ2. Logo, pela deÔ¨Åni√ß√£o de probabilidade,

1 e ‚Ñ∞

‚à™ ‚Ñ∞

ùëÉ (‚Ñ∞

1

‚à™ ‚Ñ∞

2) =

ùëõ1 + ùëõ2
ùëÅ

=

ùëõ1
ùëÅ

+

ùëõ2
ùëÅ

= ùëÉ (‚Ñ∞

1) + ùëÉ (‚Ñ∞

2).

1 e ‚Ñ∞

Para ‚Ñ∞
evento simples comum. Denotemos esse evento comum por ùëõ3. Ent√£o ‚Ñ∞
ùëõ1 + ùëõ2

2 arbitr√°rios, √© suÔ¨Åciente considerarmos a possibilidade de terem algum
2 tem

‚àí ùëõ3 eventos, e da deÔ¨Åni√ß√£o de probabilidade, chegamos a

‚à™ ‚Ñ∞

1

ùëÉ (‚Ñ∞

1

‚à™ ‚Ñ∞

2) =

‚àí ùëõ3

ùëõ1 + ùëõ2
ùëÅ

=

ùëõ1
ùëÅ

+

ùëõ2
ùëÅ

‚àí ùëõ3
ùëÅ

e assim obtemos (ùëñùëñ).
Por Ô¨Åm, como ùëÉ (ùíÆ) = 1, para (ùëñùëñùëñ), temos

= ùëÉ (‚Ñ∞

1) + ùëÉ (‚Ñ∞

2) ‚àí ùëÉ (‚Ñ∞

1

‚à© ‚Ñ∞

2) ‚â§ ùëÉ (‚Ñ∞

1) + ùëÉ (‚Ñ∞

2),

1 = ùëÉ (ùíÆ) = ùëÉ (‚Ñ∞ ‚à™ ‚Ñ∞ùëê) = ùëÉ (‚Ñ∞) + ùëÉ (‚Ñ∞ùëê),

pois, ‚Ñ∞ e ‚Ñ∞ùëê s√£o disjuntos. Consequentemente,

ùëÉ (‚Ñ∞ùëê) = 1 ‚àí ùëÉ (‚Ñ∞).

Exemplo 1.1.2. Problema dos Anivers√°rios [Fel67, p. 33]: - Em um grupo formado por
ùëü pessoas, qual √© a probabilidade de pelo menos duas delas fazerem anivers√°rio no mesmo
dia?

Esse problema tem intrigado e surpreendido estudantes, pois, uma primeira obser-
va√ß√£o natural a fazer √© que, em fun√ß√£o do valor de ùëü, a probabilidade pode ser muito
alta. Sabemos que nem todos os anos t√™m a mesma dura√ß√£o (anos bissextos t√™m 366
dias). Com isso, consideraremos um ano com 365 dias. Al√©m disso, cada uma das
ùëü pessoas pode ter nascido em qualquer uma das 365 datas dispon√≠veis, isto √©, todos
os dias s√£o equiprov√°veis, o que nos d√° um espa√ßo amostral ùíÆ com 365ùëü eventos sim-
ples (que s√£o sequ√™ncias de tamanho ùëü formadas por datas). Assim, vamos supor que
ùëü < 365 uma vez que, se ùëü ‚â• 365 a probabilidade desejada seria 1.

Seja o evento ‚Ñ∞ = {ao menos 2 pessoas aniversariam no mesmo dia}; ent√£o, seu com-
plementar √© ‚Ñ∞ùëê = {ningu√©m faz anivers√°rio num mesmo dia}. Note que, para calcular o
n√∫mero de casos favor√°veis √† ‚Ñ∞ùëê precisamos contar o n√∫mero de sequ√™ncias distintas
com ùëü elementos (datas) tomados de um total de 365 datas dispon√≠veis, ou seja, basta
calcularmos um arranjo de 365 datas tomadas de ùëü em ùëü. Com isso, torna-se mais vi√°vel
calcularmos ùëÉ (‚Ñ∞ùëê) e em seguida, obtemos ùëÉ (‚Ñ∞) = 1 ‚àí ùëÉ (‚Ñ∞ùëê). Assim,

24

CAP√çTULO 1. PRELIMINARES

ùëÉ (‚Ñ∞) = 1 ‚àí

]Ô∏Å

[Ô∏Å 365!
(365‚àíùëü)!
365ùëü

[Ô∏É

= 1 ‚àí

365 ¬∑ 364 ¬∑ ... ¬∑ (365 ‚àí ùëü + 1)
365ùëü

]Ô∏É

= 1 ‚àí

(Ô∏Ç

[Ô∏Ç
1.

1 ‚àí 1
365

)Ô∏Ç

¬∑ ... ¬∑

(Ô∏Ç

1 ‚àí ùëü ‚àí 1
365

)Ô∏Ç]Ô∏Ç

.

A seguinte tabela mostra que n√£o √© necess√°rio um grupo muito grande de pessoas para
que tenhamos uma possibilidade real de ao menos duas, aniversariarem numa mesma
data.

N√∫mero de pessoas
10
20
22
23
40
60
80

ùëÉ (‚Ñ∞)
0,11695
0,41144
0,47569
0,50729
0,89123
0,99412
0,99991

Tabela 1 ‚Äì Probabilidades para um grupo com ùëü pessoas

Em particular, para ùëü = 23 pessoas, a chance de pelo menos duas terem anivers√°rio

em comum excede 50%.

Isso mostra que n√£o √© necess√°rio uma grupo muito grande de pessoas para que

tenhamos a possibilidade real de ao menos duas, aniversariarem numa mesma data.

1.1.1 Probabilidade Condicional

Os conceitos de probabilidade condicional e de independ√™ncia de eventos s√£o fun-
damentais na Teoria da Probabilidade e lastreiam parte signiÔ¨Åcativa de seu desenvol-
vimento. Para tanto, consideremos um espa√ßo amostral com resultados equiprov√°veis.

DeÔ¨Åni√ß√£o 1.1.5. Sejam ùê¥ e ùêµ dois eventos de um espa√ßo amostral ùíÆ. Se ùëÉ (ùêµ) > 0, a proba-
bilidade condicional de ùê¥ dado que ocorreu ùêµ, √© dada por:

ùëÉ (ùê¥|ùêµ) =

ùëÉ (ùê¥ ‚à© ùêµ)
ùëÉ (ùêµ)

;

(1.1)

caso ùëÉ (ùêµ) = 0, para alguns autores, √© conveniente deÔ¨Ånir ùëÉ (ùê¥|ùêµ) = ùëÉ (ùê¥).

Comparando com a deÔ¨Åni√ß√£o de probabilidade, notamos que, uma vez "certo que
ùêµ ocorreu", esse evento passa a Ô¨Ågurar como refer√™ncia para um novo espa√ßo amostral
‚Ä≤. Como ilustra√ß√£o para essa deÔ¨Åni√ß√£o, vamos considerar a seguinte situa√ß√£o espe-
ùëÜ
cial: um experimento consiste em lan√ßar um dado honesto duas vezes sobre uma mesa
perfeitamente plana, e observar o n√∫mero de pontos na face superior em cada um dos

CAP√çTULO 1. PRELIMINARES

25

lan√ßamentos. Suponha que n√£o houve a observa√ß√£o dos lan√ßamentos, por√©m, foi infor-
mado que em cada um dos lan√ßamentos, o n√∫mero de pontos observados √© menor do
que ou igual a tr√™s. Nessas condi√ß√µes, qual √© a probabilidade de que a soma dos pontos
observados nos dois lan√ßamentos seja igual a um n√∫mero primo? Para organizar as ideias,
denotemos por ùêµ, o evento: em cada um dos lan√ßamentos, o n√∫mero de pontos observa-
dos √© menor do que ou igual a tr√™s; e por ùê¥ o evento: a soma dos pontos observados nos
dois lan√ßamentos seja igual a um n√∫mero primo. Ora, claramente, estamos interessados
em saber qual √© a probabilidade de ocorrer o evento ùê¥, dado como certo, que ocorreu
o evento ùêµ. Para o espa√ßo amostral associado a esse experimento, temos os seguintes
pares (ùëõ1, ùëõ2) das possibilidades para o 1¬∫ e 2¬∫ lan√ßamentos, respectivamente:

(1, 1)
(2, 1)
(3, 1)
(4, 1)
(5, 1)
(6, 1)

(1, 2)
(2, 2)
(3, 2)
(4, 2)
(5, 2)
(6, 2)

(1, 3)
(2, 3)
(3, 3)
(4, 3)
(5, 3)
(6, 3)

(1, 4)
(2, 4)
(3, 4)
(4, 4)
(5, 4)
(6, 4)

(1, 5)
(2, 5)
(3, 5)
(4, 5)
(5, 5)
(6, 5)

(1, 6)
(2, 6)
(3, 6)
(4, 6)
(5, 6)
(6, 6)

Tabela 2 ‚Äì Resultados poss√≠veis para dois lan√ßamentos

Consideremos ùêµ = {ùëõùëò √© inteiro positivo ‚â§ 3} com 1 ‚â§ ùëò ‚â§ 2 e, ùê¥ = {ùëõ1 + ùëõ2 √© primo}

e a tabela acima, temos resumidamente:

ùêµ = {(1, 1); (1, 2); (1, 3); (2, 1); (2, 2); (2, 3); (3, 1); (3, 2); (3, 3)}

e

ùê¥ = {(1, 1); (1, 2); (1, 4); (1, 6); (2, 1); (2, 3); (2, 5); (3, 2); (3, 4); (4, 1); (4, 3); (5, 2); (5, 6); (6, 1); (6, 5)} .

Entretanto, os √∫nicos pontos de ùê¥ que interessam s√£o os que t√™m a soma de suas co-
ordenadas como valores primos ‚â§ 5. Nessas condi√ß√µes, aÔ¨Årmar que o evento ùêµ ocor-
reu signiÔ¨Åca dizer que, agora, devemos considerar apenas os pontos do espa√ßo amos-
tral que perten√ßam a ùêµ. Assim, Ô¨Åca f√°cil concluir que a probabilidade procurada √©
5
9
ùê¥ ‚à© ùêµ = {(1, 1); (1, 2); (2, 1); (2, 3); (3, 2)}, segue ùëÉ (ùê¥ ‚à© ùêµ) =

; pois dos 9 pontos de ùêµ, apenas 5 deles pertencem a ùê¥. Em outros termos, como

, e ent√£o,

e ùëÉ (ùêµ) =

5
36

9
36

ùëÉ (ùê¥|ùêµ) =

)Ô∏Ç

)Ô∏Ç =

5
9

.

(Ô∏Ç 5
36
(Ô∏Ç 9
36

Al√©m de servirem como base para modelagens diversas em situa√ß√µes pr√°ticas, as
probabilidades condicionais ainda podem ser usadas para calcularmos probabilidades
em geral, embora nem sempre tenhamos facilidade em caracterizar eventos. Para os
casos eventualmente mais espinhosos, conv√©m construirmos um condicionamento me-
nos complicado. Da f√≥rmula (1.1), obtemos ùëÉ (ùê¥ ‚à© ùêµ) = ùëÉ (ùêµ)ùëÉ (ùê¥|ùêµ). Para um n√∫mero

26

CAP√çTULO 1. PRELIMINARES

Ô¨Ånito ùëõ de interse√ß√µes, a ocorr√™ncia de um evento numa etapa ùëò < ùëõ √© inÔ¨Çuenciada pe-
las ocorr√™ncias das ùëò ‚àí 1 etapas anteriores. Essa generaliza√ß√£o exprime a probabilidade
da interse√ß√£o de ùëõ eventos por meio das probabilidades condicionais sucessivas, como
veremos nos lemas a seguir.

Lema 1.1.1 (Regra do Produto de Probabilidades). Seja ùëõ um inteiro ‚â• 2 e sejam ùê¥1,
ùê¥2, ..., ùê¥ùëõ eventos do espa√ßo amostral ùíÆ, para o qual est√° deÔ¨Ånida a probabilidade ùëÉ e com
ùëÉ (

ùëñ=1 ùê¥ùëñ) > 0, tem-se ent√£o:

‚ãÇÔ∏Äùëõ

ùëÉ (ùê¥1

‚à© ùê¥2

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëõ) = ùëÉ (ùê¥1)ùëÉ (ùê¥2

|ùê¥1)ùëÉ (ùê¥3

|ùê¥1

‚à© ùê¥2) ¬∑ ¬∑ ¬∑ ùëÉ (ùê¥ùëõ

|ùê¥1

‚à© ùê¥2

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëõ‚àí1). (1.2)

Demonstra√ß√£o: Por indu√ß√£o sobre ùëõ. Para ùëõ = 2, segue da deÔ¨Åni√ß√£o de probabilidade
condicional que,

ùëÉ (ùê¥1

‚à© ùê¥2) = ùëÉ (ùê¥1)ùëÉ (ùê¥2

|ùê¥1),

pois ùëÉ (ùê¥1) > 0. Suponha que a igualdade (1.2) seja v√°lida para ùëõ = ùëò. Temos,

ùëÉ (ùê¥1

‚à© ùê¥2

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò

‚à© ùê¥ùëò+1) = ùëÉ ((ùê¥1
= ùëÉ (ùê¥1

‚à© ùê¥2
‚à© ùê¥2
= (ùëÉ (ùê¥1)ùëÉ (ùê¥2

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò) ‚à© ùê¥ùëò+1)
|ùê¥1
‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò)ùëÉ (ùê¥ùëò+1
‚à© ùê¥2
|ùê¥1
|ùê¥1) ¬∑ ¬∑ ¬∑ ùëÉ (ùê¥ùëò

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò)
‚à© ùê¥2
‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò‚àí1))

ùëÉ (ùê¥ùëò+1

|ùê¥1

‚à© ùê¥2

‚à© ¬∑ ¬∑ ¬∑ ‚à© ùê¥ùëò).

Logo, pelo Princ√≠pio da Indu√ß√£o Matem√°tica, o lema est√° provado.

O pr√≥ximo lema nos d√° as ferramentas para calcular a probabilidade de um evento
ùê¥ conhecidas as probabilidades dos eventos que comp√µem uma parti√ß√£o de ùíÆ e as
respectivas probabilidades condicionais de ùê¥ com cada um deles.

Lema 1.1.2 (F√≥rmula da Probabilidade Total). Seja ùê∂1, ùê∂2, ..., ùê∂ùëõ uma parti√ß√£o do es-
‚à© ùê∂ùëó = ‚àÖ sempre que ùëñ (cid:44) ùëó. Seja ùê¥ um evento
pa√ßo amostral ùíÆ, isto √©, tem-se
e ùëÉ uma probabilidade > 0 deÔ¨Ånida nos eventos de ùíÆ, ent√£o:

ùëñ=1 ùê∂ùëñ = ùíÆ e ùê∂ùëñ

‚ãÉÔ∏Äùëõ

ùëõ‚àëÔ∏Å

ùëÉ (ùê¥) =

ùëÉ (ùê∂ùëñ)ùëÉ (ùê¥|ùê∂ùëñ).

ùëñ=1
Demonstra√ß√£o: Temos por hip√≥tese, ùíÆ =
segue que,

‚ãÉÔ∏Äùëõ

ùëñ=1 ùê∂ùëñ e tamb√©m ùê¥ ‚àà ùíÆ. Como ùê¥ ‚à© ùíÆ = ùê¥,

ùê¥ = ùê¥ ‚à© ùíÆ = ùê¥ ‚à©

‚éõ
ùëõ‚ãÉÔ∏Å
‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚é†

ùê∂ùëñ

ùëõ‚ãÉÔ∏Å

(ùê¥ ‚à© ùê∂ùëñ).

=

ùëñ=1
Calculando a probabilidade de ùê¥, utilizando o fato dos eventos serem disjuntos, o lema
anterior e a deÔ¨Åni√ß√£o de probabilidade condicional, obtemos:
ùëÉ (ùê¥) = ùëÉ (

ùëñ=1 ùëÉ (ùê∂ùëñ)ùëÉ (ùê¥|ùê∂ùëñ)

ùëñ=1 ùëÉ (ùê¥ ‚à© ùê∂ùëñ) =

ùëñ=1(ùê¥ ‚à© ùê∂ùëñ)) =

‚ãÉÔ∏Äùëõ

‚àëÔ∏Äùëõ

‚àëÔ∏Äùëõ

ùëñ=1

Com o prop√≥sito de ilustrar esses dois √∫ltimos resultados, vamos discutir um exem-

plo.

CAP√çTULO 1. PRELIMINARES

27

Exemplo 1.1.3. Tem-se 33 bolas que se distinguem apenas pela cor, distribu√≠das em cinco
urnas distintas. Dessas bolas, 13 s√£o brancas e 20 s√£o pretas. Dessas urnas, sabe-se que:
uma delas tem 5 bolas brancas e 10 pretas; duas delas t√™m 2 bolas brancas e 3 pretas e, as
outras duas, t√™m 2 bolas brancas e 2 pretas.

Uma dessas urnas √© aleatoriamente escolhida, e desta, uma bola √© aleatoriamente reti-

rada. Qual √© a probabilidade de que a bola retirada seja preta?

Resolu√ß√£o: Vamos denotar por ùí´ , o evento: a bola retirada √© preta. Denotemos ainda
os eventos: uma delas tem 5 bolas brancas e 10 bolas pretas por ùê¥1; duas delas t√™m 2
bolas brancas e 3 bolas pretas por ùê¥2; e, as outras duas, t√™m 2 bolas brancas e 2 pretas
por ùê¥3. Sabendo que uma bola somente pode ser retirada de uma urna de composi√ß√£o
‚à© ùí´ . Pela deÔ¨Åni√ß√£o de probabilidade
‚à© ùí´ + ùê¥3
ùê¥1 , ùê¥2 ou ùê¥3, temos que ùí´ = ùê¥1
condicional e pela f√≥rmula de probabilidade total,

‚à© ùí´ + ùê¥2

ùëÉ (ùí´ ) = ùëÉ (ùê¥1)ùëÉ (ùí´ |ùê¥1) + ùëÉ (ùê¥2)ùëÉ (ùí´ |ùê¥2) + ùëÉ (ùê¥3)ùëÉ (ùí´ |ùê¥3).

Por outro lado, temos as probabilidades:
2
5

; ùëÉ (ùê¥2) =

; ùëÉ (ùê¥3) =

ùëÉ (ùê¥1) =

1
5

2
5

Com isso, conclu√≠mos que ùëÉ (ùí´ ) =

; ùëÉ (ùí´ |ùê¥1) =
2
¬∑ 2
5
3

1
5

+

2
3
¬∑ 3
5

3
; ùëÉ (ùí´ |ùê¥2) =
5
43
¬∑ 1
.
75
2

2
5

=

+

e ùëÉ (ùí´ |ùê¥3) =

1
2

.

1.1.2 Independ√™ncia de Eventos

Apresentamos inicialmente uma no√ß√£o intuitiva da independ√™ncia de dois eventos,
pois, mostra que a probabilidade de um n√£o √© alterada pela informa√ß√£o de que o outro
ocorreu.

DeÔ¨Åni√ß√£o 1.1.6. Sejam ùê¥ e ùêµ dois eventos de um espa√ßo amostral ùíÆ, e suponha que ùëÉ (ùêµ) > 0.
O evento ùê¥ √© dito independente do evento ùêµ se: ùëÉ (ùê¥|ùêµ) = ùëÉ (ùê¥).

Se o evento ùê¥ √© independente do evento ùêµ, ent√£o,

ùëÉ (ùê¥ ‚à© ùêµ) = ùëÉ (ùêµ)ùëÉ (ùê¥|ùêµ) = ùëÉ (ùê¥)ùëÉ (ùêµ).

Ademais, parece natural que o evento ùêµ seja independente do evento ùê¥. De fato, pois,
para ùëÉ (ùê¥) > 0,

ùëÉ (ùêµ|ùê¥) =

ùëÉ (ùê¥ ‚à© ùêµ)
ùëÉ (ùê¥)

=

ùëÉ (ùê¥)ùëÉ (ùêµ)
ùëÉ (ùê¥)

= ùëÉ (ùêµ).

Com isso, podemos aÔ¨Årmar que os eventos ùê¥ e ùêµ s√£o independentes se, e somente se,

ùëÉ (ùê¥ ‚à© ùêµ) = ùëÉ (ùê¥)ùëÉ (ùêµ).

A partir dessas condi√ß√µes, e da √∫ltima igualdade, podemos generalizar a deÔ¨Åni√ß√£o de
independ√™ncia de eventos para mais de dois eventos.

28

CAP√çTULO 1. PRELIMINARES

DeÔ¨Åni√ß√£o 1.1.7. Sejam os eventos ùê¥1, ùê¥2, ..., ùê¥ùëõ de um espa√ßo amostral ùíÆ. Esses eventos s√£o
¬∑ ¬∑ ¬∑‚à©ùê¥ùëñùëò ) = ùëÉ (ùê¥ùëñ1)ùëÉ (ùê¥ùëñ2) ¬∑ ¬∑ ¬∑ ùëÉ (ùê¥ùëñùëò ) para todo ùëò = 2, 3, . . . , ùëõ
ditos independentes se: ùëÉ (ùê¥ùëñ1
e todo {ùëñ1, ùëñ2, . . . , ùëñùëò

‚à©ùê¥ùëñ2
} ‚äÇ {1, 2, . . . , ùëõ}.

Um problema cl√°ssico no estudo da Teoria das Probabilidades e cuja solu√ß√£o √© atri-
bu√≠da a Pierre de Fermat no s√©culo XVII, √© o de observar que, para ensaios do tipo
sucesso-fracasso que s√£o realizados de forma independente, com probabilidade de su-
cesso ùëù, qual seria a probabilidade de ocorrerem ùëÅ sucessos antes de ùëÄ fracassos?

Na solu√ß√£o √© inicialmente apontado que o evento: N sucessos antes de M fracassos √©
equivalente √†: ocorrerem, ao menos, N sucessos nos primeiros M+N-1 ensaios. Para obter-
mos a probabilidade de ùëò sucessos em ùëÅ + ùëÄ ‚àí 1 ensaios, como a ordem de ocorr√™ncia
dos ensaios bem sucedidos n√£o importa, ent√£o, pela independ√™ncia entre os ensaios,
temos,

ùëÉ ({ùëò sucessos em (ùëÅ + ùëÄ ‚àí 1) ensaios}) =

)Ô∏É

(Ô∏É
ùëÅ + ùëÄ ‚àí 1
ùëò

¬∑ ùëùùëò ¬∑ (1 ‚àí ùëù)(ùëÅ +ùëÄ‚àí1)‚àíùëò

e, ent√£o,

ùëÉ ({ùëÅ sucessos antes de ùëÄ fracassos}) =

ùëÅ +ùëÄ‚àí1‚àëÔ∏Å

ùëò=ùëÅ

)Ô∏É
(Ô∏É
ùëÅ + ùëÄ ‚àí 1
ùëò

¬∑ ùëùùëò ¬∑ (1 ‚àí ùëù)(ùëÅ +ùëÄ‚àí1)‚àíùëò.

1.1.3 Vari√°veis Aleat√≥rias e Processos Estoc√°sticos

Nesta se√ß√£o, apresentaremos deÔ¨Åni√ß√µes de vari√°vel aleat√≥ria e de processos estoc√°s-
ticos que ser√£o √∫teis na resolu√ß√£o de aplica√ß√µes do cap√≠tulo 3. Havendo curiosidade e
interesse por parte do leitor em uma exposi√ß√£o mais detalhada e aprofundada, vale a
leitura de [Jam15] e [Doo53].

Podemos deÔ¨Ånir, informalmente, uma vari√°vel aleat√≥ria como uma fun√ß√£o capaz de
associar a cada ponto de um espa√ßo amostral um n√∫mero real. Neste trabalho, estamos
interessados em um tipo espec√≠Ô¨Åco que √© a vari√°vel aleat√≥ria discreta.

DeÔ¨Åni√ß√£o 1.1.8. Uma vari√°vel aleat√≥ria ùëã em um espa√ßo de probabilidade √© uma fun√ß√£o
real ùëã : ùëÜ ‚Üí R se o conjunto {ùëã ‚â§ ùë•} = {ùëü ‚àà ùëÜ, ùë°ùëéùëôùëûùë¢ùëí, ùëã(ùëü) ‚â§ ùë•} √© um evento aleat√≥rio para
todo ùë• ‚àà R.

DeÔ¨Åni√ß√£o 1.1.9. Seja ùëã uma vari√°vel aleat√≥ria. Se ùëã assume valores em um conjunto
enumer√°vel diz-se que ùëã √© uma vari√°vel aleat√≥ria discreta.

Em outros termos, se ùëã √© uma vari√°vel com valores ùë•1, ùë•2, . . ., ent√£o, para ùëñ = 1, 2, . . .

tem-se ùëù(ùë•ùëñ) = ùëÉ (ùëã = ùë•ùëñ).

Exemplo 1.1.4. Consideremos a situa√ß√£o descrita no exemplo 1.1.1. Precisamos determinar
a probabilidade de, ao Ô¨Ånal da terceira retirada ao acaso, exatamente duas dessas pe√ßas sejam

CAP√çTULO 1. PRELIMINARES

29

boas. Para isso, deÔ¨Ånamos ùëã a vari√°vel aleat√≥ria que nos d√° o n√∫mero de pe√ßas boas, e,
considere ainda que nessa linha de produ√ß√£o 4% das pe√ßas produzidas s√£o defeituosas e que
as retiradas s√£o independentes.

Estamos interessados em calcular ùëÉ (ùëã = 2). Observando os pontos do espa√ßo amos-
tral, temos favoravelmente ùêµùêµùê∑, ùêµùê∑ùêµ e ùê∑ùêµùêµ. Assim e sendo √≥bvio que 96% das pe√ßas
produzidas s√£o boas, segue que:

ùëÉ (ùëã = 2) = ùëÉ (ùêµùêµùê∑) + ùëÉ (ùêµùê∑ùêµ) + ùëÉ (ùê∑ùêµùêµ) = 3(0, 96)2(0, 04) = 11, 06%.

DeÔ¨Åni√ß√£o 1.1.10. Um processo estoc√°stico √© um modelo matem√°tico utilizado no estudo de
fen√¥menos aleat√≥rios cujos resultados s√£o fun√ß√µes.

Em outros termos, consideremos um conjunto ùêæ n√£o-vazio de reais ‚â• 0. Fixando um
ùëò, podemos pensar num processo estoc√°stico como uma fam√≠lia de vari√°veis aleat√≥rias
ùëò‚ààùêæ onde ùëãùëò : ùëÜ ‚Üí ùê∏ para cada ùëò ‚àà ùêæ e um conjunto enumer√°vel ùê∏ que possui uma
}
{ùëãùëò
sequ√™ncia de resultados poss√≠veis ùê∏1, ùê∏2, . . .. Um processo estoc√°stico onde, dado um
n√∫mero Ô¨Ånito de vari√°veis, o valor condicionalmente associado a uma delas depende
do valor imediatamente anterior √© chamado processo de Markov. Resumidamente,

ùëÉ (ùëãùëò = ùë•ùëò

| ùëã1 = ùë•1, . . . , ùëãùëò‚àí2 = ùë•ùëò‚àí2, ùëãùëò‚àí1 = ùë•ùëò‚àí1) = ùëÉ (ùëãùëò = ùë•ùëò

| ùëãùëò‚àí1 = ùë•ùëò‚àí1) = ùëùùëò‚àí1ùëò;

e um processo cuja probabilidade condicional √© satisfeita nesses termos √© dito ser uma
cadeia de Markov.

1.2 Matrizes

Nesta se√ß√£o, deÔ¨Åniremos uma matriz e, resumidamente, um espa√ßo vetorial. Ap√≥s,
apresentaremos alguns dos principais tipos de matrizes. Em seguida, apresentaremos
de forma sucinta conceitos considerados b√°sicos, como as opera√ß√µes entre matrizes,
determinantes, sistemas e transforma√ß√µes lineares, autovalores e autovetores. Para
uma aprecia√ß√£o mais aprofundada do que trataremos nesta se√ß√£o, √© necess√°rio algumas
leituras da jovem, por√©m, vasta literatura da √Ålgebra Linear. Em particular, de autores
com os quais servir-me, como [Ser02], [Bol78] e [Lim04].

DeÔ¨Åni√ß√£o 1.2.1. Dados ùëö e ùëõ naturais, deÔ¨Ånimos uma matriz real ùê¥ de ordem ùëö‚àípor‚àíùëõ,
ou simplesmente, ùê¥ùëö√óùëõ - como uma tabela formada por n√∫meros reais ùëéùëñùëó com 1 ‚â§ ùëñ ‚â§ ùëö e
1 ‚â§ ùëó ‚â§ ùëõ, dispostos em ùëö linhas e ùëõ colunas. Os n√∫meros reais ùëéùëñùëó s√£o chamados de entradas
da matriz ùê¥ e localizam-se na intersec√ß√£o da linha ùëñ com a coluna ùëó.

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé12
ùëé11
ùëé22
ùëé21
...
...
ùëéùëö1 ùëéùëö2

¬∑ ¬∑ ¬∑
ùëé1ùëõ
¬∑ ¬∑ ¬∑
ùëé2ùëõ
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëöùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

30

CAP√çTULO 1. PRELIMINARES

Deste ponto em diante, cabe registrarmos para Ô¨Åns pr√°ticos que, sempre que nos
referirmos a uma matriz o faremos denominando-a por uma letra mai√∫scula do nosso
alfabeto e, quando necess√°rio, indicaremos sua ordem; tamb√©m a representaremos por
uma tabela entre par√™nteses conforme Ô¨Åzemos na deÔ¨Åni√ß√£o acima. O s√≠mbolo ‚Ñ≥(ùëö, ùëõ)
denota o conjunto de todas as matrizes ùëö‚àípor‚àíùëõ. Em rela√ß√£o √†s suas entradas, para
uma refer√™ncia escrita tamb√©m de ordem pr√°tica, utilizaremos a nota√ß√£o ùëéùëñùëó, e tam-
b√©m, ùê¥ùëñùëó sempre que n√£o houver d√∫vidas ou ambiguidades. Uma matriz ùëö‚àípor‚àíùëõ
cujas entradas s√£o todas nulas, d√°-se o nome de matriz nula; na literatura encontra-se
simplesmente expressa por 0ùëö√óùëõ.

Embora o termo vetor evoque intuitivamente aos estudantes, a no√ß√£o de uma gran-
deza f√≠sica com dire√ß√£o, sentido e magnitude, aqui entretanto, o tomaremos com uma
no√ß√£o e um contexto mais amplos. Em outros termos, o tomaremos como um elemento
de um conjunto algebricamente estruturado, no qual est√£o bem deÔ¨Ånidas a adi√ß√£o en-
tre esses elementos e a multiplica√ß√£o por um n√∫mero real. Estas opera√ß√µes satisfazem
a comutatividade, a associatividade e a distributividade. Este conjunto, que √© o ter-
reno onde se desenvolve a √Ålgebra Linear √© denominado espa√ßo vetorial. Como um
exemplo, para todo natural ùëõ, temos o conjunto Rùëõ, que representa o espa√ßo vetorial
euclidiano n-dimensional. Os elementos de Rùëõ s√£o as listas ordenadas de n√∫meros
reais denominadas como ‚Éóùë¢ = (ùë¢1, ùë¢2, . . . , ùë¢ùëõ). Para o espa√ßo vetorial R‚àû, seus elementos
s√£o as listas inÔ¨Ånitas como ‚Éóùëé = (ùëé1, ùëé2, . . . , ùëéùëõ . . .).

Um subconjunto ùêπ de um espa√ßo vetorial ùê∏, para o qual sejam deÔ¨Ånidas as mesmas
opera√ß√µes, e satisfa√ßa as mesmas condi√ß√µes, √© um subespa√ßo vetorial do espa√ßo ùê∏.
Dizemos que ùêπ √© um conjunto linearmente independente (abreviadamente, l.i.) quando
nenhum vetor ‚Éóùë£ ‚àà ùêπ √© escrito como combina√ß√£o linear de outros vetores de ùêπ, isto √©,
n√£o existem ùõºùëñ reais (cid:44) 0, para 1 ‚â§ ùëñ ‚â§ ùëõ tais que, ‚Éóùë£ = ùõº1 ‚Éóùë£1 + ¬∑ ¬∑ ¬∑ + ùõºùëõ ‚Éóùë£ùëõ, com ‚Éóùë£ùëñ
‚àà ùêπ. Para
o caso em que ùêπ = {Ô∏Ä‚Éóùë£}Ô∏Ä, se ‚Éóùë£ (cid:44) ‚Éó0 ent√£o, por deÔ¨Åni√ß√£o, ùêπ √© l.i. Quando ùêπ √© l.i., diz-se
tamb√©m que seus elementos s√£o todos (cid:44) ‚Éó0 e s√£o vetores linearmente independentes, pois,
naturalmente, o vetor nulo √© combina√ß√£o linear de quaisquer outros. Do contr√°rio, um
conjunto ùëã ‚àà ùê∏ diz-se linearmente dependente (abreviadamente l.d.) quando n√£o √© l.i.
Isto signiÔ¨Åca que algum dos vetores ‚Éóùë¢ ‚àà ùëã √© combina√ß√£o linear de outros elementos de
ùëã, ou ent√£o, que ùëã =

{Ô∏Å
‚Éó0

}Ô∏Å
.

Uma base de um espa√ßo vetorial ùê∏ √© um conjunto ‚Ñ¨ ‚äÇ ùê∏ linearmente independente
que gera ùê∏. Isto signiÔ¨Åca que todo vetor ‚Éóùë£ ‚àà ùê∏ √© expresso de modo √∫nico como combi-
na√ß√£o linear de elementos de ‚Ñ¨. Os vetores ùëí1 = (1, 0, 0, . . . , 0) , ùëí2 = (0, 1, 0, . . . , 0) , ¬∑ ¬∑ ¬∑ , ùëíùëõ =
(0, 0, . . . , 1) formam uma base de Rùëõ que se chama base can√¥nica. Se um espa√ßo veto-
rial ùê∏ admite uma base com ùëò elementos, ent√£o, todas as bases de ùê∏ tem exatamente ùëò
elementos, e esse n√∫mero ùëò √© chamado de dimens√£o do espa√ßo vetorial ùê∏.

No contexto das matrizes, por exemplo, uma matriz ùê¥ de ordem ùëõ‚àípor‚àíùëö, pode-
¬∑ ¬∑ ¬∑ ùëéùëñùëõ), enquanto a ùëó-√©sima

mos representar a ùëñ-√©sima linha pelo vetor-linha (ùëéùëñ1 ùëéùëñ2

CAP√çTULO 1. PRELIMINARES

31

coluna pelo vetor-coluna

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé1ùëó
ùëé2ùëó
...
ùëéùëöùëó

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

que s√£o, respectivamente, elementos dos espa√ßos vetoriais Rùëõ e Rùëö.

Utilizaremos a partir desse ponto, exceto quando mencionado de forma distinta, a

representa√ß√£o dos vetores como

‚éõ

‚éû

‚Éóùë£ =

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

ùë£1
ùë£2
...
ùë£ùëõ
A transposta de uma matriz ùê¥ ‚àà ‚Ñ≥(ùëö, ùëõ) √© a matriz ùê¥ùëá cujas entradas s√£o ùëéùëóùëñ, isto
√©, as colunas de ùê¥ s√£o as linhas de ùê¥ùëá . Quando ùëö = ùëõ, ent√£o ùê¥ √© dita ser uma matriz
quadrada (ou simplesmente, de ordem ùëõ). Essa matriz, √© ainda chamada de sim√©trica
se, e somente se ùê¥ùëá = ùê¥, isto √©, ùëéùëñùëó = ùëéùëóùëñ para todo ùëñ e todo ùëó. Ilustrando; a matriz

.

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1 ‚àí7 6
‚àí7
0
1
5
0
6

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

√© uma matriz sim√©trica.

As entradas ùëéùëñùëñ com 1 ‚â§ ùëñ ‚â§ ùëõ, de uma matriz quadrada ùê¥ formam a sua diagonal
principal. Uma matriz diagonal de ordem ùëõ √© uma matriz quadrada de ordem ùëõ em
que todos os elementos que n√£o perten√ßam √† sua diagonal principal s√£o nulos, isto √©,
se ùê¥ √© uma matriz diagonal, ent√£o, ùëéùëñùëó = 0 sempre que ùëñ (cid:44) ùëó:

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé11
0
...
0

0
ùëé22
...
0

¬∑ ¬∑ ¬∑
0
¬∑ ¬∑ ¬∑
0
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëõùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Uma matriz diagonal de ordem ùëõ para a qual, ùëöùëñùëó =

‚éß
‚é™‚é™‚é™‚é®
0, se ùëñ (cid:44) ùëó
‚é™‚é™‚é™‚é©
1 se ùëñ = ùëó

√© chamada de

matriz identidade de ordem ùëõ e denotada por ùêºùëõ. Em outras palavras,

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1 0 ¬∑ ¬∑ ¬∑ 0
0 1 ¬∑ ¬∑ ¬∑ 0
...
...
. . .
0 0 ¬∑ ¬∑ ¬∑ 1

...

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

ùêºùëõ =

32

CAP√çTULO 1. PRELIMINARES

A matriz identidade √© um caso especial de uma matriz de permuta√ß√£o. Esta, √©
uma matriz quadrada com exatamente uma entrada diferente de zero em cada linha e
cada coluna, sendo essa entrada um 1. Trataremos de forma detalhada das matrizes de
permuta√ß√£o na se√ß√£o 2.2.

A uma matriz quadrada ùê¥ tal que, ùëéùëñùëó = 0 sempre que ùëñ > ùëó, d√°-se o nome de matriz

triangular superior de ordem ùëõ:

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé11 ùëé12
0
ùëé22
...
...
0
0

¬∑ ¬∑ ¬∑ ùëé1ùëõ
¬∑ ¬∑ ¬∑ ùëé2ùëõ
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëõùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

;

por outro lado, quando ùëéùëñùëó = 0 sempre que ùëñ < ùëó, √© uma matriz triangular inferior de
ordem ùëõ:

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0
ùëé11
ùëé21 ùëé22
...
...
ùëéùëõ1 ùëéùëõ2

¬∑ ¬∑ ¬∑
0
¬∑ ¬∑ ¬∑
0
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëõùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

1.2.1 Opera√ß√µes com Matrizes

Dizemos que duas matrizes ùê¥ e ùêµ de mesma ordem ùëö‚àípor‚àíùëõ s√£o iguais, e escreve-

mos ùê¥ = ùêµ, quando, para todo 1 ‚â§ ùëñ ‚â§ ùëö e 1 ‚â§ ùëó ‚â§ ùëõ tem-se ùëéùëñùëó = ùëèùëñùëó.

Se ùê¥ e ùêµ s√£o duas matrizes de mesma ordem ùëö √ó ùëõ e, ùõº e ùõΩ s√£o constantes reais
quaisquer, ent√£o, a soma de ùê¥ e ùêµ denotada por ùê¥ + ùêµ, √© uma matriz ùê∂ com ordem
ùëö‚àípor‚àíùëõ tal que, ùëêùëñùëó = ùëéùëñùëó + ùëèùëñùëó para todo 1 ‚â§ ùëñ ‚â§ ùëö, e todo 1 ‚â§ ùëó ‚â§ ùëõ; a multiplica√ß√£o
por escalar ùõº de uma matriz ùê¥ √© uma matriz ùõºùê¥ = ùõºùëéùëñùëó pata todo ùëñ e todo ùëó.

ùõºùê¥ = ùõº ¬∑

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé12
ùëé11
ùëé22
ùëé21
...
...
ùëéùëö1 ùëéùëö2

¬∑ ¬∑ ¬∑
ùëé1ùëõ
¬∑ ¬∑ ¬∑
ùëé2ùëõ
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëöùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

=

ùõºùëé11 ùõºùëé12
ùõºùëé21 ùõºùëé22

...

...

ùõºùëéùëö1 ùõºùëéùëö2

¬∑ ¬∑ ¬∑ ùõºùëé1ùëõ
¬∑ ¬∑ ¬∑ ùõºùëé2ùëõ
. . .
¬∑ ¬∑ ¬∑ ùõºùëéùëöùëõ

...

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

A adi√ß√£o entre matrizes tem propriedades semelhantes √† adi√ß√£o entre n√∫meros re-

ais e, √† adi√ß√£o entre elementos de um espa√ßo vetorial:

(i) ùê¥ + ùêµ = ùêµ + ùê¥ (Comutatividade);

(ii) (ùê¥ + ùêµ) + ùê∂ = ùê¥ + (ùêµ + ùê∂) (Associatividade);

(iii) ùê¥ + (‚àíùê¥) = 0 com 0 a matriz nula com mesma ordem de ùê¥;

CAP√çTULO 1. PRELIMINARES

33

(iv) ùê¥ + 0 = ùê¥ (Elemento Neutro).

VeriÔ¨Åcamos ainda que, para quaisquer ùê¥ e ùêµ em ‚Ñ≥(ùëö, ùëõ), e ùõº, ùõΩ em R vale:

(i) ùõº(ùê¥ + ùêµ) = ùõºùê¥ + ùõºùêµ (Distributividade);

(ii) (ùõº + ùõΩ)ùê¥ = ùõºùê¥ + ùõΩùê¥;

(iii) ùõº(ùõΩùê¥) = (ùõºùõΩ)ùê¥ e 1ùê¥ = ùê¥.

O conceito de multiplica√ß√£o de matrizes, cuja ideia foi expandida, formalizada e
apresentada por Arthur Cayley em 1858, em seu trabalho intitulado A Memoir on the
Theory of Matrices, publicado na revista Philosophical Transactions of the Royal Society of
London; embora n√£o seja de trivial execu√ß√£o, √© de amplo conhecimento por estudantes
do Ensino M√©dio. O produto matricial ùê¥ùêµ entre as matrizes ùê¥ùëö√óùëõ e ùêµùëõ√óùëù √© deÔ¨Ånido como
a matriz ùê∑ùëö√óùëù, tal que, ùê∑ = ùê¥ùêµ, isto √©,

ùëëùëñùëó =

‚àëÔ∏Å

1‚â§ùëò‚â§ùëõ

ùëéùëñùëòùëèùëòùëó = ùëéùëñ1ùëè1ùëó + ¬∑ ¬∑ ¬∑ + ùëéùëñùëõùëèùëõùëó.

Observando a deÔ¨Åni√ß√£o assim apresentada, veriÔ¨Åcamos que, para que seja poss√≠vel
o produto ùê¥ùêµ √© necess√°rio que o n√∫mero de colunas de ùê¥ seja igual ao n√∫mero de linhas
de ùêµ. Uma outra forma de entender esse produto √© por meio de uma combina√ß√£o linear
entre os vetores-coluna de ùê¥ e as entradas (ou escalares) de cada vetor-coluna de ùêµ.
Resumidamente, consideremos a matriz ùê¥ùëö√óùëõ e o vetor ‚Éóùë£ em Rùëõ. Ent√£o, da deÔ¨Åni√ß√£o
acima temos:

ùê¥‚Éóùë£ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé12
ùëé11
ùëé22
ùëé21
...
...
ùëéùëö1 ùëéùëö2

¬∑ ¬∑ ¬∑
ùëé1ùëõ
¬∑ ¬∑ ¬∑
ùëé2ùëõ
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëöùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

ùë£1
ùë£2
...
ùë£ùëõ

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

=

ùëé11ùë£1 + ùëé12ùë£2 + ¬∑ ¬∑ ¬∑ + ùëé1ùëõùë£ùëõ
ùëé21ùë£1 + ùëé22ùë£2 + ¬∑ ¬∑ ¬∑ + ùëé2ùëõùë£ùëõ
...
ùëéùëö1ùë£1 + ùëéùëö2ùë£2 + ¬∑ ¬∑ ¬∑ + ùëéùëöùëõùë£ùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Vale ressaltar ainda que, em geral, o produto matricial n√£o e comutativo, isto √©, ùê¥ùêµ (cid:44)
ùêµùê¥. Algumas raz√µes justiÔ¨Åcam essa particularidade: para ùê¥ùëö√óùëõ e ùêµùëõ√óùëù, segue que ùê¥ùêµ
est√° bem deÔ¨Ånida e ùêµùê¥, por sua vez, n√£o se ùëö (cid:44) ùëù ; supondo ambas bem deÔ¨Ånidas e com
mesmo tamanho, podemos ter elementos de ùê¥ùêµ distintos dos elementos de ùêµùê¥, por
2 1
5 6

‚éû
, temos que, ùê¥ùêµ =

contra-exemplo, se ùê¥ =

6
5
19 20

0 1
2 3

enquanto

e ùêµ =

‚éü‚éü‚éü‚éü‚é†

‚éü‚éü‚éü‚éü‚é†

‚éü‚éü‚éü‚éü‚é†

‚éú‚éú‚éú‚éú‚éù

‚éú‚éú‚éú‚éú‚éù

‚éú‚éú‚éú‚éú‚éù

‚éû

‚éû

‚éõ

‚éõ

‚éõ

ùêµùê¥ =

. Dentre as propriedades do produto matricial, destacamos:

‚éõ

‚éú‚éú‚éú‚éú‚éù

2
5
12 23

‚éû

‚éü‚éü‚éü‚éü‚é†

(ùëñ) ùê¥(ùêµùê∂) = (ùê¥ùêµ)ùê∂ Associatividade;

(ùëñùëñ) ùê¥(ùêµ + ùê∂) = ùê¥ùêµ + ùê¥ùê∂ Distributividade √† esquerda;

34

CAP√çTULO 1. PRELIMINARES

(ùëñùëñùëñ) (ùê¥ + ùêµ)ùê∂ = ùê¥ùê∂ + ùêµùê∂ Distributividade √† direita.

Conv√©m destacarmos que para uma matriz quadrada ùê¥ de ordem ùëõ‚àípor‚àíùëõ, deÔ¨Åne-
se ùê¥0 = ùêºùëõ. Ademais, ùê¥1 = ùê¥; ùê¥2 = ùê¥ ¬∑ ùê¥; e de modo geral ùê¥ùëò = ùê¥ ¬∑ ¬∑ ¬∑ ùê¥ com ùëò fatores
iguais a ùê¥.

DeÔ¨Åni√ß√£o 1.2.2. Seja ùê¥ uma matriz quadrada de ordem ùëõ. Se existir uma matriz quadrada
ùêµ com ordem ùëõ, tal que, ùê¥ùêµ = ùêµùê¥ = ùêºùëõ, ent√£o, diremos que ùê¥ √© invert√≠vel e que ùêµ √© sua in-
‚àí1. Se n√£o existir uma matriz ùêµ, ent√£o a matriz ùê¥ n√£o √© invert√≠vel
versa denotada por ùêµ = ùê¥
(equivalentemente, √© singular).

Da deÔ¨Åni√ß√£o acima, veriÔ¨Åcamos que vale tamb√©m a aÔ¨Årma√ß√£o de que ùêµ √© invert√≠vel
e que ùê¥ √© sua inversa. VeriÔ¨Åcamos tamb√©m que se ùêµ e ùê∂ s√£o inversas de uma matriz
ùê¥ ent√£o ùêµ = ùê∂. Com efeito, pois, dado que ùêµ √© inversa de ùê¥, temos ùêµùê¥ = ùêº. Com isso,
multiplicando √† direita ambos os membros, pela matriz ùê∂ , temos (ùêµùê¥)ùê∂ = ùêºùê∂ = ùê∂.
Por outro lado, √© fato que (ùêµùê¥)ùê∂ = ùêµ(ùê¥ùê∂) = ùêµùêº = ùêµ dado que ùê∂ tamb√©m √© inversa de
ùê¥. Ent√£o, conclu√≠mos que ùêµ = ùê∂. H√° ainda um rico contexto onde as opera√ß√µes entre
matrizes, em particular, a multiplica√ß√£o, tem papel de destaque. Trata-se das transfor-
ma√ß√µes lineares. Por ser distinto das ferramentas que precisaremos, n√£o trataremos
desse contexto.

Outro importante conceito acerca das matrizes quadradas e da aplicabilidade para
modelar e resolver problemas diversos, √© o de determinante. Inicialmente sendo utili-
zado na resolu√ß√£o de sistemas de equa√ß√µes lineares ou simplesmente, sistemas linea-
res com ùëõ equa√ß√µes e ùëõ inc√≥gnitas, que encontramos na literatura inclusive do ensino
m√©dio.

Resumidamente apresentado de forma matricial como ùê¥‚Éóùë• = ‚Éóùëè, √© expresso como a

igualdade a seguir:

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëé11
ùëé12
ùëé21
ùëé22
...
...
ùëéùëö1 ùëéùëö2

¬∑ ¬∑ ¬∑
ùëé1ùëõ
¬∑ ¬∑ ¬∑
ùëé2ùëõ
...
. . .
¬∑ ¬∑ ¬∑ ùëéùëöùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

ùë•1
ùë•2
...
ùë•ùëõ

=

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëè1
ùëè2
...
ùëèùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Posteriormente, o determinante foi tamb√©m identiÔ¨Åcado como a √°rea de um paralelo-
gramo, como o volume de um paralelep√≠pedo e, como uma fun√ß√£o multilinear alter-
nada que diferentemente das fun√ß√µes reais, associam n√∫meros reais a vari√°veis que s√£o
matrizes quadradas. Denotaremos o determinante de uma matriz ùê¥ por det ùê¥. A fun-
√ß√£o determinante tem propriedades √∫teis que tornam pr√°ticas provas e demonstra√ß√µes
de resultados importantes. Destacamos algumas:

Dada uma matriz quadrada ùê¥ de ordem ùëõ,

CAP√çTULO 1. PRELIMINARES

35

(ùëñ) det ùê¥ = 0 se, e somente se ùê¥ √© singular. Outro aspecto dessa singularidade s√£o as
matrizes que possuem linhas(ou colunas) nulas, possuem duas linhas id√™nticas,
ou possuem duas linhas proporcionais ou duas colunas proporcionais;

(ùëñùëñ) det ùê¥ = det ùê¥ùëá ;

(ùëñùëñùëñ) det(ùëò.ùê¥) = ùëòùëõ. det ùê¥ para ùëò ‚àà R;

(ùëñùë£) det(ùê¥.ùêµ) = det ùê¥. det ùêµ se ùêµ for quadrada com mesma ordem de ùê¥;

Ademais, se det ùê¥ (cid:44) 0, ent√£o ùê¥ √© invert√≠vel, e segue diretamente que det ùê¥

‚àí1 =

1
det ùê¥

.

1.3 Autovalor e Autovetor

Sejam ùê¥ uma matriz quadrada de ordem ùëõ e ‚Éóùë¢ um vetor n√£o-nulo em Rùëõ. O vetor
‚Éóùë¢ √© chamado de autovetor de ùê¥ se ùê¥‚Éóùë¢ for um m√∫ltiplo escalar de ‚Éóùë¢, isto √©, ùê¥‚Éóùë¢ = ùúÜ‚Éóùë¢
para algum escalar real (ou complexo) ùúÜ, que por sua vez, √© denominado autovalor de
ùê¥. Dizemos ainda, mais precisamente que ‚Éóùë¢ √© um autovetor associado ao autovalor ùúÜ.

Em linhas gerais, quando ‚Éóùë¢ for um autovetor de ùê¥, a multiplica√ß√£o por ùê¥ preservar√°
sua dire√ß√£o. Em virtude do sinal e da magnitude do autovalor ùúÜ associado a ‚Éóùë¢, a
multiplica√ß√£o ùê¥‚Éóùë¢ = ùúÜ‚Éóùë¢ comprime ou expande o vetor ‚Éóùë¢, invertendo seu sentido no
caso em que ùúÜ < 0. A equa√ß√£o ùê¥‚Éóùë¢ = ùúÜ‚Éóùë¢ pode ser equivalentemente escrita como
‚àí ùê¥)‚Éóùë¢ = ‚Éó0 . Dessa forma, para que ùúÜ seja um autovalor de ùê¥
ùê¥‚Éóùë¢ = ùúÜùêºùëõ‚Éóùë¢, e da√≠, (ùúÜùêºùëõ
esta equa√ß√£o caracter√≠stica deve possuir alguma solu√ß√£o ‚Éóùë¢ n√£o-nula (n√£o-trivial), e
‚àí ùê¥) = 0.
isso ocorre se, e somente se a matriz (ùúÜùêºùëõ
‚àí ùê¥) encontramos um polin√¥mio de grau ùëõ chamado polin√¥mio
Expandindo det(ùúÜùêºùëõ
caracter√≠stico de ùê¥ em ùúÜ da forma, ùëÉ (ùúÜ) = ùúÜùëõ + ùõº1ùúÜùëõ‚àí1 + ¬∑ ¬∑ ¬∑ + ùõºùëõ onde o coeÔ¨Åciente l√≠der
√© 1.

‚àí ùê¥) √© singular, ou seja, se det(ùúÜùêºùëõ

Pelo Teorema Fundamental de √Ålgebra, ele ter√° exatamente ùëõ ra√≠zes complexas
(contadas suas multiplicidades) que s√£o os autovalores de ùê¥. A multiplicidade al-
g√©brica √© o n√∫mero de vezes que ùúÜ zera o polin√¥mio e, a multiplicidade geom√©trica
√© a dimens√£o do subespa√ßo de autovetores associados a ùúÜ. Como consequ√™ncias das
deÔ¨Åni√ß√µes de autovalores e de autovetores, e das caracter√≠sticas acima, seguem as pro-
posi√ß√µes [1.3.1] e [1.3.2].

Proposi√ß√£o 1.3.1. Autovetores de uma matriz quadrada ùê¥ de ordem ùëõ associados a autova-
lores distintos s√£o linearmente independentes.

Proposi√ß√£o 1.3.2. Se ùê¥ for uma matriz quadrada de ordem ùëõ triangular (superior, inferior
ou diagonal) ent√£o seus autovalores s√£o as entradas de sua diagonal principal.

36

CAP√çTULO 1. PRELIMINARES

Por outro lado, observamos ainda que, sendo ‚Éóùë¢ e ‚Éóùë£ dois autovetores associados
ao mesmo autovalor ùúÜ0, isto √©, ùê¥‚Éóùë¢ = ùúÜ0‚Éóùë¢ e ùê¥‚Éóùë£ = ùúÜ0‚Éóùë£, ent√£o, para quaisquer ùëê1 e ùëê2
complexos (e obviamente, reais) um vetor ‚Éóùë§ = ùëê1‚Éóùë¢ + ùëê2‚Éóùë£ √© tal que, ùê¥ ‚Éóùë§ = ùúÜ0 ‚Éóùë§.

Com efeito, pois,

ùê¥ ‚Éóùë§ = ùê¥(ùëê1‚Éóùë¢ + ùëê2‚Éóùë£) = ùëê1ùê¥‚Éóùë¢ + ùëê2ùê¥‚Éóùë£ = ùëê1ùúÜ0‚Éóùë¢ + ùëê2ùúÜ0‚Éóùë£ = ùúÜ0(ùëê1‚Éóùë¢ + ùëê2‚Éóùë£) = ùúÜ0 ‚Éóùë§.

Como os autovetores associados a um autovalor ùúÜ de uma matriz ùê¥ s√£o os vetores n√£o
‚àí ùê¥)‚Éóùë¢ = ‚Éó0, podemos aÔ¨Årmar que esses autovetores
nulos que satisfazem a equa√ß√£o (ùúÜùêºùëõ
‚àí ùê¥), ou seja, do conjunto que
s√£o os vetores n√£o nulos do espa√ßo nulo da matriz (ùúÜùêºùëõ
‚àíùê¥)‚Éóùë¢ = ‚Éó0. Esse conjunto √© denominado
coleciona as solu√ß√µes n√£o-nulas do sistema (ùúÜùêºùëõ
auto-espa√ßo de ùê¥ associado ùúÜ.

Proposi√ß√£o 1.3.3. Se ùëò for inteiro positivo, ùúÜ um autovalor de uma matriz quadrada ùê¥ de
ordem ùëõ e ‚Éóùë¢ um autovetor associado, ent√£o ùúÜùëò √© um autovalor de ùê¥ùëò e ‚Éóùë¢ √© um autovetor
associado.

Proposi√ß√£o 1.3.4. Se ùê¥ √© uma matriz quadrada de ordem ùëõ, ent√£o s√£o equivalentes as se-
guintes aÔ¨Årma√ß√µes:

(a) ùëëùëíùë°(ùê¥) (cid:44) 0, isto √©, ùê¥ √© invert√≠vel(n√£o singular);

(b) Os vetores-coluna de ùê¥ s√£o linearmente independentes e geram Rùëõ;

(c) Os vetores-linha de ùê¥ s√£o linearmente independentes e geram Rùëõ;

(d) Os vetores-coluna(e tamb√©m, linha) de ùê¥ formam uma base de Rùëõ.

Como consequ√™ncia desses resultados e para tornar pr√°tica a resolu√ß√£o de proble-
mas onde h√° necessidade de calcular pot√™ncias de matrizes, a decomposi√ß√£o de uma
‚àí1 onde ùëÜ √© uma matriz invert√≠vel e ùê∑ uma matriz diagonal,
matriz ùê¥ na forma ùê¥ = ùëÜùê∑ùëÜ
√© uma chave importante. Essa decomposi√ß√£o √© chamada de decomposi√ß√£o espectral da
matriz ùê¥ que por sua vez, √© dita ser diagonaliz√°vel. Os vetores-coluna da matriz ùëÜ s√£o
os autovetores de ùê¥ e as entradas da diagonal principal de ùê∑ s√£o os autovalores de ùê¥
associados aos respectivos autovetores.

Como exemplo dessa decomposi√ß√£o, consideremos a matriz

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 0 ‚àí2
1
1 2
3
1 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Seu polin√¥mio caracter√≠stico √© ùëÉùê¥(ùúÜ) = (ùúÜ ‚àí 2)2(ùúÜ ‚àí 1) e disso obtemos os autovalores
‚éû
‚àí1
0
1

, e, para ùúÜ = 1, o autovetor

ùúÜ1 = 2 com autovetores associados ‚Éóùë£ =

e ‚Éóùë¢ =

0
1
0

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éû

‚éõ

‚éõ

CAP√çTULO 1. PRELIMINARES

37

‚Éóùë§ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí2
1
1

forma,

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

. Assim, fazendo ùëÜ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí1 0 ‚àí2
1
1
0
1
0
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

, temos ùëÜ

‚àí1 =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

2
0
1
1
1
1
‚àí1 0 ‚àí1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

, e dessa

‚àí1ùê¥ùëÜ =

ùëÜ

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

2
0
1
1
1
1
‚àí1 0 ‚àí1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

0 0 ‚àí2
1
1 2
3
1 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

‚àí1 0 ‚àí2
1
1
0
1
0
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

=

2 0 0
0 2 0
0 0 1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

= ùê∑

donde conclu√≠mos que,

ùê¥ = ùëÜùê∑ùëÜ

‚àí1 =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí1 0 ‚àí2
1
1
0
1
0
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

2 0 0
0 2 0
0 0 1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

¬∑

2
0
1
1
1
1
‚àí1 0 ‚àí1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

2 Matrizes de Markov

Neste cap√≠tulo mostraremos uma importante ferramenta no estudo e na solu√ß√£o de
problemas que surgem a partir da an√°lise do comportamento de certos sistemas f√≠si-
cos que evolvem constantemente, sob a inÔ¨Çu√™ncia de um conjunto Ô¨Ånito de vari√°veis
cujos valores mudam com o passar do tempo. Esses sistemas s√£o chamados de Siste-
mas Din√¢micos e seu estudo compreende campos de pesquisa importantes da matem√°-
tica como a Teoria das Probabilidades, √Ålgebra Linear, F√≠sica Matem√°tica e Equa√ß√µes
Diferenciais; tendo aplica√ß√µes relevantes nas engenharias, biologia, economia, dentre
outras ci√™ncias sociais. DeÔ¨Åniremos as Matrizes de Markov, fruto de estudos do ma-
tem√°tico russo Andrei Andreyevich Markov que descreveu matematicamente, sob o
ponto de vista do produto matricial, o c√°lculo de probabilidades de ocorr√™ncia de cer-
tos eventos que dependem apenas do estado em que o fen√¥meno se encontra para que
seja calculada a probabilidade de estar num estado seguinte.

2.1 DeÔ¨Åni√ß√£o e exemplos iniciais

DeÔ¨Åni√ß√£o 2.1.1. Uma matriz quadrada ‚â• 0 diremos ser uma Matriz de Markov se a soma
das entradas de cada vetor-coluna √© sempre igual a 1.

Na Teoria da Probabilidade essas matrizes s√£o tradicionalmente chamadas de ma-
trizes de transi√ß√£o de probabilidades (ou simplesmente matriz de transi√ß√£o) e, cada
vetor-linha tem como soma de suas entradas o valor 1. Em nosso trabalho considera-
remos a soma das entradas de cada vetor-coluna sempre igual a 1.

Como exemplo trivial, a matriz ùê¥ =

identidade s√£o matrizes de Markov.

‚éõ

‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚é†

2
3
1
3

1
2
1
2

√© uma matriz de Markov; matrizes

As matrizes de Markov tamb√©m s√£o conhecidas como matrizes estoc√°sticas. Cada
coluna de uma matriz de Markov √© um vetor cujas entradas s√£o ‚â• 0 e com soma 1.
Cada um desses vetores s√£o chamados vetor de probabilidade (ou simplesmente, vetor
estoc√°stico). Vejamos alguns resultados acerca desse tipo especial de matriz.

Proposi√ß√£o 2.1.1. Se ‚Éóùëù √© um vetor estoc√°stico e ùê¥ √© uma matriz de Markov, ent√£o, ‚Éóùê¥ùëù √© um
vetor estoc√°stico.

Demonstra√ß√£o: Suponha que ‚Éóùëé1, ‚Éóùëé2, . . . , ‚Éóùëéùëõ sejam os vetores coluna de ùê¥ e ùëù1, ùëù2, . . . , ùëùùëõ
as entradas n√£o negativas do vetor estoc√°stico ‚Éóùëù. O produto ùê¥‚Éóùëù pode ser expresso como
uma combina√ß√£o linear dos vetores-coluna de ùê¥, com os coeÔ¨Åcientes sendo as entradas

40

CAP√çTULO 2. MATRIZES DE MARKOV

de ‚Éóùëù, isto √©, denotando por ùëùùëñ com 1 ‚â§ ùëñ ‚â§ ùëõ, as entradas de ‚Éóùê¥ùëù, segue que

ùê¥‚Éóùëù =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëù1
ùëù2
...
ùëùùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

para ùëù1 =

‚àëÔ∏Å

1‚â§ùëò‚â§ùëõ

ùëùùëòùëé1ùëò; ùëù2 =

‚àëÔ∏Å

1‚â§ùëò‚â§ùëõ

ùëùùëòùëé2ùëò; ¬∑ ¬∑ ¬∑ ; ùëùùëõ =

‚àëÔ∏Å

1‚â§ùëò‚â§ùëõ

ùëùùëòùëéùëõùëò.

Ora, se somarmos ùëù1 +ùëù2 +¬∑ ¬∑ ¬∑+ùëùùëõ obtemos ùëù1
que ùê¥‚Éóùëù √© um vetor estoc√°stico.

¬∑1+ùëù2

¬∑1+¬∑ ¬∑ ¬∑+ùëùùëõ

¬∑1 = 1, donde conclu√≠mos

Proposi√ß√£o 2.1.2. O produto de duas matrizes de Markov de uma mesma ordem √© uma
matriz de Markov.

Demonstra√ß√£o: Sejam ùê¥ e ùêµ duas matrizes de Markov de uma mesma ordem, e ‚Éóùëèùëñ com
1 ‚â§ ùëñ ‚â§ ùëõ os vetores-coluna de ùêµ. A matriz ùê¥ùêµ √© tal que, suas colunas s√£o os vetores ùê¥‚Éóùëèùëñ
com 1 ‚â§ ùëñ ‚â§ ùëõ. Note que cada ùê¥‚Éóùëèùëñ √© um vetor estoc√°stico, conforme provamos acima,
para todo ùëñ. Conclu√≠mos que ùê¥ùêµ √© uma matriz de Markov.

VeriÔ¨Åcamos com facilidade que a soma de duas matrizes de Markov n√£o √© uma
matriz de Markov, pois, considerando as matrizes ùê¥ e ùêµ, como da proposi√ß√£o acima, a
soma das entradas de cada vetor-coluna da matriz ùê¥ + ùêµ ser√° igual a 2. A inversa de
uma matriz de Markov n√£o √©, necessariamente, uma matriz de Markov. Com efeito,

pois, a matriz ùê¥ =

tem como inversa a matriz ùê¥

‚àí1 =

que, embora

‚éõ

‚éú‚éú‚éú‚éú‚éù

4 ‚àí2
‚àí3
3

‚éû

‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éù

1
2
1
2

‚éû

‚éü‚éü‚éü‚éü‚é†

1
3
2
3

tenha soma das entradas dos vetores-coluna iguais a 1, possui entradas negativas.

No que diz respeito a autovalores e autovetores de uma matriz de Markov, temos o

seguinte resultado.

Proposi√ß√£o 2.1.3. Uma matriz de Markov tem sempre um autovalor igual a 1. Qualquer
outro √©, em valor absoluto, menor do que ou igual a 1.

Demonstra√ß√£o: Seja ùê¥ uma matriz de Markov de ordem ùëõ. A soma das entradas de
cada vetor-linha de sua transposta ùê¥ùëá √© igual a 1. Dessa forma, a matriz ùê¥ùëá tem,
portanto, o autovetor

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1
1
...
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

‚Éóùë£ =

Como matrizes transpostas t√™m o mesmo determinante, como vimos no cap√≠tulo 1, as
‚àíùê¥ùëá ) t√™m o mesmo determinante, de maneira que os autovalo-
matrizes (ùúÜùêºùëõ
res de ùê¥ e de ùê¥ùëá s√£o os mesmos. Assim, como ùê¥ùëá tem autovalor 1, a matriz ùê¥ tamb√©m
possui autovalor 1.

‚àíùê¥) e (ùúÜùêºùëõ

CAP√çTULO 2. MATRIZES DE MARKOV

41

Suponha agora que ‚Éóùë¢ √© um autovetor associado a um autovalor com |ùúÜ| > 1. En-
t√£o, ùê¥ùëò ‚Éóùë¢ = |ùúÜ|ùëò ‚Éóùë¢ tem entradas que crescem exponencialmente para ùëò suÔ¨Åcientemente
grande. Isso implica que existe (ùê¥ùëò)ùëñùëó>1. Mas, ùê¥ùëò √© uma matriz de Markov e tem todas
as suas entradas ‚â§ 1. E assim, a suposi√ß√£o de um autovalor maior do que 1 n√£o pode
ser v√°lida, e ent√£o conclu√≠mos que todos os outros autovalores s√£o, em valor absoluto,
menor do que ou igual a 1.

Vamos ilustrar a deÔ¨Åni√ß√£o e os resultados acima.

‚éõ

‚éû

Exemplo 2.1.1. A matriz de Markov

1
5
1
5
1
5
1
5
1
5
vetor-linha igual a 1. Ent√£o, pela proposi√ß√£o acima, tem um autovalor ùúÜ1 = 1 e um autovetor

tem a soma das entradas de cada

1
5
1
5
1
5
1
5
1
5

1
5
1
5
1
5
1
5
1
5

1
5
1
5
1
5
1
5
1
5

1
5
1
5
1
5
1
5
1
5

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

associado ‚Éóùë¢ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1
1
1
1
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Ademais, essa matriz tem polin√¥mio caracter√≠stico ùëÉ (ùúÜ) = ùúÜ4(ùúÜ ‚àí 1), donde tiramos seu
outro autovalor ùúÜ2 = 0 com multiplicidade 4. Os autovetores associados a esse autovalor
s√£o:

‚Éóùë£1 =

,

‚Éóùë£2 =

,

‚Éóùë£3 =

,

‚Éóùë£4 =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí1
0
0
0
1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚àí1
0
0
1
0

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚àí1
0
1
0
0

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí1
1
0
0
0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

2.2 Matrizes Irredut√≠veis

Nesta se√ß√£o, trataremos de conceitos que s√£o menos estudados e trabalhados nos
cursos de √Ålgebra Linear, como os de matriz ‚â• 0, positiva, redut√≠vel e irredut√≠vel.
Nosso objetivo √© conhecer os elementos e propriedades relevantes que utilizaremos na
demonstra√ß√£o do Teorema de Perron-Frobenius. Faremos ent√£o, uma breve exposi√ß√£o
destes conceitos e de suas propriedades.

DeÔ¨Åni√ß√£o 2.2.1. Uma matriz real ùê¥ de tamanho ùëõ‚àípor‚àíùëõ √© uma matriz n√£o-negativa, a
‚â• 0 para cada ùëñ e ùëó em {1, 2, ..., ùëõ}. Por outro lado, se ùê¥ √©
qual denota-se por ùê¥ ‚â• 0, se ùê¥ùëñùëó

42

CAP√çTULO 2. MATRIZES DE MARKOV

uma matriz positiva ent√£o ela tem ùê¥ùëñùëó > 0 para cada ùëñ e ùëó em {1, 2, ..., ùëõ}, e por conseguinte,
a denotamos por ùê¥ > 0.

Notamos da deÔ¨Åni√ß√£o acima que, se ùê¥ ‚â• 0 ent√£o, para todo ùëò ‚â• 1, veriÔ¨Åca-se que
ùê¥ùëò ‚â• 0, e ainda, que ùê¥ùëò > 0 sempre que a matriz ùê¥ for positiva ou tiver a maior parte
das entradas de cada linha e de cada coluna n√£o-nula. Como exemplos de matrizes
‚â• 0 que utilizaremos neste trabalho, destacamos as matrizes de permuta√ß√£o, que s√£o
matrizes quadradas na qual cada linha e cada coluna tem uma √∫nica entrada igual a
1 e, todas as outras, nulas. Outra maneira de concebermos as matrizes de permuta-
√ß√£o √© veriÔ¨Åcarmos que elas resultam de um reordenamento das linhas(ou colunas) das
matrizes identidade. Nesse contexto, utilizando os vetores da base can√¥nica do espa√ßo
Rùëõ com ùëõ ‚â• 2, temos que, para ùëõ = 2 existem duas matrizes de permuta√ß√µes poss√≠veis,
a saber: (ùëí1, ùëí2) e (ùëí2, ùëí1). De modo an√°logo, veriÔ¨Åcamos que para ùëõ = 3 existem seis
matrizes de permuta√ß√µes poss√≠veis, para ùëõ = 4 existem vinte e quatro, etc. Nessas con-
di√ß√µes, existem ùëõ! matrizes de permuta√ß√µes poss√≠veis a partir da identidade de ordem
ùëõ. As matrizes

‚éõ

‚éú‚éú‚éú‚éú‚éù

0 1
1 0

‚éû

‚éü‚éü‚éü‚éü‚é† ,

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 0 1
1 0 0
0 1 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 1 0 0
1 0 0 0
0 0 1 0
0 0 0 1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

s√£o exemplos de algumas matrizes de permuta√ß√µes de ordens 2, 3 e 4, respectivamente.

Pela deÔ¨Åni√ß√£o das matrizes de permuta√ß√£o, podemos veriÔ¨Åcar facilmente que:

(i) O produto matricial entre matrizes de permuta√ß√£o √© uma matriz de permuta√ß√£o;

(ii) Elas s√£o matrizes ortogonais, isto √©, sua inversa √© igual √† sua transposta (ùëÉ

‚àí1 = ùëÉ ùëá ).
Em particular, o determinante de uma matriz de permuta√ß√£o √© sempre igual a ¬±1.

De fato, para (i) a conclus√£o √© imediata, pois, √© suÔ¨Åciente notarmos que, se trata da
permuta√ß√£o das linhas da identidade. Para (ii), note que ùëÉ ùëá ùëÉ = ùêº (onde ùêº √© a identidade
de ordem correspondente). Ademais, det(ùëÉ ùëá ùëÉ ) = det(ùëÉ ùëá ) det(ùëÉ ) = (det(ùëÉ ))2 = 1, donde
conclu√≠mos que det(ùëÉ ) = ¬±1.

Dada uma matriz ùê¥, o produto ùëÉ ùê¥ troca as linhas da matriz ùê¥, enquanto o produto
‚àí1ùê¥ùëÉ troca as linhas e as colunas de ùê¥ do mesmo

ùê¥ùëÉ troca as colunas. J√° o produto ùëÉ
modo.

DeÔ¨Åni√ß√£o 2.2.2. Uma matriz quadrada ùê¥ √© dita redut√≠vel se existe uma matriz de permu-
ta√ß√£o ùëÉ , tal que

‚àí1ùê¥ùëÉ =

ùëÉ

‚éõ

‚éú‚éú‚éú‚éú‚éù

ùëã ùëå
0 ùëç

‚éû

‚éü‚éü‚éü‚éü‚é† ,

CAP√çTULO 2. MATRIZES DE MARKOV

43

onde ùëã e ùëç s√£o matrizes quadradas; a matriz 0 √© nula e ùëå qualquer. Se uma matriz quadrada
ùê¥ n√£o √© redut√≠vel, ent√£o ela √© irredut√≠vel, o que signiÔ¨Åca dizer que a matriz ùê¥ n√£o √© similar,
por uma matriz de permuta√ß√£o, a uma matriz bloco-triangular-superior.

Nesse contexto, √© natural ent√£o, questionarmos: H√° alguma caracter√≠stica ou pro-
priedade comum √†s matrizes redut√≠veis? E √†s irredut√≠veis? Caso exista, √© poss√≠vel ilus-
trarmos tais caracter√≠sticas ou propriedades? Mencionamos que matrizes irredut√≠veis
s√£o fundamentais nos estudos de grupos lineares e representa√ß√µes de grupos [Za93].

Para toda matriz ùê¥ ‚â• 0 de tamanho ùëõ‚àípor‚àíùëõ podemos associar um grafo orientado
Œì (ùê¥), onde seus v√©rtices s√£o os n√∫meros 1, 2, ..., ùëõ e para cada par (ùëñ, ùëó) de v√©rtices existe
uma aresta orientada de ùëñ para ùëó se, e somente se ùê¥ùëñùëó > 0. Em um grafo como este, um
caminho orientado deÔ¨Åne uma sequ√™ncia de v√©rtices conectados por arestas orientadas.
‚àí1ùê¥ùëÉ ) =
A partir desta deÔ¨Åni√ß√£o e do efeito do produto ùëÉ
Œì (ùê¥) a menos da ordem dos v√©rtices.

‚àí1ùê¥ùëÉ sobre ùê¥, temos que Œì (ùëÉ

Vamos ilustrar alguns exemplos de matrizes ùê¥ ‚â• 0 e seus respectivos grafos asso-
ciados que nos ajudar√£o a identiÔ¨Åcar caracter√≠sticas ou propriedades comuns e que
sirvam tamb√©m como conveniente crit√©rio de redutibilidade e de irredutibilidade.

(1) Matrizes com algumas entradas nulas

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1 2 0
4 5 0
7 8 9

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

ùêµ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 2 0
4 5 6
7 8 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

Œì (ùê¥) :

1

(cid:47) 2

3(cid:69)

Œì (ùêµ) : 1

(cid:47) 2

3

VeriÔ¨Åcamos com os exemplos acima, a exist√™ncia de la√ßos nos v√©rtices 1, 2 e 3 da
matriz ùê¥ e no v√©rtice 2 da matriz ùêµ, que ilustram uma entrada positiva na diagonal
principal dessas matrizes. VeriÔ¨Åcamos tamb√©m facilmente que, em rela√ß√£o √† matriz ùê¥,
n√£o h√° caminhos orientados dos v√©rtices 1 e 2 para o v√©rtice 3, o que ilustra um grafo
n√£o fortemente conexo.

O resultado seguinte garante que a transposi√ß√£o de matrizes preserva a irredutibi-

lidade.

Proposi√ß√£o 2.2.1. Se ùê¥ √© uma matriz irredut√≠vel, ent√£o ùê¥ùëá tamb√©m √© irredut√≠vel.

Demonstra√ß√£o: Se ùê¥ùëá fosse redut√≠vel, ent√£o, existiria uma matriz de permuta√ß√£o ùëÑ
tal que,

‚àí1ùê¥ùëá ùëÑ =

ùëÑ

‚é°

‚é¢‚é¢‚é¢‚é¢‚é£

ùëã ùëå
0 ùëç

‚é§

‚é•‚é•‚é•‚é•‚é¶

,

(cid:23)
(cid:23)
(cid:47)
(cid:7)
(cid:7)
(cid:111)
(cid:111)
(cid:69)
(cid:64)
(cid:64)
(cid:79)
(cid:79)
(cid:47)
(cid:23)
(cid:23)
(cid:111)
(cid:111)
(cid:0)
(cid:0)
(cid:64)
(cid:64)
(cid:79)
(cid:79)
44

CAP√çTULO 2. MATRIZES DE MARKOV

para ùëã e ùëç quadradas. Com isso, e do fato de ùëÑ ser ortogonal, seguiria que,

‚àí1ùê¥ùëá ùëÑ = [ùëÑ

‚àí1ùê¥ùëÑ]ùëá

ùëÑ

e disso ter√≠amos, ùëÑ

‚àí1ùê¥ùëÑ =

‚é°

‚é¢‚é¢‚é¢‚é¢‚é£

ùëãùëá
0ùëá
ùëå ùëá ùëçùëá

‚é§

‚é•‚é•‚é•‚é•‚é¶

.

Considere a matriz de permuta√ß√£o ùëÉ cujas entradas s√£o todas nulas salvo aquelas
na diagonal n√£o-principal que s√£o iguais a 1. Em outros termos, se ùëÉ possui ordem
ùëõ-por-ùëõ ent√£o ùëùùëñùëó = 1 se ùëñ + ùëó = ùëõ + 1, ùëùùëñùëó = 0 sempre que ùëñ + ùëó (cid:44) ùëõ + 1. Notemos que se ùê¥
possui ordem ùëõ-por-ùëõ ent√£o ùê¥ùëÉ √© obtida de ùê¥ escrevendo-se as colunas de ùê¥ na ordem
inversa, e ùëÉ ùê¥ por sua vez, obtida de ùê¥ escrevendo-se as linhas de ùê¥ na ordem inversa.
Em particular, ùëÉ

‚àí1 = ùëÉ . Assim

ùëÉ

‚àí1(ùëÑ

‚àí1ùê¥ùëÑ)ùëÉ =

‚é•‚é•‚é•‚é•‚é¶
‚Ä≤ quadradas. Entretanto, isso contradiz a hip√≥tese de ùê¥ ser irre-

‚é¢‚é¢‚é¢‚é¢‚é£

‚Ä≤

ùëå
ùëã

‚Ä≤, ùëã

‚é§

‚Ä≤

‚é°

‚Ä≤

ùëç
0‚Ä≤

com submatrizes ùëç
dut√≠vel. Portanto, se ùê¥ √© irredut√≠vel, ent√£o ùê¥ùëá tamb√©m √© irredut√≠vel.

Podemos obter exemplos mais evidentes acerca das matrizes redut√≠veis e irredut√≠-

veis atrav√©s do resultado seguinte.

Proposi√ß√£o 2.2.2. Seja ùê¥ uma matriz ‚â• 0 de tamanho ùëõ‚àípor‚àíùëõ. Ent√£o, as seguintes aÔ¨År-
ma√ß√µes s√£o equivalentes:

(1) ùê¥ √© irredut√≠vel;

(2) O conjunto {1, 2, ..., ùëõ} n√£o pode ser dividido em dois subconjuntos n√£o-vazios ùêº e ùêΩ com

a propriedade: ùê¥ùëñùëó = 0 se ùëñ ‚àà ùêº e ùëó ‚àà ùêΩ;

(3) O grafo Œì (ùê¥) √© fortemente conexo, isto √©, para quaisquer dois v√©rtices distintos ùëñ e ùëó de

Œì (ùê¥), existe um caminho orientado de ùëñ para ùëó em Œì (ùê¥).

Demonstra√ß√£o: (1) ‚áí (2) : Suponhamos que o conjunto {1, 2, ..., ùëõ} seja particionado
em dois subconjuntos n√£o-vazios ùêº e ùêΩ, tal que, ùê¥ùëñùëó = 0 sempre que (ùëñ, ùëó) ‚àà ùêº √ó ùêΩ. En-
t√£o a matriz ùê¥ tem em alguma linha (ou coluna), no m√≠nimo, (ùëõ ‚àí 1) entradas nulas
abaixo (ou acima) da sua diagonal principal conforme ùëñ > ùëó (ou ùëñ < ùëó, respectivamente).
Dessa forma, e pela proposi√ß√£o anterior, conseguimos uma matriz de permuta√ß√£o ùëÉ
‚àí1ùê¥ùëÉ √© similar, por ùëÉ a uma matriz bloco-triangular-superior, o que
de tal sorte que ùëÉ
contradiz a irredutibilidade de ùê¥.

(2) ‚áí (3) Por outro lado, n√£o sendo poss√≠vel uma parti√ß√£o do conjunto {1, 2, ..., ùëõ}
em dois subconjuntos ùêº e ùêΩ com ùê¥ùëñùëó = 0, ent√£o devemos ter ùê¥ùëñùëó > 0 para cada par (ùëñ, ùëó),
ou ao menos, para os pares consecutivos dois a dois, tomados numa sequ√™ncia como
ùëñ1 < ùëñ2 < ¬∑ ¬∑ ¬∑ < ùëñùëò < ùëó. Pela deÔ¨Åni√ß√£o de grafo, temos associado √† matriz ùê¥ um grafo Œì (ùê¥)
fortemente conexo.

CAP√çTULO 2. MATRIZES DE MARKOV

45

(3) ‚áí (1) Se Œì (ùê¥) √© fortemente conexo ent√£o todos os seus v√©rtices est√£o dois a
dois, conectados direta ou indiretamente. Em outros termos, se ocorrer ùê¥ùëñùëóùõº = 0, ent√£o
ocorrer√° ùê¥ùëñùëóùõΩ > 0 e ùê¥ùëóùõΩùëóùõº > 0. Nessas condi√ß√µes, o conjunto {1, 2, ..., ùëõ} n√£o pode ser
particionado em dois subconjuntos n√£o vazios ùêº e ùêΩ com ùê¥ùëñùëó = 0 sempre que (ùëñ, ùëó) ‚àà ùêº √ó ùêΩ,
e consequentemente a matriz ùê¥ √© irredut√≠vel.

A partir do exposto at√© aqui, podemos elencar algumas caracter√≠sticas e proprieda-

des referentes √†s matrizes redut√≠veis e √†s irredut√≠veis por meio de alguns exemplos.

2.2.1 Exemplos de matrizes redut√≠veis

‚Ä¢ Matriz Identidade. De fato, pois, √© suÔ¨Åciente observarmos que todas as entradas
nulas est√£o distribu√≠das acima e abaixo da diagonal principal, e nesses casos, seus
grafos n√£o s√£o fortemente conexos e o conjunto {1, 2, ..., ùëõ} pode ser facilmente
dividido em subconjuntos ùêº e ùêΩ com ùê¥ùëñùëó = 0 sempre que ùëñ ‚àà ùêº e ùëó ‚àà ùêΩ.
‚éû

‚éõ

ùêº2 =

‚éú‚éú‚éú‚éú‚éù

1 0
0 1

‚éü‚éü‚éü‚éü‚é† ,

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1 0 0
0 1 0
0 0 1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

ùêº3 =

Œì (ùêº2) :

1

2

Œì (ùêº3) :

1

2

3(cid:69)

O que estende aos demais casos de dimens√£o superior a 3.

‚Ä¢ Matrizes Triangulares (inferiores e superiores). √â um caso an√°logo ao das ma-
trizes identidade, por√©m, aqui com entradas nulas inferiores (ou superiores) √†
diagonal principal, o que nos possibilita veriÔ¨Åcar.
‚éõ

‚éû

ùëáùëñ =

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0
0
ùõº1
0
ùõº2 ùõº3
ùõº4 ùõº5 ùõº6

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

ùëáùë† =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùõΩ1 ùõΩ2 ùõΩ3
0 ùõΩ4 ùõΩ5
0 ùõΩ6
0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

Œì (ùëáùëñ) : 1

2

3(cid:69)

Œì (ùëáùë†) : 1

2

3 (cid:89)

(cid:23)
(cid:23)
(cid:7)
(cid:7)
(cid:23)
(cid:23)
(cid:7)
(cid:7)
(cid:69)
(cid:23)
(cid:23)
(cid:7)
(cid:7)
(cid:111)
(cid:111)
(cid:69)
(cid:64)
(cid:64)
(cid:79)
(cid:79)
(cid:7)
(cid:7)
(cid:47)
(cid:47)
(cid:15)
(cid:15)
(cid:23)
(cid:23)
(cid:0)
(cid:0)
(cid:89)
46

CAP√çTULO 2. MATRIZES DE MARKOV

Em ambos os casos, veriÔ¨Åcamos que os grafos n√£o s√£o fortemente conexos, pois,
em Œì (ùëáùëñ) n√£o h√° caminho orientado do v√©rtice 1 para o v√©rtice 2, por exemplo.
Assim como ocorre em Œì (ùëáùë†) que n√£o h√° caminho orientado do v√©rtice 2 para o
v√©rtice 1. Nestes casos, o mesmo se aplica √†s matrizes de ordens superiores.

‚Ä¢ Matrizes com Ô¨Ålas nulas (linha ou coluna). Notamos com facilidade que um
vetor-linha (ou vetor-coluna) nulo em uma matriz ùê¥ùëõ√óùëõ nos d√° uma divis√£o do
conjunto {1, 2, ..., ùëõ} em dois subconjunto ùêº e ùêΩ com a propriedade: ùê¥ùëñùëó = 0 se ùëñ ‚àà ùêº
e ùëó ‚àà ùêΩ, pois, Ô¨Åxando uma linha ùëò para 1 ‚â§ ùëò ‚â§ ùëõ, isso nos d√° ùê¥ùëòùëó = 0 com ùëó
percorrendo os valores {1, 2, ..., ùëõ}, e ent√£o, tomamos os subconjuntos ùêº = {ùëò} e
ùêΩ = {1, 2, ..., ùëõ} ‚àñ {ùëò}. Ilustrando

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùê¥ =

ùê¥11
ùê¥21
...

ùê¥12
ùê¥22
...

¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑

¬∑ ¬∑ ¬∑

ùê¥1ùëõ
ùê¥2ùëõ
...

ùê¥ùëò1 = 0 ùê¥ùëò2 = 0 ¬∑ ¬∑ ¬∑ ùê¥ùëòùëõ = 0

...
ùê¥ùëõ1

...
ùê¥ùëõ2

¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑

...
ùê¥ùëõùëõ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

Conclu√≠mos de forma an√°loga tomando nula uma coluna arbitr√°ria de ùê¥.

2.2.2 Exemplos de matrizes irredut√≠veis

‚Ä¢ Matrizes Positivas. Com efeito, pois, dada uma matriz ùê¥ùëõ√óùëõ positiva, a matriz
‚àí1ùê¥ùëÉ n√£o ser√° bloco-triangular-superior, visto que n√£o possui entradas nulas.
ùëÉ
Temos ainda, associado a essa matriz um grafo fortemente conexo. Vejamos um
caso que ilustra essa caracter√≠stica.

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùê¥ =

ùê¥11 ùê¥12 ùê¥13 ùê¥14
ùê¥21 ùê¥22 ùê¥23 ùê¥24
ùê¥31 ùê¥32 ùê¥33 ùê¥34
ùê¥41 ùê¥42 ùê¥43 ùê¥44

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

,

Œì (ùê¥) : 1

3 (cid:89)

2

4(cid:69)

Analogamente estende-se para matrizes de ordem menor e maior do que 4.

‚Ä¢ Matrizes com diagonal principal nula e demais entradas positivas. Dada uma
matriz ùê¥ com essa caracter√≠stica, √© imediata a sua irredutibilidade uma vez que
ùê¥ùëñùëó = 0 se, e somente se ùëñ = ùëó. Nessas condi√ß√µes, ilustramos.

(cid:7)
(cid:7)
(cid:47)
(cid:47)
(cid:15)
(cid:15)
(cid:30)
(cid:30)
(cid:23)
(cid:23)
(cid:111)
(cid:111)
(cid:15)
(cid:15)
(cid:0)
(cid:0)
(cid:89)
(cid:47)
(cid:47)
(cid:79)
(cid:79)
(cid:64)
(cid:64)
(cid:69)
(cid:79)
(cid:79)
(cid:111)
(cid:111)
(cid:94)
(cid:94)
CAP√çTULO 2. MATRIZES DE MARKOV

47

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 ùê¥12 ùê¥13 ùê¥14
0 ùê¥23 ùê¥24
ùê¥21
0 ùê¥34
ùê¥31 ùê¥32
0
ùê¥41 ùê¥42 ùê¥43

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

Œì (ùê¥) : 1

3

2

4

‚Ä¢ Matrizes com diagonal n√£o-principal nula e demais entradas positivas. Dada
uma matriz ùê¥ùëõ√óùëõ com essa caracter√≠stica, basta veriÔ¨Åcarmos que ùê¥ùëñùëó = 0 se, e
somente se ùëñ + ùëó = (ùëõ + 1). Esse fato nos diz que, para cada ùëñ tem um √∫nico ùëó que
satisfaz essa igualdade, e portanto, o conjunto {1, 2, ..., ùëõ} n√£o pode ser dividido
em dois subconjuntos ùêº e ùêΩ. Vale tamb√©m salientar, que o grafo associado a uma
matriz nessas condi√ß√µes, √© fortemente conexo. Vejamos um exemplo.

ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0
ùê¥11 ùê¥12 ùê¥13
0 ùê¥24
ùê¥21 ùê¥22
0 ùê¥33 ùê¥34
ùê¥31
0 ùê¥42 ùê¥43 ùê¥44

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

Œì (ùê¥) : 1

3(cid:69)

2

(cid:54) 4 (cid:89)

2.3 Perron-Frobenius

O teorema de Perron-Frobenius emerge em diversos ramos da matem√°tica, por
exemplo nas teorias de automorÔ¨Åsmos de grupos livres [BH12], de sistemas din√¢micos
e erg√≥dicos [PY98], Sec. 3.2; e de categorias tensoriais [EGNO15], Sec. 3.2. Nesta se√ß√£o,
utilizaremos os conceitos de matriz ‚â• 0, positiva, de irredutibilidade e propriedades
dessas matrizes, que tratamos na se√ß√£o anterior, para a demonstra√ß√£o desse teorema
que √© o principal resultado desse cap√≠tulo.

DeÔ¨Åni√ß√£o 2.3.1. Seja ùê¥ uma matriz irredut√≠vel ‚â• 0, n√£o-nula. O autovalor denotado por
ùëÉ ùêπ(ùê¥) √© chamado de Autovalor Perron-Frobenius de ùê¥. Se ùê¥ √© irredut√≠vel, nula de or-
dem 1, deÔ¨Ånimos ùëÉ ùêπ(ùê¥) = 0. O vetor-coluna positivo ‚Éóùë£ com ùê¥‚Éóùë£ = ùëÉ ùêπ(ùê¥)‚Éóùë£ √© chamado de
Autovetor Direito Perron-Frobenius de ùê¥.

Teorema 2.3.1. (Perron-Frobenius) Seja ùê¥ uma matriz real ‚â• 0 n√£o-nula, irredut√≠vel.
Ent√£o,

(1) ùê¥ tem um √∫nico autovetor > 0, real, a menos da multiplica√ß√£o por um n√∫mero real

positivo; o autovalor ùëÉ ùêπ(ùê¥) associado √© positivo;

(cid:40)
(cid:40)
(cid:21)
(cid:21)
(cid:30)
(cid:30)
(cid:118)
(cid:118)
(cid:9)
(cid:9)
(cid:0)
(cid:0)
(cid:72)
(cid:72)
(cid:54)
(cid:54)
(cid:64)
(cid:64)
(cid:86)
(cid:86)
(cid:104)
(cid:104)
(cid:94)
(cid:94)
(cid:23)
(cid:23)
(cid:40)
(cid:40)
(cid:21)
(cid:21)
(cid:7)
(cid:7)
(cid:118)
(cid:118)
(cid:9)
(cid:9)
(cid:69)
(cid:72)
(cid:72)
(cid:54)
(cid:89)
(cid:86)
(cid:86)
(cid:104)
(cid:104)
48

CAP√çTULO 2. MATRIZES DE MARKOV

(2) ùëÉ ùêπ(ùê¥) = ùëÉ ùêπ(ùê¥ùëá );

(3) Para cada autovalor ùúÜ de ùê¥, vale | ùúÜ |‚â§ ùëÉ ùêπ(ùê¥);

(4) Para o autovalor ùëÉ ùêπ(ùê¥) corresponde um √∫nico autovetor real √† direita, a menos da

multiplica√ß√£o por um n√∫mero real;

Al√©m disso, sendo ‚Éóùúî um vetor-coluna real, n√£o-nulo , n√£o-negativo, e ùõº um n√∫mero real
n√£o-negativo, segue que

(5) Se ùê¥ ‚Éóùúî ‚â§ ùëÉ ùêπ(ùê¥) ‚Éóùúî, ent√£o ùê¥ ‚Éóùúî = ùëÉ ùêπ(ùê¥) ‚Éóùúî;

(6) Se ùê¥ ‚Éóùúî ‚â§ ùõº ‚Éóùúî, ent√£o ùëÉ ùêπ(ùê¥) ‚â§ ùõº.

Sugerimos a quem n√£o queira ler a demonstra√ß√£o dele que prove-o, √† guisa de exer-

c√≠cio, no caso 2-por-2. Comecemos por demonstrar o lema a seguir.

Lema 2.3.2. Seja ùê¥ uma matriz irredut√≠vel ‚â• 0, n√£o-nula de tamanho ùëõ-por-ùëõ. Ent√£o a
matriz ùêµ =

ùëñ=0 ùê¥ùëñ √© positiva. Em particular, se ùë• ‚àà Rùëõ, com 0 (cid:44) ùë• ‚â• 0, ent√£o ùêµùë• > 0.

‚àëÔ∏Äùëõ‚àí1

Demonstra√ß√£o: Note que cada entrada da diagonal principal de ùêµ √© positiva, isto √©,
ùêµùëñùëñ > 0. Note ainda que a matriz ùêµ pode ser expressa como

ùêµ = ùêºùëõ +

ùëõ‚àí1‚àëÔ∏Å

ùëñ=1

ùê¥ùëñ.

Devemos provar que ùêµùëñùëó > 0 para ùëñ (cid:44) ùëó. Como por hip√≥tese, ùê¥ √© irredut√≠vel, n√£o-
negativa e n√£o-nula, o grafo Œì (ùê¥) de ùê¥ √© fortemente conexo, isto √©, conforme provamos
na Proposi√ß√£o 2.2.2, para quaisquer dois v√©rtices distintos ùëñ, ùëó existe um caminho ori-
entado de ùëñ para ùëó formado por arestas orientadas entre dois v√©rtices consecutivos. Se
todos esses v√©rtices forem distintos, segue ainda da deÔ¨Åni√ß√£o do grafo Œì (ùê¥) de ùê¥ que
ùê¥ùëñ0ùëñ1ùê¥ùëñ1ùëñ2...ùê¥ùëñùëò‚àí1ùëñùëò > 0. Portanto, (ùê¥ùëò)ùëñùëó > 0 e consequentemente, ùêµùëñùëó > 0 como quer√≠amos
provar.

DeÔ¨Åni√ß√£o 2.3.2. Sejam ùëÅ e ùëÄ matrizes reais. Escrevemos ùëÅ ‚â§ ùëÄ para signiÔ¨Åcar que ùëÅ
‚â§ ùëÄùëñùëó para todo par de √≠ndices (ùëñ, ùëó). N√≥s tamb√©m
e ùëÄ t√™m o mesmo tamanho e que ùëÅùëñùëó
dizemos que a matriz ùëÅ √© dominada pela matriz ùëÄ se ùëÅ ‚â§ ùê¥, onde ùê¥ √© uma submatriz da
matriz ùëÄ.

‚àëÔ∏Äùëõ
DeÔ¨Åni√ß√£o 2.3.3. Para ‚Éóùë• = (ùë•1, . . . , ùë•ùëõ) ‚àà Rùëõ deÔ¨Ånimos | ‚Éóùë• |=
norma da soma. DeÔ¨Ånimos tamb√©m ùõ• = {Ô∏Ä‚Éóùë• ‚àà Rùëõ | ‚Éóùë• ‚â• 0; | ‚Éóùë• |= 1}Ô∏Ä.

ùëñ=1

| ùë•ùëñ

| que √© denominada

Temos uma representa√ß√£o geom√©trica desse conjunto quando associamos seus ele-
mentos a pontos do plano ou do espa√ßo, como um segmento de extremos (1, 0) e (0, 1)
em R2, ou uma regi√£o triangular com v√©rtices (1, 0, 0), (0, 1, 0) e (0, 0, 1) em R3.

CAP√çTULO 2. MATRIZES DE MARKOV

49

Figura 1 ‚Äì Representa√ß√£o geom√©trica de ‚àÜ em R2

Figura 2 ‚Äì Representa√ß√£o geom√©trica de ‚àÜ em R3

Deste ponto em diante, apresentamos uma demonstra√ß√£o do Teorema de Perron-
Frobenius que segue uma ideia sugerida pelo matem√°tico alem√£o Helmut Wielandt,
em Unzerlegbare nicht negative Matrizen, cuja tradu√ß√£o livre √© "Matrizes n√£o-negativas
irredut√≠veis".

Demonstra√ß√£o Perron-Frobenius: (1) e (2) Primeiro provamos que existe um vetor-
coluna ‚Éóùë¶ > 0 e um n√∫mero ùúÜ > 0, tal que, ùê¥‚Éóùë¶ = ùúÜ‚Éóùë¶. Seja ùê¥ uma matriz quadrada de
ordem ùëõ. Seja ‚Éóùë¢ um vetor-linha de tamanho ùëõ com cada entrada igual a 1. Conside-
rando um vetor ‚Éóùë• ‚àà ùõ•, aÔ¨Årmamos que sup{ùúå | ùëíùë•ùëñùë†ùë°ùëí ‚Éóùë• ‚àà ùõ•, ùë°ùëéùëô ùëûùë¢ùëí, ùê¥‚Éóùë• ‚â• ùúå‚Éóùë•} √© um
n√∫mero real. De fato, pois, se ùê¥‚Éóùë• ‚â• ùúå‚Éóùë• para algum ‚Éóùë• ‚àà ùõ•, ent√£o, claramente teremos

ùúå = ùúå‚Éóùë¢‚Éóùë• ‚â§ ‚Éóùë¢ùê¥‚Éóùë• ‚â§ ‚Éóùë¢ùê¥(‚Éóùë¢)ùëá .

Denotando o supremo acima por ùúÜ, segue do fato de ùõ• ser compacto que existe
um vetor ‚Éóùë¶ ‚àà ùõ•, tal que, ùê¥‚Éóùë¶ ‚â• ùúÜ‚Éóùë¶. Suponhamos por contradi√ß√£o, que ùê¥‚Éóùë¶ (cid:44) ùúÜ‚Éóùë¶. Ent√£o,

50

CAP√çTULO 2. MATRIZES DE MARKOV

‚Ä≤, e portanto, ùúÜ = ùúÜ
‚Éóùë¶‚Ä≤
| ‚Éóùë¶‚Ä≤ |

‚àëÔ∏Äùëõ‚àí1

ùêµùê¥‚Éóùë¶ > ùúÜùêµ‚Éóùë¶, onde ùêµ = ùêºùëõ +

ùëñ=1 ùê¥ùëñ √© positiva conforme provamos no Lema 2.3.2. Assim,
‚àà ùõ•, entretanto,

sendo fato que ùê¥ùêµ = ùêµùê¥, conseguimos obter ùê¥‚Éóùë• > ùúÜ‚Éóùë• para ‚Éóùë• =

ùêµ‚Éóùë¶
| ùêµ‚Éóùë¶ |
ùëñ=0 ùúÜùëñ ‚Éóùë¶, e sendo ùêµ‚Éóùë¶ > 0
isso contradiz a maximalidade de ùúÜ. Consequentemente, ùêµ‚Éóùë¶ =
obtemos tamb√©m do lema anterior que ‚Éóùë¶ > 0. Novamente, de ùê¥‚Éóùë¶ = ùúÜ‚Éóùë¶ segue que ùúÜ > 0.
Por simetria, existe um vetor-linha ‚Éóùëß > 0 e um n√∫mero real ùúá > 0, tais que, ‚Éóùëßùê¥ = ùúá‚Éóùëß.
Ent√£o, ùúá‚Éóùëß‚Éóùë¶ = ‚Éóùëßùê¥‚Éóùë¶ = ùúÜ‚Éóùëß‚Éóùë¶ e, ‚Éóùëß‚Éóùë¶ > 0, donde segue que ùúá = ùúÜ.
Agora, seja ‚Éóùë¶‚Ä≤ um autovetor positivo arbitr√°rio de ùê¥, e seja ùúÜ
Como anteriormente, obteremos ùúá = ùúÜ

‚Ä≤ o autovalor associado.
‚Ä≤. Suponhamos que ‚Éóùë¶‚Ä≤ n√£o

‚àëÔ∏Äùëõ‚àí1

e

seja um m√∫ltiplo escalar de ‚Éóùë¶. Ent√£o os pontos

‚Éóùë¶
| ‚Éóùë¶ | pertencem a ùõ•, s√£o distintos
e a reta que os cont√©m intercepta a borda de ùõ• em algum ponto ‚Éóùë£. Como ‚Éóùë£ √© autovetor
de ùê¥, e portanto, de ùêµ, conclu√≠mos que ùêµ‚Éóùë£ √© um m√∫ltiplo escalar de ‚Éóùë£. Assim, alguma
coordenada do vetor ‚Éóùêµùë£ √© nula, o que contradiz o Lema 2.3.2. Novamente, obtemos
ent√£o que ‚Éóùë¶‚Ä≤ √© um m√∫ltiplo escalar e assim, Ô¨Åca provado (1). Da identidade acima
ùúá = ùúÜ, obtemos a prova da aÔ¨Årma√ß√£o (2). Em particular, como ùê¥ e ùê¥ùëá t√™m o mesmo
polin√¥mio caracter√≠stico, possuem os mesmos autovalores.
(3) Seja ùê¥‚Éóùë¢ = ùúè ‚Éóùë¢ com ùúè ‚àà C e ‚Éóùë¢ ‚àà Cùëõ, para ‚Éóùë¢ (cid:44) 0. DeÔ¨Åna ‚Éóùë¢‚Ä≤ = (| ùë¢1
|)ùëá . Ent√£o
ùê¥ ‚Éóùë¢‚Ä≤ ‚â•| ùúè | ‚Éóùë¢‚Ä≤. Seja ‚Éóùëé > 0 o vetor-linha, tal que, ‚Éóùëéùê¥ = ùúÜ‚Éóùëé onde ùúÜ = ùëÉ ùêπ(ùê¥). Ent√£o ùúÜ‚Éóùëé ‚Éóùë¢‚Ä≤ =
‚Éóùëéùê¥ ‚Éóùë¢‚Ä≤ ‚â•| ùúè | ‚Éóùëé ‚Éóùë¢‚Ä≤ e ‚Éóùëé ‚Éóùë¢‚Ä≤ > 0, de modo que ùúÜ ‚â•| ùúè |.
(4) Seja ‚Éóùëè um autovetor positivo e ‚Éóùëê um autovetor arbitr√°rio associado a ùëÉ ùêπ(ùê¥). Ent√£o
para um n√∫mero suÔ¨Åcientemente grande ùëü > 0 o vetor ‚Éóùëê + ùëü‚Éóùëè tamb√©m √© um autovetor
positivo associado ao autovalor ùëÉ ùêπ(ùê¥). Pela aÔ¨Årma√ß√£o (1) este vetor, e portanto o vetor
‚Éóùëê √© um m√∫ltiplo escalar do vetor ‚Éóùëè.
(5) Suponha que ùê¥ ‚Éóùúî ‚â§ ùúÜ ‚Éóùúî e ùê¥ ‚Éóùúî (cid:44) ùúÜ ‚Éóùúî, onde ùúÜ = ùëÉ ùêπ(ùê¥). Seja ‚Éóùëß > 0 um vetor-linha tal
que, ‚Éóùëßùê¥ = ùúÜ‚Éóùëß. Ent√£o ùúÜ‚Éóùëß ‚Éóùúî = ‚Éóùëßùê¥ ‚Éóùúî < ùúÜ‚Éóùëß ‚Éóùúî √© uma contradi√ß√£o. Portanto, se ùê¥ ‚Éóùúî ‚â§ ùúÜ ‚Éóùúî ent√£o
ùê¥ ‚Éóùúî = ùúÜ ‚Éóùúî.
(6) Suponhamos que ùê¥ ‚Éóùúî ‚â§ ùõº ‚Éóùúî e ùúÜ > ùõº, onde ùúÜ = ùëÉ ùêπ(ùê¥). Tomando o vetor-linha ‚Éóùëß > 0
tal que ‚Éóùëßùê¥ = ùúÜ‚Éóùëß, segue que ùúÜ‚Éóùëß ‚Éóùúî = ‚Éóùëßùê¥ ‚Éóùúî ‚â§ ùõº‚Éóùëß ‚Éóùúî, o que √© um absurdo. Logo, se ùê¥ ‚Éóùúî ‚â§ ùõº ‚Éóùúî,
ent√£o ùëÉ ùêπ(ùê¥) ‚â§ ùõº, como quer√≠amos demonstrar.

|, ..., | ùë¢ùëõ

Teorema 2.3.3. Sejam ùëÄ e ùëÄ1 matrizes quadradas reais, ‚â• 0, e seja ùëÄ1 irredut√≠vel e do-
minada por ùëÄ. Suponha que ùëÄ ‚Éóùë§ ‚â§ ùúÜ ‚Éóùë§ para algum n√∫mero ùúÜ > 0 e vetor ‚Éóùë§ > 0. Ent√£o ou
ùëÉ ùêπ(ùëÄ1) < ùúÜ ou ùëÉ ùêπ(ùëÄ1) = ùúÜ e, a menos da conjuga√ß√£o por uma matriz de permuta√ß√£o,

ùëÄ =

‚éõ

‚éú‚éú‚éú‚éú‚éù

ùëÄ1 0
ùê∂ ùê∑

‚éû

‚éü‚éü‚éü‚éü‚é† .

Demonstra√ß√£o: Sem perda de generalidade, vamos supor que

ùëÄ =

‚éõ

‚éú‚éú‚éú‚éú‚éù

ùê¥ ùêµ
ùê∂ ùê∑

‚éû

‚éü‚éü‚éü‚éü‚é† ,

CAP√çTULO 2. MATRIZES DE MARKOV

51

e ùëÄ1

‚â§ ùê¥. Pondo ‚Éóùë§ =

triz ùê¥. Ent√£o,

Da√≠,

‚éõ

‚éú‚éú‚éú‚éú‚éù

‚Éóùë¢
‚Éóùë£

‚éû

‚éü‚éü‚éü‚éü‚é†

, onde o tamanho de ‚Éóùë¢ corresponde ao tamanho da subma-

‚éõ

‚éú‚éú‚éú‚éú‚éù

ùúÜ

‚éû

‚éü‚éü‚éü‚éü‚é†

‚Éóùë¢
‚Éóùë£

‚â• ùëÄ

‚éõ

‚éú‚éú‚éú‚éú‚éù

‚Éóùë¢
‚Éóùë£

‚éû

‚éü‚éü‚éü‚éü‚é†

‚éõ

‚éú‚éú‚éú‚éú‚éù

=

ùê¥‚Éóùë¢ + ùêµ‚Éóùë£
ùê∂ ‚Éóùë¢ + ùê∑‚Éóùë£

‚éû

‚éü‚éü‚éü‚éü‚é† ,

ùëÄ1‚Éóùë¢ ‚â§ ùê¥‚Éóùë¢ ‚â§ ùê¥‚Éóùë¢ + ùêµ‚Éóùë£ ‚â§ ùúÜ‚Éóùë¢.

Como ùëÄ1‚Éóùë¢ ‚â§ ùúÜ‚Éóùë¢, ent√£o segue da aÔ¨Årma√ß√£o (6) do Teorema 2.3.1 que ùëÉ ùêπ(ùëÄ1) ‚â§ ùúÜ. Caso
ùëÉ ùêπ(ùëÄ1) = ùúÜ, ent√£o pela aÔ¨Årma√ß√£o (5), ùëÄ1‚Éóùë¢ = ùúÜ‚Éóùë¢. Portanto, ùêµ‚Éóùë£ = 0. Sendo ‚Éóùë£ > 0, como
ùêµ ‚â• 0 ent√£o ùêµ = 0.

Corol√°rio 2.3.4. Sejam ùëÄ e ùëÄ1 matrizes quadradas reais, irredut√≠veis, ‚â• 0, e sendo ùëÄ1
dominada por ùëÄ e ùëÄ (cid:44) ùëÄ1. Ent√£o ùëÉ ùêπ(ùëÄ1) < ùëÉ ùêπ(ùëÄ).

Demonstra√ß√£o: Pelo Teorema 2.3.3 anterior, segue diretamente que ùëÄ1‚Éóùë¢ ‚â§ ùúÜ‚Éóùë¢. Supo-
‚éõ
‚éú‚éú‚éú‚éú‚éù

‚éû
, e isso contraria a hip√≥tese de ùëÄ

nha que ùëÉ ùêπ(ùëÄ1) = ùúÜ. Ent√£o ter√≠amos ùëÄ =

‚éü‚éü‚éü‚éü‚é†

ùê¥ 0
ùê∂ ùê∑

ser irredut√≠vel. Portanto, ùëÉ ùêπ(ùëÄ1) < ùëÉ ùêπ(ùëÄ) como quer√≠amos mostrar.

Teorema 2.3.5. Seja ùê¥ uma matriz ‚â• 0, n√£o-nula, irredut√≠vel, com entradas inteiras, e
autovalor Perron-Frobenius ùúÜ. Ent√£o, s√£o v√°lidos

(a) ùúÜ ‚â• 1;

(b) Se ùúÜ = 1, ent√£o ùê¥ √© uma matriz de permuta√ß√£o;

(c) ùê¥ùëñùëó

‚â§ ùúÜùëõ para todo ùëñ, ùëó em {1, . . . , ùëõ} .

Demonstra√ß√£o: Pelo Teorema de Perron-Frobenius, existe um vetor-coluna ‚Éóùë£ > 0 tal
que, ùê¥‚Éóùë£ = ùúÜ‚Éóùë£. Seja ‚Éóùë¢ o vetor-linha de tamanho ùëõ e cada entrada igual a 1. Assim, para
provarmos (a) e (b) calculamos diretamente

‚Éóùë¢ùê¥‚Éóùë£ = ùúÜ‚Éóùë¢‚Éóùë£ =

‚éõ
ùëõ‚àëÔ∏Å
‚éú‚éú‚éú‚éú‚éú‚éù

ùëñ=1

‚éû

‚éü‚éü‚éü‚éü‚éü‚é†

ùê¥ùëñ1

ùë£1 + ¬∑ ¬∑ ¬∑ +

‚éõ
ùëõ‚àëÔ∏Å
‚éú‚éú‚éú‚éú‚éú‚éù

ùëñ=1

‚éû

‚éü‚éü‚éü‚éü‚éü‚é†

ùê¥ùëñùëõ

ùë£ùëõ = ùúÜùë£1 + ¬∑ ¬∑ ¬∑ + ùúÜùë£ùëõ,

‚àëÔ∏Äùëõ

onde notamos que para cada ùëó a soma
ùëñ=1 ùê¥ùëñùëó √© pelo menos 1, pois, a matriz ùê¥ √© n√£o-
negativa, n√£o-nula, irredut√≠vel e tem entradas inteiras. Portanto, ùúÜ ‚â• 1. Se ùúÜ = 1, ent√£o
cada uma dessas somas ser√° igual a 1. Dessa forma, cada coluna da ùê¥ √© constitu√≠da
inteiramente de zeros, com exce√ß√£o de uma √∫nica entrada igual a 1. Com isso, ùê¥ n√£o
cont√©m linha nula e √© uma matriz de permuta√ß√£o.

Para (c), Ô¨Åxamos ùëñ, ùëó ‚àà {1, . . . , ùëõ}. Na demonstra√ß√£o do Lema 2.3.2 mostramos que
existe um n√∫mero natural ùëò tal que (ùê¥ùëò)ùëñùëó > 0; al√©m disso, 0 ‚â§ ùëò ‚â§ ùëõ ‚àí 1. Visto que ùê¥
tem suas entradas inteiras, segue que (ùê¥ùëò)ùëñùëó

‚â• 1. De ùê¥ùëò‚Éóùë£ = ùúÜùëò‚Éóùë£ temos

52

CAP√çTULO 2. MATRIZES DE MARKOV

Ademais, de ùê¥‚Éóùë£ = ùúÜ‚Éóùë£ deduzimos que

ùë£ùëó

‚â§ (ùê¥ùëò)ùëñùëóùë£ùëó

‚â§ ùúÜùëòùë£ùëó.

ùê¥ùëñùëóùë£ùëó

‚â§ ùúÜùë£ùëó

‚â§ ùúÜùëò+1ùë£ùëó

‚â§ ùúÜùëõùë£ùëó,

o que prova (c).

Corol√°rio 2.3.6. Seja ùëü um n√∫mero real e ùëõ um n√∫mero natural. Ent√£o existe apenas um
n√∫mero Ô¨Ånito de matrizes quadradas ‚â• 0, irredut√≠veis, com entradas inteiras e autovalores
Perron-Frobenius n√£o excedendo ùëü.

Demonstra√ß√£o: De fato, pelo teorema anterior como cada entrada de uma tal matriz
ùê¥ √© inteira, ela est√° no intervalo [0, ùëüùëõ].

3 Aplica√ß√µes

Neste cap√≠tulo, apresentaremos 4 exemplos com problemas onde podemos veriÔ¨Å-
car aplica√ß√µes das matrizes de Markov e do Teorema de Perron-Frobenius. S√£o eles:
Problema 4 da 23¬∫ OBM; Problema dos ùëõ mentirosos; O PageRank e O Modelo de
Difus√£o de Ehrenfest.

3.1 XXIII OBM - Olimp√≠ada Brasileira de Matem√°tica

Um ratinho ocupa inicialmente a gaiola ùê¥ e √© treinado para mudar de gaiola atravessando
um t√∫nel sempre que soa um alarme. Cada vez que soa o alarme o ratinho escolhe qualquer
um dos t√∫neis incidentes a sua gaiola com igual probabilidade e sem ser afetado por escolhas
anteriores. Qual √© a probabilidade de que ap√≥s o alarme soar 23 vezes, o ratinho ocupe a
gaiola ùêµ?

Figura 3 ‚Äì Um esquema das gaiolas

Este √© o problema 4 proposto na 23¬™ Olimp√≠ada Brasileira de Matem√°tica, [Eur02].

Resolu√ß√£o: Diferentemente do que √© apresentado nas resolu√ß√µes j√° publicadas ante-
riormente, utilizaremos a matem√°tica subjacente a partir do instrumental referente √†
Cadeia de Markov [Dia09] e diagonaliza√ß√£o de matrizes. Para tanto, come√ßamos por
considerar o conjunto ùêæ = {1, 2, 3, 4, 5, 6}, que representa os estados de transi√ß√µes or-
denadas das gaiolas de A at√© F, respectivamente. De acordo com as informa√ß√µes do
problema, ‚Äúcada vez que o alarme soa o ratinho escolhe qualquer um dos t√∫neis inci-
dentes a sua gaiola com igual probabilidade e sem ser afetado por escolhas anteriores‚Äù,
isso ent√£o nos diz que as transi√ß√µes satisfazem a uma Cadeia de Markov. A partir das
disposi√ß√µes das gaiolas, veriÔ¨Åcamos as probabilidades condicionais ùëÉ (ùëãùëõ+1 = ùëó|ùëãùëõ = ùëñ)
associadas √†s transi√ß√µes, e disso, os valores ùëù = 1
2 quando estiver saindo das gaiolas A,
C, F e D, e, ùëû = 1
Com isso, podemos construir a seguinte matriz ùëÄ de transi√ß√£o:

3 quando estiver saindo das gaiolas B e E.

54

CAP√çTULO 3. APLICA√á√ïES

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùëÄ =

2 0 1

0 1
3 0 1
1
0 1
2 0 0 0 1
1
3 0 1
0 1
0 0 1

2 0 0
3 0 1
3 0
2 0 0 0 1
2
2 0
3 0 1
3
2 0

2 0 1

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

)Ô∏Å
(Ô∏Å
1 0 0 0 0 0

onde ùëÄùëá √© uma Matriz de Markov. Considerando ‚ÉóùëÄ0 =
o vetor-
linha estoc√°stico inicial de distribui√ß√£o de probabilidade (posto que o ratinho est√° ini-
(23)
cialmente na gaiola A(cid:79)) precisamos calcular ùëÄ
12 , isto √©, a probabilidade do ratinho
ocupar a gaiola B ap√≥s o alarme soar 23 vezes, e que por sua vez, √© o mesmo que a
segunda coordenada do vetor ‚ÉóùëÄ0ùëÄ23. Para isso, devemos calcular a pot√™ncia ùëÄ23 o
que pode parecer intimidador, computacionalmente. Entretanto, se pudermos lan√ßar
‚àí1, onde a matriz ùëÜ √© invert√≠vel
m√£o da decomposi√ß√£o da matriz ùëÄ na forma ùëÄ = ùëÜùê∑ùëÜ
e a matriz ùê∑ √© diagonal, obteremos ent√£o, com facilidade

ùëÄ23 = (ùëÜùê∑ùëÜ

‚àí1)23 = ùëÜùê∑23ùëÜ

‚àí1 = ùëÜ.

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùê∑

(23)
11
0

0

0

0

0

ùê∑

0
(23)
22
0

0

0

0

ùê∑

0

0
(23)
33
0

0

0

0

0

ùê∑

0
(23)
44
0

0

0

0

0

ùê∑

0
(23)
55
0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

0

0

0

0

0
(23)
66

ùê∑

‚àí1

.ùëÜ

uma vez que, para elevar uma matriz diagonal a uma pot√™ncia ùëõ basta elevar cada
entrada de sua diagonal principal a ùëõ. Assim, a matriz ùëÄ ser√° diagonaliz√°vel e, as
entradas da diagonal principal da matriz ùê∑ ser√£o os autovalores de ùëÄ. Uma pergunta
surge naturalmente: A matriz ùëÄ √© diagonaliz√°vel? De acordo com o que mostramos
em Se√ß√£o 1.3 a resposta √© sim, pois, ùëÄ tem seis autovalores distintos. Considerando os
vetores-linha de ùëÄ, notamos que para cada um deles a soma de suas entradas √© igual 1.
Esse fato, de imediato nos d√° que ùúÜ1 = 1 √© um autovalor de ùëÄ que tem como autovetor

direito associado ‚Éóùë£1 =

. Do fato do tra√ßo da matriz ùëÄ ser nulo, isso nos garante

que, ou ‚àí1 √© um dos outros cinco autovalores, ou, √© a soma de ao menos, dois outros.
Buscando os demais autovalores encontramos o polin√¥mio caracter√≠stico

‚éõ
‚éû
1
1
1
1
1
1

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

CAP√çTULO 3. APLICA√á√ïES

55

ùëëùëíùë°(ùúÜùêº6

‚àí ùëÄ) =

‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí

2 0 1

ùúÜ 1
3 ùúÜ 1
1
0 1
2 0 0 ùúÜ 1
1
3 0 1
0 1
0 0 1

2 0 0
3 0 1
3 0
2 ùúÜ 0 0 1
2
2 0
3 ùúÜ 1
3
2 ùúÜ

2 0 1

‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí‚Éí

= ùúÜ6 ‚àí 23
18

ùúÜ4 +

41
144

ùúÜ2 ‚àí 1
144

o qual notamos facilmente a partir dos expoentes pares da vari√°vel ùúÜ, que tem ra√≠zes
com valores sim√©tricos. Podemos, ent√£o, aÔ¨Årmar que ùúÜ2 = ‚àí1 √© outro autovalor de ùëÄ.
Calculando as demais ra√≠zes do polin√¥mio equivalente 144ùúÜ6 ‚àí 184ùúÜ4 + 41ùúÜ2 ‚àí 1 = 0,
estas s√£o ùúÜ = ¬±1
2

. Com os demais autovetores, obtemos:

e ùúÜ = ¬±1
6

‚Ä¢ ùúÜ1 = 1

associado a

‚Éóùë£1 =

)Ô∏Å
(Ô∏Å
;
1 1 1 1 1 1

‚Ä¢ ùúÜ2 = ‚àí1

associado a

‚Éóùë£2 =

(Ô∏Å

‚àí1 1 ‚àí1 1 ‚àí1 1

)Ô∏Å
;

‚Ä¢ ùúÜ3 =

1
2
‚Ä¢ ùúÜ4 = ‚àí1
2
‚Ä¢ ùúÜ5 = ‚àí1
6

‚Ä¢ ùúÜ6 =

1
6

associado a

‚Éóùë£3 =

)Ô∏Å
(Ô∏Å
‚àí1 0 1 ‚àí1 0 1
;

associado a

‚Éóùë£4 =

(Ô∏Å

)Ô∏Å
1 0 ‚àí1 ‚àí1 0 1
;

associado a

‚Éóùë£5 =

associado a

‚Éóùë£6 =

(Ô∏Ç

1 ‚àí4
3
(Ô∏Ç
‚àí1 ‚àí4
3

1 1 ‚àí4
3

‚àí1 1

4
3

)Ô∏Ç

1

;

)Ô∏Ç

1

.

A partir desses resultados, e do fato de que todos os autovalores s√£o distintos e com
multiplicidade alg√©brica 1, e que portanto, seus autovetores s√£o linearmente indepen-
dentes, a matriz ùëÄ √© diagonaliz√°vel. Formando uma matriz ùëÜ com os seis autovetores
de ùëÄ sendo seus vetores-coluna, temos de imediato que ùëÜ √© invert√≠vel. Com isso, en-
contramos a decomposi√ß√£o espectral de ùëÄ = ùëÜùê∑ùëÜ

‚àí1 como segue,

‚éõ
‚àí1
1
‚àí1 ‚àí1
1 ‚àí1
‚àí1
1

1
0 ‚àí 4
‚àí 4
3
3
1 ‚àí1
1
0 ‚àí 4
3
1
1

1 ‚àí1 ‚àí1 1
1
0
1
1
1 ‚àí1 1
4
1
0
3
1
1
1

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éû
‚éõ
‚àí1
0 0 0
0
0
0 ‚àí 1
0 0 0
0
2
0 ‚àí 1
6 0 0 0
0
1
6 0 0
0
0
0
0 1
2 0
0
0
0
0 0 1
0
0
0

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚àí 1
7
1
4
3
28
‚àí 3
28
‚àí 1
4
1
7

.

3
14
0
‚àí 3
14
‚àí 3
14
0
3
14

‚àí 1
7
‚àí 1
4
3
28
‚àí 3
28
1
4
1
7

1
7
‚àí 1
4
3
28
3
28
‚àí 1
4
1
7

‚àí 3
14
0
‚àí 3
14
3
14
0
3
14

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

1
7
1
4
3
28
3
28
1
4
1
7

.

Finalmente, calculamos

‚ÉóùëÄ0.ùëÄ23 =

(Ô∏É
0

)Ô∏É

(Ô∏É

¬∑

3
7

623 + 1
623

0

2
7

+

1
224

‚àí 3
14

¬∑ 1
623 0

2
7

+

1
224

‚àí 3
14

¬∑ 1
623

)Ô∏É

56

CAP√çTULO 3. APLICA√á√ïES

donde tiramos que ùëÄ

mada de 42, 85%.

(23)
12 =

)Ô∏É

(Ô∏É

¬∑

3
7

623 + 1
623

(cid:27) 0, 4285, isto √©, uma probabilidade aproxi-

3.2 O Problema dos ùëõ mentirosos

O Problema dos ùëõ mentirosos e a Cadeia de Markov [Fel67] "Se cada uma das pessoas
ùê¥, ùêµ, ùê∂, ùê∑ dizem a verdade uma vez em tr√™s vezes (independentemente), e ùê¥ aÔ¨Årma que ùêµ
nega que ùê∂ declara que ùê∑ √© um mentiroso, qual a probabilidade de que ùê∑ estava dizendo a
verdade?"

Este problema foi primeiramente tratado por A.S. Eddington e teve sua solu√ß√£o

publicada em Monthly [4288, Vol.57(1950) pp. 43-45].

Resolu√ß√£o: Note inicialmente que, existem apenas oito declara√ß√µes distintas que po-
dem ser feitas pela pessoa ùê¥. Na formula√ß√£o original, as pessoas ùê∂, ùêµ e ùê¥ declaram
sucessivamente tr√™s aÔ¨Årma√ß√µes que podem ser verdadeiras ou falsas, e que podem se
contradizer. Tem-se ainda que, apenas ùê∑ e ùê∂ conhecem o estado inicial. No entanto,
tomado pelo valor nominal, cada aÔ¨Årma√ß√£o implicaria ou que ùê∑ est√° dizendo a ver-
dade ou que ele mente. Assim, por exemplo, se ùêµ negar que ùê∂ aÔ¨Årma que ùê∑ √© um
mentiroso, ele implica que ùê∑ diz a verdade. Se, por outro lado, ùê¥ nega que ùêµ negou,
etc., ent√£o isso implica que ùê∑ √© um mentiroso. Utilizaremos uma terminologia neutra,
e falaremos de um processo casual com dois estados poss√≠veis onde, eventualmente, o
estado observado √© 1 ou 2 conforme a √∫ltima aÔ¨Årma√ß√£o de que ùê∑ √© honesto ou menti-
roso. Inicialmente, ou seja, no instante 0, o estado observado √© 1 ou 2 de acordo com o
que ùê∑ diz verdade ou mentira, respectivamente, e, cada sequ√™ncia de amostra poss√≠vel
do processo acaba sendo representada por uma sucess√£o dos d√≠gitos 1 e 2.

Fundamentalmente, o processo de Markov caracteriza-se pelo fato de que cada pes-
soa conhece apenas a aÔ¨Årma√ß√£o da √∫ltima falante. Ainda, no instante ùëõ o estado obser-
vado muda ou permanece o mesmo de acordo com a ùëõ-√©sima falante diz a verdade ou
mente. Nessas condi√ß√µes, obtemos um modelo que representa uma Cadeia de Markov
mais simples:

‚Ä¢ Temos dois estados poss√≠veis 1 e 2 nos quais, inicialmente, as suas respectivas
probabilidades s√£o ùõº e ùõΩ, naturalmente com ùõº + ùõΩ = 1. Independentemente do
que ocorra at√© o tempo ùëõ, temos probabilidade ùëù de que exatamente no tempo ùëõ, o
estado observado n√£o sofra altera√ß√£o, e ùëû = (1‚àíùëù) de que haja altera√ß√£o. Buscamos
as probabilidades condicionais ùë•ùëõ e ùë¶ùëõ que o processo realmente come√ßou a partir
do estado 1 dado que, no tempo ùëõ o estado observado √©, respectivamente, 1 ou 2.

Na vers√£o original, tem-se ùõº = ùëù =

, ùëõ = 3 e somente ùë•ùëõ √© requerida;

1
3

CAP√çTULO 3. APLICA√á√ïES

57

‚Ä¢ Em cada etapa temos quatro transi√ß√µes poss√≠veis 1 ‚Ü¶‚Üí 1, 1 ‚Ü¶‚Üí 2, 2 ‚Ü¶‚Üí 1, 2 ‚Ü¶‚Üí 2 e
as correspondentes probabilidades de transi√ß√£o, por suposi√ß√£o, s√£o ùëù11 = ùëù22 =
ùëù e ùëù12 = ùëù21 = (1 ‚àí ùëù). Assim, supondo que em um determinado momento o
(ùëõ)
ùëóùëò a probabilidade de que ùëõ etapas depois, o
sistema est√° num estado ùëó e sendo ùëù
(ùëõ)
ùëóùëò √© chamada a probabilidade de transi√ß√£o
estado observado seja ùëò, temos que ùëù
(1)
ùëó ‚Ü¶‚Üí ùëò da ùëõ-√©sima etapa, onde claramente ùëù
ùëóùëò = ùëùùëóùëò e, a partir das possibilidades
de transi√ß√£o do estado ùëó para o estado ùëò em duas etapas e de suas respectivas
probabilidades,

ùëù

(2)
ùëóùëò = ùëùùëó1ùëù1ùëò + ùëùùëó2ùëù2ùëò.

(3.1)

O que de modo geral, a partir de igualdades recursivas, pode ser expresso por,

ùëù

(ùëõ+1)
ùëóùëò

= ùëù

(ùëõ)
ùëó1 ùëù1ùëò + ùëù

(ùëõ)
ùëó2 ùëù2ùëò.

(3.2)

As igualdades (3.1) e (3.2) acima podem ser obtidas de forma direta por meio das
pot√™ncias da matriz

ùëÉ =

‚éõ

ùëù
‚éú‚éú‚éú‚éú‚éù
1 ‚àí ùëù

‚éû

‚éü‚éü‚éü‚éü‚é†

1 ‚àí ùëù
ùëù

‚éõ

‚éú‚éú‚éú‚éú‚éù

=

ùëù11 ùëù12
ùëù21 ùëù22

‚éû

‚éü‚éü‚éü‚éü‚é† .

(3.3)

‚Ä¢ Sendo ùõº e ùõΩ as probabilidades iniciais respectivas aos estados 1 e 2, ent√£o, deno-

tando por ùëí

(ùëõ)
ùëò a probabilidade de observar no instante ùëõ o estado ùëò, segue que,

ùëí

(ùëõ)
ùëò = ùõºùëù

(ùëõ)
1ùëò + ùõΩùëù

(ùëõ)
2ùëò .

Encontramos, portanto, para as probabilidades condicionais ùë•ùëõ e ùë¶ùëõ, que

ùë•ùëõ =

ùõºùëù

(ùëõ)
11
(ùëõ)
ùëí
1

,

ùë¶ùëõ =

ùõºùëù

(ùëõ)
12
(ùëõ)
ùëí
2

.

(3.4)

(3.5)

‚Ä¢ Retomando √† matriz ùëÉ em (3.3). Precisamos calcular ùëÉ ùëõ, e para isso, conforme
utilizamos na resolu√ß√£o do problema (3.1), escreveremos a sua decomposi√ß√£o es-
pectral. Como ùëÉ √© uma matriz de Markov, e seus vetores-linha tem a soma de
suas coordenadas iguais a 1, temos que ùúÜ1 = 1 √© um autovalor associado ao auto-
)Ô∏Å
. Buscando o outro autovalor e autovetor associado encontramos,
vetor ‚Éóùë£1 =
ùúÜ2 = (2ùëù ‚àí 1) e ‚Éóùë£2 =

)Ô∏Å
. Assim, escrevemos a decomposi√ß√£o

(Ô∏Å
1 ‚àí1

(Ô∏Å
1 1

‚éõ

‚éû
1
1
‚éú‚éú‚éú‚éú‚éù
‚àí1 1

‚éü‚éü‚éü‚éü‚é† .

‚éõ

‚éú‚éú‚éú‚éú‚éù

ùëÉ =

2ùëù ‚àí 1 0
1

0

‚éû

‚éü‚éü‚éü‚éü‚é† .

‚éõ

‚éú‚éú‚éú‚éú‚éù

1
2
1
2

‚éû

‚éü‚éü‚éü‚éü‚é† .

‚àí 1
2
1
2

58

CAP√çTULO 3. APLICA√á√ïES

Consequentemente,

ùëÉ ùëõ =

‚éõ

‚éú‚éú‚éú‚éú‚éù

‚éû
1
1
‚àí1 1

‚éü‚éü‚éü‚éü‚é† .

‚éõ
(2ùëù ‚àí 1)ùëõ 0
‚éú‚éú‚éú‚éú‚éù
1

0

‚éû

‚éü‚éü‚éü‚éü‚é† .

‚éõ

‚éú‚éú‚éú‚éú‚éù

1
2
1
2

‚éû

‚éü‚éü‚éü‚éü‚é†

‚àí 1
2
1
2

=

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

(2ùëù ‚àí 1)ùëõ + 1
2
1 ‚àí (2ùëù ‚àí 1)ùëõ
2

1 ‚àí (2ùëù ‚àí 1)ùëõ
2
(2ùëù ‚àí 1)ùëõ + 1
2

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

(3.6)

Finalmente, para explicitarmos as probabilidades condicionais conforme exibidas
em (3.5) basta substituirmos as express√µes (3.6) e (3.4) nesta igualdade, o que nos d√°,

ùë•ùëõ =

ùõº. [(2ùëù ‚àí 1)ùëõ + 1]
1 + (2ùëù ‚àí 1)ùëõ.(ùõº ‚àí ùõΩ)

,

ùë¶ùëõ =

ùõº. [1 ‚àí (2ùëù ‚àí 1)ùëõ]
1 ‚àí [(2ùëù ‚àí 1)ùëõ.(ùõº ‚àí ùõΩ)]

.

(3.7)

1
3

13
41

Como na vers√£o original, estamos interessados em determinar ùë•ùëõ para ùëõ = 3 e
. Substituindo os valores em quest√£o, conclu√≠mos que a probabilidade pro-

ùõº = ùëù =

7
20

(cid:27) 31, 71%. Al√©m disso, temos ùë¶ùëõ =

. Conv√©m ainda veriÔ¨Åcarmos
curada √© ùë•3 =
‚Üí ùõº conforme ùëõ ‚Üí ‚àû, isto √©, a probabilidade
que, como 0 < ùëù < 1, ent√£o claramente ùë•ùëõ
condicional de que o processo come√ßou a partir do estado 1, dado que para um n√∫mero
suÔ¨Åcientemente grande de etapas o estado observado √© novamente 1, converge para a
probabilidade inicial ùõº.
Mentiroso Preferencial. At√© aqui, as chances de uma pessoa dizer a verdade n√£o de-
pendem da aÔ¨Årma√ß√£o que ele deve transmitir. Suponhamos ent√£o, que cada pessoa
tem a prefer√™ncia de aÔ¨Årmar que ùê∑ diz a verdade. Assim, uma transi√ß√£o 1 ‚Ü¶‚Üí 1 √© mais
prov√°vel que 2 ‚Ü¶‚Üí 2, enquanto 1 ‚Ü¶‚Üí 2 √© menos prov√°vel que 2 ‚Ü¶‚Üí 1. Podemos tratar
este caso geral da mesma forma que tratamos o problema espec√≠Ô¨Åco anterior. Para isso,
‚Ä≤. Naturalmente, todas as igualdades
‚Ä≤ e ùëù22 = ùëù
fa√ßamos ùëù11 = ùëù, ùëù12 = 1 ‚àí ùëù, ùëù21 = 1 ‚àí ùëù
acima s√£o aplicadas, exceto a igualdade (3.6) que deve ser substitu√≠da por

ùëÉ ùëõ =

‚éõ

ùëù
‚éú‚éú‚éú‚éú‚éù
1 ‚àí ùëù

‚Ä≤

‚éû
ùëõ

‚éü‚éü‚éü‚éü‚é†

1 ‚àí ùëù
‚Ä≤
ùëù

=

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

(ùëù + ùëù

(ùëù + ùëù

‚Ä≤ ‚àí 1)ùëõ(ùëù ‚àí 1) + ùëù
ùëù + ùëù‚Ä≤ ‚àí 2
‚Ä≤ ‚àí 1)ùëõ(1 ‚àí ùëù
ùëù + ùëù‚Ä≤ ‚àí 2

‚Ä≤) + ùëù

‚Ä≤ ‚àí 1

(ùëù + ùëù

‚Ä≤ ‚àí 1)ùëõ(1 ‚àí ùëù) + ùëù ‚àí 1

‚Ä≤ ‚àí 1

(ùëù + ùëù

‚Ä≤ ‚àí 1)ùëõ(ùëù

‚Ä≤ ‚àí 1) + ùëù ‚àí 1

ùëù + ùëù‚Ä≤ ‚àí 2

ùëù + ùëù‚Ä≤ ‚àí 2

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

Nessas condi√ß√µes, o resultado Ô¨Ånal √© agora

ùë•ùëõ =

ùõº ¬∑ [(1 ‚àí ùëù

‚Ä≤) + (1 ‚àí ùëù) ¬∑ (ùëù + ùëù
(1 ‚àí ùëù‚Ä≤) + [ùõº(1 ‚àí ùëù) ‚àí ùõΩ(1 ‚àí ùëù‚Ä≤)] ¬∑ (2ùëù‚Ä≤ ‚àí 1)ùëõ

‚Ä≤ ‚àí 1)ùëõ]

3.3 O PageRank

Um conjunto de n√≥s com conex√µes √© um grafo. Qualquer rede pode ser descrita
por um grafo. A estrutura de links da web forma um grafo, onde os sites individuais
s√£o os n√≥s e existe uma seta do site ùëéùëñ para o site ùëéùëó se ùëéùëñ se liga a ùëéùëó. A matriz de

CAP√çTULO 3. APLICA√á√ïES

59

adjac√™ncia ùê¥ deste grafo √© chamada de grafo da web. Se houver ùëõ sites, ent√£o a matriz
de adjac√™ncia √© uma matriz ùëõ √ó ùëõ com entradas ùê¥ùëñùëó = 1 se existir um link de ùëéùëñ para ùëéùëó.
Se dividirmos cada coluna pela quantidade de n√∫meros 1 dessa coluna, obtemos uma
matriz de Markov A que √© chamada de matriz da web normalizada. DeÔ¨Åna a matriz

1
ùëõ

para todo ùëñ, ùëó. Os estudantes de p√≥s-gradua√ß√£o e posteriores
ùê∏ que satisfaz ùê∏ùëñùëó =
empres√°rios Sergey Brin e Lawrence Page tiveram em 1996 a seguinte ideia de um
bilh√£o de d√≥lares:

A matriz do Google √© a matriz ùê∫ = ùëëùê¥ + (1 ‚àí ùëë)ùê∏, onde 0 < ùëë < 1 √© um par√¢metro
chamado fator de amortecimento e ùê¥ √© a matriz de Markov obtida da matriz de adja-
c√™ncia escalonando as linhas para se tornar matriz estoc√°stica. Esta √© uma matriz de
Markov ùëõ √ó ùëõ com autovalor 1. Seu autovetor Perron-Frobenius ‚Éóùë£ escalado de forma
que o maior valor seja 10 √© chamado de PageRank do fator de amortecimento ùëë. A
equa√ß√£o do PageRank √© [ùëëùê¥ + (1 ‚àí ùëë)ùê∏]‚Éóùë£ = ‚Éóùë£.

O fator de amortecimento pode parecer um pouco misterioso. Brin e Page escre-
veram: ‚ÄúO PageRank pode ser tamb√©m considerado um modelo de comportamento
do usu√°rio. Assumimos que h√° um ‚ÄôsurÔ¨Åsta aleat√≥rio‚Äô que recebe uma p√°gina da Web
aleatoriamente e continua clicando nos links, nunca atingindo ‚Äôde volta‚Äô, mas eventu-
almente Ô¨Åca entediado e come√ßa em outra p√°gina aleat√≥ria. A probabilidade de que
o surÔ¨Åsta aleat√≥rio visite uma p√°gina √© seu PageRank. O fator de amortecimento √© a
probabilidade em cada p√°gina de o ‚ÄôsurÔ¨Åsta aleat√≥rio‚Äô Ô¨Åcar entediado e solicitar outra
p√°gina aleat√≥ria. Uma varia√ß√£o importante √© adicionar apenas o fator de amorteci-
mento ùëë a uma √∫nica p√°gina ou a um grupo de p√°ginas. Isso permite personaliza√ß√£o
e pode tornar quase imposs√≠vel enganar deliberadamente o sistema para obter uma
classiÔ¨Åca√ß√£o mais alta. Temos v√°rias outras extens√µes para o PageRank.‚Äù

Vamos resolver um caso simples que ilustra essas condi√ß√µes.

Considere uma rede com quatro sites ùëÜ1, ùëÜ2, ùëÜ3 e ùëÜ4 conectados por meio de links conforme

ilustrado no grafo a seguir.

ùëÜ1

ùëÜ2

ùëÜ3

ùëÜ4

Vamos encontrar o pagerank para o fator ùëë = 0, 1.

Resolu√ß√£o: A matriz de adjac√™ncia do grafo acima e sua matriz da web normalizada
s√£o respectivamente,

ùëÄ =

‚éû
‚éõ
0 1 1 1
0 0 1 1
1 0 0 0
1 0 1 0

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

,

ùëí ùê¥ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 1 1
1
3
2
1
0 0 1
3
2
1
2 0 0 0
2 0 1
1
3 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

(cid:47)
(cid:47)
(cid:15)
(cid:15)
(cid:31)
(cid:31)
(cid:111)
(cid:111)
(cid:47)
(cid:47)
(cid:63)
(cid:63)
(cid:79)
(cid:79)
(cid:95)
(cid:95)
60

CAP√çTULO 3. APLICA√á√ïES

Com isso, e tendo ainda a matriz

ùê∏ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1
4
1
4
1
4
1
4

1
4
1
4
1
4
1
4

1
4
1
4
1
4
1
4

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

1
4
1
4
1
4
1
4

,

obtemos a matriz do Google

ùê∫ =

¬∑

1
10

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 1 1
1
3
2
0 0 1
1
3
2
1
2 0 0 0
2 0 1
1
3 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

+

¬∑

9
10

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

1
4
1
4
1
4
1
4

1
4
1
4
1
4
1
4

1
4
1
4
1
4
1
4

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

1
4
1
4
1
4
1
4

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

9
40
9
40
11
40
11
40

=

13
40
9
40
9
40
9
40

31
120
31
120
9
40
31
120

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

11
40
11
40
9
40
9
40

.

O Pagerank do fator de amortecimento ùëë ser√° o autovetor Perron-Frobenius ‚Éóùë£, tal

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùë•
ùë¶
ùëß
ùë§

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

obtemos o sistema

que, ùê∫‚Éóùë£ = ‚Éóùë£ e sua maior entrada ser√° 10. Assim, pondo ‚Éóùë£ =

‚éß

‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©

9
40 ùë• + 13
40 ùë• + 9
9
40 ùë• + 9
11
11
40 ùë• + 9

40 ùë¶ + 31
40 ùë¶ + 31
40 ùë¶ + 9
40 ùë¶ + 31

120ùëß + 11
120ùëß + 11
40ùëß + 9
120ùëß + 9

40 ùë§ = ùë•
40 ùë§ = ùë¶
40 ùë§ = ùëß
40 ùë§ = ùë§

que possui inÔ¨Ånitas solu√ß√µes, sendo que, a sua solu√ß√£o relevante para o fator ùëë √©

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

10
443100
48741
63300
7161
2110
231

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚Éóùë£ =

que √© o seu Pagerank, e nos diz que o site ùëÜ1 √© o mais acessado direta-

mente ou, por meio de links nos sites ùëÜ2, ùëÜ3 e ùëÜ4 que levam o usu√°rio at√© ùëÜ1.

Esse mesmo caso visto sob outra interessante abordagem nos d√° a distribui√ß√£o das
probabilidades de acesso aos sites ùëÜ1, ùëÜ2, ùëÜ3 e ùëÜ4. Para este Ô¨Åm, consideremos a ma-
triz de transi√ß√£o ùëÉ de uma cadeia de Markov, associada √†s probabilidades do usu√°rio
estando no site ùëñ acessar o site ùëó,

ùëÉ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 0 1 1
2
1
3 0 0 0
1
2 0 1
1
3
2
1
1
2 0 0
3

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

CAP√çTULO 3. APLICA√á√ïES

61

Seu autovetor Perron-Frobenius √© a sua distribui√ß√£o de equil√≠brio est√°vel. Nesse
ùëò=1 ùë£ùëò = 1 s√£o as probabilidades

contexto, as entradas ùë£ùëò desse autovetor ‚Éóùë£, tais que,
que buscamos e revelam qual site tem o maior √≠ndice de acessos. Assim, o sistema

‚àëÔ∏Ä4

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0 0 1 1
2
1
3 0 0 0
2 0 1
1
1
3
2
1
1
2 0 0
3

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

=

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

ùë•
ùë¶
ùëß
ùë§

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

ùë•
ùë¶
ùëß
ùë§

¬∑

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éõ

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

‚éû

2
2
3
3
2
1

tem inÔ¨Ånitas solu√ß√µes caracterizadas por ùë° ¬∑

, obviamente para ùë° ‚àà R.

Escolhendo ùë° =

6
31

de modo conveniente a satisfazer a condi√ß√£o dada, obtemos

‚Éóùë£ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

12
31
4
31
9
31
6
31

.

(cid:27) 38, 71%,
Da√≠, temos que as probabilidades de acesso aos respectivos sites s√£o ùëÜ1 = 12
31
(cid:27) 19, 35%, donde conclu√≠mos que quanto
(cid:27) 29, 03% e ùëÜ4 = 6
ùëÜ2 = 4
31
31
mais a rede √© acessada, o site ùëÜ1 tem maior probabilidade de ser visitado com 38, 71%.

(cid:27) 12, 9%, ùëÜ3 = 9
31

3.4 O Modelo de Difus√£o de Ehrenfest

Este modelo foi estudado e apresentado pelos f√≠sicos te√≥ricos Tatyana e Paul Eh-
renfest ainda na primeira d√©cada do s√©culo XX. Trata-se da sua vers√£o considerada
b√°sica e fornece explica√ß√µes relevantes fundamentadas na mec√¢nica estat√≠stica - que
tem como objetivo estudar e explicar o comportamento macrosc√≥pico a partir das leis
microsc√≥picas - para um problema inquietante, o da irreversibilidade. As leis da f√≠sica
baseiam-se em mec√¢nica qu√¢ntica (que √© probabil√≠stica), portanto, um tratamento es-
toc√°stico faz-se necess√°rio nesse contexto. O casal Ehrenfest conseguiu 20 anos antes
do desenvolvimento da mec√¢nica qu√¢ntica moderna, introduzir um modelo probabi-
l√≠stico para descrever a origem da irreversibilidade em sistemas f√≠sicos. Este modelo
vem sendo usado extensivamente para estudar aplica√ß√µes do Teorema H de Boltzmann
(sobre a entropia termodin√¢mica e o caos molecular) e entender como a simetria do
tempo subjacente nas leis do movimento geram a assimetria de tempo dos processos
de difus√£o.

62

CAP√çTULO 3. APLICA√á√ïES

Considere um sistema formado por dois recipientes id√™nticos ùê¥ e ùêµ ligados por uma pe-
quena abertura, e que o recipiente ùê¥ cont√©m um g√°s constitu√≠do por um n√∫mero Ô¨Ånito de
mol√©culas indistingu√≠veis. Tais mol√©culas transitam de ùê¥ para ùêµ regidas pelas leis da me-
c√¢nica e da termodin√¢mica at√© que num dado momento, os recipientes encontram-se em
equil√≠brio macrosc√≥pico (quando suas press√µes internas s√£o iguais). Considere tamb√©m que
n√£o h√° interfer√™ncias externas ao sistema e que, as velocidades e as posi√ß√µes das mol√©culas
no interior dos recipientes s√£o irrelevantes. Qual a probabilidade de mesmo num instante de
tempo arbitrariamente remoto, cada mol√©cula regressar ao recipiente ùê¥? Caso esse regresso
ocorra, √© poss√≠vel determinar o tempo necess√°rio?.

Resolu√ß√£o: Como neste trabalho n√£o h√° a pretens√£o de apresentar e nem discutir os
fundamentos da mec√¢nica estat√≠stica, apresentaremos de forma introdut√≥ria um mo-
delo de evolu√ß√£o estoc√°stica que responde satisfatoriamente ao modelo em quest√£o.

Seja ùëö o n√∫mero total de mol√©culas. Estamos interessados em observar do ponto de
vista probabil√≠stico o tr√¢nsito das mol√©culas, ent√£o, consideraremos que apenas uma
mol√©cula passa de um recipiente para o outro a cada instante de tempo, e que todas
as mol√©culas t√™m a mesma probabilidade de passar de um recipiente para o outro.
Temos um n√∫mero Ô¨Åxo de mol√©culas, por isso, deduzimos o n√∫mero de mol√©culas de
um recipiente a partir do n√∫mero de mol√©culas do outro. O estado desse sistema ser√°
determinado por

ùëãùëõ := n√∫mero de mol√©culas em B no instante n,

onde, como o recipiente ùêµ pode conter 0, 1, 2, etc. at√© no m√°ximo ùëö mol√©culas, ent√£o,
‚àà ùê∏ùëö. Suporemos a
para ùê∏ùëö := {0, 1, 2, . . . , ùëö}, que √© o espa√ßo dos estados, temos ùëãùëõ
condi√ß√£o inicial ùëã0 = 0, isto √©, todas as mol√©culas est√£o no recipiente ùê¥. Precisamos
determinar a evolu√ß√£o do n√∫mero de mol√©culas em ùêµ em fun√ß√£o do tempo ùëõ, ou seja,
ùëã0, ùëã1, ùëã2, . . . , a partir do fato de que apenas uma mol√©cula passa de um recipiente
¬± 1, e assim, quando ùëãùëõ = ùëò temos
para o outro. Nessas condi√ß√µes, temos ùëãùëõ+1 = ùëãùëõ
ùëò mol√©culas em ùêµ e consequentemente, ùëö ‚àí ùëò em ùê¥. Dessa forma, no tempo ùëõ + 1 a
mol√©cula estar√° ou em ùëò ‚àí 1: uma mol√©cula passou de ùêµ para ùê¥; ou em ùëò + 1: uma
mol√©cula passou de ùê¥ para ùêµ.

At√© aqui, temos uma Cadeia de Markov com ùëö + 1 estados ùê∏(0) = 0, ùê∏(1) = 1, ¬∑ ¬∑ ¬∑ ,
ùê∏(ùëö) = ùëö e transi√ß√µes poss√≠veis apenas para os estados, imediatamente, anterior e pos-
terior, pois, em cada instante uma mol√©cula move-se aleatoriamente de seu recipiente
para o outro enquanto o estado do sistema √© determinado pelo n√∫mero de mol√©culas
em ùêµ. Para ùëã1, o primeiro estado imediatamente ap√≥s a condi√ß√£o inicial, segue que
ùëã1 = 1, pois, dado que em ùëõ = 0 o recipiente ùêµ estava vazio, em ùëõ = 1 devemos ter
um mol√©cula em ùêµ, o que probabilisticamente, representamos por ùëù(0 ‚Ü¶‚Üí 1) = 1, isto √©,
estando ùêµ vazio, uma mol√©cula passa de ùê¥ para ùêµ com probabilidade 1. Supondo ent√£o
ùëãùëõ = ùëò, a probabilidade da mol√©cula a ser movida estar em ùêµ ser√°

CAP√çTULO 3. APLICA√á√ïES

63

consequentemente, se for uma mol√©cula que esteja em ùê¥, a probabilidade ser√°

ùëù(ùëò ‚Ü¶‚Üí ùëò ‚àí 1) =

ùëò
ùëö

,

ùëù(ùëò ‚Ü¶‚Üí ùëò + 1) =

ùëö ‚àí ùëò
ùëö

.

Essas probabilidades correspondentes acima, s√£o chamadas de probabilidades de
transi√ß√£o e podem ser escritas como entradas da matriz quadrada ùëÄ com ordem (ùëö+1),
tais que, ùëÄùëñùëó := ùëù(ùëñ ‚Ü¶‚Üí ùëó). A matriz ùëÄ constru√≠da como segue, √© chamada de matriz de
, conforme respectivamente, ùëó = ùëñ ‚àí1 ou ùëó = ùëñ +1,

transi√ß√£o, onde ùëÄùëñùëó =

ùëó
ùëö

ou ùëÄùëñùëó = 1‚àí ùëó
ùëö

ùëÄ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0
1
ùëö
0
...
0

0

1
0
0 1 ‚àí 1
ùëö
2
ùëö
...
0

0
...
0

0

0
1 ‚àí 2
ùëö
...
0

0

0

0

¬∑ ¬∑ ¬∑ 0 0
¬∑ ¬∑ ¬∑ 0 0

¬∑ ¬∑ ¬∑

¬∑ ¬∑ ¬∑ 0 0
...
...
1
¬∑ ¬∑ ¬∑ 0
ùëö
¬∑ ¬∑ ¬∑ 1 0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

Temos claramente para todo ùëñ, ùëó, que ùëÄùëñùëó

‚â• 0, e que

‚àëÔ∏Ä

ùëò=ùëñ¬±1 ùëÄùëñùëò = 1 para todo ùëñ. Essas

propriedades fazem com que ùëÄùëá seja uma matriz de Markov.

Note que temos o vetor-coluna ‚Éóùë¢(0) =

com ùëö + 1 entradas, representando a

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

1
0
...
0
0

condi√ß√£o inicial ùëã0 = 0, e signiÔ¨Åcando que no tempo ùëõ = 0 suas entradas s√£o,

(0)
ùë¢
ùëò

:= ùëù(ùëã0 = ùëò) =

‚éß
‚é™‚é™‚é™‚é®
1, se k=1,
‚é™‚é™‚é™‚é©
0, caso contr√°rio.

Dado que, a probabilidade contida em ‚Éóùë¢(0) concentrada em 0 no tempo ùëõ = 0,

espalha-se pelo sistema, segue para ùëõ = 1, que

‚Éóùë¢(1) =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

0
1
...
0
0

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

= ùëÄùëá ‚Éóùë¢(0),

64

e

CAP√çTULO 3. APLICA√á√ïES

‚Éóùë¢(2) =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

1
ùëö
0
ùëö‚àí1
ùëö
0
...
0

= ùëÄùëá ‚Éóùë¢(1),

e de modo generalizado, notamos que

‚Éóùë¢(ùëõ) =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

(ùëõ)
ùë¢
0

...

(ùëõ)
ùëö

ùë¢

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

= ùëÄùëá ‚Éóùë¢(ùëõ‚àí1)

(ùëõ)

‚àëÔ∏Ä

(ùëõ)
s√£o n√£o-
√© o vetor de distribui√ß√£o de probabilidade no tempo ùëõ, onde as entradas ùë¢
ùëò
ùëò = 1 para ùëò percorrendo o conjunto {0, 1, 2, . . . , ùëö} com a interpreta√ß√£o
negativas e
ùë¢
(ùëõ)
de que ùë¢
ùëò = ùëÉ (a mol√©cula estar em k no instante n). De fato, estando a mol√©cula em ùëò
no instante ùëõ, isto signiÔ¨Åca que no instante ùëõ ‚àí 1 devia estar em ùëò ‚àí 1 ou mesmo, em
ùëò + 1. Disso, tiramos que

(ùëõ)

ùë¢

ùëò = ùëÉ (ùëò ‚àí 1 ‚Ü¶‚Üí ùëò).ùë¢

(ùëõ‚àí1)
ùëò‚àí1 + ùëÉ (ùëò + 1 ‚Ü¶‚Üí ùëò).ùë¢

(ùëõ‚àí1)
ùëò+1 ,

o que equivalentemente representamos de forma vetorial como ‚Éóùë¢(ùëõ) = ùëÄùëá ‚Éóùë¢(ùëõ‚àí1).

Para a condi√ß√£o inicial dada, a evolu√ß√£o do sistema converge para um estado de
equil√≠brio em termos de n√∫mero de mol√©culas em cada recipiente. Estamos interessa-
dos em provar esse comportamento a partir da matriz ùëÄùëá , mais precisamente, veriÔ¨Å-
cando o que acontece com (ùëÄùëá )ùëõ quando ùëõ ‚Üí ‚àû. Tal veriÔ¨Åca√ß√£o ser√° mais interessante
se a matriz ùëÄùëá satisÔ¨Åzer as condi√ß√µes do Teorema de Perron-Frobenius, entretanto,

isso n√£o ocorre. Consideremos, ent√£o, uma matriz ùëÄùúÄ, para 0 < ùúÄ <
sendo uma pe-
quena varia√ß√£o associada √† fra√ß√£o de tempo em que a mol√©cula permanece num estado,
conforme deÔ¨Ånimos a seguir:

1
ùëö

ùëÄùúÄ =

‚éõ

‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù

2ùúÄ

1 ‚àí 2ùúÄ

0
...
...

0

1
ùëö

‚àí ùúÄ

2ùúÄ
1 ‚àí 1
ùëö
0

‚àí ùúÄ

0

0

0

2
ùëö

‚àí ùúÄ

‚àí ùúÄ

2ùúÄ
1 ‚àí 2
ùëö
0

¬∑ ¬∑ ¬∑

¬∑ ¬∑ ¬∑

¬∑ ¬∑ ¬∑

3
ùëö

‚àí ùúÄ

2ùúÄ
1 ‚àí 3
ùëö
0

‚àí ùúÄ

‚éû

‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†

.

0

0
...

0

1 ‚àí 2ùúÄ

2ùúÄ

0

0

0

¬∑ ¬∑ ¬∑

. . .

1
ùëö

‚àí ùúÄ

CAP√çTULO 3. APLICA√á√ïES

65

Com isso, dadas as matrizes quadradas ùëÄùëá e ùëÄùúÄ de ordem ùëö + 1, deÔ¨Ånimos a dis-

t√¢ncia entre ùëÄùëá e ùëÄùúÄ por

ùëë(ùëÄùëá , ùëÄùúÄ) := max

1‚â§ùëñ,ùëó‚â§ùëö+1

| (ùëÄùëá )ùëñùëó

‚àí (ùëÄùúÄ)ùëñùëó

|,

| ‚â§ 2ùúÄ para todo ùëñ, ùëó. Nessas condi√ß√µes, a dist√¢n-
donde veriÔ¨Åcamos que | (ùëÄùëá )ùëñùëó
cia ùëë(ùëÄùëá , ùëÄùúÄ) entre as matrizes ùëÄùëá e ùëÄùúÄ torna-se t√£o pequena quanto se queira, isto
√©,

‚àí (ùëÄùúÄ)ùëñùëó

ùëÄùúÄ = ùëÄùëá .

lim
ùúÄ‚Üí0

Al√©m disso, temos associado √† matriz ùëÄùúÄ um grafo Œì (ùëÄùúÄ) tal que, todas as entradas
de ùëÄùúÄ cujos √≠ndices s√£o n√∫meros consecutivos, s√£o positivas. Consequentemente, para
quaisquer dois v√©rtices distintos ùëñ, ùëó de Œì (ùëÄùúÄ) deve existir uma aresta orientada de ùëñ
para ùëó, e assim, o grafo Œì (ùëÄùúÄ) √© fortemente conexo e a matriz ùëÄùúÄ √© irredut√≠vel, de
sobremaneira que (ùëÄùëö
ùúÄ )ùëñùëó > 0 e a matriz satisfaz as condi√ß√µes do Teorema de Perron-
Frobenius.

Conclu√≠mos da√≠ que, como ‚Éóùë¢(ùëõ) = ùëÄùëá ‚Éóùë¢(ùëõ‚àí1), isto √©, a distribui√ß√£o para um tempo ùëõ
√© calculada recursivamente a partir de ùëõ ‚àí 1; existe no equil√≠brio, uma distribui√ß√£o ‚Éóùë£
com entradas

ùë£ùëò := lim

ùëõ‚Üí‚àû ùë¢

(ùëõ)
ùëò = lim

ùëõ‚Üí‚àû ùëÉ (ùëãùëõ = ùëò)

qualquer que seja a distribui√ß√£o inicial ‚Éóùë¢.

Dessa forma, obtemos ‚Éóùë£ fazendo

(ùëÄùëá ùë£)ùëò = ( lim

ùëõ‚Üí‚àû ùëÄùëá ùë¢(ùëõ))ùëò = ( lim

ùëõ‚Üí‚àû ùë¢(ùëõ+1))ùëò = (ùë£)ùëò = ùë£ùëò

e assim, ùëÄùëá ‚Éóùë£ = ‚Éóùë£, o que mostra que ‚Éóùë£ √© uma distribui√ß√£o invariante em rela√ß√£o ùëÄùëá .
Com outras palavras, ‚Éóùë£ √© o √∫nico autovetor associado ao autovalor de Perron-Frobenius
ùëÉ ùêπ(ùëÄùëá ) = 1. Portanto, h√° uma probabilidade de regresso das mol√©culas para o recipi-
ente ùê¥, ainda que para um tempo humanamente imposs√≠vel de ser vivido.

Refer√™ncias

[BH12]

M. Bestvina, and M. Handel, Train tracks and automorphisms of free
groups, Annals of Mathematics (2), vol. 135 (1992), no. 1, pp. 1‚Äì51.

[Bog08]

Bogopolski, O. Introduction to Group Theory, EMS: European Mathema-
tical Society, English edition; Dortmund, Germany 2008.

[Bol78]

Boldrini, J. L.; Costa, S. I. R.; Ribeiro, V. L. F. F.; Wetzler, H. G. √Ålgebra
Linear - Harper & Row do Brasil, S√£o Pulo, 1¬™ed. 1978.

[Dia09]

Diaconis, P. The Markov chain Monte Carlo revolution, Bulletin of the
AMS, Vol. 46, 2009, p. 179‚Äì205.

[Doo53] Doob, J.L., Stochastic Processes. New York, John Wiley, 1953.

[EGNO15] Etingof, P.; Gelaki, Sh.; Nikshych, D.; Ostrik, V. Tensor categories, Mathe-
matical Surveys and Monographs, Vol. 205, American Mathematical Soci-
ety, 2015.

[Eur02]

Revista Eureka! n¬∫13, p. 41-44, Sociedade Brasileira de Matem√°tica, 2002.

[Fel67]

Feller, W. An Introduction to Probability Theory and Its Applications.
JOHN WILEY & SONS, New York, 3nd Ed.,1967.

[GM18]

Google Matrix: fundamentals, applications and beyond; Workshop, 15-
18 October 2018, https://indico.math.cnrs.fr/event/3475/overview.

[Jam15]

James, B. R. Probabilidade: Um Curso em N√≠vel Intermedi√°rio, Projeto
Euclides, IMPA, Rio de Janeiro, 2015.

[Lim04]

Lima, E. L. √Ålgebra Linear, Cole√ß√£o Matem√°tica Universit√°ria, IMPA, 7¬™
ed., Rio de Janeiro, 2004.

[Mag15] Magalh√£es, M. N. Probabilidade e Vari√°veis Aleat√≥rias. EDUSP: Editora
da Universidade de S√£o Paulo, S√£o Paulo, 3¬™ Edi√ß√£o, 2¬™ reimpress√£o, 2015.

[MCCF06] Morgado, A. C.; de Carvalho, J. B. P.; Carvalho, P. C. P.; e Fernandez, P.
An√°lise Combinat√≥ria e Probabilidade, SBM; Cole√ß√£o do Professor de Ma-
tem√°tica, 9¬™ ed., Rio de Janeiro, 2006.

[PY98]

Pollicott, M.; Yuri, M. Dynamical Systems and Ergodic Theory, London
Mathematical Society Student Texts 40, Cambridge University Press.

68

[Ser02]

[Za93]

REFER√äNCIAS

Serre, D. Matrices : Theory and Applications, Springer-Verlag New York,
2002.

Zalesskii, A.E. Linear Groups, Em Algebra IV, Encyclopaedia of Mathema-
tical Sciences, Vol. 37, Springer-Verlag, 1993.


Universidade  do  Estado  do  Rio  de  Janeiro 

Centro de Educação e Humanidades 

Faculdade de Formação de Professores 

Igor  Luiz  Doria  Pinheiro 

O que os indicadores dizem sobre a evolução do cenário 

educacional  no  Brasil: perspectivas  a  partir  da  avaliação  PISA 

na  área  de  Matemática 

São Gonçalo 

2021 

  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Igor Luiz Doria Pinheiro 

O que os indicadores dizem sobre a evolução do cenário educacional no 
Brasil:  perspectivas a partir da avaliação PISA na área de Matemática 

Dissertação apresentada, como requisito par- 
cial  para  obtenção  do    título    de   Mestre, 
ao  Programa  de  Pós-Graduação  do  Mes- 
trado  Profissional  em  Matemática  em  Rede 
Nacional-PROFMAT,  da  Universidade  do 
Estado  do  Rio  de  Janeiro.  Área  de  concen- 
tração:  Ensino de Matemática. 

Orientadora:  Profa.Dra Marcele Câmara de Souza  
Coorientadora:  Profa.Dra Fernanda Pereira Rodrigues 

São Gonçalo 

2021 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
CATALOGAÇÃO NA FONTE 
UERJ / REDE SIRIUS / BIBLIOTECA CTC/D 

D979 

Luiz Doria Pinheiro, Igor 

O que os indicadores dizem sobre a evolução do cenário educacional no 
Brasil:  perspectivas  a  partir  da  avaliação  PISA  na  área  de  Matemática  / 
Igor Luiz Doria Pinheiro.  – São Gonçalo, 2021- 

71 f. 

Orientador: Profa.Dra Marcele Câmara de Souza 
Dissertação  (Mestrado)  –  Universidade  do  Estado  do  Rio  de  Janeiro, 
Faculdade  de  Formação  de  Professores,  Programa  de  Pós-Graduação  do 
Mestrado  Profissional  em  Matemática  em  Rede  Nacional-PROFMAT,  2021. 

1.  Estatísticas..  2.  Matemática..  3.  Educação..  I.  Profa.Dra  Marcele 
Câmara  de  Souza.  II.  Universidade  do  Estado  do  Rio  de  Janeiro.  III. 
Faculdade de Formação de Professores.  IV. Título 

CDU  02:141:005.7 

Autorizo,  apenas para fins acadêmicos e científicos,  a reprodução total ou parcial desta 
dissertação, desde que citada a fonte. 

Assinatura 

Data 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Igor Luiz Doria Pinheiro 

O que os indicadores dizem sobre a evolução do cenário educacional no 
Brasil:  perspectivas a partir da avaliação PISA na área de Matemática 

Dissertação apresentada, como requisito par- 
cial  para  obtenção  do    título    de   Mestre, 
ao  Programa  de  Pós-Graduação  do  Mes- 
trado  Profissional  em  Matemática  em  Rede 
Nacional-PROFMAT,  da  Universidade  do 
Estado  do  Rio  de  Janeiro.  Área  de  concen- 
tração:  Ensino de Matemática. 

Aprovada em dd de mês de 2021. 

Banca Examinadora: 

Profa.Dra Marcele Câmara de Souza (Orientadora) 
Faculdade de Formação de Professores - UERJ 

Profa.Dra Fernanda Pereira Rodrigues (Coorientadora) 
Faculdade de Formação de Professores - UERJ 

Profa.Dra Priscila Cardoso Petito 
 Faculdade de Formação de Professores - UERJ 

                                   Colégio Pedro II 

Profa.Dra Andreia Carvalho Maciel Barbosa 

São Gonçalo 

2021 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
DEDICATÓRIA 

Em memória da minha avó, que tanto se empenhou para que eu me dedicasse aos 

meus estudos. 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
AGRADECIMENTOS 

Agradeço  primeiramente  a  Deus  por  ter  chegado  até  aqui  e  por  todas  as 

oportunidades e graças concedidas. 

À  minha  mãe,  pelo  apoio  nos  momentos  de  incerteza  e  por  me  dar  forças  para 

prosseguir nessa caminhada 

À  equipe  pedagógica  da  escola  onde  trabalho,  pela  compreensão  e  flexibilização 

dos horários  para  que  estes  pudessem se  adequar  a  realização deste  curso. 

Aos meus colegas do Mestrado Profissional em Matemática, pela companhia e pelo 

compartilhamento  de  experiências,  materiais  e  conhecimentos.  Em  particular  ao  Sr. 
Veriano,       pelo apoio em todo decorrer desta jornada. 

Aos professores e as instituições de ensino que contribuíram em algum momento 

com a minha formação. 

Às minhas orientadoras, Professora Doutora Marcele Câmara de Souza e Professora 

Doutora  Fernanda  Pereira  Rodrigues,  por  terem  acreditado  na  minha  ideia  e  aceitado 
orientar uma dissertação com uma proposta voltada para um tema tão importante para os 

profissionais que, assim como eu, atuam na educação básica. Agradeço pelas orientações, 
pela paciência e pela disponibilidade. 

          Por  fim,  agradeço  a  todos  que  de  alguma  forma  contribuíram  nesse  processo.

 
 
 
RESUMO 

LUIZ DORIA PINHEIRO, I.L.D.P O que os indicadores dizem sobre a evolução do 
cenário educacional no Brasil: perspectivas a partir da avaliação PISA na área de 
Matemática. 2021. 71 f. Dissertação (Mestrado em Mestrado Profissional em 
Matemática em Rede Nacional-PROFMAT) – Faculdade de Formação de Professores, 
Universidade do Estado do Rio de Janeiro, São Gonçalo, 2021. 

Este trabalho discute a evolução da educação no Brasil sob a perspectiva da avalia- 
ção  PISA.  Para  o  desenvolimento  desta  discussão,  foi  realizado  um  estudo  do  histórico 
brasileiro  na  área  de  Matemática  nesta  avaliação,  procurando  examinar  aspectos  que 
permeiam esses resultados. Por ser frequentemente adotada como principal comparativo 
internacional e ter seus resultados adotados como referência para indicar a qualidade da 
educação  do  país,  é  de  fundamental  importância  para  o  debate  educacional  uma  visão 
mais  ampla  das  informações  que  cercam  os  resultados  dessa  avaliação  em  larga  escala. 
Para tanto, foi realizada uma revisão bibliográfica dos relatórios nacionais e da literatura 
acerca  do  histórico  dessa  avaliação  e  dos  contextos  que  pretendemos  analisar.  A  partir 
disso,  foi  elaborado  um  estudo  dos  recortes  amostrais,  examinando  a  evolução  desses 
resultados  dentro  de  um  quadro  contextual  que  considera  os  seguintes  aspectos  da 
educação  em  nosso  país:  nível  de  escolarização,  evolução  dos  investimentos  em 
educação,  desigualdades  regionais,  condições  escolares  e  diferenças  entre  as  diversas 
redes  ensino.  Com  isso,  as  argumentações  deste  trabalho  têm  como  objetivos  promover 
reflexões  além  da  visão  reducionista  apresentada  pelos  rankings,  e  explicitar  o  quanto 
uma  avaliação  simplista  desses  resultados  pode  não  refletir  o  real  cenário  do  ensino  de 
Matemática  no  nosso  país.  Procura-se  aprofundar  as  discussões  sobre  a  qualidade  da 
educação,  ressaltando  a  importância  da  interpretação  e  do entendimento  dos  contextos 
pelos quais foram construídos estes resultados. Esperamos que este estudo possa ajudar a 
aproximar o diálogo entre pesquisadores, educadores e sociedade. 

Palavras-chave:  Estatísticas. Matemática. Educação. PISA. 

 
  
 
 
 
 
ABSTRACT 

LUIZ DORIA PINHEIRO, I.L.D.P Título do trabalho em inglês. 2021. 71 f. Dissertação 
(Mestrado em Mestrado Profissional em Matemática em Rede Nacional-PROFMAT) – 
Faculdade de Formação de Professores, Universidade do Estado do Rio de Janeiro, São 
Gonçalo, 2021. 

This  paper  discusses  the  evolution  of  education  in  Brazil  from  the  perspective  of  the 
PISA assessment. For the development of this discussion, a study of the Brazilian history 
in the area of Mathematics was carried out in this evaluation, seeking to examine aspects 
that  permeate  these  results.  As  it  is  frequently  adopted  as  the  main  international 
comparative and its results are adopted as a reference to indicate the quality of education 
in  the  country,  a  broader  view  of  the  information  surrounding  the  results  of  this  large-
scale evaluation is of fundamental importance for the educational debate. To this end, a 
bibliographic  review  of  national  reports  and  literature  on  the  history  of  this  evaluation 
and  the  contexts  we  intend  to  analyze  was  carried  out.  Based  on  this,  a  study  of  the 
sample cuts was carried out, examining the evolution of these results within a contextual 
framework  that  considers  the  following  aspects  of  education  in  our  country:  level  of 
schooling, evolution of investments in education, regional inequalities, school conditions 
and differences between the different education networks. With this, the arguments of this 
work aim to promote reflections beyond the reductionist view presented by the rankings, 
and  to  explain  how  a  simplistic  evaluation  of  these  results  may  not  reflect  the  real 
scenario of Mathematics teaching in our country. It seeks to deepen the discussions on the 
quality  of  education,  emphasizing  the  importance  of  interpreting  and  understanding  the 
contexts in which these results were constructed. We hope that this study can help bring 
the dialogue between researchers, educators and society closer together. 

Keywords:  Stats. Math. Education. PISA. 

 
 
 
 
 
LISTA DE FIGURAS 

Figura 1 

- Comparação com países de alto desempenho ............................................... 22 

Figura 2 

- Comparativo  do  desempenho  médio  na  escala  global  de  Matemática 

por ano de escolaridade ................................................................................. 26 

Figura  3 
-  Estudantes  elegíveis  do  Brasil  no  PISA ........................................................... 27 
Figura  4  -  Médias  do  Brasil  no  PISA ................................................................................... 30 
Figura 5  - Um retrato da evolução dos estados brasileiros ............................................. 35 

Figura 6  - Variação das médias em Matemática na avaliação PISA por região ............. 38 
Figura 7  - Perspectivas Regionais .................................................................................... 40 
Figura 8  - Médias de alunos por turma ............................................................................ 45 
46 
Figura 9  - Quantidade de funcionários por aluno, por dependência administrativa 

Figura  10  -  Selecionando  a  correlação  de  Pearson  no  Excel .............................................. 67 
Figura  11  -  Selecionando  os  dados  da  tabela ...................................................................... 68 
Figura  12  -  Encontrando  o  coeficiente  de  correlação .......................................................... 68 

Tabela 21  -  Valores  críticos  para  o  coeficiente  r  de  Pearson .............................................. 69 
Figura 13  - Gasto Municipal por Matricula x Resultado do Ideb Municipal ................. 70 

Figura 14  - Gasto Municipal por Matricula x Resultado do Ideb Municipal ................. 70 

 
  
 
 
 
LISTA DE TABELAS 

            Tabela  1 

-  Evolução  dos  países  no  PISA............................................................................ 21 

            Tabela  2 

-  A  evolução  de  Peru  e  Portugal ......................................................................... 24 

Tabela 3 
Tabela 4 

- Média nacional no PISA por ano de escolaridade........................................ 25 
-  Composição  da  amostra  de  acordo  com  o  nível  de  ensino ............................. 27 

- Média dos estudantes de acordo com o segmento ........................................ 28 
Tabela 5 
Tabela 6 
- Composição da amostra do Ensino Fundamental ........................................ 28 
Tabela 7    - Percentuais de estudantes brasileiros por nível de proficiência ................... 29 

            Tabela 8 - Estimativa  do  percentual  do  investimento  público  total  em  Educação 

em relação  ao  PIB por  nível de ensino -  2000-2015 ....................................... 31 

Tabela 9 - Estimativa do investimento público direto em Educação por estudante, com 

valores atualizados para 2015 pelo Índice Nacional de Preços ao 

Consumidor Amplo (IPCA) por nível de ensino - 2000-2015 ...................... 32 

Tabela 10 - Investimentos em educação por estudante do Ensino Básico por ciclo 

da avaliação PISA (R$) ................................................................................. 32 

Tabela 11 - Investimentos  em  educação  por  estudante  do  Ensino  Médio  por  ciclo 

da avaliação PISA (R$) ................................................................................. 33 

Tabela 12 - Investimentos em educação por estudante do Ensino Fundamental por 

ciclo da avaliação PISA (R$) ........................................................................ 33 

Tabela 13  - Variação das médias em Matemática na avaliação PISA por região .......... 36 
            Tabela 14  - Variação das médias em Matemática na avaliação PISA por região........... 38 

            Tabela  15  -  A  influência  das  condições  escolares ................................................................ 43 

Tabela 16  - Médias por dependência administrativa ....................................................... 44 
            Tabela 17  - O Brasil na IMO ............................................................................................ 53 

Tabela 18 - Desempenho escolar e investimento por aluno/ano na educação básica 

(2003) ............................................................................................................. 55 

           Tabela 19 - Percentual de Adultos, entre 25 e 64 anos, de alguns países, que concluiu 

pelo menos a etapa final da educação básica ............................................... 56 
            Tabela 20  - Tabela 15 representada no Excel ............................................................. 66 

            Tabela 21  -  Valores  críticos  para  o  coeficiente  r  de  Pearson .............................................. 69 
           Tabela 22   - Evolução do resultado na avaliação de Matemática do PISA por UF ................ 71 
Tabela 23   - Evolução do resultado na avaliação de Matemática do PISA por UF ................ 72

 
 
LISTA DE ABREVIATURAS E SIGLAS 

AM 

DAEB 
DF 
ENEM 

IDH 

INEP 
IMO 

LLECE 
MA 

MEC 
OCDE 
PIB 

PISA 
RJ 

SAEB 
SE 

UF 

Amazonas 

Diretoria de Avaliação da Educação Básica 
Distrito Federal 
Exame Nacional do Ensino Médio 

Índice de Desenvolvimento Humano 

Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira 
Olimpíada Internacional de Matemática 

Laboratório Latino-Americano de Avaliação da Qualidade da Educação 
Maranhão 

Ministério da Educação e Cultura 
Organização para a Cooperação e Desenvolvimento Econômico 
Produto Interno Bruto 

Programa Internacional de Avaliação de Estudantes 
Rio de Janeiro 

Sistema de Avaliação da Educação Básica 
Sergipe 

Unidade da Federação 

 
  
 
 
SUMÁRIO 

4.1 
4.2 
4.3 
5 
5.1 

5.2 

6 

INTRODUÇÃO .................................................................................................... 12 
1             A AVALIAÇÃO PISA ........................................................................ ...........14 
1.1 
Uma visão geral sobre o PISA   .................................................................... 14 
1.2 
Histórico do PISA.............................................................................................. 16 
2 
Escala de proficiência de Matemática do PISA ........................................... 18 
3 
A EVOLUÇÃO DOS RESULTADOS DO BRASIL NO PISA.......... 21 
4 

ASPECTOS DOS RESULTADOS DO PISA SOB A PERSPECTIVA 
NACIONAL ..................................................................................................... 25 
A influência da escolarização ................................................................................ 25 
A evolução dos investimentos em educação .................................................. 31 
Os resultados do país sob uma perspectiva regional ................................ 34 
A INFLUÊNCIA DAS CONDIÇÕES ESCOLARES ........................... 40 

Os impactos da disponibilidade de profissionais para  o  atendi- 
mento da população estudantil ........................................................................... 40 

Um olhar para os resultados de acordo com a dependência ad- 
ministrativa.............................................................................................................. 44 

BREVES CONSIDERAÇÕES SOBRE A RELEVÂNCIA DA AVA- 
LIAÇÃO PISA ................................................................................................ 47 
CONCLUSÃO ....................................................................................................... 54 
REFERÊNCIAS ................................................................................................... 59 
APÊNDICE  A – Noções estatísticas utilizadas neste trabalho ..................... 62 
APÊNDICE B – A correlação de Pearson no software Excel ....................... 66 

ANEXO A – Valores críticos do coeficiente de correlação de Pearson .......... 69 
ANEXO B – Evolução comparativa dos investimentos municipais com os 
resultados do Ideb ............................................................................................... 70 

ANEXO  C – Resultados em Matemática no PISA por UF ........................... 71 

 
INTRODUÇÃO 

12 

No  presente  trabalho  realizaremos  uma  análise  comparativa  dos  resultados  em 

Matemática  expressos  pelo  Programa  Internacional  de  Avaliação  de  Estudantes  (PISA), 

procurando  correlacionar  os  indicativos  dos  resultados  desse  exame  às  característicass 
apresentadas pelo nosso país que podem influenciar no panorama educacional. Buscamos 

entender  os  resultados  do  nosso  país,  em  vista  da  sua  evolução  histórica,  procurando 
contextualizar  esses  resultados  à  luz  da  evolução  dos  investimentos  nacionais  e  das 

especificidades do nosso sistema educacional, como o histórico do nível de escolarização 
dos estudantes brasileiros, as desigualdades regionais e as diferenças existentes entre as 

nossas  redes  de  ensino.  Consideramos  que  a  interpretação  de  tais  resultados  pode 
auxiliar  na  elaboração  de  um  panorama  do  ensino de  Matemática  em  nosso  país, 

buscando compreender quais direcionamentos estão sendo tomados  no  que  concerne  ao 
processo educacional. 

A  base  de  interesse  desta  pesquisa  originou-se  ao  longo  de  minha  trajetória  aca- 
dêmica  e  profissional.    Como  estudante  do  ensino  básico,  constitui-me  como  integrante 
do  público  alvo  do  nosso  sistema  educacional  nas  esferas  particular,  estadual  e  federal. 

Em  minha  atuação  como  docente,  leciono  desde  o  ano  de  2015  na  rede  estadual  como 
professor do ensino médio e dos anos finais do ensino fundamental.  

A  motivação  para  a  realização  dessa  pesquisa  se  deve,  ao  fato  de  que  a  minha 
percepção,  proporcionada  a  partir  dessa  experiência  pessoal,  conjuntamente  as  minhas 

leituras  iniciais  de  documentos  oficiais,  como  os  relatórios  nacionais  e  informações 
divulgadas  pela  entidade  responsável  pela  organização  e  aplicação  da  avaliação  PISA, 

não  me  conduzirem  a  uma  interpretação  convergente  a  narrativa  frequentemente 
apresentada pela mídia ao grande público sobre o cenário da educação e que constitui o 

senso  comum  de  piora  contínua  dos resultados  educacionais.  Em  busca  de  uma  melhor 
compreensão de seu significado, resolvi investigar o que nos dizem esses indicadores. 

Este estudo se concentrará em buscar compreender o que os resultados nas avalia- 
ções  de  Matemática  podem  nos  indicar.  Para  tanto  procuraremos  situá-los  sob  aspectos 

como a perspectiva internacional, para que possamos nos referenciar estabelecendo nossa 
evolução  dentro  de  um  quadro  comparativo,  e  sob  a  perspectiva  nacional,  procurando 

compreender o histórico dos resultados brasileiros, avaliando a sua evolução e analisando 
fatores que os permeiam. Com isso, buscamos interpretar de que forma esses resultados 
podem  expressar  o  desenvolvimento  da  nossa  educação,  procurando  um  olhar  além  da 
questão  classificatória  estabelecida  pelo  ranking,  produto  pelo  qual  a  avaliação  é  mais 

popularmente  conhecida.  Acreditamos  que  o  entendimento  do  contexto  a  partir  do  qual 
esses  resultados  foram  construídos  pode  ser  de  bom  proveito  para  conhecer  um  pouco 

mais da trajetória da educação em nosso país e aprofundar os debates sobre a qualidade 
da educação básica.  

 
 
 
 
 
13 
Desta forma, ao reunir e organizar esses dados, esperamos de alguma forma poder 
contribuir  com  o  trabalho  de  pesquisadores,  gestores  e  demais  pessoas  interessadas  em 

tomar parte na discussão sobre os rumos do sistema educacional e em contribuir  para a 
melhoria do ensino em nosso país. 

No primeiro capítulo, realizamos na primeira seção uma breve introdução sobre a 
avaliação PISA, apresentando seus objetivos e caraterísticas principais.  Na segunda seção, 

apresentamos uma retrospectiva histórica dessa avaliação sob a perspectiva dos relatórios 
nacionais. Na última seção, apresentamos a escala de proficiência adotada para a área de 

Matemática. 

No segundo capítulo, procuramos situar a evolução dos resultados brasileiros no ce- 

nário internacional, contextualizando os avanços nacionais quando comparados a evolução 
dos resultados de outros países. 

No terceiro capítulo, começamos a examinar a contribuição de alguns fatores que 
parecem dialogar com os resultados. Observamos em particular, na primeira seção, a evo- 

lução da escolarização dos estudantes que compuseram as amostras nacionais e na segunda 
seção a evolução dos investimentos em educação. Na terceira seção, observamos um re- 

corte regional, procurando identificar como esses resultados estão distribuídos pelo nosso 
território.  Dessa  forma  esperamos  compreender  um  pouco  melhor  a  representatividade 

desses resultados. 

No  quarto  capítulo,  avaliamos  a  influência  das  condições  escolares,  adotando  na 

primeira seção um enfoque na quantidade de profissionais disponíveis para o atendimento 
dos estudantes. Para uma melhor compreensão do impacto desses fatores, realizamos na 

segunda seção um breve comparativo dos resultados por dependência administrativa. 

No  quinto  capítulo,  pontuamos  algumas  observações  que  consideramos  perti- 

nentes  sobre  o  peso  atribuído  aos  resultados  dessa  avaliação.  Tais  ponderações  podem 
acentuar  a  importância  de  relativizar  as  análises  sobre  os  resultados  do  PISA,  para  que 

estes sejam interpretados de forma que possibilite o entendimento  dos seus significados 
conforme o contexto analisado. 

 
  
14 

1  A AVALIAÇÃO PISA 

1.1  Uma  visão  geral  sobre  o PISA 

A avaliação PISA é organizada pela Organização para a Cooperação e Desenvol- 
vimento  Econômico  (OCDE),  tendo  como  objetivo  principal  a  produção  de  indicadores 
que possam contribuir para a discussão sobre a qualidade da educação básica e que pos- 
sam subsidiar políticas nacionais de melhoria  da educação, conforme descrito em INEP 
(2007)1.  Desta  forma,  a  partir  da  interpretação  dos  resultados  observados,  podem  ser 
estabelecidas políticas públicas e norteadas diretrizes curriculares visando a melhoria da 
qualidade  educacional  em  nosso  país.  Atualmente  mais  de  70  países  participam  desta 
avaliação, o que faz com que ela seja considerada o principal referencial internacional para 
correlacionar  os  desempenhos  educacionais  entre  as  nações,  assim  como  acompanhar o 
desenvolvimento do nível educacional de um país. 

No  Brasil,  o  PISA  integra  um  conjunto  de  avaliações  e  exames  nacionais  e  in- 

ternacionais  coordenados  pela  Diretoria  de  Avaliação  da  Educação  Básica  (DAEB),  do 

Instituto  Nacional  de  Estudos  e  Pesquisas  Educacionais  Anísio  Teixeira  (INEP),  que é 
responsável  também  pelo  Exame  Nacional  do  Ensino  Médio  (ENEM)  e  pelo  Sistema 

de Avaliação da Educação Básica (SAEB). Na atualidade, os estudantes brasileiros, além 
de  participarem  das  avaliações  nacionais,  também  são  parte  integrante  dos  estudos  re- 

gionais  coordenados  pelo  Laboratório  Latino-Americano  de  Avaliação  da  Qualidade  da 
Educação (LLECE) e do PISA, coordenado pela OCDE. 

A avaliação PISA é aplicada a cada três anos. A cada edição, uma das três áreas 
que a avaliação abrange (leitura, Matemática e ciências) é considerada o foco ou domínio 

principal da avaliação, sendo a maior parte dos itens da avaliação referentes a essa área 
(aproximadamente metade do total  de tempo  do teste) e os questionários propostos vol- 

tados para a coleta de informações relacionadas à aprendizagem desse domínio. Os itens 
restantes  são  voltados  para  as  outras  duas  áreas  e,  embora  em  menor  quantidade,  ainda 

podem fornecer elementos suficientes para comparações entre os anos. 

Com  essa  alternância  de  avaliação  das  áreas  do  conhecimento,  apresentam-se,  a 
cada  nove  anos,  uma  análise  aprofundada  do  desempenho  dos  estudantes  no  domínio 

principal e, a cada edição, uma análise das tendências nos domínios secundários. 

Por considerar que os níveis escolares em geral não são bons indicadores de onde 

os alunos estão em seu desenvolvimento cognitivo, os organizadores da avaliação PISA 
acreditam que o desempenho dos alunos pode ser melhor comparado internacionalmente 

1 http://portal.inep.gov.br/artigo/-/asset_publisher/B4AQV9zFY7Bv/content/o-que-e-o-pisa/21206 

 
 
 
 
 
 
 
 
 
                                                      
 
15 

ao  escolher  alunos  de  uma  idade  específica.  Dessa  forma,  o  PISA  pode  acompanhar  ao 
longo do tempo o conhecimento e as habilidades de indivíduos nascidos no mesmo ano 

que ainda estão na escola aos 15 anos, apesar da diversidade de suas histórias de educação 
dentro  e  fora  da  escola.  A  adoção  de  tal  critério  é  justificada  pelas  diferenças  entre  os 

países quanto aos seguintes fatores: natureza e extensão da educação e dos cuidados pré-
primários,  idade  de  ingresso  na  educação  formal,  estrutura  do  sistema  educacional  e 

prevalência da repetência.  

A idade de 15 anos é escolhida sob a justificativa de que é nessa faixa etária que 

na maioria dos países participantes os jovens estão se aproximando do final da educação 
formal  compulsória  e  que  isso  permite  avaliar  até  que  ponto  os  estudantes  desta  idade 

adquiriram conhecimentos e habilidades essenciais para plena participação na vida social 
e econômica. 

Dessa  forma,  foi  estabelecido  que  os  participantes  devem  ter  entre  15  anos  e  3 
meses e 16 anos e 2 meses no momento  da aplicação do teste, e devem ter completado 

pelo menos 6 anos de escolaridade formal (o que corresponde em nosso país a alunos a 
partir do sétimo ano do ensino fundamental). Os estudantes podem estar matriculados em 

qualquer tipo de instituição, em período integral ou parcial, em programas acadêmicos ou 
profissionais, e frequentar escolas públicas, privadas ou escolas estrangeiras dentro do país. 

A taxa de exclusão geral dentro de um país deve ser inferior a 5% para garantir que, sob 
hipóteses  razoáveis,  quaisquer  distorções  nas  pontuações  médias  nacionais  permaneçam 

dentro  de  mais  ou  menos  5  pontos.  A  exclusão  pode  ocorrer  tanto  pelas  escolas  que 
participaram pelos alunos que participaram nas escolas. 

As informações coletadas a partir dos resultados do PISA nos possibilitam avaliar 
os dados sob diferentes pontos de vista, de forma que os resultados podem ser observados 

em  âmbito  nacional  ou  regional,  assim  como  a  leitura  dos  dados  analisados  pode  ter 
enfoque na dependência administrativa, observando separadamente os resultados das redes 

federal, estadual e privada.  Conforme INEP (2018), além da realização da prova, o PISA 
coleta  informações  contextuais  por  meio  de  questionários  aplicados  aos  estudantes, 

professores, diretores de escola e pais dos estudantes.  A partir da análise dos resultados 
e das informações extraídas destes questionários, são elaborados relatórios nacionais que 

possibilitam  a  leitura  desses  dados,  contextualizando-os  a  questões  sociais,  culturais  e 
econômicas, o que nos permite ter uma visão mais abrangente dos resultados observados. 

Com isso, temos acesso a outros indicadores, além da pontuação obtida na prova, os quais 
nos trazem informações que podem em parte explicar os resultados do país nesta avaliação, 

visto que, existem questões intrínsecas ao desenvolvimento do processo educacional que 
vão  além  do  ambiente  de  sala  de  aula.  Na  próxima  seção,  apresentaremos  uma  breve 

retrospectiva histórica dessa avaliação, pontuando observações sobre como estes resultados 
foram divulgados por meio dos relatórios nacionais. 

 
  
 
16 

1.2  Histórico  do  PISA 

A  avaliação  PISA  foi  aplicada  pela  primeira  vez  no  ano  2000.  De  acordo  com  o 
relatório desta  edição  INEP  (2001),  32  países  integraram  esta  avaliação,  sendo  o  Brasil 
o  único  representante  da  América  do  Sul.  Ainda  correspondendo  a  mesma  edição,  houve 
uma  aplicação  posterior2,  onde  outros  11  países  ingressaram,  o  que  fez  com  que  o  Brasil 
passasse  a  ter a  companhia  de  Argentina,  Chile  e  Peru  da  América  do  Sul,  embora  tal 
fato  não  conste  neste  relatório,  elaborado  antes  da  realização  deste  exame  por  parte 
desses  países.  Neste  relatório  são  apresentados  como  indicadores  socioeducacionais:  o  PIB 
(Produto  Interno  Bruto)  per  capita,  o  IDH:  Índice  de  Desenvolvimento  Humano,  o  Índice 
de  Gini3,  a  taxa  de  analfabetismo  e  a  população  com  curso  superior  desses  países  de 
forma  a  contextualizar  os  resultados  dessa  avaliação.  Essa  contextualização  é  realizada 
contemplando  a  média  geral  e  os  resultados  obtidos  em  leitura  (foco  do  exame  nesta 
primeira  edição),  não  havendo  assim  dados  mais  detalhados  sobre  os  resultados  nacionais 
em Matemática. 

A edição de 2003 foi a primeira que teve Matemática como foco da avaliação. Nesta 

edição o número de países participantes aumentou para 41, com o Uruguai juntando-se a 

Brasil e México como únicos representantes da América Latina, uma vez que Argentina, 
Chile  e  Peru  não  tomaram  parte  desta  edição.  Para  esta  edição  não  foi  elaborado  um 
relatório nacional nos mesmos moldes da primeira edição, ou do que viria a ser adotado 

nas  edições  posteriores,  mas  um  "resumo  técnico".  Nele  são  destacados  os  avanços  em 
relação à edição anterior na área, como o aumento da média de 300 para 350 pontos, na 

área de conteúdo “Espaço e Forma”, ressaltando que apenas três outros países (Bélgica, 
Indonésia e Letônia), além do Brasil, apresentaram melhoras de desempenho nessa área. 

Da mesma forma, em “Mudança e Relação”, a  média brasileira passou de 263 para 333 
pontos, registrando o maior aumento de desempenho entre todos os países avaliados. 

Na edição de 2006, a avaliação passou a contar com 57 participantes.  Com a adesão 
da Colômbia, e os retornos de Argentina e Chile após suas ausências na edição de 2003, 

contamos com 5 representantes da América do Sul: Argentina, Brasil, Chile, Colômbia e 
Uruguai , fato este que possibilitou a partir  desta edição a comparação da evolução dos 

resultados do nosso país com a evolução dos países vizinhos nas edições posteriores. A 
partir  desta  edição,  os  relatórios  nacionais  passaram  a  seguir  o  modelo  que  foi  adotado 

nas edições seguintes, que além das comparações internacionais, traz informações em cada 
área do conhecimento detalhadas por: médias gerais por região e por unidade da federação, 

2 Informação disponível em:  http://dadosroraima.com/2017/05/resultado-da-avaliacao-do-pisa-2000/ 
3 O Índice de Gini, é um coeficiente que mede o grau de concentração de renda. Esse indicador, varia de 0 a 1, sendo que o valor  zero 
representa uma situação onde todos têm a mesma  renda, e o valor  um  representaria uma só pessoa concentrando toda a riqueza. 

 
 
 
 
                                                      
17 

resultados das escolas públicas e privadas, a influência da série cursada no desempenho 
dos alunos, a influência do nível socioeconômico e cultural e do nível de escolaridade dos 

pais no desempenho dos alunos, a associação entre os recursos da escola e o desempenho 
dos alunos. 

A edição de 2009 passou a contar com 66 economias participantes. Este relatório 
deu  continuidade  ao  modelo  adotado  a  partir  de  2006.  Pela  primeira  vez  foi  possível 

avaliar as evoluções obtidas em âmbito nacional. 

No ano de 2012, a avaliação PISA voltou a ter a área de Matemática como foco da 

edição. Por isso, seus resultados são comparados principalmente com a edição de 2003 do 
ponto  de  vista  internacional.  Em  âmbito  nacional,  a  análise  da  evolução  dos  resultados 

deu prosseguimento ao que vinha sendo feito, buscando enriquecer as informações trazidas 
nos  relatórios  das  edições  anteriores,  conforme  INEP  (2013,  p.23):  "Embora  o  PISA 

utilize amostras estaduais desde 2006, apenas os resultados de 2009 e 2012 contam com 
maior representatividade e menor erro padrão." 

Este relatório, devido ao foco desta edição, traz o detalhamento dos resultados por 
conteúdo matemático (mudanças e relações, espaço e forma, quantidade, indeterminação 

e  dados)  e  por  processo  matemático  (formular,  empregar  e  interpretar)  por  unidade  da 
federação.  De acordo com INEP (2013), 

Formular  envolve  a  capacidade  de  identificar  oportunidades  de  utilização  da  matemática; 
perceber  que  a  matemática  pode  ser  aplicada  na  compreensão  e  na  resolução  de  problemas; 
providenciar  estrutura  matemática,  representação  e  variáveis;  e  fazer  suposições  sobre  como 
resolver o problema. Empregar envolve aplicar a razão e utilizar conceitos matemáticos; analisar 
a  informação  em  um  modelo  matemático,  por  meio  do  desenvolvimento  de  cálculos, 
procedimentos,  equações  e  modelos;  desenvolver  descrições  matemáticas  e  utilizar  suas 
ferramentas  para  resolver  problemas.  Interpretar  matematicamente  envolve  refletir  sobre 
soluções  matemáticas  e  interpretá-las  em  um  determinado  contexto de  problema; inclui avaliar 
as  soluções  e  os  raciocínios  matemáticos  empregados,  e  verificar  se  os  resultados  são 
razoáveis e fazem sentido naquela situação específica. (INEP, 2013, p.18). 

Como novidade principal, podemos apontar a seção “Fatores associados aos resul- 

tados”, nos quais procura examinar aspectos relacionados às condições escolares. 

A edição de 2015 apresentou como principal novidade o fato de os testes do PISA 
passarem  a  ser  aplicados  em  computador,  através  de  uma  plataforma  de  aplicação  off- 

line  desenvolvida  pelo  consórcio  internacional  do  PISA.  Para  países  que  não  puderem 
testar  seus  alunos  pelo  computador,  ainda  é  realizada  a  aplicação  em  papel,  sendo  essa 

limitada aos itens comuns. Nesta edição a avaliação alcançou a marca de 70 economias 
participantes. 

O  relatório  de  2015  se  aprofunda  bastante  em examinar  os  questionários  contex- 
tuais  do  PISA,  e  apresenta  características  bem  mais  técnicas  em  relação  aos  relatórios 

 
  
 
18 

anteriores. 

Na edição de 2018, compuseram a avaliação 79 economias. O relatório desta edição 
volta a se aproximar do modelo de apresentação entre 2006 e 2012, entretanto para esta 
edição não foram apresentados os resultados detalhados por Unidade Federativa. Nele é 

apresentada a evolução dos resultados a partir de 2003, quando pela primeira vez na série 
histórica, a avaliação teve a área de Matemática como foco. 

Por  ser  uma  avaliação  realizada  a  cada  3  anos,  a  próxima  aplicação  (que  teria 
novamente Matemática como domínio principal) estava prevista para ser realizada neste 

ano de 2021. No entanto, em decorrência do enfrentamento da pandemia de COVID-19, 
esta  avaliação  foi  adiada  para  2022  e  consequentemente,  para  retomar  o  planejamento 

trienal,  a  edição  de  2024  foi  postergada  para  2025.  A  partir  dessas  próximas  leituras 
poderemos  começar  a  estimar  os  impactos  das  lacunas  de  aprendizagem  decorrentes  do 

período pandêmico. 

1.3  Escala de proficiência de Matemática do PISA 

A cada faixa de pontuação, o PISA associa um nível, dentro do qual é esperado que 
o  aluno  que  obteve  a  pontuação  correspondente  àquele  nível  possua  habilidades  e 
competências  consideradas  necessárias  para  que  ele  tenha  obtido  o  resultado que  foi 
atingido. Nesta seção são apresentadas as descrições relativas a cada um dos níveis4: 

• Abaixo  do nível  1 

A OCDE não especifica as habilidades desenvolvidas. 

•  Nível 1 

Os estudantes são capazes de responder a questões que envolvem contextos famili- 
ares, nas quais todas as informações relevantes estão presentes e as questões estão 

claramente definidas. Conseguem identificar informações e executar procedimentos 
rotineiros, de acordo com instruções diretas, em situações explícitas.  Conseguem re- 

alizar ações que são, quase sempre, óbvias e que decorrem diretamente dos estímulos 
dados. 

•  Nível 2 

Os  estudantes  são  capazes  de  interpretar  e  reconhecer  situações  em  contextos  que 
não  exigem  mais  do  que  inferências  diretas.  Conseguem  extrair  informações  rele- 
vantes de uma única fonte e utilizar um único modo de representação.  Conseguem 

4 Definições dos níveis extraídas do Relatório Brasil no Pisa 2018. 

 
 
 
 
 
 
 
 
 
                                                      
empregar  algoritmos,  fórmulas,  procedimentos  ou  convenções  básicos  para  resol- 
ver problemas que envolvem números inteiros. São capazes de fazer interpretações 

19 

literais de resultados. 

•  Nível 3 

Os estudantes são capazes de executar procedimentos descritos com clareza, inclu- 
sive  aqueles  que  exigem  decisões  sequenciais.  Suas  interpretações  são  seguras  o 

suficiente para servirem de base à construção de um modelo simples ou à seleção e 
aplicação  de  estratégias  simples  de  resolução  de  problemas.  São  capazes  de  inter- 

pretar e de utilizar representações baseadas em diferentes fontes de informação e de 
raciocinar diretamente com base nelas. Demonstram alguma capacidade para lidar 

com  porcentagens,  frações  e  números  decimais,  e  para  trabalhar  com  relações  de 
proporcionalidade. Suas soluções indicam que eles se envolvem em interpretações e 

raciocínios básicos. 

•  Nível 4 

Os estudantes são capazes de trabalhar de maneira eficaz com modelos explícitos em 

situações concretas complexas, que podem envolver restrições ou exigir formulação 
de  hipóteses.  São  capazes  de  selecionar  e  de  integrar  diferentes  representações,  inclu- 

sive representações simbólicas, relacionando-as diretamente a aspectos de situações 
da vida real. Conseguem utilizar seu conjunto limitado de habilidades e raciocinar 

com  alguma  perspicácia  em  contextos  diretos.  São  capazes  de  construir  e  de  co- 
municar explicações e argumentos com base em suas interpretações, argumentos e 

ações. 

•  Nível 5 

Os estudantes são capazes de desenvolver modelos para situações complexas e tra- 

balhar com eles, identificando restrições e especificando hipóteses. Conseguem se- 
lecionar, comparar e avaliar estratégias adequadas de  resolução de problemas para 
lidar com problemas complexos relacionados a esses modelos. Conseguem trabalhar 
estrategicamente, utilizando um vasto e bem desenvolvido conjunto de habilidades 

de  pensamento  e  de  raciocínio,  representações  conectadas  de  maneira  adequada, 
caracterizações  simbólicas  e  formais,  e  percepção  relativa  a  essas  situações.  Co- 

meçam a  refletir  sobre  suas  ações  e  são  capazes  de  formular  e  de  comunicar  suas 
interpretações e raciocínios. 

•  Nível 6 

Os  estudantes  são  capazes  de  conceituar,  generalizar  e  utilizar  informações  com 

base em suas investigações e na modelagem de problemas complexos, e são capazes 

 
  
 
20 

de  usar  seu  conhecimento  em  contextos  relativamente  não  padronizados.  Conse- 
guem estabelecer ligações entre diferentes fontes de informação e representações, e 

transitar entre elas com flexibilidade. Evidenciam um pensamento e um raciocínio 
matemáticos avançados. São capazes de associar sua percepção e sua compreensão 

junto  com  um  domínio  de  operações  e  relações  matemáticas  simbólicas  e  formais 
para desenvolver novas abordagens e estratégias que lhes permitam lidar com situa- 

ções novas. Conseguem refletir sobre suas ações e formular e comunicar com precisão 
suas ações e reflexões relacionadas às constatações, interpretações e argumentações 

que  elaboram;  são  ainda  capazes  de  explicar  por  que  razão  estas  são  adequadas  à 
situação original. 

De acordo com a OCDE: 

[...]  Atingir  pelo  menos  o  nível  2  é  particularmente  importante,  segundo  a OCDE, uma  vez 
que ele é considerado o nível básico de proficiência que se espera de todos os jovens, a fim 
de  tirar  proveito  de  novas  oportunidades  de  aprendizagem  e  de  participar    plenamente  da 
vida social, econômica e cívica da sociedade moderna em um mundo globalizado. (OCDE, 
2016 apud INEP, 2016, p.80) 

Conforme  podemos  perceber  pela  descrição  de  cada  nível,  eles  são  organizados  de 
forma cumulativa, ou seja, podemos pressupor, por exemplo, que um aluno que tenha atingido 

o nível 3, possua também as habilidades e competências descritas nos níveis anteriores. Assim 
a  cada  nível  descrito,  amplia-se  em  relação  aos  níveis  anteriores  a  quantidade  e  a 

complexidade dos procedimentos que o estudante é capaz de realizar.  

 
 
 
 
 
 
2  A EVOLUÇÃO DOS RESULTADOS DO BRASIL NO PISA 

21 

Neste capítulo, faremos um compilado dos dados que consideramos mais relevantes 

para a nossa análise, examinando o Brasil e tendo como parâmetro o cenário internacio- 
nal. Com isso, tentaremos estabelecer uma série histórica e, a partir destas informações, 

identificar  os  fatores  que  parecem  estar  mais proximamente  relacionados  aos  resultados 
obtidos. Desejamos correlacionar aspectos que apresentam influência no desempenho dos 

alunos,  assim  como  buscamos  encontrar  boas  práticas  que  possam  integrar  medidas 
relativas às políticas institucionais a serem adotadas. 

Adotando os relatórios nacionais como referência para a análise da avaliação PISA, 
podemos  observar  que,  desde  o  ano  de  2009,  o  Brasil  tem  tido  seus  resultados 

examinados  de  forma  comparativa  com  outros  países,  de  acordo  com  os  critérios 
mencionados a                               seguir: 

Todos os países da América Latina participantes – por sua proximidade regional e cultural 
com o Brasil; 
Espanha e Portugal – por sua proximidade cultural com o Brasil; 
Estados Unidos – por ter um sistema federativo e grande extensão territorial, assim como o 
Brasil; 
Canadá – por ter grande extensão territorial, assim como o Brasil, além de geralmente 
apresentar alto desempenho; 
Coreia – um país asiático que geralmente apresenta alto desempenho;  
Finlândia – um país europeu que geralmente apresenta alto desempenho (Inep, 2020, p. 20). 

Na análise que considera o Brasil de forma comparativa com esse grupo de países, 
no  período  que  se  estende  de  2003  a  2012,  considerando  aqueles  que  participaram  de 
todas as edições nesse intervalo, o Brasil foi o país cuja média aumentou de forma mais 

significativa, conforme podemos observar na Tabela 1. 

                                              Tabela 1 - Evolução dos países no PISA 

Fonte:  O autor, 2021 5 

5 Adaptado de INEP, 2013, p.15 

 
  
 
 
 
 
                                                      
22 

Esse período compreende as duas edições em que Matemática foi a área avaliada 

como domínio principal neste exame (respectivamente 2003 e 2012). 

Complementando  as  informações  extraídas  da  Tabela  1,  construímos o gráfico 
da  Figura  1,  ao  qual  acrescentamos  a  visualização  dos  resultados  das  outras  edições 
realizadas6,  além  do  Brasil,  de  Canadá  e  Finlândia.    Esses  dois  países  que  tem  sido 
escolhidos  como  referência,  entre  outros  motivos,  por  geralmente  apresentarem  um  alto 
desempenho,  vem  apresentando  quedas  em  suas  médias.  A  diferença  entre  a  média  da 
Finlândia  e  a  do  Brasil,  que  na  primeira  edição  chegou  a  ser  de  aproximadamente  202 
pontos, na leitura mais recente (realizada em 2018) encontrava-se na casa dos 123 pontos. 
Analogamente,  a  diferença  em  relação  a  média  do  Canadá  que  na  primeira  leitura  foi 
girava em torno de 199 pontos, na última leitura realizada estava situada na faixa dos 128 
pontos. 

                                                Figura  1  -  Comparação  com  países  de  alto  desempenho  

                                                                         Fonte:  O autor, 2021 

Após realizarmos essas observações, procuramos analisar aspectos relacionados ao 
desempenho do grupo de países avaliados em cada edição, objetivando identificar aqueles 

que, em termos de resultados, estão mais próximos do nosso país. Procuramos também, 
por meio do estudo da evolução desses resultados, identificar modelos e propostas educa- 

cionais que podem apresentar impactos significativos considerando a realidade do ensino 
básico do Brasil. 

A  partir  dessas  informações,  realizaremos  algumas  observações  acerca  dos  fatos 

relacionados  aos  critérios  mais  frequentemente  adotados  ao  analisar  o  desempenho  do 
nosso país na avaliação PISA. Acreditamos que de acordo com os critérios que escolhe- 

mos adotar, podemos extrair diferentes interpretações e acrescentar elementos que podem 
contribuir para o debate educacional. 

Em  primeiro  lugar,  o  universo  amostral  é  sempre  diferente  de  uma  edição  para 

6 Informações obtidas dos documentos: Resultados Nacionais PISA  2009 e Relatório Brasil no Pisa 2018. 

 
 
 
 
 
                                                      
23 

outra,  havendo  novos  países  a  aderirem  à  avaliação,  assim  como  países  que  em  algum 
momento deixam de participar. 

Por este motivo, consideramos que avaliar o desempenho do país apenas pelo ran- 
king,  pode  proporcionar  a  sensação  de  uma  piora  da  qualidade  do  ensino  pela  perda  de 

posições. Na realidade, temos um cenário no qual a média brasileira aumentou de forma 
relevante, embora este fato possa não se expressar por uma melhora da colocação do país. 

Tal fato pode ser explicado tanto pelo  aumento do  número  de países/economias partici- 
pantes, como também pela significativa diferença inicial apresentada em relação às demais 

nações participantes já na primeira edição: 

Outro  problema  evidente  é  que  há  variações  significativas  de  proficiência que não chegam a 
modificar posições relativas e, portanto, não são contempladas nos rankings. É o que ocorre 
com o Brasil, comparativamente  com  os  países que  participaram  da  aplicação  de  2000.  Tanto 
neste  ano  como  em  2009,  o  Brasil  foi  o  pior  colocado  no  grupo  que  participou  do Pisa 2000, 
embora  a  nota  média  tenha  subido  de  75%  para  80%  da   média  não  ponderada  da  prova 
(SOARES; NASCIMENTO, 2012, p.  77). 

Esse  fato  nos  mostra  o  quão  significativa  era  a  diferença  entre  o  Brasil  e  os  países 

participantes  na  primeira  edição.  Sob  tal  perspectiva,  mesmo  melhoras  consideráveis 
podem  não  ser  expressas  por  meio  do  ganho  de  posições  ao  classificarmos  os  resultados 

dos países por meio de rankings. 

Consideramos, pela evolução dos países apresentada no decorrer das edições, sob a 

perspectiva das evoluções contínuas, que alguns países merecem atenção especial ao avali- 
armos de forma comparativa com o nosso país, por apresentarem progressos consistentes. 

Como já dissemos anteriormente, um estudo mais detalhado do sistema educacional des- 
sas nações fugiria do escopo do presente trabalho, mas consideramos pertinente realizar 

alguns apontamentos que podem interessar aos pesquisadores que desejarem se aprofun- 
dar nesse tema. Para finalizar esta seção vejamos o caso particular de alguns países cujo 

exame da evolução dos resultados pode ser de bom proveito. 

Nesse contexto, destacamos as evoluções de Peru e Portugal, países que apresen- 
taram evoluções contínuas e variações consideráveis em suas médias, conforme podemos 
observar  na  Tabela  27.  Em  suas  trajetórias  nessa  avaliação,  esses  dois  países  sempre 
apresentaram  melhoras  de  uma  participação  para  a  participação  seguinte.  Peru  aderiu  a 
primeira  edição  (em  uma  aplicação  posterior),  tendo  ficado  de  fora  das  duas  aplicações 
subsequentes, retornando definitivamente ao grupo de países integrantes da avaliação em 
2009.  Portugal,  por  sua  vez,  assim  como  o  Brasil,  esteve  presente  desde  a  primeira 
aplicação, tendo continuado como integrante do conjunto de países participantes em todas 
as edições dessa avaliação. 

7 Informações obtidas dos documentos: Resultados Nacionais Pisa 2009 e Relatório Brasil no Pisa 2018. 

 
  
 
 
                                                      
                                                     Tabela 2 - A evolução de Peru e Portugal 

24 

  Fonte:  O autor, 2021 

Peru e Portugal estão entre os países que os relatórios nacionais do INEP incluem 

em sua comparação, devido à sua proximidade cultural com o Brasil, e acreditamos que 
estes  sejam  indicativos  de  que  a  avaliação  do  desenvolvimento  destes  países  em 

particular possa servir como referência para compreender quais práticas educacionais têm 
sido bem sucedidas para melhoria da qualidade da educação. 

Uma vez que situamos a evolução do desempenho do Brasil em relação aos outros 
países, conseguimos perceber que houve uma melhora relativa do desempenho brasileiro 

no  quadro  internacional,  ainda  que  não  expressa  se  avaliada  por  uma  abordagem 
classificatória. Nosso direcionamento, a partir da próxima seção nos encaminhará para os 

desdobramentos  dessa avaliação  em  larga  escala  no  âmbito  do  nosso  território,  onde 
examinaremos alguns dos fatores que podem estar associados aos resultados. 

 
 
 
3  ASPECTOS DOS RESULTADOS DO PISA SOB A PERSPECTIVA 
NACIONAL 

25 

3.1  A  influência  da  escolarização 

Inicialmente, observaremos a evolução do desempenho dos estudantes  brasileiros 

no  PISA  de  acordo  com  seu  ano  de  escolaridade.  Para  estar  elegível  para  a  realização 
dessa avaliação, o estudante deve ter 15 anos de idade e estar cursando a partir do sétimo 

ano do ensino fundamental.  

                                 Tabela 3 - Média nacional no PISA por ano de escolaridade 

                                     Fonte:  O   a u t o r ,   2 0 2 1 8   

Conforme  podemos  observar  a  partir  da  Tabela  3,  alunos  com  menos  anos  de 

escolaridade  apresentaram  médias  menores.  A  inclusão  dos  estudantes  do  sétimo  ano  a 
partir  de  2015  pode  ser  apresentado  como  um  dos  fatores  que  contribuíram  para a 
diminuição significativa da média nacional em relação as leituras anteriores, embora este 

não possa ser apontado como grande responsável, visto que mesmo desconsiderando esse 
grupo  ainda  haveria  um  decréscimo  considerável  ao  compararmos  com  os  resultados 

apresentados nas edições anteriores.  Essa inclusão ocorreu conforme exposto: 

Com a ampliação do Ensino Fundamental para nove anos de duração (Lei n° 11.274, de 6 de 
fevereiro de 2006), todos os estudantes elegíveis  a partir do 7° ano foram incluídos no PISA 
2015.  Essa  transição  do  sistema  de  oito  para  nove  anos  do  Ensino  Fundamental  incluiu  o 
período de três ciclos do PISA; contudo, não se observam diferenças expressivas na distribuição 
de  estudantes  nesses  ciclos  mesmo  com  a  inclusão  do  7°  ano  na  amostra  de  2015.  (INEP, 
2016, p.  27). 

Podemos  perceber que  o  período em  que  houve uma melhora dos resultados na- 

8 Adaptado de INEP, 2020, p.119 

 
  
 
 
 
 
 
                                                      
26 

cionais  nessa  avaliação,  corresponde  a  um  aumento  nos  anos  de  escolaridade.  Também 
podemos  observar  pela  Tabela  3  que  na  edição  de  2003  a  maior  quantidade  dos  alunos 

participantes  encontrava-se  no  primeiro  do  ano  do  ensino  médio,  sendo  o  percentual  de 
alunos  do  segundo  ano  do  ensino  médio  menor  inclusive  que  a  porcentagem  de 

estudantes do nono ano. Essa tendência se inverteu nas edições posteriores, nas quais nas 
amostras  observadas  o  maior  percentual  de  alunos  participantes  passou  a  ser  de  alunos 

do segundo ano do ensino médio. 

Conforme  podemos  observar  no  gráfico  da  Figura  2,  uma  possível  justificativa 

para influência da quantidade de anos completos de estudo nos resultados dos estudantes 
brasileiros é apresentada por 

Enquanto  nos  países  da  OCDE,  com  pouco  atraso  escolar,  a  maioria  dos  estudantes  com  idade 
próxima  aos  15  anos  cursa  a  mesma  série,  o  equivalente  ao  1°  ano  do  ensino  médio  (ou  10 
anos  de  estudo  como  mostra  o  gráfico),  no  Brasil  e  México  são  muitos  os  estudantes 
cursando séries mais atrasadas. Em 2003, cerca de 38,5% dos estudantes brasileiros não estavam 
na série adequada e em 2012 conseguimos reduzir para 22,6%, ainda um percentual elevado. Em 
síntese,  temos  estudantes  sendo  avaliados  em  habilidades  e  competências  que  ainda  não  lhes 
foram ensinadas nas escolas. Por certo, este cenário é uma das causas que „puxa para baixo‟ a 
média global do Brasil, posicionando um percentual elevado de    estudantes  nos  níveis  mais 
baixos da escala do PISA. Embora México também tenha estudantes  atrasados, o problema é 
mais grave no Brasil. (NUNES; AGUIAR; ELLIOT, 2015, p.  17). 

                      Figura 2 - Comparativo da média na escala global de Matemática  por ano de escolaridade 

                     Fonte: NUNES; AGUIAR; ELLIOT, 2015.p.16 

Em seu estudo, Klein (2011) avalia como as mudanças nas datas de aplicação do 

exame  podem  alterar  a  composição  da  amostra.  Isso  nos  mostra  que  podem  existir  ou- 
tros  fatores,  além  dos  índices  de  reprovação  e  evasão,  que  podem  apresentar  influência 

nas amostras e consequentemente nos resultados. Para que possamos melhor compreen- 
der  alguns  desses  fatores,  consideramos  uma  análise  mais  aprofundada  de  seus  recortes 

amostrais. 

 
 
 
 
 
 
27 

Se considerarmos as duas avaliações em que a ênfase recorreu sobre Matemática (2003 e 2012), 
observa-se  um  aumento  de  35  pontos  nas  médias globais.  Cerca  de  metade  desse  aumento, 
segundo  relatório  da  OCDE  (2015),  pode  ser  explicada  por  mudanças  na  composição 
demográfica e socioeconômica da população estudantil.  (ORTIGÃO; SANTOS; LIMA, 2018, 
p.  381). 

Conforme  podemos  observar  no  gráfico  da  Figura  3,  o  percentual  de  estudantes 

considerados elegíveis aumentou de forma significativa, elevando-se de 68% em 2003, para 
93% em 2018. Este fato representa que, neste período, houve a diminuição da proporção 

de jovens fora da escola e de estudantes com menos de 6 anos completos de escolaridade 
na  faixa  etária  coberta  pela  avaliação, configurando um processo de democratização do 

ensino. 

                        Figura 3 - Estudantes elegíveis do Brasil no PISA 

   Fonte:  INEP, 2020.p.43 

Podemos observar a composição das amostras considerando os percentuais de alu- 

nos do ensino fundamental e do ensino médio a partir da Tabela 4, construída a partir das 
informações extraídas da Tabela 3. Também a partir da Tabela 3, elaboramos as tabelas 

seguintes, que especificam os resultados e as composições das amostras  identificados  de 
acordo com esses segmentos. 

                       Tabela 4 - Composição da amostra de acordo com o nível de ensino       

                                            Fonte:  O autor, 2021 

 
  
 
 
 
 
28 

Ao observamos a evolução dos percentuais dos estudantes que compõe a amostra, 
podemos perceber que de 2003 a 2015 houve uma redução na proporção da participação 

de estudantes dos anos finais do ensino fundamental. 

Ao compararmos as médias por segmento, observamos alguns pontos que conside- 

ramos importantes: 

I) Na  Tabela  5,  podemos  observar  a  expressiva  diferença  entre  as  médias  dos 
segmentos.  A  menor  diferença  registrada  entre  as  médias  do  ensino  médio  e  do  ensino 
fundamental  foi  superior  a  60  pontos.  Com  isso,  o  aumento  do  percentual  de  alunos  do 

ensino médio expressa um consequente aumento da média global.  

                         Tabela 5 - Média de acordo com o segmento 

                                                  Fonte:  O autor, 2021 

II) O significativo aumento registrado nas médias dos estudantes do ensino funda- 
mental, ocorridos principalmente entre 2003 e 2009. Embora o crescimento nesse período 

possa ser justificado, a princípio, pela composição da amostra, podemos notar que: 

• Se compararmos os resultados de 2003 com os de 2012 (edições nas quais matemá- 
tica  foi  o  foco  da  avaliação),  o  ganho  é  ainda  mais  expressivo.  Principalmente  ao 
considerarmos  que  a  composição  da  amsotra  do  ensino  fundamental  dessas 

edições é semelhante, conforme podemos observar na Tabela 6. 

Tabela 6 - Composição da amostra do Ensino 

Fundamental 

                                                      Fonte: O autor, 2021 

 
 
                     
 
29 

• Ao  compararmos  a  primeira  e  a  última  leitura  realizadas,  podemos  afirmar  que, 
embora a amostra de 2018 apresente uma média de escolarização  menor do que a 
de  2003,  os  seus  resultados  são  melhores.  Cabe  ainda  ressaltar  que  as  médias  do 
7◦  e 8◦  anos na edição de 2018 são respectivamente superiores as médias do 8◦  do 
9◦ ano da edição de 2003. Ou seja, é como se nesse período os alunos desses níveis 
tivessem ganho 1 ano de estudo. 

Um dos reflexos da melhoria apresentada no ensino fundamental, onde se concen- 

travam  as  médias  mais  baixas,  pode  ser  observado  a  partir  da  Tabela  7.  Essa  tabela 
apresenta  a  evolução  dos  estudantes  brasileiros  de  acordo  com  o  nível  de  proficiência. 

Nela  podemos  notar  que  no  período  de  2003  a  2012,  diminuiu  de  forma  significativa  o 
percentual de estudantes abaixo do nível 1, ao passo que cada uma destas edições houve 

aumento nos percentuais de estudantes nos níveis 1,2 e 3. 

Tabela 7 - Percentuais de estudantes brasileiros por nível de proficiência 

                       Fonte: O autor, 2021 9  

Consideramos  pertinente  ressaltar  que  na  leitura  de  2003,  mais  da  metade  dos 

estudantes situavam-se  abaixo  do nível 1 (53,26%), de forma que a evolução registrada 
nas  edições  posteriores  representou  que  na  edição  de  2012,  comparativamente  a  2003, 

passamos a ter 18,04% a menos dos nossos alunos no nível mais crítico. 

Nesse contexto, podemos perceber que o percentual de alunos abaixo do nível 2, 

foi reduzido nesse período de 75,16% para 67,09% e com isso, a média de pontuações do 
país se elevou, conforme podemos observar no gráfico da Figura 4. 

9 Dados extraídos de: https://databank.worldbank.org/source/education-statistics-%5e-all-indicators. 

 
  
 
 
 
 
 
 
 
 
                                      
 
 
 
 
 
 
 
 
 
 
                                                      
 
                                      Figura 4 - Médias do Brasil no PISA 

30 

                                                Fonte: O autor, 202110  

A verificação de que a melhora da educação nesse período se concentrou  princi- 
palmente no ensino fundamental também foi observada por Falcão (2015) em seu estudo, 

ao analisar a correlação entre os resultados do  Índice de Desenvolvimento da Educação 
Básica (Ideb) e a ampliação dos investimentos em educação no período de 2005 a 2013: 

Foi  encontrada  correlação  positiva  e  significante  entre  o  gasto  em  educação  municipal  por 
matrícula e o resultado do Ideb das escolas municipais, cujo coeficiente de correlação mantém-se 
por volta de 0,45 no período analisado. Com a observação dos gráficos 3.8 (Anexo B) e dos 
dados  apresentados  anteriormente,  conclui-se  que  entre  2005  e  2013  houve  um  crescimento 
significativo do gasto por matrícula dos municípios em educação no mesmo período em que os 
indicadores  de  qualidade  da  educação da  rede  municipal  de  ensino  apresentaram  melhora. 
Adicionalmente,  os  gráficos  3.8  revelam  que  maiores  níveis  de  gasto  em  educação  estão 
relacionados  positivamente  a  melhores  desempenhos  dos  alunos  no  Ideb,  indicando  que  os 
esforços realizados pelos  municípios  podem  colaborar  para  a  melhoria  dos resultados  escolares 
de seus alunos, principalmente no caso do Ensino Fundamental.  (FALCÃO, 2015, p.  43). 

Utilizaremos  essa  ideia  de  correlação  na  próxima  seção,  ao  examinar  a  evolução 
dos  investimentos  do  nosso  país  em  educação.  Consideramos  importante  ressaltar  que 
utilizaremos este indicador, o coeficiente de correlação, apenas como uma medida do grau 

dessa correlação. Com isso, queremos dizer que não é nosso objetivo aqui, a partir dele, 
determinar uma relação de causa e consequência. Ou seja, no presente trabalho, buscamos 

apenas identificar se os períodos de ampliação de investimentos coincidem com a evolução 
histórica dos resultados nacionais.  No Apêndice A, além de uma breve explicação sobre 

o conceito de correlação, disponibilizamos as fórmulas utilizadas e os cálculos realizados 
neste trabalho. 

10 Dados  extraídos  de: https://databank.worldbank.org/source/education-statistics-%5e-all-indicators. 

 
 
                                             
                                                                    
 
 
                                                      
 
 
31 

3.2  A evolução dos investimentos em educação 

Na seção anterior, vimos como  as médias dos estudantes se  comportavam  de acordo 
com  o  seu  nível  de  escolarização,  e  foi  possível  comparar  esses  resultados ao longo das 

edições.  Também  foi  possível  observar  dentro  de  uma  mesma  edição  os  resultados  de  cada 
nível de ensino, o que nos possibilitou uma melhor visualização dessas informações. 

Consideramos que a educação é um processo contínuo. Isso significa que quando, 
por exemplo, um estudante de 1◦ ano do ensino médio participa de uma avaliação de larga 
escala, em moldes semelhantes aos do PISA, não estão sendo avaliados os conhecimentos 
referentes apenas ao ano em que ele se encontra, mas todos os conhecimentos adquiridos 
por ele ao longo da sua trajetória no ensino básico. 

Dessa  forma,  entendemos  que  os  investimentos  realizados  apresentam  resultados 
a  médio  e  longo  prazo.  Portanto,  ao  analisarmos  os  resultados  desses  investimentos, 
procuraremos compreender como a sua evolução está relacionada aos resultados obtidos 

pelos  estudantes.  Para  tanto,  inicialmente  consideramos  as  Tabelas  8  e  9,  que  nos 
apresentam como os investimentos em educação evoluíram em relação ao PIB, assim como       

evoluíram os investimentos diretos por estudante. 

Tabela 8 - Estimativa do percentual do investimento público total em Educação no Brasil em 
relação ao PIB por nível de ensino - 2000-2015 

        Fonte:  Anuário da educação 2020, p.120 

A  partir  das  informações  extraídas  da  Tabela  9,  para  que  possamos  avaliar  o 

impacto  da  variação  desses  investimentos,  inicialmente  realizamos  algumas  con- 

siderações. Como cada ciclo do PISA compreende três anos, para cada ciclo consideramos 

 
  
 
 
 
 
                               Tabela 9 - Estimativa do investimento público direto em Educação por estudante  

                                    no Brasil,  com  valores  atualizados  para  2015  pelo  Índice  Nacional de Preços ao  

                              Consumidor Amplo (IPCA) por nível de ensino - 2000-2015 

32 

                                Fonte: Anuário da educação 2020, p.121 

o investimento médio por estudante nos anos que o compõe. Portanto, nas Tabelas 10, 11 

e  12,  ao  nos  referirmos  aos  investimentos  relacionados  à  edição  de  2003,  estamos 
considerando o investimento médio no triênio que se inicia no ano de 2001 e se estende 

até 2003, ano no qual a avaliação foi realizada. Esse investimento médio foi obtido a partir 
dos valores extraídos da Tabela 9. 

Tabela 10 - Investimentos em educação por estudante do Ensino Básico por ciclo da 
avaliação PISA (R$) 

                                    Fonte: O autor, 2021 

Na  terceira  coluna  das  Tabelas  10,11  e  12  está  representada  a  diferença entre  o 

investimento  médio  realizado  em  uma  edição  para  o  investimento  realizado  na  edição 
anterior.  Estes  valores  foram  obtidos  subtraindo-se  o  valor  de  cada  linha  da            

segunda coluna pelo valor da linha anterior. 

 
 
 
                                 
 
 
 
 
 
33 
Como desejamos compreender a correlação entre a variação dos investimentos em educação e 
as médias dos estudantes, determinamos o coeficiente de Correlação de Pearson        (Apêndice 
A.1) entre os valores dessa terceira coluna e as médias nacionais em cada edição. 

Tabela 11 - Investimentos em educação por estudante do Ensino Médio        por ciclo da          
avaliação PISA (R$)   

                     Fonte: O autor, 2021 

Tabela 12 - Investimentos em educação por estudante do Ensino Fundamental por ciclo da 
avaliação PISA (R$) 

                                 Fonte: O autor, 2021 

Podemos perceber que a variação dos investimentos na educação básica apresenta- 

se fortemente relacionada ao comportamento das médias, sendo o coeficiente de correlação 
r = 0,99 (conforme apresentado no Apêndice A.1.1.1). 

A correlação entre o aumento nos investimentos para os anos finais do Ensino Fun- 
damental e os resultados dos estudantes deste segmento também foi positiva, tendo sido 

encontrado o coeficiente r = 0,97 (Apêndice A.1.1.3).  Ao contrário do que imaginávamos, 
ao  especificarmos  os  investimentos  e  as  médias  para  o  Ensino  Médio,  o  coeficiente  de 

correlação entre a variação dos investimentos e os resultados obtidos pelo Ensino Médio 
foi  negativo  r  =  -0,45  (conforme  apresentado  no  Apêndice  A.1.1.2),  no  entanto  o  valor 
encontrado não pode ser considerado significativo, ou seja, não há evidência de correlação 

linear  (conforme  critério  apresentado  no  Apêndice  A.1).    Esses  resultados  nos  sugerem 
que a ampliação nos investimentos em educação expressaram um saldo positivo. Nossos 

resultados estão em consonância com o que sugerem os resultados encontrados por Falcão 
(2015) ao realizar um estudo que investiga a correlação entre a evolução dos investimen- 

tos em educação e o resultados expressos  pelo Índice de Desenvolvimento da Educação 
Básica (Ideb). O Ideb é um indicador formulado para medir a qualidade do aprendizado 

nacional e estabelecer metas para a melhoria do ensino. O Ideb é calculado a partir dos 
dados sobre aprovação escolar, obtidos no Censo Escolar, e das médias de desempenho no 

 
  
 
 
 
 
34 

Saeb11.  Conforme Falcão (2015) nos aponta: 

Quanto  à  utilização  do  Gasto  em  Educação  estadual  na  melhoria  do  ensino,  tem-se  que  a 
expansão  do  gasto  público  em  educação  pelos  governos estaduais  acompanhou  melhoras  nas 
notas das avaliações padronizadas de matemática e língua portuguesa e no resultado do Ideb para 
o  Ensino  Fundamental  e  Ensino  Médio.  A  correlação  entre  gasto  em  educação  por  matrícula  e 
desempenho  dos  alunos  mostra  que,  de  fato,  maiores  volumes  de  gasto  na  educação estadual 
estão  positivamente  relacionados  a melhores  resultados  do  Ideb,  ainda  que  com  pequena 
magnitude. A baixa correlação encontrada sugere a necessidade de maior atenção para a gestão 
do  gasto  estadual.  Além  disso,  as  notas  dos  alunos  do  Ensino  Médio,  principal 
responsabilidade da rede estadual de ensino, caíram desde 2009, mantendo o resultado do Ideb 
estagnado  para  esta  etapa,  o  que indica que políticas  de educação estaduais devem atuar  no 
sentido de  melhorar  o  aproveitamento  dos  alunos  nos  últimos  anos  da  Educação  Básica. 
(FALCÃO, 2015, p.  46). 

A  partir  dos  indicativos  apontados  pelos  resultados  nacionais,  consideramos  im- 
portante examinar como esse comportamento se reflete em nível regional. Dessa forma, 

em nossa próxima seção procuraremos observar quais são as tendências apresentadas de 
acordo com a evolução das Unidades Federativas. Esperamos que ao avaliar as perspec- 

tivas apresentadas pela avaliação PISA nesse contexto, seja possível extrair informações 
relevantes para buscar identificar quais políticas educacionais tem apresentado resultados 

mais efetivos. 

3.3  Os resultados do país sob uma perspectiva regional 

Na  presente  seção,  iremos  nos  aprofundar  nas  características  apresentadas  pelos 
resultados  das Unidades da Federação (UFs).  É  importante  observar  que  tais resultados 

só começaram a ser disponibilizados a partir da edição de 2006, conforme explicado por 
INEP: 

11 Informações 
atuacao/pesquisas-estatisticas-e-indicadores/ideb>.  

disponíveis 

em: 

<http://portal.mec.gov.br/conheca-o-ideb>.   e    <https://www.gov.br/inep/pt-  br/areas-de-

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                      
 
35 

No Brasil, as primeiras edições do PISA limitaram-se à amostra mínima de pouco mais de 4.000 
alunos: 4.893 em 2000 e 4.452 em 2003, o que proporcionou apenas resultados globais. Como o 
Brasil apresenta uma grande desigualdade entre as regiões e a ocorrência de distorção idade-série 
ainda  é  acentuada,  os resultados  não forneciam um  quadro  muito  preciso do desempenho dos 
alunos  brasileiros  de  15  anos.  Em  2006,  para  atender  uma  demanda  de  informações  mais 
detalhadas sobre essa população,  a  amostra  foi  ampliada,  visando  a  permitir  afirmações  sobre o 
desempenho dos alunos nas regiões geográficas brasileiras, com suas unidades da federação, bem 
como por série cursada e por dependência administrativa da escola. Embora a amostra brasileira 
ainda não ofereça um retrato muito nítido dos desempenhos por unidade da federação, com a 
expansão  realizada  em  2006  já  é  possível  falar  em  resultados  regionais.  (INEP,  2008,  p. 
25). 

A partir  dessas informações consideraremos nesse ponto  de nossa análise, as va- 
riações regionais dos resultados apresentados em nosso território.  Das edições  de 2006 

até  2015,  os  relatórios  nacionais  do  INEP  apresentaram  os  resultados  dessa  avaliação 
especificados  por  unidade  da  federação.  Considerando  esse  período,  realizaremos  uma 

avaliação desses resultados, separando essas unidades em grupos de acordo com o com- 
portamento das variações de suas médias, conforme descreveremos a seguir. Esses grupos 

foram representados no mapa apresentado na Figura 5. 

                    Figura 5 - Um retrato da evolução dos estados brasileiros 

 Fonte:  O autor, 2021 

O primeiro grupo foi escolhido considerando os estados que apresentaram melhoras 
consistentes  no  decorrer  dessas  edições.  Nesse  grupo,  também  incluímos  o  estado  do 

Paraná,  cujos  resultados  permaneceram  estabilizados  acima  de  400  pontos  em  todas  as 
avaliações nesse período, e o Maranhão que possui um avanço significativo de 2006 para 

2009 e manteve-se na mesma faixa desde então. Este grupo encontra-se representado pela 
cor  verde  no  mapa.  O  segundo  grupo  é  constituído  pelas  unidades  federativas  que 
apresentaram  em  suas  respectivas  médias  um  comportamento  semelhante  ao  da  média 

 
  
 
 
36 

nacional,  sendo  caracterizado  principalmente  pelas  UFs  que  tiveram  uma  queda  de 
desempenho significativa na última edição desta série.  Optamos por sinalizar os estados 

deste grupo pela cor vermelha. O terceiro grupo é formado pelas UFs que apresentaram 
alternâncias no decorrer das edições, sendo que na última leitura a oscilação que tiveram 

e suas médias não pode ser considerada como "um ponto fora da curva", por estar dentro 
de uma margem de variação que já haviam apresentado em edições anteriores. Os estados 

pertencentes a este grupo estão representados na cor amarela. 

Analisando  as  médias  por  região,  podemos  observar  a  significativa  redução  da 

desigualdade  expressa  pelos  resultados  regionais.  Se  na  edição  de  2006  a  diferença 
entre a  região  com  a  maior  média  e  a  região  com  a  pior  média  ficou  na  casa  dos  72 

pontos, na  edição  de  2018  essa  diferença  foi  reduzida  para  38  pontos.  Consideramos 
importante  observar  que  essa  redução  de  mais  de  30  pontos  deve-se  muito  mais  ao 

avanço da região Nordeste (+30) do que à queda nos resultados da região Sul (-4). 

Tabela 13 - Variação das médias em Matemática na avaliação PISA    
por  região 

Fonte:  O   a u t o r ,   2 0 2 1 12   

Objetivando  compreender  melhor  essas  variações  regionais,  procuramos  explorar 

como foi que se desenvolveu o comportamento da flutuação dessas médias por UF. 

Ao organizarmos os resultados estaduais sob o formato de ranking (Anexo C), como 

a avaliação é mais popularmente conhecida, os resultados apresentados por algumas UFs 
chamaram mais a nossa atenção. 

Desta forma, observaremos de forma mais aprofundada um conjunto formado por 

4 estados e pelo Distrito Federal, seguindo os critérios listados a seguir: 

• Sergipe:  Maior queda de desempenho relativa às outras Unidades Federativas (es- 

tado que mais perdeu posições no ranking no período analisado) 

• Amazonas:  Maior  aumento  de  desempenho  absoluto  (maior  aumento  da  própria 

pontuação no período analisado) e relativo. 

•  Distrito Federal:  Maior queda de desempenho absoluta. 

12 Informações obtidas dos documentos: RESULTADOS NACIONAIS – PISA 2006 e Relatório Brasil no Pisa (2018). 

 
 
 
 
                                                      
 
 
37 

• Maranhão:  Uma  das  melhoras  mais  consideráveis  de  desempenho  absoluto  no 

período analisado, sem que isso se reflita em ganho de posições no ranking. 

•  Rio de Janeiro:  Estado onde a pesquisa foi realizada. 

Inicialmente, vamos destacar alguns pontos importantes na evolução dessas UFs. 

O  estado  de  Sergipe  apresentou  grandes  oscilações  de  uma  edição  para  outra  no 
período analisado, alternando duas quedas significativas (2009 e 2015) com uma melhora 

considerável (2012). 

Na  edição  de  2006,  Maranhão  teve  270  pontos  na  média  de  Matemática,  sendo 

este o  pior  resultado  de  todas  as  UFs  nas  quatro  edições  analisadas,  tendo  ficado 
naquela  edição 65 pontos atrás da média do antepenúltimo colocado. Na edição posterior 

registrou  um  expressivo aumento  de 74,6 pontos e este desempenho  manteve-se estável 
nas edições seguintes, aproximando-se desta forma do resultado obtido pelas outras UFs. 

O  Distrito  Federal  manteve-se  na  primeira  posição  nas  três  primeiras  edições 
anali- sadas, caindo para o quinto lugar na última. Na edição de 2006, o DF registrou a 

maior média já alcançada em Matemática por uma UF (431 pontos), no entanto após três 
quedas sucessivas  em  sua  média  deixou  pela  primeira  vez  o  posto  de  UF  com  melhor 

pontuação nessa área do conhecimento. 

Por  outro  lado,  o  estado  do  Amazonas  após  apresentar  no  ano  de  2006  uma  das 

duas únicas médias abaixo de 300 pontos já registradas entre as nossas UFs (298 pontos, 
superando  apenas  os  270  pontos  do  Maranhão,  registrados  nessa  mesma  edição),  apre- 

sentou melhoras sucessivas nas outras três edições, saltando da penúltima posição, para o 
décimo  lugar,  igualando  assim  o  melhor  resultado  já  atingido  por  um  estado  da  região 

Norte (Rondônia em 2006). 

Por  fim,  o  estado  do  Rio  de  Janeiro,  embora  venha  perdendo  posições  a  cada 

edição,  apresentou  um  resultado  estável  nas  três  primeiras  edições,  estando  acima  da 
média nacional ou próximo dela. No entanto, de forma similar a outras UFs, apresentou 

uma queda brusca em sua média na edição de 2015. 

Um dos objetivos do nosso trabalho é identificar as possíveis causas de uma queda 

tão  acentuada  nessa  edição  depois  de  sucessivas  melhoras  nas  leituras  anteriores.  Para 
tanto subdividiremos essa etapa de nossa análise em duas partes. Em um primeiro mo- 

mento, seguindo a mesma linha da análise realizada no contexto nacional, vamos observar 
a composição da amostra em termos de anos de escolaridade nessas UFs, realizando um 

comparativo entre as edições de 2012 e 2015.  Em seguida avaliaremos alguns dos aspec- 
tos apontados nos relatórios nacionais como fatores associados aos resultados, buscando 
identificar outras variáveis que possam nos ajudar a compreender o motivo dessa oscilação. 
De  forma  semelhante  ao  observado  para  os  resultados  nacionais,  os  resultados 

 
  
 
estaduais  nos  apontam  para  a  influência  do  nível  de  escolarização  dos  estudantes  nos 
resultados  dessa  avaliação.  Para  realizar  essa  observação,  comparamos  os  resultados 

dessas  UFs  nos  anos  finais  do  ensino  fundamental  (AF)  e  do  ensino  médio  (EM)  no 
gráfico da Figura 6 e a composição das amostras na Tabela 1413. 

                            Figura 6 - Variação das médias em Matemática na avaliação PISA por região  

38 

                                                Fonte:  O autor, 2021  

Enquanto as UFs que aumentaram de forma significativa a proporção de estudantes 
dos anos finais do ensino fundamental apresentaram queda relevante em suas  médias, o 

Amazonas que seguiu caminho inverso, ampliando a participação do estudantes do ensino 
médio em sua amostra viu sua média se elevar de forma considerável. Enquanto isso, o 

estado do Maranhão que manteve proporções semelhantes na composição de sua amostra 
em ambas as edições teve seu resultado estabilizado. 

Tabela 14 - Variação das médias em Matemática na 

avaliação PISA por região 

                                                   Fonte: O autor, 2021

13 Figuras 6 e Tabela 14 elaboradas a partir das informações disponíveis nos documentos Relatório Nacional  PISA 2012 Resultados 
brasileiros e Brasil no PISA 2015 Análises e reflexões sobre o desempenho dos estudantes brasileiros. 

 
 
 
                                                      
Essa constatação nos indica um impacto significativo que sugere a importância de 
examinar as possíveis causas que conduzem à elevação do quantitativo de estudantes  em 

situação de distorção série-idade. 

39 

 
  
 
4  A INFLUÊNCIA DAS CONDIÇÕES ESCOLARES 

40 

4.1  Os impactos da disponibilidade de profissionais para o atendimento da 

população estudantil 

Analisando inicialmente o caso do município do Rio de Janeiro, identificamos um 

estudo  que  aponta  uma  forte  correlação  entre  o  número  de  alunos  por  sala  no  Ensino 
Médio e os índices de aprovação.  Os autores enfatizam que: 

Diante  dos  resultados  do  estudo,  percebe-se,  de  acordo  com  a  correlação  de  Pearson,  que  a 
Média de Alunos por Turma tem grande influência na Taxa de Rendimentos dos Alunos de 
forma negativa, ou seja, quanto   mais alunos  há em uma turma pior o desempenho escolar 
deles.  Além  disso,  todos  os  testes  estatísticos  demonstram  que  o  modelo  explica  o 
fenômeno.[...]  Diante  do  resultado  apresentado,  as  autoridades  podem  entender  como  o 
quantitativo de alunos pode influenciar a taxa de rendimento. De acordo com a análise, quanto 
menor  a  turma,  maior  será  sua  taxa  de  rendimento.  Então  recomenda-se  que  cresçam  os 
investimentos  em  escolas  públicas  que  disponibilizam  o  nível  médio  com  a  finalidade  de 
aumentar  o  número  de  turmas  e,  consequentemente,  diminuir  a  média  de  alunos  por  turma. 
Com essas medidas, de acordo com os resultados deste estudo, a Taxa de Rendimento dos 
Alunos irá aumentar, ou seja, haverá melhor aprendizado dos alunos. Assim, propõe-se que seja 
refletido  a  questões  associadas  a  políticas  públicas  e  gestão  das  escolas  do  Rio  de  Janeiro; 
sugere-se que as turmas sejam menores para que o desempenho dos alunos seja melhorado. 
(BEZERRA et al., 2020, p. 8). 

Esses resultados podem ser visualizados por meio do gráfico da Figura 7 

                                      Figura 7 – Perspectivas Regionais 

                                      Fonte: CECIERJ (2020)14 

Buscando identificar se tal conclusão pode ser estendida para a avaliação que é o 
objeto de nosso  estudo, procuramos  ampliar nossos  referenciais teóricos  acerca da dinâmica 

dessa relação entre o tamanho médio das turmas e o rendimento dos estudantes. 

14 Disponível em: https://educacaopublica.cecierj.edu.br/artigos/20/36/analise-da-correlacao-entre-a-media-de-alunos-por-turma-na-
taxa-de-rendimento-de-alunos-nas-escolas-publicas-de-ensino-medio-no-municipio-do-rio-de-janeiro. 

 
 
 
 
 
 
 
                                                      
 
41 

O relatório Education at Glance nos aponta que: 

Os resultados mostram que não há uma correlação directa entre o ratio professor/aluno. Há 
30 estudantes ou mais por turma no Japão, na Coreia e no México, no Brasil, Chile e Israel, 
contra  20  ou  menos  na  Dinamarca,  Islândia,  Luxemburgo,  Suíça  e  Federação  Russa,  mas 
somente 2,7% dos estudantes no Luxemburgo, por exemplo, fazem parte do melhor grupo na 
escala de matemáticas do PISA, em comparação com os 8,2%  do  Japão.  (OCDE,  2006,  p. 
2). 

Apesar  destes  resultados  internacionais,  entendemos  que  o  processo  educacional 

não  se  desenvolve  de  forma  desconectada  do  contexto  onde  se  encontra  inserido.  Com 
isso, não podemos interpretar apenas os resultados sem levar em consideração os aspec- 
tos históricos, econômicos, sociais e culturais que podem influenciar esse processo. Dessa 

forma, a política educacional que é bem sucedida em um país, não necessariamente apre- 
sentará os mesmos resultados se aplicada em outro país. 

Quando consideramos um recorte regional dentro do nosso país no Capítulo 3, por 
exemplo, podemos observar que, apesar da redução da desigualdade, ainda há uma dife- 
rença expressiva entre as médias das nossas regiões. A diferença entre a média da região 
Sul e a média da região Norte, por exemplo, ainda é superior a 30 pontos. Uma das dife- 

renças bem acentuadas que pudemos observar entre as características dessas regiões foi a 
discrepância deste indicador: "a região Sul apresentou a menor proporção aluno-professor 

(19,3), enquanto a região Norte (35,5) obteve o maior resultado entre as demais" (INEP, 
2020, p. 148) 

Por esses motivos, consideramos importante em nossa análise observar países com 
realidade  que  apresentem  uma  maior  proximidade  à  nossa,  quando  considerados  esses 

aspectos.    Em  seu estudo  sobre  os  impactos  da  dimensão  das  turmas no  sistema  educa- 
tivo português, MUCHARREIRA et al. (2017) explicita as justificativas que corroboram 

o nosso entendimento: 

Todavia,  outros  autores  chamam  atenção  para  um  conjunto  de  considerações  que  nem 
sempre têm sido tomadas em linha de conta, e que questionam estas assunções: em primeiro 
lugar, a dimensão de turma, constituindo um fator que provoca alterações na estrutura escolar, 
está   necessariamente  dependente  do  contexto.  Isto  quer  dizer  que  não  só  a  dimensão  de 
turma é variável, como os seus efeitos diferem. Além do que se passa na escola, a dimensão 
das  turmas  está  em  parte  dependente  de  dinâmicas  extraescolares  –  demográficas,  políticas, 
culturais - que são diferentes de país para país (Buckingham,2003; Blatchford et al, 2016; Harfitt 
2015;  Englehart  2007,  2011).  É  esta  realidade  contextual  que  explica  em  parte  fenómenos 
como o dos países asiáticos, que apresentam extraordinários resultados apesar de manterem uma 
dimensão  média  de  turma  mais  elevada  tanto  ao  nível  do  ensino  básico,  como  ao  nível  do 
ensino secundário (OECD,2016 b, 2016 c). (MUCHARREIRA et al. 2017,p. 34) 

Em  sua  revisão  de  literatura,  elencam  os  benefícios  que  a  adoção  dessa  política 

 
  
 
42 

poderia promover.  Conforme nos apresenta MUCHARREIRA et al.  (2017) : 

Também Borman e Hewes (2002), Krueger (2002) Bracey e Stellar (2003), McRobbie et al. 
(2004) e Normore e Ilon (2006) por outros autores, estes investigadores referem benefícios a 
médio prazo, aquando ainda da presença dos alunos no sistema educativo, como a redução de 
despesas  resultante  de  um  decréscimo  das  retenções,  de  uma  diminuição  de  necessidades  de 
educação especial, de uma diminuição dos processos disciplinares, para além de um reforço da 
probabilidade  de  continuidade  dos  estudos,  no  mínimo,  até  ao  ensino  secundário. 
(MUCHARREIRA  et al. 2017, p.  49) 

Essa compreensão está em consonância com os resultados encontrados no estudo 
sobre  o  Rio  de  Janeiro,  referenciado  anteriormente,  e  dialoga  com  a  avaliação  apresen- 

tada  nos  relatórios  nacionais: "A  repetência  implica  um  custo  financeiro,  uma  vez  que 
o Estado paga dois anos da mesma educação para um mesmo estudante." (INEP, 2013, p. 

56). "Especialmente no caso do Brasil, os custos estimados da repetência somam bilhões 
de reais, bastante onerosos aos cofres públicos".  (BACHETTO apud Inep, 2016, p. 212). 

Dessa  forma,  entendemos  que,  embora  o  investimento  na  redução  do  número  de 
alunos por turma possa por um lado representar um aumento de "gastos" com servidores  

e estrutura, por outro poderia acarretar uma redução  de despesas, diminuindo o impacto 
dos custos da repetência. 

Além  disso,  compreendemos  a  partir  das  informações  apresentadas,  que  mesmo 
não  sendo  encontrada  uma  correlação  direta  entre  o  tamanho  médio  das  classes  e  os 

resultados dos países, uma vez constatada a influência do nível de escolaridade, podemos 
inferir que, em última análise a redução do tamanho das classes é uma medida que pode 

apresentar um impacto significativo. 

A partir dessa constatação, decidimos observar como as condições de trabalho dos 

profissionais da educação e os resultados da avaliação PISA podem estar relacionados. 

Em nossa análise da influência das condições escolares nos resultados de matemá- 

tica,  para  examinar  do  ponto  de  vista  comparativo  entre  os  países,  estamos  escolhendo 
avaliar os indicadores da edição de 2012. Por ter sido a edição mais recente cujo enfoque 

foi a área de Matemática, os indicadores referentes à associação entre as condições esco- 
lares e os resultados obtidos pelos países nessa área do conhecimento são disponibilizados 
de forma mais detalhada. 

Ao observamos a correlação entre a média obtida em Matemática nessa edição e o 
tamanho médio da classe nos países selecionados pelo INEP para comparação, conforme a 
Tabela 15, por possuírem características que os aproximam do Brasil, encontra- mos um 

coeficiente de r1 = -0,57. Tomando como referência o quantitativo de estudantes que são 

atendidos  por  professor  de  Matemática  esse  coeficiente  foi  de  r2  =  -0,55.  Quando 
excluídos Finlândia e Coréia do Sul, por serem países com características mais distantes 

das do  Brasil,  esses  indicadores  oscilam  para  r1  =  -  0,68  e  r2  =  -0,53  respectivamente. 
Os  cálculos  efetuados  para  determinar  esses  valores  para  os  coeficientes  de  correlação 
foram  realizados  utilizando  o  software  Excel.  A  descrição  do  procedimento  realizado  é 
apresentada no Apêndice B.   

 
 
43 

Desta forma, a correlação entre o número de estudantes por turma e a média no PISA foi 
mais forte, e pôde ser considerada significativa, quando são adotados como comparativo 

países com características mais semelhantes as do Brasil. Essa correlação negativa indica 
que quanto maior é o número de alunos que os profissionais precisam atender por turma, 

piores são os resultados apresentados por eles. 

Tabela 15 -  A  influência das  condições  escolares  

                                          Fonte:  O autor, 202115 

Em relação a este último indicador: 

Observa-se que o Brasil registra uma das piores razões entre número de estudantes e número de 
professores  (de  matemática  ou  não).  Isoladamente,  esse  indicador  é  questionável:  Peru 
apresenta uma razão mais favorável e resultados piores[...]  (INEP, 2013, p.  60). 

Conforme  mencionado  anteriormente,  mesmo  que  esses  resultados  não  apontem 

uma correlação significativa, a influência destes indicadores pode se apresentar de forma 
indireta,  por exemplo,  ao impactar os índices  de aprovação e consequentemente o  nível 

de escolaridade dos participantes. 

É interessante notar a citação deste país como exemplo, pois embora não tenhamos 

registros  das  leituras  posteriores  deste  indicador,  o  Peru  foi  um  país  que  efetivamente 
ultrapassou a média do Brasil nas edições seguintes desta avaliação, o que pode sugerir 

que a médio e longo prazo, a adoção de tal política possa estar associada a uma melhora 
dos resultados educacionais. 

Tais  indicativos  nos  sugerem  que  a  qualidade  do  ensino  nos  países  com  maior 
proximidade  ao  nosso  pode  estar  associada  à  relação  entre  o  número  de  alunos  e  ao 

quantitativo de profissionais disponível para atender essa demanda educacional. 

15 Informações  obtidas  no documento  Relatório Nacional  PISA 2012 Resultados brasileiros 

 
  
 
 
                                                      
44 

4.2  Um olhar para os resultados de acordo com a dependência 

administrativa 

Um dos apontamentos  frequentemente veiculados nos meios de comunicação é a 

discrepância entre os resultados observados para cada rede de ensino. 

Procurando  compreender  como  as  redes  de  ensino  podem  influenciar  no  desem- 
penho dos estudantes, buscamos avaliar os resultados nacionais adotando o enfoque nas 

dependências  administrativas.  Inicialmente,  ressaltamos  que,  como  a  faixa  de  escolari- 
dade dessa avaliação compreende o segundo segmento do ensino fundamental e o ensino 

médio,  optamos  por  não  incluir  no  quadro  comparativo  a  rede  municipal,  por  esta  ser 
responsável principalmente pela pré-escola e pelos anos iniciais do ensino fundamental. 

Conforme  podemos  observar  na  Tabela  16,  no  período  de  2009  a  2018,  o  desempenho 
entre  as  redes  estadual,  federal  e  particular,  quando  analisadas  comparativamente,  não 

apresentou  alterações  significativas  entre  2009  e  2015.  Com  isso,  queremos  dizer  que 
mesmo  considerando  o  erro  padrão  de  cada  rede,  a  rede  estadual  apresentava  o 

desempenho mais baixo e a rede federal o mais alto. É importante destacar que cerca de 
70% dos estudantes são oriundos das escolas estaduais, tendo estes portanto, o maior peso 

na  composição  da  média  nacional.  Na  edição  de  2018,  pela  primeira  vez  houve  uma 
mudança  nesse  cenário,  com  a  rede  particular  apresentando  uma  média  superior  ao  da 
rede federal, embora a diferença entre elas esteja dentro do erro esperado16. 

 Tabela 16  -  Médias  por  dependência  administrativa  

  Fonte:  O autor, 202117 

Os resultados da edição de 2012 nos permitem observar que: 

A  análise  das  diversas  redes  públicas  destaca  a  rede  federal  com  a  melhor  média  em 
matemática. Todavia, essa rede é muito reduzida, representando apenas 1,2% dos estudantes, 
uma parcela com nível socioeconômico  mais  alto  do  que  a  população  das  redes  municipais  e 
estaduais.  No  caso  da  rede  municipal,  por  ofertar  prioritariamente  o  Ensino  Fundamental,  era 
previsível um resultado inferior ao das outras redes, que concentram a oferta de Ensino Médio. 
[...] É  bastante  interessante  a  análise  da  rede  particular  em  comparação  com a rede  federal de 
ensino.  Embora  inclua  estudantes  com  nível  socioeconômico  mais  alto,  a  rede  particular 
apresenta resultado inferior ao da rede federal de ensino. Tal comparação coloca em dúvida a 
real qualidade do ensino privado no Brasil.  (INEP, 2013, p.  54). 

16 EP ^{1}: Estimativa  de  erro-padrão  na  média  da  edição  avaliada. 
17 Informações  disponíveis nos documentos:  Resultados  Nacionais PISA 2009; Relatório Nacional  PISA 2012 Resultados brasileiros; 
Brasil no PISA 2015 Análises e reflexões sobre o desempenho dos estudantes brasileiros e Relatório Brasil no Pisa  2018.. 

 
 
 
 
 
                                                      
 
45 

Podemos  também  observar  como  a  diferença  da  rede  estadual  para  a  rede  parti- 
cular diminui de forma significativa de 2009 para 2012, mas voltou a crescer nas edições 

posteriores. Essa diferença entre as médias esteve próxima dos 100 pontos na leitura mais 
recente  (2018).  É  interessante  buscar  compreender  como  a  diferença  entre  as  redes  de 

ensino  pode  ser  tão  significativa  em  nosso  país.  Quando  olhamos  para  os  resultados  de 
Portugal  também  na  edição  de  2018,  os  resultados  da  rede  pública  são  praticamente  os 

mesmos da rede privada.  Conforme o relatório nacional português: 

Em  2018,  à  semelhança  do  observado  na  avaliação  da  leitura  e  das  ciências,  a  natureza 
administrativa  da  escola  não  diferencia  significativamente  os  resultados  obtidos  em 
matemática. Apesar de os alunos das escolas privadas terem alcançado uma pontuação média 
superior (497 pontos) à verificada para os alunos de escolas do ensino público (492 pontos), 
a diferença não se revelou significativa. (IAVE, 2019, p. 85). 

Para  tentar entender  um  pouco  melhor  o  motivo  dessa  diferença  entre  os  desem- 
penhos das redes de ensino em nosso país, procuramos analisar que características essas 

redes podem apresentar que possam, mesmo que parcialmente, explicar essa significativa 
diferença  de  resultados.  E  um  fator  que  observamos,  conforme  apresentamos 

anteriormente,  foi  justamente  o  tamanho  das  turmas  atendidas.  De  acordo  com  o 
gráfico  da  Figura  8, a  rede  estadual  apresenta  turmas  com  maior  quantidade  média  de 

alunos  (37,3),  quando  comparada  com  a  rede  particular  (33,6)  e  com  a  rede  federal 
(32,6).  Nesse  comparativo, é  importante  observar  como  nas  redes  estaduais  o  modelo 

mais  frequente  (aproximada-  mente  40%)  são  as  turmas  na  faixa  de  36  a  40  alunos,  o 
atendimento modal (também na faixa  de  40%)  são  turmas  na  faixa  de  31  a  35  alunos. 

Enquanto  isso,  na  rede  particular, as  turmas  mais  comuns  (cerca  de  30%),  atendem 
grupos de 26 a 30 alunos. 

                    Figura 8 - Médias de alunos por turma 

                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Fonte:  INEP, 2016, p. 219 

Ressalta-se também a relação de alunos atendidos por funcionário disponível. Em 
levantamento realizado com base nos microdados do Censo Escolar de 2016 e do ENEM 

2016, e divulgado em sua página, Sales (2018) nos aponta que a razão entre o número de 

 
  
 
                                                 
funcionários e o  quantitativo de alunos é de 0,22 na esfera estadual, enquanto  na esfera 
federal é de 0,54 (mais que o dobro) e na esfera particular é de 0,68 (mais que o triplo, 

quando comparada com a rede estadual). 

46 

Figura  9  -  Quantidade  de  funcionários  por  aluno,  por  dependência 

administrativa 

                                 Fonte: SALES (2018)18 

Quando observamos os resultados por dependência administrativa, podemos notar 
uma  maior  proximidade  entre  os  resultados  das  esferas  federal  e  particular,  tendo  em 

vista  a  distância  considerável  entre  os  resultados  destas  duas  e  os  das  redes  estaduais. 
Esse indicativo apresenta-se em consonância com o que sugerem os resultados encontrados 

anteriormente ao avaliarmos a influência das condições escolares. Também é importante 
ressaltar  que,  os  alunos  de  escolas  federais  e  particulares  podem  ser  selecionados  por 

meio de critérios estabelecidos pela instituição, como por exemplo, provas classificatórias 
e avaliação de históricos escolares.  

Conforme mencionamos anteriormente, aproximadamente 70% dos estudantes da 
amostra do nosso país são provenientes das redes estaduais de ensino. Consideramos que 

poderia  ser  interessante  a  elaboração  de  relatórios  específicos  detalhando  os  resultados 
estaduais, em moldes semelhantes ao relatório nacional. 

Dessa forma, a disponibilização das informações detalhadas sobre as amostras esta- 
duais pode proporcionar uma melhor leitura dos resultados, assim como identificar ações 

que podem ser implementadas. Informações sobre o nível de escolaridade dos estudantes, 
as condições ofertadas pela rede (por exemplo, tamanho médio das turmas e quantidade 

de alunos atendidos por professor), a composição da amostra conforme as dependências 
administrativas, podem complementar de forma significativa a interpretação dos resulta- 
dos  nacionais.  Além  disso,  ao  explicitar  a  destinação  dos  investimentos  realizados  (por 
exemplo,  se  foram  utilizados  para  expansão  da  rede  de  ensino  ou  ampliação  do  quadro 

docente), a efetividade de cada ação pode ser melhor compreendida. 

18 Disponível em: 
https://leosalesblog.wordpress.com/2018/02/03/escola-ruim-aluno-ruim-entendendo-a-relacao-entre-estrutura-escolar-e-desempenho-
no-enem/.  

 
 
 
 
                                                      
 
5  BREVES CONSIDERAÇÕES SOBRE A RELEVÂNCIA DA 
AVALIAÇÃO  PISA 

47 

Antes de finalizarmos o presente trabalho, existem algumas ponderações acerca da 

avaliação PISA que merecem ser  observadas. Algumas considerações já foram expostas nos 
capítulos anteriores, como a excessiva atribuição de significância ao ranking em detrimento 

de uma avaliação contextual desses resultados e a comparação entre países com realidades 
completamente distintas. 

Questionamentos  como  amostras  não  representativas  (e  a  eventual  possibilidade 
de caracterizarem vícios amostrais) e adoção do enfoque desta avaliação como principal 

delineador da qualidade educacional dos países (quando há outras abordagens possíveis, 
e áreas do conhecimento não contempladas por esta avaliação, como no caso das ciências 

humanas) estão entre  os principais fatores que  exigem uma certa ressalva ao considerar 
os resultados  dessa avaliação.  A forma como esses resultados costumam ser  divulgados 

podem  induzir  interpretações  equivocadas  daquilo  que  eles  representam  e  consequente- 
mente conduzir ações errôneas no direcionamento de políticas educacionais. Uma vez que 
se  opte  por  adotá-la  como  uma  avaliação  norteadora  de  políticas  públicas  destinadas  a 

educação (o que também é preciso deixar claro, não deixa de ser uma escolha), sua abor- 
dagem  precisa  ser  reavaliada,  com  seus  resultados  debatidos  por  especialistas  da  área  e 

discussões centradas em prol dos interesses da sociedade. 

Alguns desses aspectos foram apresentados em reportagem da revista Nova Escola. 

No  que  tange  ao  processo  de  seleção  das  amostras,  alguns  dos  principais  apontamentos 
são descritos por Ratier (2016):  

 
  
 
 
 
48 

Taxa de não-resposta: Para evitar que apenas os alunos mais bem preparados de cada escola 
façam a prova, a OCDE estabelece patamares altos:  é preciso participação de um mínimo de 
85% das escolas selecionadas e 80% dos estudantes. Em alguns casos, porém, a entidade aceita 
índices  inferiores,  incluindo  as  notas  nos  resultados  finais.  Na  última  avaliação,  Amapá  e 
Paraná não alcançaram os percentuais requeridos, o que requer maior cuidado na análise dos 
resultados do Pisa 2015 para esses dois estados.[...] 
Exclusão  de  alunos:  Cada  país  pode  excluir  até  5%  do  total  da  população  da  participação  do 
exame.  Há  várias  razões  aceitas  para  a  exclusão:  escolas  localizadas  em  regiões  remotas  ou 
inacessíveis, alunos com baixo entendimento da língua nacional ou com deficiências intelectuais 
severas. O Brasil, por exemplo, não aplicou o exame nas escolas indígenas, nas escolas rurais 
da região Norte e nas escolas internacionais. 
Em  2012,  oito  nações  ultrapassaram  o  limite  de  5%:  Dinamarca,  Estônia,  Noruega,  Espanha, 
Estados  Unidos,  Suécia, Reino  Unido  e  Luxemburgo 
–  campeão  da  exclusão,  com  8,4%  do  total  de  estudantes.  A  suspeita  é  que  esses  países 
estariam  deixando  de  fora  os  estudantes  com  mais  dificuldade,  o  que  poderia  aumentar 
artificialmente  suas  notas.  É  o  que  argumenta  o  físico  e  estatístico  teórico  Joachim  Wuttke,  do 
Jülich Centre for Neutron Science (JCNS), na Alemanha, no artigo Uncertanties and Bias in 
PISA (“Incertezas e vieses no Pisa”, na tradução em português).    (RATIER, 2016) 

Apesar de serem suposições, um exame de caráter amostral e de natureza compe- 

titiva,  trata-se  de  uma possibilidade  que  não  pode  ser  completamente  descartada.  Como 
exemplo da promoção de resultados artificiais como consequência do comparativo da qua- 

lidade educacional por meio de ranking, podemos citar o encerramento da divulgação do 
ENEM por escola, realizada originalmente com objetivos semelhantes ao PISA, conforme 

nota divulgada pelo MEC (2018) 

A primeira divulgação do Enem por Escola ocorreu em 2005, oito anos após a criação do exame. 
As  médias  passaram  a  ser  calculadas  para  auxiliar  professores,  diretores  e  demais  gestores 
educacionais  na  identificação  de  deficiências  e  boas  práticas.  Inicialmente,  também  eram 
divulgadas notas para total Brasil, Unidade da Federação e município. Em todas as edições, 
só  eram  considerados  nos  cálculos  das  médias  aqueles  participantes  que  declararam  que  iriam 
concluir o Ensino Médio naquele ano (concluintes) e todas as escolas que tinham no mínimo 10 
participantes. A  última  edição  do  Enem  por  Escola  foi  em  2015.  Em  setembro  de  2017,  o 
Inep  anunciou  o  encerramento  do  Enem  por  Escola  em  função  da  inadequação  do  uso  dos 
resultados como indicador de qualidade do ensino médio e o uso inapropriado feito pela mídia 
e alguns gestores educacionais, que buscavam ranquear as escolas.  (MEC, 2018) 

Conforme reportagem publicada pelo Portal G1 em  8  de agosto de 2015, alguns 

grupos  educacionais poderiam  estar adotando  o expediente  de criar  escolas apenas  com 
alunos selecionados  por possuir bom desempenho, objetivando ganhar destaque no ranking 
de melhores médias do  Enem.  Embora  os  diretores  de  escolas  ouvidos  pela  reportagem 
tenham  negado  a  utilização desta prática como estratégia de pubicidade, alegando que a 

formação  de  turmas  pequenas  são  componentes  de  projetos  pedagógicos  diversos,  a 
reportagem apresentou os seguintes dados: 

 
 
49 

Metade dos 20 colégios com as melhores notas no Exame Nacional do Ensino Médio (Enem 
2014)  têm  índices  de  permanência  de  alunos  considerados  baixos  pelo  Ministério  da 
Educação (MEC). 
Entre  as  20  escolas,  somente  seis  ostentam  taxas  de  permanência  de  80%,  considerada 
adequada  pelo  ministério.  As  demais  se  enquadram  em  patamares  inferiores,  sendo  sete  com 
menos de 20% de permanência. A taxa indica quantos alunos foram matriculados somente no 
ano da prova, ficando apenas um ano no colégio.[...] 
Durante  coletiva  para  a  divulgação  do  ranking,  na  quarta  (5),  o presidente do Inep,  Chico 
Soares, disse que o índice de permanência muito abaixo revela o garimpo de alunos. 
"A explicação é óbvia.  Essa  escola tem  um processo de seleção.  Ou  ela traz aquele aluno 
brilhante de outra escola para seu terceiro ano [do Ensino Médio] ou ela exclui os seus alunos 
que tem desempenho pior", afirmou.  (SOARES, 2015) 

Essas práticas já vêm sendo debatidas quando é proposta a comparação da quali- 

dade das redes de ensino, conforme entrevista concedida nessa mesma publicação: 

[...]  Alejandra  Meraz  Velasco,  coordenadora-geral  do  Todos  pela  Educação,  foi  outra  a 
comemorar a medida. Para ela, o índice de permanência é importante para impedir que colégios 
façam  uma  seleção  de  estudantes  que  têm  maior  expectativa  de  bom  desempenho  no  Enem, 
descartando aqueles que não estão com o rendimento desejável. 
"Se  temos  corte  de  alunos  que  fizeram  todo  o  percurso  de  ensino  naquela  escola,  a  nota  do 
Enem não vai refletir a qualidade do colégio. Essa é uma das vantagens da escola particular 
no ranking: ela pode escolher sua clientela", destacou a coordenadora.  (SOARES, 2015) 

Portanto,  medir  a  qualidade  da  educação  por  meio  dos  famosos  rankings  pode 
gerar interpretações incorretas, uma vez que a realidade do trabalho realizado no campo 

educacional não está refletida necessariamente. No contexto mencionado, as instituições 
de ensino se destacam por realizar um processo seletivo, e não pela qualidade do processo 

formativo. Esse é um dos possíveis desdobramentos, quando no lugar de consequência, a 
"escalada" de um ranking passa a ser vista como um objetivo. 

 
  
 
  
50 

O principal problema deste ranking é que ele pode, em alguma medida, refletir o comportamento 
oportunístico por parte das instituições de ensino. Como mencionado anteriormente, é possível 
que as instituições expulsem os piores alunos de forma a que eles não representem a escola no 
Enem,  levando  ao  aumento  da  sua  média  e  classificação  no  ranking. Por  conseguinte,  as 
escolas  preocupadas  em  recuperar  alunos  com  dificuldades  seriam  piores  ranqueadas.  Caso  os 
pais/alunos escolham as suas escolas com base neste ranking, isto pode levar a uma  segregação 
no  mercado.  Isto  porque  as  escolas  melhores  ranqueadas  teriam  um  excesso  de  demanda, 
selecionariam cada vez mais os melhores alunos dentro do pool maior disponível de candidatos 
e,  como  resultado,  manteriam  ou  melhorariam  suas  posições  no  ranking.  O  contrário 
verificar-se-ia  com as escolas relativamente piores.  O problema é que estas últimas podem ser as 
mais eficientes na produção do serviço educacional. (ANDRADE, 2011, p.  339-340). 

Outro aspecto a ser considerado na composição das amostras  dessa avaliação é a 

questão da inclusão dos estudantes com necessidades especiais: 

Alunos com deficiência: Eles participam ou não da avaliação? A resposta varia de edição para 
edição  e  de  país  para  país.  No  Pisa  de  2003,  o  Reino  Unido  deixou  de  fora  as  escolas 
especiais,  enquanto  a  Alemanha  as  incluiu.  No  artigo  Cautions  on  OECD‟s  Recent 
Educational Survey (PISA) (“Cautelas na recente pesquisa educacional da OCDE (PISA)”, 
na  tradução  em  português),  publicado  em  2003,  o  pesquisador  estima  que  isso  pode  ter 
aumentado a média britânica em 8 pontos. 
Um segundo aspecto se refere às provas simplificadas, versões mais curtas do teste normal (uma 
hora em vez de duas), desenhadas especialmente para estudantes de inclusão. No Pisa 2003, 
segundo Joachim Wuttke, do JCNS,  apenas 0,9% dos austríacos fizeram essa  modalidade, 
entre os húngaros o índice foi de 6,1% - o desempenho da Hungria no teste simplificado foi, 
em média, 200 pontos superior ao dos austríacos. A desconfiança, então, é que alguns países 
poderiam aplicar o teste em alunos que não possuem deficiência.  (RATIER, 2016) 

Aqui destacamos que tais desdobramentos, do nosso ponto de vista, sequer deve- 
riam  ter  margem  para  ocorrer.  Acreditamos  que  a  educação  inclusiva  não  deveria  ser 

inserida no contexto de uma avaliação de aspecto competitivo, na qual espera-se que de- 
terminadas  habilidades  e  competências  tenham  sido  alcançadas  em  determinada  idade. 

O seu desenvolvimento ser mensurado dentro desse contexto é questionável, pois podem 
estar sendo desconsideradas especificidades, uma vez que os níveis dessa modalidade não 

necessariamente encontram-se atrelados ao tempo cronológico. 

Além disso, a dificuldade de uma melhor análise pela ausência de comparativos, 

acaba fazendo com que os "índices de eficiência da educação" do nosso país, sob perspectiva 
internacional, fiquem restritos a este parâmetro. Existem outras avaliações internacionais 

como a TIMSS (Estudo de tendências internacionais em Matemática e Ciências, em tra- 
dução livre), realizada a cada 4 anos e aplicada para alunos na faixa etária dos 10 aos 14 

anos,  que em 2015 contou com a adesão de 49 países. Por sua vez, a avaliação PIRLS 

 
 
51 

(Progresso  no  Estudo  Internacional  de  Alfabetização  e  Leitura,  em  tradução  livre)  é  re- 
alizada a cada 5 anos e aplicada para alunos na faixa dos 10 anos,  tendo sido realizada 

por  55  países  em  2011.  Ambas  as  avaliações  são  organizadas  pela  IEA  (International 
Association for the Evaluation of Educational Achievement), com enfoque nos currículos 

dos países participantes. Quando são alteradas as métricas da avaliação, como esperado, 
também são afetados os resultados, conforme pode ser observado no caso explicitado por 

Ratier (2016) 

As diferenças de faixa etária dos alunos, de foco do exame e de amostra mudam muita coisa. 
O caso mais emblemático é o da Rússia. Em Matemática,  o  país  aparece  em  19°  na  lista 
do  Pisa  e  em  6° na  lista do TIMSS. O fosso aumenta entre Pisa e PIRLS, que mede Leitura. 
A Rússia é 28° no Pisa, mas alcança a vice-liderança no PIRLS. (RATIER, 2016) 

Como o Brasil não participa dessas avaliações internacionais em larga escala, não 
podemos realizar tal comparativo. No entanto, ao olharmos para uma avaliação de cará- 
ter  mais  específico,  realizada  por  um  grupo  seleto  de  estudantes,  a  Olimpíada 
Internacional de Matemática (IMO), competição da qual participam estudantes do ensino 
médio  na  faixa  de  14  a  19  anos,  e  que  conta  anualmente  com  a  participação  do  Brasil 
(exceto  em  1980)  desde  1979  o  panorama  já  seria  diferente.  Como  o  número  de  países 
varia de edição para edição, a organizadora disponibiliza um "ranking relativo" no qual é 
possível observar a posição do seu país proporcionalmente ao total de participantes. Um 
exemplo  de  como  essa  métrica  nos  possibilita  uma  melhor  leitura:  é  possível  que  ao 
olharmos  apenas  para  a  posição  absoluta,  quando  comparados  os  resultados  de  1979 
(primeira  participação  brasileira,  um  22◦  lugar)  com  os  de  2018,  ano  da  edição  mais 
recente do PISA (estivemos em 28◦ lugar na IMO) , tenhamos a falsa impressão de piora 
no desempenho nacional. No entanto, em 1979, havia 23 participantes (ou seja, estivemos 
em  penúltimo  lugar,  somente  à  frente  de  4,55%  das  nações  participantes),  enquanto  na 
edição de 2018, tomaram parte 107 países (ou seja, o Brasil teve um desempenho melhor 
que 74,53% dos participantes). 

Cabe destacar nesse sentido que, nas edições de 1979 até 1996, o Brasil somente em 

uma única oportunidade (em 1985) foi melhor do que mais de 60% dos países participantes. 
De  1997  até  2021,  apenas  uma  vez  deixou  de  ser  (no  ano  2000).  Do  ponto  de  vista  do 

ranking relativo as quinze melhores participações do Brasil aconteceram após o ano 2000, 
sendo as cinco melhores ocorridas a partir de 2008, conforme mostra a Tabela 17 

Apesar de envolver um universo amostral de países participantes maior do que o 
PISA, desde que este começou a ser aplicado, os resultados destas olimpíadas não parecem 

ser tão avaliados como indicativo da qualidade do ensino em comparativo internacional, 
nem  tão  amplamente  divulgados.  Por  envolver  um  grupo  selecionado  de  estudantes  e 

por atribuir premiações individuais, o sucesso do país nessa avaliação, quando noticiado, 
costuma ser muito mais associado ao mérito individual do estudante do que ao sistema de 

 
  
 
52 

ensino que o formou, apesar da evolução consistente e expressiva dos resultados nacionais 
nas duas últimas décadas. 

Realizadas  estas  considerações,  é  importante  salientar  que  a  avaliação  PISA  nos 
fornece, mesmo que parcialmente, resultados passíveis de serem analisados, mas que para 

que estes resultados possam ser efetivamente utilizados em prol da melhoria da educação, 
é importante que eles sejam interpretados e divulgados de forma que sejam investigadas 

possíveis causas e propostas alternativas de mudança com base nas informações extraídas 
a partir deles. 

 
 
53 

Tabela 17 - O Brasil na IMO 

Fonte: O autor19  

19 Informações  disponíveis em: http://www.imo- official.org/country_team_r.aspx?code=BRA. 

 
  
 
 
 
 
 
 
 
  
                                                      
CONCLUSÃO 

54 

Neste trabalho, buscamos aprofundar o entendimento do significado dos resultados 

da  avaliação  PISA  na  área  de  Matemática.  Com  os  apontamentos  realizados  esperamos 
contribuir para pesquisas que tenham como objetivo avaliar políticas públicas educacionais 

a partir dos indicativos sugeridos pelos resultados brasileiros nesta avaliação. 

Para tanto, procuramos interpretar alguns fatores específicos, objetivando esclare- 

cer alguns pontos propagados pelo senso comum, muito pela forma como esses resultados 
são amplamente difundidos pela mídia e disseminados pelas redes sociais. Vamos exami- 

nar algumas das afirmações com as quais, ao acompanhar notícias sobre o tema educação, 
possivelmente  já  tenhamos  nos  deparado,  analisando-as  de  forma  crítica  a  partir  dos 

resultados encontrados neste trabalho.  

I) A educação vem piorando muito nos últimos 20 anos e o PISA comprova isso. 
A avaliação PISA, iniciada no ano 2000, nos mostra inicialmente uma ampliação 
do acesso à educação, conforme indicado pelo aumento expressivo no percentual de jovens 
considerados  aptos  a  realizar  este  exame.  Este  fato,  por  si  só,  já  denota  um  avanço 

no  campo  educacional.  Como  desdobramento  dessa  democratização  do  ensino  e  da 
ampliação  do  nível  de  escolarização  dos  estudantes,  podemos  observar  em  Matemática, 

que é nossa área de interesse, que houve uma expressiva e consistente evolução na média 
nacional nas 4 primeiras  edições, tendo o Brasil alcançado sua melhor média nessa área na 

edição de 2012, antes de uma oscilação nas duas edições posteriores. A evolução do país 
nessa  área,  conforme  vimos  no  Capítulo  5,  coincide  com  o  período  dos  melhores 

resultados  nacionais  na  IMO,  sendo  esta  realizada  desde  1979.  Embora  para  melhor 
analisar  os  resultados das olimpíadas seja necessário um estudo mais aprofundado, talvez 

com outro enfoque, o importante é que a princípio a convergência dos indicativos dessas 
duas avaliações nesse período sugerem avanços significativos nessa área. 

II) Os estudantes não aprendem nada na escola.  Os professores não ensinam. 
Se  tal  afirmação  correspondesse  à  realidade  dos  fatos,  não  poderíamos  observar 

os significativos ganhos nas médias dos estudantes a cada etapa escolar, conforme vimos 
ao  estudar  a  influência  da  escolarização.  As  consideráveis  diferenças  nas  médias  dos 

estudantes,  quando  comparados  por  nível  de  ensino,  evidenciam  que  o  processo  de 
ensino-aprendizagem está evoluindo a cada etapa que se completa. 

III) Investir em educação não traz resultado. Brasil "gasta" muito e tem resultados 

piores do que países que "gastam" menos. 

Em primeiro lugar, para avaliar se os investimentos estão tendo resultados ou não, 

é  preciso  avaliá-los  levando  em  consideração  a  evolução  dos  próprios  resultados.  Para 
tal análise, utilizamos neste estudo, o indicador estatístico conhecido como coeficiente de 

correlação  de  Pearson.  Com  este  trabalho,  não  objetivamos  identificar  se  a  expansão 
desses investimentos foi a causa dessa evolução, apenas fizemos uso deste indicador para 

constatar se a ampliação de investimentos em cada ciclo dessa avaliação coincidia com a 

 
 
 
 
55 

evolução das médias em Matemática. 

Além do mais é preciso, ao realizar a avaliação do "gasto", considerar a natureza 
desses  recursos.  Em  uma  analogia  a  fábula  de  Esopo  da  lebre  e  da  tartaruga,  se  um 
país  já  investia  historicamente  em  educação,  possuindo  uma  população  escolarizada  e 

uma diferença significativa em relação aos nossos resultados, é de se pressupor que não 
iremos "ultrapassar" esse país por investir mais do que ele em um passado recente. Essa 

defasagem histórica pode ser observada desde as primeiras aplicações da avaliação PISA 
ao observarmos dois comparativos internacionais referentes ao ano de 2003: o rendimento 

escolar  avaliado  no  PISA  daquele  ano  comparado  ao  investimento  anual  por  estudante 
(Tabela  1 8 )  e  o  percentual  da  população  adulta  que  concluiu  pelo  menos  a etapa 

final da educação básica (Tabela 19): 

Tabela 18  –  Desempenho  escolar  e  investimento por  aluno/ano na  educação básica (2003) 

                                                Fonte:  RUIZ; RAMOS; HINGEL, 2007, p. 8 

Conforme  observado  por  Ruiz,  Ramos  e  Hingel  (2007): 

A  verdade é que os países de economias consolidadas investem por aluno/ano, em  média, 
algo em torno de US$ 7 mil na Educação Básica – e são países que estão muito à frente do 
Brasil,  que  se  encontra  em  último  lugar,  como  indicam  os  resultados  do  PISA,  Programa 
Internacional de Avaliação de Desempenho, aplicado para jovens de 15 anos, nas disciplinas 
de  Língua  Portuguesa,  Matemática  e  Ciências.  [...]  Países  como  Argentina,  Chile  e  México 
investem  mais  do  que  o  dobro  investido  pelo  Brasil  no  Ensino  Médio.  Ou  seja, 
independentemente do país, nesse campo inexistem mágicas: não há como melhorar a qualidade 
do ensino sem que haja investimento adequado. (RUIZ, RAMOS e HINGEL, 2007, p.  8) 

Em entrevista, Andressa Pellanda (Todos Pela Educação) aponta: 

 
  
 
 
 
56 

Existe  um  falso  gatilho  na  comparação  do  percentual  investido  com  os países  da  OCDE. 
Primeiro  que  os  países  comparados  têm  níveis  de  desenvolvimento  e  de  qualidade  da 
educação muito díspares (a Noruega, por exemplo, não precisa investir em incluir milhões de 
crianças  na  escola  como  o  Brasil)  e,  portanto,  necessitam  de  investimentos  diferentes. E, 
segundo,  só  comparar  o  investimento  absoluto  pode  dar  a  entender que  isso  se  reverte  em 
investimentos  nas  áreas  que  precisam  e  isso  não necessariamente  ocorre  (o  salário  dos 
professores no Brasil, por exemplo,  é  consideravelmente pior que o de países que  investem  em 
absoluto menos do que o Brasil em educação).  No investimento por aluno, por exemplo, o 
Brasil está muito aquém da média dos países da OCDE. O investimento por percentual do 
PIB  é  a  metodologia  utilizada  no  PNE, porque é o disposto pela Constituição.  Entretanto, 
dependendo do PIB de cada país, esse valor em termos absolutos pode ser muito  maior ou 
muito menor.  (GUIMARÃES, 2019) 

Tabela  19  -  Percentual  de  Adultos,  entre  25  e  64  anos,  de  alguns 
países,  que  concluiu  pelo  menos  a  etapa  final  da 
educação básica 

                                                 Fonte:  RUIZ; RAMOS; HINGEL, 2007, p.4 

Mesmo  ao  comparar  a  relação  "gasto  x  resultado"  com  outros  países  da 
América do  Sul,  é  importante  contextualizar  essa  informação.  Conforme  avaliamos  ao 
estudar a influência das condições escolares, se desejamos realizar uma comparação com 

o  Peru,  um  país  que  efetivamente  ultrapassou  o  Brasil,  é  importante  observar  como  o 
tamanho médio das turmas e a razão estudante-professor são significativamente menores 

quando comparados às médias brasileiras, estando  bem próximas  das médias dos países 
membros  da  OCDE.  Por  sua  vez  a  Colômbia,  quando  analisamos  o  histórico  de  seus 
resultados, é um país que foi ultrapassado pelo Brasil em 2009, e do qual chegamos a nos 
distanciar  em  2012  (ciclos  nos  quais,  conforme  a  Tabela  9 ,  ocorreram  as  maiores 

ampliações em investimentos quando comparados ao ciclo anterior).  

 
 
 
 
57 

Em 2015, a Colômbia ultrapassou o Brasil, tendo mantido-se à frente na edição seguinte,  
alcançando  em  seu  teto  histórico  nesta  disciplina  a  mesma  média  de  pontuação  que  já 

havia  sido  alcançada  pelo  Brasil  ainda  em  2012.  Isto  significa  que  esta  posição  foi 
perdida  mais  pela  descontinuidade  dos  progressos  nacionais  que  vinham  ocorrendo  nas 

edições anteriores, do que pelo fato de nossos  vizinhos terem atingido um resultado tão 
mais  expressivo  ao  ponto  de ser  considerado  utilizá-los  como  modelo.  Portanto,  é 

importante observar o que anterior- mente levou ao nosso próprio crescimento e as causas 
da descontinuidade dos progressos nacionais. 

IV) Os professores não trabalham. 
Ao avaliar a influência das condições escolares, percebemos claramente o contrário. 
A diferença entre o tamanho médio das turmas e do quantitativo de estudantes atendidos 
em média por professor dos países do tão almejado topo do ranking para o nosso eviden- 

cia  justamente  uma  sobrecarga  de  trabalho  dos  nossos  professores.  Ao  compararmos  as 
caraterísticas  dos  países  com  médias  próximas  ou  superiores  às  dos  países  membros  da 

OCDE na Tabela 15, é possível observar uma expressiva diferença desses indicadores em 
relação  aos  países  da  América  Latina  (exceto  o  Peru,  que  conforme  destacado vem 

apresentado  melhoras  expressivas).  Nenhum  dos  países  listados  com  média  superior  a 
480  nesta  tabela  (referente  a  aplicação  de  2012,  edição  mais  recente  cujo  foco  foi  em 

Matemática)  apresentou  tamanho  da  classe  ou  relação  estudantes/professor  de  matemá- 
tica superior a da Coréia do Sul (33,6 e 132,6 respectivamente). Comparados a Portugal e 

Finlândia, os professores de Matemática brasileiros atendiam em média muito mais do que 
o  dobro  de  alunos.  Tal  constatação  também  pôde  ser  verificada  quando  examinamos  os 

resultados por dependência administrativa, sendo os melhores resultados alcançados pe- 
las  redes  que  atendem  quantitativos  menores  (particular  e  federal)  quando  comparadas 

com  as  escolas  das  esferas  estaduais.  Também  ressalta-se  a  discrepância  apontada  no 
número  de  funcionários  disponíveis  para  atender  o  quantitativo  de  alunos.  Um  número 

insuficiente de funcionários  pode  apresentar  como  possível  desdobramento  por  exemplo 
um acúmulo  de  funções por  integrantes  da equipe  pedagógica, o  que pode, entre outros 

fatores, contribuir para a queda da qualidade do atendimento ofertado. 

V) A posição no ranking PISA é o que determina a qualidade da educação no país. 
O PISA precisa ser explorado muito além da questão classificatória.  Além da ava- 
liação em si, ele possui questionários contextuais e produz uma série de indicadores cuja 

análise pode agregar muito mais do que a média em si. Além disso, é difícil estabelecer 
uma forma de mensurar a qualidade da educação de uma forma universal sem levar em 

consideração o contexto social, cultural, histórico e econômico diverso dos  países com- 
ponentes.  Cada  região  pode  apresentar  necessidades  educacionais  distintas  que  variam 

de acordo com o seu desenvolvimento e os interesses locais. Dessa forma, um país pode 
produzir bons (ou maus) resultados educacionais sem que isto se reflita no exame,  mas 

 
  
 
58 

contemple as suas próprias especificidades. 

 Com  este  trabalho,  esperamos  ter  conseguido  propor  algumas  reflexões  sobre  as 
incosistências  das  interpretações  mais  amplamente  difundidas  a  respeito  dos  resultados  da 

avaliação  PISA  e  esclarecer  algumas  distorções  que  podem  ocorrer  no  entendimento  do 
cenário  da  educação  básica  em  nosso  país.  Entendemos  que  o  aprofundamento  dessa 

discussão  e  a  contextualização  desses  resultados,  podem  ser  de  bom  proveito  na  busca  da 
melhoria da educação no Brasil, e foi o que buscamos trazer neste trabalho. 

Esperamos ter contribuído com aqueles interessados em  entender um pouco mais 
sobre o significado dessa avaliação e com os que desejam buscar caminhos para a cons- 
trução de propostas que tenham como objetivo o desenvolvimento educacional em nosso 

país. 

 
 
REFERÊNCIAS 

59 

ANDRADE, E. C. Rankings em educação: tipos, problemas, informações e mudanças. 
Estudos Econômicos (São Paulo), v. 41, p. 323-343, 2011. Disponível 
em:<https://www.scielo.br/j/ee/a/JxfLhwgVSHYKcZKy8FrNz5J/?lang=pt&format=pdf>. 
Acesso em: 30 ago. 2021. 

BEZERRA, L. F.; GONÇALVES, C. P.; CUNHA, D. O.; OLIVEIRA, F. L. Análise da 
correlação entre a média de alunos por turma na taxa de rendimento de alunos nas escolas 
públicas de ensino médio no Município do Rio de Janeiro. Educação Pública, v. 20, n.
36. 
Disponível em: <https://educacaopublica.cecierj.edu.br/artigos/20/36/analise- da-correlacao-
entre-a-media-de-alunos-por-turma-na-taxa-de-rendimento-de-alunos-nas- escolas-publicas-
de-ensino-medio-no-municipio-do-rio-de-janeiro>. Acesso em: 17 nov. 2020 

FALCÃO, M. A.C. A Evolução dos gastos em educação no Brasil e sua relação com 
indicadores educacionais. 2015. 53f. Monografia de Bacharelado. Universidade Federal do 
Rio de Janeiro. Instituto de Economia. 2015. Disponível em : 
<https://pantheon.ufrj.br/bitstream/11422/992/1/MACFalc%C3%A3o.pdf>. Acesso em: 07 
jan. 2021.  

GUIMARÃES, C. O Plano Nacional de Educação foi um pacto social firmado pela sociedade 
brasileira. Fiocruz. 03 jun. 2019. Disponível em: 
https://www.epsjv.fiocruz.br/noticias/entrevista/o-plano-nacional-de-educacao-foi-um-pacto-
social-firmado-pela-sociedade. Acesso em: 24 ago. 2021 

IAVE. Instituto de Avaliação Educativa, I.P. PISA 2018 – PORTUGAL. Relatório 
Nacional. Lisboa: 2019. Disponível em: 
https://www.cnedu.pt/content/noticias/internacional/RELATORIO_NACIONAL_PISA2018_
IAVE.pdf  Acesso em: 15 jan. 2022. 

INEP. Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Relatório 
Nacional Pisa 2000. Brasília: 2001. Disponível 
em: 
<https://download.inep.gov.br/publicacoes/institucionais/avaliacoes_e_exames_da_educacao 
Acesso em: 10 set. 2020. 

INEP. Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Resumo 
técnico Pisa 2003 - Brasil. Brasília: 2003. Disponível em: 
<https://download.inep.gov.br/download/internacional/pisa/result_pisa2003_resum_tec.pdf>. 
Acesso em: 11 nov. 2020. 

INEP Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Resultados 
nacionais - Pisa 2006. Brasília: 2008. Disponível em: 
<https://download.inep.gov.br/download/internacional/pisa/Relatorio_PISA2006.pdf>. 
Acesso em: 10 set. 2020. 

INEP Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Resultados 
nacionais – Pisa 2009. Brasília: Disponível em: 
<https://download.inep.gov.br/acoes_internacionais/pisa/resultados/2009/brasil_relatorio_naci
on>. Acesso em: 8 set. 2020. 

INEP. Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Relatório 
Nacional - Pisa 2012 Resultados brasileiros. Brasília: 2013. Disponível em: 
<https://download.inep.gov.br/acoes_internacionais/pisa/resultados/2014/relatorio_nacional_p
isa>. Acesso em: 14 mar. 2020. 

 
  
 
 
 
60 

INEP. Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Brasil no  
PISA 2015.  Análises  e  reflexões  sobre  o  desempenho dos estudantes brasileiros. 
Brasília: 2016. Disponível em: 
<https://download.inep.gov.br/acoes_internacionais/pisa/resultados/2015/pisa2015_completo_
fin>. Acesso em: 8 ago. 2020. 

INEP. Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Relatório 
Brasil no PISA 2018. Brasília: 2020. Disponível 
em:<https://download.inep.gov.br/publicacoes/institucionais/avaliacoes_e_exames_da_educac
ao>. Acesso em: 17 nov. 2020. 

KLEIN, R. Uma re-análise dos resultados do PISA: problemas de comparabilidade. Ensaio:  
avaliação e políticas públicas em educação, v. 19, p. 717-768, 2011. Disponível em: 
<https://www.scielo.br/j/ensaio/a/j9V9wjtcBWtGkdm5dy75CzS/?format=pdf&lang=pt>. 
Acesso em: 3 set. 2021. 

LIRA. S. A. Análise de correlação: Abordagem Teórica e de construção dos coeficientes com 
aplicações. 2004. 196f . Pós Graduação em Métodos Numéricos em Engenharia dos Setores 
de Ciências Exatas Dissertação – Universidade Federal do Paraná, Curitiba, 2004. Disponível 
em: < http://www.ipardes.pr.gov.br/sites/ipardes/arquivos_restritos/files/documento/2019-
09/sachiko_dissertacao_2004.pdf>. Acesso em: 28 mai. 2021 

MUCHARREIRA, P. et al. (2017). A dimensão das turmas no Sistema Educativo Português. 
Secretaria-Geral da Educação e Ciência. Lisboa: ISCTE- Instituto Universitário de Lisboa e 
CIES Centro de Investigação e Estudos de Sociologia, 20-197. Disponível em: < 
https://repositorio.ul.pt/bitstream/10451/31326/1/A%20Dimens%C3%A3o%20das%20Turma
s%20no%20Sistema%20Educativo%20Portugu%C3%AAs.pdf>. Acesso em: 01 abr. 2021 

NUNES, S. M. L.; AGUIAR, G. S.; ELLIOT, L.G. Avaliação em Matemática de Brasil e 
México: Pisa 2003-2012. In: XIV Conferencia Interamericana de Educación Matemática. 
2014. Disponível em: <http://ciaemredumate.org/memorias- ciaem/xiv/pdf/Vol6Curr.pdf>. 
Acesso em: 2 fev. 2021. 

OCDE. Organização para a Cooperação e o Desenvolvimento Econômico. Panorama da 
Educação: Indicadores da OCDE – Edição 2006. EDUCATION AT A GLANCE: OECD 
INDICATORS – 2006 EDITION – ISBN-92-64-02531-6 © OECD 2006. Disponível em: < 
https://www.oecd.org/education/skills-beyond-school/37393599.pdf>. Acesso em: 2 nov. 
2021 

ORTIGÃO, M. I. R., SANTOS, M. J. C., & LIMA, R. de L. (2018). Letramento em 
Matemática no PISA: o que sabem e podem fazer os estudantes?. Zetetike, 26(2), 375–389. 
Disponível em : <https://doi.org/10.20396/zet.v26i2.8650093>. Acesso em: 13 jul. 2021  

RATIER,R. Nove motivos para desconfiar do Pisa. Nova  Escola. 20 dez. 2016. Disponível 
em: https://novaescola.org.br/conteudo/4697/nove-motivos-para-desconfiar-do-pisa. Acesso 
em: 16 ago. 2021 

RIBEIRO, R. A. Correlações nos DFA de diversos perfis geológicos. 2010. 105f. Dissertação 
de Mestrado. Universidade Federal do Rio Grande do Norte. Centro de Ciências Exatas e da 
Terra. Centro de Tecnologia. 2010. Disponível em: 
<https://repositorio.ufrn.br/jspui/bitstream/123456789/12917/1/CorrelacoesDfaDiversos_Ribe
iro_2010.pdf>. Acesso em: 04 jun. 2021 

RUIZ, A. I.; RAMOS, M. N.; HINGEL, M. Escassez de professores no Ensino Médio: 
propostas estruturais e emergenciais. Ministério da Educação. Conselho Nacional de 
Educação. Câmara de Educação Básica, 2007. Disponível em: 

 
 
 
 
 
 
 
 
<http://portal.mec.gov.br/cne/arquivos/pdf/escassez1.pdf>. Acesso em: 18 out. 2021. 

61 

SOARES, W. Metade no 'top 20' do Enem recebe maioria dos alunos no ano da prova. Portal 
G1, 8 ago. 2015. Disponível em: http://g1.globo.com/educacao/noticia/2015/08/metade-no-
top-20-do-enem-recebe-maioria-dos-alunos-no-ano-da-prova.html. Acesso em: 30 ago. 2021 

SOARES, S. S. D.; NASCIMENTO, P. A. M. M. Evolução do desempenho cognitivo dos 
jovens brasileiros no Pisa. Cadernos de pesquisa, v. 42, p. 68-87, 2012.  

 
  
 
 
 
APÊNDICE  A – Noções estatísticas utilizadas neste trabalho 

62 

A.1  A correlação de Pearson 

Quando realizamos um teste de Correlação Linear entre duas variáveis, nosso ob- 
jetivo  é  averiguar  o  quanto  uma  delas  está  relacionada  com  a  outra.  Conforme  Ribeiro 

(2010): 

O “r” de Karl Pearson é utilizado com o intuito de verificar o grau de correlação  linear  entre 
os  valores  emparelhados  da  amostra.  Para  saber se  o  coeficiente  de  correlação  linear  “r”  é 
significativo, o mesmo deve ser comparado com os valores da tabela (Valor Crítico). Deve- 
se  levar  em  consideração  a  quantidade  de  dados  emparelhados.  Se  o  módulo  do  valor 
calculado de “r” excede o valor da tabela, conclui-se que há correlação linear significativa. Em 
caso contrário, não há evidência de  correlação  linear  (TRIOLLA apud RIBEIRO,  2010, p. 
54). 

Em linhas gerais, esse método estatístico nos fornece o grau de correlação linear 
entre duas variáveis. O indicador do grau de correlação pode assumir valores que variam 
de -1 até 1, onde quanto mais perto dos extremos, mais forte é essa correlação.  O valor 

0 indica que as variáveis não dependem uma da outra. O valor 1 indica uma correlação 
positiva perfeita, ou seja, o aumento de uma variável está associado ao aumento da outra, 

enquanto  o  valor  -1  aponta  uma  correlação  negativa  perfeita,  ou  seja,  o  crescimento  de 
uma  variável  está  associado  ao  decrescimento  da  outra.  Os  possíveis  valores  obtidos 

para o coeficiente de correlação linear r, podem ser interpretados conforme Lira (2004) 

Segundo  CALLEGARI-JACQUES  (2003,  p.  90),  o  coeficiente  de  correlação  pode  ser 
avaliado qualitativamente  da seguinte  forma:  se  0,00 < | | < 0,30 , existe fraca correlação 
linear; se 0,30 ≤  | | < 0,60 , existe moderada correlação linear; se 0,60 ≤ | | < 0,90 , existe 
forte correlação linear;  se  0,90  ≤  | | <  1,00  ,  existe  correlação  linear  muito  forte. (LIRA, 
2004, p. 41) 

Conforme podemos observar na tabela da Figura 33 (Anexo A), os valores críticos 
(rc)  dependem  da  quantidade  n  de  dados  emparelhados  na  amostra.  Isto  significa,  que 
quanto  menor  o  número  de  pares  (X,Y),  maior  precisará  ser  o  valor  de  r  para  que  a 
correlação encontrada possa ser considerada significativa. 

Para o cálculo desse coeficiente de correlação linear r, utilizamos a fórmula: 

. 

 
 
 
 
 
             
 
 
                    
 
 
 
 
A.1.1  Cálculos 

A.1.1.1  Correlação da Tabela 10 

63 

A.1.1.2  Correlação da Tabela 11 

 
  
 
 
 
 
 
 
 
 
64 

 
 
 
 
 
 
A.1.1.3  Correlação da Tabela 12 

65 

 
  
 
 
 
APÊNDICE B – A correlação de Pearson no software Excel 

66 

B.1  Exemplos 

Os cálculos utilizados no Apêndice A, podem ser automatizados com a utilização 
do software Excel. Veremos a seguir o procedimento para efetuar estes cálculos, utilizando 

como exemplo os dados Tabela 15 reapresentados na Tabela 20: 

                   Tabela 20  – Tabela 15 representada no Excel 

                                             Fonte:  O autor, 2021 

Inicialmente, ao selecionar INSERIR FUNÇÃO, será aberta uma caixa de seleção, 

por  meio  da  qual  escolheremos  aplicar  em  nossa  tabela  a  correlação  de  Pearson, 
conforme apresentado na Figura 10 

Em  seguida,  selecionamos  em  nossa  tabela  as  colunas  que  irão  corresponder  aos 
valores  de  X  e  de  Y,  conforme  apresentado  no  Apêndice  A.  Em  nosso  caso  estamos 

procu- rando identificar a correlação entre as médias em matemática na edição de 2012 do 
PISA  (Figura  11)  do  conjunto  de  países  selecionados,  e  o  tamanho  médio  das  turmas 

nesse grupo de países (Figura 12). 

Após selecionarmos os nossos dados e aplicarmos a fórmula, encontramos um valor 

aproximado de r = -0,57. 

Seguindo  este  mesmo  procedimento  descrito  acima  para  a  mesma  Tabela  15,  no 
entanto  correlacionando  a  média  do  ano  de  2012  à  razão  estudantes/professor  de 
Matemática,  obtivemos  um  valor  de  r  =  -0,55.  Em  nenhum  desses  dois  casos  o  valor 
encontrado  para  r,   considerando  que  nossa  amostra  foi  composta  por  12  países, 

excedeu  em  módulo o  valor  crítico  da  tabela  da  Figura  33  ( rc  =  0, 576).   Excluindo 
Coreia do Sul e Finlândia, 

 
 
 
 
 
 
                                               Figura 10 - Selecionando a correlação de Pearson no Excel 

67 

Fonte:  O autor, 2021 

por serem os países mais distantes culturalmente do nosso, encontramos para a correlação 
entre a média em Matemática na avaliação de 2012 e a quantidade média de alunos por 
turma,  considerando  os  10  países  restantes  um  valor  de  r  =  -  0,68  e  para  a  correlação 
entre a  média  em  Matemática  e  o  quantitativo  de  estudantes  que  são  atendidos  por 
professor  de  Matemática  um  valor  de  r  =  -0,53,  sendo  para  o  grupo  considerado  de  10 
países,  o  valor  crítico  rc  =  0,  632.  Desta  forma,  para  o  conjunto  de  países  utilizados  como 
comparativo, por possuírem características semelhantes às do Brasil, a correlação entre a 
média de alunos por turma e a média em Matemática na edição de 2012  do  PISA  pode 
ser considerada significativa. 

 
  
 
 
Figura 11 - Selecionando os dados da tabela  

68 

Fonte:  O autor, 2021 

Figura  12  -  Encontrando  o  coeficiente  de  correlação  

                                              Fonte:  O autor, 2021 

 
 
 
 
 
 
ANEXO A – Valores críticos do coeficiente de correlação de Pearson 

                                                      Tabela 21 - Valores críticos para o coeficiente r de Pearson  

69 

 Fonte:  Triola apud  Ribeiro (2010, p. 91) 

 
  
 
 
 
 
ANEXO B – Evolução comparativa dos investimentos municipais com os resultados do 
Ideb 

70 

   Figura 13 - Gasto Municipal por Matricula x Resultado do Ideb Municipal 

  Fonte:  FALCÃO, 2015, p. 43  

  Figura 14 - Gasto Municipal por Matricula x Resultado do Ideb Municipal  

   Fonte:  FALCÃO, 2015, p. 44 

 
 
 
 
 
 
 
 
 
 
ANEXO  C – Resultados em Matemática no PISA por UF 

Tabela 22 - Evolução do resultado na avaliação de Matemática do     PISA 

por UF 

71 

                              Fonte: O autor, 2021 

 
  
 
 
 
 
                              
72 

Tabela 23 - Evolução do resultado na avaliação de Matemática do PISA por  UF 

Fonte: O autor, 2021 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

UFRB - Universidade Federal do Rec ˆoncavo da Bahia
CETEC - Centro de Ciˆencias Exatas e Tecnol ´ogicas
PROFMAT - Mestrado Profissional em Matem ´atica

TEOREMA CENTRAL DO LIMITE:
COMPREENDENDO E APLICANDO

JOSÉ EDUARDO COSTA ALVES

CRUZ DAS ALMAS
26 DE JULHO DE 2016

JOSÉ EDUARDO COSTA ALVES

TEOREMA CENTRAL DO LIMITE:
COMPREENDENDO E APLICANDO

Dissertação apresentada ao Programa de Mestrado
Proﬁssional em Matemática do Centro de Ciências
Exatas e Tecnológicas da Universidade Federal do
Recôncavo da Bahia e da Sociedade Brasileira de
Matemática como parte dos requisitos para a obtenção
do título de Mestre .

Orientador: Juarez dos Santos Azevedo

Cruz das Almas
26 de julho de 2016

                             FICHA CATALOGRÁFICA  Ficha elaborada pela Biblioteca Universitária de Cruz das Almas - UFRB.     A474t                             Alves, José Eduardo Costa.                                              Teorema central do limite: compreendendo e aplicando / José Eduardo Costa Alves._ Cruz das Almas, BA, 2016.                                                107f.; il.                                                 Orientador: Juarez dos Santos Azevedo.                                                 Dissertação (Mestrado) – Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas.                                                1.Matemática – Problemas, exercícios etc. 2.Matemática – Estudo e ensino. I.Universidade Federal do Recôncavo da Bahia, Centro de Ciências Exatas e Tecnológicas. I.Título.                                                                                          CDD: 510.7                   Este trabalho é dedicado a minha querida família. A minha mãe Aidyl, a minha esposa Marta e
aos meus ﬁlhos Igor e Ivan.

Agradecimentos

Quero registrar, aqui, minha gratidão a todos aqueles que fazem parte deste

momento.

Primeiramente, quero agradecer a Deus pela saúde e disposição, pelo discer-
nimento e por iluminar o meu caminho a ﬁm de vencer esta jornada árdua porém
necessária em minha vida.

Agradeço a minha mãe Aidyl pela compreensão em minhas ausências e pelo

apoio dado.

Aos meus ﬁlhos Igor e Ivan, pela paciência e compreensão nas minhas ausências.

À minha querida esposa Marta que esteve sempre ao meu lado, apoiando-me
e dando-me todo suporte necessário para concluir com exito esta etapa da minha
caminhada.

Ao meu grande orientador, Juarez Azevedo, com quem tive o privilégio de

estudar.

Ao Centro de Ciências Exatas e Tecnológicas pelo acolhimento nesses anos.

Aos professores do PROFMAT com quem tive o enorme prazer de conviver e

estudar.

Aos meus colegas da turma de 2014.1 que, ao meu lado, venceram esta jornada.

A banca examinadora pela valiosa participação e acolhimento deste trabalho.

“A distância entre o sonho e a conquista, chama-se atitude.”
(Autor Desconhecido.)

Resumo

Neste trabalho vamos abordar o Teorema Central do Limite desde o conceito mais
intuitivo até as suas deﬁnições e características mais consistentes e rigorosas. Inicial-
mente, apresentaremos os conceitos fundamentais em probabilidade como variáveis
aleatórias, esperança matemática e variância. Em seguida, teremos alguns teoremas
como o Teorema da Unicidade, o Teorema de Helly-Bray e o Teorema da Continuidade
de Paul-Levy servindo de apoio para as demonstrações dos teoremas limites inclusive
o Teorema Central do Limite de Lindeberg. Depois, exibiremos algumas situações
problemas mostrando o uso do Teorema Central do Limite na sociedade e nas ciências e,
por ﬁm, relatamos algumas propostas didáticas de aplicação de atividades em sala de
aula no Ensino Médio.

Palavras-chave: Teorema Central do Limite, distribuição normal, situações problemas.

Abstract

In this paper we report the Central Limit Theorem from the most intuitive
concept to your settings and more consistent and accurate characteristics. Initially, we
present the fundamental concepts in probability as random variables, mathematical
expectation and variance. Next, we will have some theorems as Theorem of the Oniness,
Helly-Bray Theorem and Paul-Levy Continuity Theorem serving as support for the
demonstrations of theorems boundaries including the central theorem of Lindeberg
limit. Then, we’ll show some problems situations showing the use of the central limit
theorem in society and science ﬁnally, we report some didactic activities proposed
application in the classroom in high school.

Keywords: Central Limit Theorem, normal distribution, problem situations .

Lista de ilustrações

Figura 1 – Curva normal de média µ e desvio padrão σ.
. . . . . . . . . . . . . .
Figura 2 – Curva normal padrão com µ = 0 e σ = 1. . . . . . . . . . . . . . . . . .
Figura 3 – Tabela normal padrão para z ≥ 0. Fonte: (MORETTIN, 2004).
. . . .
Figura 4 – Comparação entre o histograma de Poisson e a curva normal
. . . .
Figura 5 – Probabilidade de 1.02% de mulheres grávidas
. . . . . . . . . . . . .
. . . . . . . . . . . . . .
Figura 6 – Probabilidade de ocorrer até 6 atendimentos.
Figura 7 – Probabilidade no lance entre R$ 100 000.00 e R$ 120 000.00 . . . . . .
Figura 8 – Probabilidade de 19.08% de demorar mais que 15 minutos . . . . . .
Figura 9 – Probabilidade em se pagar menos em portes do correio que através
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figura 10 – Probabilidade de mais de 1002 elos numa corrente de 50 metros. . . .
Figura 11 – Representação gráﬁca da probabilidade de imunizados . . . . . . . .
Figura 12 – Representação gráﬁca da probabilidade do saldo médio amostral
. .
Figura 13 – Representação gráﬁca do intervalo de conﬁança numa curva normal.

do peso da caixa.

29
31
32
56
75
77
79
81

84
87
92
93
94

Sumário

INTRODUÇÃO .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

VARIÁVEIS ALEATÓRIAS, MOMENTOS CENTRAIS E DISTRI-
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
BUIÇÃO.

.

.

.

.

.

Função de densidade e de distribuição . . . . . . . . . . . . . . . . . .

Esperança matemática . . . . . . . . . . . . . . . . . . . . . . . . . . .

Momentos Centrais . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Algumas distribuições de variáveis aleatórias . . . . . . . . . . . . .

A distribuição normal

. . . . . . . . . . . . . . . . . . . . . . . . . . .

FUNÇÃO CARACTERÍSTICA E CONVERGÊNCIA EM DISTRI-
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
BUIÇÃO .

.

.

.

.

Função geradora de momentos . . . . . . . . . . . . . . . . . . . . . .

Função característica . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Convergência em distribuição . . . . . . . . . . . . . . . . . . . . . . .

16

17

20

22

25

28

33

33

38

44

TEOREMA CENTRAL DO LIMITE . . . . . . . . . . . . . . . . . . .

55

O Teorema Central do Limite para variáveis independentes e iden-
ticamente distribuídas.

. . . . . . . . . . . . . . . . . . . . . . . . . . .

O Teorema Central do Limite de Lindeberg . . . . . . . . . . . . . . .

APLICANDO O TEOREMA CENTRAL DO LIMITE . . . . . . . . .

Primeiras aplicações

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

Outras aplicações . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

57

63

73

73

82

1

2

2.1

2.2

2.3

2.4

2.5

3

3.1

3.2

3.3

4

4.1

4.2

5

5.1

5.2

6

6.1

6.2

6.3

7

8

APLICAÇÕES DO TEOREMA CENTRAL DO LIMITE NA INFE-
RÊNCIA ESTATÍSTICA. . . . . . . . . . . . . . . . . . . . . . . . . . .

Noções gerais de inferência estatística . . . . . . . . . . . . . . . . . .

Distribuição amostral . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Intervalos de conﬁança . . . . . . . . . . . . . . . . . . . . . . . . . . .

88

88

90

93

PROPOSTA DE ATIVIDADES EM SALA DE AULA . . . . . . . . .

98

CONCLUSÃO .

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104

REFERÊNCIAS .

.

.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

12

1

Introdução

A imprevisibilidade esteve presente na humanidade desde sempre, dia após dia,
era após era, sempre cercando a vida de todos. A certeza absoluta, mesmo querendo
despontar na frente, não impera na mente do ser humano, única e exclusivamente,
porque não há certeza absoluta. Como seres humanos, somos relativos, nossos atos são
relativos, o mundo que nós vivemos é relativo. Relativo no sentido de haver variáveis
externas, fora de nosso controle, que interferem no resultado de nossas ações, sejam
elas individuais ou coletivas, na tomada de decisões, até nos fenômenos naturais. Não
conseguimos prever o que vem a seguir em nossas vidas ou na sociedade, no máximo,
podemos inferir sobre um futuro de acordo com nosso interesse. Dado a essas e outras
situações descritas é que o homem, com o intuito de estar no controle, de poder decidir
ou até interferir nestes acontecimentos ditos aleatórios, desenvolveu e aperfeiçoou
outros campos matemáticos que são a estatística e a teoria das probabilidades. O que
veremos aqui neste trabalho é um elo fortemente estabelecido entre estes dois campos,
ou seja, entre a estatística e a probabilidade que é o Teorema Central do Limite. No
decorrer da introdução, vamos nos referir ao Teorema Central do Limite como TCL.

O TCL tem o termo central relacionado a palavra teorema e não a palavra limite.
No sentido etimológico, é um teorema, logo é uma proposição passível de demonstração,
é central porque tem a média e a variabilidade em torno da média como parâmetros e é
um teorema limite porque suas propriedades derivam de convergências ou aproximações.
Em termos gerais, o TCL aﬁrma que uma sucessão de n variáveis independentes e
identicamente distribuídas terá sua soma convergindo para uma distribuição normal
reduzida ou normal padrão sempre que o tamanho n for suﬁcientemente grande1 ou
estiver crescendo inﬁnitamente. Isso quer dizer que se Sn é uma sucessão de n variáveis
independentes e identicamente distribuídas com sua distribuição própria então, Sn terá
uma distribuição aproximadamente normal com média nula e variância unitária, ou

1 O termo suﬁcientemente grande é muito relativo. Na distribuição de Poisson e na exponencial, o
valor mínimo de seus parâmetros para a aplicação do TCL é para λ ≥ 5. Para distribuições amostrais,
o número n de elementos deve ser igual ou superior a 30.

Capítulo 1. Introdução

13

seja, Sn ∼ N(0, 1), através da variável normalmente reduzida Z, onde

Z = X − EX
VarX

.

Nos referimos aqui a uma sucessão de variáveis aleatórias do tipo X1

, X2

, . . . Xn.

Todas sendo partes de X pois Sn é um subconjunto de X.

Em outras palavras, variáveis aleatórias possuem distribuições especíﬁcas dentro
de um estudo ou de uma análise de acontecimentos por exemplo, a massa e a altura de
uma determinada população, geralmente, é normalmente distribuída. Calcular o tempo
de espera até a ocorrência de algum evento segue, em geral, uma distribuição geométrica
assim como a distribuição exponencial é muito utilizada na determinação do tempo
de desintegração de uma partícula radioativa. Muitas destas distribuições possuem
funções de densidades compostas por termos exponenciais ou termos combinatórios e,
em estudos envolvendo grandes quantidades de elementos populacionais ou amostrais,
como habitantes de um município ou grandes medidas de tempo, aplicar tais valores
a estes termos, tornam o uso destas funções com pouca viabilidade. Através de uma
aproximação normal, pela variável Z, não precisamos conhecer ou aplicar estas funções
de densidades, bastando apenas conhecer a média ponderada da variável aleatória em
questão. Essas características estão nas soluções das situações problemas presentes no
Capítulo 5.

Na estatística inferencial, o TCL atua no campo amostral em situações bem
especíﬁcas fazendo a distribuição amostral obedecer um comportamento muito próximo
de uma distribuição normal padrão com o intuito de promover maior conﬁabilidade nas
estimativas realizadas. Eis algumas dessas situações especíﬁcas2. Primeiramente se a
distribuição populacional é normalmente distribuída com média conhecida e variância
desconhecida, o TCL garante que a distribuição amostral terá distribuição normal padrão
com média igual a zero e variância igual a 1, denominada também de distribuição Z.
Para amostras de tamanho menor que trinta usa-se a distribuição T de Student, ou
simplesmente a distribuição T. Se a distribuição populacional não for normal ou for
desconhecida, com média e variância conhecida, o TCL aproxima a distribuição amostral
em uma distribuição normal padrão. Se a população for normalmente distribuída ou
sua distribuição for desconhecida, com sua variância também desconhecida então o
TCL garante que a distribuição amostral tenderá a uma distribuição normal padrão
através da variância amostral S. Ou seja, para variância desconhecido temos:

D−→ N(0, 1).

X − µ
S√
n

2 Vamos ﬁxar, neste pequeno relato introdutório, o tamanho das amostras como sendo maior ou igual a

trinta.

Capítulo 1. Introdução

14

Continuando na inferência estatística, se o tamanho da população for ﬁnita, o
TCL aﬁrma que quanto mais próximo o tamanho da amostra estiver do tamanho real
de uma população, mais próximos os estimadores amostrais estarão dos parâmetros
reais seguindo o comportamento da distribuição normal, ou seja, mais concentrados
em torno da média real os valores amostrais estarão e menor será a variabilidade
destes valores. Com isso, quanto mais próximo da média real o valor estiver, maior é a
probabilidade de ocorrência e quando um valor amostral estiver mais distante da média
real, menor é a probabilidade de ocorrência deste valor. Para população de tamanho
inﬁnito, o TCL age da mesma maneira, ou seja, quanto maior a dimensão da amostra
maior é a probabilidade de que a média amostral esteja bem próxima da média real e,
consequentemente, a amplitude de variação dos valores dessa média amostral tende a
diminuir.

O trabalho apresentado aqui tem como característica um enfoque básico do
TCL porém este enfoque não é estritamente teórico, ou seja, não envolve abordagens
históricas, nem apresentação dos conceitos em livros textos ou então sobre uma aplicação
especíﬁca do TCL. Possui sim muita apresentação não textual como gráﬁcos e fórmulas
matemáticas nos teoremas e demonstrações já que é voltado para um público bem
especíﬁco composto por estudantes de graduação ou graduados em área aﬁns e
professores licenciados em matemática.

Como dito acima, não houve uma fundamentação teórica baseada em relatos
históricos, no entanto, podemos encontrar em (FISCHER, 2011) uma abordagem histórica
sucinta do desenvolvimento do TCL, em (HALD, 2004) um desenvolvimento histórico
da inferência estatística de Bernoulli a Fischer e, em (BELLHOUSE, 2007), uma biograﬁa
de Abraham DeMoivre, o precursor de tudo que foi abordado neste estudo.

A estrutura deste trabalho dar-se-à em forma de capítulos. Cada um dos
capítulos contribui para a totalidade da obra de uma forma bem particular, ou seja,
mesmo contendo abordagens distintas todos são indispensáveis uma vez que atendem
a proposta de fazer o leitor compreender e conhecer as aplicações do Teorema Central
do Limite. O Capítulo 2 aborda sobre os termos e notações utilizadas nos outros
capítulos tais como a deﬁnição e os tipos de variáveis aleatórias, as relações e diferenças
entre a função de distribuição e a função de densidade, a média e a variância de uma
variável aleatória e as funções de distribuições utilizadas nos exemplos de aplicações,
em especial para a distribuição normal e a sua curva normal. O Capítulo 3 relata
acerca das funções características e da convergência em distribuição. Este capítulo é
constituído por deﬁnições, teoremas e suas demonstrações com o intuito de dar suporte
para o Capítulo 4 que apresenta formalmente o Teorema Central do Limite em três
versões: o teorema limite para variáveis aleatórias independentes e identicamente
distribuídas com sua versão inicial proposta por DeMoivre e Laplace e o teorema limite

Capítulo 1. Introdução

15

para variáveis independentes não identicamente distribuídas que é o Teorema Central
do Limite de Lindeberg. Estes três capítulos nos fornecem conﬁabilidade e segurança
para o desenvolvimento do trabalho.

Os três capítulos seguintes estão encarregados de apresentar as aplicações do TCL.
O Capítulo 5 faz comparações entre a probabilidade através da função de densidade
da variável e através da aproximação normal exempliﬁcando toda a apresentação
do Capítulo 5. O Capítulo 6 leva o TCL para o campo da inferência estatística mais
precisamente para as estimativas pontuais e intervalares, apresentando também algumas
noções básicas de inferência, distribuição amostral e intervalo de conﬁança para um
melhor entendimento por parte dos leitores. O sexto capítulo conduz o TCL para a
educação básica, mais especiﬁcamente para professores e alunos do Ensino Médio
apresentando propostas de atividades em sala de aula, onde podemos introduzir o
conceito do TCL em situações bastante práticas para os alunos. A conclusão ﬁnaliza este
trabalho relatando de forma objetiva uma síntese de tudo que foi exibido nos capítulos
anteriores. Faz recomendações de outra proposta de aplicação que é a tábua de Galton,
ratiﬁcando assim toda a importância que o Teorema Central do Limite possui, tanto na
teoria das probabilidades quanto na própria matemática como um todo.

16

2

Variáveis aleatórias, momentos centrais
e distribuição.

Quando estudamos fenômenos aleatórios, ou seja, episódios com pouca ou
nenhuma chance de previsibilidade, aplicamos métodos estatísticos e probabilísticos na
intenção de quantiﬁcar dados que, muitas vezes, não são representados numericamente.
Esses dados são reconhecidos como variáveis e a quantiﬁcação dessas variáveis podem
ser realizadas por meio de funções. As variáveis são classiﬁcadas como qualitativas ou
quantitativas. Neste trabalho, vamos utilizar apenas variáveis quantitativas 1.

Deﬁnição 2.1 Seja (Ω, A, P) um espaço de probabilidades. Uma função real X: Ω → R é
chamada de variável aleatória se, deﬁnida no espaço amostral Ω para todo ω ∈ Ω, associar um
único elemento real X(ω), isto é, ω ↦→ X(ω).

Exemplo 2.1 Dentro de uma urna há duas bolas brancas e duas vermelhas. Ao extrairmos duas
bolas quaisquer, sem reposição, e observarmos a sua cor, temos que o espaço amostral Ω será
deﬁnido como:

Ω = {(B, B); (B, V); (V, B); (V, V)},

onde B = bola branca e V = bola vermelha.

Seja X a variável aleatória deﬁnida como o número de vezes que a bola de cor branca
= 2. Para ω
2
= 0. Com isso,

aparece nas duas bolas retiradas da urna. Assim para ω
= (B, V) e ω
= (V, B) temos que X2
obtemos o conjunto X tal que X = {0, 1, 2}.

= (V, V) temos que X3

= (B, B) temos que X1

= 1 e, para ω

3

4

1

Exemplo 2.2 No evento medir a vida útil de um carro, em anos, uma possibilidade para o espaço
amostral (Ω) seria de todos os números reais não negativos, isto é, Ω = [0, ∞). Sendo X a
variável aleatória deﬁnida como o número de anos de vida útil do carro, temos que X assume
valores reais não negativos dentro do conjunto Ω.

1 As variáveis qualitativas podem ser nominais ou ordinais e as deixamos de fora pois não podemos

atribuir valores numéricos.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

17

No Exemplo 2.1, a variável aleatória em questão assume apenas valores inteiros,
com um número deﬁnido de possíveis ocorrências. Estas características descrevem uma
variável aleatória discreta. No Exemplo 2.2, a variável assume valores inteiros e não
inteiros com um número inﬁnito de ocorrências. Temos, então, uma variável aleatória
contínua. Se observarmos a Deﬁnição 2.1, para a variável aleatória discreta temos o
contradomínio da função X como um conjunto ﬁnito ou inﬁnito enumerável de valores
reais. Para a variável aleatória contínua, temos o contradomínio da função X como um
conjunto inﬁnito não enumerável ou intervalos de números reais.

2.1 Função de densidade e de distribuição

Nesta seção, vamos entender o que é uma função de densidade e o que é uma
função de distribuição, ambas aplicadas a variáveis discretas ou contínuas. Uma função
de densidade associa a cada valor atribuído pela variável aleatória a probabilidade do
evento correspondente. Notemos pela seguinte deﬁnição,

Deﬁnição 2.2 Seja X uma variável aleatória discreta. Uma função real f é dita função discreta
de densidade de X se f (a) = P(X = a), para algum a real. Caso f (a) > 0, podemos aﬁrmar que a
é um possível valor da variável X.

Observaremos agora três propriedades de uma função discreta de densidade X.

Propriedade 2.1 Para um x real, f (x) ≥ 0.

Prova : Pela Deﬁnição 2.2 f (x) = P(X = x). Como característica, 0 ≤ P(X = x) ≤ 1

então f (x) ≥ 0.

(cid:4)

Propriedade 2.2 Se um subconjunto deﬁnido por {x| f (x) (cid:44) 0} for ﬁnito ou inﬁnito enumerável
dentro do contradomínio R então este subconjunto será representado por {x1

, · · · }.

, x2

Prova : Pela Propriedade 2.1, f (x) ≥ 0. Logo, f (x) = 0 ou f (x) > 0. Para f (x) > 0,
, · · · }

a Deﬁnição 2.2 aﬁrma que x é um possível valor de X. Portanto, o conjunto {x1
existe e representa o subconjunto {x| f (x) (cid:44) 0}.

, x2

Propriedade 2.3 Seja {xi} um subconjunto real com i = 1, 2, · · · . Se f (xi) > 0 então
∑︀

i f (xi) = 1.

(cid:4)

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

18

Prova : Para todos os valores possíveis de i, os f (xi) são distintos entre si. Assim,
a soma f (x1) + f (x2) + · · · compõe todo o espaço amostral em questão. Como a soma
das probabilidades é a probabilidade da soma,

∑︁

i

f (xi) =

∑︁

i

P(X = xi) = P

⎜⎜⎜⎜⎝

i

⎛
∑︁

⎞
⎟⎟⎟⎟⎠
(X = xi)

= P

⎛
⋃︁

⎜⎜⎜⎜⎝

i

⎞
⎟⎟⎟⎟⎠
{X = xi}

= P(Ω) = 1,

pois a união de todos os possíveis eventos forma todo o espaço amostral e a

probabilidade de ocorrência de todo o espaço amostral é igual a 1. Portanto,

∑︁

i

f (xi) = 1.

(cid:4)

Se uma função real f goza das Propriedades 2.1, 2.2 e 2.3 então, podemos aﬁrmar

que f é uma função de densidade discreta.

Uma função de densidade contínua é também denominada de função densidade
em relação a integração. Isso porque, para realizarmos uma soma dentro de um intervalo
real não enumerável, utilizamos o cálculo integral. Em relação a Deﬁnição 2.2, aﬁrmando
que f (a) = P(X = a), se a variável X for contínua, então f (a) = 0. Notemos que, dado
(cid:15) > 0,

f (a) = P(X = a) ≤ P(a − (cid:15) < X ≤ a) = P(X ≤ a) − P(X ≤ a − (cid:15)).

Para (cid:15) muito próximo de zero temos:

P(X ≤ a − (cid:15)) = P(X ≤ a).

lim
(cid:15)→0

Logo,

lim
(cid:15)→0

[P(X ≤ a) − P(X ≤ a − (cid:15))] = lim
(cid:15)→0
= lim
(cid:15)→0
= 0.

P(X ≤ a) − lim
(cid:15)→0
P(X ≤ a) − lim
(cid:15)→0

P(X ≤ a − (cid:15))
P(X ≤ a)

Assim, para X contínua, P(X = a) = 0. Ou seja, a probabilidade de uma variável aleatória
contínua assumir um determinado valor a é igual a zero. Podemos, com isso, concluir
que a função contínua de densidade não trabalha com valores pontuais e sim com
intervalos reais não enumeráveis. A Propriedade 2.3 pode, então, ser expressa como

∫︁ ∞

−∞

f (x)dx = 1.

(1)

A função de distribuição, denotada por F, nos dá uma maneira de descrever
como as probabilidades são associadas aos valores ou aos intervalos de valores de

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

19

uma variável aleatória. A probabilidade P, em função da variável X, deﬁnida por
PX(IR) = P(X ∈ IR), onde IR é um intervalo real qualquer, é denominada de distribuição
de X. Com isso, temos que

F(X) = P(X ≤ x),

−∞ < x < ∞.

Eis a deﬁnição de uma função de distribuição.

Deﬁnição 2.3 Qualquer que seja uma função real F, um elemento x do domínio de F e F(x+)
a imagem de F quando os valores do domínio de F tendem a x pela direita com as seguintes
propriedades:

(i) ∀x, 0 ≤ F(x) ≤ 1.

(ii) F é uma função não decrescente de x.

(iii) F(−∞) = 0 e F(+∞) = 1.

(iv) F(x+) = F(x) para todo x.

F é uma função de distribuição se satisfaz as quatro propriedades acima.

Se a variável X estiver entre dois valores reais teremos

P(a < X ≤ b) = P(X ≤ b) − P(X ≤ a) = F(b) − F(a),

∀a, b ∈ R.

(2)

A variável aleatória sendo discreta ou contínua, podemos representar sua função
de distribuição através de sua função densidade. Esta relação está na proposição
seguinte e sua demonstração encontra-se em (JAMES, 2010).

Proposição 2.1 Seja X uma variável aleatória e f(x) sua função de densidade.

(i) Se X for discreta com valores em {x1

, x2

, · · · } temos que

F(X) = PX(IR) =

∑︁

i;xi∈IR

P(X = xi) =

∑︁

i;xi∈IR

f (xi),

onde qualquer IR é ﬁnito ou inﬁnito enumerável.

(ii) Se X for contínua temos que

F(X) = PX(IR) =

∫︁

IR

f (x)dx,

onde qualquer IR é inﬁnito não enumerável.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

20

O item (ii) da Proposição 2.1 estabelece uma importante relação entre a função

de distribuição e a função densidade

F(X) =

∫︁

IR

′
f (x)dx ⇐⇒ F

(x) = f (x)

ou, de outra maneira,

dF(x)
dx

= f (x) ⇐⇒ dF(x) = f (x)dx.

(3)

Ainda pelo item (ii) da Proposição 2.1, podemos reescrever a relação expressa

pela igualdade (2) da seguinte maneira,

P(a < X ≤ b) =

∫︁ b

a

f (x)dx = F(b) − F(a),

∀a, b ∈ R.

Podemos perceber que, independentemente da situação da variável aleatória, a
função de distribuição comporta-se semelhantemente, tanto através da probabilidade
quanto pela integração.

2.2 Esperança matemática

Esta seção apresenta uma formalização para o conceito de esperança matemática.
A esperança matemática ou valor esperado da variável X é representada por EX ou µX e
refere-se a média ponderada dos possíveis valores de X. Quando sabemos que X é a
variável em questão, utilizamos apenas µ ao invés de µX. Encontrar a média de uma
variável aleatória é uma forma de tentar reduzir a distribuição de probabilidade a um
único número que suponhamos representar o valor típico de X.

A deﬁnição geral de esperança matemática passa primeiro por um teorema no

qual veremos agora.

Teorema 2.1 Seja X uma variável aleatória. Uma aproximação para X será deﬁnida como X(cid:15)
tal que

X(cid:15) = (cid:15)k

se

(cid:15)k ≤ X < (cid:15)(k + 1)

k ∈ Z.

Se, para algum (cid:15) > 0, X(cid:15) tem esperança ﬁnita então X(cid:15) tem esperança ﬁnita para todo (cid:15) > 0 e

lim(cid:15)→∞

EX(cid:15)

(4)

existe e é ﬁnito.

A partir do Teorema 2.1, temos a seguinte deﬁnição.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

21

Deﬁnição 2.4 X é uma variável aleatória e X(cid:15) é uma aproximação de X apresentada no Teorema
2.1 com (cid:15) > 0. Se, para algum (cid:15) > 0, X(cid:15) tem esperança ﬁnita então a variável X possui esperança
ﬁnita que será denotada por

EX = lim(cid:15)→∞

EX(cid:15).

Para maiores esclarecimentos sobre a deﬁnição geral de esperança consultar o

Capítulo 7 em (HOEL, 1978).

Para o caso da variável ser discreta, temos a seguinte deﬁnição.

Deﬁnição 2.5 Seja X uma variável aleatória discreta qualquer, que assume um número ﬁnito
, . . . , xr. O valor esperado ou a esperança de X, é o número
de valores x1

, x2

Para

EX =

∞∑︁

i=1

xi f (xi).

∞∑︁

i=1

|xi| f (xi) < ∞,

(5)

temos que X possui esperança ﬁnita e deﬁnimos sua esperança através da igualdade (5).

No caso da variável ser contínua, temos a seguinte deﬁnição.

Deﬁnição 2.6 Seja X uma variável aleatória contínua qualquer, que assume um número inﬁnito
de valores reais não enumeráveis ou dentro de um intervalo real. O valor esperado ou a esperança
de X, é o número:

∫︁ ∞

EX =

x f (x)dx

−∞

(6)

A esperança de uma variável contínua apresentada na igualdade (6) pode ser

reescrita como:

EX =

∫︁ ∞

−∞

xdF(x).

(7)

A integral apresentada na igualdade (7) é conhecida como a Integral de Riemann-

Stieltjes.

O teorema seguinte é uma importante propriedade de esperança matemática,
referindo-se ao fato que a soma de variáveis discretas com esperança ﬁnita também é
ﬁnita. Para o caso de variáveis contínuas, o procedimento é bem semelhante porém
utilizamos a integral contida na igualdade (7) ao invés da representação por somatórios.

Teorema 2.2 Sejam X e Y duas variáveis aleatórias tendo esperanças ﬁnitas.Sendo assim, X +
Y tem esperança ﬁnita e E(X + Y) = EX + EY.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

22

Demonstração : Fazendo W = X + Y e g, uma função de densidade em função
de W onde g(w) = g(x, y) = x + y. Com isso, temos que g é uma função de densidade
conjunta das variáveis X e Y. Vamos utilizar a desigualdade triangular |x + y| ≤ |x| + |y|.

E|W| =

=

=

=

=

=

∑︁

x,y
∑︁

|g(w)| f (x, y) =

∑︁

x,y

|g(x, y)| f (x, y)

∑︁

|x + y| f (x, y)

x
∑︁

y
∑︁

x
∑︁

y
∑︁

|x + y| f (x, y) ≤

∑︁

∑︁

(|x| + |y|) f (x, y)

|x| f (x, y) +

x
∑︁

∑︁

y

|y| f (x, y)

∑︁

y

f (x, y) +

x
∑︁

y

|y|

∑︁

y

x

f (x, y)

x
∑︁

y

|x|

x
∑︁

|x| fX(x) +

∑︁

|y| fY(y)

x

y
= E|X| + E|Y| < ∞

pois, por hipótese, as variáveis X e Y possuem esperança ﬁnita. Com isso, E|W| < ∞,
isto é, a variável W possui esperança ﬁnita.

(cid:4)

2.3 Momentos Centrais

Nesta seção, vamos discorrer acerca de momentos centrais de uma variável
aleatória discreta. Estar escrevendo sobre momentos é de fundamental importância pois
estamos introduzindo a idéia e posterior deﬁnição de variância e desvio padrão que é
uma medida estatística muito relevante para a utilização do Teorema Central do Limite.
Os momentos podem nos dar informações parciais sobre uma determinada medida de
probabilidade de uma variável aleatória. Os momentos principais apresentados nesta
seção serão os momentos de primeira e de segunda ordem.

Os momentos da variável X podem ser deﬁnidos pelas esperanças de potências

de X. Vejamos a deﬁnição descrita a seguir.

Deﬁnição 2.7 Seja X uma variável aleatória discreta e seja r ≥ 0 um número inteiro. Dizemos
que X tem um momento de ordem r se Xr tem esperança ﬁnita. Neste caso deﬁnimos o r-ésimo
momento de X como EXr.

Pela Deﬁnição 2.5, podemos determinar o r-ésimo momento através da função

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

de densidade f contida na igualdade abaixo

EXr =

∑︁

x

xr f (x).

23

(8)

Teorema 2.3 Se o r-ésimo momento de uma variável aleatória existir, então todos os momentos
de ordem menores do que r também existem.

Demonstração : Por deﬁnição, r ≥ 0. Seja k ≥ 0 um número inteiro com k ≤ r.
Por deﬁnição de potência, se |x| ≤ 1 então |xk| = |x|k e |x|r ≤ |x|k ≤ 1. Por outro lado, se
|x| > 1, teremos |xk| = |x|k ≤ |x|r. Para os dois casos, podemos aﬁrmar que |x|k ≤ |x|r + 1.

Como |x|k ≤ |x|r + 1, temos que E(|x|k) ≤ E(|x|r + 1). Vamos mostrar que |x|k tem

esperança ﬁnita. Para isso, precisamos mostrar que E(|x|k) < ∞.

E(|x|k) ≤ E(|x|r + 1) =

∑︁

x

|xr + 1| f (x) ≤

∑︁

x

|xr| f (x) +

∑︁

x

f (x).

Por hipótese, E|x|r < ∞ e

∑︀

∑︁

x

|xr| f (x) +

x 1 f (x) = P(X = x) = 1. Sendo assim,
∑︁

∑︁

1 f (x) ≤

|xr| f (x) + 1 < ∞.

x

x

Concluímos, então, que todos os momentos de ordem k, menores do que r,

também existem.

(cid:4)

Deﬁnição 2.8 Seja X uma variável aleatória, com média aritmética µ = E(X) e r ≥ 0 um
número inteiro. Dizemos que X − µ tem um momento de ordem r se (X − µ)r tem esperança ﬁnita.
Neste caso, deﬁnimos o r-ésimo momento de X − µ como E(X − µ)r. Sendo assim, denominamos
(X − µ)r como o r-ésimo momento central de X, já que é o r-ésimo momento em torno da média.

Pela igualdade (8), podemos determinar o r-ésimo momento central através da função
de densidade f, onde

E(X − µ)r =

(x − µ)r f (x).

(9)

∑︁

x
De agora até o ﬁnal desta seção, vamos utilizar a notação EX ao invés de µ. Assim,
escreveremos (X − µ)r como (X − EX)r e, atribuiremos a r os valores 1 e 2.

Fazendo r = 1, no primeiro membro da igualdade (8) temos que

Isto signiﬁca que o primeiro momento de X é a sua média ponderada µ.

EXr = EX1 = EX.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

24

Fazendo r = 1, no primeiro membro da igualdade (9) temos

E(X − EX)r = E(X − EX) = EX − E(EX) = EX − EX = 0.

Podemos perceber que o primeiro momento central de X é igual a zero, ou seja, µ = 0.

Ao atribuirmos r = 2 ao primeiro membro da igualdade (8) , vamos obter
EX2. Este segundo momento de X será denominado de variância pois E(X) = 0 e
representamos por VarX ou também por σ2. Para os capítulos seguintes, vamos utilizar
o segundo momento central ao invés apenas do segundo momento. Com isso, a partir
da igualdade (9), temos

E(X − EX)2 = E[(X)2 − 2XEX + (EX)2]
= E(X)2 − 2EXEX + (EX)2
= E(X)2 − 2(EX)2 + (EX)2
= E(X)2 − (EX)2.

Podemos então escrever a variância de X como

VarX = E(X)2 − (EX)2.

(10)

Consequentemente, temos que apresentar outra medida que surge a partir do
segundo momento que é o desvio padrão. Ao representarmos a variância por σ2
podemos obter o desvio padrão da seguinte maneira,

√

VarX.

σ =

(11)

Ou seja, o desvio padrão σ é a raiz quadrada da variância.

A seguir, temos algumas propriedades, muito uteis, para os capítulos seguintes.

Teorema 2.4 Seja X uma variável aleatória com esperança ﬁnita.

(i) VarX ≥ 0

(ii) Se c é uma constante e X = c então VarX = 0.

(iii) Var(aX) = a2VarX, onde a é uma constante real.

(iv) Se X e Y são variáveis aleatórias mutuamente independentes, então Var(X + Y) =

VarX + VarY.

Demonstração :

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

25

(i) Por deﬁnição, VarX = E(X − EX)2 como todo quadrado é sempre positivo então

VarX ≥ 0.

(ii) Como Ec = c, para todo c constante, se X = c então

Var(c) = E(c − Ec)2 = E(c − c)2 = E02 = E0 = 0.

(iii) Seja Z’ uma variável aleatória tal que Z′ = aX. Se para uma constante a temos

E(aX) = aE(X) então

Var(aX) = VarZ

′ = E(Z

′

)2

′ − EZ
= E(aX − E(aX))2
= E(aX − aEX)2
= E(a(X − EX))2
= E(a2(X − EX)2)
= a2E(X − EX)2
= a2VarX.

(iv) Seja W uma variável aleatória tal que W = X + Y. Vamos utilizar a fórmula

VarX = EX2 − (EX)2.

Var(X + Y) = VarW = EW2 − (EW)2

= E(X + Y)2 − [E(X + Y)]2
= E(X2 + 2XY + Y2) − (EX + EY)2
= E(X2 + 2XY + Y2) − [(EX)2 + 2EXEY + (EY)2]
= EX2 + E2XEY + EY2 − (EX)2 − 2EXEY − (EY)2
= EX2 − (EX)2 + EY2 − (EY)2 + 2EXEY − 2EXEY
= EX2 − (EX)2 + EY2 − (EY)2
= VarX + VarY.

(cid:4)

Finalizando esta etapa, podemos entender porque a variância e o desvio padrão
são medidas estatísticas de dispersão. Vejamos, pela igualdade (10), que eles representam
a diferença em torno da média que é uma medida central. Na seção 2.5, com a
apresentação da curva normal, esta observação torna-se mais clara e coerente.

2.4 Algumas distribuições de variáveis aleatórias

Vamos abordar, nesta seção, três distribuições de variáveis aleatórias discretas
que é a distribuição uniforme discreta, a binomial e a distribuição de Poisson e duas

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

26

distribuições de variáveis aleatórias contínuas que são a distribuição uniforme contínua
e a distribuição exponencial. Basicamente, iremos expor suas funções de distribuição, a
média e a variância de cada uma delas. Deixamos a distribuição normal para o próximo
capítulo, sua importância é crucial para o desenvolvimento dos capítulos destinados a
aplicações práticas do Teorema Central do Limite. As demonstrações das proposições
apresentadas nesta seção que vão da Proposição 2.2 até a Proposição 2.6 encontram-se
em (NATARIO, 2012).

1. Distribuição uniforme discreta. Uma variável aleatória X possui distribuição

uniformemente discreta se a sua função de densidade é da forma

f (x) = 1
x

x = 1, 2, · · · , n.

A distribuição uniforme discreta possui apenas o parâmetro n que signiﬁca o

para cada tentativa, isto é, todas
número de tentativas com a probabilidade de
as tentativas possuem a mesma probabilidade de ocorrência. Se X segue uma
distribuição uniforme discreta, representamos por X ∼ U(n).

1
n

Proposição 2.2 Seja X uma variável aleatória com distribuição uniformemente discreta
de parâmetro n. Então:
(i) EX = n + 1
.
2
(ii) VarX = n2 − 1
12
1
n

(iii) F(x) = ∑︀x
i=1

.

.

2. Distribuição binomial. Uma variável aleatória X possui distribuição binomial se

a sua função de densidade é da forma

f (x) =

(︃

)︃
n
x

px(1 − p)n−x

x = 0, 1, 2, · · · , n.

Os parâmetros de uma distribuição binomial são os números de tentativas inde-
pendentes representada por n e a probabilidade p de sucesso em cada uma dessas
tentativas. Importante destacar que o complementar de p é 1 − p, que signiﬁca a
probabilidade de ocorrência de falha ou fracasso numa tentativa. Se X segue uma
distribuição binomial representamos por X ∼ Bin(n, p).

Proposição 2.3 Seja X uma variável aleatória com distribuição binomial de parâmetros n
e p. Então:

(i) EX = np.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

27

(ii) VarX = np(1-p).
(iii) F(x) = ∑︀x
i=0

)︀
(︀n
x

px(1 − p)n−x.

3. Distribuição de Poisson. Uma variável aleatória X possui distribuição de Poisson

se a sua função de densidade é da forma

f (x) = e

−λ λx
x!

x = 0, 1, 2, · · ·

A distribuição de Poisson possui apenas o parâmetro λ que indica a taxa de
ocorrência por unidade medida. Por exemplo, λ é o número de ligações numa
central telefônica ou o número de atendimentos numa agencia bancária. Se X
segue uma distribuição de Poisson, representamos por X ∼ Poisson(λ).

Proposição 2.4 Seja X uma variável aleatória com distribuição de Poisson de parâmetro
λ. Então:

(i) EX = λ.

(ii) VarX = λ.
(iii) F(x) = ∑︀x
i=0

e−λλi
i!

.

4. Distribuição uniforme contínua. Uma variável aleatória X possui distribuição
uniformemente contínua no intervalo [a, b] se a sua função de densidade é da
forma

f (x) =

1
b − a

⎧
⎪⎪⎪⎨
⎪⎪⎪⎩

, se a ≤ x ≤ b
0, se para outros valores de x.

Os parâmetros de uma distribuição uniformemente contínua são as extremidades
do intervalo onde a variável aleatória está contida, ou seja, os valores de a e b em
[a, b] onde −∞ < a ≤ X < b < ∞. Muito utilizado em programação já que grande
parte das linguagens de programação ou planilhas de cálculo possuem um gerador
de números aleatórios, que gera a partir de uma distribuição uniforme, com
valores entre 0 e 1. Logo, se X segue uma distribuição uniformemente contínua,
representamos por X ∼ U[a, b].

Proposição 2.5 Seja X uma variável aleatória com distribuição uniforme contínua de
parâmetros a e b. Então:
(i) EX = a + b
2
(ii) VarX = (b − a)2

.

.

12

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

28

⎧

⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩

0,
x − a
,
b − a
1,

se x < a
se a ≤ x < b.
se x ≥ b

(iii) F(x) =

.

5. Distribuição exponencial. Uma variável aleatória X possui distribuição exponen-

cial se a sua função de densidade é da forma

f (x) =

⎧
⎪⎪⎨
⎪⎪⎩

λe−λx, se x > 0,
0, se x ≤ 0.

λ > 0

A distribuição exponencial possui apenas o parâmetro λ. Este tipo de distribuição
serve de modelo para estudo de tempo de espera, tais como o tempo até a falha
de um equipamento ou tempo necessário para completar uma tarefa. Neste
caso, λ é o parâmetro de taxa de tempo como, por exemplo, o tempo médio
de vida, enquanto que o x é o tempo de falha. Importante salientar que λ e x
devem compartilhar da mesma unidade de medida. Se X segue uma distribuição
exponencial, representamos por X ∼ Exp(λ).

Proposição 2.6 Seja X uma variável aleatória, distribuída exponencialmente, de parâme-
tro λ. Então:
(i) EX = 1
λ .
(ii) VarX = 1
λ2 .
⎧
⎪⎪⎨
⎪⎪⎩

se x < 0
se x ≥ 0.

0,
1 − e−λx,

(iii) F(x) =

2.5 A distribuição normal

A distribuição normal tem todo o mérito em ter uma seção dedicada exclusiva-
mente ao seu estudo. Isso deve-se a grande relevância que ela tem na probabilidade e
na estatística inferencial. Vamos observar esta importância nos capítulos que discorrem
sobre as aplicações do Teorema Central do Limite. Esta é a última seção deste capítulo e
faremos uma breve exposição sobre a distribuição normal, seus parâmetros, sua forma
reduzida, a curva normal com suas propriedades e a tabela z. Para mais detalhes, vide
(PINHEIRO, 2009).

Uma variável aleatória X é uma variável aleatória normalmente distribuída, se a

função densidade de X for dada por:

f (x) =

−(x−µ)2
2σ2

e

1
√
2π

σ

x ∈ R, µ ∈ R e σ > 0.

(12)

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

29

A distribuição normal possui dois parâmetros que são µ e σ2. Vimos, na Seção 2.2
e 2.3 que µ representa a esperança ou valor esperado de uma variável e σ2 a sua variância.
Muitas variáveis aleatórias seguem uma distribuição normal porém, o interessante é que
outras distribuições derivam dela tais como a distribuição qui-quadrado, a lognormal e
a de Cauchy2. Outras distribuições não normais podem se tornar aproximadamente
normais a medida que o valor do parâmetro torna-se suﬁcientemente grande. Esta
aproximação se deve ao Teorema Central do Limite, no Capítulo 5. Se X segue uma
distribuição normal, representamos por X ∼ N(µ, σ2).

Proposição 2.7 Seja X uma variável aleatória, normalmente distribuída, de parâmetro µ e σ2 .
Então:

(i) EX = µ.

(ii) VarX = σ2.

A demonstração da Proposição 2.7 encontra-se em (NATARIO, 2012).

A Figura 1, a seguir, representa graﬁcamente a função de densidade normal.

Figura 1 – Curva normal de média µ e desvio padrão σ.

Vejamos algumas características desta curva.

(1) A média, a mediana e a moda numa distribuição normal são iguais.

(2) A curva normal tem o formato de um sino e seu eixo de simetria é paralelo ao eixo

das ordenadas e se localiza no valor da média.

(3) Quando a curva normal começa a se afastar da média (eixo de simetria), ela se
aproxima cada vez mais do eixo das abscissas porém, a curva nunca o tocará
(característica de função exponencial). Com isso dizemos que o eixo das abscissas
é assintota da função.

2 Consultar (FARIAS, 2009) para a qui-quadrado e lognormal e (GARCIA, 2008) para distribuição de

Cauchy.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

30

(4) No gráﬁco, os pontos µ − σ e µ + σ são pontos de inﬂexão da curva normal já que
da esquerda até µ − σ e de µ + σ para a direita a curva tem concavidade voltada
para cima enquanto que entre µ − σ e µ + σ a curva tem concavidade voltada para
baixo.

(5) A área sob a curva normal determina a probabilidade de ocorrência do evento em
questão. A área total sob a curva sendo igual a 1 quer dizer que a probabilidade
de ocorrência é de 100%. Entre os pontos simétricos no eixo das abscissas temos o
seguinte:

– Se a área da curva está entre µ − σ e µ + σ, a probabilidade é igual a 68.26%.
– Se a área da curva está entre µ − 2σ e µ + 2σ, a probabilidade é igual a 95.44%.
– Se a área da curva está entre µ − 3σ e µ + 3σ, a probabilidade é igual a 99.73%.
– Se a área da curva está entre µ − 4σ e µ + 4σ, a probabilidade é igual a 99.994%.

A igualdade (12) é a função de uma variável aleatória com distribuição normal.

Fazendo uma substituição do tipo:

temos

1
√
2π

σ

∫︁ ∞

−∞

Ou seja,

z = x − µ

σ

,

−(x − µ)2
2σ2

e

dx =

1
√
2π

σ

∫︁ ∞

e

−∞

−1
2

2

x − µ
σ

⎞

⎟⎟⎟⎟⎟⎠

⎛

⎜⎜⎜⎜⎜⎝

dx = 1√
2π

−z2
2 dz.

e

∫︁ ∞

−∞

−z2
2 .

g(z) = 1√
2π

e

(13)

(14)

Ao compararmos as Funções (12) e (14) podemos observar que g(z) possui todas
as características de uma função com distribuição normal porém esta aﬁrmação só é
válida se µ = 0 e σ2 = 1. Com isso, temos uma variável aleatória Z, normalmente
distribuída, com uma média ﬁxada em zero e um desvio padrão unitário, isto é,
Z ∼ N(0, 1). A Função (14) é denominada de função com distribuição normal padrão
ou normal reduzida de abscissa z.

O gráﬁco de uma função com distribuição normal reduzida tem o mesmo
comportamento e características que o gráﬁco da curva normal de parâmetros µ e σ,
como podemos observar pela Figura 2.

A tabela z, apresentada na Figura 3, nos fornece a probabilidade de Z ≤ z que
nada mais é que a área sob a curva normal de acordo com os valores de z ≥ 0. Para
valores negativos de z, podemos utilizar as duas igualdades abaixo que são originárias
a partir da propriedade de simetria da curva normal em relação a média.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

31

Figura 2 – Curva normal padrão com µ = 0 e σ = 1.

(cid:111) P(Z ≤ −z) = 0.5 − P(Z ≤ z).

As provas do Teorema Central do Limite necessitam de outros conceitos para
o seu desenvolvimento. O conceito de convergência em distribuição e de funções
características tem teoremas que o regem. No Capítulo 3, estes teoremas serão enunciados
e demonstrados com o rigor que eles merecem.

Capítulo 2. Variáveis aleatórias, momentos centrais e distribuição.

32

Figura 3 – Tabela normal padrão para z ≥ 0. Fonte: (MORETTIN, 2004).

33

3

Função característica e convergência em
distribuição

No Capítulo 2, abordamos sobre a esperança e a variância de variáveis aleatórias
com suas deﬁnições e propriedades muito bem deﬁnidas. Também vimos que se tratam
de momentos de primeira e de segunda ordem respectivamente, isto é, para uma
variável X, se a esperança existe então o primeiro e o segundo momento de X são
representados por E(X) e E(X)2. Veriﬁcamos, também, onde estes momentos assumem
papel fundamental dentro da estatística e probabilidade sendo esta na distribuição
normal, um tipo de distribuição que abrange muitos fenômenos, dentre eles, fenômenos
biológicos e sociais. Com isso, podemos apresentar um conceito muito importante para
determinar distribuições de probabilidades de variáveis aleatórias, já que estas funções
de distribuição muitas vezes, podem ser expressas através de seus momentos. Estamos
falando de função geradora de momentos1, a primeira parte do desenvolvimento deste
capítulo. Em seguida, trataremos das funções características onde precisaremos enunciar
e provar o Teorema da Unicidade e, por ﬁm, sobre convergência em distribuição, onde
será apresentado o Teorema da Continuidade de Levy fechando assim todo o aparato
necessário para o sucesso no desenvolvimento do capítulo seguinte que trata-se do
Teorema Central do Limite.

3.1 Função geradora de momentos

Muitos autores pesquisados não dão uma importância muito signiﬁcativa para
a função geradora de momentos devido ao fato que, em algumas distribuições, como
por exemplo, a distribuição de Cauchy, ela não existe, isto é, não converge para um
valor ﬁnito, fazendo-se necessário garantir primeiro sua existência. Veriﬁcamos que
é necessário apresentar o conceito de função geradora de momentos pois dá suporte
para os conceitos de função característica e pela sua importância na prova do Teorema
Central do Limite de DeMoivre e Laplace.

1

Para mais esclarecimentos, vide (MEYER, 1970).

Capítulo 3. Função característica e convergência em distribuição

34

A deﬁnição seguinte apresenta a função geradora de momentos para o caso

discreto e o caso contínuo.

Deﬁnição 3.1 Seja X uma variável aleatória com função de distribuição p(xj) para j = 1, 2, 3, · · ·
no caso discreto, ou função de densidade h(x) no caso contínuo. Representando a função geradora
de momentos por MX(t), se a variável aleatória possui distribuição discreta então

MX(t) =

∞∑︁

j=1

etx jp(xj).

Se a variável aleatória possui distribuição contínua então

MX(t) =

∫︁ ∞

−∞

etxh(x).

Porém, observe que em ambos os casos, MX(t) representa a esperança de etx logo, escreveremos a
função geradora de momentos como

onde etX possui esperança ﬁnita.

MX(t) = EetX,

Antes de continuarmos, vamos observar porque a função MX(t) possui o nome de função
geradora de momentos.

Para garantirmos a existência de MX(t), vamos supor −t0

< t < t0 e que, para

algum t0 positivo, MX(t) seja ﬁnita.

A função ex, escrita em Série de Maclaurin, é representada como

ex = 1 + x + x2
2!

+ · · · + xn
n!

+ · · · .

Aplicando a igualdade (15) para a função etx,

Com isso,

ou seja,

etx = 1 + tx + (tx)2
2!

+ · · · + (tx)n
n!

+ · · · =

∞∑︁

n=0

tnXn
n!

.

MX(t) = Eetx = E

(︃

1 + tx + (tx)2
2!

+ · · · + (tx)n
n!

)︃

+ · · ·

,

MX(t) = E

∞∑︁

n=0

tnXn
n!

=

∞∑︁

n=0

EXn
n!

tn,

(15)

(16)

(17)

(18)

EXn
n!

onde
Série de Maclaurin, teremos

representa o coeﬁciente de tn. Escrevendo uma função deﬁnida por f(x) em

f (x) = 1 + f

′

(0)t + f ′′(0)t2

2!

+ · · · + f (n)(0)tn

n!

+ · · · .

Capítulo 3. Função característica e convergência em distribuição

Sendo assim, MX(t) será escrito como

ou seja,

MX(t) = 1 + M

′

X(0)t + · · · +

M(n)
X tn
n!

+ · · · ,

MX(t) =

∞∑︁

n=0

tn
n!

dn
dtn MX(t) [t = 0],

35

(19)

(20)

onde

dn
1
dtn MX(t) [t = 0] é o coeﬁciente de tn.
n!
Se igualarmos os coeﬁcientes de tn nas igualdades (18) e (20), podemos notar que

1
n!

dn

dtn MX(t) [t = 0] = EXn

n!

⇐⇒ EXn = dn

dtn MX(t) [t = 0].

(21)

Isso mostra que a função MX(t) para t = 0 gera momentos de X de acordo com a sua
ordem de derivação.

Eis algumas propriedades relevantes para o desenvolvimento deste trabalho.

Propriedade 3.1 Para t = 0, MX(0) = 1.

Prova : É imediato pois, da igualdade (19), ao atribuirmos t = 0, todas as parcelas,

a partir da segunda, reduzir-se-à a zero, isto é,

MX(0) = 1 + M

′

X(0)0 +

M(2)
X 02
2

+ · · · +

M(n)
X 0n
n!

+ · · · .

Assim, MX(0) = 1.

(cid:4)

Propriedade 3.2 Sejam X e Y variáveis aleatórias independentes. As funções etX e etY também
são independentes. Com isso,

MX+Y(t) = MX(t)MY(t).

Prova :

MX+Y(t) = Eet(X+Y) = EetX+tY
= EetXetY = EetXEetY
= MX(t)MY(t).

A Propriedade 3.2 pode ser expandida para as variáveis X1

, X2

, · · · , Xn, todas

independentes, onde

MX1

+X2+···+Xn(t) = MX1(t)MX2(t) · · · MXn(t).

(cid:4)

Capítulo 3. Função característica e convergência em distribuição

36

Em seguida, veremos dois exemplos envolvendo densidades normais. No
primeiro exemplo, devemos encontrar a função geradora de momentos de uma variável
com distribuição normal pois com este resultado vamos, no segundo exemplo, encontrar
os momentos desta variável.

Exemplo 3.1 Encontre a função geradora de momentos de uma variável aleatória X que possui
distribuição normal de média µ e variância σ2.

Solução : Recordando a função densidade de uma variável com distribuição

normal

f (x) =

− (x−µ)2
2σ2

.

e

1
√
2π

σ

Com isso podemos escrever MX(t) como

MX(t) = EetX =

∫︁ ∞

−∞

etx f (x)dx =

∫︁ ∞

−∞

etx

1
√
2π

σ

− (x−µ)2
e

2σ2 dx.

(22)

Fazendo x − µ = y temos que x = y + µ e dy = dx. Substituindo, na última integral

da Igualdade (22), teremos

∫︁ ∞

−∞

etx

1
√
2π

e

σ

− (x−µ)2

2σ2 dx =

∫︁ ∞

−∞

∫︁ ∞

et(y+µ)

− y2
e

2σ2 dy

1
√
2π

σ

= etµ

= etµ

− y2

etye

2σ2 dy

ty2σ2
2σ2

− y2
2σ2 dy.

e

(23)

1
√
2π
1
√
2π

σ

−∞
∫︁ ∞

−∞

σ

Reescrevendo o expoente do integrando da integral dada em (23),

ty2σ2
2σ2

− y2
2σ2

]︃

+ (tσ2)2
2σ2

− (tσ2)2
2σ2

]︃

[︃

[︃

= −

= −

− (2y)tσ2
y2
2σ2
2σ2
− (2y)tσ2
y2
2σ2
2σ2
= − (y − (tσ2)2)
= − (y − (tσ2)2)

2σ2

2σ2

+ (tσ2)2
2σ2
+ t2σ2
.
2

Voltando para o desenvolvimento da integral em (23).

etµ

∫︁ ∞

−∞

σ

1
√
2π

ty2σ2
2σ2

− y2
2σ2 dy = etµ

e

∫︁ ∞

1
√
2π

−∞

σ
∫︁ ∞

− (y−(tσ2)2)
e
2σ2

+ t2σ2

2 dy =

= etµ

e

t2σ2
2

− (y−(tσ2)2)
e

2σ2 dy.

1
√
2π

−∞

σ

Capítulo 3. Função característica e convergência em distribuição

37

Logo,

MX(t) = etµ

e

t2σ2
2

∫︁ ∞

−∞

σ

1
√
2π

− (y−(tσ2)2)
e

2σ2 dy; −∞ < t < ∞.

Observe que o integrando de MX(t) é uma função de densidade normal cujos parâmetros
são µ = tσ2 e σ2 e, pela igualdade (1), do Capítulo 2, esta integral é igual a 1. Com isso,

e

∫︁ ∞

−∞

σ

1
√
2π

e

− (y−(tσ2)2)

2σ2 dy = 1

MX(t) = etµ

e

t2σ2
2

.

(24)

Note que a função geradora de momentos de X com distribuição normal também

possui parâmetros µ e σ2 assim como a função de distribuição normal.

No exemplo seguinte, podemos veriﬁcar como se comporta a função geradora

de momentos para a variável aleatória X ∼ N(0, σ2).

Exemplo 3.2 Seja X uma variável aleatória com distribuição normal de média µ = 0 e variância
σ2. Encontre os momentos da variável X através da função geradora de momentos.

Solução : Pelo Exemplo 3.1 temos que

Como µ = 0,

MX(t) = etµ

e

t2σ2
2

, −∞ < t < ∞

MX(t) = e

t2σ2
2

, −∞ < t < ∞.

Temos, pela igualdade (16), que

etX =

∞∑︁

n=0

tnXn
n!

.

Logo,

t2σ2
2

e

=

=

=

∞∑︁

[︃

]︃n

t2σ2
2

1
n!

n=0
∞∑︁

n=0
∞∑︁

n=0

t2nσ2n
2nn!

σ2n

2nn!

t2n.

Pela segunda igualdade apresentada na equivalência em (21) onde

EXn
n!

= 1
n!

dn
dtn MX(t) [t = 0],

Capítulo 3. Função característica e convergência em distribuição

temos que,

e

EX2n
(2n)!

=

σ2n

2nn!

EX2n =

σ2n(2n)!
2nn!

.

38

(25)

Podemos observar, numa distribuição normal com N(0, σ2), que os momentos
de ordem par são dados pela igualdade (25) e os momentos de ordem ímpar são todos
iguais a zero inclusive por hipótese, a média, que é o momento de primeira ordem, é
igual a zero.

3.2 Função característica

Nesta seção, vamos apresentar algumas particularidades acerca da função
característica, estabelecendo relações diretas com a função geradora de momentos,
enunciar o Teorema da Fórmula de Inversão necessária para encontrar funções de
densidades de uma variável a partir de sua função característica e o Teorema da
Unicidade.

Eis a deﬁnição formal da função característica,

Deﬁnição 3.2 A função característica ϕ, da variável aleatória X, é a função ϕ : R → C onde,
para cada x real do domínio, temos ϕX(t) como imagem, tal que,

ϕX(t) = EeitX.

(26)

Observe que a função característica é deﬁnida no conjunto dos números com-
plexos. Todos os autores cujas obras estão contidas na referência deste trabalho e
que escreveram sobre funções características, apresentaram algumas propriedades de
números complexos para mostrar que não haverá mudanças algébricas bruscas pois
muitas propriedades são semelhantes aos dos números reais. Vide JAMES, (2010).

Na Seção 3.1, vimos que para um t do domínio, a função geradora de momentos
pode não convergir para um valor ﬁnito. Por isso precisamos, antes de enunciar uma
proposição, deﬁnir que a função geradora de momentos MX(t) seja ﬁnita. Vamos ver
que a função característica de uma variável aleatória sempre será ﬁnita, ou seja, sempre
está deﬁnida no domínio da função.

No Teorema 2.2 do Capítulo 2, vimos que se X e Y são duas variáveis aleatórias
ambas com esperanças ﬁnitas então a variável resultante da soma X+Y terá esperança
ﬁnita. Sejam X1 e X2 duas variáveis aleatórias ambas com esperanças ﬁnitas e seja X’
uma variável tal que X′ = X1
−1. O número i é chamado de número

+ iX2, onde i =

√

Capítulo 3. Função característica e convergência em distribuição

39

imaginário ou coeﬁciente complexo. Denominamos X’ de variável aleatória complexa
que também terá esperança ﬁnita, já que X1 e X2 também os têm.

Se aplicarmos o fato explicitado no parágrafo anterior que a soma de variáveis
com esperança ﬁnita possui esperança ﬁnita então, escrevendo eitx através da Fórmula
de Euler,

eitx = cos(tx) + isen(tx).

(27)

A norma de eitx é calculada como

|eitx|2 = cos2(tx) + sen2(tx)

= [cos2(tx) + sen2(tx)]

1

2 .

Pela Relação Fundamental da Trigonometria, sen2x + cos2x = 1. Logo,

[cos2(tx) + sen2(tx)]

1

2 = [1]

1

2 = 1,

ou seja, a função eitx possui norma unitária. Como a esperança de uma constante é a
própria constante, temos que

|ϕX(t)| = |Eeitx| ≤ E|eitx| = E1 = 1,

ou seja,

|ϕX(t)| ≤ 1.

Isso nos mostra que as funções características são limitadas. Logo, podemos aﬁrmar
que funções características possuem esperança ﬁnita ∀t tal que −∞ < t < ∞.

Vamos enunciar agora algumas propriedades das funções características.

Propriedade 3.3 Se em seu domínio t = 0 então a função característica é igual a 1, ou seja,
ϕ(0) = 1.

Prova : Para t = 0,

ϕ(0) = Eei.0.x = Ee0 = E1 = 1.

(cid:4)

Propriedade 3.4 Sendo X e Y variáveis aleatórias independentes e, eitX e eitY também ambas
independentes,

ϕX+Y(t) = ϕX(t)ϕY(t)

∀t ∈ R.

Prova : Para X e Y independentes, temos,

ϕX+Y(t) = Eeit(X+Y) = EeitX+itY =
= EeitXeitY = EeitXEeitY =
= ϕX(t)ϕY(t).

Da Propriedade 3.4, temos duas observações a fazer:

(cid:4)

Capítulo 3. Função característica e convergência em distribuição

40

1. As propriedades com números reais utilizadas na prova desta propriedade

estendem-se para os números complexos.

2. Por indução, podemos generalizar a propriedade para mais de duas variáveis, i.é,

ϕX1

+X2+X3+···+Xn(t) =

n∏︁

j=1

ϕXj(t).

Propriedade 3.5 Seja Y uma variável aleatória em função de X, tal que Y = aX + b, com a e b
constantes reais, assim,

ϕY(t) = eitbϕX(at).

Prova : Como Y = aX + b, temos que

ϕY(t) = ϕaX+b(t) = Eeit(aX+b) = EeitaX+itb =
= EeitaXeitb = eitbEei(at)X =
= eitbϕX(at).

(cid:4)

Não apresentaremos a prova desta propriedade, deixando ao leitor que tiver

interesse consultar o sexto capítulo em (JAMES, 2010).

Propriedade 3.6 Se o momento do módulo da variável X de ordem n existe então a função
característica de X possui n derivadas contínuas, isto é,

E|X|n < ∞ ⇐⇒ ϕx(t) =

∫︁

(ix)keitxdFk(X),

k = 1, 2, · · · , n.

O exemplo seguinte nos dará a função característica da variável X quando esta

se distribui normalmente.

Exemplo 3.3 Seja X uma variável aleatória que possui distribuição normal de parâmetros µ = 0
e variância σ2. Vamos obter a função ϕX(t).

Solução : Através da expansão em Série de Maclaurin para a exponencial,

apresentada na Igualdade (17), temos que

ϕX(t) = EeitX = E

∞∑︁

[itX]n
n!

n=0
∞∑︁

n=0

inEXn
n!

tn.

=

Capítulo 3. Função característica e convergência em distribuição

41

Na Seção 3.1, Exemplo 3.2, vimos que uma variável que se distribui normalmente
com média 0 e variância σ2 possui apenas momentos de ordem 2n, já que todos os
momentos de ordem ímpar são iguais a zero e esses momentos são da forma

EX2n =

σ2n(2n)!
2nn!

.

Sendo assim,

∞∑︁

n=0

inEXn
n!

tn =

=

=

∞∑︁

i2n

σ2n(2n)!
2nn!
(2n)!

t2n =

∞∑︁

n=0
∞∑︁

n=0

t2n =

i2nEX2n
(2n)!
i2nσ2n(2n)!
2nn!(2n)!

n=0

t2n =

∞∑︁

[︃

n=0

]︃n

i2σ2t2
2

=

1
n!

∞∑︁

n=0

∞∑︁

n=0
⎡

i2nσ2n
2nn!
−t2σ2
2
n!

t2n =

)

n

⎤

⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

=

(

⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

−t2σ2
2

.

= e

Portanto, a função característica de uma variável aleatória X ∼ N(0, σ2) é dada

por

−t2σ2
2

.

ϕX(t) = e

(28)

O Exemplo 3.4 mostrará uma relação interessante entre MX e ϕX.

Exemplo 3.4 Seja X uma variável aleatória tal que X ∼ N(µ, σ2), mostrar que

MX(it) = ϕX(t),

t ∈ R.

Solução : Lembrando da igualdade (24) para variáveis com distribuições normais,

Podemos dizer que,

MX(t) = etµ

e

t2σ2
2

.

MX(it) = eitµ
= eitµ
= eitµ

e

e

e

(it)2σ2
2

i2t2σ2
2

−t2σ2
2

.

onde

Isto é,

MX(it) = eitµ

e

−t2σ2
2

.

(29)

Capítulo 3. Função característica e convergência em distribuição

42

A igualdade (29) logo acima é a forma geral de ϕX(t) na igualdade (28) para X ∼ N(µ, σ2).
Portanto,

MX(it) = eitµ

e

−t2σ2
2 = ϕX(t).

A propriedade enunciada a seguir não seguiu a ordem das propriedades desta
seção pois possui uma particularidade muito interessante que é o fato de ser consequência
da Fórmula de Inversão, um método capaz de obter a função de distribuição de uma
variável aleatória através de sua função característica. Já sabemos que, através da
função de distribuição de uma variável, podemos obter a sua função característica.
Basta reescrever a Deﬁnição 3.2 como

ϕX(t) =

∫︁ ∞

−∞

eitXdFX,

t ∈ R.

Apenas como lembrete, para que uma função f seja contínua em um ponto a é
necessário que a função esteja deﬁnida em a e que os valores de f, para x próximos de a,
estejam próximos de f(a). Assim dizemos que a é um ponto de continuidade da função f.

Antes de apresentar o Teorema da Fórmula de Inversão, vamos enunciar o
Teorema da Convergência Dominada. Este teorema não será demonstrado já que não
houve utilidade direta no desenvolvimento do Teorema Central do Limite embora
o Teorema da Convergência Dominada, também conhecida como de Teorema da
Convergência Dominada de Lebesgue seja um importante resultado da teoria da medida
que nos permite garantir a integrabilidade de uma função mensurável.

Teorema 3.1 (Teorema da Convergência Dominada) Seja fn : E → R uma sequência de
funções integráveis que converge, quase sempre em E, para uma função real mensurável f. Se
existe uma função integrável g tal que | fn| ≤ g para todo n natural, então f é integrável e

∫︁

E

fn(x)dx −→

∫︁

E

f (x)dx.

A demonstração encontra-se em (JAMES, 2010).

O teorema seguinte enuncia a Fórmula de Inversão que é conhecido também
como a transformada inversa de Fourrier. Antes de enunciá-lo, vamos ressaltar alguns
tópicos essenciais para o seu entendimento.

(i) Uma função F tem um limite L à direita ou à esquerda no ponto x se F(x + h) → L
quando h → 0. Quando estes limites existem, representamos o limite à direita
como F(x+) e o limite à esquerda como F(x−).

(ii) Seja ˜F(c) tal que

com x, y e u sendo números reais e u > 0 e x < y.

˜F(c) = 1
2

+
(F(c

) + F(c

−

)), ∀c ∈ R

Capítulo 3. Função característica e convergência em distribuição

(iii) Caso F seja contínua em c, dizemos que ˜F(c) = F(c).

(iv) Fazendo

h(t) =

⎧
⎪⎪⎪⎨
⎪⎪⎪⎩

e−itx − e−ity
, quando x (cid:44) 0
it
y − x, quando x = 0

43

(30)

Temos que h(t) é uma função contínua e limitada para todo t real. Vejamos:

|h(t)| =

⃒⃒⃒⃒⃒

e−itx − e−ity
it

⃒⃒⃒⃒⃒

.

⃒⃒⃒⃒e

i(x+y)t
2

⃒⃒⃒⃒

= 1,

Como

temos que

|h(t)| =

=

⃒⃒⃒⃒⃒

i(x+y)t
2

⃒⃒⃒⃒e
⃒⃒⃒⃒
e−itx − e−ity
it
⃒⃒⃒⃒⃒⃒
2 i(x−y)t
2 i(y−x)t − e 1
e 1

it

⃒⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒

.

Pela Fórmula de Euler,

⃒⃒⃒⃒⃒⃒

2 i(y−x)t − e 1
e 1

2 i(x−y)t

it

⃒⃒⃒⃒⃒⃒

=

⃒⃒⃒⃒⃒⃒⃒

2sen

]︁

[︁ (y−x)t
2

t

⃒⃒⃒⃒⃒⃒⃒

.

Como |senα| ≤ α, ∀α ∈ R, então

2sen

]︁

[︁ (y−x)t
2

t

⃒⃒⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒⃒⃒

=

⃒⃒⃒⃒⃒

2
t

⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒⃒

sen

[︃

(y − x)t
2

]︃⃒⃒⃒⃒⃒⃒

≤ 2
t

(y − x)t
2

≤ y − x.

Teorema 3.2 (Fórmula de Inversão) Dado uma variável aleatória X que possui uma função
de distribuição FX e função característica ϕX, para x e y, pontos de continuidade de FX, com
x < y, temos que

1
2π lim

u→∞

∫︁ u

−u

e−itx − e−ity
it

ϕ(t)dt = ˜F(y) − ˜F(x)

(31)

A demonstração encontra-se em (JAMES, 2010).

O próximo teorema é o Teorema da Unicidade. Este nos mostra que a função
de distribuição de uma variável aleatória arbitrária é determinada por sua função
característica correspondente.

Teorema 3.3 (Teorema da Unicidade) Sejam X e Y duas variáveis cujas funções caracterís-
ticas são ϕX e ϕY e de funções de distribuição igual a FX e FY, respectivamente. Se ϕX = ϕY,
então FX = FY.

Capítulo 3. Função característica e convergência em distribuição

44

Demonstração : Considere ˜F(ω) = 1

2 (F(ω+) + F(ω−)), ∀ω ∈ R. Caso F seja contínua

em ω, dizemos que ˜F(ω) = F(ω).

Pelo Teorema 3.2, onde a e b ∈ R com a < b,

˜FX(b) − ˜FX(a) = ˜FY(b) − ˜FY(a)

(32)

e, fazendo a tender a menos inﬁnito, temos lim
a→−∞

˜FX(a) −→ 0 e lim
a→−∞
Com isso, a igualdade (32) reduz-se a ˜FX(b) = ˜FY(b), ∀b ∈ R.
Seja c < b, pela monotonicidade de FX e FY e pela deﬁnição de ˜F,

˜FY(a) −→ 0.

FX(c) ≤ ˜FX(b) ≤ FX(b)

e FY(c) ≤ ˜FY(b) ≤ FY(b).

Pela continuidade à direita da função de distribuição2,

˜FX(b) = FX(c)

e

lim
b↓c

˜FY(b) = FY(c).

lim
b↓c

Então, FX(c) = FY(c) ∀c ∈ R.

Na próxima seção, trataremos da convergência em distribuição, conceito muito

importante, indispensável para o sucesso das provas apresentadas no Capítulo 4.

3.3 Convergência em distribuição

Esta seção é de fundamental importância para os estudos deste trabalho já
que as demonstrações apresentadas no capítulo seguinte se baseiam fortemente neste
conceito e suas consequências. O principal objetivo desta seção é a prova do Teorema
da Continuidade de Paul Levy.

O termo convergência refere-se a tendência de vários aspectos de se identiﬁcarem
num ponto, mais especiﬁcamente, uma sequência ou uma série é dita convergente
quando a quantidade n de seus termos cresce indeﬁnidamente e a sequência ou a
série se aproxima cada vez mais de um número real (ou complexo). Este conceito está
estreitamente relacionado ao conceito de limite do Cálculo Diferencial. Por isso para
maiores esclarecimentos consultar (GUIDORIZZI, 2006).

Referindo-se a convergência de variáveis aleatórias há três principais tipos de
convergências que é a convergência quase certa, a convergência em probabilidade e
a convergência em distribuição. Esta última como ferramenta de estudos. Os outros
dois tipos: a quase certa e em probabilidade, serão apresentados apenas como informes
complementares de maneira bem breve. Para mais informação, vide (COLETTI, 2008).

Vamos considerar X1
de probabilidade (ω, A, P).

, X2

, · · · e X como variáveis aleatórias contidas num espaço

2

b ↓ c signiﬁca que o valor de b decresce até o valor de c, já que c < b.

Capítulo 3. Função característica e convergência em distribuição

45

1. Convergência quase certa.

Xn converge para X quase certamente, denotado por Xn

q.c−→ X, se o evento

{ω ∈ Ω : Xn(ω)

n→∞−−−→ X(ω)}

tem probabilidade 1.

Este modo de convergência é a base para o Teorema da Lei dos Grandes Números
juntamente com a Lei Forte de Kolmogorov e o Lema de Borel-Cantelli.

2. Convergência em probabilidade.

Xn converge para X em probabilidade, denotado por Xn
(cid:15) > 0,

P(|Xn − X| > (cid:15))

n→∞−−−→ 0.

P−→ X, se para qualquer

A convergência em probabilidade está relacionada com a Lei Fraca dos Grandes
Números, onde o principais conceitos utilizados são as desigualdades de Markov
e de Chebyshev 3.

O interessante na convergência quase certa não é dizer que

∀ω ∈ Ω, Xn(ω)

n→∞−−−→ X(ω)

e sim que a probabilidade do evento D = {ω ∈ Ω : |Z(ω)| ≥ 1}, denominado conjunto de
exceção, seja igual a zero.

Na convergência em probabilidade, a idéia da deﬁnição nos retrata que a distância
entre Xn e X quanto menor, maior é a probabilidade de acontecer e quando tiver muito
próximas, a probabilidade é bem alta.

A deﬁnição de convergência em distribuição será apresentada com maior rigor

pela sua importância dentro do nosso estudo. Vejamos formalmente a sua deﬁnição.

Deﬁnição 3.3 (Convergência em Distribuição) As variáveis aleatórias X1
sequência (Xn)n∈N converge em distribuição para a variável aleatória X se

, X2

, · · · , Xn da

Fn(X) = F(X).

lim
n→∞

Reescrevendo a Deﬁnição 3.3 a ﬁm de reforçar a relação direta da variável

aleatória e sua função de distribuição:

Para n ∈ N , Fn(X)

D−→ F(X) =⇒ Xn

D−→ X,

quando n → ∞.

3

Para os lema de Borel-Cantelli e a Desigualdade de Chebyshev consultar (FELLER, 1968).

Capítulo 3. Função característica e convergência em distribuição

46

A convergência em distribuição relaciona as funções de distribuições das variáveis
ao invés da variável em si, ela nos mostra que quanto maior o n, mais a sequência das
funções de distribuições tende a função de distribuição propriamente dita. Pelo fato da
condição de convergência se dar através das funções de distribuições de Xn e X, este
modo de convergência é considerado o mais fraco entre os três citados nesta seção. Por
esse motivo, quando uma sequência de variáveis converge em distribuição para uma
variável dizemos que converge fracamente.

A seguir, vamos apresentar a deﬁnição de limite de sequência. (GUIDORIZZI,

2006).

Deﬁnição 3.4 Sejam (an) uma sequência e a um número real. Se lim
n→∞
que (an) converge para a. Assim, deﬁnimos que para todo (cid:15) > 0, existe um n0

an = a, então dizemos
∈ N onde,

an = a ⇐⇒ n > n0

=⇒ |an − a| < (cid:15).

lim
n→∞

(33)

O ponto principal desta seção é o Teorema da Continuidade de Paul Levy. Para
obtermos a prova com o rigor matemático que ele merece, vamos precisar do resultado de
um outro teorema que é o Teorema de Helly-Bray. Este nos mostra que a convergência
de funções de distribuições de uma sequência de suas respectivas variáveis leva a
convergência das esperanças de determinadas funções contínuas e limitadas.

Teorema 3.4 (Teorema de Helly-Bray) Dadas as variáveis aleatórias X1
respectivas funções de distribuições F1
converge em distribuição para F então

, · · · , com suas
, · · · e X com sua função de distribuição F. Se Fn

, X2

, F2

∫︁

g(x)dFn(x)

∫︁

n→∞−−−→

g(x)dF(x)

(34)

onde g é uma função contínua, limitada e deﬁnida no conjunto dos reais.

Demonstração : Vamos aplicar aqui o conceito de limite de uma sequência no
cálculo diferencial apresentado na Deﬁnição 3.4. Sendo assim, para todo n natural com
n ≥ n0 e (cid:15) > 0, devemos mostrar que

∫︁

⃒⃒⃒⃒⃒

∫︁

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒

< (cid:15).

(35)

Sejam a e b pontos de continuidade de F, onde x está deﬁnido no intervalo [a, b],

tal que −∞ < a < b < ∞.

Capítulo 3. Função característica e convergência em distribuição

47

∫︁

⃒⃒⃒⃒⃒

∫︁

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒

=

−

≤

−

∫︁

⃒⃒⃒⃒⃒

∫︁ b

a
∫︁

⃒⃒⃒⃒⃒⃒

∫︁ b

a

∫︁ b

g(x)dFn(x) −

a
∫︁ b

g(x)dF(x) +

g(x)dFn(x) +
∫︁

g(x)dF(x) −

∫︁ b

a

g(x)dF(x)

g(x)dFn(x)

a
∫︁ b

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

+

⃒⃒⃒⃒⃒⃒

a
∫︁ b

a

⃒⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒⃒

∫︁ b

a

g(x)dFn(x)

+

g(x)dFn(x)

∫︁

g(x)dF(x) −

g(x)dF(x)

(36)

⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒⃒

Por hipótese, seja c = sup|g(x)| < ∞, com x ∈ R e considere (cid:15) > 0.

Precisaremos transformar todos os três módulos do segundo membro da desi-

gualdade (36). Pegando inicialmente o último módulo, temos:

∫︁ ∞

g(x)dF(x) +

g(x)dFn(x)

⃒⃒⃒⃒⃒⃒

∫︁ b

a

∫︁

g(x)dF(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

=

≤

≤

<

∫︁ a

−∞
∫︁ a

⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒

−∞

∫︁ a

−∞
∫︁ a

b
∫︁ ∞

b
∫︁ ∞

b

g(x)dF(x)

⃒⃒⃒⃒⃒

+

⃒⃒⃒⃒⃒

|g(x)|dF(x) +
∫︁ ∞

cdF(x) +

⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒

g(x)dF(x)

|g(x)|dF(x)

−∞
(︃∫︁ a

−∞

< c

dF(x) +

cdF(x)

b
∫︁ ∞

)︃
dF(x)

b

= c (F(a) − F(−∞) + F(+∞) − F(b)) ,

pelo item (iii) da Deﬁnição 2.3,

c (F(a) − F(−∞) + F(+∞) − F(b)) = c (F(a) + 1 − F(b)) .

Como pontos de continuidade são densos, se pegarmos, no intervalo [a, b], um
valor de a suﬁcientemente pequeno e um valor de b suﬁcientemente grande, ou melhor,
se ﬁzermos a → −∞ e b → +∞ teremos que

F(a) + 1 − F(b) → 0.

Sendo assim,

⃒⃒⃒⃒⃒⃒

∫︁ b

a

∫︁

g(x)dF(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

≤ c(F(a) + 1 − F(b)) < (cid:15).

Capítulo 3. Função característica e convergência em distribuição

48

Continuando com a desigualdade (36),

∫︁

⃒⃒⃒⃒⃒⃒

g(x)dFn(x) −

∫︁ b

a

g(x)dFn(x)

⃒⃒⃒⃒⃒⃒

=

≤

≤

<

⃒⃒⃒⃒⃒

g(x)dFn(x)

g(x)dFn(x)

⃒⃒⃒⃒⃒

|g(x)|dFn(x)

b
∫︁ ∞

b
∫︁ ∞

b

∫︁ ∞

g(x)dFn(x) +

g(x)dFn(x)

⃒⃒⃒⃒⃒

+

⃒⃒⃒⃒⃒

|g(x)|dFn(x) +
∫︁ ∞

cdFn(x) +

∫︁ a

−∞
∫︁ a

⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒

−∞

∫︁ a

−∞
∫︁ a

−∞
(︃∫︁ a

cdFn(x)

b
∫︁ ∞

)︃
dFn(x)

< c

dFn(x) +

−∞

b
= c(Fn(a) + 1 − Fn(b)).

Como, por hipótese, Fn(X)

D−→ F(x) então,

c(Fn(a) + 1 − Fn(b))

D−→ c(F(a) + 1 − F(b)) < (cid:15).

Para ﬁnalizar a demonstração, precisamos que mostrar que, para valores suﬁci-

entemente grandes de n,

⃒⃒⃒⃒⃒⃒

∫︁ b

a

g(x)dFn(x) −

∫︁ b

a

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

< (cid:15).

(37)

Ao tomarmos pontos no intervalo [a, b] denotados por x0
< · · · < xN = b, podemos considerar x0
< x1

a = x0
continuidade de F. Sendo g(x) uma função contínua com x, x j ∈ [a, b], temos que

, · · · , xN onde
, · · · , xN como pontos de

< x2

, x1

, x2

, x2

, x1

|g(x) − g(x j)| < (cid:15),

(38)

para todo x ∈ [x j, x j+1] onde j ∈ {0, 1, 2, · · · , N − 1}.

Aplicando integral deﬁnida no intervalo [xj, x j+1] em cada termo da desigualdade

(38),

|g(x) − g(x j)| < (cid:15) ⇐⇒

⇐⇒

∫︁ x j+1

x j
∫︁ x j+1

∫︁ x j+1

g(x)dFn(x) −

x j

g(x)dFn(x) − g(xj)

⃒⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒⃒

g(xj)dFn(x)

∫︁ x j+1

x j

dFn(x)

⃒⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒⃒

∫︁ x j+1

<

(cid:15)dFn(x)

x j
∫︁ x j+1

< (cid:15)

g(x)dFn(x) − g(x j)

dFn(x) <

∫︁ x j+1

x j

xj
∫︁ x j+1

⇐⇒ −(cid:15)

<

(cid:15)

x j
∫︁ x j+1

x j

dFn(x).

x j
∫︁ x j+1

x j

dFn(x)

dFn(x)

(39)

Capítulo 3. Função característica e convergência em distribuição

49

∫︁ x j+1

⇐⇒ −(cid:15)

dFn(x) + g(x j)

∫︁ x j+1

dFn(x) <

<

(cid:15)

x j
∫︁ x j+1

x j

dFn(x) + g(x j)

x j
∫︁ x j+1

x j

dFn(x)

∫︁ x j+1

x j

g(x)dFn(x)

⇐⇒ −(cid:15)[Fn(x j+1) − Fn(x j)] + g(x j)[Fn(x j+1) − Fn(xj)] <

<

(cid:15)[Fn(x j+1

− Fn(x j)] + g(x j)[Fn(x j+1

− Fn(x j)]

⇐⇒ [g(xj) − (cid:15)][Fn(x j+1) − Fn(x j)] <

<

[g(xj) + (cid:15)][Fn(x j+1) − Fn(x j)].

∫︁ x j+1

g(x)dFn(x)

x j

Fazendo

e

teremos,

mnj = [g(x j) − (cid:15)][Fn(x j+1) − Fn(xj)]

Mnj = [g(x j) + (cid:15)][Fn(xj+1) − Fn(xj)]

mnj <

∫︁ x j+1

x j

g(x)dFn(x) < Mnj.

∫︁ x j+1

x j

g(x)dFn(x)

(40)

(41)

Por hipótese, FN

D−→ F. Logo, a última equivalência em (39) pode ser reescrita

como

[g(x j) − (cid:15)][F(x j+1) − F(x j)] <

∫︁ xj+1

x j

g(x)dF(x) < [g(x j) + (cid:15)][F(xj+1) − F(xj)]

(42)

Fazendo

e

teremos,

mj = [g(xj) − (cid:15)][F(xj+1) − F(x j)]

Mj = [g(x j) + (cid:15)][F(x j+1) − F(xj)]

mj <

∫︁ x j+1

x j

g(x)dF(x) < M j.

(43)

A diferença entre as desigualdades (41) e (43) é igual a

mnj − Mj ≤

∫︁ x j+1

x

g(x)dFn(x) −

∫︁ x j+1

x j

g(x)dF(x) ≤ Mnj − mj.

(44)

Capítulo 3. Função característica e convergência em distribuição

Para j variando de 0 a N − 1,

N−1∑︁

i=0

(mnj − M j) ≤

∫︁ b

a

g(x)dFn(x) −

∫︁ b

a

g(x)dF(x) ≤

N−1∑︁

(Mnj − mj).

i=0

Como mnj

n→∞−−−→ mj e Mnj

n→∞−−−→ M j temos que

N−1∑︁

(mnj − Mj) −→

N−1∑︁

(mj − M j) = −2(cid:15)(F(b) − F(a)) ≥ −2(cid:15)

e

j=0

N−1∑︁

j=0

j=0

(Mnj − mj) −→

N−1∑︁

j=0

(Mj − mj) = 2(cid:15)(F(b) − F(a)) ≤ 2(cid:15).

De (46) e (47), e para n suﬁcientemente grande,

50

(45)

(46)

(47)

N−1∑︁

⃒⃒⃒⃒⃒⃒⃒

(mnj − M j) −

(mj − M j)

< (cid:15)

e

(Mnj − mj) −

j=0

j=0

j=0

i=0

⃒⃒⃒⃒⃒⃒⃒

N−1∑︁

⃒⃒⃒⃒⃒⃒⃒

N−1∑︁

(M j − mj)

⃒⃒⃒⃒⃒⃒⃒

< (cid:15)

N−1∑︁

assim,

N−1∑︁

j=0

(mnj − M j) ≥ −3(cid:15)

e

N−1∑︁

j=0

(Mnj − mj) ≤ 3(cid:15).

Com isso, a desigualdade (45) será reescrita como

−3(cid:15) ≤

∫︁ b

a

g(x)dFn(x) −

∫︁ b

a

g(x)dF(x) ≤ 3(cid:15)

(48)

e, consequentemente,

⃒⃒⃒⃒⃒⃒

∫︁ b

a

g(x)dFn(x) −

∫︁ b

a

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

≤ 3(cid:15).

Pela desigualdade (36),

∫︁

⃒⃒⃒⃒⃒

∫︁

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒

∫︁

⃒⃒⃒⃒⃒⃒

∫︁ b

≤

−

∫︁ b

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

+

⃒⃒⃒⃒⃒⃒

a
∫︁ b

a

a

⃒⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒⃒

∫︁ b

a

g(x)dFn(x)

+

g(x)dFn(x)

∫︁

g(x)dF(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒⃒

≤ (cid:15) + (cid:15) + 3(cid:15) = 5(cid:15).

Portanto,

∫︁

⃒⃒⃒⃒⃒

∫︁

g(x)dFn(x) −

g(x)dF(x)

⃒⃒⃒⃒⃒

≤ (cid:15).

(cid:4)

Capítulo 3. Função característica e convergência em distribuição

51

O resultado imediato desta aplicação e consequentemente do Teorema de Helly-
Bray é que uma sequência de n funções características de uma sequência de n variáveis
aleatórias converge para a sua função característica, ou seja,

ϕXN(t)

n→∞−−−→ ϕX(t).

(49)

Chegamos ao teorema mais importante dentro do conceito de convergência em
distribuição que é o teorema da continuidade pois o teorema nos diz que o limite de
uma sequência de funções características também é uma função característica com a
condição de ser contínua no ponto zero.

Teorema 3.5 (Teorema da Continuidade de Paul-Levy) Sejam F1
tribuição e sejam ϕ
1
mente para um limite ϕ e se ϕ é contínua no ponto zero, então,

, · · · , funções de dis-
, · · · , suas respectivas funções características. Se ϕn converge pontual-

, ϕ
2

, F2

(a) existe uma função de distribuição F tal que Fn

D−→ F e,

(b) ϕ é a função característica de F.

Demonstração : Para provar que Fn converge fracamente para alguma função de
distribuição, primeiro vamos provar que para toda sequência de funções de distribuição
, · · · e uma
atendendo as condições do Teorema 3.5, existem uma subsequência Fn1
D−→ F, quando j → ∞. Para isso vamos dividir a
função de distribuição F tais que Fnj
demonstração em duas etapas:

, Fn2

(i) Existem uma subsequência Fn1

, Fn2

, · · · e uma função F : R → [0, 1] tais que F é

não-decrescente e contínua à direita e

Fnj

D−→ F,

quando

j −→ ∞,

para todo x como ponto de continuidade de F e

(ii) a função F, apresentada no item (i), é uma função de distribuição, onde F(∞) = 1 e

F(−∞) = 0.

Para provarmos o item (i), descrito logo acima, vamos usar o método da
, · · · uma enumeração dos racionais da reta. Seja M a

, r2

diagonalização. Sejam r1
seguinte matriz:

M =

⎡

⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

4

F1 F2 F3 F4
3 F1
2 F1
F1
1 F1
3 F2
2 F2
1 F2
F2
3 F3
2 F3
F3
1 F3
3 F4
2 F4
1 F4
F4
...
...
...
...

4

4

4

· · ·
· · ·
· · ·
· · ·
· · ·
. . .

⎤

⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

Capítulo 3. Função característica e convergência em distribuição

52

(︁
Fj
1

)︁

(︁

, Fj
2

, · · ·

Na matriz M temos que a sequência

contida na (j + 1)-ésima linha
é uma subsequência da sequência contida na j-ésima linha que converge no racional
Fj−1
r j, para j ≤ 1. Podemos notar que, como
é uma sequência
1
limitada de números reais, ela possui uma subsequência convergente logo, podemos
= Fj
escolher a sequência
j,
para j ≥ 1, temos que a subsequência (Fnj)j converge em todos os racionais da reta.
Chamemos o limite de F(rk), de modo que Fnj(rk) −→ F(rk) para todo k. Como F é uma
função de distribuição então 0 ≤ F(rk) ≤ 1 e é não decrescente no conjunto dos racionais.
Vamos deﬁnir F em função de um x irracional como

conforme descrito acima. Considerando Fn j

(r j), Fj−1

(rj), Fj−1

(r j), · · ·

(︁
Fj
1

, Fj
3

, Fj
2

, · · ·

)︁

)︁

2

3

F(x) = lim
r↓x; r∈Q

F(r)

dessa forma, F é deﬁnida como uma função não-decrescente, mas não é necessariamente
contínua à direita.

Vamos provar que Fnj(x) −→ F(x) para todo x como ponto de continuidade de F,
isto é, mostrar apenas que há a convergência, não garantindo que esta convergência seja
em distribuição.

Supondo x um ponto de continuidade de F e r′ e r′′ racionais tais que r′ < x < r′′

e F(r′′) − (cid:15) < F(x) < F(r′′) + (cid:15) então,

F(x) − (cid:15) < F(r

′

′

) = lim
j→∞
≤ lim
j→∞
′′
= F(r

) ≤ lim
j→∞

Fnj(r
supFnj(x) ≤ lim
j→∞
) < F(x) + (cid:15).

in f Fnj(x)
′′
Fnj(r

)

j→∞
−−−→ F(x). Mostrando assim a convergência de Fn para F.
Vamos, agora, mostrar que F é uma função de distribuição, ou seja, provar o item (ii).

Para (cid:15) arbitrário, Fnj(x)

Iniciaremos observando que

∫︁ t

0

ϕnj(s)ds =

∫︁ t

∫︁ ∞

0

−∞

eisxdFnj(x)ds.

(50)

Sendo a função eisx uma função limitada, a ordem das integrais pode ser alterada

sem qualquer prejuízo, isto é,

∫︁ t

0

ϕnj(s)ds =

=

=

=

∫︁ t

∫︁ ∞

−∞
[︃∫︁ t

eisxdFnj(x)ds
]︃
eisxds

dFnj(x)

[︃

t

]︃

⃒⃒⃒⃒⃒

0
eisx
ix
0
eitx − 1
ix

dFn j(x)

dFnj(x).

0
∫︁ ∞

−∞
∫︁ ∞

−∞
∫︁ ∞

−∞

Capítulo 3. Função característica e convergência em distribuição

Seja g′(x) uma função tal que

′

g

(x) =

⎧
⎪⎪⎪⎨
⎪⎪⎪⎩

eitx − 1
ix

, quando x (cid:44) 0
t, quando x = 0.

53

(51)

Observe que g′(x) é uma função contínua em x = 0 e limitada. Assim, pelo

Teorema de Helly-Bray,

∫︁ ∞

−∞

eitx − 1
ix

dFnj(x) =

=

∫︁ ∞

−∞
∫︁ ∞

−∞

′

g

(x)dFnj(x) −→

′
g

(x)dF(x) =

eitx − 1
ix

dF(x) =

eisxdFnj(x)ds.

∫︁ ∞

−∞
∫︁ ∞

∫︁ t

0

−∞

O processo acima nos mostra que há uma convergência entre ϕnj e ϕ. Como ϕ é
contínua no ponto zero, podemos dizer que ϕ é limitada e mensurável e, pelo Teorema
da Convergência Dominada, temos que

∫︁ t

0

ϕnj(s)ds −→

∫︁ t

0

ϕ(s)ds.

(52)

Através da segunda integral temos,

∫︁ t

0

ϕ(s)ds =

∫︁ t

∫︁ ∞

0

−∞

eisxdF(x)ds ⇐⇒ 1
t

∫︁ t

0

ϕ(s)ds = 1
t

∫︁ t

[︃∫︁ ∞

0

−∞

]︃
eisxdF(x)

ds,

t = 0

Como, pela Propriedade 3.3 , ϕ(0) = 1, com s = 0 e fazendo t tender a zero,

∫︁ t

0

1
t

ϕ(s)ds −→ ϕ(0)

e

∫︁ t

∫︁ ∞

0

−∞

1
t

eisxdF(x)ds −→

∫︁ ∞

−∞

1dF(x).

(53)

Com isso podemos aﬁrmar que

ϕ(0) =

∫︁ ∞

−∞

1dF(x) = F(∞) − F(−∞) = 1.

Como F(∞) − F(−∞) = 1 mostramos que F(∞) = 1 e F(−∞) = 0

Agora, mostraremos que a convergência do item (i), do início desta demonstração,

é uma convergência em distribuição.

Para isso, precisamos de sequências de funções de distribuição atendendo as
· · · e
condições do teorema onde, em toda sequência, haverá uma subsequência Fn1
uma função de distribuição F tal que, para todo j tendendo ao inﬁnito teremos que Fnj
convergirá fracamente para F.

, Fn2

Aplicando o método de redução ao absurdo, vamos supor que Fn não convirja
em distribuição para F porém, a subsequência Fnj convirja em distribuição para F.

Capítulo 3. Função característica e convergência em distribuição

54

Sendo assim, seja x um ponto de continuidade em F e escreveremos uma subsequência
F1′, F2′, · · · , atendendo as condições do Teorema 3.5, onde esta subsequência convirja
em distribuição para um ponto a em F, diferente de F(x). Por hipótese, haverá uma
subsequência F1′′, F2′′, · · · da subsequência F1′, F2′, · · · e outra função de distribuição G
D−→ F
onde Fn′′
então as funções F e G possuem a mesma função característica ϕ e consequentemente,
D−→ a (cid:44) F(x), temos uma contradição em
são iguais. Ora, como Fn′′
relação a subsequência Fn′′, logo, Fn

D−→ G. Porém, como a subsequência Fn′′

D−→ G é uma subsequência de Fnj

D−→ G(x) = F(x) e Fn′′

D−→ F.

(cid:4)

Ao concluir tal demonstração, observamos a grande relação de uma função
característica e sua função de distribuição. As funções de distribuição "dependem
continuamente"de suas funções características. Por esta razão este teorema é conhecido
comumente como "Teorema da Continuidade"(HOEL, 1978).

Ao ﬁnal deste capítulo, carregado de deﬁnições e teoremas, construímos um
sólido alicerce, fundamentando conceitos muito importantes para o desenvolvimento
do próximo capítulo. Agora, chegamos a um dos pontos principais que é apresentar
algumas versões de um conceito considerado um dos mais importante dentro da
estatística e probabilidade que é o Teorema Central do Limite.

55

4

Teorema Central do Limite

Vamos iniciar este capítulo com um exemplo prático, retratando uma situação
normal do dia a dia, com o intuito de apresentar uma idéia do que trata o Teorema
Central do Limite.

Numa empresa de Call Center ou, melhor dizendo, de telemarketing, constatou-se
que, em média, a cada hora atendem-se 4 ligações. A proposta é analisar ao longo de
um dia de trabalho o comportamento gráﬁco e tirar algumas conclusões.

A variável X representa o número de ligações a cada hora de trabalho e possui

distribuição discreta de Poisson de parâmetro λ = 4.

Analisaremos o seu gráﬁco de quatro maneiras diferentes, mantendo a média de

ligações por hora.

(1) durante uma hora de trabalho.

(2) durante um turno de quatro horas de trabalho.

(3) durante uma jornada de oito horas de trabalho.

(4) durante uma jornada de dez horas de trabalho, adicionando duas horas extras.

Temos assim outra variável representada por Y, que está em função das variáveis
, . . . , Xk onde k possui variações especíﬁcas em cada um dos itens acima e

X1

, X2

Y =

n∑︁

k=1

Xk,

onde Y também possui Distribuição de Poisson, com média µ = nλ e variância σ2 = nλ.

(1) Para uma hora de trabalho, temos λ = 4 e n = 1 logo, µ = 4.

(2) Para um turno de trabalho, temos λ = 4 e n = 4 logo, µ = 16.

Capítulo 4. Teorema Central do Limite

56

(3) Para uma jornada de oito horas de trabalho, temos λ = 4 e n = 8 logo, µ = 32.

(4) Para uma jornada de dez horas de trabalho, temos λ = 4 e n = 10 logo, µ = 40.

Vejamos os gráﬁcos dos respectivos itens.

Figura 4 – Comparação entre o histograma de Poisson e a curva normal

Podemos observar, na Figura 4, que, quando o ampliamos o tempo de trabalho
nos itens de (1) a (4) descritos logo acima consequentemente, o número de telefonemas
também aumenta e o histograma de Poisson vai se aproximando cada vez mais da curva
normal. Se contabilizássemos o período de uma semana ou de um mês, o histograma
seria muito mais aproximado da curva normal. Isso deve-se ao Teorema Central do
Limite.

O Teorema Central do Limite nos diz que para uma quantidade n de variáveis
independentes, enquanto o valor de n cresce inﬁnitamente, a distribuição da variável
tenderá a uma distribuição normal de parâmetros µ = 0 e σ2 = 1.

Considere uma sequência de variáveis aleatórias independentes, X1

, · · ·
, · · · a sequência de
deﬁnidas no mesmo espaço de probabilidade (Ω, A, P), e seja S1
Sn
somas parciais, deﬁnidas por Sn = X1
− µ multiplicada
n
pela raiz quadrada de n converge fracamente para uma distribuição normal de média
nula, ou seja,

, S2
+ · · · + Xn. A diferença

+ X2

, X2

√

n

(︂Sn
n

)︂

− µ

D−→ N(0, σ2).

Este capítulo está dividido em duas seções. Na primeira seção, vamos enunciar e
provar o teorema limite de DeMoivre-Laplace para variáveis com distribuição binomial
como um caso particular do teorema limite para variáveis com qualquer distribuição

Capítulo 4. Teorema Central do Limite

57

porém sempre com a condição de que as variáveis sejam iid (independentes e identica-
mente distribuídas). Na segunda seção, abordaremos sobre a Condição de Lindeberg
e, consequentemente, o teorema limite, cujas variáveis são independentes mas não
são identicamente distribuídas, ﬁnalizando toda abordagem dedutiva, necessária para
fundamentar os próximos capítulos onde aplicaremos todo este aparato em situações
práticas e concretas.

4.1 O Teorema Central do Limite para variáveis indepen-

dentes e identicamente distribuídas.

Na situação descrita no início deste capítulo, as variáveis são iid, onde todas
possuem a distribuição de Poisson. Logo, se encaixa diretamente na abordagem desta
seção.

O teorema abaixo é a forma geral do teorema limite para variáveis iid, que seguiu

soberana até o aparecimento da Condição de Lindeberg e sua irrefutável veracidade.

, X2

Teorema 4.1 X1
com média e variância de Xi igual a µ e σ2, respectivamente. Se Sn = X1
média e variância igual a nµ e nσ2 respectivamente, então:

, · · · , são variáveis aleatórias independentes e identicamente distribuídas
+ · · · + Xn, com

+ X2

Sn − nµ
√
σ
n

D−→ N(0, 1).

(54)

Demonstração : No Capítulo 2, vimos que se Z = σX + µ então Z* = X−µ

σ e que

E(Z*) = 0 e Var(Z*) = 1. Com isso, iniciamos supondo que µ = 0.

Pelo Teorema da Continuidade de Paul Levy, esta demostração consiste em

mostrar que,

(t) −→ e

−t2
2 , ∀t ∈ R.

ϕ Sn

√

σ

n

Pela deﬁnição de função característica, na qual ϕX(t) = EeitX, podemos escrever

(t) = Eeit Sn
√
n .

σ

ϕ Sn

√

σ

n

(t) = Eeit Sn

√

σ

n = Ee

itSn
√
σ

n = Eei

t
√

σ

n

Sn

ϕ Sn

√

σ

n

Fazendo uma mudança de variável, v = t
√
σ

n ,

Eei

σ

t
√

n

Sn = EeivSn = ϕSn(v) = ϕSn

(︃

)︃

t
√

n

σ

Capítulo 4. Teorema Central do Limite

58

Como, por hipótese, Sn = X1

+X2

+· · ·+Xn e os Xi, i = 1, 2, · · · , n são identicamente

distribuídos então,

)︃

t
√

n

σ

. . . ϕXn

(︃

)︃

t
√

n

σ

ϕSn

(︃

)︃

t
√

n

σ

= ϕX1

n∏︁

=

(︃

σ

t
√

n

(︃

ϕXi

)︃

(︃

ϕX2
)︃

t
√

n

σ
)︃

i=1

(︃

= ϕn
Xi

σ

t
√

n

(︁ t
√
σ

)︁
.

σ

n

√

(t) = ϕn
Ou seja, ϕ Sn
Xi
Lembremos que ϕ(t) = ϕX(t) = ∫︀
Por hipótese, E2(X1) existe então a função ϕ possui duas derivadas contínuas, ou

eitxdFX(x).

n

seja,

∫︁

ϕ(n)(t) =

(ix)neitxdFX(x),

n = 0, 1, 2

Fazendo t = 0 temos,

∫︁

∫︁

ϕ(n)(0) =

=

= in

(ix)ne0dFX(x)

(ix)ndFX(x)
∫︁

xndFX(x)

= inEXn.

Aplicando a Expansão de Taylor1 de ordem 1 em volta de 0 na função ϕ, com

Resto de Lagrange com 0 < α(t) ≤ t,

1∑︁

ϕ(t) =

ϕ(n)(0)
n!

(t − 0)n +

ϕ(2)(α(t))
2

(t − 0)0 +

(t − 0) +

=

n=0
ϕ(0)(0)
0!
= ϕ(0) + ϕ′

(0)t +

ϕ(1)(0)
1!
ϕ′′(α(t))
2

t2

ϕ(2)(α(t))
2!

(t − 0)2

Precisamos obter os valores de ϕn(0) com n = 0, 1, 2. Para isso, vamos fazer o

seguinte:

1

Para maiores esclarecimentos, consultar (GUIDORIZZI, 2006).

Capítulo 4. Teorema Central do Limite

59

ϕ(t) = ϕ(0) + ϕ′

(0)t +

= ϕ(0) + ϕ′

(0)t +

= ϕ(0) + ϕ′

(0)t +

t2

ϕ′′(α(t))
2
ϕ′′(α(t))
2
ϕ′′(0)
2

t2 +
t2 + t2
2

t2 −

ϕ′′(0)
ϕ′′(0)
2
2
(α(t)) − ϕ′′
[ϕ′′

(0)]

t2

Como ϕ(n)(0) = inEXn, podemos calcular ϕ(0), ϕ′(0) e ϕ′′(0). Com isso,

ϕ(0) = i0EX0 = 1,
ϕ′
(0) = iEX = 0
(0) = i2EX2 = −1σ2 = −σ2.

e

ϕ′′

Sendo assim, podemos escrever ϕ(t) como

ϕ(t) = 1 −

−t2σ2
2

+ t2
2

e(t),

onde e(t) é uma função originária de ϕ′′(α(t)) − ϕ′′(0).

Vamos agora utilizar ϕ

)︁

(︁ t
√
σ

n

ao invés de ϕ(t).

(︃

ϕ

)︃

t
√

n

σ

= 1 +

= 1 +

(︃

−

)︃2

σ2

t
√

σ

n
2
− t2
√
σ2

n2

2

+

σ2

σ2

+

(︃

)︃2

t
√

2

n

)︃

(︃

e

t
√

n

σ

(︃

n2

e

)︃

t
√

n

σ

σ

t2
√

2

= 1 +

− t2
n
2
= 1 − t2
2n
= 1 − t2
2n

+

t2
nσ2
2
+ t2

2nσ2 e
1 + 1
σ2 e

[︃

(︃

e

t
√

σ

)︃

n
)︃

(︃

(︃

σ

σ

t
√

)︃]︃

n

n

t
√

Elevando ambos os membros a n,
[︃

)︃]︃n

(︃

[︃

t
√

ϕ

σ

=

n

1 − t2
2n

)︃]︃]︃n

[︃

1 + 1
σ2 e

(︃

t
√

n

σ

Precisamos analisar o comportamento da expressão 1 + 1
σ2 e

)︁

(︁ t
√
σ

n

quando n tende

ao inﬁnito, ou seja, calcular o seu limite. Assim:

Capítulo 4. Teorema Central do Limite

60

[︃

1 + 1
σ2 e

)︃]︃

(︃

t
√

n

σ

lim
n→∞

= 1 + 1

σ2 lim
n→∞

)︃

(︃

e

t
√

n

σ

= 1 + 1

σ2 0 = 1.

Isso signiﬁca que quanto mais o valor de n cresce, a expressão 1 + 1
σ2 e
[︃
tende a 1 − t2
1 − t2
2n
2n

1 + 1
σ2 e

(︁ t
√
σ

)︁]︂]︃n

a 1 e, consequentemente, a expressão

[︂

n

(︁ t
√
σ

)︁

n

tende

. Isto é,

[︃

[︃

1 − t2
2n

1 + 1
σ2 e

(︃

t
√

n

σ

)︃]︃]︃n

D−→ 1 − t2
2n

.

No cálculo diferencial, o limite de Euler, no conjunto dos números complexos,

nos mostra que se uma sequência cn converge para c então

]︂n

[︂
1 + cn
n

lim
n→∞

= ec.

Assim, para n tendendo ao inﬁnito,

]︃n

[︃

1 − t2
2n

lim
n→∞

= lim
n→∞

⎡

⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

1 +

−t2
2
n

⎤
n

⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

t2
2 .

−
= e

Isto signiﬁca que

(︃

ϕn

)︃

t
√

n

σ

= ϕ Sn

√

σ

n

(t) → e

−t2
2 , ∀t ∈ R,

e que a convergência dada em (54) é válida. Portanto,

Sn − nµ
√
σ
n

D−→ N(0, 1).

(cid:4)
Com essa demonstração, o Teorema 4.1 está disponível para ser aplicado em situações
que envolvam variáveis independentes e identicamente distribuídas para diferentes
tipos de distribuições.

O próximo teorema é um caso particular do Teorema Central do Limite para
variáveis independentes e identicamente distribuídas já que as variáveis possuem
distribuição de Bernoulli. Este teorema tem uma grande importância para o desenvol-
vimento da probabilidade pois constitui o marco inicial para o grandioso estudo feito
posteriormente por outros.

Capítulo 4. Teorema Central do Limite

61

, · · · , são variá-
Teorema 4.2 (Teorema Central do Limite de DeMoivre e Laplace) X1
veis aleatórias independentes e identicamente distribuídas que possui distribuição binomial de
+ X2
parâmetros n e p, com 0 < p < 1. Se Sn = X1

+ · · · + Xn, então:

, X2

Sn − np
√︀
np(1 − p)

D−→ N(0, 1)

(55)

Demonstração: Vamos seguir o mesmo procedimento utilizado na demonstração
do Teorema 4.1, atentando ao fato que Xi possui média igual a p e variança igual a
p(1 - p), ou seja, E(Xi) = p e Var(Xi) = p(1 − p) já que Xi possui distribuição binomial.
Sendo assim, a média de Sn é igual a np, e a variância de Sn é igual a np(1 - p).

Vamos considerar Y como sendo a variável padronizada de X. Sendo assim,

podemos escrever a variável Y como

Y = X − np
np(1 − p)

√︀

A função característica de X é ϕY(t) = EetY. Vamos mostrar que a variável X

possui função de distribuição normal padrão.

X − np
√︀
np(1 − p) = Ee

EetY = Ee

−

= e

−

√︀

tx
np(1 − p)
tnp
√︀
np(1 − p) Ee

√︀

tnp
np(1 − p)
tx
np(1 − p)

√︀

Lembremos que, sendo X uma variável discreta então sua média é dada por

EX =

n∑︁

j=0

x j f (x j),

onde f (x j) é a função de distribuição de X. Com isso,

tnp
np(1 − p) Ee

−

√︀

e

tx

√︀
np(1 − p) = e

−

tnp
np(1 − p)

√︀

−

tnp
np(1 − p)

√︀

= e

n∑︁

x=o

e

(︃

n∑︁

x=o

tx
np(1 − p)

√︀

(︃

)︃
n
x

px(1 − p)n−x

)︃
n
x

⎛

⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝

pe

t
np(1 − p)

√︀

⎞
x

⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠

(1 − p)n−x

Capítulo 4. Teorema Central do Limite

tnp
np(1 − p)

√︀

−
= e

t
np(1 − p)

√︀

1 − p + pe

⎛

⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝

⎛

tp
np(1 − p)

−

√︀

e

1 − p + pe

n

t
np(1 − p)

√︀

−
(1 − p)e

tp

√︀

np(1 − p) + pe

t(1 − p)
np(1 − p)

√︀

=

=

⎡

⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

⎡

⎞
n

⎤
⎞

⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

⎤

n

Escrevendo ex como uma soma inﬁnita teremos

ex =

∞∑︁

n=0

.

xn
n!

Nesse sentido podemos aﬁrmar que

tp

√︀

np(1 − p) =

−

e

⎛

⎜⎜⎜⎜⎝1 −

tp
np(1 − p)

√︀

+

t2p2
2np(1 − p)

+ · · ·

⎞

⎟⎟⎟⎟⎠

e

t(1 − p)
np(1 − p) =

√︀

e

⎛

⎜⎜⎜⎜⎝1 + t(1 − p)
np(1 − p)

√︀

+ t2(1 − p)2
2np(1 − p)

+ · · ·

⎞

⎟⎟⎟⎟⎠

Utilizando as igualdades (59) e (60) temos que,

62

(56)

(57)

(58)

(59)

(60)

−
(1 − p)e

tp

√︀
np(1 − p) + pe

t(1 − p)
√︀
np(1 − p) = (1 − p)

⎛

+

t2p2
2np(1 − p)

+ · · ·

⎞

⎟⎟⎟⎟⎠

+ t2(1 − p)2
2np(1 − p)

⎞

+ · · ·

⎟⎟⎟⎟⎠
+ tp(1 − p)
np(1 − p)

√︀

+ · · ·

⎛

√︀

√︀

+ p

tp
np(1 − p)

⎜⎜⎜⎜⎝1 −
⎜⎜⎜⎜⎝1 + t(1 − p)
np(1 − p)
= (1 − p) + p − tp(1 − p)
np(1 − p)
+ t2p(1 − p)2
2np(1 − p)

√︀

+ t2p2(1 − p)
2np(1 − p)
= 1 + p(1 − p)t2
2np(1 − p)
= 1 + t2
2n

+ · · ·

+ · · ·

Capítulo 4. Teorema Central do Limite

63

Elevando esta última igualdade a n-ésima potência, poderemos escrever EetY

como

EetY = (1 + t2
2n

+ · · · )n

= (1 +

t2
2
n

+ · · · )n n→∞−−−→ e

t2
2 .

Ora, as variáveis discretas X e Y possuem a mesma distribuição, ambas são
binomiais, e também a função característica da variável Y se aproxima da função de
distribuição normal padrão. Através do Teorema da Unicidade, citada no Capítulo
3, podemos concluir que a distribuição da variável X também se aproxima de uma
distribuição normal padrão ﬁnalizando assim a demonstração.

(cid:4)

4.2 O Teorema Central do Limite de Lindeberg

Um matemático ﬁnlandês, por volta de 1920, desenvolve um método capaz de
generalizar a aproximação normal a partir de qualquer distribuição de probabilidade e
não só com variáveis aleatórias identicamente distribuídas. Seu nome é Jarl Waldemar
Lindeberg (1876 - 1932) e este método é o teorema limite sob uma condição muito forte
conhecida por Condição de Lindeberg, descrita logo abaixo na igualdade (61).
∫︁

⎡

∀(cid:15) > 0, lim
n→∞

n∑︁

⎢⎢⎢⎢⎢⎣

1
s2
n

k=1

|x−µ

|>(cid:15)sn

k

⎤
⎥⎥⎥⎥⎥⎦
(x − µk)2dFk(x)

= 0.

(61)

n, a soma das variâncias de Xk, com k = 1, 2, · · · , as parcelas de s2

n são do

Sendo s2
k, ou seja,

tipo σ2

s2
n

= σ2
1

+ σ2
2

+ · · · + σ2
n

.

A Condição de Lindeberg mostra que, para valores de n suﬁcientemente grandes, a
inﬂuência de uma parcela σ2
k é muito pequena não afetando a característica da soma s2
n.
Como as variâncias não possuem distribuições idênticas então utilizamos a parcela de
maior variância para mostrar este fato. Em outras palavras,

σ2
k
s2
n

max
1≤k≤n

n→∞−−−→ 0.

(62)

Antes de apresentarmos a prova do Teorema Central do Limite de Lindeberg,
precisamos enunciar dois lemas e realizar a veriﬁcação da Condição de Lindeberg para
a convergência (63) descrita logo abaixo, onde

Sn − ESn
sn

D−→ N(0, 1).

(63)

O primeiro lema trata da ordem de séries do tipo

∑︀

k kλ.

Capítulo 4. Teorema Central do Limite

64

Lema 4.1 Para λ > 0,

1
nλ+1

n∑︁

k=1

k

λ n→∞−−−→ 1

λ + 1

,

de maneira que

∑︀n

k=1 kλ é da ordem de nλ+1.

Demonstração:

Sejam xλ e kλ duas potências atendendo a seguinte condição,

(cid:111) xλ ≤ kλ, para k − 1 ≤ x ≤ k e

∫︁ k

k−1

λ

x

dx ≤

∫︁ k

k−1

λ

k

dx = k

λ

x|k−1

k

= k

λ.

(cid:111) xλ ≥ kλ, para k ≤ x ≤ k + 1 e

∫︁ k+1

λ

x

dx ≥

∫︁ k+1

k

k

λ

−k

dx = k

λ

x|k

k+1

= k

λ.

Com isso, podemos escrever a seguinte desigualdade,

∫︁ k

k−1

λ

x

dx ≤ k

λ ≤

∫︁ k+1

k

λ
x

dx.

(64)

Fazendo o valor de k variar de 1 até n, a desigualdade (64) pode ser reescrita da

seguinte forma

∫︁ n

0

λ
x

dx ≤

n∑︁

k=1

λ ≤

k

A integral da esquerda em (65) é igual a

∫︁ n+1

1

nλ+1
λ + 1

λ
x

dx.

. Isto é,

(65)

∫︁ n

0

λ
x

dx = xλ+1
λ + 1

⃒⃒⃒⃒⃒

n

0

= nλ+1
λ + 1

.

A integral da direita em (65) é igual a

(n + 1)λ+1 − 1
λ + 1

. Ou seja,

∫︁ n+1

1

λ
x

dx = xλ+1
λ + 1

⃒⃒⃒⃒⃒

1

n+1

= (n + 1)λ+1 − 1
λ + 1

.

Temos ainda que

(n + 1)λ+1 − 1
λ + 1

≤ (n + 1)λ+1
λ + 1

.

Capítulo 4. Teorema Central do Limite

65

Assim, a desigualdade (65) será reescrita como

nλ+1
λ + 1

≤

n∑︁

k=1

k

λ ≤ (n + 1)λ+1

λ + 1

.

Dividindo-se todos os membros da desigualdade por nλ+1, o resultado será

1
λ + 1

≤ 1
nλ+1

n∑︁

k=1

k

λ ≤ 1

λ + 1

)︂λ+1

.

(︂n + 1
n

Para concluirmos, precisamos mostrar que

1
λ + 1

(︂ n + 1
n

lim
n→∞

)︂λ+1

= 1

λ + 1

.

Sendo assim,

1
λ + 1

(︂n + 1
n

lim
n→∞

)︂λ+1

)︂λ+1

)︂λ+1

(︂n + 1
n
1 + 1
n

(︂

lim
n→∞

lim
n→∞

.

=

=

=

1
λ + 1
1
λ + 1
1
λ + 1

Após a prova do Lema 4.1, podemos veriﬁcar a Condição de Lindeberg para a

convergência normal dada em (63).

Sejam X1
de parâmetros -n e n.

, X2

, · · · , variáveis independentes onde Xn possui distribuição uniforme

Admitindo-se que µk = 0, a variância de Xk é dada por

∫︁

=

σ2
k

(x − µk)2dFk(x).

Como a variável X é uniformemente distribuída então dFk(x) = fk(x)dx = 1
2k

para µk = 0, podemos escrever

dx e,

∫︁

(x − µk)2dFk(x) =

(x − 0)2 1
2k
∫︁ k

dx

x2dx

k

−k
x3
3

⃒⃒⃒⃒⃒

−k

∫︁ k

−k
= 1
2k
= 1
2k
= k2
3

Capítulo 4. Teorema Central do Limite

e

Para 1 ≤ k ≤ n e (cid:15) > 0,

=

s2
n

n∑︁

k=1

=

σ2
k

n∑︁

k=1

.

k2
3

66

(66)

∫︁

|x|>(cid:15)sn

∫︁

x2dFk(x) =

x2I|x|>(cid:15)sn(x)dFk(x) = 1
2k

∫︁ k

−k

x2I|x|>(cid:15)sn(x)dx.

(67)

Pela deﬁnição de função de densidade uniforme, f(x) assume valor zero para
valores fora do intervalo fechado [-k, k] logo, a integral da direita na igualdade (67)
tende a zero quando n tende ao inﬁnito. Pela igualdade (66),

s2
n
n3

= 1
n2+1

n∑︁

k=1

k2
3

= 1
3

⎛

⎜⎜⎜⎜⎜⎝

1
n2+1

⎞

⎟⎟⎟⎟⎟⎠

.

k2

n∑︁

k=1

O termo entre parênteses atende a condição do Lema 4.1. Ou seja,

e consequentemente

1
n2+1

n∑︁

k=1

k2 −→ 1
3

,

s2
n
n3

−→ 1
9

.

Para concluirmos, vamos mostrar que

∀(cid:15) > 0, 1
s2
n

∫︁ k

n∑︁

k=1

−k

x2I|x|>(cid:15)sn(x)dx −→ 0.

Note que

s2
n
n2

= s2

n

n3 n. Com isso,
s2
n
n2

lim
n→∞

s2
n
n3 n
s2
n
n3 lim
n→∞

n

= lim
n→∞

= lim
n→∞
= ∞.

Ora, se

s2
n
n2 tende ao inﬁnito então

1
s2
n
n2

tende a zero. Consequentemente,

1
s2
n

∫︁ k

n∑︁

k=1

−k

x2I|x|>(cid:15)sn(x)dx → 0.

(cid:4)

Capítulo 4. Teorema Central do Limite

67

O próximo lema trata-se de uma generalização do Limite de Euler para números
complexos utilizado na demonstração do Teorema 4.1, onde diz que se cn → c então
[︂
1 + cn
n

→ ec.

]︂n

Lema 4.2 Seja cn,k uma sequência de números complexos onde

∑︀n

k=1 cn,k

n→∞−−−→ c. Se

e, sendo M uma constante que não está em função de n,

|cn,k| n→∞−−−→ 0

max
1≤k≤n

então,

n∑︁

k=1

|cn,k| ≤ M < ∞

n∏︁

(1 + cn,k)

n→∞−−−→ ec.

k=1

Bem, agora conseguimos reunir todos os requisitos necessários para podermos
provar o Teorema Central do Limite de Lindeberg. O processo de demonstração segue
alguns caminhos semelhantes à demonstração do Teorema 4.1 além da utilização do
Lema 4.1 e 4.2.

, · · · , são variáveis aleató-
Teorema 4.3 (Teorema Central do Limite de Lindeberg) X1
rias independentes que não possuem distribuições idênticas. Por isso, a média de Xn é igual a µn
e a variância de Xn é igual a σ2
Sendo Sn = X1

n. Xn possui variância ﬁnita e para algum n, σ2
+ · · · + Xn com variância s2

VarSn, a convergência

n tal que sn =

+ X2

> 0.

, X2

√

n

normal

Sn − ESn
sn

D−→ N(0, 1)

é válida se a Condição de Lindeberg for satisfeita:

∀(cid:15) > 0, lim
n→∞

⎡

⎢⎢⎢⎢⎢⎣

1
s2
n

∫︁

n∑︁

k=1

|x−µ

|>(cid:15)sn

k

⎤
⎥⎥⎥⎥⎥⎦
(x − µk)2dFk(x)

= 0.

Demonstração : Como dito anteriormente, iremos proceder com o mesmo
objetivo apresentado no início da demonstração do Teorema 4.1 , ou seja, vamos concluir
a demonstração quando mostrarmos que :

n→∞−−−→ e

−t2
2 .

(t)

ϕ

Sn − ESn
sn

(68)

Por hipótese, as variáveis são independentes e Sn = X1

+ X2

+ · · · + Xn. Como

EXk = µk,

Capítulo 4. Teorema Central do Limite

68

ϕ

Sn − ESn
sn

(t) = ϕ

∑︀n

k=1

= ϕ

X1

Xk − EXk
sn
(t)ϕ

− µ
1

(t)

(t) · · · ϕ

− µ

2

X2

sn

sn

(t)

Xn − µn
sn

n∏︁

ϕ

=

k=1

n∏︁

k=1

=

(t)

Xk − µk
sn
Xk − µk
sn

it
Ee

Assim, precisamos mostrar que

Xk − µk
sn

it
Ee

n∏︁

k=1

n→∞−−−→ e

−t2
2 .

(69)

Primeiramente, vamos utilizar a fórmula de expansão em série de Taylor dada

por:

eitx =

∞∑︁

n=0

(itx)n
n!

.

A expansão em Série de Taylor de segunda ordem é

eitx ≈

2∑︁

n=0

(itx)n
n!

= (itx)0
0!

+ itx
1!

+ (it ¯x)2
2!

= 1 + itx + θ

1(x)

t2x2
2

,

com |θ

1(x)| < 1,

e a de terceira ordem,

eitx ≈

3∑︁

n=0

(itx)n
n!

+ (itx)2
2!

+ (it ¯x)3
3!

+ itx
1!

= (itx)0
0!
= 1 + itx − t2x2
2

+ θ

2(x)

t3x3
6

,

com |θ

2(x)| < 1.

Dado um (cid:15) > 0 e |x| variando em torno de (cid:15), vamos reescrever eitx como uma

única expressão,

eitx ≈ 1 + itx − t2x2
2
onde r(cid:15)(x) é deﬁnida por duas sentenças em função de x com parâmetro (cid:15), ou

+ r(cid:15)(x),

(70)

seja,

r(cid:15)(x) =

⎧

⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩

(1 + θ

1(x))

θ

2(x)

t2x2
2
t3x3
6

se |x| > (cid:15)

se |x| ≤ (cid:15)

.

Capítulo 4. Teorema Central do Limite

69

Vamos escrever Eeit

Xk

−µ
k
sn através da Expressão (70),

−µ

Xk

k

sn =

Eeit

∫︁

eit

x−µ

k

sn dFk(x) =

∫︁ [︃

1 + it

(︂ x − µk
sn
∫︁

)︂

− t2
2
(︂x − µk
sn
dFk(x).

it

dFk(x) +
(︂x − µk
sn

r(cid:15)

)︂

∫︁

∫︁

=

+

)︂

(︂x − µk
sn

)︂

+ r(cid:15)
∫︁

dFk(x) −

)︂]︃

(︂x − µk
sn
(︂x − µk
sn

t2
2

dFk(x)

)︂

dFk(x)

Pela deﬁnição de função densidade,

∫︁

dFk(x) = 1

e, por linearidade,

r(cid:15)

)︂

(︂x − µk
sn

[︂
1 + θ
1

=

(︂x − µk
sn

)︂]︂ t2
2

(︂x − µk
sn

)︂2

+ θ
2

(︂x − µk
sn

)︂ t3
6

(︂x − µk
sn

)︂3

,

(71)

onde |x − µk| > (cid:15)sn na primeira parcela e |x − µk| ≤ (cid:15)sn na segunda parcela ambas

no segundo membro da igualdade (71).

)︂2

dFk(x) +

∫︁

r(cid:15)

)︂

(︂x − µk
sn

dFk(x)

Portanto,

∫︁

dFk(x) +

∫︁

it

)︂

(︃

(︂x − µk
sn
Xk − µk
sn
[︂

(︂x − µk
t2
sn
2
)︃2
Xk − µk
sn
)︂]︂ (︂x − µk

dFk(x) −
)︃

∫︁

(︃

1 + θ
1

E

− t2
2
(︂x − µk
sn
)︂ (︂x − µk
sn

(︂ x − µk
sn

sn

)︂3

dFk(x).

|x−µ

|>(cid:15)sn

k

θ

2

|x−µ

|≤(cid:15)sn

k

= 1 + itE

∫︁

∫︁

+ t2
2
+ t3
6

)︂2

dFk(x)

Capítulo 4. Teorema Central do Limite

70

Admitindo-se que EXk = µk = 0 e EX2
k

= VarXk = σ2, temos que:

[︂
1 + θ

1

)︂]︂ (︂x − µk

)︂2

dFk(x)

sn

)︂3

dFk(x)

(︃

)︃

Xk − µk
sn

− t2
2

E

1 + itE
∫︁

(︃

)︃2

Xk − µk
sn
(︂x − µk
sn
)︂ (︂x − µk
sn

(︂x − µk
sn
− t2
2s2
n
(︂x − µk
sn
)︂ (︂x − µk
sn

(︂x − µk
sn

)︃

1

+ t2
2
+ t3
6

|>(cid:15)sn

k

|x−µ

∫︁

θ

2

|x−µ
(︃

k

|≤(cid:15)sn
EXk − µk
sn
[︂
1 + θ

|x−µ

|>(cid:15)sn

k

∫︁

θ

2

= 1 + it
∫︁

+ t2
2
+ t3
6

− 2EXkµk + µ2
k)

(EX2
k
)︂]︂ (︂x − µk

)︂2

dFk(x)

sn

)︂3

dFk(x)

= 1 −

+ t3
6s2
n

= 1 −

k

|x−µ
t2σ2
k
2s2
n
∫︁

∫︁

|≤(cid:15)sn
+ t2
2s2
|x−µ
n
(︂x − µk
sn

|≤(cid:15)sn

k

k

|x−µ
t2σ2
k
2s2
n

+ en,k.

[︂

1 + θ

1

)︂]︂

(︂x − µk
sn

(x − µk)2dFk(x)

(72)

)︂

(︂ x − µk
sn

2

(x − µk)2dFk(x)

|>(cid:15)sn
)︂

θ

Vamos analisar o resto en,k e reescrevê-la de forma a estar aplicando a Condição de
Lindeberg e, com isso, simpliﬁcar a igualdade (72).

Observe que |θ
≤ (cid:15) e que,

⃒⃒⃒⃒⃒

Xk − µk
sn

⃒⃒⃒⃒⃒

1(x)| < 1, logo 0 < 1 + θ

1(x) < 2 e que |Xk − µk| ≤ (cid:15)sn. Sendo assim,

|θ

2(x)| < 1 ⇐⇒ −(cid:15) < (cid:15)θ

2(x) < (cid:15),

(cid:15) > 0.

Com isso,

∫︁

∫︁

∫︁

+

|en,k| = t2
2s2
n
|t|3
6s2
n
≤ t2
2s2
n
∫︁
≤ t2
s2
n

|x−µ

|>(cid:15)sn

k

|x−µ

|≤(cid:15)sn

k

|x−µ

|>(cid:15)sn

k

⃒⃒⃒⃒⃒
⃒⃒⃒⃒⃒

1 + θ
1

x − µk
sn

)︂⃒⃒⃒⃒⃒

(︂x − µk
sn
(︂x − µk
sn

θ
2

⃒⃒⃒⃒⃒

⃒⃒⃒⃒⃒

2(x − µk)2dFk(x) +

(x − µk)2dFk(x)

)︂⃒⃒⃒⃒⃒

(x − µk)2dFk(x)

|t|3
6s2
n
∫︁

∫︁

|x−µ
k

|≤(cid:15)sn

(cid:15)(x − µk)2dFk(x)

(x − µk)2dFk(x).

|x−µ

|≤(cid:15)sn

k

(cid:15)|t|3
6s2
n

(x − µk)2dFk(x) +

|x−µ

|>(cid:15)sn

k

Continuando,

n∑︁

k=1

|en,k| ≤ t2 1
s2
n

∫︁

n∑︁

k=1

|x−µ

|>(cid:15)sn

k

(x − µk)2dFk(x) +

(cid:15)|t|3
6

1
s2
n

∫︁

n∑︁

k=1

|x−µ

|≤(cid:15)sn

k

(x − µk)2dFk(x).

Capítulo 4. Teorema Central do Limite

71

A Condição de Lindeberg nos diz que

⎡

⎢⎢⎢⎢⎢⎣

1
s2
n

lim
n→∞

∫︁

n∑︁

k=1

|x−µ

|>(cid:15)sn

k

⎤
⎥⎥⎥⎥⎥⎦
(x − µk)2dFk(x)

= 0

1
s2
n

∫︁

n∑︁

k=1

|x−µ
k

|≤(cid:15)sn

(x − µk)2dFk(x) = 1.

onde,

Sendo assim, quando n for suﬁcientemente grande,

n∑︁

k=1

|en,k| ≤

(cid:15)|t|3
6

.

Precisamos escolher uma sequência convergente de epsilons, do tipo (cid:15)j, com j =
1, 2, 3, · · · , tal que esta sequência seja simples de manipular e convirja para zero. Sendo
assim, tomemos (cid:15) = 1
m

.

Se (cid:15) = 1
m

então, para m > n, existe um nm tal que

n∑︁

k=1

|en,k| ≤

|t|3
6m

,

onde os restos en,k com nm ≤ n ≤ nm+1 são baseados no termo geral

Como a sequência (cid:15) = 1
m

aﬁrmar que:

converge para zero e

∑︀n

k=1

|en,k| ≤

.

1
m
|t|3
6m

|en,k| n→∞−−−→ 0.

n∑︁

k=1

Dando uma olhada na Expressão (69), podemos escrever que

então, podemos

(73)

n∏︁

k=1

Eeit

Xk

−µ
k

sn =

(︃

n∏︁

k=1

1 −

t2σ2
k
2s2
n

)︃

+ en,k

.

Para provarmos a convergência (69), precisamos validar o Lema 4.2. Para isso,

vamos fazer cn,k = − t2σ2

k
2s2
n

Primeiramente, veremos se

+ en,k e c = − t2
2 .
∑︀n
k=1 cn,k ≤ M com M < ∞. Então,
)︃

(︃

n∑︁

cn,k ≤

n∑︁

k=1

k=1
n∑︁

−

≤

+ en,k

n∑︁

en,k

+

k=1
≤ − t2
2

k=1
n∑︁

+

k=1

en,k −→ −t2
2

,

−

t2σ2
k
2s2
n
t2σ2
k
2s2
n
σ2
k
s2
n

n∑︁

k=1

Capítulo 4. Teorema Central do Limite

72

pois

∑︀n

k=1

σ2
k
s2
n

= 1, já que s2
n
∑︀n

= σ2
1

+ σ2
2

+ . . . + σ2

n, e

∑︀n

k=1 en,k → 0.

Com isso,

k=1 cn,k é limitado de maneira uniforme, o que quer dizer que existe,

pelo menos um M < ∞ onde

∀n,

n∑︁

k=1

cn,k ≤ M.

Agora, basta provarmos que o máximo de cn,k tende a zero quando n tende ao

inﬁnito. Logo,

max
1≤k≤n

|cn,k| ≤ max
1≤k≤n

⃒⃒⃒⃒⃒⃒

−

t2σ2
k
2s2
n

+ en,k

⃒⃒⃒⃒⃒⃒

≤ max
1≤k≤n

+ max
1≤k≤n

|en,k|

t2σ2
k
2s2
n
σ2
k
s2
n

≤ t2
2

max
1≤k≤n

+ max
1≤k≤n

|en,k|.

(74)

A primeira parcela da Expressão (74) tende a zero pelo princípio da Condição
σ2
k
s2
n

de Lindeberg que diz que para n tendendo ao inﬁnito o máximo dentre as parcelas

tende a zero. A segunda parcela também tende a zero pela convergência (73).

Portanto, pelo Lema 4.2, podemos concluir que

(︃

n∏︁

k=1

1 −

t2σ2
k
2s2
n

)︃

+ en,k

n→∞−−−→ e

−t2
2 ,

concluindo assim a demonstração do teorema limite de Lindeberg.

(cid:4)

O Teorema Central do Limite enunciado e demonstrado por Lindeberg é consi-
derada até hoje o Teorema Central do Limite mais genérico produzido. Isso porque a
condição de Lindeberg é satisfeita em todos os outros modelos de TCL2.

O próximo capítulo abordará a utilização do Teorema Central do Limite através

de várias situações problemas.

2 Considerando que as variáveis são independentes entre si

73

5

Aplicando o Teorema Central do Limite

Vamos abordar aqui situações práticas onde o Teorema Central do Limite faz jus
a sua importância em diferentes áreas do conhecimento humano como nas engenharias,
na área de saúde, economia, dentre outros tantos que surge a partir da necessidade
humana de colher informações para realizar planejamentos estratégicos e na tomada de
decisões. Outro cenário em que o TCL atua são nas situações cotidianas ou corriqueiras
pelo qual pessoas comuns podem se deparar tal como uma criança jogando um jogo de
trilha com os amigos e um deles com o seu próprio dado, através de seus lançamentos,
começa a sair apenas números altos como cinco ou seis. Numa única partida as outras
crianças podem não perceber. Porém, com o decorrer das partidas, eles com certeza
notarão algo de estranho naquele dado que sai mais a face cinco ou a seis comparado aos
outros dados, ou seja, um número maior de jogadas em algumas partidas mostrou-se
suﬁciente para apresentar desconﬁança em relação ao dado do coleguinha. Vejam o
Teorema Central do Limite em ação, na sua forma mais intuitiva, mostrando-se presente
e "dizendo": "estou aqui, conheçam-me pois sou muito útil!".

Este capítulo será dividido em duas seções distintas. A primeira seção tratará de
situações problemas envolvendo diferentes distribuições de probabilidade atentando-se
a justiﬁcativa que um dos objetivos do uso do TCL é aproximar diferentes distribuições
para a distribuição normal inclusive propondo, em alguns casos a inviabilidade de
se utilizar função de densidade de probabilidade característica da distribuição em
questão. A segunda seção apresentará outras situações problemas resolvida apenas pela
aproximação normal, a ﬁm de enriquecer o capítulo, abrangendo a área de atuação do
TCL.

5.1 Primeiras aplicações

Nesta primeira seção, o principal objetivo é mostrar que, através do Teorema
Central do Limite, podemos aproximar uma distribuição discreta ou uma distribuição
contínua para uma distribuição normal padrão utilizando a variável Z, descrita na

Capítulo 5. Aplicando o Teorema Central do Limite

74

Seção 2.5. Não haverá detalhamento nas distribuições apresentadas pois, todos estes
conceitos estão no Capítulo 2. Vamos apresentar aqui quatro situações práticas, as duas
primeiras envolvem variáveis aleatórias discretas e as duas últimas, variáveis aleatórias
contínuas. O intuito é resolver as questões de duas maneiras distintas uma é através
da função de distribuição encontrando as probabilidades reais e a outra é aplicando o
Teorema Central do Limite e aproximando normalmente tais distribuições. Em seguida,
ao compararmos estes resultados devemos veriﬁcar quão próximos eles são.

Vamos ao primeiro exemplo. Aqui temos uma situação envolvendo uma variável

aleatória discreta de distribuição binomial.

Exemplo 5.1 Baseado em dados locais, a empresa WXY constatou que o número de mulheres
grávidas correspondiam a, mais ou menos, 28% da população de mulheres daquele local. Baseado
nesta informação, se a empresa coletasse uma amostra aleatória com 120 mulheres, qual seria a
probabilidade de que, pelo menos, 45 delas estivessem grávidas?

Solução : Vamos denominar de X a variável aleatória referente ao número de
mulheres grávidas dentro da amostra coletada. Podemos notar que as características de
X segue uma distribuição binomial de parâmetros n = 120 e p = 0.28, cuja função de
densidade é dada por

f (x) =

(︃

)︃
n
x

px(1 − p)n−x

x = 0, 1, 2, · · · , n.

Como visto no Capítulo 2,

f (x) = P(X = x) porém, precisamos encontrar a

probabilidade de, no mínimo, 45 mulheres estarem grávidas, ou seja, P(X ≥ 45).

Para calcularmos P(X ≥ 45) temos duas opções:

1. P(X ≥ 45) = P(X = 45) + P(X = 46) + · · · + P(X = 120)

2. P(X ≥ 45) = 1 − P(X < 45) = 1 − [P(X = 44) + P(X = 43) + · · · + P(X = 0)]

Neste caso a resolução será feita de forma computacional. Com isso, P(X ≥ 45) = 0.0151.

Com a sua média sendo µX = 33.6 e sua variância, σ2
X

= 24.2 com desvio padrão
σX = 4.92, vamos aplicar o Teorema Central do Limite já que 120 mulheres foram
pesquisadas e esse valor é suﬁcientemente grande para tal aplicação.

Assim, vamos calcular P(X ≥ 45) através da aproximação normal pela variável Z.
Lembrando que a variável aleatória Z, para uma aproximação binomial, é escrita como
Z = X − np
np(1 − p)

√︀

.

Capítulo 5. Aplicando o Teorema Central do Limite

75

Com isso, temos que

e

Z = X − np
np(1 − p)

√︀

= 45 − 33.6
4.92

= 2.32

P(X ≥ 45) = 1 − P(X ≤ 45) = 1 − P(Z ≤ 2.32).

Pela tabela z da Figura 3,

1 − P(Z ≤ 2.32) = 1 − 0.9898 = 0.0102.

Portanto, a probabilidade é que, pelo menos, 1.02% das mulheres estejam
grávidas. A Figura 5 ilustra graﬁcamente como a probabilidade refere-se a área cinza
sob a curva normal.

Figura 5 – Probabilidade de 1.02% de mulheres grávidas

O próximo exemplo retrata uma aplicação da distribuição de Poisson. Adaptação

de (MARTINS, 2010).

Exemplo 5.2 Um consultório médico tem um atendimento médio diário de 10 pacientes. Num
dia normal de funcionamento, determine a probabilidade de atender, no máximo, 6 pacientes.

Solução : Seja a variável X a quantidade de atendimentos em um dia de
funcionamento na clínica. A probabilidade de atender, no máximo, 6 pacientes é
representado por P(X ≤ 6).

Primeiramente, vamos calcular a probabilidade através de sua função de pro-
, de parâmetro λ = 10. Atender, no

babilidade encontrada no Capítulo 2, f (x) = e−λλx
x!
máximo, 6 pessoas quer dizer que x ≤ 6.

Encontrar a probabilidade de, no máximo, 6 atendimentos é o mesmo que
encontrar a soma das probabilidades para x menores ou iguais a 6, x = 0, 1, 2, 3, 4, 5, 6,
ou seja,

P(X ≤ 6) = P(X = 0) + P(X = 1) + P(X = 2) + P(X = 3) + P(X = 4) + P(X = 5) + P(X = 6)

Capítulo 5. Aplicando o Teorema Central do Limite

ou,

P(X ≤ 6) =

6∑︁

k=0

P(X = k).

76

(75)

Tais probabilidades serão calculadas individualmente, como veremos abaixo.

Para isso, temos que e−10 = 0, 00004539.

Para x = 0,

Para x = 1,

Para x = 2,

Para x = 3,

Para x = 4,

Para x = 5,

Para x = 6,

P(X = 0) = e−10100

0!

= 0, 000045.

P(X = 1) = e−10101

1!

= 0, 00045.

P(X = 2) = e−10102

2!

= 0, 002269.

P(X = 3) = e−10103

3!

= 0, 007565.

P(X = 4) = e−10104

4!

= 0, 018912.

P(X = 5) = e−10105

5!

= 0, 037825.

P(X = 6) = e−10106

6!

= 0, 063041.

Agora vamos aplicar estes valores na igualdade (75).

P(X ≤ 6) = 0, 000045 + 0, 000453 + 0, 002269
+ 0, 007565 + 0, 018912 + 0, 037825
+ 0, 063041 = 0, 13011.

Aproximadamente, há 13% de probabilidade de haver, no máximo, 6 atendimen-

tos num dia normal de funcionamento.

Em seguida, vamos usar a aproximação da distribuição de Poisson por uma
normal através do Teorema Central do Limite. Lembremos que, para podermos
aproximar normalmente a distribuição de Poisson, devemos ter λ ≥ 5 . A média e a
variância da distribuição de Poisson neste caso são

µ = λ = 10

Capítulo 5. Aplicando o Teorema Central do Limite

77

e

σ =

√

λ =

√

10.

O valor de x será aproximado para um valor decimal pois estamos no campo dos
reais através da transformação de uma variável aleatória discreta para uma contínua.
Com isso, vamos fazer x = 6.2.

Seja Z a variável aleatória normalizada de X. Assim,

P(X ≤ 6.2) = P

(︂
Z ≤

)︂

x − µ
σ

(︃

= P

)︃

Z ≤ 6.2 − 10√
10

= P(Z ≤ −1.20).

Através da propriedade P(Z ≤ −z) = 0.5 − P(Z ≤ z) aplicada na tabela z,

P(Z ≤ −1.20) = 0.1151.

A Figura 6 ilustra a área encontrada que é a probabilidade calculada pela

aproximação normal.

Figura 6 – Probabilidade de ocorrer até 6 atendimentos.

Assim, há uma probabilidade de 11.51% de ocorrer, no máximo, 6 atendimentos

num dia normal de funcionamento.

Neste próximo exemplo, apresentamos uma situação envolvendo uma variável
aleatória com distribuição uniforme contínua. Exemplo adaptado de (FARIAS, 2009).

Exemplo 5.3 O senhor Antônio é um investidor e, dentre os diferentes ramos de atuação, vai
investir em lotes de terra para revenda ou construção. Ele está participando de um leilão e está
interessado em dar um lance de um lote de terra. Há um outro licitante com os mesmos interesses
que o senhor Antônio. O leiloeiro comunicou que, pelas regras estabelecidas para este leilão, o
lance mais alto acima de R$ 100 000.00 será aceito. Vamos supor que o lance dado pelo outro
licitante interessado nesse lote de terra seja uma variável aleatória uniformemente distribuída
entre R$ 100 000.00 e R$ 150 000.00. Sabendo disso,

(a) se o senhor Antônio der um lance de R$ 120 000.00, qual é a probabilidade dele ﬁcar com o

lote?

Capítulo 5. Aplicando o Teorema Central do Limite

78

(b) se o senhor Antônio der um lance de R$ 140 000.00, qual é a probabilidade dele ﬁcar com o

lote?

Solução :

(a) Seja X uma variável aleatória que representa o lance dado pelo senhor Antônio.
Podemos observar que esta variável possui distribuição uniforme contínua de
parâmetros a = R$ 100 000.00 e b = R$ 150 000.00. No Capítulo 2 encontram-se a
função de distribuição, a média e a variância de X. Como a função de distribuição
é dada por:

F(x) = x − a
b − a

,

vamos encontrar P(X = x), com x = 120 000.
Como X é uma variável aleatória contínua, P(X = x) = 0. Por deﬁnição de
distribuição uniforme contínua, a ≤ x ≤ b logo, vamos encontrar a probabilidade
de um lance estar entre R$ 100 000.00 e R$ 120 000.00, ou seja, P(X ≤ 120 000).

P(X ≤ 120 000) = 120 000 − 100 000
150 000 − 100 000

= 20 000
50 000

= 0.4.

Assim, com um lance de R$ 120 000.00 você tem uma chance de 40% em ﬁcar com
o lote.

Agora, a resolução dar-se-á através da aproximação normal pelo Teorema Central
do Limite. Vamos encontrar o valor da média e do desvio padrão de X.

µ = a + b
2

= 100 000 + 150 000
2

= 125 000

√︂

σ =

(b − a)2
12

=

√︂

(150 000 − 100 000)2
12

= 50 000√
12

= 14 433.7567.

e

Assim,

P(X ≤ 120 000) = P

(︂

Z ≤ 120 000 − 125 000

14 433.7567

)︂

= P(Z ≤ −0.35) = 0.3632.

A Figura 7 ilustra a transformação realizada na variável X e a probabilidade em
forma de área sob a curva normal.

Capítulo 5. Aplicando o Teorema Central do Limite

79

Figura 7 – Probabilidade no lance entre R$ 100 000.00 e R$ 120 000.00

Através da aproximação normal, a chance em ﬁcar com o lote é de 36.32%.

(b) Seguindo os mesmos procedimentos apresentados no item (a), vamos aplicar a

função de distribuição de X para x ≤ 140 000.

P(X ≤ 140 000) = 140 000 − 100 000
150 000 − 100 000

= 40 000
50 000

= 0.8.

Assim, com um lance de R$ 140 000.00 você tem uma chance de 80% em ﬁcar com
o lote.

Agora, a resolução dar-se-á através da aproximação normal pelo Teorema Central
do Limite. Conhecendo o valor da média e do desvio padrão de X, calculado no
item (a), vamos calcular P(X ≤ 140 000). Assim,
Z ≤ 140 000 − 125 000

= P(Z ≤ 1.04) = 0.8508.

P(X ≤ 140 000) = P

)︂

(︂

14 433.7567

Através da aproximação normal, a chance em ﬁcar com o lote é de 85.08%.

A seguir, temos o último exemplo desta seção. Aqui, a situação problema aborda
uma distribuição exponencial e uma característica especíﬁca desta distribuição é a
propriedade de falta de memória1.

Exemplo 5.4 Segundo uma lei conhecida como a lei dos quinze minutos, todas as agências
bancárias tem que atender o cliente em até 15 minutos sob a condição de sofrer sanções judiciais
como advertências ou até multas. Uma agência bancária de grande movimentação, tanto de
pessoas quanto de dinheiro tem o tempo médio de atendimento por cliente de 8 minutos e esse
tempo é uma variável aleatória exponencial.

(a) Determine a função de distribuição de X.

(b) Encontre a probabilidade de um cliente, ao receber sua senha, demorar mais que 15 minutos

para ser atendido.

1

Para consultas, vide (ROSS, 2010).

Capítulo 5. Aplicando o Teorema Central do Limite

80

(c) Encontre a probabilidade de um cliente, ao receber sua senha, demorar mais que 8 minutos

para ser atendido.

(d) Um cliente teve sua senha chamada e já está sendo atendido há 7 minutos. Encontre a

probabilidade de um cliente demorar mais que 15 minutos para ser atendido.

Solução :

(a) A função de distribuição de uma variável aleatória exponencial é dada por

F(x) =

⎧
⎪⎪⎨
⎪⎪⎩

0 se x < 0
se x ≥ 0

1 − e−λx

O parâmetro de λ será extraído da média fornecida pela questão. Ou seja,

µ = 1
λ

= 8 ⇔ λ = 1
8

Logo, a função de distribuição que atende a situação apresentada na questão é

F(x) =

⎧
⎪⎪⎨
⎪⎪⎩

0 se x < 0
se x ≥ 0

1 − e−x/8

(b) Primeiramente, resolver pela função de distribuição encontrada no item (a). Como

x = 15, vamos calcular P(X > 15). Assim,

P(X > 15) = 1 − P(X ≤ 15) = 1 − (1 − e

−15/8) = e

−15/8 = 0.1533.

Logo, a probabilidade de um cliente demorar mais que 15 minutos nesta agência é
de 15.33%.

Agora, através do Teorema Central do Limite, vamos utilizar a variável Z e realizar
uma aproximação normal. Conhecendo a média de atendimento µ = 8 e o seu
desvio padrão

σ =

√︂

1
λ2

=

⎯⎸⎸⎷ 1
1
82

= 8,

vamos calcular P(X > 15). Sendo assim,
P(X > 15) = 1−P(X ≤ 15) = 1−P(Z ≤ 15 − 8

8

)1−P(Z ≤ 0.875) = 1−0.8092 = 0.1908.

Assim, a probabilidade de um cliente demorar mais que 15 minutos nesta agência,
através da aproximação normal, é de 19.08%. A Figura 8 ilustra claramente a área
sob a curva normal como a probabilidade encontrada com a aproximação normal.

Capítulo 5. Aplicando o Teorema Central do Limite

81

Figura 8 – Probabilidade de 19.08% de demorar mais que 15 minutos

(c) Seguindo o mesmo procedimento apresentado no item (b). Primeiramente resolver
pela sua função de distribuição. Como x = 8, vamos calcular P(X > 8). Logo,

P(X > 8) = 1 − P(X ≤ 8) = 1 − (1 − e

−8/8) = e

−1 = 0.3679.

Assim, a probabilidade de um cliente demorar mais que 8 minutos nesta agência é
de 36.79%.

Agora, através do Teorema Central do Limite, vamos utilizar a variável Z e
realizar uma aproximação normal. Conhecendo a média de atendimento µ = 8 e
o seu desvio padrão σ = 8, percebemos que o desvio padrão, numa distribuição
exponencial, possui o mesmo valor que a sua média, vamos calcular P(X > 8).
Com isso,

P(X > 8) = P(X ≥ 8.5) = 1 − P(X < 8.5)
(︂

)︂

Z < 8.5 − 8
= 1 − P
= 1 − P(Z < 0.06) = 1 − 0.5239
= 0.4761.

8

Assim, a probabilidade de um cliente demorar mais que 15 minutos nesta agência,
através da aproximação normal, é de 47.61%.

(d) Neste caso vamos calcular a probabilidade condicional do atendimento ser superior
a quinze minutos mesmo já tendo passado-se sete minutos de atendimento, ou seja,
vamos calcular P(X > 15|X > 7). Para isso precisamos calcular a probabilidade do
tempo do atendimento ser maior do que sete minutos, ou seja, P(X > 7). Assim,

P(X > 7) = e

−7/8 = 0.4169.

Com este dado e o resultado do item (b) temos,

P(X > 15|X > 7) = P(X > 15)
P(X > 7)

= 0.1533
0.4169

= 0.3677.

Capítulo 5. Aplicando o Teorema Central do Limite

82

Comparando este resultado com o do item (c) podemos observar que as probabilidades
são iguais. Em outras palavras, o tempo de duração do atendimento de oito minutos
passado ou não algum tempo de atendimento caracteriza probabilidades iguais. Este
fato refere-se a uma propriedade conhecida como a falta de memória da distribuição
exponencial. Esta propriedade, resumidamente falando, aﬁrma que o tempo restante
para concluir o evento independe do tempo passado desde o inicio do evento. Mais
especiﬁcamente, o tempo restante para concluir o atendimento deste cliente na agência
não está ligado ao tempo decorrido desde o início do atendimento, ou seja, a probabili-
dade do cliente ser atendido num tempo superior a quinze minutos não depende dos
sete minutos de atendimento já decorridos.

Eis alguns comentários a respeito dos exemplos desta seção e suas formas de
resolução. Podemos observar que os resultados obtidos através da função de distribuição
e da aproximação normal são próximos e essa proximidade tende a aumentar quando o
valor do parâmetro populacional cresce, resumindo, quanto maior o valor do parâmetro
mais próximo os resultados serão. No Exemplo 5.2, ao aumentarmos o valor do
parâmetro λ por exemplo, para λ = 20, vamos obter, aproximadamente, 0.026% através
da função de densidade e 0.09% pela aproximação normal, ou seja, os valores tendem a
ﬁcar mais próximos, graças ao Teorema Central do Limite pois proporciona um alto
grau de conﬁabilidade nos resultados.

Outro ponto a ser considerado é praticidade da aproximação normal sobre a
função de probabilidade, isto é, com poucas operações é possível se chegar ao resultado
esperado. Para exemplos que envolvam funções exponenciais, como os Exemplos 5.2 e
5.4, para uma resolução realizada manualmente, mesmo com o uso de uma calculadora
cientíﬁca por exemplo, quanto maior o valor de λ, mais inviável vai ﬁcando o cálculo a
ponto de ser resolvido apenas de forma computacional com software especíﬁcos.

Estes comentários expressam a importância do Teorema Central do Limite nas
aplicações acima, nas aplicações da próxima seção e do próximo capítulo. Na verdade,
em todas as situações onde podemos aplicá-lo.

5.2 Outras aplicações

As situações problemas apresentadas aqui não serão resolvidas pela função de
distribuição de suas respectivas variáveis e pela aproximação normal como ocorreu na
Seção 5.1. Aqui, a forma de resolução será através da aproximação normal, ampliando e
reforçando o emprego do Teorema Central do Limite. Esta seção contém três exemplos
e cada um deles faz referências a diferentes área de atuação humana.

Neste primeiro exemplo, temos uma questão onde não se conhece a função de
distribuição da variável porém a variância é conhecida e como n ≥ 30, a utilização do

Capítulo 5. Aplicando o Teorema Central do Limite

83

Teorema Central do Limite é indispensável.

Exemplo 5.5 Uma empresa vende caixas com biscoitos e, quando lhe é solicitado, envia-as pelo
correio. Para as evitar pesar, cobra sempre o valor de portes de correio correspondente a admitir
que qualquer caixa pesa 1445g. Cada caixa leva 80 biscoitos e o peso da embalagem plástica é
desprezável. Se soubermos que o peso de cada biscoito é variável mas que em média pesa 18g
com um desvio padrão de 5g, determine a probabilidade do valor pago em portes de correio com o
envio de uma caixa ser inferior ao valor que pagaria, caso a caixa fosse pesada.

Solução : Vamos considerar duas variáveis aleatórias X e Y. X é uma variável
com distribuição desconhecida que representa o peso, em gramas, de cada biscoito com
µX = 18 e σX = 5. Y é uma variável dependente de X, ou seja,

Y =

80∑︁

k=1

Xk,

com n = 80,

onde Y possui a mesma distribuição de X e µY = nµX e σY = σX

√

n.

O valor pago em portes de correio com o envio de uma caixa ser inferior ao
valor que pagaria, caso a caixa fosse pesada signiﬁca que Y ≥ 1445. A probabilidade de
acontecer é P(Y ≥ 1445).

Para n = 80, o Teorema Central do Limite aproxima a distribuição de Y para uma

distribuição normal reduzida. Sendo µY = 1440 e σY = 20
z ≥ 1445 − µY
σY
z ≥ 1445 − 1440
20
)︃

P(Y ≥ 1445) = P

= P

√

5

)︃

(︃

(︃

(︃

)︃

√

5 temos,

= P

z ≥ 1
√
4

5
= P(z ≥ 0.11).

Observando a tabela z de distribuição normal reduzida, temos que

P(z ≥ 0.11) = 0.4562.

Portanto, a probabilidade de pagar menos em portes do correio que na pesagem
da caixa é de 45.62%. Graﬁcamente, através da Figura 9, podemos observar a área cinza
sob a curva normal referente a probabilidade calculada pela aproximação normal.

O exemplo seguinte trabalha diretamente com duas distribuições, uma é a
distribuição normal e a outra é desconhecida. Como a quantidade analisada é o
questionamento do problema, assumimos essa quantidade igual ou superior a 30 para

Capítulo 5. Aplicando o Teorema Central do Limite

84

Figura 9 – Probabilidade em se pagar menos em portes do correio que através do peso

da caixa.

aplicarmos o Teorema Central do Limite. Este exemplo é uma adaptação de (ROSS,
2010).

Exemplo 5.6 Numa ﬁrma de construção, alguns engenheiros analisam um vão de uma ponte e
acreditam que o peso suportado, sem afetar a estrutura, é uma variável normalmente distribuída
de média 400 e variância 1600. Analisando que um carro possua peso com média 3 e variância
0.09 eis a questão: que quantidade destes carros é necessária para que a probabilidade de haver
algum dano na estrutura desse vão da ponte seja maior que 0.1?

Solução : Vamos considerar duas variáveis aleatórias X e Y. X é uma variável
com distribuição normal que representa o peso, em toneladas, de um vão da ponte.
Possui média 400 (µX = 400) e desvio padrão 40 (σX = 40). A variável Y, com distribuição
desconhecida, representa o peso, em toneladas, de um carro que passa pela ponte.
Possui média 3 e desvio padrão 0.3, ou seja, µY = 3 e σY = 0.3.

Uma terceira variável V que representa o peso, em toneladas, de uma quantidade

n de carros sobre o vão da ponte em questão é tal que

V =

n∑︁

k=1

Yk,

com a mesma distribuição de n com média igual a nµY e desvio padrão, nσY.

O número de carros tal que a probabilidade de haver algum dano na estrutura

desse vão da ponte seja maior que 0.1 é dada por

P(X ≤ V) > 0.1.

Pelas médias das variáveis n e Y percebemos que o número de carros será grande
o suﬁciente para utilizarmos a aproximação normal através do Teorema Central do

Capítulo 5. Aplicando o Teorema Central do Limite

85

Limite. Ou seja, através da aproximação a uma distribuição normal reduzida temos que

P(X ≤ V) = P(z ≤

∑︀n

k=1 Yk − 400
40

) > 0.1.

Na tabela z, de distribuição normal, o valor da normal reduzida, cuja probabili-

dade é de 0.1, é igual a -1.28. Com isso,

P(z ≤

∑︀n

k=1 Yk − 400
40

) > 0.1. ⇐⇒

⇐⇒

⇐⇒

> −1.28

Yk = −1.28 x 40 + 400

∑︀n

k=1 Yk − 400
40

n∑︁

k=1
n∑︁

k=1

Yk = 348.8.

Encontramos o somatório do peso dos n carros. Para encontrarmos o total de

carros vamos utilizar a média da variável V, isto é,

µV = 348.8 ⇐⇒ 3n = 348.8 ⇐⇒ n = 116.3 ⇐⇒ n ≈ 117.

Assim podemos dizer que o número mínimo é de 117 carros.

Este último exemplo traz uma situação de variáveis com distribuição desconhe-
cida. Aqui, o Teorema Central do Limite se faz presente pela quantidade ser maior ou
igual a 30. Traduzido de (DEKKING, 2005).

Exemplo 5.7 Uma indústria fabrica elos de metais para a confecção de correntes. O laboratório
de pesquisa da indústria modela o comprimento, em cm, de um elo pela variável aleatória X, com
o valor esperado E[X] = 5 e variância Var[X] = 0.04. O comprimento de um elo é deﬁnido de tal
maneira que o comprimento de uma corrente é igual à soma dos comprimentos de seus elos. A
indústria vende correntes com 50 metros de comprimento. Para maior garantia, 1002 elos são
usados para essas correntes. A indústria garante que a corrente não é menor do que 50 metros.
Se, por um acaso, uma corrente for muito curta, o cliente é reembolsado, e uma nova corrente lhe
é dado gratuitamente.

(a) Determinar uma estimativa de probabilidade de que, para uma corrente de pelo menos 50

metros, mais de 1002 elos são necessários.

(b) O departamento de vendas da indústria percebe que ele tem que entregar um monte de
correntes grátis e pede ao laboratório de pesquisa que está errado. Após mais investigações,
os relatórios do laboratório de pesquisa para o departamento de vendas informam que o
valor esperado 5 (cm) é incorreto, e que o valor correto é 4.99 (cm). Você acha que era
necessário comunicar uma mudança tão pequena deste valor?

Capítulo 5. Aplicando o Teorema Central do Limite

86

Solução : Para resolver esta situação primeiramente devemos entender o papel
das variáveis aleatórias participantes. Para isso, temos X como a primeira variável
representando o comprimento, em centímetros, de cada elo da corrente. O enunciado
da questão nos diz que o comprimento de um elo é deﬁnido de tal maneira que o
comprimento de uma corrente é igual à soma dos comprimentos de seus elos. Assim,
temos outra variável, em função de X, representada por Y designando a soma dos
comprimentos de seus elos na formação de uma corrente, ou seja,

Y =

n∑︁

k=1

Xk,

onde n é o números de elos necessários numa corrente de 50 metros.

(a) Devemos encontrar a probabilidade de que, numa corrente de 50 metros, mais
de 1002 elos sejam necessários. Reescrevendo esta aﬁrmação, podemos dizer que
devemos encontrar a probabilidade de que, ao usarmos 1002 elos, o comprimento
da corrente será menor que 50 metros. Representando 50 metros como 5000
centímetros para igualar as unidades de medida temos,

Y =

1002∑︁

k=1

Xk < 5 000.

Sendo assim,

1002∑︁

k=1

Xk < 5000 ⇔ 1
1002

1002∑︁

k=1
1002∑︁

Xk < 5000
1002

Xk < 4.99

⇔ 1

1002
⇔ µY < 4.99.

k=1

Vamos encontrar a probabilidade de que para mais de 1002 elos formarem uma
corrente de 50 metros a média de comprimento de cada elo deve ser menor que
4.99 centímetros, isto é,

P(µY < 4.99).

Como n = 1002, o Teorema Central do Limite nos permite utilizar a aproximação
normal através da variável Z.
µY − µX√
σY

−0.01
0.00632

= −1.58.

Z =

=

= 4.99 − 5
√︁
d 0.04
1002

Com isso, P(µY < 4.99) = P(Z < −1.58) = 0.0571.

Portanto, 5.71% é a probabilidade para uma corrente de pelo menos 50 metros,
serão necessários mais de 1002 elos. A Figura 10 ilustra claramente a probabilidade
como sendo a área cinza sob a curva normal referente aos 5.71%.

Capítulo 5. Aplicando o Teorema Central do Limite

87

Figura 10 – Probabilidade de mais de 1002 elos numa corrente de 50 metros.

(b) Na solução do item (a) vimos que a média de comprimento para cada elo era de
4.99 centímetros e como o laboratório de pesquisa concluiu este mesmo valor em
suas investigações então realmente é necessário informar ao departamento de
vendas a mudança mesmo esta sendo tão pequena.

O capítulo seguinte continuará abordando situações onde podemos aplicar o
Teorema Central do Limite porém de maneira mais especíﬁca que é na inferência
estatística.

88

6

Aplicações do Teorema Central do Limite
na inferência estatística.

Na inferência estatística, o TCL atinge um alto grau de relevância pois há condi-
ções extremamente necessárias e favoráveis para o cumprimento de suas propriedades.
Seus objetivos tornam-se completos já que em situações em que a distribuição da variável
é desconhecida, com amostras iguais ou superiores a trinta, as estimativas acontecem
mediante a aproximação normal utilizando-se de técnicas simples e rápidas através da
curva normal e da tabela z.

O desenvolvimento deste capítulo dar-se-á através de três seções. Na primeira
seção haverá uma abordagem inicial do método inferencial tais como estimadores,
parâmetros e outros tópicos de relevância. Na segunda, veremos situações problemas
envolvendo distribuições amostrais com estimativas pontuais. Na terceira e última,
veremos situações envolvendo as estimativas intervalares, comumente chamadas de
intervalos de conﬁança. Para maiores estudos, consultar (DEVORE, 2006) e (FARBER,
2010).

Torna-se essencial o tratamento de algumas deﬁnições e características da
estatística inferencial para uma melhor compreensão das situações problemas propostas
pois não foi discorrido em nenhum capítulo anterior. Este é o propósito da seção a
seguir.

6.1 Noções gerais de inferência estatística

O termo inferência nos remete a um tipo de raciocínio chamado de indutivo no
qual, através de casos particulares chegamos a uma conclusão geral. Na estatística, a
inferência exerce a mesma função de generalizar conclusões porém as premissas são
chamadas de amostras dentro de um geral denominado de população. Assim, os termos
população e amostra são a base inicial na estatística inferencial.

Ao incluirmos a probabilidade, estamos criando uma ligação entre os métodos da

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

89

estatística descritiva e da estatística inferencial levando a uma melhor compreensão de
como as técnicas inferenciais são desenvolvidas e aplicadas, como as conclusões estatísti-
cas podem ser traduzidas para a linguagem cotidiana e interpretadas,transformando-se
em tomada de decisões e na estimativas de erros que podem ocorrer durante o processo
inferencial. Enquanto que a probabilidade faz suas considerações da população para a
amostra caracterizando o método do raciocínio dedutivo, a estatística inferencial faz
suas considerações da amostra para a população distinguindo-se assim como raciocínio
indutivo.

Na inferência estatística lidamos com conceitos especíﬁcos que precisam estar
bem deﬁnidos a ﬁm de não gerar dúvidas nas questões propostas deste capítulo.
Um parâmetro é uma característica da população. Como exemplos, podemos citar a
média aritmética, a mediana ou a variância. Representamos os parâmetros através
de letras gregas. Em muitas populações, mesmo de tamanho ﬁnito, encontrar os
valores numéricos precisos de seus parâmetros é muito complicado ja que nem todas
as possibilidades existentes podem ser estudadas. Dado a esse fato, precisamos de
estimadores ou estatísticas que cumpram esse papel de fornecer dados importantes num
estudo inferencial. Estes dados numéricos que um estimador fornece é denominado
de estimativas. Representamos os estimadores através de letras do nosso alfabeto em
formato maiúsculo. Eis alguns dos estimadores utilizados neste trabalho.

∑︀

Xi
n
∑︀
(Xi − X)2Fi
n − 1

√

(cid:111) X =

(cid:111) S2 =

(cid:111) S =

para o parâmetro µ (média populacional).

para o parâmetro σ2 (variância populacional).

S2 para o parâmetro σ (desvio padrão populacional).

Há outros modelos de estimadores tais como: a frequência relativa, utilizado para
a proporção amostral de um evento populacional e a soma de duas médias populacionais,
citados aqui apenas a título de informação.

Concluindo esta etapa podemos observar que a inferência estatística se apodera
de amostras coletadas e, através de estimadores e estimativas, generalizam características
fundamentais como os parâmetros, realizando assim, estudos de uma população. Os dois
pontos fortes do estudo de uma população pela inferência estatística é estimar parâmetros
de forma pontual ou intervalar e realizar testes de hipótese. Estes procedimentos serão
relatados nos tópicos abaixo. A seguir, vamos entender onde o Teorema Central do
Limite se encaixa na estatística inferencial.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

90

6.2 Distribuição amostral

O primeiro passo na inferência estatística consiste em selecionar uma amostra

para análise. Deﬁnindo formalmente uma amostra aleatória , temos

Deﬁnição 6.1 Dadas uma população e uma variável X que se pretende estudar, uma amostra
, . . . , Xn) onde cada termo
aleatória de X é um conjunto de dimensão n representado por (X1
da amostra possua a mesma característica de X.

, X2

A Deﬁnição 6.1 aﬁrma que se a variável X de uma população possuir, por exemplo,
uma distribuição uniforme contínua então cada termo de uma amostra também possuirá
distribuição uniforme contínua. Em estatística, a distribuição da variável representa
uma de suas características.

Para uma variável aleatória populacional X, tomemos uma amostra aleatória
denominada de X. Quando X possuir distribuição normal ou aproximadamente normal,
através do Teorema Central do Limite, temos X ∼ N(µ, σ2
n ). Isso signiﬁca que a média de
X é a mesma média de X,

E(X) = E(X) = µ

e, a variância de X é a variância populacional sobre o número de elementos de X, ou
seja,

Var(X) = Var(X)

n

=

σ2

n

.

O enfoque principal, neste capítulo, foi mostrar a utilização do Teorema Central do
Limite em situações onde a distribuição da população fosse desconhecida1. Assim, temos
duas situações distintas a considerar: uma é onde a média e a variância populacional
são conhecidas. Neste caso, a igualdade (13) do Capítulo 2 é reescrita como

z =

X − µ
σ
√

.

n

(76)

A outra é quando conhecemos a média populacional mas a variância populacional é
desconhecida. Neste caso, estimamos σ2 através da variância amostral S2. Com isso, a
igualdade (76) será

z =

.

X − µ
S√
n

(77)

1

Está subentendido que o número de elementos das amostas n é igual ou superior a 30 evitando assim
redundâncias desnecessárias. Lembrando que n = 30 é o limite inferior, o ideal são amostras de
tamanhos bem maiores que 30.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

91

Quando o tamanho de uma amostra for inferior a 30, estimamos σ2 por S2 e utilizamos
a distribuição T de Student com n − 1 graus de liberdade. Para maiores consultas vide
(NATARIO, 2012).

Vamos apresentar aqui dois exemplos representando situações problemas com
distribuições amostrais. O primeiro exemplo apresenta uma situação que aborda o
conceito de proporção populacional e amostral, a relação da proporção com a distribuição
binomial e a inﬂuência do Teorema Central do Limite na solução do problema. Este
exemplo foi adaptado de (MORETTIN, 2004).

Exemplo 6.1 Uma vacina contra a gripe será utilizada e o fabricante conﬁrma a eﬁcácia em
80% dos casos. Para admitir como verdade o que foi dito pelo fabricante, serão realizado testes
para a veriﬁcação da imunidade ou não destes indivíduos. Com isso, 36 indivíduos que tomaram
a vacina foram selecionados para estes testes. Baseado nestas informações e admitindo que o
fabricante está correto em sua aﬁrmação, encontre a probabilidade, na amostra selecionada, da
proporção de imunizados ser inferior a 0.75.

Solução : Vamos admitir uma variável aleatória X representando o número de
imunizados na amostra selecionada. Não conhecemos a média e nem a variância desta
distribuição porém, podemos perceber que nestes testes só há duas possibilidades,
estarem imunizados ou não e estes resultados retrata o modelo de distribuição binomial.
Pelo tamanho da amostra, o Teorema Central do Limite nos permite realizar uma
aproximação normal, através da variável Z. Seja P a proporção amostral com P < 0.75,
devemos encontrar P(P < 0.75). Com isso,

Z =

√︂

P − p
p(1 − p)
n

√︂

= 0.75 − 0.8
0.8(0.2)
36

=

−0.05
0.067

= −0.75

Assim,

P(P < 0.75) = P(Z < −0.75) = 0.2266

Portanto a probabilidade de imunizados, na amostra, ser inferior a 0.75 é de
22.66%. A Figura 11 ilustra graﬁcamente a probabilidade encontrada através da
aproximação normal.

Podemos observar na resolução do Exemplo 6.1 que a proporção é equivalente a

média, seja ela amostral ou não.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

92

Figura 11 – Representação gráﬁca da probabilidade de imunizados

O próximo exemplo nos traz uma variável com distribuição desconhecida e a

população possui um número ﬁnito de elementos.

Exemplo 6.2 A ﬁm de ter uma referência numérica em torno de um total de 300 contas sob
seus cuidados, um analista ﬁnanceiro toma uma amostra de 15% destas contas e acha um saldo
médio amostral X e um desvio padrão de S = R$ 35 750.00. Admitindo que o saldo médio das
300 contas seja de R$ 138 000.00, encontre um valor estimado da probabilidade de se obter X
igual ou superior a R$ 148 500.00.

Solução : Este exemplo retrata uma situação onde a distribuição da variável
aleatória X é desconhecida. Mesmo a questão nos informando o valor do desvio padrão,
precisamos estimar o valor do erro padrão da média amostral, necessário no cálculo
da probabilidade exigida. Como a população possui um valor ﬁnito de contas, vamos
aplicar a seguinte fórmula:

SX

= S√
n

√︂

N − n
N − 1

Assim, o erro padrão de X,

SX

= 35 750√
45

√︂

300 − 45
300 − 1

√

= 5329.2953

0.8528 = 4921.4534

Temos que o erro padrão é igual a R$ 4921.45.

Com este valor podemos calcular a probabilidade proposta no enunciado da
questão, isto é, P(X ≥ 148500). Como o número da amostra coletada é superior a 30, o
Teorema Central do Limite nos permite utilizar a variável Z aproximando a distribuição
para uma normal padrão, ou seja X ∼ N(0, 1).

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

93

Sendo assim temos,

P(X ≥ 148500) = P

⎛

⎞

(︂

X − µ
SX

⎜⎜⎜⎜⎝

= P

Z ≥

⎟⎟⎟⎟⎠
= P(Z ≥ 2.13) = 0.5 − P(Z ≤ 2.13)
= 0.5 − 0, 4834 = 0.0166.

Z ≥ 148500 − 138000

)︂

4921.45

Figura 12 – Representação gráﬁca da probabilidade do saldo médio amostral

Portanto, a probabilidade do saldo médio da amostra coletada das contas feita

pelo analista ﬁnanceiro ser igual ou superior a R$ 148 500.00 é de 1.66%.

Vejam que na aproximação normal padrão, a probabilidade representada pela
área sombreada da Figura 12 compreende a cauda do lado direito da curva normal. E
para valores próximos às caudas, a área é muito pequena, explicando assim o resultado
encontrado na questão.

6.3

Intervalos de conﬁança

Uma estimativa pontual, como vimos na Seção 6.2, é representado por um único
valor e, em muitos casos, não reﬂete a verdadeira característica do parâmetro exato
de uma população. Um intervalo possui poder de abrangência maior que um valor
único. Por isso, uma estimativa no formato intervalar reﬂete mais signiﬁcativamente
um parâmetro populacional exprimindo a probabilidade de conﬁança que este intervalo
contenha o parâmetro em questão. A este intervalo denominamos de intervalo de
conﬁança.

Podemos deﬁnir o intervalo de conﬁança como sendo um intervalo aberto, com
números racionais, utilizado para estimar parâmetros populacionais. Geralmente os
parâmetros mais estimados são a média, a variância, o desvio padrão, a diferença de
médias e a proporção populacional. Para um melhor entendimento das resoluções
apresentadas nesta seção precisamos abordar algumas nomenclaturas especíﬁcas. A
probabilidade que o intervalo vai conter o parâmetro estimado é denominado de nível

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

94

de conﬁança ou coeﬁciente de conﬁança. Representamos por (1 − α)x100% onde α é
a probabilidade complementar do nível de conﬁança. A extremidade à esquerda é
denominado de limite inferior de conﬁança e a extremidade à direita, de limite superior
de conﬁança. Por ﬁm, a margem de erro num intervalo de conﬁança é a diferença entre
os limites de conﬁança e sua referente estimativa pontual.

Para o tamanho n de uma amostra suﬁcientemente grande, n ≥ 30, o Teorema
Central do Limite aproxima a função de distribuição amostral para uma distribuição
normal padrão e estudamos o comportamento do intervalo a partir desta aproximação.
Através da Figura 13, podemos perceber melhor os conceitos apresentados acima, isto é,
o nível de conﬁança (1 − α)x100% é a área cinza. Quanto maior o nível de conﬁança,
maior é a área na curva. A área restante é denominada de α. As extremidades da curva
são chamadas de caudas e como há duas caudas, temos que cada cauda tem área α/2.
Os valores ±z1− α

2 são os pontos críticos da curva.

Figura 13 – Representação gráﬁca do intervalo de conﬁança numa curva normal.

Nesta seção haverá dois exemplos envolvendo parâmetros distintos. Mais
especiﬁcamente, um parâmetro é a diferença de duas médias e o outro é a proporção
populacional. Poderemos observar a funcionalidade do Teorema Central do Limite
estimando intervalos de conﬁança, amplitude de intervalos e margem de erros. O
primeiro exemplo apresenta uma situação envolvendo o cálculo de intervalos de
conﬁança da diferença de duas médias populacionais, onde a variável aleatória possui
distribuição desconhecida mas as variâncias σ2 são conhecidas.

Exemplo 6.3 Os níveis de monóxido de carbono (CO) no ar é medido em ppm, que quer dizer,
partes por milhão.2 A ﬁm de conhecer os níveis de poluição atmosférica de uma capital brasileira,
foi solicitado um estudo comparando tais níveis de poluição durante o dia e durante a noite.
Duas amostras foram coletadas. Para compor a primeira amostra, foram realizadas medições
de concentrações de CO no ar, em ppm, durante 32 dias não consecutivos, sempre às 15h da
tarde, registrando-se uma média de 0.25 ppm. Para compor a segunda amostra, foram realizadas

2 A concentração em ppm indica quantas partes do soluto existem em um milhão (106) de partes da
solução (em volume ou em massa). Para soluções gasosas, a concentração em ppm é expressa em
volume.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

95

medições de concentrações de CO no ar, em ppm, durante 30 dias, aleatoriamente, sempre às
2h da manhã, registrando-se uma média de 0.15 ppm. Supondo que concentração de CO no ar
seja uma variável aleatória de desvio padrão 0.05ppm durante a noite e 0.12ppm durante o dia,
construa um intervalo de conﬁança, a um nível de signiﬁcância de 90%, para a diferença das
concentrações médias de CO de dia e à noite.

Solução : Seja X1 a variável aleatória referente ao nível de CO, em ppm, no ar
durante o dia nesta capital brasileira e X2 referente ao nível de CO, em ppm, durante a
noite. A distribuição de X1 e X2 são desconhecidas porém a variância é conhecida e o
número de amostras é igual ou superior a 30. Sendo assim, podemos aplicar o Teorema
Central do Limite e fazer uma aproximação normal, através da variável aleatória Z.

Para encontrarmos a solução do problema, devemos aplicar a fórmula do

intervalo de conﬁança para a diferença de médias, µ

− µ

1

IC(1−α)100%

=

⎛

⎜⎜⎜⎜⎜⎜⎜⎝

(X1

− X2) − z1− α

2

√︃

σ2
1
n1

+

σ2
2
n2

2, descrita abaixo,
√︃

σ2
1
n1

+

⎞

⎟⎟⎟⎟⎟⎟⎟⎠

.

σ2
2
n2

; (X1

− X2) + z1− α

2

O enunciado do problema nos fornece o seguinte, n1

X2

= 0.15, σ2
1

= 0.05 e σ2
2

= 0.12. Precisamos encontrar z

1−

3, onde P(Z ≤ z1− α

2 ) = 0.9. Logo, z1− α

2

= 1.645

α

2

= 32, n2

= 0.25,
, através da tabela z da Figura

= 30, X1

IC90%

Com isso,
⎛

√︃

σ2
1
n1

2

⎛

=

=

(X1

− X2) − z1− α

⎜⎜⎜⎜⎜⎜⎜⎝
⎜⎜⎜⎜⎝(0.25 − 0.15) − 1.645
(︁
0.1 − 1.645
= (0.061; 0.138).

√

=

+

σ2
2
n2

; (X1

− X2) + z1− α

2

√︃

σ2
1
n1

+

⎞

⎟⎟⎟⎟⎟⎟⎟⎠

σ2
2
n2

√︂

0.052
32

+ 0.122
30
√

; (0.25 − 0.15) + 1.645

√︂

0.052
32

+ 0.122
30

⎞

⎟⎟⎟⎟⎠

0.000558; 0.1 + 1.645

0.000558

)︁

Portanto, P(0.061 ≤ µ

≤ 0.138) = 0.9.
Isso quer dizer que há 90% de
conﬁança de que o intervalo entre 0.061 e 0.138 contenha a diferença das médias reais
de concentração de CO no ar.

− µ
2

1

Observe que o número zero não pertence ao intervalo encontrado. Logo, as
2 não são iguais e, como as extremidades do intervalo são positivas então
2, ou seja, a média de concentração de CO no ar durante o dia é maior que a

1 e µ

médias µ
> µ
µ

1

concentração de CO durante a noite.

O próximo exemplo trata-se de uma situação envolvendo estimativa intervalar
para proporção populacional p, cuja variável aleatória não possui distribuição normal e
a variância σ2 é desconhecida.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

96

Exemplo 6.4 Devido ao aumento da inadimplência por parte da população, o gerente ﬁnanceiro
de uma rede de lojas solicitou uma pesquisa de seus clientes acerca do uso de cartão de crédito
mencionando o seguinte aspecto: quitação total ou parcial das faturas mensais do ano anterior.
O resultado da pesquisa foi o seguinte, numa amostra, selecionada ao acaso, de 180 clientes,
veriﬁcou-se que 115 pagaram juros devido a pagamentos parciais de suas faturas.

(a) Encontre o intervalo de conﬁança, a um nível de 97.5%, para a proporção real dos clientes

com cartão de crédito que pagaram juros no ano anterior.

(b) Qual o tamanho de uma amostra para que, a um nível de conﬁança de 97.5%, o intervalo

possua uma amplitude de 0.05?

Solução :

(a) Seja X a variável aleatória que representa o número de clientes dessa rede de lojas
que usam o cartão de crédito. Dos clientes usuários de cartão de crédito, interessa
apenas aqueles que pagaram juros no ano anterior ou seja, uma proporção da
amostra. Seja p a proporção populacional. Como p é desconhecida, devemos
estimá-lo por P, a proporção amostral. Encontrando o valor de P,

P = 115
180

= 0.639.

A variável X possui distribuição binomial de parâmetros n = 180 e P = 0.639.
Como nP ≥ 5 e n(1 − P) ≥ 5, vamos realizar uma aproximação normal pela variável
Z, através do Teorema Central do Limite. Para encontrarmos o intervalo de
conﬁança devemos utilizar a fórmula:
√︂

√︂

IC(1−α)100%

=

⎛
⎜⎜⎜⎜⎝
P − z1− α

2

P(1 − P)
n

; P + z1− α

2

P(1 − P)
n

⎞

⎟⎟⎟⎟⎠

.

= 2.24. Com isso, temos todos os
Através da tabela z da Figura 3, temos que z1− α
dados necessários para compor a fórmula acima com n = 180 e P = 0.639. Assim,

2

IC97.5%

=

√︂

⎛
⎜⎜⎜⎜⎝
P − z1− α

2

⎛

=

⎜⎜⎜⎜⎝0.639 − 2.24
(︁
0.639 − 2.24
= (0.559; 0.719)

=

√︂

2

√︂

; P + z1− α

P(1 − P)
n
0.639(1 − 0.639)
180
0.00128; 0.639 + 2.24

√

P(1 − P)
n

⎞

⎟⎟⎟⎟⎠

√︂

; 0.639 + 2.24

√

)︁

0.00128

0.639(1 − 0.639)
180

⎞

⎟⎟⎟⎟⎠

Portanto, P(0.559 ≤ p ≤ 0.719) = 0.975. Isso quer dizer que há 97.5% de conﬁança
que o intervalo entre 0.559 e 0.719 contenha a proporção real de clientes que
pagaram juros no cartão de crédito no ano anterior.

Capítulo 6. Aplicações do Teorema Central do Limite na inferência estatística.

97

(b) A amplitude de um intervalo é dado pela diferença de seus valores extremos.
No intervalo de conﬁança, dizemos que a amplitude é a diferença dos limites de
conﬁança inferior e superior, expressa por:

√︂

P(1 − P)
n

2z1− α

2

√︁

α

P(1−P)
n

é conhecido como margem de erro ou erro máximo de estimativa.

onde z

1−

2

Vamos agora calcular o tamanho n de uma amostra cuja amplitude seja de 0.05.
Os valores necessários para compor a fórmula abaixo são os mesmos do item (a).

√︂

P(1 − P)
n

= 0.05

2z1− α

2

√︂

2.24

0.639(1 − 0.639)
n
√

0.2307√
n
√

= 0.05
2
= 0.025
2.24
√
n = 2.24
(︃
2.24

n =

0.025
n = 1852.096.

0.2307

0.025
√

)︃2

0.2307

Como o tamanho da amostra é representado por um número natural, temos que
n ≈ 1853 clientes selecionados para a pesquisa.

O próximo capítulo trata-se do conceito do Teorema Central do Limite aplicado
em sala de aula no Ensino Médio. As atividades apresentadas correspondem ao
nível que um aluno do Ensino Médio possa acompanhar sem problemas em relação a
pré-requisitos conceituais.

98

7

Proposta de atividades em sala de aula

Este capítulo destina-se a apresentar algumas propostas de atividades a serem
aplicadas no Ensino Médio. Estas atividades vão buscar o conceito intuitivo que os
alunos possuem acerca das características do Teorema Central do Limite utilizando,
para isso, os conhecimentos matemáticos já estudados, a experiência individual de
mundo e o conteúdo atual. O principal objetivo deste capítulo é mostrar que o conceito
do Teorema Central do Limite não está apenas nos estudantes ou proﬁssionais das
áreas aﬁns como matemática, estatística ou as engenharias, encontra-se nas pessoas,
independentemente de seu grau de escolaridade ou área de atuação, isso porque estes
conceitos estão no mundo em que vivemos e na sociedade onde somos parte integrante.
O que acontece é que muitas pessoas não se deparam ou não são estimuladas a reﬂetir
nestas situações que exigem tal compreensão. No âmbito escolar, estas situações são
colocadas em prova para que os alunos reﬂitam, questionem e construam conceitos
próprios encontrando técnicas para solucionar as situações problemas existentes.

Segundo a proposta curricular da Secretaria de Educação para o Ensino Médio,
em conjunto com o PCNEM (BRASIL, 1999), o aluno, no dever de suas atribuições, deve
ser capaz de utilizar conhecimentos de estatística e probabilidade como recurso para
a construção de argumentação com o intuito de avaliar propostas de intervenção na
realidade que o cerca. A necessidade do professor estar desenvolvendo tais competências
perpassa por atividades como as que serão apresentadas aqui.

Vamos discorrer sobre três atividades em sala de aula onde os alunos colocarão
em prática seus conhecimentos, mostrando o quanto aprenderam acerca do conteúdo
que estão estudando agora. A primeira atividade relaciona conceitos de estatística e de
probabilidade para chegarmos a noção do Teorema Central do Limite.

Atividade 01 : (Experimento, em sala de aula, com o dado.)

(cid:111) Objetivo da atividade:

Reconhecer o Teorema Central do Limite como fundamento probabilístico/estatístico

Capítulo 7. Proposta de atividades em sala de aula

99

necessário para aproximar características reais com base nas características amos-
trais.

(cid:111) Conteúdos prévios necessários:

Leitura e interpretação de gráﬁcos estatísticos e medida de tendência central e de
dispersão.

(cid:111) Recursos necessários:

Um dado, caderno, lápis ou caneta, uma calculadora básica, data show, quadro e
piloto ou giz branco.

(cid:111) Desenvolvimento da atividade:

Cada aluno vai trazer de casa um dado comum. A atividade pode ser de
individual porém, o professor pode pedir que os alunos formem grupos de acordo
com a aﬁnidade de cada um. Os alunos escolherão por conta própria o número de
jogadas por rodada, contanto que o número de jogadas estejam em ordem crescente,
por exemplo, duas jogadas na 1a rodada, 5 jogadas na 2a rodada e assim por diante. Em
cada rodada, os alunos registrarão quantas jogadas foram realizadas e o número da face
do dado voltado para cima em cada jogada. Dez rodadas são suﬁcientes para podermos
tirar as conclusões necessárias.

Finalizado esta etapa onde todos os alunos da turma ﬁzeram suas dez rodadas e
registraram no caderno, a próxima etapa é calcular a média ponderada por rodada com
a ajuda de uma calculadora, caso necessite.

O professor calcula a média real no quadro e os alunos vão comparar seus

resultados com o resultado encontrado pelo professor.

1 + 2 + 3 + 4 + 5 + 6
6

= 21
6

= 3.5.

(78)

O professor lança a seguinte pergunta: O que acontece com as médias encontradas por
vocês enquanto o número de jogadas aumentam?

O professor apresenta uma ilustração composta por histogramas de algumas
possíveis jogadas. Analisando a ilustração, o professor esclarece que a medida que o
números de jogadas aumentam, as médias encontradas vão aproximando-se de um
valor central e a dispersão diminui, ou seja, os valores na abscissa não se distanciam
muito do centro. Outro questionamento é lançado para os alunos: Se o números de
jogadas numa rodada for muito grande, algo em torno de mil jogadas, o que acontece
com essa média? E com o histograma que o representa?

Após algumas opiniões, o professor esclarece que para uma rodada com jogadas
cada vez maiores, a média dessa rodada se torna muito próxima da média real calculada

Capítulo 7. Proposta de atividades em sala de aula

100

no quadro e que a coluna central do histograma estará cada vez maior. A explicação
matemática para esta observação é o Teorema Central do Limite que aﬁrma que para
rodadas com um número de jogadas indeﬁnidamente crescente, a sua média coincidirá
coma média real do dado.

A segunda proposta consiste numa atividade onde os alunos terão a possibilidade
de interferir no acaso a partir de um experimento aleatório bastante comum nos estudos
de probabilidade que são retirada de bolas de uma urna. Vejamos a proposta e como
essa intervenção pode ser feita.

Atividade 02 : (Amostras a partir de uma urna.)

(cid:111) Objetivo da atividade:

Compreender que a probabilidade de ocorrência de um evento dentro de uma
espaço amostral aumentar é diretamente proporcional ao número de amostras
coletadas e relacionar este fato como uma propriedade do Teorema Central do
Limite.

(cid:111) Conteúdos prévios necessários:

noções básicas de estatística e cálculo de probabilidades.

(cid:111) Recursos necessários:

Uma caixa, oito bolinhas de mesmo tamanho e textura, caderno, lápis ou caneta,
quadro e piloto ou giz branco.

(cid:111) Desenvolvimento da atividade:

Uma urna contendo oito bolas de duas cores distintas, quatro azuis e quatro
marrons. As bolas azuis tem valor um e as marrons, valor dois. O aluno tem a opção
de retirar três ou quatro bolas sem reposição. Após as retiradas, as bolas voltam para
a urna e o processo recomeça com o próximo aluno. Todos os alunos daquela turma
participarão desta atividade. Os alunos devem conseguir média aritmética igual ou
superior a média populacional ou real das bolas na urna para saírem vencedores. Com
a ajuda do professor, calculam-se a média real das oito bolas contidas na urna,

1 + 1 + 1 + 1 + 2 + 2 + 2 + 2
8

= 12
8

= 1.5.

(79)

Logo, a média populacional é de 1.5.

Antes de cada aluno ir a urna realizar sua tentativa, o professor vai coletar a
primeira informação importante. No quadro, o professor coloca três opções: 3 tentativas,
4 tentativas ou tanto faz, cada aluno faz a sua escolha e diz o porque da escolha. A partir
daí, cada um faz sua tentativa, calcula a sua média e compara com a média populacional

Capítulo 7. Proposta de atividades em sala de aula

101

obtida anteriormente, µ = 1.5. O processo de retirar as bolas da urna é ﬁnalizado por
todos os alunos.

Após sorrisos, tristezas e a angustias, o professor revela que nem tudo teve a sorte
como fator preponderante. Na opção de realizar três ou quatro tentativas, houve-se um
mecanismo fazendo a sorte tender para o nosso lado que é através da probabilidade. E,
retomando a discussão da escolha de 3, 4 tentativas ou tanto faz, mostra-se que quanto
maior o número de tentativas ou quanto mais próximo o número de tentativas estiver
do total de uma população, mais próximo da média real, os resultados estarão. O
professor questiona quem sabia ou imaginava a aﬁrmação acima, cria-se um ambiente de
discussão, com mediação do professor, para introduzir o conceito intuitivo do Teorema
Central do Limite.

Esta última proposta é uma atividade que simula um jogo de loteria. Ela
representa um experimento, que através de uma atividade dinâmica, os alunos terão a
oportunidade de conhecer o Teorema Central do Limite e também estarão construindo
conceitos importantes dos conhecimentos necessários na aplicação desta atividade. A
proposta foi criada a partir de uma atividade contida em (FRAGA, 2013).

Atividade 03 : (Loteria em sala de aula)

(cid:111) Objetivo da atividade:

Identiﬁcar, nas situações cotidianas, condições favoráveis para a atuação do
Teorema Central do Limite encurtando distâncias entre estimativas amostrais e
reais.

(cid:111) Conteúdos prévios necessários:

Soma dos termos de uma progressão aritmética e medidas estatísticas: média
aritmética, variância e desvio padrão.

(cid:111) Recursos necessários:

Uma caixa, não transparente, para sortear os números, 25 bolinhas numeradas de
1 a 25, ﬁchas impressas contendo seis cartelas cada uma, lápis ou caneta, quadro,
piloto ou giz branco.

(cid:111) Desenvolvimento da atividade:

Nesta atividade o professor vai dividir a turma em grupos com quatro ou cinco alunos.
A cada aluno será entregue uma ﬁcha com seis cartelas idênticas enumeradas de 1 a 25.
Os alunos irão marcar cinco números por cartela da maneira que quiserem. A atividade
vai ser desenvolvida individualmente, mesmo os alunos estando em grupos. A proposta
consiste em sortear cinco números desses 25 números completando assim uma rodada e
realizar seis rodadas completando todas as cartelas da ﬁcha que foi entregue. A cada

Capítulo 7. Proposta de atividades em sala de aula

102

rodada, o professor observa se algum aluno acertou os cinco números sorteados numa
mesma cartela anotando no quadro os números que saíram. Ao ﬁnal das seis rodadas, o
professor tem em mãos as seis cartelas preenchidas em cada ﬁcha e as quantidades que
cada número foi sorteado. Caso algum aluno complete uma ou mais cartelas de sua
ﬁcha, o que é pouco provável, ótimo, o professor e a turma parabeniza-o mais aﬁrma
que o objetivo principal está em construção.

O passo seguinte é direcionar a atenção dos alunos para o número de vezes que
os números da cartela foram sorteados. O professor reescreve os dados agrupados numa
tabela em ordem decrescente e pergunta aos alunos quais números mais apareceram
ao ﬁnal das seis rodadas. Apos as observações perante a tabela no quadro, o professor
lança outro questionamento: estes valores fariam vocês reverem a escolha dos números
para uma próxima rodada, ou não interferem na opção de vocês? Os alunos comentarão
acerca das questionamento feito das mais diversas formas possíveis. Muitas opiniões
levantadas pelos alunos vão gerar novas discussões aí o professor deve mediar este
momento para não perder o direcionamento e o objetivo da atividade.

Em seguida, os alunos vão obter a média aritmética dos 25 números contidos
numa cartela com o seu desvio padrão e também a média aritmética e o desvio padrão
por rodada comparando os valores encontrados em cada um a ﬁm de construírem uma
conclusão fundamentada na proposta da atividade. A média aritmética µ dos números
contidos na cartela é dada por:

µ = 1
25

25∑︁

n=1

n = 325
25

= 13.

A variância σ2 dos números da cartela é:

[︁

(1 − 13)2 + (2 − 13)2 + · · · + (24 − 13)2 + (25 − 13)2]︁

σ2 = 1
25

25∑︁

n=1

(xn − µ)2 = 1
25
= 1300
25

√

= 52

e o desvio padrão é σ =
mais sorteados deveriam estar é entre 13 - 7.2 e 13 + 7.2, ou seja, entre 5.8 e 20.2.

52 = 7.2. Com isso, o intervalo numérico onde os números

De posse destes dados, o professor solicita aos alunos que façam comparação com
a tabela dos sorteios contida no quadro. Provavelmente a maioria dos números estarão
contidos no intervalo formado pelo desvio padrão em torno da média ou simplesmente
não. O professor deve lembrar aos alunos que trata-se de um experimento aleatório e
consequentemente imprevisível. O questionamento ﬁnal é: Se as rodadas com cinco
sorteios cada uma estendesse mais e mais vezes numa quantidade muito maior que seis,
os dados seriam mais conﬁáveis? Ou seja, a probabilidade daqueles números serem
sorteados numa determinada rodada eram maiores? Neste momento de exposição

Capítulo 7. Proposta de atividades em sala de aula

103

de ideias, o professor apresenta o Teorema Central do Limite, como noção conceitual,
mostrando aos alunos que a partir de uma quantidade n de rodadas maior ou igual
a trinta, o Teorema Central do Limite entra em ação fazendo a distribuição amostral
das rodadas de sorteio aproximar-se de uma forma de distribuição conhecida como
Distribuição Normal. O professor deve mostrar graﬁcamente o comportamento de
uma distribuição normal através da curva normal para os alunos possam observar
a importância do Teorema Central do Limite, ressaltando que só é possível fazer tal
aproximação quando n ≥ 30. Quanto maior for o número n de rodadas, mais próxima
a média amostral das médias obtidas por rodada estará da média real µ = 13. Asim,
os alunos perceberão que suas ideias intuitivas tem um rigor matemático muito bem
fundamentado.

104

8

Conclusão

A elaboração deste trabalho atendeu aos requisitos mínimos de compreensão
acerca de um tópico tão relevante e tão amplo na matemática que é o Teorema Central
do Limite. Todas as notações, terminologias e deﬁnições básicas em probabilidade e
estatística, utilizadas no trabalho, tais como variáveis aleatórias, esperança matemática,
variância e função de distribuição foram atendidas, de forma clara e sucinta, no primeiro
capítulo. No segundo capítulo, as proposições necessárias para desenvolver os teoremas
limites como o Teorema da Unicidade e o Teorema da Continuidade de Paul-Levy,
foram apresentadas de forma coerente e concisa, comprovando seu papel de oferecer
os pré requisitos necessários para o desenvolvimento do Capítulo 4 . Os teoremas
limites foram enunciados e demonstrados no terceiro capítulo, obedecendo todo o rigor
matemático que eles exigem porém, mostrando-se compreensível em todo seu raciocínio
dedutivo. Os Capítulos 5 e 6, dedicados a aplicabilidade do TCL, apresentaram, de
forma correta e descomplicada, várias situações problemas no intuito de romper toda a
rigidez matemática dos capítulos anteriores, abrindo espaço para a compreensão de
utilidade prática e concreta essencial para o Capítulo 7, que descreve propostas de
atividades que levam para os alunos do Ensino Médio o conceito do Teorema Central
do Limite de forma dinâmica e prazerosa.

Muitos alunos, essencialmente nas escolas públicas, concluem a Educação Básica
sem serem apresentados aos conceitos de estatística e/ou probabilidade e, quando
tem acesso a estes conhecimentos, é de forma tão superﬁcial que não dá espaço
para construção de conceitos importantes e necessários para seu desenvolvimento
conceitual e atitudinal. O Teorema Central do Limite vem como um mediador, fazendo
com que esses alunos entendam que estes processos de intuição, que eles possuem,
acerca de fatos imprevisíveis podem ser esclarecidos matematicamente, quantiﬁcados
e postos em prática de uma forma compreensível e de fácil manipulação formando,
assim, agentes ativos, participativos e transformadores no processo de construção do
próprio conhecimento, abrindo portas para futuros proﬁssionais na área da estatística e
probabilidade.

Capítulo 8. Conclusão

105

Um ponto que não foi abordado aqui mas merece toda a atenção, principalmente,
no que diz respeito a disseminação do Teorema Central do Limite, é a criação de materiais
manipuláveis que torne as pessoas como agente ativo e participativo no processo de
ensino e aprendizagem e, neste caso, temos a tábua de Galton. Muito interessante como
este material é de fácil manipulação e consegue entregar realmente o conceito proposto
por ele que é o processo de aleatoriedade, a forma de distribuição dos elementos e a
noção do Teorema Central do Limite. Para maiores consultas vide (AQUINO, 2004) que
ensina a confeccionar uma tábua de Galton e (SILVEIRA, 2011) aborda sobre erros e
incertezas na metrologia a partir da tábua de Galton onde o Teorema Central do Limite
faz-se presente na discussão.

Com tudo que foi exposto, os objetivos de compreensão e aplicação do Teorema
Central do Limite foram alcançados com êxito. Esperamos que este trabalho contribua na
divulgação da teoria das probabilidades em nossa sociedade, que a linguagem utilizada
esteja acessível a alunos e professores da Educação Básica, graduandos, graduados e
proﬁssionais de áreas aﬁns que estejam ávidos por novos conhecimentos ou necessitam
destes conhecimentos. Os reﬂexos do Teorema Central do Limite estão ao nosso redor,
acompanhado-nos em todos os lugares, não podemos simplesmente ignorar, pelo
contrário, precisamos conhecê-lo e tirar bons proveitos a nosso favor.

106

Referências

AQUINO, P. M. de. Relatório Final F-809: O Estudo da Distribuição Normal por
Galton. Campinas, 2004.

BELLHOUSE, D. R. Maty’s Biography of Abraham De Moivre, Translated, Annotated
and Augumented. [S.l.]: Institute of Mathematical Statístics, 2007. v. 22.

BRASIL. Parâmetros Curriculares Nacionais: Ensino Médio. [S.l.]: Ministério da
Educação. Secretaria de Educação Média e Tecnológica, 1999.

COLETTI Élcio Lebensztayn e C. F. Probabilidade: Teoria e Exercícios. São Paulo:
IME-USP, 2008. Desenvolvimento de material didático ou instrucional - Notas de Aula.

DEKKING, F. M. A Modern Introduction to Probability and Statistics. Understanding
Why and How. [S.l.]: Springer, 2005.

DEVORE, J. L. Probabilidade e Estatística para Engenharia e Ciências. Tradução de
Joaquim Pinheiro Nunes da Silva. São Paulo: Editora Thompson, 2006.

FARBER, R. L. e B. Estatística Aplicada. Tradução por Luciane Ferreira Pauleti
Vianna. São Paulo: Pearson Prentice Hall, 2010.

FARIAS, A. M. L. de. Variáveis aleatórias Contínuas. Rio de Janeiro: Universidade
Federal Fluminense, 2009. Desenvolvimento de material didático ou instrucional -
Notas de Aula.

FELLER, W. An Introduction to Probability Theory and its Applications, Volume 1.
[S.l.: s.n.], 1968.

FISCHER, H. A History of the Central Limit Theorem From Classical to Modern.
New York: Springer, 2011.

FRAGA, R. R. O ensino das loterias: Uma Abordagem Motivadora e Facilitadora
para a aprendizagem de Probabilidade no Ensino Médio. Rio de Janeiro-RJ: IMPA,
2013. Dissertação de Mestrado.

GARCIA, A. L. Probability, Statístics, and Random Processes for Electrical
Engineering. Toronto: Pearson Prentice Hall, 2008.

GUIDORIZZI, H. L. Um curso de cálculo, Volume I. Rio de Janeiro: LTC Editora, 2006.

Referências

107

HALD, A. A History of Parametric Statistical Inference from Bernoulli to Fisher,
1713 to 1935. Copenhagen: Department of Aplied Mathematics and Statistics -
University of Copenhagen, 2004.

HOEL, S. C. P. e. C. J. S. P. G. Introdução à teoria da probabilidade. Tradução de
Fernando Yassou Chiyoshi. Rio de Janeiro: Editora Interciência, 1978.

JAMES, B. R. Probabilidade: um curso em nível intermediário. Rio de Janeiro: LTC
Editora, 2010.

MARTINS, J. S. F. e Gilberto de A. Curso de Estatística. São Paulo: Editora Atlas, 2010.

MEYER, P. L. Probabilidade: Aplicações à estatística. In: Probabilidade: Aplicações à
Estatística. [S.l.]: Livro Técnico, 1970.

MORETTIN, W. de O. Bussab e P. A. Estatística Básica. São Paulo: Editora Saraiva,
2004.

NATARIO, I. Probabilidade e Estatística. Caparica, Portugal: Universidade Nova
Lisboa, 2012. Desenvolvimento de material didático ou instrucional-Notas de aula.

PINHEIRO, J. I. D. Estatística Básica: A arte de trabalhar com dados. Rio de Janeiro:
Elsevier Editora, 2009.

ROSS, S. Probabilidade: um curso moderno com aplicações. Tradução de Alberto
Resende De Conti. Porto Alegre: Editora Bookman, 2010.

SILVEIRA, P. L. J. e Fernando Lang da. Discutindo os conceitos de erros e incerteza
a partir da tábua de galton com estudantes de graduação: uma contribuição para
incorporação de novas abordagens da metrologia ao ensino da física superior. Porto
Alegre-RS: Caderno Brasileiro de Ensino de Física, 2011. v. 28.


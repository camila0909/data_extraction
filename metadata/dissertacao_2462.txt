Universidade Estadual Paulista “Júlio de Mesquita Filho”
Instituto de Geociências e Ciências Exatas
Campus de Rio Claro

Método dos mínimos quadrados aplicado ao
lançamento de foguetes propulsionados a ar
comprimido

Gilberto Caetano da Silva Junior

Dissertação apresentada ao Programa de Pós-
Graduação – Mestrado Proﬁssional em Mate-
mática em Rede Nacional-PROFMAT como
requisito parcial para a obtenção do grau de
Mestre

Orientadora

Profa. Dra. Sidineia Barrozo

2017

111
X111x

Silva Junior, Gilberto Caetano da

Método dos mínimos quadrados aplicado ao lançamento de fo-
guetes propulsionados a ar comprimido/ Gilberto Caetano da Silva
Junior- Rio Claro: [s.n.], 2017.

107 f.: ﬁg., tab.

Dissertação (mestrado) - Universidade Estadual Paulista, Insti-

tuto de Geociências e Ciências Exatas.

Orientadora: Sidineia Barrozo

1. Regressão linear. 2. Ensino de matemática. 3. Lançamento

de foguetes. 4. Propulsão a ar comprimido. I. Título

Ficha Catalográﬁca elaborada pela STATI - Biblioteca da UNESP
Campus de Rio Claro/SP

termo de aprovação

Gilberto Caetano da Silva Junior
Método dos mínimos quadrados aplicado ao lançamento de

foguetes propulsionados a ar comprimido

Dissertação aprovada como requisito parcial para a obtenção do grau de
Mestre no Curso de Pós-Graduação Mestrado Proﬁssional em Matemática
Universitária do Instituto de Geociências e Ciências Exatas da Universidade
Estadual Paulista “Júlio de Mesquita Filho”, pela seguinte banca examina-
dora:

Profa. Dra. Sidineia Barrozo
Orientadora

Prof. Dra. Eliris Cristina Rizziolli
Departamento de Matemática, UNESP - Rio Claro

Prof. Dra. Marisa Veiga Capela
Departamento de Físico-Química, UNESP - Araraquara

Rio Claro, 18 de outubro de 2017

Aos meus familiares e amigos.

Agradecimentos

Agradeço inicialmente a Deus, pois nos momentos de diﬁculdades e dúvidas renovei

minha perseverança na tua palavra.

À minha esposa Cláudia e minha ﬁlha Larissa pelo companherismo, compreensão e

apoio.

À SBM - Sociedade Brasileira de Matemática por estruturar um programa de Pós-
Graduação que viabiliza o acesso de muitos professores que anseiam por capacitação e
melhoramento proﬁssional.

À CAPES - Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, por
disponibilizar bolsa de estudo, sem a qual não seria possível diminuir a carga horária
de trabalho para que pudesse ter uma maior dedicação aos estudos.

À minha orientadora Professora Dra. Sidneia Barrozo pelos ensinamentos, sugestões

e correções que nortearam a realização deste trabalho.

A todos os professores do Departamento de Matemática da Unesp de Rio Claro,
em especial à Professora Dra. Suzinei Aparecida Siqueira Marconato pelo apoio e
incentivo, ao Professor Dr. Jamil Viana Pereira pela paciência e ensinamentos impres-
cindíveis a minha formação e à Professora Dra. Elíris Cristina Rizziolli pelo incentivo
e generosidade.

Aos meus colegas de curso: Helba, Henrique, Ênio, Joyce e Irma que estiveram

presentes e me ajudaram nessa caminhada que empreendi.
A minha colega de trabalho, professora Katia Lucas.

“Tenho a impressão de ter sido somente um garoto brincando e me divertindo na
praia, encontrando, de vez em quando, um seixo mais liso ou uma concha mais bonita
que a normal, enquanto que o grande oceano da verdade permanece todo
desconhecido diante de mim.”

Isaac Newton.

Resumo

Neste trabalho, apresentamos um relato de experimento realizado junto aos alunos
de ensino fundamental de uma escola pública municipal e efetuamos o ajuste de curva
dos dados observados por meio do método dos mínimos quadrados. Para tanto, discu-
timos a concepção e aplicação desse método a partir de resultados oriundos do cálculo
diferencial, da álgebra linear e alguns conceitos estatísticos. Do cálculo diferencial es-
tudamos a minimização dos erros de aproximação por meio da investigação dos pontos
de mínimo da função erro. Da álgebra linear determinamos os parâmetros da função
ajustada através da discussão e solução de um sistema de equações lineares resultante
do conjunto de derivadas parciais nulas que estabelecem o ponto crítico da função erro.
Da estatística utilizamos alguns conceitos e formulações que tratam da intensidade
da relação entre as variáveis, bem como, das incertezas na variável dependente e nos
parâmetros da função ajustada.

Palavras-chave: Regressão linear, Ensino de matemática, Lançamento de foguetes,
Propulsão a ar comprimido.

Abstract

In this work, we present a report of an experiment carried out with elementary
school students of a municipal public school, and we performed the curve adjustment of
the observed data through the least squares method. For this, we discuss the conception
and application of this method from results derived from diﬀerential calculus, linear
algebra and some statistical concepts. From the diﬀerential calculation, we study the
minimization of approximation errors by investigating the minimum points of the error
function. From linear algebra, we determine the parameters of the adjusted function
through the discussion and solution of a system of linear equations resulting from the
set of null partial derivatives that establish the critical point of the error function. From
statistics, we use some concepts and formulations that deal with the intensity of the
relationship between variables, as well as the uncertainties in the dependent variable
and the parameters of the adjusted function.

Keywords: Linear regression, Mathematics teaching, Rocket launch, Compressed air
propulsion.

Lista de Figuras

1.1 Ponto de mínimo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Ponto de mínimo e sela . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Região convexa e não convexa . . . . . . . . . . . . . . . . . . . . . . . . .
1.4 Função convexa e segmento secante . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . .
1.5 Plano tangente ao gráﬁco e vetor gradiente perpendicular

3.1 Dispersão das medidas observadas em relação à média . . . . . . . . . .
3.2 Gráﬁco de dispersão dos pontos experimentais . . . . . . . . . . . . . . .
3.3 Gráﬁcos de funções polinomiais ajustadas . . . . . . . . . . . . . . . . . .
3.4 Representação dos erros (desvios verticais) ei . . . . . . . . . . . . . . . .
3.5 Distribuição de frequência dos valores listados na tabela 2.3 . . . . . . .
3.6 Tendência da distribuição de frequência . . . . . . . . . . . . . . . . . . .
3.7 Aproximação do histograma à distribuição gaussiana . . . . . . . . . . .
3.8 Distribuição gaussiana . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.9 Área sob a curva normal entre a média e z . . . . . . . . . . . . . . . . .
3.10 Barras de incerteza . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.1 Lançamento do melhor foguete . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Gráﬁco de dispersão dos pares ordenados (x,y) . . . . . . . . . . . . . . .
4.3 Gráﬁco de dispersão e linha de tendência . . . . . . . . . . . . . . . . . .

27
33
34
35
36

68
70
71
71
74
75
76
78
80
82

94
96
97

Lista de Tabelas

3.1 Peso da saca de farinha em três medidas . . . . . . . . . . . . . . . . . . .
3.2 Média, mediana, desvios absolutos e quadrado dos desvios dos pesos da
. . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Série de medições, intervalo de valores e frequências relativas. . . . . . .

saca de farinha em estudo.

67

69
73

95
4.1 Desempenho do foguete em função do número de bombeadas . . . . . .
99
4.2 Tabela de somatório dos dados do experimento . . . . . . . . . . . . . . .
4.3 Tabela resumida de somatório dos dados do experimento . . . . . . . . . 102
4.4 Tabela de alguns somatórios dos dados do experimento, dos desvios em
relação a função e à média, do número de observações e do número de
parâmetros da função ajustada . . . . . . . . . . . . . . . . . . . . . . . . 103

Sumário

1 Noções de cálculo

2 Noções de álgebra linear

3 Método dos mínimos quadrados

3.1 Breve histórico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Concepção do método . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Abordagem não probabilística . . . . . . . . . . . . . . . . . . . . .
3.2.2 Abordagem probabilística . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . .
3.3 Problema de mínimos quadrados
3.4 Avaliação do ajuste . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

47

66
66
67
68
72
81
90

4 O experimento

92
92
4.1 Motivação para realização do experimento . . . . . . . . . . . . . . . . . .
4.2 Relato do experimento . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
4.3 Ajuste de curva . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

5 Considerações ﬁnais

Referências

105

106

Introdução

Ao realizarmos um experimento, as observações e medições resultantes da coleta de
dados estão frequentemente sujeitas a erros aleatórios e incontroláveis. Então, para que
possamos obter uma estimativa conﬁável das grandezas que estamos analisando, deve-
mos tentar estabelecer uma relação de causa e efeito entre as variáveis representativas
dessas grandezas.

Nesse sentido, a formulação de um modelo matemático pode ser o primeiro passo
na tentativa de explicar valores de uma variável em termos de outra. E o ajuste dos
parâmetros do modelo aos dados experimentais possibilitam validá-lo, ou seja, dão a
medida do quanto o modelo representa, de fato, o fenômeno que está sendo estudado.
Um dos métodos mais conhecidos para ajuste de parâmetros é o método dos míni-
mos quadrados, que em síntese, consiste em determinar os parâmetros que minimizam
a diferença entre os dados experimentais e o modelo teórico.

Nessa perspectiva, e considerando um experimento realizado junto aos alunos do
ensino fundamental de uma escola pública municipal, discutiremos nesse trabalho a
concepção e aplicação desse método a partir de resultados oriundos do cálculo diferen-
cial, da álgebra linear e de alguns conceitos estatísticos.

Assim, nos capítulos 1 e 2 apresentaremos noções de cálculo e álgebra linear cujo
encadeamento das deﬁnições e teoremas fundamentam a discussão e aplicação do mé-
todo dos mínimos quadrados. Iniciaremos o capítulo 3 com um breve histórico sobre
o surgimento do método, a ﬁm de entendermos os fatores que motivaram o seu desen-
volvimento. Em seguida, discutiremos sua concepção sob dois pontos de vista: o não
probabilístico, onde buscamos entender a métrica do método sem nos preocuparmos
com o caráter aleatório dos dados observados; e o probabilístico, onde a aleatoriedade
dos dados experimentais é imprescindível para determinarmos as melhores chances para
as estimativas dadas pelo método. Descreveremos ainda, o problema de mínimos qua-
drados considerando as incertezas inerentes ao ajuste e um critério para avaliação de
sua qualidade.

No capítulo 4, apresentaremos a motivação para a realização do experimento, o seu
delineamento, o tratamento dos dados observados, as atividades realizadas pelos alunos
como consequência do experimento e, ﬁnalizaremos com o ajuste de curva dos dados
observados de acordo com os estudos realizados nos capítulos anteriores.

10

1 Noções de cálculo

Como veremos no capítulo 3, o método dos mínimos quadrados trabalha com mi-
nimização de erros na predição de dados experimentais. Do ponto de vista do cálculo,
a minimização do erro implica em determinar uma função cujos pontos críticos sejam
pontos de mínimo. Assim, este capítulo tem por objetivo descrever os resultados do
cálculo que são relevantes para a determinação dos pontos críticos de tal função.

Estamos interessados em uma função polinomial de duas variáveis, então observe-

mos as seguintes deﬁnições:

Deﬁnição 1.1. Uma bola aberta de raio r centrada em um ponto A = (x0, y0) ∈ R2, é
o conjunto de todos os pontos P = (x, y) ∈ R2 tal que √
Exemplo 1.2. O conjunto {(x, y) ∈ R2; x2 + y2 < r2} é uma bola aberta em R2 perten-
cente ao interior de uma circunferência.

(x − x0)2 + (y − y0)2 < r.

Deﬁnição 1.3. Seja D um conjunto de pares ordenados (x, y) ∈ R2. Uma função real
f de duas variáveis em D é uma correspondência que associa um único número real
z = f (x, y) a cada par ordenado (x, y) em D.
Deﬁnição 1.4. O conjunto D, denominado domínio de f , é o maior subconjunto de
R2 para o qual faz sentido a correspondência em questão, e o conjunto de valores
de z assumidos por f é um subconjunto de R denominado imagem de f , e dado por
Im(f ) = {z = f (x, y); (x, y) ∈ D}.
Exemplo 1.5. Seja a função de duas variáveis f (x, y) =
25 − x2 − y2. O domínio de
f é o conjunto de todos os pares ordenados (x, y) para os quais 25 − x2 − y2 ≥ 0, ou
seja, D = {(x, y) ∈ R2; x2 + y2 ≤ 25}. Observamos que 0 ≤ f (x, y) ≤ 5 e , portanto, a
imagem de f é o conjunto de todos os números reais no intervalo fechado [0, 5], isto é,
Im(f ) = {z ∈ R; 0 ≤ z ≤ 5}.
Deﬁnição 1.6. Dizemos que f ∶ D ⊂ R2 → R é uma função polinomial de duas variáveis
e grau n quando pode ser escrita na forma

√

f (x, y) = a0xn

+ a1xn−1y + ⋯ + an−1xyn−1

+ anyn

=

n
∑
i=0

aixn−iyi,

onde n é um número inteiro não negativo e a0, a1, ⋯, an são números reais.

11

Tendo em vista as deﬁnições descritas anteriormente e tomando uma função poli-
nomial f ∶ D ⊂ R2 → R, dada por z = f (x, y), queremos garantir que tal função seja
diferenciável em todo ponto de R2. Para tanto, vamos descrever e discutir as seguintes
deﬁnições e teoremas:

12

Deﬁnição 1.7. (Limite) Seja f ∶ D ⊂ R2 → R uma função deﬁnida sobre uma bola
aberta e L um número real. Dizemos que existe o limite de f (x, y) quando (x, y) tende
(x0, y0) e este limite é igual a L, o que denotamos por
f (x, y) = L, se e
somente se, para todo número real ε > 0 for possível encontrar um número real δ > 0,
tal que ∣f (x, y) − L∣ < ε, sempre que (x, y) ∈ D e 0 <
Teorema 1.8. Seja a função f deﬁnida sobre uma bola aberta e na vizinhança do
ponto (x0, y0), exceto possivelmente no próprio ponto (x0, y0), e uma constante real c.
Assim:

(x − x0)2 + (y − y0)2 < δ.

lim
(x,y)→(x0,y0)

√

a) se f (x, y) = c, então

lim
(x,y)→(x0,y0)

f (x, y) = c;

b) se f (x, y) = x, então

c) se f (x, y) = y, então

lim
(x,y)→(x0,y0)

f (x, y) = x0;

lim
(x,y)→(x0,y0)

f (x, y) = y0.

Demonstração:
que se

então

a) Dado ε > 0 arbitrário, queremos mostrar que existe δ > 0 tal

√

0 <

(x − x0)2 + (y − y0)2 < δ,

∣f (x, y) − c∣ < ε.

De fato, para f (x, y) = c, temos que

∣f (x, y) − c∣ = ∣c − c∣ = 0 < ε, ∀(x, y) ∈ R2.

Logo,

lim
(x,y)→(x0,y0)

f (x, y) = c, ∀(x0, y0) ∈ R2.

b) Dado ε > 0 qualquer, queremos mostrar que existe δ = ε, tal que se
√

0 <

(x − x0)2 + (y − y0)2 < δ,

então

∣f (x, y) − x∣ ≤ ε.

De fato, tomando f (x, y) = x, temos que

∣f (x, y) − x0∣ = ∣x − x0∣ =

√

(x − x0)2 ≤

√

(x − x0)2 + (y − y0)2 < δ = ε.

Portanto,

lim
(x,y)→(x0,y0)

f (x, y) = x0.

c) Seja f (x, y) = y. De maneira análoga ao que foi feito no item (b), temos que

lim
(x,y)→(x0,y0)

f (x, y) = y0.

13

∎

Teorema 1.9. (Propriedades do limite) Sejam as funções f e g deﬁnidas sobre
uma bola aberta e na vizinhança do ponto (x0, y0), exceto possivelmente no próprio
ponto (x0, y0), e C uma constante. Se
g(x, y) = M ,
lim
(x,y)→(x0,y0)
então:

f (x, y) = L e

lim
(x,y)→(x0,y0)

1)

2)

3)

lim
(x,y)→(x0,y0)

[f (x, y) + g(x, y)] = L + M ;

lim
(x,y)→(x0,y0)

lim
(x,y)→(x0,y0)

f (x, y) ⋅ g(x, y) = L ⋅ M ;

C ⋅ f (x, y) = C ⋅ L

Demonstração: (Lima[13])

1) Pela deﬁnição 1.7, demonstrar que

lim
(x,y)→(x0,y0)

[f (x, y) + g(x, y)] = L + M,

implica em demonstrar que dado ε > 0, existe δ > 0 tal que:

sempre que

∣[f (x, y) + g(x, y)] − (L + M )∣ < ε

√

0 <

(x − x0)2 + (y − y0)2 < δ.

Como por hipótese, existem os limites

lim
(x,y)→(x0,y0)

f (x, y) = L e

lim
(x,y)→(x0,y0)

g(x, y) = M,

os valores

∣f (x, y) − L∣

e

∣g(x, y) − M ∣

podem tornar-se arbitrariamente pequenos quando escolhemos (x, y) suﬁciente-
mente próximo de (x0, y0). Em particular, podem tornar-se menores que ε
. Desta
2
forma temos que

∣f (x, y) − L∣ <

ε
2

sempre que

e

√

0 <

(x − x0)2 + (y − y0)2 < δ1

∣g(x, y) − M ∣ <

ε
2

14

sempre que

√

0 <

(x − x0)2 + (y − y0)2 < δ2.

Tomando δ = min{δ1, δ2}, temos que:

e

sempre que

∣f (x, y) − L∣ <

∣g(x, y) − M ∣ <

ε
2

ε
2

√

0 <

(x − x0)2 + (y − y0)2 < δ.

Usando as propriedades associativa e comutativa da adição, bem como a desi-
gualdade triangular, temos:

∣[f (x, y) + g(x, y) − (L + M )]∣ = ∣[f (x, y) − L] + [g(x, y) − M ]∣ ≤

sempre que

Isso mostra que

≤ ∣f (x, y) − L∣ + ∣g(x, y) − M ∣ <

ε
2 +

ε
2 = ε

√

0 <

(x − x0)2 + (y − y0)2 < δ.

lim
(x,y)→(x0,y0)

[f (x, y) + g(x, y)] = L + M.

2) Para demonstrar que

lim
(x,y)→(x0,y0)

f (x, y) ⋅ g(x, y) = L ⋅ M,

vamos inicialmente considerar o seguinte caso particular:

sejam as funções f (x, y) e h(x, y), tais que

e

Queremos demonstrar que

lim
(x,y)→(x0,y0)

f (x, y) = L

lim
(x,y)→(x0,y0)

h(x, y) = 0.

lim
(x,y)→(x0,y0)

f (x, y) ⋅ h(x, y) = 0,

ou seja, dado ε > 0, existe δ > 0 tal que

sempre que

∣f (x, y) ⋅ h(x, y)∣ < ε

√

0 <

(x − x0)2 + (y − y0)2 < δ.

Assim, tomando ε = 1, temos que

15

sempre que

Mas,

Então,

sempre que

Por outro lado, para

∣f (x, y) − L∣ < 1

√

0 <

(x − x0)2 + (y − y0)2 < δ1.

∣f (x, y)∣ = ∣f (x, y) − L + L∣ ≤ ∣f (x, y) − L∣ + ∣L∣ < 1 + ∣L∣.

∣f (x, y)∣ < 1 + ∣L∣

√

0 <

(x − x0)2 + (y − y0)2 < δ1.

lim
(x,y)→(x0,y0)

h(x, y) = 0,

temos que ∣h(x, y)∣ pode tornar-se suﬁcientemente pequeno quando aproximamos
(x, y) de (x0, y0), de tal forma que

∣h(x, y)∣ <

ε
(1 + ∣L∣)

sempre que

0 <
Portanto, se tomarmos δ = min{δ1, δ2}, temos que

(x − x0)2 + (y − y0)2 < δ2.

√

∣f (x, y) ⋅ h(x, y)∣ = ∣f (x, y)∣ ⋅ ∣h(x, y)∣ < (1 + ∣L∣) ⋅ ∣h(x, y)∣ < (1 + ∣L∣) ⋅

ε
(1 + ∣L∣)

= ε

sempre que

Isso mostra que

√

0 <

(x − x0)2 + (y − y0)2 < δ.

lim
(x,y)→(x0,y0)

f (x, y) ⋅ h(x, y) = 0.

Vamos agora demonstrar que

lim
(x,y)→(x0,y0)

f (x, y) ⋅ g(x, y) = L ⋅ M.

Isto é, dado ε > 0, existe δ > 0 tal que

sempre que

∣[f (x, y) ⋅ g(x, y)] − L ⋅ M ∣ < ε

√

0 <

(x − x0)2 + (y − y0)2 < δ.

16

Temos que

[f (x, y) ⋅ g(x, y) − L ⋅ M ] = f (x, y) ⋅ g(x, y) − f (x, y) ⋅ M + f (x, y) ⋅ M − L ⋅ M =

= f (x, y) ⋅ [g(x, y) − M ] + M ⋅ [f (x, y) − L].

Como

e

segue que

lim
(x,y)→(x0,y0)

f (x, y) = L

lim
(x,y)→(x0,y0)

g(x, y) = M,

lim
(x,y)→(x0,y0)

[f (x, y) − L] = 0 =

lim
(x,y)→(x0,y0)

[g(x, y) − M ].

Portanto, pelos resultados do caso particular, temos que:

lim
(x,y)→(x0,y0)

f (x, y) ⋅ [g(x, y) − M ] = 0 =

lim
(x,y)→(x0,y0)

M ⋅ [f (x, y) − L].

Tomando os resultados obtidos na demonstração do item (1), temos que

lim
(x,y)→(x0,y0)

[f (x, y) ⋅ g(x, y) − L ⋅ M ] = 0,

ou seja,

lim
(x,y)→(x0,y0)

[f (x, y) ⋅ g(x, y)] = L ⋅ M.

Como queríamos demonstrar.

3) Para demonstração de

do item (2).

lim
(x,y)→(x0,y0)

C ⋅ f (x, y) = C ⋅ L usamos raciocínio análogo ao

∎

Deﬁnição 1.10. (Continuidade) Seja f uma função deﬁnida sobre uma bola aberta
f (x, y) e
contendo (x0, y0). Dizemos que f é contínua em (x0, y0) se existe
f (x, y) = f (x0, y0). Dizemos que f é contínua num conjunto D, se ela for

lim
(x,y)→(x0,y0)

lim
(x,y)→(x0,y0)
contínua em todos os pontos desse conjunto.

Teorema 1.11. (Propriedades da continuidade) Se as funções f e g são contínuas
no ponto (x0, y0) e C é uma constante, então (C ⋅ f ), (f + g) e (f ⋅ g) também são
contínuas em (x0, y0).

Demonstração: (Lima [13]) Tomando f (x, y) e g(x, y) contínuas em (x0, y0), então,
da deﬁnição 1.10 temos que

lim
(x,y)→(x0,y0)

f (x, y) = f (x0, y0)

17

e

Dos itens (1), (2) e (3) do teorema 1.9, notamos que

lim
(x,y)→(x0,y0)

g(x, y) = g(x0, y0).

lim
(x,y)→(x0,y0)

[f (x, y) + g(x, y)] = f (x0, y0) + g(x0, y0),

lim
(x,y)→(x0,y0)

[f (x, y) ⋅ g(x, y)] = f (x0, y0) ⋅ g(x0, y0),

lim
(x,y)→(x0,y0)

[C ⋅ f (x, y)] = C ⋅ f (x0, y0).

e

Logo:

[f (x, y) + g(x, y)], [f (x, y) ⋅ g(x, y)]

e

[C ⋅ f (x, y)]

são contínuas em (x0, y0).
∎
Teorema 1.12. Polinômios nas variáveis x e y são funções contínuas em todo ponto
de R2.

Demonstração: (Lima [13]): Dos itens (1) e (2) do teorema 1.9, segue por indução
que se C1, C2, ⋯, Cn são constantes e f1(x, y), f2(x, y), ⋯, fn(x, y) são funções tais que

lim
(x,y)→(x0,y0)

fi(x, y), {i = 1, 2, ⋯, n} existem, então

n
[
∑
i=1
Do item (2) do teorema 1.9, segue por indução que:

lim
(x,y)→(x0,y0)

Ci ⋅ fi(x, y)] =

n
∑
i=1

Ci ⋅ [

lim
(x,y)→(x0,y0)

fi(x, y)] .

(1.1)

[f1(x, y)⋯fn(x, y)] = [

lim
(x,y)→(x0,y0)
Do teorema 1.8, itens (b) e (c) e da equação (1.2), temos que se m e n são inteiros

lim
(x,y)→(x0,y0)

lim
(x,y)→(x0,y0)

f1(x, y)] ⋯ [

fn(x, y)] .

(1.2)

não negativos, então:

e

lim
(x,y)→(x0,y0)

xm

= [

lim
(x,y)→(x0,y0)

x] ⋯ [

lim
(x,y)→(x0,y0)

x] = xm

0

lim
(x,y)→(x0,y0)

yn

= [

lim
(x,y)→(x0,y0)

y] ⋯ [

lim
(x,y)→(x0,y0)

y] = yn
0 .

(1.3)

(1.4)

Do item (2) do teorema 1.9, das equações (1.3) e (1.4), concluímos que se m, n são
inteiros não negativos, então

lim
(x,y)→(x0,y0)

xm

⋅ yn

= xm

0 ⋅ yn
0 .

Das equações (1.1) e (1.5), concluímos que se f (x, y) é um polinômio, então

lim
(x,y)→(x0,y0)

f (x, y) = f (x0, y0).

(1.5)

(1.6)

Portanto, do teorema 1.11 e da equação (1.6) segue que polinômios nas variáveis x e y
são funções contínuas em todo ponto de R2.
∎

18

Exemplo 1.13. Seja a função f ∶ D ⊂ R2 → R, dada por

f (x, y) = x4

+ 5x3y2

+ 6xy4

+ 6.

Temos que f (x, y) é uma função polinomial, daí segue do teorema 1.12 e da equação
(1.6) que

lim
(x,y)→(x0,y0)

f (x, y) = f (x0, y0),

qualquer (x0, y0) ∈ D. Ou seja, f (x, y) é contínua em todo ponto (x0, y0) em R2.

Deﬁnição 1.14. Seja uma função f ∶ D ⊂ R2 → R, dada por z = f (x, y). Deﬁnimos a
derivada parcial de f em relação a x por

∂f
∂x (x, y) = lim

∆x→0

f (x + ∆x, y) − f (x, y)
∆x

se tal limite existir. Analogamente a derivada parcial de f em relação a y é deﬁnida
por

∂f
∂y (x, y) = lim

∆y→0

f (x, y + ∆y) − f (x, y)
∆y

se tal limite existir.
Exemplo 1.15. Seja a função f (x, y) = 5x2 + 2xy + 2y2. Queremos encontrar ∂f
e ∂f
∂y (x, y). Segue que:
i. ∂f

∂x (x, y) = lim

∆x→0

f (x + ∆x, y) − f (x, y)
∆x

=

∂x (x, y)

= lim
∆x→0

5(x + ∆x)2 + 2(x + ∆x)y + 2y2 − (5x2 + 2xy + 2y2)
∆x

= lim
∆x→0

10x∆x + 5(∆x)2 + 2y∆x
∆x

∆x→0(10x − 5∆x + 2y) = 10x + 2y.
= lim

ii. ∂f

∂y (x, y) = lim

∆y→0

f (x, y + ∆y) − f (x, y)
∆y

=

= lim
∆x→0

5x2 + 2x(y + ∆y) + 2(y + ∆y)2 − (5x2 + 2xy + 2y2)
∆y

∆x→0(2x + 4y + 2∆y) = 2x + 4y.
= lim

19

Tomando

e

∂f
∂x (x, y) = 10x + 2y

∂f
∂y (x, y) = 2x + 4y,

temos que se (x0, y0) = (1, 1) é um ponto particular do domínio de f , então

∂f
∂x (1, 1) = 10 + 2 = 12

e

∂f
∂y (1, 1) = 2 + 4 = 6.
Observação 1.16. Na prática, quando derivamos uma função parcialmente, tomamos
uma variável e as outras consideramos como constante. Assim, a derivação é feita como
se fosse para uma função ordinária, onde todas as regras de derivação para funções
de uma variável continuam válidas. Portanto, usando a deﬁnição, é possível provar
(vide[12]) que as derivadas parciais satisfazem as seguintes propriedades para cada
variável:

i. Se c é uma constante e se f (x) = c para todo x, então f ′(x) = 0 ;

ii. Se f e g são funções, se h é a função deﬁnida por h(x) = f (x) + g(x), e se f ′(x)

e g′(x) existem, então h′(x) = f ′(x) + g′(x);

iii. Se f e g são funções, se h é a função deﬁnida por h(x) = f (x) ⋅ g(x), e se f ′(x) e

g′(x) existem, então h′(x) = f (x) ⋅ g′(x) + g(x) ⋅ f ′(x);

iv. Se f e g são funções, se h é a função deﬁnida por

h(x) =

f (x)
g(x)

,

onde

g(x) ≠ 0,

e se f ′(x) e g′(x) existem, então

h′(x) =

g(x) ⋅ f ′(x) − f (x) ⋅ g′(x)
[g(x)]2

.

Estamos interessados em funções polinomiais, onde as propriedades supramenciona-
das são necessárias para o cálculo das derivadas parciais dessas funções. Por atender
particularmente nossos interesses, destacamos a seguinte propriedade:

Teorema 1.17. A função f (x) = xn, com n inteiro, é derivável para todo x ∈ R se
n ≥ 0 e derivável para x ∈ R∗ se n < 0. Nos dois casos f ′(x) = nxn−1.

Demonstração: Separamos a demonstração em duas partes: primeiro encontraremos
a derivada de xn para n ≥ 0 usando a fórmula do binômio de Newton [12]. Em seguida,
encontraremos a derivada de xn para n < 0 usando a derivada do quociente [12].

1) Seja f (x) = xn, com n ≥ 0. Pela deﬁnição de derivada temos que

f ′(x) = lim
h→0

f (x + h) − f (x)
h

= lim
h→0

(x + h)n − xn
h

.

20

Expandindo (x + h)n, obtemos
n
n
1)xn−1h1
0)xn−0h0

(x + h)

+ (

= (

n

+ ⋯ + (

n

n − 1)xn−(n−1)hn−1

n
n)xn−nhn,

+ (

o que corresponde a

(x + h)

n

= xn

+ nxn−1h + ⋯ + nxhn−1

+ hn.

Logo,

− xn
Colocando h em evidência na igualdade anterior, obtemos

= nxn−1h + ⋯ + nxhn−1

(x + h)

n

+ hn.

n
(x + h)

− xn

= h(nxn−1

+ ⋯ + nxhn−2

+ hn−1

).

Dividindo ambos os lados da igualdade anterior por h, resulta em

(x + h)n − xn
h

= (nxn−1

+ ⋯ + nxhn−2

+ hn−1

).

Portanto,

f ′(x) = lim
h→0

(x + h)n − xn
h

h→0(nxn−1
= lim

+ ⋯ + nxhn−2

+ hn−1

) = nxn−1.

2) Seja f (x) = xn, com n < 0. Tomando n = −m, com m > 0 e xn = x−m =
. Se x ≠ 0 então, pela derivada do quociente segue que

que f (x) =

1
xm

f ′(x) =

(1)′(xm) − 1(xm)′
(xm)2

−mxm−1
x2m

=

= −mx−m−1

= nxn−1.

1
xm

, temos

∎

Diante disto, e retomando o exemplo 1.15 podemos determinar ∂f

∂x (x, y) e ∂f

∂y (x, y)

usando 1.17. Assim, temos que

e

∂
∂x (5x2

∂
∂y (5x2

+ 2xy + 2y2

) = 2 ⋅ 5x2−1

+ 2x1−1y = 10x + 2y

+ 2xy + 2y2

) = 2xy1−1

+ 2 ⋅ 2y2−1

= 2x + 4y.

21

Deﬁnição 1.18. Seja uma função f ∶ D ⊂ R2 → R. Dizemos que o incremento de f no
ponto (x0, y0) ∈ D, denotado por ∆f (x0, y0) é dado por:

∆f (x0, y0) = f (x0 + ∆x, y0 + ∆y) − f (x0, y0).

Deﬁnição 1.19. Uma função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta, é dita
diferenciável em (x0, y0) se o incremento de f em (x0, y0) pode ser escrito por

∆f (x0, y0) =

∂
∂x (x0, y0)∆x +

∂
∂y (x0, y0)∆y + λ1∆x + λ2∆y,

onde λ1 e λ2 são funções de ∆x e ∆y tal que λ1 → 0 e λ2 → 0 quando (∆x, ∆y) → (0, 0).

Teorema 1.20. Se a função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta é diferen-
ciável no ponto (x0, y0) ∈ D, então ela é contínua neste ponto.

Demonstração: (Leithold [12]) Das deﬁnições 1.18 e 1.19 segue que

f (x0 + ∆x, y0 + ∆y) − f (x0, y0) =

∂
∂x (x0, y0)∆x +

∂
∂y (x0, y0)∆y + λ1∆x + λ2∆y.

Logo,

f (x0 + ∆x, y0 + ∆y) = f (x0, y0) +

∂
∂x (x0, y0)∆x +

∂
∂y (x0, y0)∆y + λ1∆x + λ2∆y.

Assim, tomando o limite quando ∆x e ∆y tendem a zero temos

lim
(∆x,∆y)→(0,0)

f (x0 + ∆x, y0 + ∆y) =

=

lim
(∆x,∆y)→(0,0)

[f (x0, y0) +

∂
∂x (x0, y0)∆x +

∂
∂y (x0, y0)∆y + λ1∆x + λ2∆y] ,

podemos reescrever como:

lim
(∆x,∆y)→(0,0)

f (x0 + ∆x, y0 + ∆y) =

lim
(∆x,∆y)→(0,0)

f (x0, y0) +

lim
(∆x,∆y)→(0,0)

∂
∂x (x0, y0)∆x+

+

lim
(∆x,∆y)→(0,0)

∂
∂y (x0, y0)∆y +

lim
(∆x,∆y)→(0,0)

λ1∆x +

lim
(∆x,∆y)→(0,0)

λ2∆y.

Mas

Então, do item (2) do teorema 1.9, segue que

lim
∆x→0

∆x = lim
∆y→0

∆y = 0.

lim
(∆x,∆)y→(0,0)

∂
∂x (x0, y0)∆x = 0 =

lim
(∆x,∆y)→(0,0)

∂
∂y (x0, y0)∆y

e

lim
(∆x,∆y)→(0,0)

λ1∆x = 0 =

lim
(∆x,∆y)→(0,0)

λ2∆y.

22

Desta forma, temos que

lim
(∆x,∆y)→(0,0)

f (x0 + ∆x, y0 + ∆y) =

lim
(∆x,∆y)→(0,0)

f (x0, y0).

Como

segue que

lim
(∆x,∆y)→(0,0)

f (x0, y0) = f (x0, y0),

lim
(∆x,∆y)→(0,0)

f (x0 + ∆x, y0 + ∆y) = f (x0, y0).

(1.7)

Tomando x0 + ∆x = x e y0 + ∆y = y, temos que f (x0 + ∆x, y0 + ∆y) = f (x, y) e
(∆x, ∆y) → (0, 0) é equivalente a (x, y) → (x0, y0). Então, da equação (1.7) segue que

lim
(x,y)→(x0,y0)

f (x, y) = f (x0, y0).

Portanto, da deﬁnição 1.10 concluímos que f é contínua em (x0, y0).

∎

Deﬁnição 1.21. Dada uma função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta e
um ponto (x0, y0) ∈ D. Dizemos que f é diferenciável em (x0, y0) se existirem a, b ∈ R,
tais que:

lim
(∆x,∆y)→(x0,y0)

f (x0 + ∆x, y0 + ∆y) − f (x0, y0) − a∆x − b∆y
(∆x)2 + (∆y)2

√

= 0.

Teorema 1.22. Se uma função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta é
diferenciável em um ponto (x0, y0) ∈ D, então existem as derivadas parciais ∂f
∂x (x0, y0)
e ∂f
∂y (x0, y0).

Demonstração: (Leithold [12]) Da deﬁnição 1.21 temos que

i. tomando (∆x, 0) segue que

lim
(∆x,∆y)→(x0,y0)

f (x0 + ∆x, y0 + ∆y) − f (x0, y0) − a∆x − b∆y
(∆x)2 + (∆y)2

√

= 0

⇐⇒ lim
∆x→0

⇐⇒ lim
∆x→0

⇐⇒ lim
∆x→0

√

f (x0 + ∆x, y0) − f (x0, y0) − a∆x
∆x2
f (x0 + ∆x, y0) − f (x0, y0) − a∆x
∣∆x∣
f (x0 + ∆x, y0) − f (x0, y0)
∆x

= a.

= 0

= 0

ii. tomando (0, ∆y) segue que

lim
(∆x,∆y)→(x0,y0)

f (x0 + ∆x, y0 + ∆y) − f (x0, y0) − a∆x − b∆y
(∆x)2 + (∆y)2

√

= 0

23

= 0

= 0

⇐⇒ lim
∆y→0

f (x0, y0 + ∆y) − f (x0, y0) − b∆y
∆y2

√

⇐⇒ lim
∆y→0

f (x0, y0 + ∆y) − f (x0, y0) − b∆y
∣∆y∣
f (x0, y0 + ∆y) − f (x0, y0)
∆y

= b.

⇐⇒ lim
∆y→0

Assim, pela deﬁnição 1.14 temos que ∂f

∂y (x0, y0) = b. Portanto, se
f é diferenciável no ponto (x0, y0) ∈ D, então a e b da deﬁnição 1.21 são as derivadas
parciais nesse mesmo ponto.
∎

∂x (x0, y0) = a e ∂f

Teorema 1.23. Seja f ∶ D ⊂ R2 → R uma função de duas variáveis x e y deﬁnida
∂x (x0, y0) e ∂f
sobre uma bola aberta. Supondo que ∂f
∂x (x0, y0) e

∂y (x0, y0) existam. Se ∂f

∂f
∂y (x0, y0) forem contínuas em (x0, y0) ∈ D, então f é diferenciável nesse ponto.
Demonstração: (Leithold [12]) Considerando o teorema do valor médio para uma
função de uma variável aplicado para uma função de duas variáveis (vide demonstração
em [12]) e tomando um ponto (x0 + ∆x, y0 + ∆y) ∈ D, temos que

∆f (x0, y0) = f (x0 + ∆x, y0 + ∆y) − f (x0, y0).

Somando e subtraindo f (x0 + ∆x, y0) no lado direito da equação acima, obtemos

∆f (x0, y0) = [f (x0 + ∆x, y0 + ∆y) − f (x0 + ∆x, y0)] + [f (x0 + ∆x, y0) − f (x0, y0)] (1.8)

Por hipótese ∂f
∂x

e ∂f
∂y

existem em (x0 + ∆x, y0 + ∆y), então se tomarmos λ1 e λ2

respectivamente entre (x0, x0 + ∆x) e (y0, y0 + ∆y), segue que

f (x0 + ∆x, y0 + ∆y) − f (x0 + ∆x, y0) = ∆y

∂f
∂y (x0 + ∆x, λ2)

f (x0 + ∆x, y0) − f (x0, y0) = ∆x

∂f
∂x (λ1, y0)

Substituindo (1.9) e (1.10) em (1.8), temos

(1.9)

(1.10)

∂f
∂y (x0 + ∆x, λ2) + ∆x
Como (x0 + ∆x, y0 + ∆y) ∈ D, λ1 e λ2 estão respectivamente entre (x0, x0 + ∆x) e

∂f
∂x (λ1, y0)

∆f (x0, y0) = ∆y

(1.11)

(y0, y0 + ∆y), e ∂f
∂x

e ∂f
∂y

são contínuas, temos que

∂f
∂x (λ1, y0) =

lim
∆(x,y)→(0,0)
∂f
∂y (x0 + ∆x, λ2) =

∂f
∂x (x0, y0)
∂f
∂y (x0, y0)

lim
∆(x,y)→(0,0)

(1.12)

(1.13)

Se tomarmos

segue da equação (1.12) que

Supondo

β1 =

∂f
∂x (λ1, y0) −

∂f
∂x (x0, y0),

lim
∆(x,y)→(0,0)

β1 = 0.

β2 =

∂f
∂y (x0 + ∆x, λ2) −

∂f
∂y (x0, y0),

segue da equação (1.13) que

Substituindo (1.14) e (1.16) em (1.11), obtemos

lim
∆(x,y)→(0,0)

β2 = 0.

∆f (x0, y0) = ∆y[

∂f
∂y (x0, y0) + β2] + ∆x[

∂f
∂x (x0, y0) + β1],

donde vem

∆f (x0, y0) = ∆x

∂f
∂x (x0, y0) + ∆y

∂f
∂y (x0, y0) + β1∆x + β2∆y.

24

(1.14)

(1.15)

(1.16)

(1.17)

(1.18)

(1.19)

Daí segue que das equações (1.15), (1.17) e (1.19) a deﬁnição 1.18 é veriﬁcada e
pela deﬁnição 1.19 podemos concluir que a função f é diferenciável em (x0, y0) ∈ D. ∎

Considerando as deﬁnições e teoremas que foram apresentados até aqui, queremos

veriﬁcar se uma função polinomial f (x, y) é diferenciável em todo ponto de R2.

Seja então uma função polinomial f ∶ D ⊂ R2 → R. Tendo em vista o que foi descrito
na observação 1.16, bem como a propriedade apresentada pelo teorema 1.17, podemos
dizer que as derivadas parciais de f são polinônimos de grau (n − 1), e, sendo assim,
pelo teorema 1.12 também são contínuas em todos os seus pontos. Isso implica que
existem as derivadas parciais de f em todos os pontos de R2 e estas são contínuas.
Então, pelo teorema 1.23 concluímos que f é diferenciável em todo ponto de R2.

Desta forma, podemos investigar se em alguns desses pontos as derivadas parciais
são nulas. As derivadas parciais nulas consistem em uma condição necessária para que
(x0, y0) ∈ D seja um ponto onde f tenha extremo local, isto é, um ponto de máximo
ou mínimo local.

Estamos interessados em determinar os pontos de míninos de uma certa função
polinomial. Então, considerando os resultados discutidos acima, sabemos que tal função
é diferenciável em todo R2, logo, esta função admite derivadas parciais em todos os
pontos de D. Nesse sentido, e de acordo com Guidorizzi [9], se f admite derivadas
parciais em todos os pontos de D, então os pontos (x0, y0) ∈ D nos quais as derivadas
parciais se anulam são, entre os pontos interiores de D, os únicos candidatos a extremos
locais de f .

25

Em vista disto, para que possamos identiﬁcar os pontos candidatos a extremos
locais, ou mais especiﬁcamente os pontos de mínimos locais de f , temos que garantir
a existência de pontos (x0, y0) ∈ D tais que as derivadas parciais sejam nulas, ou seja,

∂f
∂x (x0, y0) =
Vejamos as seguintes deﬁnições e teoremas:

∂f
∂y (x0, y0) = 0.

Deﬁnição 1.24. Seja uma função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta,
dizemos que (x0, y0) ∈ D é ponto de mínimo local de f se existe um disco aberto
B((x0, y0), r), tal que f (x, y) ≥ f (x0, y0) para todo (x0, y0) ∈ B((x0, y0), r).
Deﬁnição 1.25. Um ponto (x0, y0) para o qual ∂f
minado ponto crítico de f .

∂f
∂y (x0, y0) = 0, é deno-

∂x (x0, y0) =

Teorema 1.26. Se uma função f ∶ D ⊂ R2 → R deﬁnida sobre uma bola aberta é
diferenciável em um ponto (x0, y0) ∈ D, então uma condição necessária para que (x0, y0)
seja um ponto onde f tem um extremo local é que ∂f

∂x (x0, y0) =

∂f
∂y (x0, y0) = 0.

Demonstração: (Leithold [12]) Por hipótese temos que ∂f
∂y (x0, y0) exis-
tem, pois f é diferenciável neste ponto (T eorema1.22). Então, pela deﬁnição 1.14
existem os limites

∂x (x0, y0) e ∂f

lim
∆x→0

f (x0 + ∆x, y0) − f (x0, y0)
∆x

e

lim
∆y→0

f (x0, y0 + ∆y) − f (x0, y0)
∆y

.

Supondo que f tenha um ponto de mínimo local em (x0, y0) ∈ D. Então, segue da
deﬁnição 1.24 que

e

ou seja

e

f (x0 + ∆x, y0) ≥ f (x0, y0)

f (x0, y0 + ∆y) ≥ f (x0, y0),

f (x0 + ∆x, y0) − f (x0, y0) ≥ 0

f (x0, y0 + ∆y) − f (x0, y0) ≥ 0,

sempre que ∆x e ∆y forem suﬁcientemente pequenos, tais que
(x0 + ∆x, y0) e (x0, y0 + ∆y) estejam em um disco aberto B contendo (x0, y0). Desta
forma, observamos que:

26

i. Se ∆x aproxima-se de zero pela esquerda, então ∆x < 0. Assim,

f (x0 + ∆x0, y0) − f (x0, y0)
∆x

≤ 0,

já que o numerador é positivo. Logo, ∂f

∂x (x0, y0) ≤ 0;

ii. Analogamente, se ∆x aproxima-se de zero pela direita, então ∆x > 0. Assim,

f (x0 + ∆x0, y0) − f (x0, y0)
∆x

≥ 0.

Logo, ∂f

∂x (x0, y0) ≥ 0;

iii. Utilizando o mesmo raciocínio para ∆y, temos que ∆y aproxima-se de zero pela

esquerda, então ∆y < 0. Logo,

f (x0, y0 + ∆y0) − f (x0, y0)
∆y

≤ 0,

ou seja, ∂f

∂y (x0, y0) ≤ 0;

iv. Se ∆y aproxima-se de zero pela direita, então ∆y > 0. Assim,

f (x0, y0 + ∆y0) − f (x0, y0)
∆y

≥ 0.

Logo, ∂f

∂y (x0, y0) ≥ 0.

De acordo com o que foi exposto, concluímos que se ∂f

∂x (x0, y0) e ∂f

∂y (x0, y0) existem,

então as desigualdades

e

∂f
∂x (x0, y0) ≤ 0,

∂f
∂x (x0, y0) ≥ 0

∂f
∂y (x0, y0) ≤ 0,

∂f
∂y (x0, y0) ≥ 0

devem valer simultaneamente, o que necessariamente implica em

∂f
∂x (x0, y0) =

∂f
∂y (x0, y0) = 0.

Exemplo 1.27. Dada a função f (x, y) = 3x2 − 4xy + 3y2 + 8x − 17y + 30

∎

e o ponto de mínimo (x0, y0) = (1, 7

2), queremos veriﬁcar se ∂f

∂x (x0, y0) =

∂f
∂y (x0, y0) = 0.

27

isso implica que existem as derivadas parciais ∂f

De fato, como f é polinomial, então é diferenciável em todo ponto (x0, y0) ∈ R2. E
∂y (x0, y0). Portanto, para

∂x (x0, y0) e ∂f

o ponto (x0, y0) = (1, 7

2) temos que:

∂f
∂x (x0, y0) = 6x0 − 4y0 + 8 = 6 ⋅ 1 − 4 ⋅

7
2 + 8 = 0

e

∂f
∂y (x0, y0) = −4x0 + 6y0 − 17 = −4 ⋅ 1 + 6 ⋅

A ﬁgura 1.1 ilustra o gráﬁco de f e a localização do ponto P = (1,

7
2 − 17 = 0.
7
2 ) sobre ele:

Figura 1.1: Ponto de mínimo

Fonte: Figura gerada pelo autor

O teorema 1.26 estabelece que os pontos críticos consistem em uma condição neces-
sária para que (x0, y0) ∈ D seja extremo local. Mas a anulação das derivadas parciais
não é condição suﬁciente para que uma função tenha extremo local em (x0, y0) ∈ D.
Um exemplo clássico desta situação pode ser constatado pela função f (x, y) = x2 − y2,
∂f
em que ∂f
∂y (0, 0) = 0, porém f não tem extremo local em (0, 0). Neste caso,
esses pontos são denominados pontos de sela. Desta forma, o teorema 1.26 nos fornece
um critério para selecionar, entre os pontos de D, candidatos a extremos locais. No en-
tanto, esse critério não nos garante que os pontos selecionados sejam de fato extremos
locais.

∂x (0, 0) =

Assim, precisamos de algum critério que estabeleça uma condição suﬁciente para
que os pontos críticos de f sejam extremos locais. Segundo Guidorizzi [9], um cri-

28

tério usualmente denominado teste da derivada segunda nos garante essa condição.
Observemos então, as deﬁnições e o teorema a seguir:

Observação 1.28. Seja uma função de duas variáveis f ∶ D ⊂ R2 → R deﬁnida sobre
uma bola aberta. Em geral, ∂f
também são funções de duas variáveis. Denotamos
∂x
estas funções por:

e ∂f
∂y

∂f
∂x = f1

e

∂f
∂y = f2.

Deﬁnição 1.29. Se as derivadas parciais de f1 e f2 existem, podemos denominá-las
derivadas parciais segundas de f . Assim, dizemos que:

i. A derivada parcial segunda de f , em relação a x, é a função dada por

∂2f
∂x2 =

∂f1
∂x = lim

∆x→0

f1(x + ∆x, y) − f1(x, y)
∆x

;

ii. A derivada parcial segunda de f , em relação a y, é a função dada por

∂2f
∂y2 =

∂f2
∂y = lim

∆y→0

f2(x, y + ∆y) − f2(x, y)
∆y

;

iii. A derivada parcial segunda de f , em relação a x e y, é a função dada por

∂2f
∂x∂y =

∂f2
∂x = lim

∆x→0

f2(x + ∆x, y) − f2(x, y)
∆x

;

iv. A derivada parcial segunda de f , em relação a y e x, é a função dada por

∂2f
∂y∂x =

∂f1
∂y = lim

∆y→0

f1(x, y + ∆y) − f1(x, y)
∆y

.

Exemplo 1.30. Dada a função f (x, y) = x7y5 − 2x3y2 + 5. Queremos determinar todas
as derivadas parciais segundas de f . Do teorema 1.17, da observação 1.28 e da deﬁnição
1.29 segue que:

i. f1 =

ii. f2 =

∂f
∂x = 7x6y5 − 6x2y2;
∂f
∂y = 5x7y4 − 4x3y;
∂f1
∂x = 42x5y5 − 12xy2;
∂f2
∂y = 20x7y3 − 4x3;
∂f2
∂x = 35x6y4 − 12x2y;
∂f1
∂y = 35x6y4 − 12x2y.

iii. ∂2f

∂x2 =

iv. ∂2f

∂y2 =

v. ∂2f

∂x∂y =

vi. ∂2f

∂y∂x =

29

Teorema 1.31. (Teste da derivada segunda) Dada uma função f ∶ D ⊂ R2 → R,
tal que suas derivadas parciais primeira e segunda sejam contínuas em uma bola aberta
B((x0, y0), r), com (x0, y0) ∈ D ponto crítico de f . Então temos que:

i. f tem um valor de mínimo local em (x0, y0) ∈ D se

∂2f
∂x2 (x0, y0) ⋅

∂2f
∂y2 (x0, y0) − [

∂2f
∂x∂y (x0, y0)]

2

> 0

e

∂2f
∂x2 (x0, y0) > 0;

ii. f tem um valor de máximo local em (x0, y0) ∈ D se

∂2f
∂x2 (x0, y0) ⋅

∂2f
∂y2 (x0, y0) − [

∂2f
∂x∂y (x0, y0)]

2

> 0

e

∂2f
∂x2 (x0, y0) < 0;

iii. f não tem um valor de extremo local em (x0, y0) ∈ D se

∂2f
∂x2 (x0, y0) ⋅

∂2f
∂y2 (x0, y0) − [

∂2f
∂x∂y (x0, y0)]

iv. Não podemos chegar a nenhuma conclusão se

∂2f
∂x2 (x0, y0) ⋅

∂2f
∂y2 (x0, y0) − [

∂2f
∂x∂y (x0, y0)]

2

2

< 0;

= 0.

Demonstração: (Leithold [12]) Faremos a demonstração apenas do item (i) do teo-
rema 1.31, pois este é pertinente ao nosso interesse em determinar pontos de mínimo
de uma certa função. Pois bem, seja

Φ(x0, y0) =

∂2f
∂x2 (x0, y0) ⋅

∂2f
∂y2 (x0, y0) − [

∂2f
∂x∂y (x0, y0)]

2

> 0.

Dado que

Φ(x0, y0) > 0 e

∂2f
∂x2 (x0, y0) > 0,

queremos mostrar que f (x0, y0) é um valor de mínimo local de f em D. Como as de-
rivadas parciais segundas são contínuas em B((x0, y0), r), segue que Φ(x0, y0) também
é contínua em B. Logo, existe uma bola aberta B1((x0, y0), r1), onde r1 ≤ r, tal que
Φ(x0, y0) > 0 e ∂2f

∂x2 (x0, y0) > 0 para todo (x0, y0) em B1.

Sejam h e k constantes, ambas não nulas, tais que o ponto (x0 + h, y0 + k) esteja em
B1. Então as equações x = x0 + ht e y = y0 + kt, com 0 ≤ t ≤ 1 deﬁnem todos os pontos
no segmento de reta de (x0, y0) a (x0 + h, y0 + k) e todos esses pontos estão em B1.

Seja F a função de uma variável deﬁnida por

Pela fórmula de Taylor [12], temos que

F (t) = f (x0 + ht, y0 + kt).

F (t) = F (0) + F ′

(0)t + F ′′ (ξ)
2!

t2,

(1.20)

(1.21)

30

onde F ′ e F ′′ são respectivamente as derivadas primeira e segunda de F e ξ está entre
0 e t.
Então se tomarmos t = 1 na equação (1.21), temos que
(0) + F ′′ (ξ)
2

F (1) = F (0) + F ′

(1.22)

,

onde 0 < ξ < 1.
Como F (0) = f (x0, y0) e F (1) = f (x0 + h, y0 + k), segue da equação (1.22) que

f (x0 + h, y0 + k) = f (x0, y0) + F ′

(0) +

(ξ).

F ′′

1
2
(t) e F ′′

Usando a regra da cadeia [12] para encontrarmos F ′

(t), obtemos

F ′

(t) = h

∂f
∂x (x0 + ht, y0 + kt) + k

∂f
∂y (x0 + ht, y0 + kt)

e

(1.23)

(1.24)

F ′′

(t) = h2 ∂2f

∂x2 (x0+ht, y0+kt)+2hk
Substituindo t por 0 na equação (1.24) obtemos

∂2f

∂x∂y (x0+ht, y0+kt)+k2 ∂2f

∂y2 (x0+ht, y0+kt). (1.25)

F ′

(0) = h

∂f
∂x (x0, y0) + k

∂f
∂y (x0, y0),

pois pelo teorema 1.26 temos que

∂f
∂x (x0, y0) =

∂f
∂y (x0, y0) = 0.

Assim segue que

e substituindo t por ξ na equação (1.25) obtemos

F ′

(0) = 0

(1.26)

F ′′

(t) = h2 ∂2f

∂x2 (x0+hξ, y0+kξ)+2hk

∂2f

∂x∂y (x0+hξ, y0+kξ)+k2 ∂2f

∂y2 (x0+hξ, y0+kξ). (1.27)

Substituindo agora as equações (1.26) e (1.27) na equação (1.23) obtemos

f (x0 + h, y0 + k) − f (x0, y0) =

1

2 [h2 ∂2f

∂x2 (x0 + hξ, y0 + kξ) + 2hk

=

∂2f

∂x∂y (x0 + hξ, y0 + kξ) + k2 ∂2f

∂y2 (x0 + hξ, y0 + kξ)] .
(1.28)

Os termos entre colchetes no lado direito da equação 1.28 podem ser escritos por

[h2 ∂2f

∂x2 (x0 + hξ, y0 + kξ) + 2hk

∂2f

∂x∂y (x0 + hξ, y0 + kξ) + k2 ∂2f

∂y2 (x0 + hξ, y0 + kξ)] =

=

+ 2hk ⋅

∂2f
∂x2

⎞
⎟
⎟
⎟
⎠
Assim, da equação (1.28) temos

⎛
⎜
⎜
⎜
⎝

∂2f
∂x∂y
∂2f
∂x2

⎡
⎢
⎢
⎢
h2
⎢
⎢
⎢
⎢
⎢
⎣

31

+ k2

⋅

∂2f
∂x∂y
∂2f
∂x2

⎛
⎜
⎜
⎜
⎝

2
⎞
⎟
⎟
⎟
⎠

− k2

⋅

∂2f
∂x∂y
∂2f
∂x2

⎛
⎜
⎜
⎜
⎝

2
⎞
⎟
⎟
⎟
⎠

+ k2

⋅

∂2f
∂y2
∂2f
∂x2

⎛
⎜
⎜
⎜
⎝

.

⎞
⎟
⎟
⎟
⎠

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

f (x0 + h, y0 + k) − f (x0, y0) =

∂2f
2∂x2 ⋅

⎡
⎢
⎛
⎢
⎢
⎜
⎢
h + k ⋅
⎜
⎢
⎜
⎢
⎢
⎝
⎢
⎣

∂2f
∂x∂y
∂2f
∂x2

⎛
⎜
⎜
⎜
⎝

2
⎞
⎟
⎟
⎟
⎠

⎞
⎟
⎟
⎟
⎠

+

∂2f
∂x2 ⋅

2

∂2f
∂x∂y ]

2

∂2f
∂y2 − [
∂2f
∂x2 )

(

Como ∂2f
∂x2 ⋅

∂2f
∂y2 − [

2

∂2f
∂x∂y ]

calculada em (x0 + hξ, y0 + kξ) é igual a

Φ(x0 + hξ, y0 + kξ) > 0. Então temos que

.

⋅ k2

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
(1.29)

∂2f
2∂x2 ⋅

⎡
⎢
⎛
⎢
⎢
⎜
⎢
h + k ⋅
⎜
⎢
⎜
⎢
⎢
⎝
⎢
⎣

2

∂2f
∂x∂y
∂2f
∂x2

⎛
⎜
⎜
⎜
⎝

⎞
⎟
⎟
⎟
⎠

⎞
⎟
⎟
⎟
⎠

+

∂2f
∂x2 ⋅

∂2f
∂y2 − [
∂2f
∂x2 )

(

2

∂2f
∂x∂y ]

2

⋅ k2

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

> 0.

Daí segue que f (x0 + h, y0 + k) − f (x0, y0) > 0. Logo, f (x0 + h, y0 + k) > f (x0, y0) para
todo (x0 + h, y0 + k) ≠ (x0, y0) em B1. Portanto, pela deﬁnição 1.24, f (x0, y0) é um
valor mínimo local de f .
∎

Exemplo 1.32. Seja a função f ∶ D ⊂ R2 → R, deﬁnida por

f (x, y) = 4x4

+ 2y2

− 2x2

− 4y + 2.

Queremos determinar os extremos locais de f se existirem. Assim, temos que

e

∂f
∂x (x, y) = 16x3

− 4x

∂f
∂y (x, y) = 4y − 4.

Tomando ∂f

∂x (x, y) =

∂f
∂y (x, y) = 0, temos y = 1 e três possibilidades para x, sendo:
, 1), (0, 1)
∂y (x, y) se anulam nos pontos (−

1
2

. Logo, ∂f

, x = 0 ou x =

1
2
, 1). Determinando as derivadas segundas de f obtemos

∂x (x, y) e ∂f

1
2

x = −
1
2

e (

− 4,

∂2f
∂x2 = 48x2
∂2f
∂y2 = 4

32

e

∂2f
∂x∂y = 0.

Aplicando o teste da derivada segunda, segue que:

i. Para o ponto (−

1
2

, 1) temos

∂2f
∂x2 (−

1
2

, 1) = 8 > 0

e

∂2f
∂x2 (−

1
2

, 1) ⋅

∂2f
∂y2 (−

1
2

, 1) − [

∂2f
∂x∂y (−

1
2

2

, 1)]

= 8 ⋅ 4 − 0 = 32 > 0.

Logo, pelo item (i) do teorema 1.31, f tem um valor mínimo local, o qual é dado
por f (−

, 1) = −

;

1
2

1
2

ii. Para o ponto (0, 1) temos

∂2f
∂x2 (0, 1) ⋅

∂2f
∂y2 (0, 1) − [

∂2f
∂x∂y (0, 1)]
Assim, pelo item (iii) do teorema 1.31, f não tem um valor de extremo local em
(0, 1), pois o ponto (0, 1) é ponto de sela de f ;

= (−4) ⋅ 4 − 0 = −16 < 0.

2

iii. Para o ponto (

1
2

, 1) temos

∂2f
∂x2 (

1
2

, 1) = 8 > 0

e

∂2f
∂x2 (

1
2

, 1) ⋅

∂2f
∂y2 (

1
2

, 1) − [

∂2f
∂x∂y (

1
2

2

, 1)]

= 8 ⋅ 4 − 0 = 32 > 0.

Logo, pelo item (i) do teorema 1.31, f tem um valor mínimo local em (

qual é dado por f (

1
2

, 1) = −

.

1
2

1
2

, 1), o

Portanto, f tem um valor mínimo local em cada um dos pontos (−

A ﬁgura 1.2 ilustra o gráﬁco de f com os pontos de mínimo e de sela:

1
2

, 1) e (

1
2

, 1).

Figura 1.2: Ponto de mínimo e sela

33

Fonte: Figura gerada pelo autor

O teorema 1.31 testa os pontos candidatos a extremos locais selecionados de acordo
com o critério estabelecido pelo teorema 1.26. Desta forma, se os candidatos se en-
quadram nas condições descritas pelo teorema 1.31, então são de fato pontos onde a
função possui extremos locais. Em particular, o ítem (i) do mesmo teorema, nos dá
condições de deduzir se os pontos que estamos investigando são efetivamente pontos
de mínimos locais.

Observando o exemplo 1.32, percebemos que uma função pode apresentar vários
pontos de mínimos locais. Mas para o estudo dos mínimos quadrados, estamos inte-
ressados em determinar que o erro seja o menor possível, isto é, do ponto de vista do
cálculo, queremos identiﬁcar dentre os pontos de mínimos locais de uma certa função,
aquele que seja um mínimo global. No entanto, o teorema 1.31 nada aﬁrma sobre a
globalidade do extremo local.

Em vista disso, precisamos estabelecer algum critério que nos garanta a globalidade
do extremo local, ou mais especiﬁcamente, a globalidade do ponto de mínimo. A
esse respeito, Bortolossi [4] aﬁrma que existe uma classe especíﬁca de funções (funções
convexas) para a qual é possível garantir a globalidade. Vejamos as seguintes deﬁnições
e teoremas:

Deﬁnição 1.33. Seja uma função f ∶ D ⊂ R2 → R. Dizemos que p0 = (x0, y0) ∈ D é um
ponto de mínimo global de f se para qualquer p = (x, y) ∈ D temos que f (p) ≥ f (p0).
Neste caso, f (p0) é o valor mínimo global de f em D.

Exemplo 1.34. Sejam uma função f ∶ D ⊂ R2 → R, dada por f (x, y) = 1 + x2 + y2 e o
ponto (x0, y0) = (0, 0). Note que f (0, 0) = 1 e como x2 +y2 ≥ 0 para qualquer (x, y) ∈ R2,
segue que 1 + x2 + y2 ≥ 1 = f (0, 0). Logo, f (x, y) ≥ f (0, 0) para qualquer (x, y) ∈ R2, ou
seja, (x0, y0) = (0, 0) é um ponto de mínimo global de f .

34

Deﬁnição 1.35. Dizemos que D ⊂ R2 é um conjunto convexo quando para quaisquer
p, q ∈ D, veriﬁcamos que [(1 − t)p + tq] ∈ D, para todo t ∈ [0, 1]. Isto é, se o segmento
de reta que une dois pontos quaisquer de D está sempre contido em D. A ﬁgura 1.3
ilustra isto:

Figura 1.3: Região convexa e não convexa

Fonte: Figura gerada pelo autor

Deﬁnição 1.36. Seja uma função f ∶ D ⊂ R2 → R, com D ⊂ R2 um conjunto convexo.
Dizemos que f é uma função convexa quando

f [(1 − t)p + tq] ≤ (1 − t)f (p) + tf (q),

para todo p, q ∈ D e t ∈ [0, 1]. Caso a desigualdade seja veriﬁcada no sentido estrito,
dizemos que a função é estritamente convexa.

Observação 1.37. (Bortolossi [4]) Uma vez escolhidos p, q ∈ D, para cada t ∈ [0, 1]
temos que:

i. As expressões

x(t) = (1 − t)p + tq

e

s(t) = (1 − t)f (p) + tf (q)

compõem os pontos (x(t), s(t)) sobre a reta secante que passa pelos pontos
(p, f (p)) e (q, f (q));

ii. As expressões

x(t) = (1 − t)p + tq

e

f (x(t)) = f ((1 − t)p + tq)

compõem os pontos (x(t), f (x(t))) no gráﬁco de f .

35

Então, dizer que f satisfaz

f [(1 − t)p + tq] ≤ (1 − t)f (p) + tf (q)

da deﬁnição 1.36, signiﬁca aﬁrmar que o segmento de reta secante que passa pelos
pontos (p, f (p)) e (q, f (q)) sempre está acima ou coincide com o gráﬁco de f sobre o
segmento de reta que vai de p a q. A ﬁgura 1.4 ilustra essa aﬁrmação.

Figura 1.4: Função convexa e segmento secante

Fonte: Adaptado de Bortolossi

Os teoremas a seguir recorrem à derivada direcional para estabelecer a convexidade
de uma função diferenciável. Então, vamos efetuar alguns esclarecimentos para melhor
entendimento desses teoremas. De acordo com Bortolossi [4], dada uma função f ∶ D ⊂
R2 → R, onde D ⊂ R2 é um aberto, e um ponto p = (a, b) ∈ D, as derivadas direcionais
representam, geometricamente, um deslocamento no domínio D de f por uma reta que
passa pelo ponto p = (a, b) e cuja direção é dada por um vetor unitário ⃗v = (v1, v2)
denominado vetor diretor. Assim, a medida que efetuamos o deslocamento, analisamos
o comportamento de f sobre a reta.

Mas, para que possamos realizar o deslocamento, devemos considerar o traço da
curva parametrizada α(t) = p+t⃗v que descreve a mencionada reta, tal que esta é paralela
ao vetor ⃗v, α(0) = (a, b) e, para valores suﬁcientemente pequenos de t, α(t) ∈ D. Isto
feito, analisamos o comportamento de f sobre a reta, estudando a função composta de
uma única variável f (α(t)) = f (a + tv1, b + tv2). Ou seja, determinamos o limite
f (p + t⃗v) − f (p)
t

f (a + tv1, b + tv2) − f (a, b)
t

f (α(t)) − f (α(0))
t

= lim
t→0

= lim
t→0

lim
t→0

,

caso ele exista.

Assim, de acordo com a deﬁnição 1.14 podemos denotar

f (p + t⃗v) − f (p)
t

lim
t→0

=

∂f
∂⃗v (p)

36

(1.30)

e ∂f
∂⃗v (p) é o número real denominado derivada direcional de f no ponto p = (a, b) e na
direção do vetor ⃗v = (v1, v2).
Podemos determinar a derivada direcional ∂f
∂⃗v (p), sem fazer uso do cálculo do limite

Para tanto, basta que façamos o produto interno entre o vetor gradiente

f (p + t⃗v) − f (p)
t

.

lim
t→0

∇f (p) = (

∂f
∂x (p),

∂f
∂y (p))

e o vetor diretor ⃗v = (v1, v2). Isto é [4]:

∂f
∂⃗v (p) = ∇f (p) ⋅ ⃗v =

∂f
∂x (p)v1 +

∂f
∂y (p)v2.

(1.31)

Como a derivada direcional representa o deslocamento no domínio D de f , vale
ressaltar que o vetor gradiente ∇f da função f indica o sentido e a direção na qual,
por deslocamento a partir de um ponto p = (a, b), obtemos a máxima variação dessa
função. É perpendicular ao plano tangente ao gráﬁco de f no ponto p = (a, b). Vejamos
a ﬁgura 1.5:

Figura 1.5: Plano tangente ao gráﬁco e vetor gradiente perpendicular

Fonte: Figura gerada pelo autor

Teorema 1.38. Seja um conjunto convexo D ⊂ R2 e f ∶ D ⊂ R2 → R uma função
deﬁnida sobre uma bola aberta e diferenciável em todo ponto de D. Então, f é uma
função convexa em D se, e somente se f (q) ≥ f (p) + (q − p) ⋅ ∇f (p), para quaisquer
p, q ∈ D.

37

Demonstração: (Amorim [1] e Hlenka [10])

(⇒) Seja f diferenciável e convexa em D. Tomando dois pontos quaisquer p, q ∈ D,

deﬁnimos o vetor ⃗v = (q − p) e tomamos t ∈ (0, 1]. Assim, temos

f (p + t⃗v) = f (p + tq − tp) = f [tq + (1 − t)p].

Por hipótese

f [tq + (1 − t)p] ≤ tf (q) + (1 − t)f (p) = tf (q) − tf (p) + f (p) = t[f (q) − f (p)] + f (p).

Portanto,

t[f (q) − f (p)] ≥ t(p + t⃗v) − f (p).
Dividindo ambos os lados da desigualdade por t > 0, temos

f (q) − f (p) ≥

t(p + t⃗v) − f (p)
t

.

Tomando agora o limite quando t → 0+, obtemos

t(p + t⃗v) − f (p)
t

,

f (q) − f (p) ≥ lim
t→0+
sendo que, de acordo com o visto em (1.30), o lado direito da desigualdade (1.32) é
exatamente a derivada direcional de f na direção de ⃗v, no ponto p. Observamos que
embora ⃗v não seja um vetor unitário, como t foi tomado no intervalo (0, 1], o produto
t⃗v atende as condições da deﬁnição de derivada direcional.
Logo, a desigualdade (1.32) pode ser escrita como

(1.32)

f (q) − f (p) ≥

∂f
∂⃗v (p).

(1.33)

Porém, conforme visto em (1.31)

Assim, substituindo em (1.33), temos que

∂f
∂⃗v (p) = ⃗v ⋅ ∇f (p).

f (q) − f (p) ≥ ⃗v ⋅ ∇f (p),

o que é equivalente a

f (q) ≥ f (p) + (q − p) ⋅ ∇f (p).
Portanto, f convexa para quaisquer p, q ∈ D, implica em e f (q) ≥ f (p) + (q − p) ⋅ ∇f (p).
(⇐) Reciprocamente, tomando p, q quaisquer do domínio e x = tq + (1 − t)p com

t ∈ [0, 1], por hipótese temos que

f (x) + (p − x) ⋅ ∇f (x) ≤ f (p)

e

f (x) + (q − x) ⋅ ∇f (x) ≤ f (q).

Mutiplicando a primeira desigualdade por (1 − t) > 0, obtemos

(1 − t)f (x) + (1 − t)(p − x) ⋅ ∇f (x) ≤ (1 − t)f (p).

Multiplicando a segunda desigualdade por t > 0, obtemos

tf (x) + t(q − x) ⋅ ∇f (x) ≤ tf (q).

Somando as desigualdades (1.34) e (1.35), temos

38

(1.34)

(1.35)

tf (x) + (1 − t)f (x) + t(q − x) ⋅ ∇f (x) + (1 − t)(p − x) ⋅ ∇f (x) ≤ tf (q) + (1 − t)f (p).

Efetuando algumas manipulações algébricas no lado esquerdo da desigualdade, obtemos

f (x) + [tq + (1 − t)p − x]∇f (x) ≤ tf (q) + (1 − t)f (p).

Como x = tq + (1 − t)p, então

Daí segue que

Logo,

f (x) + [x − x]∇f (x) ≤ tf (q) + (1 − t)f (p).

f (x) ≤ tf (q) + (1 − t)f (p).

f [tq + (1 − t)p] ≤ tf (q) + (1 − t)f (p).

Portanto, f é uma função convexa em D.

∎

Teorema 1.39. Seja um conjunto convexo D ⊂ R2 e f ∶ D ⊂ R2 → R uma função
convexa em D. Então, todo ponto de mínimo local é mínimo global.

Demonstração: (Amorim [1]) Supondo que x ∈ D seja um ponto de mínimo local
que não seja global. Então, existe y ∈ D, tal que f (y) < f (x). Tomando z ∈ D, com
z = ty + (1 − t)x e t ∈ (0, 1], uma vez que f é convexa, temos

f [ty + (1 − t)x] ≤ tf (y) + (1 − t)f (x) = f (x) + t[f (y) − f (x)],

ou seja,

f (z) ≤ f (x) + t[f (y) − f (x)].
Mas f (y) − f (x) < 0, então para t ∈ (0, 1] temos que t[f (y) − f (x)] < 0. Logo, f (x) +
t[f (y) − f (x)] < f (x) e consequentemente f (z) < f (x).

Considerando t suﬁcientemente pequeno, podemos aﬁrmar que z é arbitrariamente
próximo de x, e como f (z) < f (x) e z ∈ D, temos uma contradição na hipótese de x
ser ponto de mínimo local que não seja global. Portanto, todo ponto de mínimo local
deve ser mínimo global.

∎

39

Deﬁnição 1.40. Seja uma função f ∶ D ⊂ R2 → R e p um ponto crítico de f . Dizemos
que a matriz quadrada (n×n) das derivadas parciais segundas de f é a matriz hessiana
Hf (p) de f .

Observação 1.41. O teorema de Shwarz (vide [12]) aﬁrma que se as derivadas parciais
são contínuas até segunda ordem, então a ordem de derivação não importa, ou seja,

∂2f
∂x∂y =

∂2f
∂y∂x

.

Assim, como consequência desse teorema, temos que dada uma função f ∶ D ⊂ R2 → R
e p um ponto crítico de f , a matriz hessiana Hf (p) é simétrica em cada ponto de D
quando as derivadas parciais segundas de f são contínuas em todo ponto de D.

Deﬁnição 1.42. Seja H uma matriz quadrada de ordem n × n. Um menor de ordem
k é o determinante de uma submatriz k × k de H, obtida removendo-se (n − k) linhas
e (n − k) colunas de H.

Deﬁnição 1.43. Um menor principal de ordem k é um menor de ordem k no qual
as linhas e colunas de mesmo índice foram removidas. Mais especiﬁcamente, se as
linhas i1, i2, ⋯, in−k foram removidas, então as colunas removidas são as de índice
j1, j2, ⋯, jn−k.

Deﬁnição 1.44. Seja H uma matriz 1 quadrada n × n formada por números reais. A
forma quadrática associada à matriz H é a função escalar Q ∶ Rn → R, deﬁnida por
Q(h) = hT ⋅ H ⋅ h. Isto é,

Q(h1, h2, ⋯, hn) = [ h1 h2

. . . hn ] ⋅

a11 a12
. . .
an1 an2

⋮

. . . a1n
. . .
. . . ann

⋮

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

h1

⋮
hn

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Deﬁnição 1.45. Sejam H uma matriz n × n e Q(h) = hT ⋅ H ⋅ h a forma quadrática
associada. Dizemos que:

i. a matriz H(ou a forma quadrática Q) é positiva deﬁnida quando Q(h) > 0 para

todo h ≠ 0 em Rn;

ii. a matriz H(ou a forma quadrática Q) é positiva semideﬁnida quando Q(h) ≥ 0

para todo h ≠ 0 em Rn.

Teorema 1.46. Seja H uma matriz quadrada de ordem 2 simétrica. H é positiva e
semideﬁnida se, e somente se, todos os seus menores principais são maiores ou igual
a zero.

1As deﬁnições e teoremas pertinentes a teoria das matrizes serão descritas na seção 1.2

40

Demonstração: (Bortolossi [4]) Tomando a matriz

H =

a b

b

c

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Da deﬁnição 1.44, temos que a forma quadrática associada à matriz H é dada por
Q(h) = hT ⋅ H ⋅ h. Em notação matricial, segue que

Q(h1, h2) = [ h1 h2 ] ⋅

a b

b

c

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎣

h1
h2

.

⎤
⎥
⎥
⎥
⎥
⎦

De onde obtemos

Completando quadrado, segue que

Q(h1, h2) = ah2

1 + 2bh1h2 + ch2
2.

Q(h1, h2) = a (h2

1 +

2b
a

h1h2 +

b2
a2

2) + ch2
h2

2 −

ab2h2
2
a2

Q(h1, h2) = a (h1 +

2

h2)

+

b
a

a2ch2

2

2 − ab2h2
a2
ac − b2
a

2

b
a
Do ítem (ii) da deﬁnição 1.45, temos que a matriz H é positiva e semideﬁnida quando
Q(h1, h2) ≥ 0. Ou seja, quando

Q(h1, h2) = a (h1 +

(1.36)

h2)

h2
2.

+

a (h1 +

2

h2)

+

b
a

ac − b2
a

h2
2 ≥ 0.

Das deﬁnições 1.42 e 1.43 temos que os menores principais da matriz H, são

∣a∣ = a,

∣c∣ = c

e

a b
c
b

RRRRRRRRRRR

RRRRRRRRRRR

= ac − b2.

2

h2)

+

b
a

ac − b2
a

2 ≥ 0 se, e somente se, a ≥ 0, c ≥ 0
h2

(⇒) Supondo que Q(h1, h2) ≥ 0 implica em a ≥ 0, c ≥ 0 e ac−b2 ≥ 0. Então, tomando

Assim, queremos mostrar que a (h1 +
e ac − b2 ≥ 0.

a equação (1.36) e fazendo

resulta em

Q(1, 0) = a ⋅ (1 +

2

b
a ⋅ 0)

+

ac − b2
a

⋅ 0,

Q(1, 0) = a

41

Tomando a mesma equação e fazendo

Q(0, 1) = a ⋅ (0 +

2

b
a ⋅ 1)

+

ac − b2
a

⋅ 1

Q(0, 1) = a ⋅ (

2

b
a)

+

ac − b2
a

,

Q(0, 1) =

b2
a +

ac − b2
a

,

Q(0, 1) = c.

obtemos

Como por hipótese Q(h1, h2) ≥ 0, temos respectivamente que Q(1, 0) = a ≥ 0 e

Q(0, 1) = c ≥ 0. Ou seja, Q(h1, h2) ≥ 0 implica em a ≥ 0 e c ≥ 0.

Vamos agora considerar três subcasos:

i. Tomando Q (

−b
a

, 1) e a > 0, temos que

Q (

−b
a

, 1) = a (

2

−b
a +

b
a )

+

ac − b2
a

⋅ 1

Q (

−b
a

, 1) =

ac − b2
a

.

Como por hipótese Q(h1, h2) ≥ 0, então Q (
ac − b2 ≥ 0;

ii. Tomando Q (1, −b

c ) e c > 0, temos que

−b
a

, 1) =

ac − b2
a

≥ 0 e, portanto,

Q (1, −b

c ) = a (1 +

2

b
a ⋅ (

−b
c ))

+

ac − b2
a

2

−b
c )

⋅ (

Q (1, −b

c ) = a (1 −

2

b2
ac)

ac − b2
a

+

2

−b
c )

⋅ (

Q (1, −b

c ) =

(ac − b2)2
ac2

(ac − b2) ⋅ (−b2)
ac2

+

42

Q (1, −b

c ) =

(ac − b2) ⋅ (ac − b2 + b2)
ac2

Q (1, −b

c ) =

ac − b2
c

.

Como por hipótese Q(h1, h2) ≥ 0, então Q (1, −b
ac − b2 ≥ 0;

c ) =

ac − b2
c

≥ 0 e, portanto,

iii. Tomando Q(1, 1) e a = c = 0, temos

Q(1, 1) = a(1 +

2

b
a)

+

ac − b2
a

⋅ 1

Q(1, 1) = a (

2

a + b
a )

+

ac − b2
a

Q(1, 1) =

(a + b)2
a

ac − b2
a

+

Q(1, 1) =

a2 + 2ab + b2 + ac − b2
a

Q(1, 1) = a + 2b + c

Tomando Q(1, −1) e a = c = 0, temos

Q(1, −1) = a(1 −

2

b
a)

+

ac − b2
a

2
⋅ (−1)

Q(1, −1) = a (

2

a − b
a )

+

ac − b2
a

Q(1, −1) =

(a − b)2
a

ac − b2
a

+

Q(1, −1) =

a2 − 2ab + b2 + ac − b2
a

43

Q(1, −1) = a − 2b + c

Como por hipótese Q(h1, h2) ≥ 0 e a = c = 0, então Q(1, 1) = 2b ≥ 0 e Q(1, −1) =
−2b ≥ 0, portanto, b ≥ 0 e b ≤ 0. Logo, b = 0 e consequentemente ac − b2 = 0. Assim, nos
três subcasos observamos que ac − b2 ≥ 0, ou seja, Q(h1, h2) ≥ 0 implica em ac − b2 ≥ 0.
Desta forma, concluímos que Q(h1, h2) ≥ 0 implica em a ≥ 0, c ≥ e ac − b2 ≥ 0.

(⇐) Reciprocamente, supondo que a ≥ 0, c ≥ 0 e ac−b2 ≥ 0 implicam em Q(h1, h2) ≥

0. Segue que:

i. Se a > 0, então tomando c ≥ b2 e b2 ≥

b2
a

temos que:

c ≥

b2
a

,

multiplicando ambos os lados da desigualdade por a, obtemos

ac ≥ b2,

subtraindo b2 em ambos os lados da desigualdade anterior, obtemos

dividindo ambos os lados da desigualdade por a, temos

ac − b2

≥ 0,

ac − b2
a

≥ 0,

multiplicando ambos os lados da desigualdade anterior por h2
2

, resulta em

ac − b2
a

h2
2 ≥ 0.

(1.37)

Tomando agora a

b ≥ −h2, com b > 0 e −h2 ≥
−h2
h1

a
b ≥

,

−h2
h1

, com h1 > 0, temos que:

multiplicando ambos os lados da desigualdade por b, obtemos

a ≥

−bh2
h1

,

multiplicando ambos os lados da desigualdade anterior por h1, segue que

somando bh2 a ambos os lados da desigualdade anterior, temos

ah1 ≥ −bh2,

ah1 + bh2 ≥ 0,

elevando ambos os lados da desigualdade ao quadrado, obtemos

daí segue que

(ah1 + bh2)

2

≥ 0,

a2h2

1 + 2ah1bh2 + b2h2

2 ≥ 0,

dividindo ambos os lados da desigualdade anterior por a, temos

ah2

1 + 2bh1h2 +

b
a

h2
2,

colocando a em evidência no lado esquerdo da desigualdade, obtemos

a (h2

1 + 2h1

b
a

h2 +

h2
2) ≥ 0,

b2
a2

2

h2)

≥ 0.

que resulta em

Somando (1.37) e (1.38), obtemos

a (h1 +

b
a

a (h1 +

2

h2)

+

b
a

ac − b2
a

h2
2 ≥ 0.

44

(1.38)

(1.39)

ii. Se c > 0, então tomando a ≥ b2 e b2 ≥

no item anterior que:

b2
c

, temos por processo análogo ao realizado

ac − b2
c

h2
1 + c (h1 +

2

h2)

≥ 0.

b
c

(1.40)

iii. Se a = c = 0, então ac − b2 = −b2 ≥ 0, que equivale a b2 ≤ 0, logo b = 0. Tomando a

equação (1.39) temos que

a (h1 +

2

h2)

+

b
a

ac − b2
a

h2
2 = 0

Assim, concluímos que a ≥ 0, c ≥ 0 e ac − b2 ≥ 0 implicam em Q(h1, h2) ≥ 0.

Portanto, Q(h1, h2) ≥ 0 implica em a ≥ 0, c ≥ 0 e ac−b2 ≥ 0, e, a ≥ 0, c ≥ 0 e ac−b2 ≥ 0
∎

implicam em Q(h1, h2) ≥ 0, então a matriz H é positiva e semideﬁnida.

Teorema 1.47. Seja um conjunto convexo e aberto D ⊂ R2 e f ∶ D ⊂ R2 → R uma fun-
ção continuamente duas vezes diferenciável em todo ponto de D. Então f é uma função
convexa em D se, e somente se, a matriz hessiana Hf (p) é positiva e semideﬁnida para
todo p ∈ D.

45

Demonstração: (Hlenka [10]) (⇒) Supondo f convexa em D e tomando dois pontos
r e s quaisquer do domínio, temos por hipótese

f (r) ≥ f (s) + (r − s)∇f (s).

(1.41)

Como f é continuamente duas vezes diferenciável sobre R2, temos pela fórmula de
Taylor, que existe t ∈ (0, 1) tal que

f (r) = f (s) + (r − s)∇f (s) +

1
2(r − s)

T

2f (p)(r − s),

∇

(1.42)

onde ∇2f (p) é a matriz hessiana Hf (p) e p = tr + (1 − t)s é um ponto do segmento de
reta que une r e s.

Então, substituindo (1.42) em (1.41), obtemos

f (s) + (r − s)∇f (s) +

1
2 (r − s)

T

2f (p)(r − s) ≥ f (s) + (r − s)∇f (s),

∇

que corresponde a

Denotando (r − s) = h, segue que

T
(r − s)

2f (p)(r − s) ≥ 0.

∇

hT

2f (p)h ≥ 0,

∇

de onde vem

hT Hf (p)h ≥ 0.
Assim, segundo as deﬁnições 1.44 e 1.45, a matriz hessiana Hf (p) é positiva e semide-
ﬁnida.

(⇐) Reciprocamente supondo que a matriz hessiana Hf (p) é positiva e semideﬁ-
nida, e tomando os pontos r, s, h ∈ D tais que p = rt + (1 − t)s com t ∈ (0, 1) e h = (r − s).
Temos por hipótese que

o que corresponde a

hT Hf (p)h ≥ 0,

(r − s)

T

2f (p)(r − s) ≥ 0.

∇

Multiplicando ambos os lados da desigualdade (1.43) por 1
2

, obtemos

1
2(r − s)

T

2f (p)(r − s) ≥ 0.

∇

(1.43)

(1.44)

Tomando f (s) + (r − s)∇f (s) e somando em ambos os lados da desigualdade (1.44),
resulta em

f (s) + (r − s)∇f (s) +

1
2 (r − s)

T

2f (p)(r − s) ≥ f (s) + (r − s)∇f (s).

∇

(1.45)

Mas, pela fórmula de Taylor, temos que

f (s) + (r − s)∇f (s) +

1
2 (r − s)

T

2f (p)(r − s) = f (r).

∇

(1.46)

Então, substituindo (1.46) no lado esquerdo da desigualdade (1.45), obtemos

f (r) ≥ f (s) + (r − s)∇f (s).

Portanto, f é convexa em D.

46

∎

O teorema 1.38 nos garante a convexidade de uma dada função diferenciável. Ga-
rantida a convexidade, o teorema 1.39 nos diz que todo ponto mínimo local é mínimo
global. No entanto, segundo Bortolossi [4], o teorema 1.38 não é prático para testarmos
a convexidade da função, uma vez que exige que veriﬁquemos uma desigualdade para
todo par de pontos p e q pertencente ao domínio de f . Nesse sentido, o teorema 1.47
é uma alternativa mais prática para constatarmos tal convexidade, pois atrela esta à
classiﬁcação da matriz hessiana.

Estes resultados são relevantes para o estudo do método dos mínimos quadrados,
pois se mostrarmos que a função que minimiza os erros é convexa, garantiremos que
possui ponto de mínimo global, ou seja, garantiremos que tal função nos dá o menor
erro possível na predição dos dados experimentais.

2 Noções de álgebra linear

No capítulo 3, constataremos que a minimização do erro requer a determinação
de parâmetros de uma função que melhor se ajusta ao comportamento dos dados ex-
perimentais, isto é, dos valores observados no experimento. Para determinarmos tais
parâmetros, necessitamos solucionar um sistema de equações lineares. Nesse sentido,
esse capítulo tem por objetivo apresentar os resultados da álgebra linear que nos for-
necem embasamento teórico para discutirmos a solução desse sistema.

Como veremos mais adiante nessa seção, um sistema de equações lineares pode ser
escrito na forma matricial (equação matricial). Assim sendo, ao manipularmos as ma-
trizes geradas pelo sistema, estamos efetuando operações básicas da álgebra matricial.
Particularmente, nosso interesse está voltado para inversibilidade da matriz, pois essa
propriedade é relevante para resolução da equação matricial correspondente ao sistema
de equações lineares objeto de nosso estudo.

Em vista disto, para que possamos entender o encadeamento das operações matrici-
ais envolvidas na solução do sistema, vamos observar as seguintes deﬁnições e teoremas:

Deﬁnição 2.1. Sejam I = {1, 2, ⋯, m} e J = {1, 2, ⋯, n} dois subconjuntos de N. De-
nominamos produto cartesiano de I e J, ao conjunto I ×J cujos elementos são os pares
ordenados de números (x, y) em que x ∈ I e y ∈ J, isto é: I × J = {(x, y); x ∈ I e y ∈ J}.
Denominamos matriz m × n toda aplicação f ∶ I × J → R, isto é, uma correspondência
na qual associamos ao elemento genérico (i, j) ∈ I × J um único elemento aij ∈ R. O
número aij é chamado imagem do par (i, j). A imagem da aplicação f ∶ I × J → R é o
conjunto {a11, a12, ⋯, amn} ⊂ R e os elementos desse conjunto são os elementos da ma-
triz. Representamos uma matriz A, m × n, por uma tabela na qual os números aij são
distribuídos em m linhas e n colunas, e na qual o número aij é colocado na intersecção
das linhas de índice i com as colunas de índice j. Tal tabela é representada da seguinte
maneira:

A =

⎛
⎜
⎜
⎜
⎜
⎜
⎝

a11
a21

⋮

a12 ⋯ a1n
a22 ⋯ a2n
⋮
⋱
⋮

am1 am2 ⋯ amn

⎞
⎟
⎟
⎟
⎟
⎟
⎠m×n

ou A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

a11
a21

⋮

a12 ⋯ a1n
a22 ⋯ a2n
⋮
⋱
⋮

am1 am2 ⋯ amn

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦m×n

47

48

Deﬁnição 2.2. Duas matrizes A = (aij) e B = (bij), de mesmo tipo m × n, são iguais
se apresentam todos os elementos correspondentes iguais, ou seja, se aij = bij, qualquer
que seja i ∈ {1, 2, ⋯, m} e j ∈ {1, 2, ⋯, n}.

Deﬁnição 2.3. Denominamos matriz identidade de ordem n, a matriz quadrada (nú-
mero de linhas igual ao número de colunas) indicada por In = (δij), onde

⎧⎪⎪
⎨
⎪⎪⎩
A matriz identidade pode ser representada por

1 se i = j
0 se i ≠ j

δij =

,

com i, j ∈ {1, 2, ⋯, n}.

In =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 ⋯ 0
0 1 ⋯ 0
⋮
⋮ ⋱ ⋮
0 0 ⋯ 1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

Deﬁnição 2.4. Dadas duas matrizes A = (aij), m × p, e B = (bjk), p × n, denominamos
produto de A por B, indicado por AB, a matriz C = (cik), m × n, tal que

cik = ai1 ⋅ b1k + ai2 ⋅ b2k + ⋯ + aip ⋅ bpk =

p
∑
j=1

aij ⋅ bjk,

para {i = 1, 2, 3, ⋯, m} e {j = 1, 2, 3, ⋯, n}.

Exemplo 2.5. Sejam as matrizes

temos que

A =

AB =

⎡
⎢
⎢
⎢
⎢
⎣

⎡
⎢
⎢
⎢
⎢
⎣

1 1 2
2 3 1

⎤
⎥
⎥
⎥
⎥
⎦2×3

e B =

4
0
5

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦3×1

,

1 ⋅ 4 + 1 ⋅ 0 + 2 ⋅ 5
2 ⋅ 4 + 3 ⋅ 0 + 1 ⋅ 5

⎤
⎥
⎥
⎥
⎥
⎦2×1

=

⎡
⎢
⎢
⎢
⎢
⎣

14
13

⎤
⎥
⎥
⎥
⎥
⎦2×1

.

Dentre as propriedades do produto de matrizes, destacamos duas que são pertinen-

tes aos nossos interesses. São elas:

Teorema 2.6. (Propriedade associativa do produto de matrizes) Dadas as matrizes
A,B e C, de tipos m × n, n × p e p × r respectivamente, temos que (AB)C = A(BC).

Demonstração: (Caroli [5]) Sejam A = (aij), B = (bjk) e C = (cks), com 1 ≤ i ≤ m,
1 ≤ j ≤ n, 1 ≤ k ≤ p e 1 ≤ s ≤ r.

Denotando AB = (dik), BC = (ejs), (AB)C = (fis) e A(BC) = (gis). Queremos

mostrar que fis = gis. Da deﬁnição 2.4, temos que

fis =

p
∑
k=1

dikcks,

mas

Então,

dik =

n
∑
j=1

aijbjk.

fis =

p
∑
k=1

n
∑
j=1

(

aijbjk) cks =

p
∑
k=1

n
∑
j=1

(

aijbjkcks) =

n
∑
j=1

p
∑
k=1

(

aijbjkcks) =

n
∑
j=1

aij (

p
∑
k=1

bjkcks) .

Pela mesma deﬁnição, temos

Daí, segue que

p
∑
k=1

bjkcks = ejs.

n
∑
j=1
Portanto, fis = gis, o que implica em (AB)C = A(BC).

bjkcks) =

n
∑
j=1

aijejs.

aij (

p
∑
k=1

Teorema 2.7. Se A é uma matriz do tipo m × p, então AIn = A = InA.

Demonstração: (Caroli [5]) Sejam as matrizes

49

∎

A = (aij),

com

⎧⎪⎪
⎨
⎪⎪⎩

1 ≤ i ≤ m
1 ≤ j ≤ p

e

In = (δik),

com

⎧⎪⎪
⎨
⎪⎪⎩

1 ≤ j ≤ p
1 ≤ k ≤ n

.

Denotando AIn = (bik) e InA = (cik), e de acordo com a deﬁnição 2.4, podemos

escrever

e

bik =

cik =

p
∑
j=1

p
∑
j=1

aijδjk = ai1δ1k + ai2δ2k + ⋯ + aipδpk

δjkaij = ai1δ1k + ai2δ2k + ⋯ + aipδpk

Da deﬁnição 2.3, temos

então segue que

e

δij =

⎧⎪⎪
⎨
⎪⎪⎩

1 se i = j
0 se i ≠ j

,

bik = ai1 ⋅ 0 + ⋯ + aik ⋅ 1 + ⋯ + aip ⋅ 0 = aik,

cik = ai1 ⋅ 0 + ⋯ + aik ⋅ 1 + ⋯ + aip ⋅ 0 = aik.

Assim, como bik = aik = cik, resulta que AIn = A = InA.

∎

Deﬁnição 2.8. Denominamos matriz transposta da matriz A = (aij), m × n, a matriz
⎧⎪⎪
. Isto é, as linhas da matriz A
At = (bji), n × m, onde bji = aij, com
⎨
⎪⎪⎩
coincidem ordenadamente com as colunas da matriz At.

1 ≤ i ≤ m
1 ≤ j ≤ n

50

Exemplo 2.9. Seja a matriz

A =

1 5 7
4 3 2
9 6 8

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦3×3

,

então pela deﬁnição 2.8, a matriz transposta de A é dada por:

At

=

1 4 9
5 3 6
7 2 8

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦3×3

.

Deﬁnição 2.10. Dada uma matriz A de ordem n, denominamos de inversa de A a
matriz B, tal que AB = BA = In. Denotamos a matriz inversa por A−1.
Teorema 2.11. Se uma matriz quadrada A = (aij), de ordem n, é inversível, então a
sua inversa é única.

Demonstração: (Caroli [5]) Supondo que existam duas matrizes B e C inversas da
matriz A. Assim, de acordo com a deﬁnição 2.10, temos que:

i. AB = BA = In,

ii. AC = CA = In.

Do teorema 2.7, segue que

Como por hipótese

então podemos escrever

Do teorema 2.6, temos que

Desta forma, segue que

Mas, por hipótese

então

Do teorema 2.7, temos que

B = BIn.

In = AC,

B = B(AC).

B(AC) = (BA)C.

B = (BA)C.

(BA) = In,

B = InC.

InC = C,

o que implica em B = C. Portanto, B = C = A−1 é a única inversa da matriz A.

∎

51

Exemplo 2.12. Sejam as matrizes

A =

3 1
5 2

⎡
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎦2×2

e B =

⎡
⎢
⎢
⎢
⎢
⎣

2 −1
3
−5

⎤
⎥
⎥
⎥
⎥
⎦2×2

.

Então, pela deﬁnição 2.4, temos que

AB =

e

BA =

⎡
⎢
⎢
⎢
⎢
⎣

⎡
⎢
⎢
⎢
⎢
⎣

3 1
5 2

⎤
⎥
⎥
⎥
⎥
⎦2×2

⋅

⎡
⎢
⎢
⎢
⎢
⎣

2 −1
3
−5

⎤
⎥
⎥
⎥
⎥
⎦2×2

=

⎡
⎢
⎢
⎢
⎢
⎣

3 ⋅ 2 + 1 ⋅ (−5) 3 ⋅ (−1) + 1 ⋅ 3
5 ⋅ 2 + 2 ⋅ (−5) 5 ⋅ (−1) + 2 ⋅ 3

2 −1
3
−5

⎤
⎥
⎥
⎥
⎥
⎦2×2

⋅

⎡
⎢
⎢
⎢
⎢
⎣

3 1
5 2

⎤
⎥
⎥
⎥
⎥
⎦2×2

=

⎡
⎢
⎢
⎢
⎢
⎣

2 ⋅ 3 + (−1) ⋅ 5 2 ⋅ 1 + (−1) ⋅ 2
−5 ⋅ 1 + 3 ⋅ 2
−5 ⋅ 3 + 3 ⋅ 5

⎤
⎥
⎥
⎥
⎥
⎦

=

⎡
⎢
⎢
⎢
⎢
⎣

1 0
0 1

⎤
⎥
⎥
⎥
⎥
⎦

=

⎡
⎢
⎢
⎢
⎢
⎣

1 0
0 1

⎤
⎥
⎥
⎥
⎥
⎦

.

⎤
⎥
⎥
⎥
⎥
⎦

Portanto, temos que AB = BA = In e de acordo com o teorema 2.11, B é a única

matriz inversa de A. Assim, podemos denotar B = A−1.

Observamos que a deﬁnição 2.10 nos permite veriﬁcar se duas matrizes são inversas
ou não, assim como, o teorema 2.11 nos garante a unicidade da matriz inversa. No
entanto, estes não nos fornecem informações para que possamos veriﬁcar se uma certa
matriz admite inversa ou não, muito menos um critério para determiná-la.

Nessa perspectiva, as deﬁnições e teoremas a seguir nos indicarão que a admissi-
bilidade da inversa de uma matriz é inerente ao cálculo do determinante. Por outro
lado, se a matriz admite inversa, uma maneira de encontrá-la é fazendo uso da matriz
adjunta. Vejamos então, tais deﬁnições e teoremas:

Deﬁnição 2.13. Seja o conjunto J = {1, 2, ⋯, n} um subconjunto de N. Denominamos
uma permutação de J a correspondência bijetiva P ∶ J → J. Denotamos a permutação
por

P =

⎛
⎝

1

2

⋯

n

P (1) P (2) ⋯ P (n)

,

⎞
⎠

onde a primeira ﬁleira representa a ordem dos elementos a serem permutados e a
segunda ﬁleira a nova ordem dada pela permutação.

Deﬁnição 2.14. Dado o conjunto J = {1, 2, ⋯, n} com n elementos distintos, a quanti-
dade de permutações possíveis desses elementos é dada por n! = n⋅(n−1)⋅(n−2)⋯3⋅2⋅1.
Denotamos o conjunto de todas as permutações de J por

⎧⎪⎪
⎨
⎪⎪⎩

n

1

2

⋯

⎛
⎝

S =

P1(1) P1(2) ⋯ P1(n)

⎞
⎠
Exemplo 2.15. Seja o conjunto J = {1, 2, 3}. A quantidade de permutações possíveis
dos elementos de J é 3! = 6, são elas:

Pk(1) Pk(2) ⋯ Pk(n)

, ⋯, ⎛
⎝

⎞
⎠

⋯

.

1

2

n

⎫⎪⎪
⎬
⎪⎪⎭

⎛
⎝

1

2
P1(1) P1(2) P1(3)

3

⎞
⎠

=

⎛
⎝

1 2 3
1 2 3

;

⎞
⎠

52

⎞
⎠

⎞
⎠

⎞
⎠

⎞
⎠

⎞
⎠

=

=

=

=

=

⎛
⎝

⎛
⎝

⎛
⎝

⎛
⎝

⎛
⎝

1 2 3
1 3 2

1 2 3
2 1 3

1 2 3
2 3 1

1 2 3
3 1 2

1 2 3
3 2 1

;

;

;

;

.

⎞
⎠

⎞
⎠

⎞
⎠

⎞
⎠

⎞
⎠

⎛
⎝

⎛
⎝

⎛
⎝

⎛
⎝

⎛
⎝

1

2
P2(1) P2(2) P2(3)

3

1

2
P3(1) P3(2) P3(3)

3

1

2
P4(1) P4(2) P4(3)

3

1

2
P5(1) P5(2) P5(3)

3

1

2
P6(1) P6(2) P6(3)

3

E o conjunto de todas as permutações de J é

⎞
⎠

⎛
⎝

⎞
⎠

S =

⎧⎪⎪
⎨
⎪⎪⎩

, ⎛
⎝

, ⎛
⎝

1 2 3
1 2 3

1 2 3
1 3 2

1 2 3
2 1 3

⎫⎪⎪
⎬
⎪⎪⎭
Deﬁnição 2.16. Seja uma permutação P ∈ S. Denotamos por Z o conjunto dos pares
(i, j) com 1 ≤ i < j ≤ n, tais que P (i) < P (j) e por W o conjunto dos pares (i, j) com
1 ≤ i < j ≤ n, tais que P (i) > P (j). Seja t o número de pares (i, j) pertencentes a W ,
denominamos t por número de inversões de P .

1 2 3
3 1 2

1 2 3
2 3 1

1 2 3
3 2 1

, ⎛
⎝

, ⎛
⎝

, ⎛
⎝

⎞
⎠

⎞
⎠

⎞
⎠

⎞
⎠

.

Exemplo 2.17. Sejam

P1 =

1 2 3 4 5
1 3 2 5 4

⎛
⎝

⎞
⎠

e P2 =

1 2 3 4 5
3 1 2 5 4

⎛
⎝

.

⎞
⎠

Temos que

i. P1(2) > P1(3) e P1(4) > P1(5),

ii. P2(1) > P2(2), P2(1) > P2(3) e P2(4) > P2(5).

Então, o número de inversões de P1 e P2 são respectivamente t = 2 e t = 3.

Deﬁnição 2.18. Seja uma permutação P ∈ S. Denotamos o sinal de P por

onde t é o número de inversões de P .

t,
ε(P ) = (−1)

Exemplo 2.19. Do exemplo 2.17 temos que ε(P1) = (−1)2 = 1 e ε(P2) = (−1)3 = −1.

53

Deﬁnição 2.20. Sejam a matriz A = (aij) de ordem n, o conjunto J = {1, 2, ⋯, n}
de índices j da matriz A, a permutação P dos elementos de J e ε(P ) o sinal da
permutação P . Denominamos determinante da matriz A o número real dado por

n!
∑
k=1
e denotamos por det(A) ou ∣A∣.
Exemplo 2.21. Seja a matriz

ε(Pk)a1pk(1)a2pk(2)⋯anpk(n)

a11 a12 a13
a21 a22 a23
a31 a32 a33
O conjunto J = {1, 2, 3} de índices j da matriz A possui 6 permutações possíveis de

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦3×3

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

A =

.

seus elementos, são elas:

P1 =

⎛
⎝

1 2 3
1 2 3

⎞
⎠

, P2 =

⎛
⎝

1 2 3
1 3 2

⎞
⎠

, P3 =

1 2 3
2 1 3

⎛
⎝

,

⎞
⎠

⎞
⎠

⎛
⎝

⎛
⎝

P4 =

, P5 =

1 2 3
2 3 1

1 2 3
3 1 2
Observamos que o número de inversões em P1, P2, P3, P4, P5 e P6 é respectivamente
t = 0, t = 1, t = 1, t = 2, t = 2 e t = 3. Assim, calculando o sinal ε(P ) de cada permutação
temos: ε(P1) = (−1)0 = 1; ε(P2) = (−1)1 = −1; ε(P3) = (−1)1 = −1; ε(P4) = (−1)2 = 1;
ε(P5) = (−1)2 = 1 e ε(P6) = (−1)3 = −1.

1 2 3
3 2 1

, P6 =

⎞
⎠

⎞
⎠

⎛
⎝

.

Tomando os sinais das permutações e calculando o determinante da matriz A pela

deﬁnição, temos que

det(A) =

6
∑
k=1

ε(Pk)a1pk(1)a2pk(2)a3pk(3) =

ε(P1)a1p1(1)a2p1(2)a3p1(3) + ε(P2)a1p2(1)a2p2(2)a3p2(3) + ε(P3)a1p3(1)a2p3(2)a3p3(3)+
+ε(P4)a1p4(1)a2p4(2)a3p4(3) + ε(P5)a1p5(1)a2p5(2)a3p5(3) + ε(P6)a1p6(1)a2p6(2)a3p6(3),

o que corresponde a

det(A) = a11a22a33 − a11a23a32 − a12a21a33 + a12a23a31 + a13a21a32 − a13a22a31,

ou

det(A) = (a11a22a33 + a12a23a31 + a13a21a32) − (a11a23a32 + a12a21a33 + a13a22a31) .
Calcular o determinante de uma matriz de ordem n > 3 diretamente pela deﬁnição

é um processo muito dispendioso, uma vez que o número de parcelas

ε(Pk)a1pk(1)a2pk(2)⋯anpk(n)
que o compõe cresce rapidamente a medida que aumentamos a ordem da matriz. Nesse
sentido, as deﬁnições e teoremas a seguir facilitarão o cálculo do determinante.

54

Observação 2.22. Denominamos o menor da deﬁnição 1.42 como menor complemen-
tar e o denotamos por Dij do elemento aij da matriz quadrada A de ordem n.

Deﬁnição 2.23. Denominamos complemento algébrico ou cofator do elemento aij de
uma matriz quadrada A de ordem n, ao produto do menor complementar Dij por
(−1)i+j, isto é: Aij = (−1)i+jDij.

Deﬁnição 2.24. Fixando a coluna de índice 1 da matriz quadrada A = (aij) de ordem
n, dizemos que o determinante de A é a soma dos produtos dos elementos da coluna
de índice 1 pelos respectivos cofatores, ou seja: det(A) =

ai1Ai1.

n
∑
i=1

Teorema 2.25. Seja a matriz quadrada A = (aij) de ordem n, se a matriz transposta
de A é At = (bji), então det(A) = det(At).

Demonstração: (Guelli [8]) Sejam as matrizes B1 e B2, de ordem (n − 1), cujos
elementos são os respectivos cofatores Bji e Aij, dos respectivos elementos bji ∈ At
e aij ∈ A. Assim, de acordo com as deﬁnições 2.23 e 2.24, desenvolvemos det(At) e
det(A), obtendo:

det(At

) = b11B11 − b21B21 + b31B31 − ⋯ + (−1)

n+1bn1Bn1 =

e

det(A) = a11A11 − a21A21 + a31A31 − ⋯ + (−1)

n+1an1An1 =

n
∑
j=1

n
∑
i=1

bj1Bj1

ai1Ai1.

Pela deﬁnição 2.8 temos que bji = aij, então Bji = Aij. Daí segue que

b11B11−b21B21+b31B31−⋯+(−1)

n+1bn1Bn1 = a11A11−a21A21+a31A31−⋯+(−1)

n+1an1An1,

o que resulta em

Portanto, concluímos que

n
∑
j=1

bj1Bj1 =

n
∑
i=1

ai1Ai1.

det(At

) = det(A).

∎

Exemplo 2.26. Seja a matriz A =

⎤
1 2 3
⎥
⎥
. O
⎥
4 7 5
⎥
⎥
9 8 6
⎥
⎦
desenvolvimento dos determinantes de A e At pela primeira coluna são dados por:

e sua transposta At =

1 4 9
2 7 8
3 5 6

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

i. det(A) = a11A11 − a21A21 + a31A31 = 2 + 48 − 99 = −49;

ii. det(At) = b11B11 − b21B21 + b31B31 = 2 + 42 − 93 = −49.

Portanto, temos det(A) = det(At) = −49.

55

Teorema 2.27. (Teorema de Laplace) Se A = (aij) é uma matriz quadrada de ordem
n, então, o det(A) é a soma dos produtos dos elementos de uma ﬁla (linha ou coluna)
aijAij, para cada índice j ﬁxado
de A pelos respectivos cofatores. Isto é: det(A) =

n
∑
i=1

ou det(A) =

n
∑
j=1

aijAij, para cada índice i ﬁxado.

Demonstração: (SÁ [16]) Vamos demonstrar por indução.

Para n = 2, ou seja, para uma matriz A = (aij) de ordem n = 2, temos

det(A) = a12A12 + a22A22 = a12(−1)

1+2D12 + a22(−1)

2+2D22 = a22a11 − a12a21,

(2.1)

quando desenvolvemos o determinante pela segunda coluna. E

det(A) = a11A11 + a21A21 = a11(−1)

1+1D11 + a21(−1)

2+1D21 = a22a11 − a12a21,

(2.2)

quando desenvolvemos o determinante pela primeira coluna.

Assim, observamos que as equações (2.1) e (2.2) são coincidentes, portanto a pro-

posição é verdadeira para n = 2.

Da observação 2.22 temos os menores complementares Dij das entradas da matriz
A. Supondo que a proposição seja verdadeira para menores complementares de uma
matriz de ordem (n−1), queremos mostrar que a proposição é verdadeira para menores
complementares de uma matriz de ordem n.
Fixando a j-ésima coluna da matriz A = (aij), com 1 < j ≤ n e desenvolvendo o
determinante, obtemos

det(A) = a1jA1j + a2jA2j + a3jA3j + ⋯ + anjAnj.

Pela deﬁnição 2.23 temos que

det(A) = a1j(−1)

1+jD1j + a2j(−1)

2+jD2j + a3j(−1)

3+jD3j + ⋯ + anj(−1)

n+jDnj.

Mas D1j, D2j, D3j, ⋯, Dnj, são determinantes de matrizes de ordem (n − 1). Portanto,
por hipótese de indução podemos calcular esses determinantes pelo teorema de Laplace.
Fazendo o desenvolvimento pela primeira coluna da matriz gerada e denotando seus
menores complementares por dij, segue que:

D1j = a21(−1)

2+1d21 + a31(−1)

3+1d31 + ⋯ + an1(−1)

n+1dn1 =

n
∑
i=2

ai1(−1)

i+1di1

D2j = a11(−1)

1+1d11 + a31(−1)

3+1d31 + ⋯ + an1(−1)

n+1dn1 = a11d11 +

⋮

Dnj = a11(−1)

1+1d11 + a21(−1)

2+1d21 + ⋯ + a(n−1)1(−1)

n−1+1d(n−1)1 =

n
∑
i=3

n−1
∑
i=1

ai1(−1)

i+1di1

ai1(−1)

i+1di1.

56

Substituindo D1j, D2j, D3j, ⋯, Dnj em det(A), obtemos:

det(A) = a1j(−1)

1+j

n
∑
i=2

{

ai1(−1)

i+1di1} + a2j(−1)

2+j

{a11d11 +

n
∑
i=3

ai1(−1)

i+1di1} + ⋯

⋯ + anj(−1)

n+j

n−1
∑
i=1

{

ai1(−1)

i+1di1} .

Tomando em det(A) todas parcelas onde a11 aparece, obtemos

a2j(−1)

2+ja11d11 + a3j(−1)

3+ja11d11 + ⋯ + anj(−1)

n+ja11d11.

Colocando em evidência o elemento a11, temos

a11 {a2j(−1)

2+jd11 + a3j(−1)

3+jd11 + ⋯ + anj(−1)

n+jd11} .

(2.3)

Tomando o fator {a2j(−1)2+jd11 + a3j(−1)3+jd11 + ⋯ + anj(−1)n+jd11} da expressão (2.3),
observamos que este fator é o desenvolvimento, pela j-ésima coluna, de um determi-
nante D da matriz A = (aij). Então, podemos escrevê-lo como

D = a2j(−1)

2+jk2j + a3j(−1)

3+jk3j + ⋯ + anj(−1)

n+jknj,

(2.4)

onde kij são os menores complementares da matriz gerada.

Mas o determinante desenvolvido na expressão (2.4) é o determinante D11 da matriz

A = (aij). Logo,

a11 {a2j(−1)

2+jd11 + a3j(−1)

3+jd11 + ⋯ + anj(−1)

n+jd11} = a11D11.

Analogamente, se tomarmos em det(A) todas as parcelas onde a21 aparece, obtemos

a21 {a1j(−1)

jd21 − a3j(−1)

1+jd21 − ⋯ − anj(−1)

n−2+jd21} = −a21D21.

Assim, por hipótese de indução, se tomarmos somente as parcelas onde an1 aparece,
temos

±an1 {a1j(−1)

1+jd1j + a2j(−1)

2+jd2j + ⋯ + a(n−1)j(−1)

n−1+jd(n−1)1} = ±an1Dn1.

Portanto,

que é equivalente a

det(A) = a11D11 − a21D21 + ⋯ ± an1Dn1,

det(A) = a11A11 + a21A21 + ⋯ ± an1An1.
Deste modo, pela arbitrariedade da escolha de j, concluímos que a proposição é ver-
dadeira para todas as colunas da matriz A = (aij).

Queremos agora, mostrar que a proposição é válida para todas as linhas da matriz
A = (aij). Fixando sua i-ésima linha, com 1 < i ≤ n, tomando a matriz transposta

At = bji da matriz A, denotando o menor complementar do elemento bji por dji e
usando At
para indicar os cofatores de bji. Podemos de acordo com a hipótese do
ji
teorema de Laplace, calcular o determinante de At, fazendo seu desenvolvimento pela
i-ésima coluna de sua matriz.
Assim sendo, temos que

57

det(At

) = b1iAt

1i + b2iAt

2i + ⋯ + bniAt

ni,

isto é:

det(At

) = b1i(−1)

1+id1i + b2i(−1)

2+id2i + ⋯ + bni(−1)

n+idni.

Mas pela deﬁnição 2.8 e pelo teorema 2.25 observamos que

det(At

) = b1i(−1)

1+id1i + b2i(−1)

2+id2i + ⋯ + bni(−1)

n+idni =

= a1j(−1)

1+jD1j + a2j(−1)

2+jD2j + ⋯ + anj(−1)

n+jDnj = det(A).

Deste modo, pela arbitrariedade da escolha de j, concluímos que a proposição é ver-
dadeira para todas as linhas da matriz A = (aij).

Portanto, pelo princípio da indução, temos que a proposição é verdadeira para

qualquer coluna ou linha da matriz A = (aij).

∎

Exemplo 2.28. Seja a matriz A =

, o desenvolvimento do determi-

nante de A pela segunda linha é coincidente com o desenvolvimento pela terceira co-
luna. Isto é:

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

2
1 −1
3
1
2
5 −2
−4

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

det(A) = a21A21 + a22A22 + a23A23 = a13A13 + a23A23 + a33A33 =

= 2

RRRRRRRRRRR

−1
2
5 −2

RRRRRRRRRRR

2+1

(−1)

+ 1

RRRRRRRRRRR

1
2
−4 −2

RRRRRRRRRRR

2+2

(−1)

+ 3

= 2

RRRRRRRRRRR

2
1
−4 5

RRRRRRRRRRR

1+3

(−1)

+ 3

RRRRRRRRRRR

1 −1
5
−4

RRRRRRRRRRR

2+3

(−1)

+ (−2)

RRRRRRRRRRR
RRRRRRRRRRR

1 −1
5
−4

RRRRRRRRRRR

2+3

(−1)

=

1 −1
1
2

RRRRRRRRRRR

3+3

(−1)

= 19

Teorema 2.29. Se A1 é a matriz quadrada que se obtém da matriz quadrada A = (aij),
de ordem n, trocando entre si as posições de duas linhas (ou colunas) distintas, então
det(A1) = −det(A).

Demonstração: (Guelli [8]) Vamos demonstrar por indução.
Para a matriz quadrada A = (aij), de ordem 2, temos:

A =

⎡
⎢
⎢
⎢
⎢
⎣

a11 a12
a21 a22

⎤
⎥
⎥
⎥
⎥
⎦

e A1 =

a21 a22
a11 a12

⎡
⎢
⎢
⎢
⎢
⎣

,

⎤
⎥
⎥
⎥
⎥
⎦

58

então segue que

det(A) = a11a22 − a21a12

e det(A1) = a21a12 − a11a22.

Assim, temos que det(A1) = −det(A). Portanto, para matrizes de ordem n = 2, a
propriedade é verdadeira.

Supondo que a propriedade seja verdadeira para matrizes de ordem (n − 1), quere-
mos mostrar que é verdadeira para matrizes de ordem n. Então, desenvolvendo det(A1)
e det(A) pelos elementos da linha de índice p, admitindo que esta linha não seja ne-
nhuma das duas que foram trocadas de lugar e sabendo que os menores complementares
indicados por dij eij das respectivas matrizes A e A1, satisfazem dij = −eij, de acordo
com a hipótese. Observamos que

det(A) = ap1Ap1 + ap2Ap2 + ⋯ + apnApn =

n
∑
j=1

apjApj

e

det(A1) = ap1(−Ap1) + ap2(−Ap2) + ⋯ + apn(−Apn) = −

n
∑
j=1

apjApj.

Isto mostra que det(A1) = −

apjApj = −det(A). Portanto, pelo princípio de indu-

ção, a proposição é verdadeira para qualquer matriz quadrada de ordem n.

∎

n
∑
j=1

Exemplo 2.30. Sejam as matrizes A =

e A1 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

2 1 8
3 7 3
4 2 2

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

3 7 3
2 1 8
4 2 2

⎤
⎥
⎥
. Desenvolvendo
⎥
⎥
⎥
⎥
⎦

os det(A) e det(A1) pela terceira linha, pois esta não é nenhuma das linhas permutadas,
temos que

det(A) = a31A31 + a32A32 + a33A33 = 4 ⋅ (−53) + 2 ⋅ 18 + 2 ⋅ 11 = −154

e

det(A1) = a31(A1)31 + a32(A1)32 + a33(A1)33 = 4 ⋅ 53 + 2 ⋅ (−18) + 2 ⋅ (−11) = 154

Assim, concluímos que det(A1) = −det(A).

Teorema 2.31. Se uma matriz quadrada A = (aij), de ordem n, tem duas linhas (ou
colunas) formadas por elementos respectivamente iguais, então det(A) = 0.

Demonstração: (Guelli [8]) Seja uma matriz quadrada A = (aij), de ordem n. Su-
pondo que as linhas de índices p e q dessa matriz sejam formadas por elementos res-
pectivamente iguais, ou seja: apj = aqj para todo j ∈ {1, 2, ⋯, n}, e que trocando entre
si estas linhas, obtemos uma nova matriz A1, tal que A1 = A. Então, de acordo com o
teorema 2.29 e pela hipótese do teorema 2.31, temos respectivamente

−det(A1) = det(A)

e det(A1) = det(A).

Daí segue que

mas

−det(A1) = det(A1),

−det(A1) = det(A1) ⇐⇒ det(A1) = 0.

Portanto, concluímos que det(A) = 0.

59

∎

Exemplo 2.32. Seja a matriz A =

linha, obtemos

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

3 1 2
4 1 5
3 1 2

⎤
⎥
⎥
, desenvolvendo o det(A) pela segunda
⎥
⎥
⎥
⎥
⎦

det(A) = a21A21 + a22A22 + a23A23 = 4 ⋅ 0 + 1 ⋅ 0 + 5 ⋅ 0 = 0.

Portanto, temos que det(A) = 0.

Teorema 2.33. (Teorema de Cauchy) Em toda matriz quadrada A = (aij), de ordem
n, a soma dos produtos dos elementos de uma linha (ou coluna), ordenadamente, pelos
cofatores dos elementos de outra linha (ou coluna) é igual a zero.

Demonstração: (Guelli [8]) Seja a matriz quadrada A = (aij), de ordem n. Substi-
tuindo em A a linha de índice s pela linha de índice r, obtemos a matriz A1 com duas
linhas iguais, então conforme o teorema 2.31, o det(A1) = 0. Assim sendo, se desenvol-
vermos o det(A1) pelos elementos da linha de índice s, obtemos det(A1) =
asjAsj,

mas det(A1) = 0, então

n
∑
j=1

asjAsj = 0.

Exemplo 2.34. Calculando a soma dos produtos dos elementos da primeira linha pelos

cofatores dos elementos da segunda linha da matriz A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣
(ai − gc) + c(−1)

c
a b
d e f
g h i

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

, temos

2+3

(ah − gb) =

a(−1)

2+1

(bi − ch) + b(−1)

2+2

= −a(bi − ch) + b(ai − gc) − c(ah − gb) =

= −abi + ach + abi − bcg − ach + bcg = 0

Deﬁnição 2.35. Dada uma matriz quadrada A = (aij), de ordem n, dizemos que a
matriz dos cofatores, denotada por C, é a matriz que se obtém de A, substituindo cada
elemento de A por seu cofator. Ou seja:

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

a11 a12 ⋯ a1n
a21 a22 ⋯ a2n
⋮
⋮
an1 an2 ⋯ ann

⋱

⋮

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

→ C =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

A11 A12 ⋯ A1n
A21 A22 ⋯ A2n
⋮

⋱

⋮

⋮

An1 An2 ⋯ Ann

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

n
∑
j=1

∎

Deﬁnição 2.36. Dada a matriz A = (aij), de ordem n, denominamos matriz adjunta
e denotamos por A a matriz transposta da matriz dos cofatores, isto é: A = C t.

60

Exemplo 2.37. Seja a matriz A =

⎤
⎥
⎥
⎥
⎥
⎦
cofatores dos elementos de A é dada por C =

4 7
2 3

⎡
⎢
⎢
⎢
⎢
⎣

, da deﬁnição 2.23 temos que a matriz dos

⎡
⎢
⎢
⎢
⎢
⎣

3 −2
4
−7

⎤
⎥
⎥
⎥
⎥
⎦

, então A =

⎡
⎢
⎢
⎢
⎢
⎣

3 −7
4
−2

.

⎤
⎥
⎥
⎥
⎥
⎦

Deﬁnição 2.38. Dado um número real α e uma matriz quadrada A = (aij), de ordem
n. Obtemos a matriz αA = (bij), com i, j ∈ {1, 2, ⋯, n} quando multiplicamos por α
todos os elementos de A.

Exemplo 2.39. Seja o número α = 3 e a matriz A =
de α por A é dado da seguinte maneira:

⎡
⎢
⎢
⎢
⎢
⎣

4 −1
2
0

⎤
⎥
⎥
⎥
⎥
⎦

, temos que o produto

αA =

⎡
⎢
⎢
⎢
⎢
⎣

3 ⋅ 4 3 ⋅ (−1)
3 ⋅ 0

3 ⋅ 2

⎤
⎥
⎥
⎥
⎥
⎦

=

⎡
⎢
⎢
⎢
⎢
⎣

12 −3
6
0

.

⎤
⎥
⎥
⎥
⎥
⎦

Teorema 2.40. Sejam A, det(A), A e In, respectivamente uma matriz quadrada de
ordem n, seu determinante, sua matriz adjunta e a matriz identidade de ordem n.
Então AA = AA = det(A)In.
Demonstração: (Guelli [8]) Seja AA = (bik), então pela deﬁnição 2.4 temos que

n
∑
j=1
onde Ajk, de acordo com as deﬁnições 2.35 e 2.36 são os elementos da matriz transposta
da matriz de cofatores dos elementos da matriz A. Daí segue que

aijAjk,

bik =

i. Pelo teorema 2.27, bik = det(A) para i = k;

ii. Pelo teorema 2.33, bik = 0 para i ≠ k.
Então, a matriz AA é dada por

AA =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

det(A)
0

⋮
0

0

0
0

⋯
det(A) ⋯
⋱
⋯ det(A)

⋮
0

⋮

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

.

Da deﬁnição 2.38 temos que

det(A) ⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 ⋯ 0
0 1 ⋯ 0
⋮
⋮ ⋱ ⋮
0 0 ⋯ 1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

=

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

det(A)
0

⋮
0

0

0
0

⋯
det(A) ⋯
⋱
⋯ det(A)

⋮
0

⋮

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

.

Logo,

AA =

det(A)
0

⋮
0

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

0

0
0

⋯
det(A) ⋯
⋱
⋯ det(A)

⋮
0

⋮

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

= det(A) ⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 ⋯ 0
0 1 ⋯ 0
⋮ ⋱ ⋮
⋮
0 0 ⋯ 1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

.

Da deﬁnição 2.3 temos que

Portanto, AA = det(A)In.

In =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 ⋯ 0
0 1 ⋯ 0
⋮
⋮ ⋱ ⋮
0 0 ⋯ 1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×n

.

61

∎

Teorema 2.41. Se A = (aij) é uma matriz quadrada de ordem n tal que det(A) ≠ 0,
então a matriz inversa da matriz A é A−1 =

A.

1
det(A)

Demonstração: (Guelli [8]) Seja a matriz quadrada A = (aij), de ordem n. Supondo
que det(A) ≠ 0 e considerando o teorema 2.40, temos que

Daí segue que

AA = det(A)In.

1
det(A)

AA = In.

Pelo teorema 2.6 podemos escrever a equação (2.5) como

1
det(A)

(

A) A = In.

Conforme a deﬁnição 2.10, temos que

Então, comparando as equações (2.6) e (2.7), observamos

A−1A = In

1
det(A)

(

A) A = A−1A.

Desta forma, concluímos que

A−1

=

1
det(A)

A.

(2.5)

(2.6)

(2.7)

∎

62

Exemplo 2.42. Sejam a matriz

e sua matriz adjunta

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 1 1
2 3 2
4 7 5

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

2 −1
1
0
−2
1
1
2 −3

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Temos que det(A) = 1, então pelo teorema 2.42 segue que

A−1

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣
Corolário 2.43. A condição necessária e suﬁciente para que uma matriz quadrada
A = (aij) de ordem n seja inversível, é que det(A) ≠ 0.

2 −1
1
0
−2
1
1
2 −3

1
det(A)

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

A =

=

.

Pelo teorema 2.41 e corolário 2.43 temos estabelecida a condição de admissibilidade
da inversa de uma matriz. Esse resultado será utilizado mais adiante nesta seção, para
que possamos discutir a solução de sistemas de equações lineares.

Estamos interessados em discutir um sistema em função de parâmetros. Nesse
sentido, e de acordo com Iezzi et.al. [11], essa discussão implica em classiﬁcar o sistema
quanto ao número de suas soluções, ou seja, em compatível, compatível indeterminado
ou incompatível para cada valor do parâmetro. Para que possamos entender essa
classiﬁcação, observemos as seguintes deﬁnições:

Deﬁnição 2.44. Uma equação linear em n incógnitas x1, x2, ⋯, xn é uma equação da
forma a1x1 + a2x2 + ⋯ + anxn = b, onde os números a1, a2, ⋯, an ∈ R são denominados
coeﬁcientes e b ∈ R é o termo independente da equação.

Deﬁnição 2.45. Denominamos solução de uma equação linear a n incógnitas à ênupla
ou conjunto ordenado de n números {α1, α2, ⋯, αn} que, substituídos na equação em
lugar de x1, x2, ⋯, xn, respectivamente, a transforma em uma sentença verdadeira, isto
é: {α1, α2, ⋯, αn} é solução se, e somente se, a1α1 + a2α2 + ⋯ + anαn = b é verdadeira.

Exemplo 2.46. Considerando a equação 3x1 +2x2 +x3 −2x4 = −2, temos que o conjunto
ordenado (1, −1, 1, 2) é solução da equação pois a sentença 3 ⋅ 1 + 2 ⋅ (−1) + 1 − 2 ⋅ 2 = −2
é verdadeira.

Deﬁnição 2.47. Sejam aij e bi números reais, com 1 ≤ i ≤ m e 1 ≤ j ≤ n. Então, um
sistema linear de m equações e n incógnitas é um sistema da seguinte forma:

63

a11x1 + a12x2 + ⋯ + a1nxn = b1
a21x1 + a22x2 + ⋯ + a2nxn = b2
⋮
am1x1 + am2x2 + ⋯ + amnxn = bm

em que x1, x2, ⋯, xn são as incógnitas, aij os coeﬁcientes e bi os termos independen-

tes do sistema de equações lineares.

Deﬁnição 2.48. Uma n − upla ou conjunto ordenado de números {α1, α2, ⋯, αn} é
solução do sistema de equações lineares se for, simultaneamente, solução de todas as
equações do sistema, ou seja: {α1, α2, ⋯, αn} é solução se, e somente se, ai1α1 + ai2α2 +
⋯ + ainαn = bi, para todo i ∈ {1, 2, ⋯, n}.
Exemplo 2.49. Seja o sistema de equações lineares

x + y + z = 0
2x + 3y + z = 0
x + y + 2z = 1

O sistema admite como solução o conjunto (−2, 1, 1), pois:

(−2) + 1 + 1 = 0 (verdadeira)
2 ⋅ (−2) + 3 ⋅ 1 + 1 = 0 (verdadeira)
(−2) + 1 + 2 ⋅ 1 = 1 (verdadeira)

Mas não admite (2, −1, −1) como solução pois:

2 + (−1) + (−1) = 0 (verdadeira)
2 ⋅ 2 + 3 ⋅ (−1) + (−1) = 0 (verdadeira)
(−2) + (−1) + 2 ⋅ (−1) = 1 (f alsa)
Deﬁnição 2.50. Seja um sistema linear de m equações e n incógnitas. Dizemos que
o sistema é:

i. Compatível, quando possui uma única solução;

ii. Compatível indeterminado, quando possui inﬁnitas soluções;

iii. Incompatível, quando não possui solução.

Assim, a deﬁnição 2.50 nos dá a classiﬁcação do sistema de equações quanto ao
número de soluções. Pois bem, estamos interessados num sistema compatível em que o
número de equações é igual ao número de incógnitas. A esse respeito, Iezzi et. al. [11]
aﬁrma que para discutirmos sistemas de n equações e n incógnitas devemos calcular o
det(A), onde A é a matriz gerada pelo sistema. Bem como, analisarmos os seguintes
casos:

64

i. det(A) ≠ 0, então o sistema é compatível;

ii. det(A) = 0, então o sistema é compatível indeterminado ou incompatível.

As deﬁnições e o teorema a seguir nos garantem as condições para que tenhamos

um sistema compatível. são eles:

Deﬁnição 2.51. Um sistema linear de m equações e n incógnitas pode ser escrito em
notação matricial, ou seja, na forma AX = B, onde:

A =

a11
a21

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
Temos então, que

⋮

a12 ⋯ a1n
a22 ⋯ a2n
⋮
⋱
⋮

am1 am2 ⋯ amn

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦m×n

; X =

x1
x2

⋮
xn

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×1

e B =

b1
b2

⋮
bn

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦n×1

.

AX = B ⇐⇒

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

a11
a21

⋮

a12 ⋯ a1n
a22 ⋯ a2n
⋮
⋱
⋮

am1 am2 ⋯ amn

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

x1
x2

⋮
xn

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

=

b1
b2

⋮
bn

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Deﬁnição 2.52. Se o número de equações de um sistema linear for igual ao número
de incógnitas, a matriz A é quadrada, portanto, existe det(A) que denominamos deter-
minante do sistema.

Deﬁnição 2.53. Um sistema de n equações a n incógnitas é chamado sistema normal
quando o determinante do sistema é diferente de zero.

Teorema 2.54. Seja um sistema linear de n equações e n incógnitas. Se a matriz A
dos coeﬁcientes, de tamanho n × n, for inversível, então o sistema é classiﬁcado como
compatível, ou seja, possui uma única solução indicada por X = A−1B.

Demonstração: Se a matriz A = (aij) dos coeﬁcientes é quadrada de ordem n, então
pela deﬁnição 2.52 existe o det(A). Da deﬁnição 2.53, temos que, se det(A) ≠ 0 então
o sistema é denominado normal. Em vista disso e supondo que o sistema seja normal,
segue do corolário 2.43 e do teorema 2.11 que existe A−1 e é única.

De fato, se tomarmos a equação matricial AX = B correspondente ao sistema e

multiplicarmos ambos os lados da igualdade por A−1, obtemos:

Mas,

Então, segue que

A−1AX = A−1B.

A−1A = In.

InX = A−1B.

65

O que resulta em

X = A−1B.

Portanto, concluímos que se o sistema for normal, a solução existe e é unica. Em

outras palavras, o sistema é compatível.

Exemplo 2.55. Seja o sistema

∎

x + 2y + 4z = 0
3x + y + 2z = 0
x − y − z = 5

Escrevendo o sistema em notação matricial, obtemos:

AX = B ⇐⇒

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

4
2
1
3
2
1
1 −1 −1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

x
y
z

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

=

0
0
5

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Calculando o determinante da matriz A, a matriz de cofatores dos elementos (aij)

e a matriz adjunta de A, temos:

i. det(A) = −5

ii. C =

A11 A12 A13
A21 A22 A23
A31 A32 A33

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

iii. A = C t =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

0
1 −2
5 −5 10
3 −5
−4

=

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1
−2 −5
0

5 −4
3
10 −5

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Daí segue que a solução do sistema X = A−1B é dada por:

X =

1
det(A)

⋅ A ⋅ B =

1
(−5)

⋅

O que resulta em

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 −2
0
5 −5 10
3 −5
−4

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

0
0
5

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

X =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

0
−10
5

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Dos resultados apresentados nesta seção, em síntese, temos que dado um sistema de
equações lineares, podemos denotá-lo na forma de equação matricial, ou seja AX = B,
onde A, X e B são as matrizes geradas. Se a matriz A dos coeﬁcientes for inversível,
então a equação matricial possui solução e esta é única. Em outras palavras, a existência
e unicidade da solução da equação matricial implica na existência e unicidade da solução
do sistema de equações lineares correspondente.

3 Método dos mínimos quadrados

3.1 Breve histórico

De acordo com Crato [7], um dos maiores problemas com que sempre se debateram
os astrônomos foi o da combinação de observações, feitas necessariamente com erros,
para estimação de parâmetros de posição dos corpos celestes. Astrônomos da Grécia
antiga, tais como Hiparco (180 − 125 a.C.), Eratóstenes (276 − 194 a.C.) e Aristarco
(310 − 230 a.C.), aceitavam aproximações em suas medições e não se preocupavam com
erros em suas mensurações, ou pelo menos, não escreveram sobre esses problemas.

Ainda de acordo com Crato [7], Tycho Brahe (1546 − 1601) astrônomo da era pré
– telescópica foi um dos primeiros a se preocupar com as medidas e o rigor das ob-
servações. Fazia várias medições de um mesmo parâmetro, juntava essas observações,
eliminava erros grosseiros e obtinha médias que utilizava para suas estimativas. Esse
controle da precisão da medida era uma novidade para época.

O estudo matemático da combinação de observações, realizado de forma sistemática,
iniciou-se com Roger Joseph Boscovich (1711 − 1787), Pierre Simon Laplace (1749 −
1827), Adrien - Marie Legendre (1752 − 1833) e Carl Friedrich Gauss (1777 − 1855).
Tentava-se encontrar um método ideal de combinação de observações, em particular,
tentava-se determinar os parâmetros das órbitas dos cometas a partir de medições
pontuais obtidas em diferentes momentos.

A solução encontrada que teve maior desenvolvimento teórico e maior aplicação
prática, foi a do método dos mínimos quadrados, publicada por Legendre em 1805 na
sua obra intitulada Nouvelles Méthodes pour la détermination des orbites des cometes
(Novos métodos para determinação das órbitas dos cometas), e por Gauss em 1809
na Theoria Motus Corporum Coelestium (Teoria do movimento dos corpos celestes).
Embora Legendre tenha antecipado a apresentação de seus resultados, sabe-se que
Gauss os tinha obtido muito antes, entre 1794 e 1795, por isso se atribui a este último
a prioridade da criação do método.

66

Concepção do método

67

3.2 Concepção do método

Queremos nesta seção, discorrer brevemente sobre os pressupostos que levaram ao
desenvolvimento do método dos mínimos quadrados. Para tanto, vamos iniciar com o
seguinte problema:

“Como estimar um parâmetro com base em medidas repetidas, com valores
ligeiramente diferentes?”

Para melhor compreensão do problema apresentado, vejamos o exemplo a seguir:

Exemplo 3.1. Uma balança mecânica foi utilizada para medir o peso de uma saca
de farinha. Foram efetuadas três medições consecutivas, e observaram-se pequenas
diferenças nos resultados. Veja tabela 3.1:

Tabela 3.1: Peso da saca de farinha em três medidas

Série de medições
Peso em Kg

1ª
21

2ª
18

3ª
21

Fonte: Tabela gerada pelo autor

Como combinar essas observações de modo a obter uma estimativa plausível do
peso da saca? Precisamos de uma medida que tende a tipiﬁcar, ou, representar melhor
o conjunto de medidas. Uma maneira historicamente usual para determinar tal medida
é a média aritmética. Nesse sentido, o próprio Gauss disse que:

“tem sido costume encarar como um axioma a hipótese de que, se uma quan-
tidade foi determinada por várias observações diretas, feitas nas mesmas
circunstâncias e com igual cuidado, então a média aritmética dos valores
observados fornece o valor mais provável, se não rigorosamente, pelo menos
com grande aproximação”. (citado por Crato [7])

De acordo com Stevenson [17], a média possui certas propriedades interessantes e

úteis que explicam por que é a mais usada. São elas:

i. Pode sempre ser calculada

ii. Para um dado conjunto de valores, a média é única;

iii. É sensível a todos os valores do conjunto. Assim, se um valor se modiﬁca, a

média também se modiﬁca;

iv. Somando-se, subtraindo-se, multiplicando-se ou dividindo-se uma constante a
cada valor do conjunto, a média ﬁcará respectivamente aumentada, reduzida,
multiplicada ou dividida do valor dessa constante;

Concepção do método

68

v. A soma dos desvios dos valores de um conjunto a contar da média é zero.

Desta forma, considerando as características da média e tomando-a como método
de estimativa, é possível generalizar os princípios desse método a um problema mais
complexo, como a determinação simultânea de vários parâmetros? Crato [7] aﬁrma que
a partir deste questionamento Gauss desenvolveu o método dos mínimos quadrados.
Para tanto, ele atacou o problema de duas maneiras:

i. Qual a métrica que leva a escolha da média aritmética?

ii. Qual a distribuição dos erros que leva a que a média aritmética forneça uma

estimativa ótima?

3.2.1 Abordagem não probabilística

A primeira abordagem pretende determinar em que sentido a média aritmética
fornece uma aproximação ótima a um conjunto de observações. Neste caso, temos uma
questão estatística ou matemática que não envolve um processo probabilístico, ou seja,
não há preocupação com o caráter aleatório das medidas.

Retomando o exemplo 3.1, vamos considerar a média aritmética (dada por ¯x = 20kg)
como estimativa que representa o conjunto de medidas observadas. Estas medidas
estão nas proximidades da média, então queremos determinar um valor que represente
o quanto elas estão próximas da estimativa. Veja a ﬁgura 3.1 que ilustra a idéia de
desvios das medidas observadas (pontos) em relação à média:

Figura 3.1: Dispersão das medidas observadas em relação à média

Fonte: Adaptada de Stevenson [17]

Para determinar um valor que indique a proximidade com a média x, poderíamos
calcular a soma dos desvios, porém, neste caso, esse valor é zero. Então, é conveniente

que façamos a soma dos desvios absolutos, isto é:

∣xi − ¯x∣ = 4. No entanto, se

3
∑
i=1

considerarmos outra estimativa, a mediana ˜x , por exemplo, obteremos:

3
∑
i=1

∣xi − ˜x∣ = 3.

Concepção do método

69

Diante disto, parece que a mediana fornece uma estimativa preferível, pois indica uma
proximidade maior entre o valor observado e o valor estimado. Mas se observarmos
a Tabela 3.2, percebemos que a média aritmética é o valor que minimiza a soma dos
quadrados dos desvios, enquanto a mediana é o valor que minimiza a soma dos desvios
absolutos:

Tabela 3.2: Média, mediana, desvios absolutos e quadrado dos desvios dos pesos da
saca de farinha em estudo.

¯x
20
20
20

˜x
21
21
21

∣xi − ¯x∣
1
2
1

∣xi − ˜x∣
0
3
0

2
(xi − ¯x)
1
4
1

2

(xi − ˜x)
0
9
0

–

–

4

3

6

9

xi
21
18
21

3
∑
i=1

Fonte: Adaptada de Crato [7]

Assim sendo, qual dos dois critérios obtém a melhor aproximação entre valor obser-
vado e valor estimado? A esse respeito, Vuolo [18] aﬁrma que a soma dos quadrados
dos desvios é uma quantidade mais razoável que a soma dos módulos dos desvios.

De fato, Vuolo [18] diz que se tomarmos três medidas distintas x1, x2 e x3, bem
como a soma dos desvios absolutos S = ∣d1∣ + ∣d2∣ + ∣d3∣ com di = xi − ˜x, de tal modo que
a mediana ˜x seja a melhor estimativa que minimiza essa soma, e por outro lado, se
admitirmos x1 ≤ x2 ≤ x3, ˜x entre x1 e x2 e ∣d1∣ + ∣d3∣ = (x3 − ˜x) + (˜x − x1) = (x3 − x1),
notamos que ∣d1∣ + ∣d3∣ não depende de ˜x. À vista disto, para minimizarmos S, basta
minimizarmos ∣d2∣, o que implica ∣d2∣ = 0, ou seja, ˜x = x2.

Segundo Stevenson [17], a mediana divide um conjunto ordenado de valores em dois
grupos iguais, dos quais, uma metade terá valores inferiores à mediana e a outra metade
valores superiores à mediana. Deste modo, temos que o resultado supra mencionado
pode ser generalizado da seguinte forma:

i. Se tivermos um número impar de observações, a mediana deve ser o valor inter-

mediário;

ii. Se tivermos um número par de observações, a mediana deve ser o valor médio

dos dois valores xi intermediários.

Então, no caso das três medidas, supondo x2 muito próximo de x1, por exemplo, ˜x
seria muito próximo de x1, o que não é muito razoável quando estamos buscando uma
medida central que tipiﬁca um conjunto de medidas. Nesse sentido, a média é uma
estimativa preferível e a soma dos quadrados dos desvios parece ser um procedimento
melhor que a soma dos desvios absolutos.

Concepção do método

70

Assumindo que o critério dos mínimos quadrados é o melhor procedimento que
minimiza os desvios a contar da média, é possível generalizá-lo a outro tipo de esti-
madores? Ou seja, será possível encontrar processos de estimar parâmetros de modo
que as diferenças nas observações (erros) sejam mínimas? De acordo com Crato [7],
os estudos de Gauss levaram-no a deduzir um método de combinar observações e, com
base nelas, estimar os parâmetros de uma função que minimiza os desvios a contar da
função.

Isto signiﬁca que, ao determinarmos os parâmetros de uma função, estamos estabe-
lecendo uma estimativa ﬁável do tipo de relação entre variáveis distintas inerentes ao
mesmo objeto observado. Ou seja, estamos ajustando à curva que melhor se aproxima
do comportamento dos pontos experimentais.

Supondo que os valores observados sejam oriundos de um processo de medição com
duas variáveis x e y, queremos veriﬁcar se entre tais variáveis existe uma relação, onde
a variável x possa ser caracterizada como independente. De acordo com Vuolo [18], os
resultados obtidos das medições são denominados pontos experimentais, sendo que cada
par de resultados (x, y) pode ser representado como um ponto no gráﬁco Y versusX,
que é denominado diagrama de dispersão. Vejamos a ﬁgura 3.2:

Figura 3.2: Gráﬁco de dispersão dos pontos experimentais

Fonte: Figura gerada pelo autor

Visualizando os pontos experimentais no diagrama de dispersão e supondo que haja
uma relação entre as variáveis x e y, esta relação, determina o padrão da disposição dos
pontos no gráﬁco. Logo, ajustar uma curva que se aproxima do comportamento destes
pontos, signiﬁca ajustar uma função g(x) que melhor se aproxima do comportamento
dos dados obtidos experimentalmente.

Entretanto, qual função deve ser ajustada à dispersão dos pontos experimentais?
Segundo Ruggiero e Lopes [15], a escolha da função depende de considerações teóricas
inerentes ao experimento ou do próprio padrão apresentado pelos pontos. Vejamos
a ﬁgura 3.3 que ilustra algumas possibilidades de ajuste de funções polinomiais aos

Concepção do método

71

pontos experimentais:

Figura 3.3: Gráﬁcos de funções polinomiais ajustadas

Fonte: Figura gerada pelo autor

Uma vez deﬁnida a função g(x) a ser ajustada, precisamos estabelecer um critério
para determinação de seus parâmetros que torne mínimo os erros (desvios verticais) de
aproximação em cada ponto (xi, yi) do gráﬁco de dispersão. Vejamos a ﬁgura 3.4:

Figura 3.4: Representação dos erros (desvios verticais) ei

Fonte: Figura gerada pelo autor

Concepção do método

72

Da ﬁgura 3.4, temos que e1,e2 e e3 representam três dos desvios verticais de cada

um dos n pontos até a função g(x). Assim, veriﬁcamos que:

e1 = ∣g(x1) − y1∣, e2 = ∣g(x2) − y2∣, ⋯, en = ∣g(xn) − yn∣.

Como e1

2 = ∣g(x1) − y1∣

2

= (g(x1) − y1)

2, segue que:

e1

2 + e2

2 + ⋯ + en

2 = (g(x1) − y1)

2

2
+ (g(x2) − y2)

2
+ ⋯ + (g(xn) − yn)

=

=

n
∑
i=1

(g(xi) − yi)

2.

n
∑
i=1

Desta forma,

(g(xi) − yi)

2 deve ser mínima para os melhores valores dos parâme-

tros de g(x). Isto signiﬁca que, se os dados se comportam como função polinomial, a
melhor função a ser ajustada com forma e números de parâmetros predeterminados é
dada pela função:

g(x; a1, a2, ⋯, ap) = a1g1(x) + a2g2(x) + ⋯ + apgp(x),

onde as funções g1(x), g2(x), ⋯, gp(x) são potências de x, ou seja,

g1(x) = xn, g2(x) = xn−1, ⋯, gp−1(x) = x, gp(x) = 1
e os particulares valores dos parâmetros a1, a2, ⋯, ap devem ser tais que minimizam

n
∑
i=1

(g(xi; a1, a2, ⋯, ap) − yi)

2.

3.2.2 Abordagem probabilística

Crato [7] nos diz que a segunda abordagem de Gauss tem por objetivo determinar
as melhores chances de que a estimativa dada pela média seja uma aproximação ótima
em um conjunto de valores observados. Desta forma, o problema é estudado conforme
um processo probabilístico, onde o caráter aleatório das observações é muito relevante.
De acordo com Stevenson [17], se as medidas observadas mostram aleatoriedade
nos resultados, então estas tendem a apresentar diferenças de valores de uma obser-
vação para outra. Se as diferenças são inﬂuenciadas por fatores (erros) que ocorrem
de maneira análoga em observações repetidas um grande número de vezes, então no
conjunto de observações existem medidas que podem ser mais prováveis que outras.
Nesse sentido, como determinar as medidas mais prováveis?

Retomando o exemplo da medição do peso da saca de farinha, extrapolando as ob-
servações para um número maior de medições e supondo que se mantenham as pequenas
diferenças de valores, não podemos esperar que as medidas observadas apresentem ape-
nas resultados inteiros, pois existe uma inﬁnidade de valores que essas medidas podem
assumir. Esse fato não nos permite pensar na ocorrência da probabilidade de um va-
lor especíﬁco, seria pouco razoável, uma vez que as chances seriam muito pequenas.
Assim, como podemos determinar a medida mais provável do peso da saca?

Concepção do método

73

Segundo Vuolo [18], podemos estabelecer intervalos de valores com centros e tama-
nhos dados por medidas especíﬁcas. Estas medidas devem ser tais que qualquer valor
observado estará incluído em um e somente um intervalo. Em vista disso, admitindo
que as medidas observadas na medição do peso da saca de farinha ocorram no inter-
valo (18, 22), podemos estabelecer subintervalos de valores e enquadrar as medidas em
agrupamentos de porcentagens de ocorrências, ou seja, numa distribuição de frequên-
cias relativas. Esta distribuição “... mostra a proporção de vezes em que as medidas
tendem a assumir um dos valores observados” (STEVENSON, 1981)[17]. Vejamos a
tabela 3.3:

Tabela 3.3: Série de medições, intervalo de valores e frequências relativas.

Série de
Medições

Série de
Peso
(kg) medições

1ª
2ª
3ª
4ª
5ª
6ª
7ª
8ª
9ª
10ª

18,25
19,00
18,75
19,25
19,50
19,25
19,75
19,00
18,50
19,00

11ª
12ª
13ª
14ª
15ª
16ª
17ª
18ª
19ª
20ª

Peso
(kg)

19,25
19,25
20,00
20,25
20,50
19,50
19,50
19,75
19,75
20,75

Intervalo
de valores

Frequências
relativas

18,25 a 18,75
18,75 a 19,25
19,25 a 19,75
19,75 a 20,25
20,25 a 21,75
—
—
—
—
—

10%
20%
35%
20%
15%
—
—
—
—
—

Fonte: Tabela gerada pelo autor

Stevenson [17] explica que os intervalos e as respectivas frequências relativas listadas
na tabela 3.3 podem ser representados por um histograma. Neste, os intervalos são
distribuidos ao longo do eixo horizontal e as frequências ao longo do vertical, onde
as fronteiras das barras coincidem com os pontos extremos dos intervalos. Vejamos a
ﬁgura 3.5:

Concepção do método

74

Figura 3.5: Distribuição de frequência dos valores listados na tabela 2.3

Fonte: Figura gerada pelo autor

Da ﬁgura 3.5 temos que:

i. Ik(k = 1, 2, 3, ⋯, n) são intervalos de valores;

ii. ∆ =

In − I1
√
N

é a amplitude ou tamanho do intervalo Ik;

iii. N é o número de observações;

iv. √

N com 5 ≤

√

N ≤ 15 é a quantidade de intervalos da distribuição 1;

v. Fj(j = 1, 2, 3, ⋯, m) são as frequências das medidas observadas que incidem em

cada intervalo.

Ao observarmos a ﬁgura 3.5, constatamos que o valor mais provável para a medida
do peso da saca de farinha parece estar situado próximo ao intervalo que apresenta a
maior frequência. A média ¯x = 19, 44 está numa posição intermediária entre os extremos
desse intervalo, ou seja:19, 25 < ¯x < 19, 75. Então, podemos supor que a média é o
valor mais provável. Por outro lado, sabemos que o peso do objeto é constante, logo,
as diferenças de medidas correspondem a erros nas observações. Como já discutido
na seção 3.2.1, os erros são desvios em relação a média que podem ser minimizados
conforme o critério dos mínimos quadrados.

Isto posto, queremos saber qual será a distribuição dos erros que faz com que a es-
timativa dada pela média, seja a de maior probabilidade de se aproximar do verdadeiro
peso da saca de farinha.

1De acordo com Stevenson [17], a quantidade de intervalos é limitada por 5 ≤

N ≤ 15, pois se for
menor que 5 pode ocultar detalhes importantes dos dados, e, se for maior que 15 torna apresentação
da distribuição demasiadamente detalhada.

√

Concepção do método

75

Stevenson [17] salienta que desde o século XVIII astrônomos e outros cientistas
observaram que quando se coletava grande número de mensurações, dispondo-as numa
distribuição de frequência, elas se apresentavam repetidamente de forma análoga à da
ﬁgura 3.6.

Figura 3.6: Tendência da distribuição de frequência

Fonte: Figura gerada pelo autor

A tendência apresentada pela ﬁgura 3.6 indica que as medidas observadas distribuem-
se em torno da média, onde os valores com maior frequência de ocorrência estão nas
suas proximidades, enquanto que os de menor frequência estão mais distantes. A vista
disto, podemos supor que a distribuição dos erros minimizados que tem a média como
estimativa, segue a tendência apresentada pela ﬁgura 3.6.

De fato, Crato [7] relata que Gauss deduziu uma distribuição matemática que jus-
tiﬁca o uso da média e do método dos mínimos quadrados, denominada distribuição
normal ou Gaussiana. Essa distribuição estabelece uma boa aproximação ao padrão
apresentado pelo histograma destacado na ﬁgura 3.6.

Corroborando Crato, Vuolo [18] aﬁrma que tal distribuição determina que a grande
maioria dos erros aleatórios ei(i = 1, 2, ⋯, n), admitidos como tendo diferentes distribui-
ções, são tais que nenhum ei particular é muito maior que os demais. Nestas condições,
ei, então, a distribuição de erros ei converge para uma distribuição
se o erro total é

gaussiana, no limite n —→ ∞. A ﬁgura 3.7 ilustra essa aproximação:

n
∑
i=1

Concepção do método

76

Figura 3.7: Aproximação do histograma à distribuição gaussiana

Fonte: Figura gerada pelo autor

Na ﬁgura 3.7, notamos que a convergência descrita por Vuolo [18], implica que
quando aumentamos o número de intervalos e diminuímos o seu tamanho, o formato
do histograma de distribuição de frequências se aproxima do formato da distribuição
gaussiana. Ou seja, intuitivamente temos que a soma das áreas dos retângulos formados
pelas barras do histograma é uma aproximação da área da região sob a curva gaussiana
e o eixo horizontal.

Em outras palavras, a distribuição gaussiana é deﬁnida por uma função h(y) que
informa a probabilidade de uma variável assumir um dado valor pertencente a um
intervalo suﬁcientemente pequeno. Isto é, dado um conjunto {y1, y2, ⋯, yn} de n valores
possíveis que a variável pode assumir, temos que cada valor yi do conjunto, pode
ocorrer com probabilidade P (yi) ≡ ∆Pi, onde ∆Pi é um intervalo de probabilidade que
depende do tamanho do intervalo ∆y entre duas medidas, sendo ambos os intervalos
inﬁnitesimais.

Assim, a probabilidade ∆Pi é proporcional ao intervalo ∆y, e isso signiﬁca que a
razão entre ∆Pi e ∆y é uma quantia deﬁnida por h(y) = lim
. Portanto, se h(y) é
∆y→0
conhecida, podemos aﬁrmar que a probabilidade de um valor yi pertencer ao intervalo
∆y é dada por P (yi) ≅ h(yi)∆y.

∆Pi
∆y

Nesse contexto, ao aproximarmos o histograma da gaussiana, estamos, de acordo

com Malta et al.[14]:

i. tomando um intervalo [a, b] contido no domínio de h;

ii. tomando uma partição p para o intervalo, que corresponde a um conjunto ﬁnito de
valores {y0, y1⋯, yk−1, yk}, que satisfaz y0 = a < y1 < ⋯ < yk−1 < b = yk e subdivide
o intervalo [a, b] em n subintervalos [yi−1, yi];

iii. escolhendo valores c1, ⋯, ck com yi−1 ≤ ci ≤ yi, para 1 ≤ i ≤ k

de forma que a soma de Riemann de h sobre a partição p e à escolha dos valores

ci, que é dada por:

S(h, p) = h(c1) ⋅ (y1 − y0) + h(c2) ⋅ (y2 − y1) + ⋯ + h(ci) ⋅ (yi − yi−1) + ⋯

Concepção do método

77

⋯ + h(ck) ⋅ (yk − yk−1) = ∑

i=1 h(ci) ⋅ (yi − yi−1)

k

seja uma boa aproximação da função para intervalos suﬁcientemente pequenos.

Se denotarmos (yi − yi−1) por ∆yi, temos que:

S(h, p) =

k
∑
i=1

h(ci) ⋅ ∆yi.

Esta soma é a integral de h(y) entre a e b, no limite de ∆yi —→ 0. Ou seja:

lim
∆yi→0

S(h, p) = ∫

a

b

h(y)dy.

Em vista disto, podemos aﬁrmar que a probabilidade de uma variável y assumir um
valor pertencente ao intervalo [a, b] é dada pela soma das probabilidades para todos
os valores de yi neste intervalo, o que é equivalente a determinar a área sob a curva
gaussiana delimitada pelos extremos do intervalo [a, b] e o eixo horizontal. Em outros
termos, podemos aﬁrmar que:

P (a, b) = ∫

a

b

h(y)dy.

Na igualdade acima, h(y) é uma função denominada densidade de probabilidade.

Tal função é deﬁnida por

h(y) =

1
√
2π

σ

⋅ e−

1
2 ⋅(

2
y−y
σ )

, −∞ < y < ∞

e apresenta as seguintes características:

i. h(y) ≥ 0, ∀y ∈ R;

ii.

iii.

∞

∫

−∞

h(y)dy = 1;

lim
y→±∞

h(y) = 0;

iv. h(y) ﬁca completamente especiﬁcada por dois parâmetros:

n
∑

a. (y) média da distribuição normal, que indica a localização do centro da dis-
e pode assumir qualquer valor na reta real
tribuição. É dada por y =
−∞ < y < ∞;
b. (σ) desvio padrão, que indica a variabilidade ou dispersão em relação ao centro.
, onde n corresponde ao número de observações.
É dado por σ =

i=1 yi
n

n
∑

√

i=1 (yi − y)2
n − 1

O gráﬁco de h(y), ilustrado pela ﬁgura 3.8, possui algumas características peculiares

quanto ao seu formato:

i. tem a forma semelhante a de um sino;

Concepção do método

78

ii. é suave e simétrico em relação à média;

iii. possui ponto de máximo em h(y = y) =

σ
iv. (y ± σ) são os pontos de inﬂexão de h(y);

1
√
2π

;

v. o formato depende da variação dos parâmetros y e σ, que implica respectivamente

em translação e achatamento da curva;

vi. apresenta o seguinte padrão de distribuição:
a. 68% de sua área está situada entre y ± σ;
b. 95, 5% de sua área está situada entre y ± 2σ;
c. 99, 7% de sua área está situada entre y ± 3σ.

Figura 3.8: Distribuição gaussiana

Fonte: Figura gerada pelo autor

Para determinarmos a probabilidade de uma variável y assumir um valor perten-

cente ao intervalo [a, b] temos que calcular a integral

b

1
√
2π ∫

a

σ

1
2 ⋅(

2
y−y
σ )

e−

dy.

No entanto, há inﬁnitas possibilidades de combinação para os parâmetros y e σ,
o que signiﬁca inﬁnitas probabilidades se considerarmos todas as distribuições nor-
mais possíveis. Contudo, podemos contornar essa diﬁculdade reduzindo o problema a
calcular a integral de e −z2
2 .

Fazendo a substituição z =

y−y
σ

(dz =

dy

σ ), obtemos:

b

1
√
2π ∫

a

σ

2

1
2 ⋅(

y−y
σ )

e−

dy =

1
√
2π ∫

b−y
σ

a−y
σ

e −z2

2 dz,

Concepção do método

79

ou seja, uma integral de e −z2

2 no intervalo [A, B], com A =

a−y
σ

e B =

.

b−y
σ

Mas essa integral não tem solução analítica, então devemos procurar uma solução
numérica. A esse respeito Asano e Colli [2] diz que em probabilidade, como é muito
frequente o uso dessa integral, são adotadas tabelas que podem ser montadas com os
métodos de integração numérica. Uma outra possibilidade, de acordo com Vuolo [18], é
consultar Handbooks de funções matemáticas que usualmente apresentam tabelas para
esta integral.

Da substituição acima, quando utilizamos a variável z, estamos trabalhando com
valores relativos ao invés dos valores reais. Nesse sentido, Stevenson [17] argumenta
que:

Há uma vantagem em trabalhar com valores relativos. É que, em vez
de lidarmos com uma família inﬁnita de distribuições normais, precisamos
de apenas uma distribuição normal para todos os problemas. Podemos con-
verter qualquer valor de qualquer distribuição em um valor z. [...] isto nos
permite determinar todas as probabilidades da curva normal utilizando uma
única tabela padronizada.

O uso da variável z equivale a tomar a média como ponto de referência (origem) e
o desvio padrão como medida de afastamento a contar da média (unidade de medida).
Vejamos o exemplo a seguir:

Exemplo 3.2. Da tabela 3.3 temos que o valor da média é y = 19, 44 e o desvio padrão
é σ = 0, 63. Qual deverá ser a probabilidade de yi variar entre a média e o ponto
y = 20, 64?

Transformando a variável y na variável z, temos que

z =

yi − y
σ

20, 64 − 19, 44
0, 63

=

≅ 1, 9.

Consultando a tabela de probabilidades para distribuição normal padronizada [17],
constatamos que P (19, 44 ≤ y ≤ 20, 64) = P (0 ≤ z ≤ 1, 9) = 0, 4713, ou seja, há 47, 13%
de chances de yi variar entre a média e o ponto y = 20, 64. A ﬁgura 3.9. ilustra essa
probabilidade:

Concepção do método

80

Figura 3.9: Área sob a curva normal entre a média e z

Fonte: Figura gerada pelo autor

Do que foi discutido até aqui, em síntese, temos que a distribuição normal é um
modelo que aproxima a distribuição dos erros. É determinada por uma função de den-
sidade de probabilidade que toma a média como estimativa para o valor mais provável
do conjunto de observações, o desvio padrão como medida de dispersão em relação a
média e o critério dos mínimos quadrados como minimizador dos desvios. Tal função
nos informa a probabilidade de ocorrência de uma medida pertencente ao conjunto de
observações.

Na seção 3.2.1 vimos que o critério dos mínimos quadrados é o melhor procedimento
para minimizar os desvios a partir da média. Bem como, observamos que esse critério
pode ser generalizado a outros estimadores, o que implica em estimar os parâmetros
de uma função que minimiza os desvios a contar da função de modo a obter a melhor
aproximação para o conjunto de pontos experimentais.

Nessa perspectiva, queremos obter a melhor aproximação possível para o conjunto
de pontos experimentais em termos probabilísticos. Isto é, queremos determinar uma
função g(x) para a qual é máxima a probabilidade de ocorrer o particular conjunto de
pontos, enquanto que os erros ou desvios de aproximação são mínimos.

Segundo Vuolo [18], se considerarmos os pontos experimentais {xi, yi, σi}, i = 1, 2, ⋯, n,
com xi representando a variável independente, yi variável dependente e σi seu desvio
padrão, temos que a probabilidade Pi de ocorrer qualquer um dos n pontos é propor-
cional à função de densidade de probabilidade h(y), ou seja:

Pi =

1
√

2π

σi

1
2 ⋅(

2
y−yi
σi )

,

e−

daí segue que a probabilidade P de ocorrer o particular conjunto de pontos é dada por:

P = P1 ⋅ P2⋯Pn = (

n

)

⋅ (

1
√
2π

1
σ1 ⋅ σ2⋯σn

1
2 ⋅∑

n
i=1(

2
y−yi
σi )

.

) ⋅ e−

Problema de mínimos quadrados

81

Admitindo que a função g(x) estabelece a melhor aproximação aos pontos experi-
mentais de tal forma que a probabilidade P é máxima, então se substituirmos y pela
função g(xi; a1, a2⋯, ap), obtemos:
1
√
2π

1
σ1 ⋅ σ2⋯σn

P = (

) ⋅ e−

E
2 ,

⋅ (

)

n

onde

E =

n
∑
i=1

g(xi; a1, a2⋯, ap) − yi
σi

[

2

.

]

Denotando a probabilidade de ocorrência do conjunto de pontos experimentais por
P (E), podemos entender que P é uma função decrescente de E, assim, um máximo de
P ocorre quando E é mínimo. Por outro lado, conforme o que já foi discutido na seção
3.2.1, temos que E deve ser mínima para os melhores parâmetros de g(x). Ou seja, os
particulares valores dos parâmetros a1, a2, ⋯, ap devem ser tais que minimizam

2

[

n
∑
i=1

g(xi; a1, a2⋯, ap) − yi
σi
Portanto, o problema de determinar a melhor aproximação aos pontos experimentais
de tal forma que a probabilidade seja máxima e o erro seja mínimo, se reduz a obtenção
de parâmetros para uma função, que de acordo com o discutido na seção 3.2.1, possui
forma e número de parâmetros predeterminados.

]

.

3.3 Problema de mínimos quadrados

De acordo com Vuolo [18], num processo de medição tentamos determinar o valor
de uma grandeza por meio de medidas experimentais, onde o “valor verdadeiro” da
grandeza yv é desconhecido e as medidas experimentais y1, y2, ⋯, yn são aproximações
desse valor. Nestas aproximações ocorrem erros deﬁnidos por ei = yi −yv, {i = 1, 2, ⋯, n},
e estes também são valores desconhecidos, pois dependem do valor verdadeiro.

Assim, se o valor verdadeiro e o erro associado são valores desconhecidos, então
podemos aﬁrmar que há uma incerteza no melhor valor y que aproxima o valor verda-
deiro yv. Nesse sentido, Vuolo [18] explica que a incerteza é uma medida que indica
o quanto esse melhor valor pode diferir do valor verdadeiro em termos probabilísticos.
Especiﬁcamos esta medida pelo erro padrão σm, que por sua vez, é deﬁnido como o
desvio padrão da distribuição dos erros ou desvio padrão do valor médio de n medidas
observadas.

Vuolo [18] diz que o erro padrão pode ser estimado da seguinte forma:

¿
`
`
`
`(cid:192)

2
(y − yi)

n
∑
i=1
n(n − 1)

,

σm =

σ
√n =

(3.1)

Problema de mínimos quadrados

82

onde y e σ correspondem respectivamente à média e o desvio padrão das n medidas.
Graﬁcamente, podemos representar o erro padrão em cada medida observada por
meio de barras de incerteza ou barra de erros, onde cada barra tem comprimento total
2σm e é a representação do intervalo no qual está contida a medida observada (yi ±σm).
Vejamos a ﬁgura 3.10:

Figura 3.10: Barras de incerteza

Fonte: Figura gerada pelo autor

Ainda de acordo com o mesmo autor, o erro padrão é inerente ao conceito de
intervalo de conﬁança, ou seja, o erro num intervalo de conﬁança refere-se a diferença
entre a média amostral e a verdadeira média da população. Desta forma, e de acordo
com Stevenson [17], um intervalo de conﬁança dá um intervalo de valores, centrado na
estatística amostral, no qual julgamos com risco conhecido de erro, estar o parâmetro
da população.

Em outras palavras, se o nível de conﬁança de uma aﬁrmativa é a probabilidade P
de que esta aﬁrmativa esteja correta, temos que, se a aﬁrmativa for (y −δ) < yv < (y +δ),
com δ ≥ 0, então (y − δ) < yv < (y + δ) tem a probabilidade P de ser correta. Logo, tal
aﬁrmativa deﬁne um intervalo de conﬁança para o valor yv.

Stevenson [17] diz que o intervalo de conﬁança pode ser determinado da seguinte

forma:

y ± z α

2 ⋅ σm ou y ± t (1−α)

2

⋅ σm,

(3.2)

onde y e σm correspondem respectivamente à média e o erro padrão, z α
ou t (1−α)
são os coeﬁcientes de conﬁança dados respectivamente pelas tabelas de probabilidade
das distribuições normal padronizada e t-student, e α é o nível de conﬁança desejado.
Com relação aos coeﬁcientes de conﬁança, ressaltamos que geralmente os valores t são
preferíveis quando utilizamos uma amostra considerada pequena, ou seja, com número

2

2

Problema de mínimos quadrados

83

de observações n ≤ 30. Vejamos o seguinte exemplo:

Exemplo 3.3. Seja uma amostra com n = 25 observações, desvio padrão σ = 1, 5 e
média amostral y = 20. Queremos determinar o intervalo de conﬁança de 95% para
média da população.

Como a amostra é pequena, com n = 25 < 30, vamos tomar y ± t (1−α)

⋅ σm. Para um

2

nível de conﬁança de 95%, temos que

(1 − α)
2

=

(1 − 0, 95)
2

= 0, 025.

Consultando a tabela de probabilidades para distribuição t [17], constatamos que

Calculando o erro padrão, temos que

t0,025 = 2, 064.

σm =

σ
√n = 0, 3.

Daí segue que

t0,025 ⋅ σm = 2, 064 ⋅ 0, 3 = 0, 62.
Então, temos o intervalo 20 ± 0, 62, ou seja, 19, 38 < y < 20, 62 é a faixa de valores, com
95% de chances de ocorrência, onde a média da população pode estar.

Isto posto, dado um conjunto de n pontos experimentais {x1, y1}, {x2, y2}, ⋯, {xn, yn}
e supondo que a variável independente xi seja isenta de erros, para que possamos dis-
cutir o problema de mínimos quadrados, devemos considerar a incerteza σi na variável
dependente yi.

Então, tomando os pontos experimentais {x1, y1, σ1}, {x2, y2, σ2}, ⋯, {xn, yn, σn}, a
função g(xi; a1, a2⋯, ap) e considerando o que foi discutido na seção 3.2.2, temos que

E =

n
∑
i=1

g(xi; a1, a2⋯, ap) − yi
σi

[

2

]

deve ser mínima para os melhores valores dos parâmetros {a1, a2⋯, ap}.

Assumindo E como função erro, queremos determinar os melhores valores para os
parâmetros de E(a1, a2⋯, ap). Isso implica determinar o ponto de mínimo dessa função,
o que será feito por meio do cálculo diferencial.

Particularmente, estamos interessados em analisar a função E ∶ D ⊂ R2 → R dada

por

E(a1, a2) =

g(xi; a1, a2) − yi
σm

[

2

,

]

n
∑
i=1

onde g(xi; a1, a2) = a1xi + a2 e σm = σi ≡ σ1 = σ2 = ⋯ = σn, estimada por (3.1),
corresponde a incertezas iguais na variável yi.

Problema de mínimos quadrados

84

Observamos que E é uma função polinomial do segundo grau. Assim, conforme o
discutido no capítulo 1, E é contínua e diferenciável em todo ponto de D. Logo, admite
derivadas parciais nesses pontos e consequentemente deve existir um ponto onde tais
derivadas se anulam, ou seja, deve existir um ponto crítico de D em E “candidato” a
extremo local.

Isto posto, queremos determinar o ponto crítico de D em E e veriﬁcar se é extremo
local, ou mais especíﬁcamente se é ponto de mínimo local. Caso tenhamos constatado
que o ponto investigado é um ponto de mínimo local, precisamos garantir que o mesmo
seja um ponto de mínimo global para que de fato E minimize

g(xi; a1, a2) − yi
σm

[

2

.

]

n
∑
i=1

Para determinarmos o ponto crítico de E vamos efetuar os seguintes procedimentos:

i. Derivando E(a1, a2) em relação a a1, temos

∂E
∂a1

(a1, a2) =

∂
∂a1

n
∑
i=1

a1xi + a2 − yi
σm

[

2

]

=

=

n
∑
i=1

∂
∂a1

a1xi + a2 − yi
σm

[

2
]

=

n
∑
i=1

2(a1xi + a2 − yi)
(σm)2

xi =

= 2

n
∑
i=1

xi
σm

(

2

)

a1 + 2

n
∑
i=1

xi
(σm)2

a2 − 2

n
∑
i=1

xiyi
(σm)2

.

Desta forma, segue que ∂E
∂a1

(a1, a2) = 0 se, e somente se

2

n
∑
i=1

xi
σm

(

2

)

a1 + 2

n
∑
i=1

xi
(σm)2

a2 − 2

n
∑
i=1

xiyi
(σm)2 = 0,

de onde vem

xiyi
(σm)2
ii. Analogamente, derivando E(a1, a2) em relação a a2, temos

xi
(σm)2

a2 = 2

a1 + 2

xi
σm

(

)

2

n
∑
i=1

n
∑
i=1

n
∑
i=1

2

.

(3.3)

∂E
∂a2

(a1, a2) =

∂
∂a2

n
∑
i=1

a1xi + a2 − yi
σm

[

2

]

=

=

n
∑
i=1

∂
∂a2

a1xi + a2 − yi
σm

[

2

]

=

n
∑
i=1

2 (a1xi + a2 − yi)
(σm)2

=

= 2

n
∑
i=1

xi
(σm)2

a1 + 2

n
∑
i=1

1
(σm)2

a2 − 2

n
∑
i=1

yi
(σm)2 =

Problema de mínimos quadrados

85

= 2

n
∑
i=1

xi
(σm)2

a1 +

2n
(σm)2

a2 − 2

n
∑
i=1

yi
(σm)2

Logo, ∂E
∂a2

(a1, a2) = 0 se, e somente se

2

n
∑
i=1

xi
(σm)2

a1 +

2n
(σm)2

a2 − 2

n
∑
i=1

yi
(σm)2 = 0,

que resulta em

2

n
∑
i=1

xi
(σm)2

a1 +

2n
(σm)2

a2 = 2

n
∑
i=1

yi
(σm)2

.

(3.4)

Como yi e σm são valores conhecidos, então as equações (3.3) e (3.4) constituem o

seguinte sistema linear nas variáveis a1 e a2:

2

n
∑
i=1

xi
σm

(

2

)

a1 + 2

n
∑
i=1

xi
(σm)2

a2 = 2

n
∑
i=1

xiyi
(σm)2

2n
(σm)2
Por outro lado, σm é uma estimativa para incertezas iguais na variável dependente,

xi
(σm)2

yi
(σm)2

a2 = 2

a1 +

2

n
∑
i=1

n
∑
i=1

então σm é uma constante e podemos reescrever o sistema da seguinte maneira:

o que corresponde a:

2
(σm)2

n
∑
i=1

(xi)

2a1 +

2
(σm)2

n
∑
i=1

(xi)a2 =

2
(σm)2

n
∑
i=1

(xiyi)

,

2
(σm)2

n
∑
i=1

(xi)a1 +

2
(σm)2

na2 =

2
(σm)2

n
∑
i=1

(yi)

n
∑
i=1

(xi)

2a1 +

n
∑
i=1

(xi)a2 =

n
∑
i=1

(xiyi)

.(3.5)

n
∑
i=1

(xi)a1 + na2 =

n
∑
i=1

(yi)

⎧⎪⎪⎪⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎪⎪⎪⎩

⎨

O ponto (a1, a2) é ponto crítico de E se, e somente se for solução de (3.5). Então,
para que possamos determinar tal ponto, vamos reescrever (3.5) como a equação ma-
tricial AX = B, onde:

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1

2
(xi)

n
∑
i=1

(xi)

n
∑
i=1

(xi)

n

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

, B =

n
∑
i=1

yixi

n
∑
i=1

yi

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

e X =

a1
a2

⎡
⎢
⎢
⎢
⎢
⎣

.

⎤
⎥
⎥
⎥
⎥
⎦

(3.6)

⎧⎪⎪⎪⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎪⎪⎪⎩

⎨

⎧⎪⎪⎪⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎪⎪⎪⎩

⎨

Problema de mínimos quadrados

86

Conforme o discutido no capítulo 2, se a matriz A for inversível, então a solução de

AX = B é dada por X = A−1B, onde

1
det(A)
Assim, calculando o determinante e a matriz adjunta de A, temos respectivamente

A−1

A.

=

det(A) = n ⋅

n
∑
i=1

(xi)

2

− (

n
∑
i=1

2
xi)

e

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n

−

n
∑
i=1

xi

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

n
∑
i=1
De acordo com o corolário 2.43, se veriﬁcarmos que det(A) ≠ 0, constataremos que

n
∑
i=1

(xi)

xi

−

2

a matriz A é inversível. Então, tomando a matriz Y , dada por

Y =

1

⎡
⎢
⎢
n ⋅
⎢
⎢
⎣

n
∑
i=1

2
(xi)

− (

n
∑
i=1

xi)

2⎤
⎥
⎥
⎥
⎥
⎦

segue que

n

n ⋅

n
∑
i=1

(xi)

2

− (

n
∑
i=1

2
xi)

−

n
∑
i=1

xi

Y =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1
Calculando o determinante da matriz Y , obtemos

n
∑
i=1

n
∑
i=1

(xi)

− (

n ⋅

n ⋅

2

2
xi)

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n

−

n
∑
i=1

xi

−

n
∑
i=1

xi

n
∑
i=1

2
(xi)

,

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

−

n
∑
i=1

xi

n ⋅

n
∑
i=1

2
(xi)

− (

n
∑
i=1

2
xi)

n
∑
i=1

2
(xi)

2
(xi)

2
xi)

− (

n
∑
i=1

.

(3.7)

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

det(Y ) =

1

n ⋅

n
∑
i=1

(xi)

2

− (

n
∑
i=1

2 .

xi)

Fazendo o produto entre o determinante da matriz A e o determinante da matriz

Y , temos

Problema de mínimos quadrados

87

det(A)det(Y ) =

n ⋅

n ⋅

n
∑
i=1
n
∑
i=1

2

2

(xi)

− (

(xi)

− (

2
xi)

2 = 1,

xi)

n
∑
i=1
n
∑
i=1

o que implica em det(A) ≠ 0 e Y = A−1. Logo, a matriz A é inversível.
Diante disto, concluímos que

a1
a2

⎡
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎦

=

1

⎡
⎢
⎢
n ⋅
⎢
⎢
⎣

n
∑
i=1

(xi)

2

− (

n
∑
i=1

xi)

2⎤
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n

−

n
∑
i=1

xi

−

n
∑
i=1

xi

n
∑
i=1

2
(xi)

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1

yixi

n
∑
i=1

yi

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

.(3.8)

é solução de AX = B.

Desta forma, temos que (3.8) é solução de (3.5) e pelo teorema 2.54 esta solução
é única. Portanto, o ponto (a1, a2) é ponto crítico de E, e este, é o único candidato a
extremo local.

Determinado o ponto crítico (a1, a2), queremos agora veriﬁcar se este é ponto de
mínimo local. Para tanto, vamos aplicar o teste da derivada segunda em (3.5). Então,
calculando as derivadas parciais segundas de E, obtemos:

i. ∂2E
∂a2
1

ii. ∂2E
∂a2
2

(a1, a2) = 2

n
∑
i=1

(xi)

2;

(a1, a2) = 2n;

iii.

iv.

∂2E
∂a1∂a2

∂2E
∂a2∂a1

(a1, a2) = 2

(a1, a2) = 2

n
∑
i=1

n
∑
i=1

xi;

xi.

Tomando essas derivadas e considerando o teorema 1.31, temos que a função E tem

um valor de mínimo local em (a1, a2) ∈ D se

∂E
∂a2
1

(a1, a2) > 0 e

∂2E
∂a2
1

(a1, a2)

∂2E
∂a2
2

(a1, a2) − [

∂2E
∂a1∂a2

2

(a1, a2)]

> 0.

É imediato que ∂E
∂a2
1

carmos que

(a1, a2) = 2

n
∑
i=1

2
(xi)

> 0 para quaisquer xi ≠ 0. Assim, se veriﬁ-

∂2E
∂a2
1

(a1, a2)

∂2E
∂a2
2

(a1, a2) − [

∂2E
∂a1∂a2

2

(a1, a2)]

= 2

n
∑
i=1

(xi)

2

⋅ 2n − [2

2
xi]

=

n
∑
i=1

Problema de mínimos quadrados

88

= 4n

n
∑
i=1

(xi)

2

− 4 [

n
∑
i=1

2
xi]

> 0,

constataremos que (a1, a2) é ponto de mínimo local.

Seja então, xi ∈ R, com i = {1, 2, ⋯, n} e x1 ≠ x2 ≠ ⋯ ≠ xn. Da desigualdade das

médias temos que

¿
`
`
`
`(cid:192)

n
∑
i=1

(xi)

2

n

xi

n
∑
i=1
n

.

>

Elevando ao quadrado ambos os lados da desigualdade (3.9), obtemos

n
∑
i=1

(xi)

2

n

>

2
xi)

n
∑
i=1

(

n2

.

Multiplicando ambos os lados da desigualdade (3.10) por 4n2, temos

o que corresponde a

4n

n
∑
i=1

2
(xi)

> 4 (

n
∑
i=1

2
xi)

,

4n

n
∑
i=1

2
(xi)

− 4 (

n
∑
i=1

2
xi)

> 0.

(3.9)

(3.10)

(3.11)

(3.12)

Assim, conforme teste da derivada segunda, concluímos que o ponto crítico (a1, a2) é
ponto de mínimo local.

Queremos agora veriﬁcar se o ponto de mínimo local (a1, a2) é ponto de mínimo
global. De acordo com o teorema 1.39, se veriﬁcarmos que a função E é convexa,
constataremos a globalidade de (a1, a2). Mas, pelo teorema 1.47 a função E é convexa
se a matriz hessiana HE(a1, a2) é positiva e semideﬁnida. Por sua vez e conforme
o teorema 1.46, a matriz hessiana é positiva e semideﬁnida se todos os seus menores
principais são maiores ou iguais a zero. Então, tomando as derivadas parciais segundas
de E, temos que estas são elementos da matriz hessiana

∂2E
∂a2
1

∂2E
∂a1∂a2

HE(a1, a2) =

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Os menores principais de HE(a1, a2) são os seguintes determinantes:

∂2E
∂a2∂a1

∂2E
∂a2
2

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1

(xi)

2 2

2n

xi

xi

=

2

2

.

n
∑
i=1

n
∑
i=1

i. ∣ 2

n
∑
i=1

2
(xi)

∣ = 2

n
∑
i=1

(xi)

2,

ii. ∣ 2

n
∑
i=1

xi ∣ = 2

n
∑
i=1

xi,

Problema de mínimos quadrados

89

iii. ∣ 2n ∣ = 2n

iv.

RRRRRRRRRRRRRRRRRRRRRRRR

2

n
∑
i=1

(xi)

2 2

n
∑
i=1

xi

2

n
∑
i=1

xi

2n

RRRRRRRRRRRRRRRRRRRRRRRR

= 4n

n
∑
i=1

(xi)

2

− 4 (

n
∑
i=1

2
xi)

.

É imediato veriﬁcar que os determinantes (i), (ii) e (iii) são maiores ou iguais a
zero. Para veriﬁcarmos se o determinante (iv) é maior ou igual a zero, vamos considerar
todo xi ∈ R com i = {1, 2, ⋯, n}, e tomar

¿
`
`
`
`(cid:192)

n
∑
i=1

(xi)

2

n

xi

n
∑
i=1
n

,

≥

dai segue por processo análogo ao realizado para obtenção de (3.12), que

n
∑
i=1
Desta forma concluímos que todos os menores principais da matriz hessiana HE(a1, a2)

n
∑
i=1

2
(xi)

− 4 (

≥ 0.

4n

2
xi)

são maiores ou iguais a zero. Logo, a matriz é positiva semideﬁnida, a função E é con-
vexa e por conseguinte o ponto (a1, a2) é ponto de mínimo global. Portanto, E(a1, a2)
minimiza

n
∑
i=1

g(xi; a1, a2) − yi
σm

[

]

2

e consequentemente a1 e a2 são os melhores parâmetros de g(xi; a1, a2).

A incerteza na variável dependente yi implica em incerteza nos parâmetros aj que
determinam a função de ajuste dos dados experimentais. Assim sendo, queremos esti-
mar as incertezas nos melhores parâmetros de g(xi; a1, a2). A equação (3.1) nos fornece
uma estimativa de incerteza referenciada nos desvios em relação à média amostral, mas
precisamos estimar as incertezas nos parâmetros considerando os desvios em relação
a função. Adaptando os cálculos sugeridos por Stevenson [17] podemos estimar as
incertezas nos parâmetros da seguinte forma:

i. Incerteza no parâmetro a1:

σa1 =

n
∑
i=1

⎛
⎜
⎜
⎜
⎜
⎝

2
[g(xi; a1, a2) − yi]

(n − p)

1
2

⎞
⎟
⎟
⎟
⎟
⎠

⋅

⎛
⎜
⎜
⎜
⎜
⎜
⎝

1
2

,

⎞
⎟
⎟
⎟
⎟
⎟
⎠

n

n

n
∑
i=1

(xi)

2
xi]

2

− [

n
∑
i=1

(3.13)

Avaliação do ajuste

90

ii. Incerteza no parâmetro a2:

σa2 =

n
∑
i=1

⎛
⎜
⎜
⎜
⎜
⎝

2
[g(xi; a1, a2) − yi]

(n − p)

1
2

⎞
⎟
⎟
⎟
⎟
⎠

⋅

⎛
⎜
⎜
⎜
⎜
⎜
⎝

n
∑
i=1

2
(xi)

n

n
∑
i=1

(xi)

2

− [

n
∑
i=1

1
2

.

⎞
⎟
⎟
⎟
⎟
⎟
⎠

2
xi]

(3.14)

Onde n é o número de pontos experimentais e p é o número de parâmetros da função.
Tomando (3.2) e substituindo σm por (3.13) e (3.14), podemos estabelecer um
intervalo de conﬁança para os “verdadeiros” valores dos parâmetros a1 e a2. Assim,
para um certo nível de conﬁança α, temos que:

i. se n > 30, então a1 ± z α

2 ⋅ σa1

e a2 ± z α

2 ⋅ σa2

ii. se n ≤ 30, então a1 ± t (1−α)

2

⋅ σa1

e a2 ± t (1−α)

2

⋅ σa2.

3.4 Avaliação do ajuste

O método dos mínimos quadrados nos fornece os melhores parâmetros de uma
função predeterminada a ser ajustada, mas não nos permite inferir sobre a qualidade
do ajuste. Assim, de acordo com Vuolo [18] algum critério de avaliação da qualidade
do ajuste deve sempre ser utilizado juntamente com o método dos mínimos quadrados,
mesmo quando a função a ser ajustada é bem conhecida.

Um critério que podemos usar é a determinação de uma medida que estabelece o
quanto as variáveis estão relacionadas. Segundo Stevenson [17] essa medida é denomi-
nada coeﬁciente de correlação (r) e pode ser calculada da seguinte maneira:

¿
`
`
`
`
`
`
`(cid:192)

r =

1 −

n
∑
i=1

2
[yi − g(xi)]

,

(3.15)

n
∑
i=1
onde [yi − g(xi)]2 e [yi − y]2 representam respectivamente os desvios dos pontos expe-
rimentais em relação a função ajustada e à média.

(yi − y)

2

O valor de r varia de −1 a 1, essa variação caracteriza a natureza do relacionamento

entre as variáveis de tal modo que:

i. valores próximos de −1 ou 1 indicam relacionamento forte, uma vez que a disper-

são dos pontos experimentais em relação a função ajustada é pequena;

ii. valores próximos de 0 indicam relacionamento fraco, pois sugerem uma maior

dispersão dos pontos experimentais em relação a função ajustada;

Avaliação do ajuste

91

iii. valores de r > 0 indicam que valores altos (ou baixos) de uma das variáveis,

correspondem a valores altos (ou baixos) da outra;

iv. valores de r < 0 indicam que valores altos (ou baixos) de uma das variáveis,

correspondem a valores baixos (ou altos) da outra.

Podemos complementar a estatística dada pelo coeﬁciente de correlação, obtendo
uma descrição do grau de relacionamento entre as variávies por meio do coeﬁciente de
determinação (r2). Este, nos fornece a porcentagem de variação de uma variável que
é explicada estatísticamente pela variação em outra variável.

O intervalo de variação do coeﬁciente de determinação é 0 ≤ r2 ≤ 1, em termos por-
centuais, o intervalo indica que quanto mais próximo r2 estiver de 1 a variação de uma
variável será melhor explicada pela variação da outra, e isso signiﬁca, de acordo com
Stevenson [17], que a função ajustada é melhor preditor que a média. Inversamente,
a variação de uma variável não poderá ser explicada pela variação da outra variável
quanto mais próximo r2 estiver de zero, o que implica segundo o mesmo autor, que a
média é melhor preditor que a função ajustada. Vejamos o seguinte exemplo:

Exemplo 3.4. Seja um coeﬁciente de correlação r = 0, 9. O sinal de r nos diz que
existe um relacionamento positivo entre dois conjuntos de valores pertinentes a duas
variávies. O valor de r sugere que as variáveis tem um relacionamento forte. Por outro
lado, r2 = 0, 81, o que signiﬁca que 81% da variação dos valores das variáveis pode ser
explicada pelo relacionamento entre ambas.

4 O experimento

Neste capítulo, inicialmente relataremos a modelagem de um experimento realizado
por alunos do ensino fundamental nas aulas da disciplina matemática. Em seguida,
aplicaremos o método dos mínimos quadrados no ajuste de curva dos dados coletados
de acordo com o que foi discutido nos capítulos anteriores.

4.1 Motivação para realização do experimento

Na qualidade de professor de matemática de ensino fundamental de escola pública
municipal, somos regularmente levados a reﬂetir sobre nossos métodos de ensino por
meio de ações realizadas por nossos coordenadores pedagógicos. Essa prática ocorre
devido às características peculiares do sistema público de ensino, bem como, devido as
diﬁculdades de aprendizagem apresentadas por nossos alunos.

Um pressuposto recorrente destacado pelos coordenadores em suas indagações sobre

aprendizagem matemática é o seguinte:

“se os conceitos matemáticos fazem sentido para o aluno, então este

ﬁcará motivado a buscar a sua compreensão.”

Assim, o sentido para eles, é uma condição necessária para que a aprendizagem ma-
temática ocorra, e esta é estabelecida quando a prática pedagógica permite contextu-
alizações que se aproximem do cotidiano dos alunos. Nessa mesma perspectiva, Lima
(2007), citado por Costa [6], entende que “boas contextualizações são as que, por meio da
problematização, envolvam aplicações ou manipulações [...] de informações que sejam
reais ou simulem a realidade”. Ainda de acordo com o mesmo autor, a instrumen-
tação matemática adequada para traduzir as situações contextualizadas é a chamada
modelagem matemática.

Corroborando as aﬁrmações de Lima, nas citações de Costa, Bassanezi [3] diz que

“a modelagem matemática consiste na arte de transformar problemas
da realidade em problemas matemáticos e resolvê-los interpretando suas
soluções na linguagem do mundo real. Desta forma, [...] a modelagem é
um processo que alia teoria e prática, motivando seu usuário na procura do

92

Motivação para realização do experimento

93

entendimento da realidade que o cerca e na busca de meios para agir sobre
ela e transformá-la”.

Considerando então, que a modelagem matemática pudesse favorecer a construção
de sentido para o aluno no processo de ensino e aprendizagem, direcionamos esforços
para implementar uma prática de ensino que ﬁzesse uso de tal processo. E a opor-
tunidade surgiu quando, numa das escolas onde lecionamos matemática, foi realizado
junto aos alunos de 9º ano um projeto denominado MOBFOG – Mostra Brasileira de
Foguetes. Tal projeto era constituído de dois objetivos:

i. construção e melhoramento estrutural de foguetes (construídos com garrafas PET
e propulsionados a ar comprimido) de modo a atingir a maior distância possível
ao longo da trajetória horizontal;

ii. coleta e tabulação dos resultados de lançamento para envio a OBA - Olimpíada

Brasileira de Astronomia.

O projeto foi inicialmente desenvolvido pela professora da disciplina ciências, mas
na fase de coleta e tabulação dos resultados de lançamento fomos convidados a par-
ticipar. A princípio iríamos apenas ajudar os alunos (que eram comuns às disciplinas
ciências e matemática) no ordenamento e representação dos resultados.

No entanto, percebemos a possibilidade de usar a modelagem matemática como
estratégia de ensino do conteúdo que estávamos ministrando na época (função aﬁm).
Assim, transformamos essa etapa do projeto MOBFOG num experimento deﬁnido da
seguinte maneira:

Lançamento de foguete construído com garrafas PET, cuja propulsão se
dá por meio de bombeadas numa bomba de ar para bicicletas e o desempenho
é determinado pela medida (em metros) da distância percorrida ao longo
da trajetória horizontal.

O objetivo do experimento era determinar, a partir dos dados coletados, uma relação
funcional entre a distância percorrida pelo foguete ao longo da trajetória horizontal
e o número de bombeadas aplicadas para propulsioná-lo, de modo que pudéssemos
elaborar um modelo para fazer previsões de desempenho dado um número qualquer de
bombeadas.

Relato do experimento

94

4.2 Relato do experimento

Nas aulas de ciências cada aluno construiu seu foguete com adaptações e melhora-
mentos estruturais particulares. Então, estabelecemos uma amostra de 10 lançamentos
por foguete para que cada aluno determinasse o melhor desempenho de seu foguete.
Dos resultados gerados, foi construída uma tabela que destacava os melhores desem-
penhos de cada foguete, e assim, os alunos puderam eleger o melhor dos foguetes.

Estabelecido o melhor dos foguetes, foi feita uma segunda amostra, onde cada aluno
realizou 10 lançamentos com este foguete. Analogamente ao que foi feito na primeira
amostra, os resultados foram organizados numa tabela geral dos melhores desempenhos
e assim, os alunos conseguiram determinar o melhor desempenho individual com o
melhor foguete. A ﬁgura 4.1 ilustra um dos lançamentos do melhor foguete.

Figura 4.1: Lançamento do melhor foguete

Fonte: Foto gerada pelo autor

Ordenamos o experimento dessa forma pois observamos que cada aluno apresentava
variação no número de bombeadas realizadas de um lançamento para outro, devido a
falhas na bomba, bem como havia variação no número de bombeadas de aluno para
aluno devido as características físicas de cada um.

Procedendo dessa maneira, obtivemos um conjunto de dados oriundos dos melhores
desempenhos do foguete gerados a partir dos melhores desempenhos individuais dos
alunos. Esses dados foram organizados na tabela 4.1:

Relato do experimento

95

Tabela 4.1: Desempenho do foguete em função do número de bombeadas

Série
de

Número
de

lançamentos bombeadas

Distância
percorrida
(em metros)

Série
de

Número
de

lançamentos bombeadas

Distância
percorrida
(em metros)

1ª
2ª
3ª
4ª
5ª
6ª
7ª
8ª
9ª
10ª
11ª

98
43
160
22
34
73
31
67
80
29
107

68,32
29,91
119,42
13,95
20,76
64,38
17,46
44,25
56,98
16,45
75,2

12ª
13ª
14ª
15ª
16ª
17ª
18ª
19ª
20ª
21ª
22ª

89
140
112
19
36
42
56
115
49
125
33

69,21
109,68
92,64
13,9
20,26
29,21
48,23
97,1
30,12
108,16
22,13

Fonte: Tabela gerada pelo autor

A partir dessa tabela, ministramos numa primeira etapa, aula expositiva na sala de
informática com o objetivo de mostrar aos alunos as várias formas de representação de
dados organizados. Dentre elas, estabelecemos de acordo com nossos objetivos, que o
gráﬁco de dispersão se apresentava como a melhor forma de representação. Denotamos
o número de bombeadas pela variável x e o desempenho do foguete pela variável y, e
desta forma, obtivemos pares ordenados (x, y) como pontos do gráﬁco de dispersão Y
versus X. Tal gráﬁco é ilustrado pela ﬁgura a seguir:

Relato do experimento

96

Figura 4.2: Gráﬁco de dispersão dos pares ordenados (x,y)

Fonte: Gráﬁco gerado pelo autor

Numa segunda etapa da aula, tomamos a ﬁgura 4.2 e induzimos uma discussão a
respeito do signiﬁcado da disposição dos pontos no gráﬁco. Considerando o conteúdo
que os alunos estavam estudando naquele momento, queríamos que percebessem al-
guma relação entre as variáveis. Dentre as várias suposições que ﬁzeram, uma delas
chamou atenção, um aluno aﬁrmou que “a variação dos valores no eixo das abscissas x,
parecia provocar uma variação nos valores do eixo das ordenadas y, mas não conseguia
entender como isso acontecia.”

A esse respeito, Rezende (2003) citado por Costa [6], aﬁrma que “compreender que
a variação de uma grandeza depende da variação de outra é um aspecto importante no
estudo do conceito de função [...], mas se torna incompleto se não estudarmos como
ocorre esta variação...” Em vista disto, percebemos que estávamos no caminho certo no
uso da modelagem como estratégia de ensino, uma vez que esta abordagem favoreceria
a discussão e compreensão da variação enquanto relação entre as variáveis, e isso
poderia ajudar os alunos a assimilar melhor os conceitos que estavam estudando.

Assim, decidimos mostrar aos estudantes que se existisse uma relação entre as
variáveis x e y, esta determinaria o padrão da disposição dos pontos no gráﬁco de
dispersão. Perguntamos a eles se reconheciam algum padrão na disposição dos pontos
da ﬁgura 4.2, e a resposta foi negativa.

Diante disto, explicamos que embora fosse impossível uma reta passar por cada
um dos pontos grafados na ﬁgura 4.2, o comportamento destes indicava com certa
razoabilidade uma relação linear entre as variáveis. Então, deveríamos encontrar uma
reta que estivesse o mais próximo possível de cada um dos pontos. Esclarecemos ainda,

Relato do experimento

97

que esse procedimento é denominado ajuste de reta aos pontos experimentais e que os
desvios (distâncias entre cada ponto e a reta) são erros de aproximação no ajuste.

Findada as explicações e esclarecimentos, resolvemos ensiná-los, usando o software
Excel ®, a efetuar o ajuste de reta aos dados experimentais por meio da construção
da linha de tendência. A ﬁgura 4.3 ilustra o resultado que obtiveram:

Figura 4.3: Gráﬁco de dispersão e linha de tendência

Fonte: Gráﬁco gerado pelo autor

Da ﬁgura 4.3, destacamos aos alunos que devido ao fato de haver diferenças relevan-
tes no desempenho individual quanto ao número de bombeadas aplicadas ao foguete,
não tínhamos certeza a respeito do desempenho do mesmo. Assim, cada barra verti-
cal na qual estava contido um ponto do gráﬁco, representava um intervalo de valores
possíveis de desempenho do foguete para um valor especíﬁco de bombeadas.

A expressão y = 0, 829x − 5, 760 dada pelo Excel, representava a equação da reta
de aproximação aos pontos experimentais, que por sua vez expressava uma relação
funcional f (x) = y entre as variáveis x e y. Desta forma, podíamos entender que
a reta ajustada era a representação gráﬁca de uma função do tipo f (x) = ax + b,
com a = 0, 829 (coeﬁciente angular da reta) indicando a variação de y por unidade
de variação de x e b = −5, 760 (coeﬁciente linear) indicando a cota da reta em x = 0.
Tal função era o modelo matemático que estávamos querendo determinar para fazer
previsões de desempenho do foguete dado um número qualquer de bombeadas.

No entanto, salientamos que embora tenhamos aﬁrmado aos alunos que a equação
y = 0, 829x − 5, 760 expressava uma relação funcional que nos permitiu formular um
modelo matemático para determinação de desempenho do foguete, sabemos que:

Relato do experimento

98

“uma relação funcional, obtida através de ajuste de dados, propicia con-
dições para formulação de modelos [...] que devem comportar em seus parâ-
metros qualidades e signiﬁcados inerentes ao fenômeno analisado e para isto
se faz necessário um estudo mais detalhado do próprio fenômeno.” (BAS-
SANEZI, 2002) [3]

Como o objetivo didático de nosso experimento era envolver os alunos em algum
processo de ensino e aprendizagem que colaborasse para que os conceitos matemáticos
estudados por eles naquele momento ﬁzessem sentido, não efetuamos uma análise mais
aprofundada das condições de lançamento do foguete, e portanto não estabelecemos
signiﬁcados empíricos para os parâmetros da função encontrada no ajuste.

Todavia, essa especiﬁcidade da modelagem não implicou em prejuízo para o en-
tendimento da concepção matemática da expressão que apresentamos como modelo,
nem tão pouco na relação que tentamos estabelecer entre as variáveis observadas no
experimento.

Os alunos manifestaram interesse em saber como o Excel formulou a expressão
y = 0, 829x − 5, 760. Explicamos a eles que tal expressão era resultado de cálculos
realizados de acordo com método dos mínimos quadrados elaborado pelo matemático
Carl Friedrich Gauss. Esse método consistia em estimar os parâmetros de uma função
ajustada aos pontos experimentais de modo que os erros de aproximação do ajuste
fossem os menores possíveis.

Justiﬁcamos aos alunos que era necessário conhecimentos avançados para entender
a parte inicial do processo de cálculo do método dos mínimos quadrados, mas como
já haviam estudado, no 8º ano, resolução de sistemas de duas equações do 1º grau
com duas incógnitas, poderíamos apresentar a eles o sistema resultante dos cálculos e
a partir dele mostrar a determinação dos parâmetros da função de ajuste.

Inicialmente, explicamos o conceito de somatório e sua notação, em seguida apre-

sentamos o sistema na sua forma geral:

22
[
∑
i=1

2
(xi)

22
∑
i=1

] ⋅ a + [

(xi)] ⋅ b = [

(xi) ⋅ (yi)]

22
∑
i=1

22
[
∑
i=1

(xi)] ⋅ a + 22 ⋅ b =

22
[
∑
i=1

(yi)]

Apresentamos o sistema dessa forma, pois não consideramos as incertezas nas ex-

plicações que ﬁzemos para os alunos.

Relato do experimento

99

Solicitamos então, que construíssem a seguinte tabela:

Tabela 4.2: Tabela de somatório dos dados do experimento

(i)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22

22
∑
i=1

(xi)
98
43
160
22
34
73
31
67
80
29
107
89
140
112
19
36
42
56
115
49
125
33

(yi)
68,32
29,91
119,42
13,95
20,76
64,38
17,46
44,25
56,98
16,45
75,2
69,21
109,68
92,64
13,9
20,26
29,21
48,23
97,1
30,12
108,16
22,13

(xi)2
9604
1849
25600
484
1156
5329
961
4489
6400
841
11449
7921
19600
12544
361
1296
1764
3136
13225
2401
15625
1089

(xi) ⋅ (yi)
6695,36
1286,13
19107,2
306,9
705,84
4699,74
541,26
2964,75
4558,4
477,05
8046,4
6159,69
15355,2
10375,68
264,1
729,36
1226,82
2700,88
11166,5
1475,88
13520
730,29

1560,00 1167,72 147124,00 113093,43

Fonte: Tabela gerada pelo autor

Em seguida, pedimos que substituíssem os resultados de somatório da tabela 4.2 no
sistema geral apresentado para que pudessem reescrevê-lo com os dados do experimento.
E assim, obtiveram o seguinte sistema:

147124 ⋅ a + 1560 ⋅ b = 113093, 43
1560 ⋅ a + 22 ⋅ b = 1167, 72

Relembramos a eles, numa breve exposição, dois métodos de resolução de sistemas
de duas equações do 1º grau com duas incógnitas, denominados método da substituição
e método da adição. Solicitamos então, que escolhessem um dos métodos para que

Relato do experimento

100

trabalhassem de maneira homogênea, elegeram o método da substituição e efetuaram
seus cálculos. Organizamos os resultados apresentados da seguinte maneira:

Tomando a equação

Isolando a em (4.1), obtemos

Substituindo (4.2) na equação

1560 ⋅ a + 22 ⋅ b = 1167, 72.

a =

1167, 72 − 22 ⋅ b
1560

.

obtemos

Que resulta em

147124 ⋅ a + 1560 ⋅ b = 113093, 43

147124 ⋅

1167, 72 − 22 ⋅ b
1560

+ 1560 ⋅ b = 113093, 43.

b =

−2965, 457
514, 826 = −5, 760.

Substituindo (4.4) em (4.2) obtemos

a =

1167, 72 − 22 ⋅ (−5, 760)
1560

= 0, 829.

(4.1)

(4.2)

(4.3)

(4.4)

(4.5)

Diante dos resultados (4.4) e (4.5), esclarecemos aos alunos que como tínhamos

estabelecido que a função de ajuste dos pontos experimentais era do tipo

f (x) = ax + b,

onde f (x) = y representava a relação funcional entre as variáveis x e y de nosso expe-
rimento, poderíamos concluir que a função procurada era

f (x) = 0, 829x − 5, 760,

e esta conﬁrmava o modelo sugerido pelo Execel.

Isto posto, encerramos o experimento solicitando aos alunos que realizassem duas

atividades:

i. Construir, usando a planilha Excel, uma tabela contendo número de bombeadas,
valores coletados do desempenho do foguete, valores dados pela simulação de
desempenho do modelo e erro absoluto associado. Fazer uma breve explicação
dos resultados apresentados na tabela;

ii. Dada a função f ∶ R → R tal que f (x) = 0, 829x − 5, 760, responder e fazer o que

se pede:

Ajuste de curva

101

1-) Qual é a raiz dessa função? Qual é o seu signiﬁcado geométrico?

2-) Construir o gráﬁco de f ;

3-) Fazer o estudo de sinal da função f .

A atividade (i) tinha por objetivo propiciar aos alunos a possibilidade de inferência
da idéia de aproximação e variação, e, a atividade (ii) o de favorecer a análise da
função f (x) = 0, 829 ⋅ x − 5, 76 de acordo com os conteúdos estudados em sala de aula.

4.3 Ajuste de curva

Do que foi relatado na seção 4.2, vimos que o comportamento dos pontos experi-
mentais indicava uma relação linear entre as variáveis designadas por x e y. Em vista
disto e dadas as restrições do nível de escolaridade dos alunos, ﬁzemos o ajuste de reta
apresentando a eles apenas uma síntese dos cálculos exigidos pelo método dos míni-
mos quadrados. Assim sendo, queremos nessa seção realizar o ajuste efetivo dos dados
obtidos no experimento.

De acordo com a discussão feita no capítulo 3, encontrar a melhor reta que descreve

o comportamento dos pontos experimentais implica em ajustar a função

g(xi; a, b) = ax + b.

Para tanto, devemos determinar os valores dos parâmetros a e b de tal forma que
minimizem os erros de aproximação dados por:

E(a, b) =

n
∑
i=1

g(xi; a, b) − yi)
σi

[

2

]

=

n
∑
i=1

(axi + b) − yi)
σi

[

2
]

.

Conforme o que foi visto em (3.5) tais valores devem satisfazer, necessariamente,

às condições:

n
∑
i=1

∂E
∂a = 0 ⇐⇒
∂E
∂b = 0 ⇐⇒

(xi)

2a +

n
∑
i=1

xib =

n
∑
i=1

yixi

n
∑
i=1

xia + nb =

n
∑
i=1

yi

(4.6)

(4.7)

Reescrevendo as equações (4.6) e (4.7) em notação matricial, ou seja na forma

AX = B, onde

A =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1

2
(xi)

n
∑
i=1

xi

n
∑
i=1

xi

n

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

, B =

n
∑
i=1

yixi

n
∑
i=1

yi

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

e X =

a
b

⎡
⎢
⎢
⎢
⎢
⎣

,

⎤
⎥
⎥
⎥
⎥
⎦

Ajuste de curva

102

temos que a solução geral para ajuste da função é dada por X = A−1B, ou seja:

a
b

⎡
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎦

=

1

⎡
⎢
⎢
n ⋅
⎢
⎢
⎣

n
∑
i=1

(xi)

2

− (

n
∑
i=1

xi)

2⎤
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n

−

n
∑
i=1

xi

−

n
∑
i=1

xi

n
∑
i=1

(xi)

2

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

n
∑
i=1

yixi

n
∑
i=1

yi

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

.(4.8)

Assim, tomando os valores da tabela 4.1 e calculando os somatórios descritos na

solução geral (4.8), obtemos os resultados listados na tabela 4.3:

Tabela 4.3: Tabela resumida de somatório dos dados do experimento

2

n
∑
i=1

(xi)
147124,00

xi

n
∑
i=1
1560,00

yi

n
∑
i=1
1167,72

n
∑
i=1

yixi

113093,43

n

22

Fonte: Tabela gerada pelo autor

Substituindo os valores da tabela 4.3 na equação (4.8), obtemos

a
b

⎡
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎦

=

1
[22 ⋅ 147124 − (1560)2]

⋅

⎡
⎢
⎢
⎢
⎢
⎣

22

−1560
−1560 147124

⎤
⎥
⎥
⎥
⎥
⎦

⋅

⎡
⎢
⎢
⎢
⎢
⎣

113093, 43
1167, 72

.

⎤
⎥
⎥
⎥
⎥
⎦

O que resulta em

a = 0, 829771
b = −5, 760120

Stevenson [17] aﬁrma que ao tomarmos um número n de observações para determi-
narmos a função g(x), este número é relativamente pequeno diante de uma população
inﬁnita de pares de valores possíveis. Assim, g(x) é uma estimativa da real relação,
porém desconhecida, que existe entre as variáveis observadas. Consequentemente, os
parâmetros a e b de g(x) também são estimativas dos reais parâmetros populacionais
correspondentes.

Em vista disto, precisamos estimar as incertezas e estabelecer os intervalos de con-
ﬁança para os verdadeiros valores dos parâmetros a e b de g(x). Então, considerando
a função g(x), a média y dos n pontos experimentais, os valores descritos na tabela 4.1
e calculando alguns somatórios, obtemos a seguinte tabela:

Ajuste de curva

103

Tabela 4.4: Tabela de alguns somatórios dos dados do experimento, dos desvios em
relação a função e à média, do número de observações e do número de parâmetros da
função ajustada

n
∑
i=1

2
(xi)
147124,00

2
xi)

n
∑
i=1

(

2433600,00

n
∑
i=1

2
[g(xi) − yi]
622,453593

n
∑
i=1

2
[y − yi]
25757,431527

n

22

p

2

Fonte: Tabela gerada pelo autor

Tomando os valores da tabela 4.4 e substituindo em (3.13) e (3.14), obtemos as

incertezas em a e b:

σa = (

622, 453593
22 − 2

1
2

)

⋅ (

22
22 ⋅ 147124 − 2433600)

1
2

= 0, 029198

e

σb = (

622, 453593
22 − 2

1
2

)

⋅ (

147124
22 ⋅ 147124 − 2433600)

1
2

= 2, 387744.

Queremos estabelecer um intervalo de conﬁança de 95% para os verdadeiros valores
dos parâmetros a e b. Como o número de observações é pequeno, n = 22 < 30, de (3.2)
vamos tomar

Então, consultando a tabela de probabilidades para distribuição t [17] e calculando
t (1−α)
2

, com α = 0, 95 e (n − p) = 20 graus de liberdade, temos que

t (1−α)
2

σm.

(4.9)

t (1−0,95)
2

= t0,025 = 2, 086.

Substituindo σm por σa e σb e aplicando em (4.9), obtemos respectivamente:

t0,025 ⋅ σa = 2, 086 ⋅ 0, 029198 = 0, 060907028

e

t0,025 ⋅ σb = 2, 086 ⋅ 2, 387744 = 4, 980833984.

Assim, temos que o intervalo de conﬁança de 95% para os verdadeiros valores dos

parâmetros a e b são:

a ± 0, 060907028 ou 0, 768863972 < a < 0, 890678028

e

b ± 4, 980833984 ou − 10, 74095398 < b < −0, 779286016.

Tomando os valores da tabela 4.4 e aplicando em (3.15), obtemos o coeﬁciente de

correlação

√

r =

1 −

622, 453593
25757, 431527 = 0, 987843.

Ajuste de curva

104

O sinal e o valor de r sugerem que as variáveis x e y tem um relacionamento
positivo e forte, ou seja, a medida que cresce os valores da variável x também cresce
os valores da variável y, bem como, a dispersão entre os pontos experimentais e a
função ajustada é pequena. Por outro lado, temos que o coeﬁciente de determinação
r2 = 0, 975834 nos indica que aproximadamente 97, 5834% da variação dos valores de
y podem ser explicados pela variação dos valores de x, e isso signiﬁca que a função
ajustada é melhor preditor que a média.

Portanto, de acordo com o método dos mínimos quadrados, a função

g(x) = 0, 829771x − 5, 760120,

com

a = (0, 8298 ± 0, 061)

e

b = (−5, 7601 ± 4, 981)

é a que melhor se ajusta aos dados experimentais.

5 Considerações ﬁnais

De acordo com as orientações descritas nos Parâmetros Curriculares Nacionais –
PCNs, que enfatiza a resolução de problemas, a compreensão e aplicação de conceitos
matemáticos como elementos norteadores da prática pedagógica, realizamos junto aos
alunos do ensino fundamental de uma escola pública, a modelagem matemática de um
experimento, onde tivemos a oportunidade de implementar uma abordagem de ensino
que nos permitiu contextualizar os conteúdos curriculares que estávamos ministrando.
A modelagem do experimento enquanto prática pedagógica, objetivava a determi-
nação de um modelo (oriundo do ajuste de função aos dados observados) para que os
alunos pudessem perceber, a partir de uma situação vivenciada na prática, as aplicações
dos conceitos matemáticos estudados em sala de aula.

Nesse sentido, uma discussão mais aprofundada com os alunos, sobre o método
usado e as condições gerais de ajuste, não faziam parte do contexto pedagógico no
qual construímos essa prática de ensino, sobretudo por conta do nível educacional dos
alunos (9º ano do ensino fundamental).

A partir desse experimento, no entanto, pudemos efetuar um estudo do método
dos mínimos quadrados fundamentado em resultados matemáticos que nos permitiu
ampliar nosso entendimento acerca das concepções e aplicabilidade do método.

Assim, da vivência que tivemos na aplicação do experimento e do estudo que rea-
lizamos, concluímos que é viável extrapolar essa prática para alunos do ensino médio,
de modo a explorar a aplicabilidade de conceitos tais como: funções, operações com
matrizes, resolução de sistemas lineares, entre outros que possam ser enquadrados em
situações-problema que atendam as restrições do experimento e do processo de cálculo
do método.

105

Referências

[1] AMORIM, Ronan Gomes de. Introdução à Análise Convexa - Conjuntos e Funções
Convexas. Dissertação de Mestrado. Goiânia/GO: PROFMAT - UFG, 2013.

[2] ASANO, Claudio Hirofume. COLLI, Eduardo. Cálculo numérico - Fundamentos

e Aplicações. São Paulo: Edusp, 2009.

[3] BASSANEZI, Rodney Carlos.Ensino-aprendizagem com modelagem matemática:

uma nova estratégia. São Paulo: Contexto, 2002.

[4] BORTOLOSSI, Humberto José. Cálculo Diferencial a Várias Variáveis- Uma
introdução à Teoria de Otimização, Rio de Janeiro: Ed. PUC-Rio; São Paulo:
Loyola, 2002.

[5] CAROLI, Alésio de. [et al.]. Matrizes, Vetores, Geometria analítica: teoria e exer-

cícios. 17ª ed. São Paulo: Nobel, 1989.

[6] COSTA, Matheus Moreira. O ensino das funções exponenciais: uma proposta por
meio de contextualização, modelagem matemática e recursos tecnológicos. Disser-
tação de Mestrado. Rio Claro/SP: PROFMAT - UNESP, 2016.

[7] CRATO, N. O papel dos mínimos quadrados na descoberta dos planetas.

Disponível em: https://pascal.iseg.utl.pt/ncrato/papers/
MinQdSPM.pdf.27.01.2014.

[8] GUELLI, Cid. Augusto [et.al.].Álgebra II: análise combinatória, probabilidade, ma-
trizes, determinantes, sistemas lineares. Matemática moderna. São Paulo: mo-
derna, vol. 6, 197-?.

[9] GUIDORIZZI, Hamilton Luiz. Um curso de cálculo, 5ª ed. Rio de Janeiro: LTC,

vol. 2, 2002.

[10] HLENKA, Vanessa. Principais propriedades de funções convexas. Monograﬁa. Cu-

ritiba: UFPR, 2006.

[11] IEZZI, Gelson. [et.al.]. Matemática 2º grau, 2ª série: versão azul. São Paulo:

Atual, 1993.

106

Referências

107

[12] LEITHOLD, Louis. O cálculo com Geometria Analítica. Tradução: PATARRA,

Cyro de Carvalho. 3ª ed. São Paulo: Editora Harbra, vol. 2, 1994.

[13] LIMA, Paulo Cupertino de. Cálculo de Várias Variáveis. Belo Horizonte: Editora

UFMG, 2009.

[14] MALTA, Iaci. [et al.]. Cálculo a uma variável. São Paulo: loyola, 2002.

[15] RUGGIERO, Marcia A. Gomes. LOPES, Vera Lúcia da Rocha. Cálculo Numérico
- Aspectos Computacionais, 2ª ed. São Paulo: Person Makron Books, 1996.

[16] SÁ, Fernanda Lúcia. Estudo dos determinantes. Caderno DÁ Licença. Rio de Ja-

neiro, v.5, Ano 6, p. 70-84, Dez. 2004.

[17] STEVENSON, Willian J. Estatística aplicada à administração. Tradução: FARIA,

Alfredo Alves. São Paulo:Harper Row do Brasil, 1981.

[18] VUOLO, José Henrique. Fundamentos da Teoria de Erros, São Paulo: Editora

Edgard Blücher Ltda, 2002.


Universidade Federal De Mato Grosso
Instituto De Ciˆencias Exatas e Da Terra
Departamento de Matem´atica

Probabilidade e simula¸c˜oes em
planilhas eletrˆonicas

Edinei Jesus Teixeira de Paula

Mestrado Proﬁssional em Matem´atica: PROFMAT/SBM

Orientador: Prof. Dr. Moiseis dos Santos Cecconello

Trabalho ﬁnanciado pela Capes

Cuiab´a - MT

Mar¸co de 2013

Probabilidade e simula¸c˜oes em
planilhas eletrˆonicas

Este exemplar corresponde `a reda¸c˜ao ﬁnal da dis-
serta¸c˜ao devidamente corrigida e defendida por
Edinei Jesus Teixeira de Paula e aprovada pela co-
miss˜ao julgadora.

Cuiab´a, 16 de mar¸co de 2013.

Prof. Dr. Moiseis dos Santos Cecconello
Orientador

Banca examinadora:

Dr.

Moiseis dos Santos Cecconello

Prof.
(UFMT)
Profa. Dra. Vera L´ucia Martins Sandanielo
(UFMT)
Prof. Dr. Jeﬀerson Cruz dos Santos Leite (UFPI)

Disserta¸c˜ao apresentada ao curso de Mestrado
Proﬁssional em Matem´atica - PROFMAT da Uni-
versidade Federal de Mato Grosso, como requisito
parcial para obten¸c˜ao do t´ıtulo de Mestre em
Matem´atica.

Disserta¸c˜ao de Mestrado defendida em 16 de mar¸co de 2013 e aprovada pela

banca examinadora composta pelos Professores Doutores

Prof. Dr. Moiseis dos Santos Cecconello

Profa. Dra. Vera L´ucia Martins Sandanielo

Prof. Dr. Jeﬀerson Cruz dos Santos Leite

A minha esposa Anaiara, pelo amor, e

compreens˜ao durante toda a realiza¸c˜ao

deste trabalho, a minha irm˜a Edin´eia

pelo companheirismo e as duas pessoas

a quem devo minha vida e todas as
minhas realiza¸c˜oes, meus pais ´Edio e

Izaura.

Agradecimentos

`A Deus pela vida e por ter me dado sabedoria para a realiza¸c˜ao deste trabalho.
´A meu orientador, professor Doutor Dr. Moiseis dos Santos Cecconello, pela paciˆencia,

dedica¸c˜ao, apoio e competˆencia. Sua contribui¸c˜ao foi essencial para a realiza¸c˜ao deste

trabalho.
`A todos os professores e tutoras do Mestrado Proﬁssional em Matem´atica da UFMT, que

com seus ensinamentos deram contribui¸c˜oes signiﬁcativa para a minha forma¸c˜ao.
`A meus pais, ´Edio e Izaura, que me ensinaram a viver com dignidade, que iluminaram os

meus caminhos com afeto e dedica¸c˜ao, e que s˜ao a minha maior inspira¸c˜ao matem´atica.

Ao minha esposa Anaiara pelo amor, carinho e paciˆencia durantes estes dois anos.

Ao minha irm˜a Edin´eia pelo incentivo, apoio e companheirismo em todos os momentos.

A todos colegas de mestrado, por dividir conosco todas as ang´ustias e alegrias nestes dois

anos.

Aos funcion´ario da escola 13 de Maio.
`A minha amiga e colega de trabalho professora Inˆes Nardeli e fam´ılia pelo apoio.

Muito obrigado a todos.

Resumo

O objetivo deste trabalho ´e apresentar uma metodologia diferenciada no ensino

de probabilidade, explorando ideias intuitivas de probabilidade aliada a ferramentas com-

putacionais que possibilite usar planilhas eletrˆonicas no ensino da probabilidade no ensino

m´edio. Mostrar como estas ideias e ferramentas podem contribuir para obter solu¸c˜oes de

problemas como: estimar a frequˆencia de caras no lan¸camento de uma moeda, o valor es-

perado em um determinado jogo ou aposta, a ´area de ﬁguras planas, o volume de s´olidos,

a chance de um time ser campe˜ao em um torneio. Para isso, faremos varias simula¸c˜oes de

experimentos aleat´orios e analisaremos como ele se comporta depois de varias repeti¸c˜oes.

Com o intuito de facilitar o trabalho faremos uso de planilhas eletrˆonicas, com as quais se

consegue realizar um grande n´umero de simula¸c˜oes em pouco tempo. Feito desta forma

acreditamos que o ensino da probabilidade seja mais interessante e moderno.

Palavras chave: Probabilidade; Planilhas eletrˆonicas; Ensino de Matem´atica.

Abstract

The objective of this work is to present a diﬀerent methodology in the teaching

of probability, exploring intuitive ideas of probability combined with computational tools

that enable use spreadsheets in the teaching of probability in high school. Show how these

tools can contribute ideas and solutions for problems such as estimating the frequency

of heads in a coin toss, the expected value in a certain game or bet, the area of plane

ﬁgures, volumes of solids, the chance of be a team champion in a tournament. To do

so, we simulated several random experiments and analyze how it behaves after several

repetitions. In order to facilitate the work we will make use of spreadsheets, with which

it can perform a large number of simulations in a short time. This way, we believe that

the teaching of probability is more interesting and modern.

Keywords: Probability; Spreadsheets; Mathematics Teaching.

Sum´ario

Introdu¸c˜ao

1 Probabilidade

12

14

1.1 Teoria da Probabilidade

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

1.1.1 Espa¸co Amostral

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

1.1.2 Evento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

1.1.3 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

1.2 Probabilidade condicional

. . . . . . . . . . . . . . . . . . . . . . . . . . . 31

1.3 Vari´avel aleat´oria, valor esperado e variˆancia . . . . . . . . . . . . . . . . . 36

1.3.1 Algumas vari´aveis aleat´orias especiais.
. . . . . . . . . . . . . . . . 40
´Area e probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

1.4

2 Lei dos Grandes N´umeros e simula¸c˜oes

45

2.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

2.2 Moedas e frequˆencias relativas . . . . . . . . . . . . . . . . . . . . . . . . . 46

2.2.1

Simula¸c˜ao do lan¸camento de moedas

. . . . . . . . . . . . . . . . . 46

2.3 A Lei dos Grandes N´umeros . . . . . . . . . . . . . . . . . . . . . . . . . . 50

3 Simula¸c˜ao em planilhas eletrˆonicas

54

3.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

3.2 Lan¸camento de dados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

3.3 Simula¸c˜ao de provas

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

3.4 Valor esperado de uma vari´avel aleat´oria . . . . . . . . . . . . . . . . . . . 58
´Areas e volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

3.5

3.5.1 Volume de s´olidos . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

3.6 Probabilidade em jogos de futebol . . . . . . . . . . . . . . . . . . . . . . . 72

8

Referˆencias Bibliogr´aﬁcas

76

9

Lista de Figuras

1.1

´Arvore de possibilidades para o problema.

. . . . . . . . . . . . . . . . . . 30

1.2 Diagrama de Venn para os eventos A e B.

. . . . . . . . . . . . . . . . . . 32

2.1 Simula¸c˜oes do lan¸camento de 10 moedas. . . . . . . . . . . . . . . . . . . . 48

2.2 Simula¸c˜oes do lan¸camento de 500 moedas.

. . . . . . . . . . . . . . . . . . 48

2.3 Simula¸c˜oes do lan¸camento de 1000 moedas. . . . . . . . . . . . . . . . . . . 48

2.4 Histograma para 700 simula¸c˜oes de M100.

. . . . . . . . . . . . . . . . . . 49

2.5 Histograma para 700 simula¸c˜oes de M10000. . . . . . . . . . . . . . . . . . . 50

3.1 Simula¸c˜oes na realiza¸c˜ao de 800 realiza¸c˜oes da vari´avel Xi.

. . . . . . . . . 55

3.2 Histograma para 500 simula¸c˜oes da vari´avel aleat´oria M20000. . . . . . . . . 55

3.3 Distribui¸c˜ao de probabilidade da vari´avel S.

. . . . . . . . . . . . . . . . . 57

3.4 Simula¸c˜oes de E(Xn). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

3.5 Simula¸c˜oes de E(Xn). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

3.6 Histograma de E(Xn) para 200 simula¸c˜oes com n = 5000. . . . . . . . . . . 61

3.7 Representa¸c˜ao gr´aﬁca do espa¸co amostral R e do evento F . . . . . . . . . . 62

3.8 Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

. . . . . . . . . . . . . . . . . 63

3.9 Estimativas Mn(F ) para n ≤ 500.

. . . . . . . . . . . . . . . . . . . . . . . 64

3.10 Estimativas Mn(F ) para n ≤ 5000.

. . . . . . . . . . . . . . . . . . . . . . 64

3.11 Histograma de observa¸c˜ao da vari´avel Mn(F ).

. . . . . . . . . . . . . . . . 64

3.12 Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

. . . . . . . . . . . . . . . . . 65

3.13 Estimativas Mn(F ) para n ≤ 5000.

. . . . . . . . . . . . . . . . . . . . . . 66

3.14 Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

. . . . . . . . . . . . . . . . . 67

3.15 Estimativas Mn(F ) para n ≤ 5000.

. . . . . . . . . . . . . . . . . . . . . . 68

3.16 Histograma de observa¸c˜ao da vari´avel Mn(F ).

. . . . . . . . . . . . . . . . 68

3.17 Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

. . . . . . . . . . . . . . . . . 69

10

3.18 Estimativas Mn(F ) para n ≤ 10000. . . . . . . . . . . . . . . . . . . . . . . 70

3.19 Estimativas Mn(F ) para n ≤ 10000. . . . . . . . . . . . . . . . . . . . . . . 71

3.20 Estimativas Mn(F ) para n ≤ 10000. . . . . . . . . . . . . . . . . . . . . . . 72

3.21 Simula¸c˜ao da frequˆencia relativa para 5000 repeti¸c˜oes. . . . . . . . . . . . . 74

11

Introdu¸c˜ao

Embora conste como um dos temas a ser abordado pelos Parˆametros Curriculares

Nacionais, o ensino de probabilidade nas escolas de ensino b´asico ´e frequentemente negli-

genciado ou, na melhor das hip´oteses, abordado de forma bem superﬁcial, sem levar em

conta as solu¸c˜oes que esta valiosa teoria tem para contribuir em situa¸c˜oes do cotidiano.

Como argumento a favor do que acabou de ser dito, podemos veriﬁcar a grande maioria

dos livros did´aticos adotados em nossas escolas. A maioria dos exemplos e atividades

propostas em tais referˆencias est˜ao relacionados com lan¸camentos de moedas, dados ou

cartas de baralho e similares.

Podemos levantar diversas hip´oteses de quais motivos levam ao negligenciamento

no ensino de probabilidade das escolas. Um destes tais motivos, possivelmente, ´e a diﬁcul-

dade inerente ao conte´udo, pois o mesmo exige o conhecimento de problemas envolvendo

contagem al´em da interpreta¸c˜ao agu¸cada para estabelecer os espa¸cos amostrais e eventos

de interesse. Nos parece n˜ao haver d´uvida de que a diﬁculdade inerente ao estudo das

probabilidades aliado os problemas com pouco apelo motivacional proposto nos livros

did´aticos levam alunos e professores a darem pouca importˆancia para esta t˜ao importante

´area da matem´atica presenta na vida de cada indiv´ıduo da sociedade moderna.

Nosso objetivo neste trabalho n˜ao ´e abordar os aspectos educacionais da conte´udo.

N˜ao faremos nenhuma an´alise para determinar os problemas relacionados ao ensino de

probabilidade na educa¸c˜ao b´asica. Temos como principal objetivo nesta disserta¸c˜ao apre-

sentar uma abordagem alternativa ao ensino de probabilidades, explorando ideias intuiti-

vas aliadas as ferramentas computacionais. Pretendemos mostrar como tais ideias podem

contribuir para obtemos solu¸c˜oes de problemas como a estimativa de ´areas de ﬁguras

planas, volumes de s´olidos, estimativas de probabilidade de um determinado equipe ser

campe˜a de um torneio de futebol quando ainda faltam algumas rodadas para o seu ﬁm.

Para atingirmos o objetivo proposto, organizamos este trabalho como segue.

12

No primeiro cap´ıtulo apresentaremos a teoria da probabilidade, suas deﬁni¸c˜oes e

como us´a-la para resolver problemas. Apresentamos ainda os importantes conceitos de

vari´aveis aleat´orias, valor esperado e variˆancia bem como uma deﬁni¸c˜ao axiom´atica de

´area e sua rela¸c˜ao com o conceito de probabilidade.

O segundo cap´ıtulo apresentamos um dos principais resultados recorrentes da

teoria da probabilidades - a Lei dos Grandes N´umeros de Bernoulli - que servir´a como

suporte te´orico para as atividade propostas no trabalho.

O terceiro cap´ıtulo ser´a dedicado aos problemas em que a teoria das probabili-
dades ser´a a ferramenta adotada para a busca da solu¸c˜ao. ´E o principal cap´ıtulo deste

trabalho pois vamos mostrar como solu¸c˜oes de problemas como a estimativa de ´areas

de ﬁguras planas, volumes de s´olidos, estimativas de probabilidades de um determinado

equipe ser campe˜a de um torneio de futebol podem ser obtidas por meio de uma ferra-

menta acess´ıvel a boa parte dos alunos e professores - as planilhas eletrˆonicas.

Esperamos que os colegas professores tenham este trabalho como um material de

apoio e/ou complementar para auxiliar tanto nas aulas em sala, quanto para um aprimo-

ramento pessoal, pois foi constru´ıdo com muita dedica¸c˜ao e buscando meios alternativos

para explicar conte´udos que os abordados pelos livros did´aticos tradicionais.

13

Cap´ıtulo 1

Probabilidade

Muitas decis˜oes que tomamos em nossas vidas dependem de certas perguntas

cujas respostas est˜ao relacionadas com experimentos aleat´orios. Dessa forma, por n˜ao

poderem ser previstas com exatid˜ao o resultado em determinadas situa¸c˜oes, devido a sua

natureza aleat´oria, ´e que s˜ao estudados m´etodos para determinar as quais desses resultados

s˜ao menos ou mais prov´aveis de ocorrerem, isto ´e, as chances de um resultado acorre. O

estudo e desenvolvimento de t´ecnicas matem´aticas para a an´alise de experimentos ou

fenˆomenos aleat´orios ´e o ramo da matem´atica denominado Teoria da Probabilidade.

Neste cap´ıtulo, abordaremos os principais conceitos necess´arios para o compreen-

dimento do que vai ser apresentado nos cap´ıtulos posteriores deste trabalho. Os conceitos

apresentados aqui podem ser encontrados em referencias como [4], [6], [7] e [9].

1.1 Teoria da Probabilidade

Por muitas vezes nos deparamos com situa¸c˜oes em que os resultados de uma

mesma a¸c˜ao podem se apresentar de formas diferentes. Por exemplo, ao lan¸carmos uma

moeda v´arias vezes, sob condi¸c˜oes idˆenticas, percebemos que em alguns desses lan¸camentos

o resultado ser´a cara, e em outros, ser´a coroa, sendo imposs´ıvel fazer uma previs˜ao exata

do pr´oximo resultado. Tais resultados s˜ao ditos aleat´orios.

Diz-se que experimentos aleat´orios s˜ao aqueles que, mesmo quando repetidos

por diversas vezes em condi¸c˜oes idˆenticas produzem resultados diferentes, ou seja, est˜ao

sujeitos `as leis do acaso. Experimentos que repetidos sob as mesmas condi¸c˜oes e que repro-

duzem resultados essencialmente idˆenticos s˜ao chamados de experimentos determin´ısticos

14

([5]).

S˜ao exemplos de experimentos aleat´orios as seguintes situa¸c˜oes:

• Tempo de espera na ﬁla de um banco;

• Hor´ario em que ir´a come¸car a chover;

• O resultado da face voltada para cima no lan¸camento de uma moeda;

• N´umero de ganhadores na Mega Sena;

• Resultado de um jogo de roleta ou dados;

A Teoria da Probabilidade ´e composta por trˆes conceitos fundamentais: espa¸co

amostral, evento e fun¸c˜ao de probabilidade ([8]).

1.1.1 Espa¸co Amostral

Em um fenˆomeno aleat´orio, isto ´e, sujeito `as leis do acaso, o conjunto formado

por todos os resultados poss´ıveis de ocorrer ´e chamado de espa¸co amostral. Denota-se por

Ω o espa¸co amostral e por # (Ω) o n´umero de elementos desse espa¸co amostral.

Vejamos alguns exemplos:

1. Num exame laboratorial para saber se uma pessoa ´e portadora de uma determi-

nada doen¸ca os resultados poss´ıveis s˜ao positivo ou negativos, logo Ω = {positivo,

negativo}, assim # (Ω) = 2;

2. Ao se observar o resultado de um jogo de futebol entre as equipes A e B, temos o

seguinte espa¸co amostral Ω = {vit´oria da equipe A, empate, vit´oria da equipe B},

# (Ω) = 3;

3. No lan¸camento de um dado, os resultados poss´ıveis de serem observados em sua face

voltada para cima s˜ao os n´umeros 1, 2, 3, 4, 5 e 6, logo Ω = {1, 2, 3, 4, 5, 6}, assim,

temos #(Ω) = 6;

4. No lan¸camento de duas moedas, tem-se o seguinte espa¸co amostral Ω = {(k, k) , (k, c) ,

(c, k) , (c, c)}, onde ”k”signiﬁca que a face voltada para cima ´e cara e ”c”signiﬁca

coroa Assim, temos que # (Ω) = 4.

15

5. Resultados poss´ıveis no sorteio da Mega-Sena. Neste caso, o n´umero de elementos

do espa¸co amostral ´e muito grande, por isso descreveremos apenas alguns deles: Ω =

{(1, 2, 3, 4, 5, 6), (1, 2, 3, 4, 5, 7), . . . , (15, 18, 23, 24, 25, 26), . . . , (23, 45, 55, 57, 58, 60),

. . . , (55, 56, 57, 58, 59, 60)}. Usando m´etodos de contagem obtemos facilmente que

# (Ω) = C 6

60 = 50063860;

6. N´umero de resultados poss´ıveis para as oito ´ultimas rodadas do campeonato brasi-

leiro de futebol. Levando-se em conta somente o resultado de cada jogo {vit´oria de

um, de outro, ou empate} em uma rodada s˜ao 310 os cen´arios imagin´aveis, assim

em 8 rodadas temos que # (Ω) = 380;

Tamb´em observamos que h´a experimentos aleat´orios nos quais n˜ao ´e poss´ıvel

contar o n´umero de elementos do seu espa¸co amostral. Seus elementos s˜ao comumente

considerados como intervalos. Segue abaixo alguns exemplos e seus respectivos espa¸cos

amostrais.

1. Medida da altura de uma pessoa, Ω = (0, ∞);

2. Tempo de espera em uma ﬁla, Ω = [0, ∞);

3. Medida da massa de um corpo, Ω = (0, ∞);

4. Distˆancia percorrida por um proj´etil ao ser lan¸cado por uma arma de fogo, Ω =

[0, ∞).

1.1.2 Evento

Qualquer subconjunto do espa¸co amostral ´e denominado evento.

Dentre os eventos a considerar, devemos incluir:

• Evento Certo - ´e aquele que coincide com espa¸co amostral. Assim temos que, no

lan¸camento de um dado numerado de 1 a 6, observar em sua face voltada para cima

um n´umero menor que 7 ´e um evento certo.

• Evento Imposs´ıvel - ´e aquele representado por um conjunto vazio. Assim, no

lan¸camento de um dado numerado de 1 a 6, observar em sua face superior um

n´umero maior que 6 ´e um evento imposs´ıvel.

16

• Evento Elementar - ´e aquele formado por um ´unico elemento do espa¸co amostral.

Designaremos por uma letra mai´uscula do nosso alfabeto os eventos relativos a

cada espa¸co amostral. Vejamos alguns exemplos:

1. No lan¸camento de uma moeda, temos o espa¸co amostral Ω = {k, c}.

Assim, podemos ter:

Evento A: “sair cara”→ A = {k}

Evento B: “sair coroa”→ B = {c}

2. No nascimento de duas crian¸cas, temos que espa¸co amostral ´e:

Ω = {(m, m) , (m, f ) , (f, m) , (f, f )}, onde denotamos “masculino”por m e “femi-

nino”por f .

Assim podemos ter:

• Evento A: “nascer duas crian¸cas do sexo masculino”→ A = {(m, m)};

• Evento B: “nascer pelo menos uma crian¸ca do sexo feminino”→ B = {(m, f ) ,

(f, m) , (f, f )};

• Evento C: “nascer crian¸cas do mesmo sexo”→ C = {(m, m) , (f, f )};

3. Ao medir a altura exata de uma pessoa, temos, entre outros, os eventos:

• Evento A :

• Evento B :

(cid:20)1
2
(cid:20)1
3

,

,

(cid:104)

(cid:104)

3
2

9
4

metros;

metros;

• Evento C : [1, 2 [ metros.

4. Ao medir o tempo exato de espera em uma ﬁla, temos, entre outros, os eventos.

• Evento A :

(cid:20)1
2

(cid:104)

, 1

horas;

• Evento B : [2, 3 [ horas.

17

1.1.3 Probabilidade

O terceiro conceito fundamental no estudo de experimentos aleat´orios ´e o de

probabilidade, isto ´e, a medida da chance de um determinado evento ocorrer. Ao longo

da hist´oria, o conceito de probabilidade sofreu modiﬁca¸c˜oes, do ponto de vista de sua

deﬁni¸c˜ao formal, com o objetivo de tornar a teoria da probabilidade mais precisa e mais

abrangente poss´ıvel.

Aqui, vamos apresentar as trˆes formas em que podemos medir a chance, ou atri-

buir probabilidade, de um determinado evento ocorrer.

1.1.3.1 Deﬁni¸c˜ao Cl´assica de Probabilidade ou Probabilidade de Laplace

Vamos considerar aqui que o espa¸co amostral seja ﬁnito, isto ´e, Ω = {r1, r2, r3, r4,

...,rn} em que ri, para i = {1, 2, 3, ..., n}, representa os poss´ıveis resultados de um expe-

rimento aleat´orio. Al´em disso, admite-se que temos uma boa raz˜ao para considerarmos

que todos os resultados sejam igualmente poss´ıveis de acontecer, ou seja, todos os eventos

tem a mesma chance de ocorrer. Neste caso, a probabilidade de um evento A ocorrer ´e

deﬁnido pela express˜ao:

no qual # (A) ´e o n´umero de elementos que comp˜oem o evento A.

p (A) =

# (A)
# (Ω)

A deﬁni¸c˜ao cl´assica de probabilidade se refere a subconjuntos unit´arios equi-

prov´aveis. Laplace referia-se aos elementos de A (ou elementos que comp˜oem A) como

casos favor´aveis e os elementos do espa¸co amostral eram chamados casos poss´ıveis ([2]).

Dessa forma, deﬁne-se:

p (A) =

n´umero de casos favor´aveis
n´umero de casos poss´ıveis

Como o evento A ´e um subconjunto de Ω, ent˜ao segue diretamente da deﬁni¸c˜ao

que:

1. 0 ≤ p (A) ≤ 1, para todo evento A , ou seja, a probabilidade de um evento A pode

assumir valores que pertencem ao intervalo [0, 1];

18

2. p (Ω) = 1, ou seja, a probabilidade do evento certo Ω, ´e igual a 1;

3. p (A ∪ B) = p (A)+p (B), ou seja, a probabilidade da uni˜ao de dois eventos ´e a soma

das probabilidades desses eventos, quando esses s˜ao eventos mutuamente exclusivos.

Muitos problemas simples, e at´e mesmo alguns mais elaborados, podem ser resol-

vidos por meio deste conceito cl´assico de probabilidade. Em geral o n´umero de elementos

do espa¸co amostral desses problemas s˜ao determinados por meio de t´ecnicas de contagem.

Vejamos alguns exemplos

Exemplo: Suponha que desejamos determinar a probabilidade de se obter um n´umero par

no lan¸camento de um dado. Vamos admitir previamente que os eventos s˜ao equiprov´aveis,

ou seja, todas as faces tˆem a mesma probabilidade de acontecer. Assim o espa¸co amostral

´e o conjunto Ω = {1, 2, 3, 4, 5, 6} ⇒ # (Ω) = 6 e o evento desejado ´e o conjunto A =

{2, 4, 6} ⇒ # (A) = 3 Pela deﬁni¸c˜ao cl´assica de probabilidade, temos:

p (A) =

# (A)
# (Ω)

⇒ p (A) =

3
6

=

1
2

Exemplo Em uma sala h´a 20 alunos, dos quais dois s˜ao irm˜aos gˆemeos. Se quatro alunos

ser˜ao escolhidos ao acaso para apresentarem um trabalho, qual a probabilidade de os

dois irm˜aos gˆemeos estarem entre os escolhidos? Seja Ω o espa¸co amostral e A o evento

“escolher os quatro alunos de modo que os gˆemeos fa¸cam parte desta escolha”, teremos:

• Para os casos poss´ıveis temos: os C 4

20 modos de escolher 4 alunos entre os 20, ou

seja, # (Ω) = C 4

20;

• Para os casos favor´aveis temos: C 2

18 modos de escolher 2 alunos entre os 18 restantes,

uma vez que os gˆemeos j´a fazem parte dos escolhidos, assim temos que # (A) = C 2

18.

Assim a probabilidade procurada ´e:

p (A) =

C 2
18
C 4
20

=

3
95

Algumas cr´ıticas podem ser feitas `a deﬁni¸c˜ao cl´assica de probabilidade:

• Considera-se na deﬁni¸c˜ao apenas os casos em que o espa¸co amostral possui um

n´umero ﬁnito de elementos;

19

• Admiti-se tamb´em, como hip´otese, que os eventos unit´arios do espa¸co amostral

sejam igualmente prov´aveis de ocorrer. Mas a ideia de igualmente prov´avel ´e equi-

valente a dizer com probabilidade igual, de modo que estamos usando o conceito de

probabilidade em sua pr´opria deﬁni¸c˜ao;

• A boa raz˜ao para admitir resultados igualmente prov´aveis esta, em geral, relacionada

com algum problema em que desejamos resolver por meio do estudo de probabili-

dade.

1.1.3.2 Deﬁni¸c˜ao frequentista

Na pr´atica nem sempre ´e poss´ıvel determinar a probabilidade de um evento, por

exemplo: Qual seria a probabilidade de um pneu furar nos primeiros mil quilˆometros?

Qual a probabilidade de seu time ser campe˜ao? Qual a probabilidade de uma pessoa

ser atingida por um raio? Estas respostas n˜ao podem ser encontradas pela deﬁni¸c˜ao

cl´assica, tudo o que se pode fazer ´e observar com que frequˆencia esses fatos acontecem,

sob as mesmas condi¸c˜oes te´oricas, com um n´umero suﬁcientemente grande de observa¸c˜oes,

podemos obter uma boa estimativa dessas probabilidades.

Consideremos um experimento aleat´orio e A um evento de um espa¸co amostral

associado ao experimento. Suponha que sob as mesmas condi¸c˜oes te´oricas, sejam realiza-

dos n ensaios independentes do experimento aleat´orio em quest˜ao e seja #A o n´umero de

vezes que o evento ocorre nas n realiza¸c˜oes. A frequˆencia relativa de ocorrˆencia do evento

A ´e deﬁnida por:

f r (A) =

n´umero de vezes que A ocorreu
n

e a probabilidade do evento A ´e deﬁnida como sendo o limite da frequˆencia relativa quando

o n´umero de vezes em que o experimento ´e realizado tende ao inﬁnito, ou seja,

p (A) = lim

n→+∞

f r (A)

Assim como no caso da deﬁni¸c˜ao cl´assica tamb´em temos que:

1. 0 ≤ p (A) ≤ 1, para todo evento A;

2. p (Ω) = 1;

20

3. p (A ∪ B) = p (A)+p (B), quando A∪B = ∅, ou seja, A e B s˜ao eventos mutuamente

exclusivos.

Algumas observa¸c˜oes sobre a deﬁni¸c˜ao frequentista merecem ser destacadas:

• Frequˆencia relativa e probabilidade n˜ao s˜ao sinˆonimos. A frequˆencia relativa de um

evento ´e um valor associado a um fato no passado (o evento foi realizado), enquanto

que probabilidade ´e um valor relativo a um fato no futuro (o evento ainda n˜ao se

realizou).

• Na pr´atica, ´e imposs´ıvel realizar um n´umero inﬁnito de vezes o experimento aleat´orio.

Assim, a probabilidade ´e estimada usando um n´umero suﬁcientemente grande de

realiza¸c˜oes do experimento em an´alise.

• A express˜ao suﬁcientemente grande ´e vaga e n˜ao tem signiﬁcado preciso. Quantas

vezes deve-se repetir o experimento: 500, 1000, 1000000? Essa quantidade de ensaios

´e ﬁxa de experimento para experimento? Al´em disso, n˜ao temos garantia de que a

frequˆencia relativa vai convergir para um n´umero do intervalo [0, 1], que representa

a probabilidade de um determinado evento acontecer.

1.1.3.3 Deﬁni¸c˜ao axiom´atica de probabilidade

As deﬁni¸c˜oes apresentadas anteriormente tˆem o apelo da intui¸c˜ao e permanecem

sendo usadas para resolver in´umeros problemas. Entretanto, elas n˜ao s˜ao suﬁcientes

para uma formula¸c˜ao matem´atica mais rigorosa da probabilidade. Com o intuito de

resolver os problemas apresentados pela deﬁni¸c˜ao cl´assica e frequentista de probabilidade,

o matem´atico russo Andrei Nikolayevich Kolmogorov, por volta de 1930, estabeleceu as

condi¸c˜oes que uma probabilidade deve satisfazer.

Primeiramente, vamos considerar que o conjunto A, formados por eventos A de

um espa¸co amostral Ω satisfa¸ca as seguintes condi¸c˜oes:

C1 - Se A ´e um evento ent˜ao Ac, que ´e o evento complementar de A, tamb´em ser´a um

evento;

C2 - Ω ´e um evento;

C3 - Se A1, A2, A3, . . . s˜ao eventos, ent˜ao

Ai, ∀ i ∈ N, tamb´em ´e um evento.

∞
(cid:91)

i=1

21

Como estas condi¸c˜oes impostas, uma probabilidade ´e uma fun¸c˜ao p : A → R que

deve satisfazer:

Axioma 1: A probabilidade de qualquer evento A ´e um n´umero n˜ao negativo menor ou

igual a 1, ou seja, 0 ≤ p (A) ≤ 1, ∀ A ∈ A

Axioma 2: A probabilidade do evento certo ´e igual a 1, ou seja, p (Ω) = 1

Axioma 3: Se A1, A2, A3, . . . s˜ao eventos disjuntos, ent˜ao a probabilidade da uni˜ao

destes eventos ´e a soma das probabilidades de cada um deles, isto ´e A1, A2, A3, . . .
∈ A e Ai ∩ Aj = ∅, i (cid:54)= j

(cid:33)

Ai

=

(cid:32) ∞
(cid:91)

p

i=j

∞
(cid:88)

i=j

p (Ai)

Algumas propriedades seguem diretamente da deﬁni¸c˜ao de probabilidade

Propriedades. Sejam o conjunto A, formados por eventos A de um espa¸co amostral Ω

e p : A → R uma probabilidade deﬁnida em A. Ent˜ao:

1. A probabilidade de ocorrer o evento ∅ ´e nula, isto ´e, p (∅) = 0;

2. Se A e AC s˜ao eventos complementares ent˜ao: p (cid:0)AC(cid:1) = 1 − p (A);

3. A probabilidade da diferen¸ca entre dois eventos ´e dada por:

p (A − B) = p (A) − p (A ∩ B)

4. A probabilidade de ocorrer a uni˜ao de dois conjuntos ´e dada por:

p (A ∪ B) = p (A) + p (B) − p (A ∩ B) , onde A ∩ B (cid:54)= ∅

22

5. A probabilidade da uni˜ao de trˆes eventos ´e dada por:

p (A ∪ B ∪ C) = p (A) + p (B) + p (C) − p (A ∩ B) − p (A ∩ C) −

−p (B ∩ C) + p (A ∩ B ∩ C)

6. Se um evento A possui menos elementos do que o evento B, ent˜ao, a probabilidade

de ocorrer o evento A ´e no m´aximo igual a probabilidade de ocorrer o evento B, ou

seja, se A ⊂ B ent˜ao p (A) ≤ p (B).

Demonstra¸c˜oes.

1. Seja A ∈ A. Sabemos que A e ∅ s˜ao mutuamente excludente, isto ´e, A ∩ ∅ = ∅.

Assim temos, pelo terceiro axioma de probabilidade, temos:

p (A) = p (A ∪ ∅) = p (A) + p(∅),

de modo que

p (∅) = p (A) − p (A) = 0

2. Temos que A ∩ AC = ∅ e A ∪ AC = Ω. Dos axiomas 2 e 3 temos que:

p (A) + p (cid:0)AC(cid:1) = p (cid:0)A ∪ AC(cid:1) = p (Ω) = 1,

e assim

p (cid:0)AC(cid:1) = 1 − p (A) .

3. Seja B ⊆ A. Temos que p (A) = p [(A − B) ∪ (A ∩ B)] = p (A − B) + p (A ∩ B),

pois (A − B) ∩ (A ∩ B) = ∅. Da´ı conclu´ımos que

p (A − B) = p (A) − p (A ∩ B) .

4. Como A ∪ B = (A − B) ∪ B ent˜ao p (A ∪ B) = p (A − B) + p (B) uma vez que

23

(A − B) ∩ B = ∅. Usando o item anterior, temos

p (A ∪ B) = p (A) + p (B) − p (A ∩ B)

no qual A ∩ B (cid:54)= ∅.

5. Para a demonstra¸c˜ao desta propriedade basta considerar B ∪ C = D e aplica a

propriedade anterior duas vezes.

6. Seja A ⊂ B de modo que B∩A = A. Usando a propriedade 3, temos que p (B − A) =

p (B) − p (B ∩ A) do qual segue que

p (B − A) = p (B) − p (A) .

Como p (B − A) ≥ 0, temos que p (A) ≤ p (B).

1.1.3.4 Probabilidade em espa¸cos amostrais ﬁnitos

Seja Ω = {a1, a2, a3, ..., ar} o espa¸co amostral ﬁnito de um experimento aleat´orio.

Considerando o evento elementar {ai}, para i ∈ {1, 2, 3, ..., r}, de acordo com a deﬁni¸c˜ao

axiom´atica, devemos associar a cada um desses eventos um n´umero real p (ai), ou sim-

plesmente pi, que satisfaz as seguintes propriedades:

• 0 ≤ pi ≤ 1, para i ∈ {1, 2, 3, ..., r};

•

r
(cid:88)

i=1

pi = 1, isto ´e, p1 + p2 + p3 + p4 + ... + pr = 1

Como exemplo, considere o experimento que consiste em lan¸car um dado e veri-

ﬁcar sua face. Neste caso, temos Ω = {1, 2, 3, 4, 5, 6}. Assim, uma das distribui¸c˜oes de

probabilidade para os eventos elementares do nosso espa¸co amostral ´e:

xi

p (xi)

1

1
6

2

1
10

3

1
3

4

1
4

5

1
12

6

1
15

Observe que, com esta escolha, todos os axiomas de probabilidade s˜ao satisfeitos,

uma vez que:

24

• p (1) + p (2) + p (3) + p (4) + p (5) + p (6) = 1;

• 0 ≤ p (1) , p (2) , p (3) , p (4) , p (5) , p (6) ≤ 1;

• p (Ω) = 1

No entanto, esta distribui¸c˜ao, n˜ao ´e apropriada do ponto vista pr´atico, pois, n˜ao

temos nenhum argumento satisfat´orio para associarmos probabilidades diferentes para os

poss´ıveis resultados do deste experimento. Neste caso, podemos atribuir probabilidade de

duas maneiras diferentes:

1. Essa associa¸c˜ao pode ser feita de modo que pi (i = 1, 2, 3, 4, 5, 6} seja suﬁcientemente

pr´oximo da frequˆencia relativa do evento {ai}, quando o experimento ´e repetido um

n´umero suﬁcientemente grande de vezes.

2. Por meio do argumento de que nenhuma face ´e melhor que a outra, logo, n˜ao

h´a nenhuma raz˜ao pela qual devemos atribuir uma probabilidade maior para uma

ou para outra face. Assim, podemos associar um valor igual para cada um dos

resultados, obtendo com isso um modelo probabil´ıstico equiprov´avel (principio da

democracia matem´atica).

Da segunda condi¸c˜ao, devemos deﬁnir pi = p(i) com (i = 1, 2, 3, 4, 5, 6 }, tomando

. A fun¸c˜ao p assim deﬁnida satisfaz as condi¸c˜oes de uma fun¸c˜ao de probabilidade

pi =

1
6

na vis˜ao axiom´atica proposta por Kolmogorov.

Do ponto de vista de teoria matem´atica, a vis˜ao axiom´atica de probabilidade

n˜ao apresenta nenhum problema. No entanto, quando deseja-se aplicar tal teoria na

modelagem de fenˆomenos do cotidiano, nos deparamos com o problema de qual valor

atribuir para a probabilidade de um evento de modo que esse modelo reﬂita o fenˆomeno

modelado.

Vejamos a seguir alguns exemplos de aplica¸c˜oes da teoria de probabilidades. Tais

exemplos s˜ao interpreta¸c˜oes de exemplos cl´assicos apresentados na literatura espec´ıﬁca

([4], [6], [7], [9] e [3]).

1.1.3.5 Alguns exemplos de aplica¸c˜ao

Exemplo: Suponha que em um dia dez peixes s˜ao capturados em um lago, marcados e

colocados novamente no lago. Alguns dias depois, vinte peixes s˜ao capturados do mesmo

25

lago e constata-se que dois desses peixes haviam sido marcados anteriormente. Deseja-se

ent˜ao saber:

1. Se o lago possui N peixes, qual ´e a probabilidade de, capturando vinte peixes,

encontrar dois peixes marcados?

2. Para que valor de N essa probabilidade ´e m´axima?

Vejamos como podemos aplicar a teoria desenvolvida anteriormente.
(cid:18)N
20

1. Para responder o primeiro questionamento, observe que h´a

(cid:19)

modos poss´ıveis

de capturar vinte peixes, que s˜ao os modos de se formar subconjuntos de vinte

elementos retirados de um conjunto de N elementos distintos. Para captura vinte

peixes, dos quais dois est˜ao marcados, devem ser capturados dois dos dez peixes j´a

marcados, o que pode ser feito de

modos, os outros 18 devem ser capturados

dentre restante de peixes que h´a no lago, os n˜ao marcados, ou seja, dentre os N − 10

peixes, o que pode ser feito de

modos. Assim, chamando de AN o evento

(cid:19)

(cid:18)10
2

(cid:19)

(cid:18)N − 10
18

de capturar dois peixes j´a marcados, tendo N peixes no lago, temos:

p (AN ) =

(cid:18)10
2

(cid:19)(cid:18)N − 10

(cid:19)

18
(cid:19)

(cid:18)N
10

.

(cid:0)10
2

(cid:1)(cid:0)N −10
(cid:1)
18
(cid:1)
(cid:0)N
10

2. Como p (AN ) =

, desejemos que p (AN ) seja m´aximo. Assim considere o

evento AN +1, pegar dois peixes j´a marcados, tendo (N + 1) peixes no lago de modo

que

p (AN +1) =

(cid:18)10
2

(cid:19)(cid:18)N + 1 − 10

(cid:19)

18
(cid:19)
(cid:18)N + 1
10

.

Agora, basta analisar para quais valores de N temos p (AN +1) ≥ p (AN ), ou seja,

at´e quando que p (AN ) crescente. Como p (AN +1) ≥ p (AN ) implica em p (AN +1) −

26

p (AN ) ≥ 0, ent˜ao,

de onde vem que

(cid:19)

(cid:19)(cid:18)N − 9

(cid:18)10
18
2
(cid:19)
(cid:18)N + 1
20

−

(cid:19)(cid:18)N − 10

(cid:19)

(cid:18)10
2

18
(cid:19)

(cid:18)N
20

≥ 0

(cid:19)

(cid:18)10
2
(cid:19)(cid:18)N + 1

(cid:20)(cid:18)N
20

(cid:19)

(cid:18)N
20

20

(cid:19)(cid:18)N − 9

(cid:19)

18

−

(cid:18)N + 1
20

(cid:19)(cid:18)N − 10

(cid:19)(cid:21)

18

≥ 0

ou ainda

(cid:20)(cid:18)N
20

(cid:19)(cid:18)N − 9

(cid:19)

18

−

(cid:18)N + 1
20

(cid:19)(cid:18)N − 10

(cid:19)(cid:21)

18

≥ 0.

Manipulando as express˜oes entre colchetes e colocando os fatores comuns em evidˆencia

podemos concluir que

ou equivalentemente

Assumindo N > 27 temos

(N − 9)
(N − 27)

−

(N + 1)
(N − 19)

≥ 0

(N − 9)
(N − 27)

≥

(N + 1)
(N − 19)

.

(N − 9)(N − 19) > (N − 27)(N + 1) ⇒

o que ´e equivalente a desigualdade

N 2 − 28N + 171 ≥ N 2 − 26N − 27 ⇒

de modo que

ou ainda N ≤ 99.

−2N ≥ −198

Portanto p(A28) < p(A29) < p(A30) < · · · < p(A99) > p(A100) > p(A101) > · · · e

assim p(AN ) ´e m´aximo quando N = 99.

O problema anterior pode ser generalizado, conforme segue.

27

Exemplo: Para determinar o tamanho da popula¸c˜ao de animais de certa esp´ecie em

uma regi˜ao, os bi´ologos, frequentemente, utilizam o m´etodo de Captura e Recaptura. O

procedimento consiste em capturar n´umero pr´e-ﬁxado m de animais da esp´ecie desejada

e marc´a-los. Em seguida, eles s˜ao soltos e espera-se um tempo para permitir que eles se

misturem aos demais. Uma segunda amostra ´e retirada com r animais e o n´umero de

animais marcados ´e contado. Com base nessa informa¸c˜ao, deseja-se estimar o tamanho

N da popula¸c˜ao desses animais na regi˜ao.

Considere o evento AN , capturar k0 peixes j´a marcados tendo N peixes no lago.

Como anteriormente, temos que

(cid:18)m
k0

p (AN ) =

(cid:19)(cid:18)N − m
r − k0
(cid:19)

(cid:19)

(cid:18)N
r

e queremos que p(AN ) seja m´aximo. Assim

p (AN +1) =

(cid:18)m
k0

(cid:19)(cid:18)N + 1 − m

(cid:19)

r − k0
(cid:19)

(cid:18)N + 1
r

.

´e a probabilidade de se pegar k0 peixes que j´a foram marcados, em r peixes capturados

tendo o lago um total de (N + 1) peixes.

Agora, basta analisar at´e quando p(AN +1) > p(AN ), ou seja, at´e quando que

p(AN ) cresce conforme crescimento de N . Procedendo de maneira semelhante ao exemplo

anterior, temos que p(AN +1) > p(AN ) implica que p(AN +1) − p(AN ) ≥ 0, ou seja,

(cid:19)

(cid:18)N + 1 − m
r − k0
(cid:18)N + 1
r

(cid:19) −

(cid:19)

(cid:18)N − m
r − k0
(cid:18)N
r

(cid:19) ≥ 0

de onde vem que

(cid:19)

(cid:18)m
k0
(cid:19)(cid:18)N + 1

(cid:20)(cid:18)N
r

(cid:19)

r

(cid:18)N
r

(cid:19)(cid:18)N + 1 − m

(cid:19)

r − k0

−

(cid:18)N + 1
r

(cid:19)(cid:21)

(cid:19)(cid:18)N − m
r − k0

≥ 0

28

ou ainda

(cid:18)N
r

(cid:19)(cid:18)N + 1 − m

(cid:19)

r − k0

−

(cid:18)N + 1
r

(cid:19)

(cid:19)(cid:18)N − m
r − k0

> 0.

Manipulando esta ´ultima express˜ao e colocando os fatores comuns em evidˆencia podemos

concluir que

(N − m + 1)
(N − m − r + k0 + 1)

≥

(N + 1)
(N − r + 1)

e, assumindo N > −m − r + k0 + 1 temos:

(N − m + 1)(N − r + 1) ≥ (N − m − r + k0 + 1)(N + 1)

de modo que

N 2 + (2 − m − r)N + (mr − r − m + 1) ≥ N 2 + (2 − m − r + k0)N + (k0 − r − m + 1),

de onde temos

ou ainda

mr ≥ k0N + k0

N ≤

mr − k0
k0

= m

r
k0

− 1.

A teoria da probabilidade tamb´em pode ser utilizada em situa¸c˜oes nas quais se de-

seja obter uma estimativa de pessoas com uma certa caracter´ıstica, em geral caracter´ıstica

de natureza constrangedora, dentro de popula¸c˜ao. Vejamos o exemplo a seguir:

Exemplo: Deseja-se estimar a propor¸c˜ao p de habitantes de determinada cidade ser

usu´ario de drogas. Para isso, realizam-se entrevistas com alguns habitantes da cidade.

N˜ao se deseja perguntar diretamente ao entrevistado se ele usa drogas, pois ele poderia se

recusar a responder, ou at´e mesmo n˜ao responder corretamente. Adota-se ent˜ao o seguinte

procedimento: prop˜oe-se ao entrevistado duas perguntar cujas respostas podem ser sim

ou n˜ao. Uma destas perguntas deve ser a pergunta de interesse, como por exemplo:

1. Vocˆe usa drogas?

2. Sua idade ´e um numero par?

29

Pede-se para o entrevistado que jogue uma moeda, longe do entrevistador, e que

se o resultado for cara, responda a primeira pergunta, e se for coroa, responda a a segunda

pergunta.

Suponha que foram realizadas mil entrevistas e obtidos quatrocentos respostas

sim. Qual seria uma estimativa para o n´umero de usu´ario de drogas dessa cidade? O

diagrama seguinte ilustra as possibilidades de respostas e suas respectivas probabilidades

Figura 1.1: ´Arvore de possibilidades para o problema.

Seja ps a probabilidade de algu´em responder sim para qualquer uma das pergun-

tas. Ent˜ao, de acordo com o diagrama da Figura 1.1, temos:

ps =

1
2

p +

1
2

·

1
2

=

1
2

p +

1
2

⇒ p = 2p1 −

1
2

.

Como quatrocentas pessoas responderam sim ´e razo´avel ent˜ao ps = 40% = 0, 4 e assim

temos: p = 2 · 0, 4 − 0, 5 = 0, 3. Logo, podemos estimar em 30% a propor¸c˜ao de usu´arios

de drogas dessa cidade.

Vejamos uma outra aplica¸c˜ao interessante da teoria de probabilidade.

Exemplo Num grupo de r pessoas, qual ´e a probabilidade de pelo menos duas delas fazer

anivers´ario no mesmo dia?

Este problema ´e bastante surpreendente, pois, para valores de r relativamente

pequeno, essa probabilidade ´e bastante alta. Consideremos o ano com 365 dias e assu-

mimos que r < 365, pois para r ≥ 365 a probabilidade procurada seria 1. Consideramos

ainda que todos os dias s˜ao equiprov´aveis. Seja A o evento de interesse, isto ´e, A = {pelo

menos duas pessoas aniversariam no mesmo dia} e seja AC o complementar do evento

A, isto ´e,AC = {nenhuma pessoa faz anivers´ario no mesmo dia que outra}. Desta forma

temos que o n´umero de elementos do evento AC ´e

#(AC) = 365 · 364 · 363 · 362 · ... · (365 − r + 1).

30

Como um ano possui 365 dias, o n´umero de elementos do nosso espa¸co amostral #(Ω)

´e o n´umero de maneiras poss´ıveis para os anivers´arios das r pessoas, e como temos 365

op¸c˜oes de dias para o nascimento de cada pessoa,ent˜ao #(Ω) = 365r. Assim,

p(AC) =

365 · 364 · 363 · 362 · ... · (365 − r + 1)
365r

.

Logo, a probabilidade de haver pelo menos duas pessoas que fazem anivers´ario no mesmo

dia, que ´e dada por:

p(A) = 1 −

365 · 364 · 363 · 362 · ... · (365 − r + 1)
365r

.

A Tabela 1.1 resume os valores de p(A) para alguns valores de r.

r

5

10

10

23

25

30

40

50

60

p(A)

0, 03

0, 12

0, 41

0, 51

0, 57

0, 71

0, 89

0, 97

0, 99

Tabela 1.1: p(A) par alguns valores de r

Note que, para um grupo de 23 pessoas, ´e mais prov´avel haver duas ou mais

pessoas que fazem anivers´ario no mesmo dia do que todas aniversariem em dias diferentes.

Note ainda que para grupos com mais de 50 pessoas, ´e quase certo que haja duas ou mais

pessoas que fa¸cam anivers´ario no mesmo dia.

1.2 Probabilidade condicional

Suponha que temos a informa¸c˜ao que um evento A ocorreu e queremos saber

qual a probabilidade de um evento B ocorrer. A probabilidade de B ocorrer dado que A

ocorreu que representaremos por p (B|A), ´e deﬁnida por:

p (B|A) =

p (A ∩ B)
p (A)

no qual admitimos que p (A) (cid:54)= 0

Uma argumenta¸c˜ao para a validade desta f´ormula pode ser feita por meio do

diagrama de Venn da Figura. Sejam dois eventos A e B de um experimento aleat´orio

31

cujo espa¸co amostral ´e Ω. Queremos calcular a probabilidade de ocorrer B, dado que A

ocorreu.

Figura 1.2: Diagrama de Venn para os eventos A e B.

Observe que, os eventos pertencentes a regi˜ao 3 do nosso diagrama, n˜ao podem

ocorrer, pois temos a informa¸c˜ao que A ocorreu, ou seja, ocorreram os eventos das regi˜oes

1 e 2. Assim, os casos favor´aveis `a ocorrˆencia de B s˜ao apenas aqueles que se encontram

na intersec¸c˜ao de A e B, ou seja, na regi˜ao 2.

Isto ´e, o n´umero de casos favor´aveis `a

ocorrˆencia de B, dado que ocorreu A, ´e # (A ∩ B). E, como j´a sabemos que o evento A

ocorreu, o n´umero de casos poss´ıveis para o experimento ﬁca reduzido a # (A), ou seja,

o espa¸co amostral original do experimento sofre uma restri¸c˜ao, passando agora a ser o

conjunto A de modo que

p (B|A) =

n´umero de casos favor´aveis
n´umero de casos poss´ıveis

=

# (A ∩ B)
# (A)

.

Dividindo o numerador e o denominador do terceiro membro desta igualdade por # (Ω)

obtemos:

p (B|A) =

# (A ∩ B)
# (Ω)
# (A)
# (Ω)

⇒ p (B|A) =

p (A ∩ B)
p (A)

.

A probabilidade condicional pode ser vista como uma nova medida de proba-

bilidade, de forma a representar melhor as chances de eventos aleat´orios a partir da

informa¸c˜ao de que um dado evento acorreu. Assim, pode-se dizer que o n´umero que asso-

ciaremos `as chances que um evento tem de ocorrer, esta intimamente relacionada ao tipo

de informa¸c˜oes que possu´ımos sobre o experimento. Nossa opini˜ao sobre um determinado

experimento depende do tipo de informa¸c˜oes que temos sobre ele.

32

1.2.0.6 Algumas aplica¸c˜oes de probabilidade condicional

Para ilustrar o uso da probabilidade condicional, consideremos a situa¸c˜ao em um

jogo de futebol entre as equipes A e B, que este ano j´a se enfrentaram nove vezes, sabe-se

que a equipe A venceu em seis ocasi˜oes e a equipe B venceu trˆes. Caso fossemos apostar

na vit´oria de uma dessas equipes, nossa intui¸c˜ao diria que ´e melhor apostar na equipe A,

j´a que ela leva vantagem em n´umero de vit´orias sobre a outra equipe. Mas antes que a

partida comece, ﬁcamos sabendo os trˆes principais jogadores da equipe A n˜ao participar˜ao

deste jogo, e que isto j´a aconteceu em 4 ocasi˜oes nas quais a equipe A perdeu seu jogo.

Repare que o cen´ario mudou, pois a equipe A ﬁcou fragilizada com a perda dos

seus principais jogadores. Com isso, nossa opini˜ao tente a mudar, pois nossa intui¸c˜ao

agora diz que ´e melhor apostar na outra equipe, que esta completa.

Analisando a situa¸c˜ao descrita acima, podemos perceber que a chance que atribu´ımos

a um determinado acontecimento ocorrer em um experimento, depende de fatos exclusi-

vamente relacionados a este experimento, em que circunstˆancia o mesmo ir´a se realizar,

ou seja, a probabilidade de sucesso em um experimento esta condicionada as condi¸c˜oes

que ele ser´a realizado. Em v´arias outras situa¸c˜oes de nossa vida cotidiana, atribu´ımos

probabilidade a um determinado evento de acordo com as informa¸c˜oes que possu´ımos

relativas a este evento.

Vejamos alguma outras situa¸c˜oes interessantes de uso do conceito de probabili-

dade condicional.

Exemplo Sabe-se que 70% dos pˆenaltis marcados a favor da Sele¸c˜ao de Futebol do Brasil

s˜ao cobrados por jogadores do Cruzeiro. A probabilidade de um pˆenalti ser convertido

´e de 80% se for cobrado por um jogador do Cruzeiro e de 60% em caso contr´ario. Um

pˆenalti a favor do Brasil acabou de ser marcado:

1. Sabendo que o pˆenalti foi convertido, qual a probabilidade do cobrador desse pˆenalti

ter sido um jogador do Cruzeiro?

2. Sabendo que o pˆenalti foi perdido, qual a probabilidade de o cobrador desse pˆenalti

ter sido um jogador do Cruzeiro?

Vejamos como esse problema pode ser resolvido sob a luz da probabilidade condicional.

1. Para um pˆenalti ser convertido, ou ele ´e cobrado por um jogador do Cruzeiro ou

n˜ao. Analisemos cada caso separadamente.

33

A probabilidade de ser cobrado por um jogador do Cruzeiro e ser convertido ´e igual a:

0, 7·0, 8 = 0, 56. Essa ´e a probabilidade dos nossos casos favor´aveis. A probabilidade

de ser cobrado por um jogador, que n˜ao seja do Cruzeiro, e ser convertido ´e igual

a: 0, 3 · 0, 6 = 0, 18. Assim, podemos concluir que a probabilidade de um pˆenalti

ser convertido a favor do Brasil ´e de 0, 56 + 0, 18 = 0, 74, ou seja, 74% dos pˆenaltis

marcados a favor do Brasil s˜ao convertidos. Essa ´e a probabilidade dos nossos

casos poss´ıveis. Logo, considerando o evento B, pˆenalti cobrado por um jogador do

Cruzeiro, e o evento A, pˆenalti convertido. Teremos que a probabilidade procurada

´e:

p (B|A) =

casos favor´aveis
casos poss´ıveis

=

0, 56
0, 74

= 0, 7567 = 75, 67%.

Exemplo Um casal acaba de ter gˆemeos. Sabendo que uma das crian¸cas ´e do sexo

feminino, qual a probabilidade de as duas crian¸cas serem do sexo feminino?

Para este problema temos o seguinte espa¸co amostral:

Ω = {(M, M ) , (M, F ) , (F, M ) , (F, F )}.

Logo, se estiv´essemos interessados em saber a probabilidade de um casal, que acabou de

ter gˆemeos, ter duas meninas, que chamaremos de evento A, ter´ıamos:

p (A) =

1
4

. Mas como temos a informa¸c˜ao que uma das crian¸cas ´e do sexo feminino, nosso espa¸co

amostral se modiﬁca, passando a ser:

B = {(M, F ) , (F, M ) , (F, F )},

uma vez que o evento (M M ) n˜ao pode ocorrer. Com isso, a probabilidade de as duas

crian¸cas serem do sexo feminino tamb´em se modiﬁca, sendo agora igual a

p (A|B) =

1
3

.

O mesmo resultado pode ser obtido por aplica¸c˜ao direta da f´ormula de probabili-

34

dade condicional. Para isso, precisamos considerar os eventos: A que representa o evento

que um dos gˆemeos ´e do sexo feminino; B que representa o evento que os gˆemeos s˜ao

do sexo feminino. Assim, p(A ∪ B) = 1/4 e p(A) = 3/4 de modo que por aplica¸c˜ao da

f´ormula p (A|B) chegamos ao mesmo resultado.

Vejamos agora como informa¸c˜oes adicionais inﬂuenciam a probabilidade desejada.

Exemplo: Um casal acaba de ter gˆemeos, sabendo-se que uma das crian¸cas ´e do sexo

feminino e se chama Paula, qual a probabilidade de as duas crian¸cas serem do sexo

feminino?

Para resolver este problema vamos chamar: de F o evento elementar nascer uma

crian¸ca do sexo feminino cujo nome n˜ao ´e Paula; de M o evento elementar nascer uma

crian¸ca do sexo masculino; e ﬁnalmente de Fp o evento nascer uma crian¸ca do sexo

feminino e receber o nome de Paula. Assim, nosso espa¸co amostral para o nascimento

dos gˆemeos ser´a

Ω = {(M, M ) , (M, F ) , (F, M ) , (F, F ) , (M, Fp) , (Fp, M ) , (F, Fp) ,

(Fp, F ) , (Fp, Fp)}.

Podemos excluir desse espa¸co amostral o evento (Fp, Fp) por ser um evento pouco prov´avel

de ocorrer. Aﬁnal, quem ´e que tem duas ﬁlhas, gˆemeas, e as registra com o mesmo nome?

Al´em disso, como temos a informa¸c˜ao que um dos gˆemeos ´e uma menina chamada Paula,

os eventos (M, M ), (M, F ), (F, M ) e (F, F ) se excluem automaticamente. Logo, com as

informa¸c˜oes fornecidas o espa¸co amostral para este problema se reduz a

Ω = {(M, Fp) , (Fp, M ) , (F, Fp) , (Fp, F )}

nos quais podemos considerar que os eventos s˜ao equiprov´aveis. Assim, a probabilidade

procurada ´e

p (A|B) =

2
4

=

1
2

.

´E importante notar que o fato de sabermos o nome de uma das crian¸cas inﬂuˆencia

diretamente na probabilidade procurada.

Para dar alcan¸car o objetivo pretendido neste trabalho, precisamos de alguns

35

conceitos mais avan¸cados da teoria de probabilidade.

1.3 Vari´avel aleat´oria, valor esperado e variˆancia

Uma vari´avel aleat´oria, denotada pela letra X, ´e uma fun¸c˜ao que associa um

n´umero real para cada evento do espa¸co amostral. Isto ´e, uma vari´avel aleat´oria ´e uma

fun¸c˜ao X : A → R, onde A ´e o conjunto formado pelos eventos de do espa¸co amostral Ω.

Para simpliﬁcar, seja VX o conjunto de valores poss´ıveis da vari´avel aleat´oria X.

As vari´aveis aleat´orias podem ser classiﬁcadas em discretas e cont´ınuas. As

vari´aveis aleat´orias discretas s˜ao vari´aveis cujo o conjunto VX ´e ﬁnito ou inﬁnito enu-

mer´avel. No caso em que VX ´e um conjunto n˜ao enumer´avel tem-se uma vari´avel aleat´oria

cont´ınua.

Seja X uma vari´avel aleat´oria discreta assumindo valores reais VX = {x1, x2, · · · , xk},

podemos atribuir uma probabilidade para cada um dos poss´ıveis valores xi assumidos por

X por meio express˜ao

pi = p(X = xi) = p({A ∈ A; X(A) = xi}),

isto ´e, a probabilidade de X assumir o valor xi ´e deﬁnida como a probabilidade dos eventos

A tais que X(A) = xi. A fun¸c˜ao p : Vx → [0, 1] deﬁnida acima ´e chamada de fun¸c˜ao de

probabilidade ou fun¸c˜ao de distribui¸c˜ao da vari´avel aleat´oria X.

Para ilustrar, consideremos o espa¸co amostral Ω resultante do lan¸camento de duas

moedas Ω = {(c, c), (c, k), (k, c), (k, k)} e seja p((c, c)) = p((c, k)) = p((k, c)) = p((k, k)) =

1/4. Consideremos X a vari´avel aleat´oria que associa para cada evento de Ω o n´umero

de caras deste evento. Assim, os poss´ıveis valores de X ´e dado por VX = {0, 1, 2} e, para

cada um desses poss´ıveis valores, temos as probabilidades

p1 = p(X = 0) =

1
4

, p2 = p(X = 1) =

1
2

e p3 = p(X = 2) =

1
4

.

N˜ao ´e dif´ıcil veriﬁcar a validade da igualdade

p(X = xi ou X = xj) = p(X = xi) + p(X = xj)

para uma vari´avel aleat´oria discreta X.

36

A esperan¸ca, ou valor esperado, de uma vari´avel aleat´oria discreta X ´e o n´umero

E(X) deﬁnido pela f´ormula

µ = E(X) =

∞
(cid:88)

i=1

xip(xi).

esperan¸ca pode ser interpretada como a m´edia da vari´avel aleat´oria X.

Exemplo: Considere um jogo no qual se lan¸cam trˆes moedas n˜ao viciadas e o jogador

recebe R$ 2, 00 caso apare¸ca uma cara, R$ 4, 00 se aparecerem duas caras e R$ 8, 00 caso

apare¸cam trˆes caras. Se nenhuma cara ocorre, nada se recebe. Quanto se esperaria ganhar

caso ﬁzesse esse jogo uma vez?

Inicialmente veriﬁcamos que o espa¸co amostral para o lan¸camento de trˆes moedas

´e o conjunto

Ω = {(k, k, k), (k, k, c), (k, c, k), (c, k, k), (k, c, c), (c, k, c), (c, c, k), (c, c, c)}.

Para representar o jogo, deﬁnimos a vari´avel aleat´oria X que retorna o n´umero de caras

de cada evento elementar de Ω. A distribui¸c˜ao de probabilidade da vari´avel aleat´oria X

est´a representada Tabela 1.2.

N´umero de caras

Probabilidade

0

1
8

1

3
8

2

3
8

3

1
8

Tabela 1.2: Distribui¸c˜ao de probabilidade da vari´avel aleat´oria X.

Se deﬁnirmos a vari´avel aleat´oria Y que representa valor a ser recebido em cada

jogada, ent˜ao podemos construir a distribui¸c˜ao de probabilidades de Y , conforme Ta-

bela 1.3.

N´umero de caras

yi: valor a ser recebido (R$)

Probabilidade: p(yi)

0

0

1
8

1

2

3
8

2

4

3
8

3

8

1
8

Tabela 1.3: Distribui¸c˜ao de probabilidade da vari´avel aleat´oria Y .

37

cujo valor ´e

E(Y ) = 0 ·

1
8

+ 2 ·

3
8

+ 4 ·

3
8

+ 8 ·

1
8

=

26
8

= 3, 25

Como o valor esperado ´e uma m´edia a longo prazo ent˜ao, ap´os v´arias jogadas, se esperaria

ganhar R$ 3, 25.

Embora as probabilidades nunca possam ser negativas o valor esperado de uma

vari´avel aleat´oria pode ser negativo, conforme podemos ver no exemplo a seguir.

Exemplo: Em um sorteio, 1500 bilhetes s˜ao vendidos a R$ 2, 00 cada. Ser˜ao 4 prˆemios

sorteados nos valores de R$ 500, 00, R$ 250, 00, R$ 150, 00 e R$ 75, 00. Se vocˆe comprar

um bilhete qual ´e o valor esperado do seu lucro?

Para encontrar o lucro para cada prˆemio, devemos subtrair o valor do prˆemio do

valor pago pelo bilhete. Assim, para o prˆemio de R$ 500, 00, temos um lucro igual a R$

500, 00−R$ 2, 00 =R$ 498, 00. E assim por diante para os demais prˆemios. Deﬁnindo a

vari´avel aleat´oria discreta X que retorna o lucro em reais, temos a seguinte distribui¸c˜ao

de probabilidades:

Lucro em reais (xi)

498

248

148

73

−2

p(xi)

1
1500

1
1500

1
1500

1
1500

1496
1500

Tabela 1.4: Distribui¸c˜ao de probabilidade da vari´avel aleat´oria X.

Para esta vari´avel aleat´oria temos o valor esperado

E(X) = 498 ·

1
1500

+ 248 ·

1
1500

+ 148 ·

1
1500

+ 73 ·

1
1500

+ (−2) ·

1496
1500

= −1, 35.

Logo, como o valor esperado ´e negativo, vocˆe espera perder uma m´edia de R$ 1, 35 por

cada bilhete que comprar.

Exemplo: Seja Ω = {e1, e2} onde p(e1) = p e p(e2) = 1−p. Considere a vari´avel aleat´oria

X deﬁnida por X(e1) = a e X(e2) = −b, com a e b positivos.

Esta vari´avel aleat´oria X serve como modelo em um jogo entre dois jogadores,

38

onde um dos jogadores aposta em um dos eventos e1 ou e2 e recebe um valor de a reais

se o evento e1 ocorre e perde b reais se ocorre o evento e2. Pergunta-se:

1. Qual ´e a esperan¸ca de X? Por aplica¸c˜ao direta da deﬁni¸c˜ao de valor esperado temos

E(X) = pa − b(1 − p) = p(a + b) − b

2. Quais devem ser os valor de a e b de modo que a aposta seja justa? Entendemos

por aposta justa aquela em que as chances de ganhar e perder s˜ao iguais, ou seja, o

valor esperado E(X) = 0. Assim,

o que implica em

p(a + b) − b = 0

a
b

=

1 − p
p

.

Outro conceito importante no estudo do comportamento de uma vari´avel aleat´oria

X ´e a variˆancia, V (X), deﬁnida por:

V (X) =

k
(cid:88)

i=1

[xi − E (X)]2 pi

A variˆancia ´e uma medida que representa o qu˜ao afastado est˜ao os dados do valor esperado

de X, ou de sua m´edia, em m´edia.

Para exempliﬁcar, consideremos aqui a vari´avel aleat´oria Y cuja a distribui¸c˜ao

de probabilidade est´a representada na Tabela 1.2 na p´agina 37. Temos ent˜ao que:

V (Y ) =

(cid:18) 13
4

(cid:19)2 1
8

(cid:18)

+

2 −

13
4

(cid:19)2 1
8

(cid:18)

+

4 −

13
4

(cid:19)2 1
8

(cid:18)

+

8 −

13
4

(cid:19)2 1
8

=

564
128

≈ 4, 40.

Vejamos a seguir alguma vari´aveis aleat´orias fundamentais para o desenvolvi-

mento deste trabalho.

39

1.3.1 Algumas vari´aveis aleat´orias especiais.

1.3.1.1 Vari´avel aleat´oria de Bernoulli

Diz-se que que X vari´avel aleat´oria de Bernoulli quando X assume apenas os

valores 0 ou 1. Sua distribui¸c˜ao de probabilidade ´e dada por:

p(X = 1) = p,

e

p(X = 0) = 1 − p.

Utilizamos a nota¸c˜ao X Bernoulli(p) para signiﬁcar que a vari´avel aleat´orio ´e de Ber-

noulli.

Em uma vari´avel aleat´oria de Bernoulli, a probabilidade p ´e denominada de
parˆametro do modelo. ´E pr´atica comum considerar como sucesso a ocorrˆencia de 1 e

de fracasso a ocorrˆencia de 0. Assim, denominamos por ensaio de Bernoulli, o experi-

mento que tem resposta dicotˆomica do tipo sucesso-fracasso.

Sejam A um evento de um espa¸co amostral Ω com p(A) = p e ω ∈ Ω um evento

elementar. Se deﬁnirmos a vari´avel aleat´oria

X(ω) =





1,

se ω ∈ A,

0,

se ω ∈ AC.

ent˜ao X Bernoulli(p). Um exemplo cl´assico do modelo de Bernoulli ´e o lan¸camento

de uma moeda. Podemos deﬁnir sucesso como a ocorrˆencia de qualquer uma das faces,

digamos cara. Dessa forma temos:

X(ω) =





1,

se ω = cara;

0,

se ω = coroa

Se a moeda for equilibrada temos p = 1/2 de modo que p(X = 1) = 1/2.

A esperan¸ca e a variˆancia de X Bernoulli(p) s˜ao respectivamente

E(X) =

k
(cid:88)

i=1

xipi = 1 · p + 0 · (1 − p) = p,

V (X) =

k
(cid:88)

[xi − E(X)]2pi = [1 − p]2p + [0 − p]2(1 − p) =

i=1

40

(1 − p)p[(1 − p) + p] = p − p2 = p(1 − p).

A repeti¸c˜ao de sucessivos ensaios de Bernoulli ´e fonte de v´arios problemas te´oricos

interessantes. Considerando uma sequˆencia de n ensaios de Bernoulli, independentes,

outros modelos podem ser constru´ıdos.

1.3.1.2 Vari´avel aleat´oria Binomial

Seja X1, X2, · · · , Xn vari´aveis aleat´oria de Bernoulli com Xi Bernoulli(p) . A

vari´avel aleat´oria X = X1 + X2 + · · · + Xn assume valor no conjunto VY = {0, 1, 2, · · · , n}

e tem distribui¸c˜ao de probabilidade binomial dada por

pi = p(Y = i) =

(cid:19)

(cid:18)n
i

pi(1 − p)n−i.

A nota¸c˜ao utilizada para esta vari´avel ´e ser´a X B(n, p).

Exemplo: A taxa de imuniza¸c˜ao de uma vacina ´e de 80%. Se um grupo de 20 pessoas

foram vacinadas, desejamos saber o comportamento probabil´ıstico do n´umero de pessoas

imunizadas desse grupo.

Seja X a vari´avel de interesse. Para cada pessoa do grupo, a probabilidade de

estar imunizada ´e 0, 8 e admitimos, ainda, independˆencia entre os resultados das v´arias

pessoas vacinadas. Dessa forma, teremos X B(20, 8), em que o sucesso corresponde `a

imuniza¸c˜ao. Por exemplo, a probabilidade de quinze pessoas estarem imunizados ´e dada

por:

p(X = 15) = p(15) =

(cid:19)

(cid:18)20
15

= 0, 815 · 0, 220−15 = 0, 175.

Na literatura encontra-se facilmente a prova do seguinte resultado.

Teorema: Se para dado n ≥ 1 e p ∈ [0, 1], X B(n, p), ent˜ao

E(X) = np,

V (X) = np(1 − p).

41

1.3.1.3 Vari´avel aleat´oria uniforme

Suponha que a vari´avel aleat´oria X assuma valores no conjunto V (X) = {x1, x2, . . . , xn},

isto ´e, X ´e uma vari´avel aleat´oria discreta. Dizemos que a vari´avel aleat´oria X ´e uniforme

quando sua distruibui¸c˜ao de probabilidade ´e dada por:

p(X = xi) =

1
n

para todo i = 1, 2, . . . , n.

No caso em que a vari´avel aleat´oria X assume valores no intervalo V (X) = (a, b),

isto ´e, X ´e uma vari´avel aleat´oria cont´ınua, ent˜ao dizemos que a vari´avel aleat´oria X ´e

uniforme quando sua distruibui¸c˜ao de probabilidade ´e dada por:

p(X ∈ I) =

l
n

para todo intervalo I ⊂ (a, b) de comprimento l.

1.4

´Area e probabilidade

A teoria da probabilidade pode ser utilizada para determinar a ´area de ﬁguras

planas. Para estabelecer a rela¸c˜ao entre ´areas e probabilidade apresenta-se abaixo a

deﬁni¸c˜ao axiom´atica de ´area. Consideramos aqui uma classe M de subconjuntos do plano

que s˜ao mensur´aveis cuja deﬁni¸c˜ao formal n˜ao abordaremos aqui (tal deﬁni¸c˜ao pode ser

encontrada por exemplo em Tom M. Apostol, [1]).

Para essa classe M de subconjuntos do plano que s˜ao mensur´aveis, deﬁnimos uma

fun¸c˜ao a : M → R, chamada de ´area, que deve satisfazer:

1. Propriedade de n˜ao negatividade. Para cada conjunto S de M , temos:

a(S) ≥ 0;

2. Propriedade aditiva. Se S e T est˜ao em M ent˜ao tamb´em est˜ao em M os con-

juntos (S ∪ T ) e (S ∩ T ) e, al´em disso,

a(S ∪ T ) = a(S) + a(T ) − a(S ∩ T ).

42

3. Invariˆancia por congruˆencia. Se um conjunto S est´a em M e se T ´e congruente

com S ent˜ao T tamb´em est´a em M e tˆem-se:

a(S) = a(T ).

4. Escolha de escala. Todo o retˆangulo R est´a em M e se os lados de R tem

comprimentos h > 0 e k > 0 ent˜ao

a(R) = hk.

5. Propriedade de exaust˜ao. Considere os conjuntos Q, S e T de maneira que

S ⊆ Q ⊆ T,

(1.1)

nos quais S e T pertencem a M e s˜ao formados por uni˜oes ﬁnitas de retˆangulos. Se

existe um ´unico n´umero c que veriﬁca as desigualdades

a(S) ≤ c ≤ a(T )

para todas as regi˜oes S e T que satisfa¸cam (1.1), ent˜ao Q ´e mens´uravel, isto ´e,

Q ∈ M e

a(Q) = c.

O primeiro desses axiomas estabelece simplesmente que a ´area de um conjunto

plano mensur´avel n˜ao pode ser um n´umero negativo. J´a o segundo axioma nos diz que,

quando um conjunto ´e formado por duas regi˜oes (as quais podem haver intersec¸c˜ao), a

´area da reuni˜ao ´e a soma das duas partes, menos a ´area da sua interse¸c˜ao. Em particular,

se a interse¸c˜ao tem ´area nula, a ´area do todo ´e a soma das ´areas das duas partes. O

terceiro axioma atribua ´areas iguais a conjuntos tendo o mesmo tamanho e forma. Seria

trivial a veriﬁca¸c˜ao dos 3 primeiros axiomas se atribu´ıssemos o n´umero zero como ´area

de cada conjunto de M . J´a o quarto axioma atribui uma ´area n˜ao nula aos retˆangulos e,

inalmente, o quinto axioma incorpora o m´etodo de exaust˜ao permitindo assim estender a

classe dos conjuntos mensur´aveis a regi˜oes mais gerais.

Consideremos agora como espa¸co amostral Ω um retˆangulo de lados h, k positivos.

43

Da deﬁni¸c˜ao axiom´atica de ´area, temos que a(Ω) = hk. Com o objetivo de atribuir uma

probabilidade ao evento A do espa¸co amostral Ω, considere a fun¸c˜ao p : A → R, no qual

A ´e o conjunto formado pelos eventos de Ω, deﬁnida pela seguinte express˜ao

p(A) =

a(A)
hk

.

Claramente temos que 0 ≤ p(A) ≤ 1, uma vez que a(A) ≤ a(Ω). Temos ainda

que se A1 e A2 s˜ao disjuntos, ent˜ao

p(A1 ∪ A2) =

a(A1 ∪ A2)
hk

=

a(A1) + a(A2)
hk

=

a(A1)
hk

+

a(A2)
hk

= p(A1) + p(A2).

Al´em disso, temos quep(Ω) = 1. Ent˜ao a fun¸c˜ao p : A → R assim deﬁnida ´e uma fun¸c˜ao

de probabilidade.

A express˜ao

p(A) =

a(A)
hk

nos permite relacionar os conceitos de ´area e probabilidade de modo que podemos usar

m´etodos de estimativas de probabilidade de ocorrˆencia de um evento A para obtermos

um valor estimado para a ´area da regi˜ao plana deﬁnida pelo evento A.

44

Cap´ıtulo 2

Lei dos Grandes N´umeros e

simula¸c˜oes

2.1

Introdu¸c˜ao

Frequentemente deseja-se saber qual a probabilidade de eventos em que nem

sempre ´e poss´ıvel determinar a sua ocorrˆencia. Por exemplo, se desejamos determinar a

probabilidade de um time ser campe˜ao, quando o campeonato aproxima-se do seu ﬁnal,

como vimos no cap´ıtulo anterior a quantidade de resultados poss´ıveis torna invi´avel a

an´alise de cada uma dessas possibilidades. O que poder´ıamos fazer seria, observar com

que frequˆencia cada time conquista o t´ıtulo por meio da observa¸c˜ao de um grande n´umero

de campeonatos, o que, na pratica, ´e naturalmente invi´avel.

Disp˜oe-se, hoje, de ferramentas que nos possibilitam fazer esse tipo de an´alise de

forma bastante aproximada, fazendo simula¸c˜oes por meio de programas computacionais

pode-se “realizar”milhares ou at´e milh˜oes de campeonatos em quest˜ao de minutos ou

at´e mesmo segundos. Neste sentido, as planilhas eletrˆonicas se mostram uma ferramenta

pr´atica para nos auxiliar nesta tarefa num n´ıvel mais elementar.

Neste cap´ıtulo vamos analisar como a frequencia relativa pode ser usada para

obter estimativas da probabilidade de um evento. Para isto ser´a utilizado um importante

resultado da teoria da probabilidades - a Lei dos Grandes N´umeros. O m´erito da Lei dos

Grandes N´umeros est´a no fato de permitir, por meio de uma longa s´erie de observa¸c˜oes,

a estimativa da probabilidade associada a fenˆomenos nos quais n˜ao ´e poss´ıvel aplicar a

deﬁni¸c˜ao cl´assica de probabilidade.

45

2.2 Moedas e frequˆencias relativas

Em 1692, Jacob Bernoulli demonstrou um teorema segundo o qual, se ´e conhecido

a probabilidade de ocorrˆencia de um evento num experimento aleat´orio, ´e poss´ıvel indicar

quais s˜ao as expectativas da frequˆencia da sua ocorrˆencia se o mesmo experimento for

repetido um n´umero consider´avel de vezes sob condi¸c˜oes semelhantes. Por outro lado, se

´e desconhecida a probabilidade de um evento, mas o n´umero de experimentos ´e muito

grande ent˜ao a sua probabilidade pode ser estimada com a precis˜ao e certeza que se

desejar.

A Lei de Bernoulli, mais conhecido como a Lei dos Grandes N´umeros, aﬁrma

que, quando conforme n´umero de realiza¸c˜oes aumenta, a frequˆencia relativa de um evento

tende a estabilizar num determinado valor que se adota como a probabilidade desse acon-

tecimento. Quando se repete um experimento um n´umero suﬁcientemente grande de vezes

´e poss´ıvel, substituir a Frequˆencia Relativa por Probabilidade com erro desprez´ıvel.

Para se compreender bem a Lei dos Grandes N´umeros e suas implica¸c˜oes, ´e inte-

ressante considerar alguns experimentos pr´aticos e tamb´em estabelecer um contraste com

a deﬁni¸c˜ao cl´assica de Probabilidade.

2.2.1 Simula¸c˜ao do lan¸camento de moedas

Usando-se a deﬁni¸c˜ao cl´assica, a probabilidade de ocorrer uma cara no lan¸camento

de uma moeda justa ´e, conhecidamente, 1/2 ou 50%.

Considere o experimento que consiste em realizar o lan¸camento de uma moeda n

vezes e observar a frequˆencia com que o evento A = face voltada para cima ´e cara acorre.

Podemos associar para cada um desses lan¸camentos a vari´avel aleat´oria

Xi =





1

0

se o envento A ocorre

se o evento A n˜ao ocorre

Consideremos ainda a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

que ´e frequˆencia relativa da ocorrˆencia do evento A.

46

Estamos interessados em responder a pergunta: O que acontece com a vari´avel

Mn conforme o n´umero de lan¸camentos n aumenta? Vamos realizar nosso experimento

de lan¸car moedinhas, felizmente, fazendo uso das planilhas eletrˆonicas. Para isto, vamos

usar a fun¸c˜ao aleat´orioentre(0;1) que retorna um valor 0 ou 1, com distribui¸c˜ao uniforme,

ou seja, com probabilidade igual de retornar o n´umero 0 ou o 1. Assim, como modelo

do nosso experimento, vamos considerar que o evento A ocorreu quando o resultado da

fun¸c˜ao aleat´orioentre(0;1) for o n´umero 1.

No experimento aleat´orio, realizado como descrito acima, foram obtidos os se-

guintes resultados representados na Tabela 2.1.

N´umero de N´umero obs.
lan¸camentos
10
150
500
20000

de caras
7
84
240
10049

Frequˆencia
relativa
0, 7 = 70%
0, 56 = 56%
0, 48 = 4%
0, 5024 = 50, 24%

Diferen¸ca para a
prob. cl´assica
30%
4%
2%
0, 24%

Tabela 2.1: Dados obtidos em simula¸c˜ao computacional do lan¸camento de moedas.

A palavra simula¸c˜ao no nosso contexto se refere ao processo de obter computacio-

nalmente um conjunto de valores da vari´avel Mn por meio de n realiza¸c˜oes do experimento

aleat´orio cujo resultado ´e a vari´avel aleat´oria Xi. Mais precisamente, neste trabalho uma

simula¸c˜ao de tamanho n consiste em obter o valor Mi, para i ≤ n.

Como se pode ver, a medida que se aumenta o n´umero de lan¸camentos, o valor da

frequˆencia relativa se aproxima cada vez mais dos 50% previstos pela deﬁni¸c˜ao cl´assica de

probabilidade. Como ´e de se esperar, pela natureza aleat´oria do experimento, cada uma

das simula¸c˜oes apresentam resultados diferentes, mas frequˆencia relativa tamb´em possui

o mesmo comportamento. Parece haver uma certa estabiliza¸c˜ao em torno de 50%.

A Figura 2.1 mostra o valor de Mn para n = 1, 2, · · · , 10 em trˆes simula¸c˜oes.

47

Figura 2.1: Simula¸c˜oes do lan¸camento de 10 moedas.

A Figura 2.2 representa o comportamento, da frequˆencia de caras, em 3 si-

mula¸c˜oes, com 500 lan¸camentos de uma moeda em cada simula¸c˜ao

Figura 2.2: Simula¸c˜oes do lan¸camento de 500 moedas.

J´a na Figura 2.3 temos trˆes simula¸c˜oes do lan¸camento de mil moedas em cada

simula¸c˜ao.

Figura 2.3: Simula¸c˜oes do lan¸camento de 1000 moedas.

Embora, cada simula¸c˜ao apresente um resultado diferente, podemos observar cla-

ramente uma menor ﬂutua¸c˜ao do valor de Mn em torno do valor 1/2 conforme o valor de

48

n aumenta. A Tabela 2.2 resume os valores de Mn obtidos em algumas simula¸c˜oes.

n
100
500
1000
5000
10000
15000
20000

M´ax M´ın M´edia
0,501
0,320
0,640
0,500
0,420
0,560
0,500
0,451
0,554
0,499
0,471
0,520
0,499
0,485
0,518
0,500
0,487
0,516
0,500
0,488
0,511

[0.45, 0.55]
0,733
0,980
0,996
1
1
1
1

[0.48, 0.52]
0,365
0,638
0,788
0,995
1
1
1

[0.49, 0.51]
0,223
0,370
0,466
0,832
0,939
0,976
0,989

Tabela 2.2: Simula¸c˜oes do lan¸camento de moedas para diferentes valores de n.

Note que, quanto maior o n´umero de lan¸camentos, menor ´e a diferen¸ca entre

as frequˆencias m´axima e m´ınima, ou seja, menor ´e a ﬂutua¸c˜ao em torno de 1/2, e mais

pr´oxima ﬁca a frequˆencia relativa da probabilidade obtida com a deﬁni¸c˜ao cl´assica.

Nas ﬁguras seguintes, vemos os histogramas para 700 simula¸c˜oes e diferentes

lan¸camentos em cada simula¸c˜ao.

Figura 2.4: Histograma para 700 simula¸c˜oes de M100.

49

Figura 2.5: Histograma para 700 simula¸c˜oes de M10000.

Note em cada ﬁgura que, quanto maior o n´umero de lan¸camentos realizados, mais

os valores de Mn obtidos se concentram em torno de 1/2.

Na se¸c˜ao seguinte, vamos mostrar o principal resultado que justiﬁca os dados

obtidos nas simula¸c˜oes apresentadas nesta se¸c˜ao.

2.3 A Lei dos Grandes N´umeros

Consideremos a vari´avel aleat´oria de Bernoulli, Xi, com i = 1, 2, . . . , n tal que,

p(Xi = 1) = p

e

p(Xi = 0) = 1 − p.

Como vimos no cap´ıtulo anterior, dada a realiza¸c˜ao de n experimentos aleat´orios pode-se

considerar a vari´avel

Mn =

X1 + X2 + · · · + Xn
n

.

A vari´avel aleat´oria Mn assume valores no conjunto

VMn = {i/n : i = 0, 1, 2, . . . , n}

e sua distribui¸c˜ao de distribui¸c˜ao de probabilidade ´e:

50

(cid:18)

m(i) = P

Mn =

(cid:19)

i
n

=

(cid:18)n
i

(cid:19)

pi(1 − p)n−i

N˜ao ´e dif´ıcil mostrar que o valor esperado e a variˆancia de Mn s˜ao dados, respec-

tivamente, por

E(Mn) = p

e

V (Mn) =

p(1 − p)
n

de modo que conforme o valor de n aumenta, os dados ﬁcam mais concentrados em torno

da m´edia E(Mn) = p. Vejamos com mais detalhes como isto acontece.

Para isso, seja ε > 0 um valor dado e estamos interessados em saber qual a

probabilidade da vari´avel Mn n˜ao pertencer ao conjunto

(cid:26)

A =

0,

1
n

,

2
n

, . . . ,

n − 1
n

(cid:27)

, 1

∩ (p − ε, p + ε).

Ou, equivalentemente, podemos escrever

AC =

(cid:26) i
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
n

:

− p

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≥ ε, i = 0, 1, 2, . . . , n

(cid:27)

e queremos encontrar p(Mn ∈ AC).

Como vimos no primeiro cap´ıtulo, a probabilidade do evento AC ocorrer ´e a soma

das probabilidades m(k) de cada evento elementar k/n ∈ AC e vamos representar isso por

p(Mn ∈ AC) =

m(k)

(cid:88)

AC

Usando a deﬁni¸c˜ao de variˆancia, temos que:

V (Mn) =

n
(cid:88)

k=0

(cid:18) k
n

(cid:19)2

− p

m(k) ≥

(cid:19)2

− p

m(k)

(cid:18) k
n

(cid:88)

AC

no qual a ´ultima desigualdade ´e verdadeira, pois estamos somando apenas os elementos

51

que est˜ao em AC. Agora, se k/n ∈ AC ent˜ao |k/n − p| ≥ ε de modo que temos

V (Mn) ≥

(cid:19)2

− p

m(k) ≥

(cid:18) k
n

(cid:88)

AC

ε2 · m(k)

(cid:88)

AC

que, colocando ε2 em evidencia na desigualdade anterior, obtemos

de onde vem que

V (Mn) ≥ ω2 (cid:88)

m(k) = ε2p (cid:0)Mn ∈ AC(cid:1)

AC

p(Mn ∈ AC) ≤

V (Mn)

ε2 =

p(1 − p)
ε2n

.

Usando o fato de p(1 − p) ≤

1
4

et˜ao temos a seguinte estimativa

p(Mn ∈ AC) = p

(cid:18)(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
n

− p

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:19)

≥ ε

≤

1
4nε2 .

o que prova a Lei dos Grandes N´umeros de Bernoulli.

A desigualdade anterior nos revela que a probabilidade de que a frequˆencia relativa

Mn esteja fora do intervalo (p − ε, p + ε) para um valor de ε > 0 escolhido, diminui

conforme consideramos mais experimentos. Assim, a convergˆencia de Mn para o valor p

desconhecido ´e dado em termos de probabilidade.

A mesma desigualdade ainda nos revela que ao usarmos a frequˆencia relativa com

estimativa para o valor p a chance de cometermos um erro maior do que ε > 0 ﬁxado ´e de

1
4nε2 .

Para ilustrar, suponha que ε = 10−2 = 0, 01 ent˜ao

1
4nε2 =

1
4n10−4

=

10000
4n

.

Suponha ainda que realizamos uma simula¸c˜ao com n = 25000. Com isso, ao considerar-

mos M25000 como estimativa para p, temos 1/10 = 10% de probabilidade que estejamos

52

cometendo um erro maior do que 10−2. Ou de maneira equivalentemente, a frequen-

cia relativa M25000 estima o valor da probabilidade desconhecida p com erro m´aximo de

ε = 0, 01 em 90% da vezes que realizarmos a simula¸c˜ao. A chance 1/10 de cometermos

um erro maior ε = 0, 01 ´e relativamente alta. No entanto, podemos diminuir este valor

simplesmente aumentando o n´umero de repeti¸c˜oes do experimento.

Para efeito de ilustra¸c˜ao, consideremos o experimento ﬁct´ıcio da moedinha da

se¸c˜ao anterior. Suponha que ε = 2.10−2 e n = 20000 de modo que

1
4nε2 =

1
4n · 4 · 10−4 =

10000
16.20000

=

1
32

.

Ent˜ao o valor

1
32

´e a probabilidade do evento M20000 /∈ (0.48, 0.52). Ou ainda, te-

mos aproximadamente 97% chance de que a probabilidade p esteja no intervalo (0.48, 0.52) .

No cap´ıtulo que segue vamos utilizar a Lei dos Grande N´umeros juntamente com

parte do que foi desenvolvido no cap´ıtulo anterior para estimarmos probabilidades de

alguns eventos de interesse bem como aplicar obtermos a ´area de algumas ﬁguras planas

e volumes de alguns s´olidos.

53

Cap´ıtulo 3

Simula¸c˜ao em planilhas eletrˆonicas

3.1

Introdu¸c˜ao

Neste cap´ıtulo vamos utilizar os dados te´oricos obtidos nos cap´ıtulos anteriores

para obter estimativas de probabilidade de alguns eventos utilizando planilhas eletrˆonicas.

3.2 Lan¸camento de dados

Consideremos o experimento aleat´orio em que desejamos simular o lan¸camento

de um dado e observar qual face est´a voltada para cima. Para simpliﬁcar, vamos olhar

apenas para o n´umero de vezes em que a face com o n´umero 1 aparece voltada para cima.

Neste experimento n˜ao temos a inten¸c˜ao de estimar a probabilidade, pois j´a a

conhecemos. O objetivo aqui ´e veriﬁcar mais uma vez o poder da Lei dos Grandes N´umeros

de Bernoulli e introduzir a ideia de simula¸c˜oes em planilhas eletrˆonicas.

Seja ri o resultado da fun¸c˜ao aleat´orioentre(1; 6). Para simular nosso lan¸camento

de dados, consideramos a vari´avel aleat´oria

Xi =





1

0

se ri ∈ {1}

se ri ∈ {2, 3, 4, 5, 6}

e deﬁnimos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

54

que ´e frequˆencia relativa da ocorrˆencia do evento de interesse.

A Figura 3.1 mostra o comportamento da vari´avel aleat´oria Mn para trˆes si-

mula¸c˜oes com 800 realiza¸c˜oes da vari´avel Xi em cada simula¸c˜ao. Assim como na simula¸c˜ao

do lan¸camento de moedas do cap´ıtulo anterior, podemos observar que Mn apresenta uma

estabiliza¸c˜ao conforme aumentamos o valor n.

Figura 3.1: Simula¸c˜oes na realiza¸c˜ao de 800 realiza¸c˜oes da vari´avel Xi.

Na Figura 3.2, temos o histograma de 500 simula¸c˜oes da vari´avel M20000 com

n = 20000 repeti¸c˜oes da vari´avel Xi.

Figura 3.2: Histograma para 500 simula¸c˜oes da vari´avel aleat´oria M20000.

Tomando ε = 2 · 10−2, e n = 20000 a Lei dos Grandes N´umeros garante que a

probabilidade m´axima de Mn estar no intervalo (p − ε, p + ε) ´e

p (Mn ∈ (p − ε, p + ε)) ≥ 1 −

1
4nε2 = 1 −

1

4n · 4 · 10−4 = 1 −

10000
16 · 20000

=

31
32

.

55

Isto ´e, em aproximadamente 97% das vezes teremos Mn no intervalo (p − ε, p + ε).

3.3 Simula¸c˜ao de provas

Considere que uma pessoa ir´a fazer uma prova, composta por 10 quest˜oes, do

tipo verdadeiro ou falso, mas que n˜ao possui conhecimento algum sobre o assunto que

ser´a abordado na mesma, ou seja, esta pessoa ir´a responder as quest˜oes de forma total-

mente aleat´oria. Qual ´e a probabilidade dessa pessoa conseguir responder corretamente

k quest˜oes com k ∈ {0, 1, 2, · · · , 10}? Em outras palavras, queremos estimar a probabili-

dade de uma pessoa, que “chuta”todas as respostas de uma prova desse tipo, responder

corretamente k quest˜oes.

O espa¸co amostral Ω para este caso ´e constitu´ıdo por todas as formas que se

pode responder as 10 quest˜oes dessa prova. Logo, como cada quest˜ao pode ser respondida

apenas como falsa ou verdadeira, temos que #(Ω) = 210.

Consideraremos o evento A que consiste em responder corretamente k quest˜oes.

Para isto, consideremos a vari´avel aleat´oria:

Qi =





1

0

se qi for respondida corretamente;

se qi n˜ao for respondida corretamente.

Queremos estimar a probabilidade da vari´avel aleat´oria

S = Q1 + Q2 + · · · + Q10

assumir o valor k.

Para estimar a probabilidade do evento de interesse por meio de uma planilha

eletrˆonica vamos proceder da seguinte forma:

1. Consideramos que a quest˜ao qi foi respondida corretamente se a fun¸c˜ao aleat´orioentre(0; 1)

retornar o valor 1;

2. Deﬁnimos a vari´avel aleat´oria S = q1 + q2 + · · · + q10;

56

3. Finalmente, consideramos a vari´avel aleat´oria

X =





1

0

se S = k

se S (cid:54)= k

no qual k ´e ﬁxado.

Como estamos interessados na probabilidade de ocorrˆencia do evento acertar k

quest˜oes ent˜ao a Lei dos Grandes n´umeros nos diz que devemos olhar para a vari´avel

aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

.

Na Figura 3.3 temos uma estimativa para a distribui¸c˜ao de probabilidade da

vari´avel X para k = 1, 2, . . . , n. A probabilidade do acerto de exatamente k quest˜oes foi

estimada observando o valor da vari´avel Mn com n = 20000. De acordo com a Lei dos

Grandes N´umeros, Mn estima a probabilidade desejada com erro menor do que 2% em

aproximadamente 97% das observa¸c˜oes da vari´avel Mn.

Figura 3.3: Distribui¸c˜ao de probabilidade da vari´avel S.

Note que, de acordo com distribui¸c˜ao estimada, as chances de conseguir acertar

cinco quest˜oes em uma prova nas condi¸c˜oes descritas no problema, ´e muito maior do

que acertar 1 quest˜ao por exemplo. Note ainda que acertar 0 ou 10 quest˜oes possuem

probabilidades iguais.

57

3.4 Valor esperado de uma vari´avel aleat´oria

Podemos ainda utilizar as planilhas eletrˆonicas com a ﬁnalidade de se obter es-

timativas do valor esperado de uma vari´avel aleat´oria, conforme vamos descrever nessa

se¸c˜ao.

Considerando um espa¸co amostral Ω = {e1, e2, e3} no qual p(e1) = p1, p(e2) = p2

e p(e3) = p3 s˜ao as probabilidade de ocorrˆencia de cada um dos eventos elementares.

Consideremos ainda a vari´avel aleat´oria

X =






a

b

c

se e1 ocorre

se e2 ocorre

se e3 ocorre

E(X) = a · p1 + b · p2 + c · p3.

ent˜ao a esperan¸ca de X ´e

Se as probabilidades s˜ao desconhecidas, podemos estimar o valor de E(X) uti-

lizando estimativas para p1, p2 e p3. O mesmo argumento pode ser utilizado para obter

o valor esperado de uma vari´avel aleat´oria discreta com um n´umero ﬁnito qualquer de

poss´ıveis resultados.

Os pr´oximos exemplo ilustram o que foi discutido acima.

Exemplo: Um jogo consiste em lan¸car trˆes moedas e observar o n´umero de caras obtidos.

Se este n´umero for igual a 1, o apostador ganha R$ 2; se for 2 ganha R$ 2; se for 3 ganha

R$ 8 e, ﬁnalmente, se for 0 o apostador perde R$ 16.

Vamos considerar a seguinte vari´avel aleat´oria

X =






−16 se ocorrer 0 caras

2 se ocorrer 1 cara

4 se ocorrer 2 caras

8 se ocorrer 3 caras.

58

Com o objetivo de estimar o valor esperado da vari´avel aleat´oria X precisamos

estimar a probabilidade de ocorrˆencia dos eventos:

A = ocorrˆencia de 0 caras no lan¸camento de trˆes moedas;

B = ocorrˆencia de 1 caras no lan¸camento de trˆes moedas;

C = ocorrˆencia de 2 caras no lan¸camento de trˆes moedas;

D = ocorrˆencia de 3 caras no lan¸camento de trˆes moedas.

Para isto, procedemos da seguinte forma:

1. Para representar o lan¸camento de cada uma das moedas, deﬁnimos os valores ri, si

e ti como resultados da fun¸c˜ao aleat´orioentre(0; 1);

2. Consideramos a vari´avel aleat´oria S = ri + si + ti;

3. Deﬁnimos as vari´aveis X (A), X (B), X (C) e X (D) pondo

X (A) =

X (C) =





1

0





1

0

se S = 0

se S (cid:54)= 0

se S = 2

se S (cid:54)= 2

X (B) =

X (D) =









1

0

1

0

se S = 1

se S (cid:54)= 1

se S = 3

se S (cid:54)= 3

4. Consideramos as vari´aveis aleat´orias

M (A)

n =

M (B)

n =

M (C)

n =

M (D)

n =

X (A)

1 + X (A)

2 + · · · + X (A)

n +

n

;

X (B)

1 + X (B)

2 + · · · + X (B)

n +

n

;

X (C)

1 + X (C)

2 + · · · + X (C)

n +

n

;

X (D)

1 + X (D)

2 + · · · + X (D)

n +

n

59

como estimativas para a probabilidade de ocorrˆencia dos eventos A, B, C e D,

respectivamente;

5. Finalmente consideramos

E(Xn) = −16 · M (A)

n + 2 · M (B)

n + 4 · M (C)

n + 8 · M (D)

n

como a estimativa para a esperan¸ca da vari´avel aleat´oria X.

As Figuras 3.4 e 3.5 mostram o comportamento de E(Xn) para trˆes simula¸c˜oes

para diferentes realiza¸c˜oes de cada uma das vari´aveis aleat´orias X (A), X (B), X (C) e X (D).

Note que, conforme o n´umero de lan¸camentos aumenta o gr´aﬁco apresenta o mesmo

comportamento de estabilidade dos casos anteriores.

Figura 3.4: Simula¸c˜oes de E(Xn).

Figura 3.5: Simula¸c˜oes de E(Xn).

60

O histograma da Figura 3.6, feito a partir de 200 simula¸c˜oes com n = 5000

realiza¸c˜oes das vari´aveis aleat´orias X (A), X (B), X (C) e X (D) em cada simula¸c˜ao, mostra o

comportamento da estimativa E(Xn) do valor esperado de X.

Figura 3.6: Histograma de E(Xn) para 200 simula¸c˜oes com n = 5000.

Percebemos que para um grande n´umero de repeti¸c˜oes desse experimento o gr´aﬁco

tende a se estabilizar em torno de 1, 25 que admitimos ser a estimativa do valor esperado

da vari´avel aleat´oria X.

3.5

´Areas e volumes

Como vimos no Capitulo 1, a ´area de uma ﬁgura plana F inscrita num retˆangulo

R de lados h > 0 e k > 0 satisfaz a seguinte rela¸c˜ao:

a(F ) = p(F )hk,

no qual p(F ) ´e a probabilidade de ocorrˆencia de F quando consideramos o retˆangulo R

como o espa¸co amostral, de modo que podemos usar as planilhas eletrˆonicas para estimar

a ´area de uma ﬁgura F .

Para simpliﬁcar vamos supor que a ﬁgura plana F esteja inscrita em um retˆangulo

com v´ertices em (a, c), (b, c), (a, d) e (b, d).

61

Figura 3.7: Representa¸c˜ao gr´aﬁca do espa¸co amostral R e do evento F .

Considere ainda a vari´avel aleat´oria

X =





1

0

se (x, y) ∈ F

se (x, y) /∈ F,

Assim, p(X = 1) = p(F ).

Para estimarmos a probabilidade p(F ) podemos proceder da seguinte forma:

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, um ponto ri ∈ [a, b];

2. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, um ponto si ∈ [c, d];

3. Usamos algum crit´erio para decidir se o ponto (ri, si) ∈ F ;

4. Atribu´ımos o valor 1 para a vari´avel aleat´oria Xi caso (ri, si) ∈ F e 0 caso (ri, si) /∈

F ;

5. Consideramos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

que ser´a usado como a estimativa para p(F ).

No que segue o m´etodo acima para obter estimativas de ´area de algumas ﬁguras

planas.

62

Exemplo: Suponha que desejamos obter a ´area abaixo da reta y = 2x, com x ∈ [0, 2],

conforme representada na Figura 3.8.

Figura 3.8: Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

Neste exemplo, um ponto (a, b) pertence ao evento de interesse se b ≤ 2a. Este ´e

o crit´erio que vamos usar para decidir se (a, b) ∈ F . Assim:

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, pares ri ∈ [0, 2] e si ∈ [0, 4].

Este passo pode ser feito numa planilha eletrˆonica usando as seguintes express˜oes:

ri = 2 · aleatorio()

e

si = 4 · aleatorio().

2. Veriﬁcamos se si ≤ 2ri. Caso verdadeiro, atribu´ımos o valor 1 para Xi e o valor 0

caso seja falso;

3. Como ´ultimo passo, consideramos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

,

para a estimativa de p(F ) e ent˜ao

an(F ) = 8Mn

´e a estimativa para a ´area de F .

As Figuras 3.9 e 3.10 representam o comportamento das estimativas Mn(F ) para

n = 500 e n = 5000 realiza¸c˜oes da vari´avel aleat´oria X.

63

Figura 3.9: Estimativas Mn(F ) para n ≤ 500.

Figura 3.10: Estimativas Mn(F ) para n ≤ 5000.

Na ﬁgura 3.11 temos o histograma referentes a cem simula¸c˜oes de an(F ), cada

uma delas com n = 20000 realiza¸c˜oes da vari´avel aleat´oria X.

Figura 3.11: Histograma de observa¸c˜ao da vari´avel Mn(F ).

64

Analisando os dados acima, podemos perceber em ambos os gr´aﬁcos tendem a se

estabilizar em 1/2, que ´e justamente a por¸c˜ao da ´area ocupada pelo triˆangulo em rela¸c˜ao

ao retˆangulo em quest˜ao. Quanto maior o n´umero de repeti¸c˜oes que fazemos mais pr´oximo

desse valor ﬁcam as estimativas do valor 1/2, conforme garantido pela Lei dos Grande

N´umeros.

Vale fazer uma observa¸c˜ao importante sobre o erro na estimativa da ´area. Pela

p desconhecida, temos uma chance m´axima de

Lei dos Grandes N´umeros, ao considerarmos Mn como estimativa para a probabilidade
1
4nε2 de que Mn /∈ (p − ε, p + ε). No
1
4nε2 de que an /∈ (a − 8ε, a + 8ε). Por
exemplo, tomando ε = 2 · 10−2 e n = 20000 ent˜ao an ∈ (4.84, 5.16) com probabilidade de

caso da ´area, temos a probabilidade m´axima de

aproximadamente de 97%.

Exemplo: Vamos agora estimar a ´area da regi˜ao localizada abaixo da curva y = sen(x),

com x ∈ [0, π].

Figura 3.12: Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, pares ri ∈ [0, π] e si ∈ [0, 1].

Este passo pode ser feito numa planilha eletrˆonica usando as seguintes express˜oes:

ri = π · aleatorio()

e

si = aleatorio().

2. Veriﬁcamos se si ≤ sen(ri). Caso verdadeiro, atribu´ımos o valor 1 para Xi e o valor

0 caso seja falso;

65

3. Como ´ultimo passo, consideramos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

,

para a estimativa de p(F ) e ent˜ao

an(F ) = πMn

´e a estimativa para a ´area de F .

Na Figura 3.13 podemos ver o comportamento da estimativa Mn(F ). Novamente,

como garantido pela Lei do Grande N´umeros, temos a convergˆencia para o valor p(F ).

Neste caso, a ´area da ﬁgura F est´a estimada em 2, 04 unidades de ´area.

Figura 3.13: Estimativas Mn(F ) para n ≤ 5000.

Vale ressaltar que o gr´aﬁco da Figura 3.14 representa a propor¸c˜ao da ´area ocupada

pela ﬁgura F com rela¸c˜ao a ´area do retˆangulo.

Exemplo: Vamos agora estimar a ´area da regi˜ao localizada no interior de uma circun-

ferˆencia de raio 4 e centro (0, 0).

66

Figura 3.14: Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

Sabemos da geometria que esta ´area ´e igual 16π unidade de ´area mas vamos aqui

estim´a-la usado o mesmo m´etodo usados nos exemplos anteriores.

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, pares ri ∈ [−4, 4] e si ∈

[−4, 4]. Como anteriormente, este passo pode ser feito numa planilha eletrˆonica

usando as seguintes express˜oes:

ri = −4 + 8 · aleatorio()

e

si = −4 + 8 · aleatorio().

2. Veriﬁcamos se s2

i + r2

i ≤ 16. Caso verdadeiro, atribu´ımos o valor 1 para Xi e o valor

0 caso seja falso;

3. Finalmente consideramos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

,

para a estimativa de p(F ) e ent˜ao

an(F ) = 16Mn

´e a estimativa para a ´area de F .

Na Figura 3.15 podemos ver o comportamento da estimativa Mn(F ). Assim como

anteriormente, a Lei do Grande N´umeros garante a convergˆencia para o valor p(F ).

67

Figura 3.15: Estimativas Mn(F ) para n ≤ 5000.

Na ﬁgura 3.16 temos o histograma referentes a 400 simula¸c˜oes de Mn(F ), cada

uma delas com n = 5000 realiza¸c˜oes da vari´avel aleat´oria X.

Figura 3.16: Histograma de observa¸c˜ao da vari´avel Mn(F ).

Exemplo: Estimar a ´area da interse¸c˜ao entre a circunferˆencia x2 + y2 = 4 e a elipse

x2
16

+ y2 = 1

68

Figura 3.17: Representa¸c˜ao gr´aﬁca da regi˜ao de interesse.

Para estimar a ´area da regi˜ao de interesse podemo proceder da seguinte forma:

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, pares ri ∈ [−4, 4]esi ∈

[−2, 2]. Como anteriormente, este passo pode ser feito numa planilha eletrˆonica

usando as seguintes express˜oes:

ri = −4 + 8 · aleatorio()

e

si = −2 + 4 · aleatorio().

2. Veriﬁcamos se s2

i + r2
0 caso seja falso; Estimativa da elipse:

i ≤ 4. Caso verdadeiro, atribu´ımos o valor 1 para Xi e o valor

3. Veriﬁcamos se

r2
i
16
0 caso seja falso.

+ s2

i ≤ 1. Caso verdadeiro, atribu´ımos o valor 1 para Yi e o valor

4. Feito isso, devemos efetuar o produto Zi = XiYi para decidir se as duas condi¸c˜oes

s˜ao satisfeitas simultaneamente e ent˜ao consideramos a vari´avel aleat´oria

Mn =

Z1 + Z2 + · · · + Zn
n

para a estimativa de p(F ) e ent˜ao

´e a estimativa para a ´area de F .

an(F ) = 32Mn

69

Na Figura 3.18 vemos a convergˆencia da estimativa Mn(F ) da probabilidade

p(F ) que representa a propor¸c˜ao da ´area ocupada pela ﬁgura de interesse com rela¸c˜ao ao

retˆangulo.

Figura 3.18: Estimativas Mn(F ) para n ≤ 10000.

3.5.1 Volume de s´olidos

Assim com ﬁzemos para a ´area, podemos proceder de maneira semelhante para

estimar o volume de alguns s´olidos geom´etricos. Neste caso, consideremos com espa¸co

amostral o paralelep´ıpedo de arestas h, k e t positivos. Neste caso temos que

v(S) = p(S) · h · k · t.

Exemplo: Consideremos o problema de estimar o volume da esfera S deﬁnida por x2 +

y2 + z2 ≤ 4.

Neste caso, procedemos da seguinte forma:

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, ternas ri ∈ [−2, 2], si ∈

[−2, 2] e ti ∈ [−2, 2]. Como anteriormente, este passo pode ser feito numa planilha

eletrˆonica usando as seguintes express˜oes:

ri = −2 + 4 · aleatorio(), si = −2 + 4 · aleatorio() e ti = −2 + 4 · aleatorio().

2. Veriﬁcamos se s2

i + r2
valor 0 caso seja falso.

i + t2

i ≤ 4. Caso verdadeiro, atribu´ımos o valor 1 para Xi e o

70

3. Finalmente consideramos a vari´avel aleat´oria

Mn =

X1 + X2 + · · · + Xn
n

,

para a estimativa de p(S) e ent˜ao

vn(S) = 64Mn

´e a estimativa do volume de S.

Na Figura 3.19 vemos a convergˆencia da estimativa Mn(S) para a probabilidade

p(S) de modo que podemos estimar o volume de S pela express˜ao vn(S) = 64Mn.

Figura 3.19: Estimativas Mn(F ) para n ≤ 10000.

Exemplo: Consideremos o problema de estimar o volume da interse¸c˜ao entre esfera

x2 + y2 + z2 = 4 e a elipsoide

x2 +

y2
9

+

z2
4

= 1.

Neste caso, procedemos da seguinte forma:

1. Escolhemos aleatoriamente, com distribui¸c˜ao uniforme, ternas ri ∈ [−2, 2], si ∈

[−3, 3] e ti ∈ [−2, 2];

2. Veriﬁcamos se s2

i + r2
valor 0 caso seja falso;

i + t2

i ≤ 4. Caso verdadeiro, atribu´ımos o valor 1 para Xi e o

3. Veriﬁcamos se

r2
i +

s2
i
9

+

t − i2
4

≤ 1.

71

Caso verdadeiro, atribu´ımos o valor 1 para Yi e o valor 0 caso seja falso;

4. Feito isso, devemos efetuar o produto Zi = XiYi para decidir se as duas condi¸c˜oes

s˜ao satisfeitas simultaneamente e ent˜ao consideramos a vari´avel aleat´oria

Mn =

Z1 + Z2 + · · · + Zn
n

para a estimativa de p(S) e ent˜ao

vn(S) = 32Mn

´e a estimativa para o volume de S.

Na Figura 3.20 vemos a convergˆencia da estimativa Mn(S) para o valor p(S).

Como anteriormente a estimativa Mn(S), representa a propor¸c˜ao da volume ocupado

pelo s´olido de interesse com rela¸c˜ao ao paralelep´ıpedo circunscrito.

Figura 3.20: Estimativas Mn(F ) para n ≤ 10000.

3.6 Probabilidade em jogos de futebol

Por meio de simula¸c˜oes tamb´em ´e poss´ıvel estimar a probabilidade de um deter-

minado time ser campe˜ao em um determinado torneio.

Vamos considerar que em um campeonato de futebol faltam trˆes rodadas para

seu ﬁnal e os times que podem ser campe˜oes possuem os seguintes quantidades de pontos:

1. Equipe A, 55 pontos;

72

2. Equipe B, 54 pontos;

3. Equipe C, 52 pontos;

4. Equipe D, 50 pontos;

Queremos estimar a probabilidade da equipe A ser a campe˜a isolada do campeo-

nato. Deﬁniremos que todas as equipes tˆem a mesma qualidade, ou seja, em qualquer jogo

todas as equipes tˆem iguais chances de vencer e, al´em disso, vit´orias, empates e derrotas

tem iguais chance de acontecer a qualquer equipe.

As probabilidades de um time vencer, empatar ou perder para outro, pode ser

atribu´ıda de forma diferente a que estamos fazendo aqui, ´e assim que se faz na pr´atica, pois

n˜ao pode um time que lidera o tornei ter mesma probabilidade de vencer um determinado

jogo do que um time que ocupa a ultima posi¸c˜ao. Mas, como j´a mencionamos, n˜ao

levaremos isso em considera¸c˜ao neste trabalho.

O experimento consiste em atribuir a uma vari´avel aleat´oria os seguintes valores

X =






0 se o time perder;

1 se o time empatar;

2 se o time vencer

Para isso, usaremos a fun¸c˜ao aleat´orioentre(0; 2) e programaremos a planilha

eletrˆonica para retornar 0 caso o n´umero sorteado seja 0, 1 caso seja 1 e 3 caso o n´umero

sorteado seja 3. E claro que se o time A joga contra o time B, esses n´umeros est˜ao condi-

cionados, ou interligados, uma vez que, no jogo entre as equipes A e B, se para a equipe

A foi sorteado o n´umero 2, torna autom´atico que a planilha eletrˆonica retorne o n´umero

0 para a equipe B, mas isso ´e f´acil de programar.

Feito isso, devemos programar a planilha eletrˆonica para contar os pontos ganhos

por todas as equipes e para retornar o n´umero 1, toda vez que a equipe A, ao ﬁm das 5

rodadas, possuir o maior n´umero de pontos e 0 caso contr´ario.

73

Fizemos isso 5000 vezes e veriﬁcamos que nestas condi¸c˜oes o time foi campe˜ao

em aproximadamente 60% das vezes. Assim podemos estimar que a probabilidade de o

time A ser campe˜ao ´e de 0, 6.

Figura 3.21: Simula¸c˜ao da frequˆencia relativa para 5000 repeti¸c˜oes.

Note que, obter esse valor usando a deﬁni¸c˜ao cl´assica ´e poss´ıvel, mas tamb´em ´e

no m´ınimo trabalhoso, pois, estamos analisando 5 times que jogar˜ao 3 vezes, cada um,

totalizando 9 jogos, considerando que os times n˜ao jogam entre si. Para cada jogo temos

3 resultados poss´ıveis, vit´oria de um time, empate e vitoria do outro time, assim ter´ıamos

de analisar 320 = 3486784401 poss´ıveis resultados. Os quais se fossemos analisar todos,

gastando em m´edia 1 segundo para analisar cada resultado, demorar´ıamos mais de 100

anos para terminar, o que n˜ao ´e uma informa¸c˜ao das mais animadoras.

74

Considera¸c˜oes ﬁnais e trabalhos

futuros

Neste trabalho apresentamos uma proposta alternativa ao ensino de probabi-

lidade, em n´ıvel de ensino m´edio, por meio de simula¸c˜oes em planilhas eletrˆonicas e

abordando problemas diferenciados dos abordados no livros did´aticos tradicionais. Ob-

servamos o qu˜ao surpreendente pode ser o uso de planilhas eletrˆonicas para estimar pro-

babilidades de eventos interessantes que, muitos deles, n˜ao ´e poss´ıvel obter pelos m´etodos

convencionais. O que a princ´ıpio nos parecia uma tarefa muito complicada e desinteres-

sante se mostrou uma ferramenta simples, interessante e muito ´util.

O ensino de probabilidade, que ´e t˜ao temido por alunos e em alguns casos, at´e

mesmo por professores, pode se tornar interessante e divertido com o aux´ılio das planilhas

eletrˆonicas.

Percebemos que o ensino de probabilidade pode ser feito em conjunto com outras

´areas da matem´atica, tais como, a geometria plana e espacial e a geometria anal´ıtica, o

que acreditamos contribuir como fonte de motiva¸c˜ao para o estudo destas ´areas citadas.

Este trabalho nunca teve a pretens˜ao de ser uma fonte deﬁnitiva de m´etodos e

problemas para o uso em sala de aula por parte de alunos e professores. Longe disso,

buscamos apenas trilhar superﬁcialmente um caminho que pode nos levar a lugares sur-

preendente na busca por um ensino mais motivante e relacionado com o nosso tempo.

Pretendemos aprofundar um pouco mais nos problemas, explorando alternativas
que foram abandonada no meio do caminho por motivos de for¸cas maiores. ´E de nosso

interesse levar as atividades aqui propostas para sala de aula, apresentado para alunos e

at´e mesmo professores como forma alternativa no ensino de probabilidades.

Finalmente, como trabalho futuro, pretendemos desenvolver uma esp´ecie de ma-

nual t´ecnico detalhando como professores e alunos podem fazer uso das planilhas eletrˆonicas

75

e probabilidade como ferramentas na busca da solu¸c˜ao de problemas.

76

Referˆencias Bibliogr´aﬁcas

[1] T. M. APOSTOL. Calculus, one-variable, with na introduction to linear algebra,

volume 1. Revert´e, Barcelona - Espanha, 2ª edition, 1988.

[2] H. EVES. Introdu¸c˜ao `a Hist´oria da Matem´atica. Editora da Unicamp, Campinas,

2004.

[3] G. IEZZI. Matem´atica: Ciˆencia e Aplica¸c˜oes., volume 2. Saraiva, S˜ao Paulo, 6ª

edition, 2010.

[4] J. R. JULIANELLI. Curso de Analise Combinat´oria e Probabilidade. Ciˆencia Mo-

derna, Rio de Janeiro, 1ª edition, 2009.

[5] E. L. LIMA. A Matem´atica do Ensino M´edio, volume 2. SBM, Rio de Janeiro, 6ª

edition, 2006.

[6] M. N. MAGALH ˜AES. Probabilidade e Vari´aveis Aleat´orias. Edusp, S˜ao Paulo, 2ª

edition, 2006.

[7] P. C. P.; PITOMBEIRA J. B.; FERNANDEZ P. MORGADO, A. C.; CARVALHO.
´Analise Combinat´oria e Probabilidade com as solu¸c˜oes dos exerc´ıcio. SBM, Rio de
Janeiro, 9ª edition, 1991.

[8] M. NETO, P. L. O. C.; CYMBALISTA. Probabilidades. Edgard Blucher, S˜ao Paulo,

2ª edition, 2005.

[9] M P; CALZOLARI I T SANTOS, J P O; MELLO. Introdu¸c˜ao `a ´Analise Combinat´oria.

Editora da Unicamp, Campinas, 3ª edition, 2002.

77


Universidade Federal do Piauí
Centro de Ciências da Natureza
Pós-Graduação em Matemática
Mestrado Profissional em Matemática
PROFMAT

Cadeias de Markov no Estudo de Probabilidade no

Ensino Médio.

Fernando Saraiva do Rego Junior

Teresina
2019

Fernando Saraiva do Rego Junior

Dissertação de Mestrado:

Cadeias de Markov no Estudo de Probabilidade no Ensino Médio.

Dissertação

submetida

à Coordenação

Acadêmica Institucional do Programa de

Mestrado Proﬁssional em Matemática em

Rede Nacional na Universidade Federal

do Piauí, oferecido em associação com a

Sociedade Brasileira de Matemática, como

requisito parcial para obtenção do grau de

Mestre em Matemática.

Orientador:
Profo. Dr. Jeﬀerson Cruz dos Santos Leite.

Teresina

2019

 1                           FICHA CATALOGRÁFICA Serviço de Processamento Técnico da Universidade Federal do Piauí Biblioteca Setorial do CCN                    Bibliotecária : Caryne Maria da Silva Gomes / CRB3-1461     R343c     Rego Júnior, Fernando Saraiva do.       Cardeias de Markov no estudo de probabilidade no ensino médio / Fernando Saraiva da Rego Júnior. – Teresina, 2019.          53 f.: il.  Dissertação (Mestrado Profissional) – Universidade Federal do Piauí, Centro de Ciências da Natureza, Pós-Graduação em Matemática - PROFMAT, 2019. Orientador: Prof. Dr. Jefferson Cruz dos Santos Leite  1. Probabilidade. 2. Processos Estocásticos. 3. Cadeia de Markov.  I. Título.           CDD 519.2 Agradecimentos

Agradeço primeiramente a Deus por ter me dado forças nos momentos mais difíceis,

momentos esses onde várias vezes pensei em desistir, mas através das minhas orações e

perseverança não deixaram que eu fraquejasse.

Aos meus pais, Fernando Saraiva do Rego (in Memorian) e Iracy Rio Lima do Rego,

que mesmo com todas as diﬁculdades ﬁnanceiras nunca deixaram de me incentivar nos

estudos.

A minha querida esposa, Luana Sevia, por sempre ter me apoiado e acreditado em mim

durante toda minha trajetória, mesmo nos momentos mais difíceis.

As minhas princesas Maria Fernanda e Isadora, que foram frutos desse mestrado e que

serviram como um incentivo a mais para minha caminhada.

Aos meus irmãos, Erton, Marcia, Iramara, Claudia e Najara, que sempre torceram pelo

meu sucesso.

Aos meus sobrinhos e aﬁlhados, que sempre torceram pelo meu sucesso e que todos nunca

deixem de acreditar nos estudos, pois estarei sempre cobrando.

Aos meus sogros, cunhados e cunhadas, por sempre depositar em mim conﬁança e respeito.

A todos (as), primos (as), tios (as), avós e avôs, que torceram por mim.

Aos meus amigos: Leonardo, Valter, Fabio, Fernando, Ronaldo e Jeﬀerson que sempre

estiveram presentes nos feriados e ﬁnais de semana pra me incentivar.

A todos os meus amigos IFMA, em especial: Jackellynne, Mackleia, Fabbio, Chaguinha,

Edson por terem me incentivado e apoiado.

Aos meus amigos do Profmat: Andrelino, André, Jaqueline, Marina, Lucas, Raphaell,

Irismar, Erivelton pelos ensinamentos e auxílios durante o curso.

A todos os professores do departamento de matemática da UFPI, em especial o professor

Jeﬀerson Leite por terem me dado a honra de ser orientado por ele e ter contribuído com

a conclusão deste trabalho.

A todos os professores que se ﬁzeram presentes nessa minha caminhada desde o ensino

básico, pois só quem é professor sabe das diﬁculdades dessa proﬁssão que é tão desvalori-

zada em nosso país, mas que ao mesmo tempo é gratiﬁcante pelos resultados que ela nos

proporciona.

Resumo

Nesmmmmte trabalho abordamos inicialmente um resumo de probabilidade com um

contexto histórico dos principais matemáticos que contribuíram com o desenvolvimento

da teoria das probabilidades, conceitos, exemplos e aplicações no nosso cotidiano. No

capitulo que trata sobre Processos Estocásticos foram apresentadas deﬁnições e exemplos

com ênfase em cadeias de Markov. Apesar de ser um conteúdo pouco abordado, até

mesmo no ensino superior em cursos de Licenciatura em Matemática, cadeias de Markov

é um conteúdo com vastas aplicações no nosso cotidiano e que podemos levar para sala de

aula para ser trabalhado junto com os conteúdos de Estatística e Probabilidade. Nosso

trabalho ainda conta com aplicações em jogos de futebol através de tabelas e gráﬁcos que

facilitam o entendimento, aprendizado e análises dos resultados obtidos.

Palavras–chave: Probabilidade, Processos Estocásticos e Cadeia de Markov.

Abstract

In this work, we initially approached a probability summary with a historical context

of the main mathematicians who contributed to the show of the theory of probabilities,

concepts, examples and applications in our daily life. Deﬁnitions and examples with

emphasis on Markov chains were made in the section dealing with Stochastic Processes.

In spite of being a little addressed content, even in higher education in undergraduate

courses in mathematics, Markov chains is content with vast applications in our daily life

and that we can take to classroom to be worked together with the contents of Statistics

and Probability. Our work also has applications in soccer games through tables and

graphs that facilitate the understanding, learning and analysis of the results obtained.

Keywords: Probability, Stochastic Processes and Markov Chain.

Sumário

Introdução

1 Contexto histórico e deﬁnições sobre Probabilidades

p. 10

p. 12

1.1 Probabilidade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 15

1.1.1 Probabilidade de Ocorrer um Evento . . . . . . . . . . . . . . .

p. 15

1.1.2 Probabilidade da União de dois Eventos

. . . . . . . . . . . . .

p. 17

1.1.3 Probabilidade Condicional

. . . . . . . . . . . . . . . . . . . . .

p. 20

1.1.4

Independência de dois eventos . . . . . . . . . . . . . . . . . . .

p. 22

1.2 Processos Estocásticos

. . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 25

2 Cadeias de Markov

p. 27

2.1 Equações de Chapman – Kolmogorov . . . . . . . . . . . . . . . . . . .

p. 31

2.2 Classiﬁcação dos Estados de Uma Cadeia de Markov . . . . . . . . . .

p. 34

2.2.1 Estado Transiente . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 34

2.2.2 Estado Recorrente

. . . . . . . . . . . . . . . . . . . . . . . . .

p. 35

2.2.3 Estado Absorvente . . . . . . . . . . . . . . . . . . . . . . . . .

p. 36

2.2.4 Estado Periódico . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 37

2.3 Cadeias Ergódicas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 39

2.4 Probabilidade de estado no Equilíbrio e tempo médio de retorno de Ca-

deias Ergódicas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

p. 40

3 Aplicações utilizando Cadeias de Markov

4 Considerações Finais

p. 43

p. 54

Referências

p. 55

10

Introdução

Quem nunca sonhou em ganhar na loteria ou em um simples bingo? Quando pensamos

em jogos sejam eles de azar ou não a primeira coisa que nos vem à cabeça é o fator sorte

como principal motivo pra ser ou não sorteado. Na matemática não trabalhamos os jogos

ou sorteios como fator sorte, mas como um ramo da matemática que estuda as chances

de um determinado resultado ocorrer em função do seu espaço amostral. Esse ramo é

conhecido como teoria das probabilidades.

Quando lançamos um dado sem que haja algum tipo de interferência externa, temos

como resultados esperados os números: 1, 2, 3, 4, 5 ou 6. Muitos apostadores por não

terem o conhecimento matemático acreditam que o fator sorte pode interferi no resultado,

entretanto a probabilidade de ocorrer qualquer um dos números a cima é a mesma.

Ser sorteado em um jogo da loteria federal é um sonho de muitos brasileiros, a grande

maioria acredita que só ganha quem tem sorte. Se você está entre esses brasileiros que

acreditam apenas no fator sorte, ﬁque sabendo que todos os apostadores têm a mesma

probabilidade de ganhar um prêmio na loteria, entretanto devemos ressaltar que essa

probabilidade pode sofrer variações para mais ou para menos dependendo do número de

bilhetes que cada jogador apostou, pois quanto maior o número de bilhetes maior será a

chance de ganhar o prêmio.

É muito comum e presente na nossa sociedade acreditar no fator sorte quando se fala

em jogos, entretanto nós matemáticos devemos sempre optar por um caminho que nos

leve à construção lógica da verdade, que seja naturalmente sistematizável e traduzível

para uma linguagem simbólica. Através do estudo das teorias das probabilidades é que

iremos estabelecer todas as possibilidades de ser ou não sorteado em um determinado

jogo.

O nosso trabalho consiste em um estudo que envolve teoria das probabilidades e

cadeias de Markov. No primeiro capítulo iremos trabalhar deﬁnições e aplicações da

teoria das probabilidades que são usadas no ensino médio, tais como: Probabilidade de

ocorrer um evento, União de eventos, Probabilidade de Ocorrer eventos independentes e

Probabilidade condicional. Nesse capítulo iremos também introduzir a ideia de processos

11

Estocásticos e algumas aplicações.

No segundo capítulo abordemos os conceitos e deﬁnições de cadeias de Markov. Mos-

tramos um pouco do contexto histórico e os principais matemáticos que contribuíram para

o estudo das cadeias de Markov. Abordaremos também as classiﬁcações e exemplos de

cadeias de Markov através de matrizes e gráﬁcos.

No terceiro capítulo traremos uma aplicação de cadeias de Markov envolvendo os jogos

de futebol, mais especiﬁcamente algumas partidas de futebol da seleção brasileira durante

a copa do mundo de 2002. Fizemos o uso de tabelas, gráﬁcos e do programa Matlab para

um melhor entendimento da aplicação.

12

1 Contexto histórico e deﬁnições

sobre Probabilidades

Desde primórdios da nossa civilização, a teoria das probabilidades vem intrigando

a nossa população, é claro que tal teoria não era tão desenvolvida e organizada como

se encontra hoje. Tudo começou a partir de simples jogos de azar tais como:

jogos

de dados, jogos de cartas e outros. Pinturas em tumbas egípcias feitas em 3500 A.C.

mostram pessoas jogando uma forma primitiva de dados feitos de um osso do calcanhar

de nome astrágalos. A cerâmica grega é uma evidência para mostrar que havia um círculo

desenhado no chão e atirava–se o astrágalo para esse círculo, similarmente como se joga

bolas de gude. No Egito, escavadores de túmulos descobriram um jogo chamado “cães

de caça e os chacais”, que se assemelha ao jogo moderno “cobras e escadas”. Parece

que esta é a fase inicial da criação dos dados de jogo. O desenvolvimento das teorias

da probabilidade e os avanços dos cálculos probabilísticos devem ser atribuídos a vários

matemáticos. Dentre os mais importantes, podemos citar:

• Niccolò Fontana (1500 – 1557) foi um matemático italiano, cujo nome está li-

gado ao triângulo de Tartaglia e à solução da equação do terceiro grau. Conhecido

como Tartaglia, publicou sua obra General Trattato, em 1556, que dedicava algu-

mas páginas aos problemas propostos por Pacioli, dentre eles o problema dos pontos.

Coloca–se assim tal problema: um jogo equitativo termina quando um dos jogado-

res vencer seis partidas. Suponha-se que por algum motivo o jogo tenha que ser

interrompido quando o primeiro jogador tenha vencido cinco partidas e o segundo

apenas três. Como as apostas devem ser repartidas? Niccolò argumentou que a

divisão deveria ser 5 : 3, que não é correta; a solução correta para esse problema foi

dada mais tarde por Fermat e Pascal.

• Girolamo Cardano (1501 – 1576) foi um polimata italiano. Escreveu mais

de 200 trabalhos sobre medicina, matemática, física, ﬁlosoﬁa, religião e música.

Na matemática foi o primeiro a introduzir as ideias gerais da teoria das equações

13

algébricas. Seu hábito de jogar também o levou a formular as primeiras regras da

teoria da probabilidade, em 1526 escreve o livro Liber de Ludo Aleae (Livro dos

jogos de azar) resolvendo vários problemas de enumeração e retoma os problemas

levantados por Luca Pacioli. A obra de Cardano, contudo, só veio a ser publicada em

1663. Cardano pensou sobre o lançamento de três dados. Se três dados são lançados

simultaneamente: há o mesmo número de maneiras de obter-se um total de 9 como

há de 10. Para um 9: (621) (531) (522) (441) (432) (333) e para 10: (631) (622)

(541) (532) (442) (433). A partir disso, Cardano descobriu que a probabilidade de

obter 9 é menor do que a obter–se um 10 (aqui, interessam também as permutações

envolvidas, os arranjos, a ordem em que os dados mostram seus resultados, e não

só as combinações dos resultados possíveis dos dados, de onde, por exemplo, uma

possibilidade – permutação – de 621, também implica 612, 216, 261, 126 e 162). Ele

também demonstrou a eﬁcácia da deﬁnição de chances como o razão entre favorável a

evolução desfavorável (o que implica que a probabilidade de um evento é dada pela

proporção de resultados favoráveis para o número total de possíveis resultados).

Cardano relata em sua autobiograﬁa, De Propria Vita que era viciado em jogos.

Escreve que havia jogado xadrez por 40 anos e dados por 25 anos. Em 1534 obteve

a cadeira de matemática em Milão.

• Galileu Galilei (1564 – 1642) também publicou um manual sobre jogos, o Con-

siderações sobre o Jogo de Dados. Essencialmente pensado sobre o problema de

Cardano, sobre a probabilidade de obter-se um total de 9 é menor do que jogando

um 10. Galileu teve o seguinte a dizer: Certos números têm a capacidade de serem

jogados porque há mais maneiras de criar esse número. Embora 9 e 10 tenham o

mesmo número de maneiras de ser criados, 10 é considerado por jogadores de dados

como sendo um resultado mais comum do que 9.

• Pierre de Fermat (1601 – 1665) foi um matemático e cientista francês que se

destacou na Teoria da Probabilidade. Os seus avanços nesta área deram-se por

volta de 1654, quando passou a trocar cartas com Pascal. A probabilidade, um

assunto desconhecido por Fermat até então, passou a objetivar descobrir as regras

matemáticas que descrevessem com maior precisão as leis do acaso. Posteriormente,

ambos determinaram as regras essenciais da probabilidade, e Pascal chegou até

mesmo a convencer–se que poderia utilizar as suas teorias para justiﬁcar a fé em

Deus. Mais especiﬁcamente numa carta datada de 24 de agosto de 1654, endereçada

a Pascal, Fermat discute o seguinte problema: dois jogadores A e B, quando A

precisa de 2 pontos para ganhar e B de 3 pontos, o jogo será certamente decidido

em quatro jogadas. Para saber quem tem mais hipóteses de ganhar, o matemático

escreve todas as combinações possíveis entre as letras a, que representa uma jogada

em favor do jogador A e b, que representa uma em favor do jogador B:

14

– 01 – aaaa 09 – baaa;

– 02 – aaab 10 – baab;

– 03 – aaba 11 – baba;

– 04 – aabb 12 – babb;

– 05 – abaa 13 – bbaa;

– 06 – abab 14 – bbab;

– 07 – abba 15 – bbba;

– 08 – abbb 16 – bbbb.

Assim sendo, num total de 16, há 11 casos favoráveis a A e 5 favoráveis a B, visto

que a ocorrência de 2 ou mais a é favorável a A e a ocorrência de 3 ou mais b a B. A

solução dada por Pascal é a seguinte: suponhamos que cada um dos jogadores aposte a

mesma quantia, 32 pistolas (moeda da época), aquele que tirar primeiramente três vezes,

seguidas ou não, o número que aposta no dado, de 1 a 6, ganhará, num total de quatro

partidas.

• Jacob Bernoulli (1654 – 1705) publicou a primeira integração de uma equação

diferencial; deu solução ao problema dos isoperímetros, que abriu caminho ao cálculo

das variações de Euler e Lagrange e estendeu suas principais aplicações ao cálculo das

probabilidades. A obra Ars Conjectandi (póstuma, 1713) e The Doctrine of Chances

(A Doutrina de Chances, 1718) de Abraham de Moivre colocou a probabilidade em

um patamar de campo da matemática, mostrando como calcular uma ampla gama

de probabilidades complexas. Bernoulli mostrou uma versão fundamental da lei dos

grandes números, o que indica que, num grande número de ensaios, a média dos

resultados é susceptível de ser muito próximo do valor desejado – por exemplo, em

1000 lançamentos de uma moeda são prováveis que ocorram cerca de 500 resultados

“cara” (e quanto maior o número de lances, o mais perto de “metade” a proporção é

provável que situe–se).

• Pierre Simon Laplace (1749 – 1827) foi um matemático, astrônomo e físico

francês. Embora tenha conduzido pesquisas substanciais sobre física, outro tema

15

principal dos esforços de sua vida foi a teoria das probabilidades. Em 1812 Laplace

publicou seu Théorie analytique des probabilités. O método de estimar a proporção

do número de casos favoráveis, comparado ao número total de casos possíveis, já

havia sido indicado por Laplace em um artigo escrito em 1779. Ele consiste em

tratar os valores sucessivos de qualquer função como coeﬁcientes na expansão de

outra função, com referência a uma variável diferente. A última é, portanto, cha-

mada de função geradora da primeira. Laplace então mostra como, por meios da

interpolação, esses coeﬁcientes podem ser determinados a partir da função geradora.

Em seguida, ele ataca o problema converso e, a partir dos coeﬁcientes, encontra a

função geradora; isso é obtido pela solução de uma equação com diferenças ﬁnitas.

O método é trabalhoso e leva na maior parte das vezes para uma distribuição normal

de probabilidades, a chamada distribuição Laplace–Gauss.

1.1 Probabilidade

De uma maneira informal, Probabilidade é o estudo de todos os resultados possíveis

de ocorrer em um experimento aleatório.

Experimentos Aleatórios são experimentos que quando realizados sobre as mesmas

condições apresentam diferentes resultados. O lançamento de um dado não viciado é

um experimento aleatório, visto que a cada vez que o dado é lançado obtemos diferentes

resultados.

Espaço Amostral (Ω) são todos os resultados possíveis em um experimento aleatório,

no caso de um dado temos como espaço amostral os números naturais de 1 a 6.

Eventos são subconjuntos do espaço amostral, no lançamento de um dado podemos ter
como Evento sair um número par, neste caso o nosso evento séria o conjunto A = {2, 4, 6}.

O Evento pode ser classiﬁcado em Evento Certo, quando o conjunto dos elementos que

formam o evento for igual ao conjunto dos elementos do Espaço Amostral. Evento é

Impossível quando o conjunto dos elementos que forma o evento não estiver contido no

espaço amostral.

1.1.1 Probabilidade de Ocorrer um Evento

A probabilidade de ocorrer um evento é igual à razão entre o número de elementos do

evento sobre o número de elementos do espaço amostral.

16

P(A) =

Número de Elementos do Evento
Número de elementos do Espaço Amostral

=

n(A)
n(Ω)

Exemplo 1.1. Qual a probabilidade de obtermos um número maior que 2 no lançamento

de um dado não viciado?

Solução: Nesse caso temos como espaço amostral o conjunto Ω = {1, 2, 3, 4, 5, 6} com
6 elementos e como evento o conjunto E = {3, 4, 5, 6} com 4 elementos. Desta forma seja

A á probabilidade de ocorre um número maior que 2 é:

P(A) =

n(A)
n(Ω)

=

4
6

= 0, 666 . . .

Exemplo 1.2. No lançamento de dois dados não viciados, qual a probabilidade de obter-

mos dois números iguais?

Solução: Espaço amostral Ω = {(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3),

(2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5),
(4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)}.

Evento A dois números iguais, A = {(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)}.

P(A) =

n(A)
n(Ω)

=

6
36

=

1
6

= 0, 1666 . . .

A probabilidade de ocorrer um Evento Certo será igual 1 pois, número de elementos do

evento é igual ao número de elementos do Espaço Amostral, caso o Evento seja Impossível

a probabilidade de ocorrer será igual a zero.

• Evento Certo (A): Como n(A) = n(Ω), temos que:

P(A) =

n(A)
n(Ω)

=

n(A)
n(A)

= 1

• Evento Impossível (A): Como n(A) = 0, temos que:

P(A) =

n(A)
n(Ω)

=

0
n(A)

= 0

Seja A um evento qualquer, termos que:

0 (cid:54) P(A) (cid:54) 1.

Exemplo 1.3. Considere o espaço amostral Ω = {a1, a2, a3, a4} e a distribuição de
probabilidades, tal que: P1 = P2 = P3 e P4 = 0, 1. Calcule:

17

a) P1, P2 e P3.

b) Seja A o evento A = {a1, a2}. Calcule P(A).

Solução: Temos que o espaço amostral Ω = {a1, a2, a3, a4}, logo:

P1 + P2 + P3 + P4 = 1,

por hipótese temos P1 = P2 = P3 e P4 = 0, 1, ou seja:

P1 + P2 + P3 + P4 = 1

P1 + P1 + P1 + P4 = 1

3 · P1 + P4 = 1

3 · P1 + 0, 1 = 1

3 · P1 = 1 − 0, 1

3 · P1 = 0, 9
0, 9
3

P1 =

P1 = 0, 3.

Seja A o evento A = {a1, a2}, temos que P1 = P2 = 0, 3 e que o evento A é formado

por a1, a2, logo:

P(A) = P1 + P2

P(A) = 0, 3 + 0, 3

P(A) = 0, 6.

1.1.2 Probabilidade da União de dois Eventos

Se A e B são eventos, então P(A ∪ B) = P(A) + P(B) − P(A ∩ B).

Fonte: De autoria

Demonstração. Da teoria de conjuntos temos que:

N(A ∪ B) = N(A) + N(B) − N(A ∩ B)

18

Dividindo ambos os membros da equação pelo número de elementos do Espaço Amos-

tral (Ω), Temos que:

N(A ∪ B)
N(Ω)

=

N(A)
N(Ω)

+

N(B)
N(Ω)

−

N(A ∩ B)
N(Ω)

Logo, temos que: P(A ∪ B) = P(A) + P(B) − P(A ∩ B).

Exemplo 1.4. Uma urna contém 20 bolas numeradas de 1 a 20. Quando uma bola é

retirada ao acaso, qual é a probabilidade do número ser múltiplo de 3 ou de 5?

Vamos resolver a questão utilizando a fórmula da probabilidade da união de dois

eventos. Sejam:

P(A) = Probabilidade de o número ser múltiplo de 3.

P(B) = Probabilidade de o número ser múltiplo de 5.

P(A ∩ B) = Probabilidade de o número ser múltiplo de 3 e 5.

Temos:

i) Existem 6 números múltiplos de 3 entre 1 e 20.

P(A) =

6
20

ii) Existem 4 números múltiplos de 5 entre 1 e 20.

P(B) =

4
20

.

iii) Apenas o número 15 é múltiplo de 3 e 5 ao mesmo tempo, quando analisamos os

números entre 1 e 20.

Logo temos que:

P(A ∩ B) =

1
20

.

P(A ∪ B) = P(A) + P(B) − P(A ∩ B).

P(A ∪ B) =

P(A ∪ B) =

+

4
20

−

1
20

.

.

6
20
9
20

Teorema 1.1. Seja A um evento qualquer e Ac o complementar desse evento, então
P(Ac) = 1 − P(A).

19

Fonte: De autoria

Demonstração. Como A ∩ Ac = ∅ e A ∪ Ac = Ω temos que:

P(A ∪ Ac) = P(A) + P(Ac),

Logo:

1 = P(A) + P(Ac) =⇒ P(Ac) = 1 − P(A).

Exemplo 1.5. Uma urna contém 6 bolas pretas, 2 bolas brancas e 10 amarelas. Uma

bola é retirada ao acaso. Qual a probabilidade de:

a) A bola não ser amarela?

b) A bola ser amarela ou preta?

c) A bola não ser branca, nem amarela?

Solução: a)Seja o evento A bola amarela, temos que:

e

P(A) =

n(A)
n(Ω)

=

10
18

=

5
9

.

P(Ac)

=

1 − P(A)

P(Ac) = 1 −

5
9

P(Ac)

P(Ac)

=

=

9 − 5
9

4
9

.

b)Seja o evento A bola amarela e o evento B bola preta, temos que:

20

e

P(A) =

n(A)
n(Ω)

=

10
18

=

5
9

.

P(B) =

n(B)
n(Ω)

=

6
18

=

1
3

.

P(A ∩ B) = 0, pois não temos bolas amarelas e pretas ao mesmo tempo.

P(A ∪ B) = P(A) + P(B) − P(A ∩ B)

P(A ∪ B) =

P(A ∪ B) =

P(A ∪ B) =

+

6
18

10
18
16
18
8
9

.

c)Seja o evento C a bola não ser branca e nem amarela. Note que a urna só contém as

bolas pretas, bolas brancas e bolas amarelas logo, se a bola não é branca e nem amarela

ela será preta. Temos que:

P(C) =

n(C)
n(Ω)

=

2
18

=

1
9

.

1.1.3 Probabilidade Condicional

Seja Ω um espaço amostral e consideremos dois eventos, A e B, com a simbologia
P(A|B) representa a probabilidade de ocorrer o evento A, sabendo que o evento B ocorreu.
Quando calculamos a probabilidade P(A|B) saímos inicialmente de um espaço amostral

Ω para um espaço amostral B.

A probabilidade de um evento A ocorrer, dado que outro evento B ocorreu, é chamada

probabilidade condicional do evento A dado B, sedo calculado da seguinte forma:

P(A|B) =

P(A ∩ B)
P(B)

.

Exemplo 1.6. Em uma cidade, tem–se a seguinte situação:

Qual a probabilidade de uma mulher ser escolhida, dado que ela esta empregada?

Solução: Sejam os eventos:

Empregados Desempregados Total

Homens

Mulheres

Total

460

140

600

40

260

300

500

400

900

21

• M: Uma mulher ser escolhida.

• E: O escolhido estar empregado.

P(M) =

400
900

P(E) =

600
900

• M e P: Ser mulher e estar empregada.

Temos que:

P(M ∩ E) =

140
900

P(M|E) =

P(M ∩ E)
P(E)

P(M|E) =

P(M|E) =

140
900
600
900

140
600

P(M|E) = 0, 2333...

P(M|E) = 23, 33%.

Exemplo 1.7. Uma escola de ensino médio tem 400 alunos em seu cadastro, sendo que:

I. 140 são rapazes;

II. 200 são moças que já concluíram o curso.

III. 30 rapazes ainda não concluíram o curso.

Ao se selecionar aleatoriamente um nome desse cadastro e sabendo–se que o nome

retirado foi o de um rapaz, a probabilidade de ele já ter concluído o curso é de:

A)

11
14

22

B)

C)

D)

E)

11
40
10
13
5
14
1
2

Solução: Vamos considerar:

P(A|B) = Probabilidade de o sorteado ter concluído o ensino médio, sabendo que foi um

rapaz.

P(A ∩ B) = Probabilidade de ser um rapaz e ter concluído o ensino médio.

P(B) = Probabilidade de ser um rapaz.

Como são 140 rapazes, em que 30 desses não concluíram o ensino médio, temos 110

rapazes com ensino médio. Sabendo que existem 400 estudantes na escola, temos:

P(A ∩ B) =

110
400

=

11
40

.

Como existem 140 rapazes e um total de 400 alunos, temos:

P(B) =

140
400

=

14
40

.

Temos que:

P(A|B) =

P(A ∩ B)
P(B)

=

11
40
14
40

=

11
40

·

40
14

=

11
14

.

1.1.4

Independência de dois eventos

Dados os eventos A e B em espaço amostral Ω, dizemos que A independe de B se

P(A|B) = P(A), isto é a ocorrência do evento B não interfere na ocorrência de A.

Pela probabilidade condicional temos que:

P(A|B) =

P(A ∩ B)
P(B)

,

sendo os eventos independentes temos P(A|B) = P(A).

Logo:

P(A|B) =

P(A ∩ B)
P(B)

= P(A) =⇒ P(A ∩ B) = P(A) · P(B)..

Exemplo 1.8. No lançamento de um dado e uma moeda. Qual a probabilidade de sair

um número par no dado e uma cara na moeda?

23

Solução: Sejam os eventos:

A: Sair um número par.

B: Sair uma cara.

Temos que:

P(A) =

3
6

=

1
2

.

P(B) =

1
2

.

P(A ∩ B) = P(A) · P(B) =

1
2

·

1
2

=

1
4

= 0, 25.

Exemplo 1.9. As probabilidades de que duas pessoas A e B resolvam um problema são:

P(A) =

e P(B) =

. Qual a probabilidade de que:

1
3

3
5

a) Ambos resolvam o problema?

b) Ao menos um resolva o problema?

c) Nenhum resolva o problema?

Solução: Estamos diante de uma questão que envolve eventos independentes pois, fato

da pessoa A saber ou não responder o problema não interfere no fato de B saber ou não

responder o problema.

Temos que:

i) A probabilidade da pessoa A resolver o problema é P(A) =

probabilidade da pessoa A não resolver o problema.

P(Ac) = 1 − P(A)

P(Ac) = 1 −

P(Ac) =

P(Ac) =

1
3
3 − 1
3

2
3

.

ii) A probabilidade da pessoa B resolver o problema é P(B) =

1
3

3
5

, logo P(Ac) será a

, logo P(Bc) será a

probabilidade da pessoa B não resolver o problema.

P(Bc) = 1 − P(B)

24

P(bc) = 1 −

P(bc) =

P(bc) =

3
5
5 − 3
5

2
5

.

iii) Probabilidade que ambos saibam responder;

P(A ∩ B) = P(A) · P(B)

P(A ∩ B) =

P(A ∩ B) =

3
5

=

·

1
3
3
15

1
5

iv) Seja C a probabilidade de ao menos um resolver o problema. Suponha que apena a

pessoa A saiba responder.

P(A ∩ Bc) = P(A) · P(Bc) =⇒ P(A ∩ Bc) =

1
3

·

2
5

=

2
15

.

Suponha que apenas a pessoa B saiba responder.

P(Ac ∩ B) = P(Ac) · P(B) =⇒ P(Ac ∩ B) =

2
3

·

3
5

=⇒ P(Ac ∩ B) =

6
15

=

2
5

.

Suponha que as duas pessoas saibam responder.

P(A ∩ B) = P(A) · P(B) =⇒ P(A ∩ B) =

1
3

·

3
5

=

3
15

.

Logo

P(C) = P(A ∩ Bc) + P(Ac ∩ B) + P(A ∩ B)
3
15

P(C) =

6
15

+

+

2
15
11
15

.

P(C) =

v) A probabilidade de nenhuma pessoa responder.

P(Ac ∩ Bc) =

2
3

·

2
5

=⇒ P(Ac ∩ Bc) =

4
15

.

1.2 Processos Estocásticos

25

Quem nunca se deparou com uma avenida movimentada e começou a imaginar a

quantidade de carros que passam por hora naquela avenida ou quem nunca imaginou a

quantidade de peças produzidas por uma empresa diariamente com ou sem defeito ou o

estoque de uma loja qualquer durante a semana, Esses e outros são exemplos práticos de

Processos Estocásticos.

Processos Estocásticos envolvem o comportamento de um conjunto de variáveis ale-

atórias durante um período de tempo, nesse processo devemos especiﬁcar o conjunto de

tempo T envolvido. Esse conjunto de tempos são os intervalos onde cada situação está

sendo analisada, tais como a quantidade de carros que trafegam por hora ou o estoque

semanal de uma loja.

Deﬁnição 1. Processo estocástico consiste em um conjunto não vazio T que chamamos

espaço paramétrico que associa cada t ∈ T de uma variável aleatória Xt : Ω −→ E todas

elas deﬁnidas sobre o mesmo espaço de probabilidades. Tomaremos usualmente como T
o conjunto [0, +∞) ou N = {0, 1, 2, . . .}. No primeiro caso, falaremos de um processo

estocástico de parâmetro contínuo e no segundo de um processo estocástico de parâmetro

discreto.

Processo Estocástico é um conjunto de variáveis aleatórias (X(t)) indexadas por um

parâmetro t pertencentes a um conjunto T . Geralmente T é tomado em um conjunto

de números inteiros não negativos, entretanto nada impede que possamos usar outros

conjuntos. A variável aleatória X(t) representa uma característica mensurável do conjunto

ao longo do tempo t.

Os Processos Estocásticos podem ser classiﬁcados em relação ao estado ou em relação

ao tempo. Em relação ao estado, o processo pode ser de estado Discreto, em que X(t)

é deﬁnido sobre um conjunto enumerável e ﬁnito ou Estado contínuo (sequência) caso

contrario.

Em relação ao tempo, o processo Estocástico pode ser de tempo discreto ou tempo

contínuo.

Exemplo 1.10.

• Número de carros que circulam em uma avenida por hora, temos um estado e tempo

discretos.

26

• Índice pluviométrico durante o ano, temos estado contínuo e tempo discreto.

• Número de usuários atendidos em um Call Center em um determinado instante,

temos o estado discreto e o tempo contínuo.

27

2 Cadeias de Markov

Andrei Andreyevich Markov nasceu no dia 14 de junho de 1856 na Rússia. Formou-se

na universidade de St. Petersburg (1878), onde se tornou professor em 1886. Os principais

trabalhos de Markov foram: teoria dos números e análise, frações contínuas, limites de

integrais, teoria da aproximação e a convergência de séries.

Markov aplicou o método das frações contínuas, inicialmente desenvolvido por Pafnuty

Chebyshev, na teoria da probabilidade. Ele também estudou sequências de variáveis

mutuamente independentes, esperando estabelecer as leis da probabilidade de forma mais

geral. Ele também provou o teorema do limite central.

Markov é particularmente lembrado pelo seu estudo de cadeias de Markov. Cadeias

de Markov é um formalismo de modelagem de sistemas que descrevem o sistema como

um processo estocástico. Desse ponto de vista o sistema modelado é caracterizado pelos

seus estados e a forma pela qual eles se alternam.

Um processo estocástico é uma cadeia de Markov se a probabilidade de ocorrências

futuras dependerem exclusivamente do estado atual, são os chamados processos sem me-

moria.

Deﬁnição 2. Seja X, uma variável aleatória que caracteriza o estado do sistema em
pontos discretos do tempo t = 0, 1, 2, 3, . . .. A família de variáveis aleatórias {Xt} forma
um processo estocástico. Um processo estocástico onde são dados os tempos t0, t1, . . . , tn,
e uma família de variáveis aleatórias {Xt} = {x0, x1, . . . , xn} é um processo de Markov se
possuir a seguinte propriedade:

P{Xtn−1 = xn−1, . . . , X0 = x0} = P

Xtn =

(cid:12)

(cid:13)

xn
Xtn−1

= xn−1

No processo de Markov as probabilidades em um ponto especiﬁco de tempo t =

0, 1, 2, . . ., são expressos por:

(cid:12)

pij = P

Xt =

j
Xt−1

(cid:13)

= i

,

(i, j) = 1, 2, . . . , n, t = 0, 1, 2, . . . , T

Tal expressão é chamada de probabilidade de transição e representa a probabilidade

do estado i em t -1 ao estado j em t. Por deﬁnição:

(cid:88)

j

pij = 1,

i = 1, 2, . . . , n e pij (cid:62) 0,

(i, j) = 1, 2, . . . , n

Para representar as probabilidades de transição em uma etapa usamos a seguinte

28

notação matricial:










P =

p11 p12 p13
p21 p22 p23
...
...
...
pn1 pn2 pn3

. . . p1n
. . . p2n
...
...
. . . pnn










A matriz P e denominada de cadeia de Markov e todas as probabilidades de transição

pij são ﬁxas e independentes ao longo do tempo.

Exemplo 2.1. Um estudante do ensino médio apresentou os seguintes resultados proba-

bilidade ao logo dos três anos de estudo:

Desempenho ao logo dos anos

A Excelente

B

C

Bom

Ruim

0,6

0,3

0,1

Os valores da tabela acima podem ser dispostos em um vetor x, denominado Vetor

de Estados:

(cid:104)

x =

0, 6 0, 3 0, 1

(cid:105)

Lembrando que a cada bateria de provas o aluno apresentou variações de desempenho

ao logo dos anos observados, como mostra a matriz a baixo:

Probabilidades de Transição

Para A Para B Para C

De A

De B

De C

0, 5

0, 3

0, 2

0, 4

0, 4

0, 5

0, 1

0, 3

0, 3

De acordo com as informações da tabela acima, podemos observar que ao logo dos 3

anos de ensino tivemos as seguintes variações:

29

• De A para A, a probabilidade de um desempenho Excelente continuar Excelente

após 3 anos é 0, 5.

• De A para B, a probabilidade de um desempenho Excelente passar a ser Bom após

3 anos é 0, 4.

• De A para C, a probabilidade de um desempenho Excelente passar a ser Ruim após

3 anos é 0, 1.

• De B para A, a probabilidade de um desempenho Bom passar a ser Excelente após

3 anos é de 0, 3.

• De B para B, a probabilidade de um desempenho Bom continuar Bom após 3 anos

é de 0, 4.

• De B para C, a probabilidade de um desempenho Bom passar a ser Ruim após 3

anos é de 0, 3.

• De C para A, a probabilidade de um desempenho Ruim passar a ser Excelente após

3 anos é de 0, 2.

• De C para B, a probabilidade de um desempenho Ruim passar a ser Bom após 3

anos é de 0, 5.

• De C para C, a probabilidade de um desempenho Ruim continuar Ruim após 3 anos

é de 0, 3.

Podemos também representar a cadeia de Markov através de um diagrama de ﬂechas.

0,3

C

0,3

0,5

0,4

B

0,1

0,3

0,2

0,4

A

0,5

Exemplo 2.2. Um professor de Engenharia compra um novo computador a cada dois

anos e tem preferência por três modelos: A, B e C. Se o modelo atual for A, o próximo

(cid:10)
(cid:10)
(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:115)
(cid:115)
(cid:9)
(cid:9)
(cid:84)
(cid:84)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
computador pode ser B com probabilidade 0, 2 ou C com probabilidade 0, 15. Se o modelo

atual for B, as probabilidades de trocar para A e C são 0, 6 e 0, 25, respectivamente, e,

se o modelo atual for C, então as probabilidades de trocas para A e C são 0, 5 e 0, 1,

respectivamente. Represente a situação como uma cadeia de Markov através da matriz de

transição e do diagrama de ﬂechas.

30

Solução: De acordo com dados da questão temos que a matriz P de transição é:

P =










A B

C

A p11 0, 2 0, 15
B 0, 6 p22 0, 25
C 0, 5 0, 1 p33










Note que não foram fornecidos os valores de p11, p22 e p33, entretanto podemos calcular

essas probabilidades, pois:

n(cid:88)

j

pij = 1,

i = 1, 2, . . . , n

Logo temos que:

i) p11 + 0, 2 + 0, 15 = 1 =⇒ p11 = 1 − 0, 35 =⇒ p11 = 0, 65.

ii) p22 + 0, 6 + 0, 25 = 1 =⇒ p22 = 1 − 0, 85 =⇒ p22 = 0, 15.

iii) p33 + 0, 5 + 0, 1 = 1 =⇒ p33 = 1 − 0, 6 =⇒ p33 = 0, 4.

Diagrama de Flexas

0,4

C

0,25

0,1

0,15

B

0,15

0,6

0,5

0,2

A

0,65

(cid:10)
(cid:10)
(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:115)
(cid:115)
(cid:9)
(cid:9)
(cid:84)
(cid:84)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
2.1 Equações de Chapman – Kolmogorov

31

Sidney Chapman foi um matemático e geofísico Britânico, nascido em janeiro de 1888,

formado pela Universidade de Cambridge, Universidade de Manchester, Trinity College.

Trabalhou como professor da Catedra Beyer de Matemática Aplicada, de 1920 a 1924.

Membro da Royal Society cujo título é concedido a cientistas notáveis e também um tipo

de aﬁliação de Royal Society para melhoramento do conhecimento natural. Recebeu vários

prêmios como: Premio Smith, Premio Adams, Medalha e Premio Appleton, Medalha De

Morgan dentre outros. Faleceu em 16 de junho de 1970 aos 82 anos em Boulder (Colorado).

Figura 1: Sidney Chapman (1888 – 1970)

Fonte: Google Images

Andrei Nikolaevich Kolmogorov foi matemático soviético, nascido em Abril de 1903

em Tambov (Rússia). Formado pela Universidade Estatal de Moscovo, trabalhou com

teoria das probabilidades, Topologia, Lógica Intuicionista, Mecânica Clássica, Teoria Al-

gorítmica da Informação e Análise de Algoritmos. Recebeu vários prêmios como: Prêmio

Wolf de Matemática, Lenin Prize in Science, Balzar Prize for Mathematical and Physical

Sciences. Participou das principais descobertas cientíﬁcas nas áreas de probabilidade e

estatística, e em teoria da informação. Autor da principal teoria cientíﬁca no campo das

probabilidades: a teoria da medida, que revolucionou o cálculo de integrais, permitindo

que as integrais fossem generalizadas para domínios com restrições. Faleceu em 20 de

outubro de 1987 na cidade de Moscou na Rússia.

Figura 2: Andrei Nikolaevich (1903 – 1987)

Fonte: Google Images

A equação de Chapman–Kolmogorov é uma identidade que relaciona as distribuições

de probabilidade conjunta de diferentes conjuntos de coordenadas de um processo esto-

cástico. A matriz de transição P é a matriz de transição de probabilidade de um estado

t para t + 1. As equações de Chapman–Kolmogorov fornecem um método para calcular

32

a transição de um estado t para t + 1, de t para t + 2, . . ., de t para t + n.

(cid:10)

(cid:11)

Dadas as probabilidade iniciais a(0) =

a(0)
t

(cid:10)

de iniciar no estado t e a matriz de

(cid:11)

transição P, as probabilidades absolutas a(n) =

a(0)
t

de estado t após n transições

(n > 0) é calculada da seguinte forma:

a(1) = a(0) · P

a(2) = a(1) · P = a(0) · P · P = a(0) · P2

a(3) = a(2) · P = a(0) · P2 · P = a(0) · P3

Seguindo o mesmo raciocínio podemos concluir que:

a(n) = a(0) · Pn, n = 1, 2, 3, . . .

A matriz Pn é chamada de matriz de transição em n etapas. Através dos cálculos

podemos concluir que:

ou

Pn = Pn−1 · P

Pn = Pn−m · Pm,

com 0 < m < n.

Exemplo 2.3. A matriz abaixo se aplica ao problema do desempenho do aluno no Exemplo

2.1:







P =

0, 5 0, 4 0, 1

0, 3 0, 4 0, 3

0, 2 0, 5 0, 3







Supondo que o desempenho inicial do aluno era Excelente, isto é a(0) = (1, 0, 0).

Determine a probabilidade dos estados após 2, 4 e 8 estados de avaliações.

Solução: Aplicando as propriedades de produto de matrizes temos que:

i) Probabilidade de transição no estado 2:

P2 = P · P =







0, 5 0, 4 0, 1

0, 3 0, 4 0, 3

0, 2 0, 5 0, 3







·







0, 5 0, 4 0, 1

0, 3 0, 4 0, 3

0, 2 0, 5 0, 3













=

0, 39 0, 41

0, 2

0, 33 0, 43 0, 24

0, 31 0, 43 0, 26

Utilizando a equação de equação de Chapman–Kolmogorov temos que:

33







a(2) = a(0) · P2 = (1, 0, 0) ·







0, 39 0, 41

0, 2

0, 33 0, 43 0, 24

0, 31 0, 43 0, 26







(cid:16)

=

0, 39 0, 41 0, 2

(cid:17)

Após 2 estados de avaliação o desempenho do aluno terá as seguintes probabilidades

possíveis, 39% de chance de ser Excelente, 41% de chance de ser Bom e 20% de

chance de ser Ruim.

ii) Probabilidade de transição no estado 4:

P4 = P2 · P2 =







0, 39 0, 41

0, 2

0, 33 0, 43 0, 24







=

0, 31 0, 43 0, 26


0, 3494 0, 4222 0, 2284

0, 345

0, 4234 0, 2316

0, 3434 0, 4238 0, 2328











·







0, 39 0, 41

0, 2

0, 33 0, 43 0, 24

0, 31 0, 43 0, 26







Utilizando a equação de equação de Chapman–Kolmogorov temos que:

a(4) = a(0) · P4 = (1, 0, 0) ·







0, 3494 0, 4222 0, 2284

0, 345

0, 4234 0, 2316

0, 3434 0, 4238 0, 2328







(cid:16)

=

0, 3494 0, 4222 0, 2284

(cid:17)

Após 4 estados de avaliação, o desempenho do aluno terá as seguintes probabilidades

possíveis, 34, 94% de chance de ser Excelente, 42, 22% de chance de ser Bom e

22, 84% de chance de ser Ruim.

iii) Probabilidade de transição no estado 8:

34







P8 = P4 · P4 =







0, 3494 0, 4222 0, 2284

0, 345

0, 4234 0, 2316

0, 3434 0, 4238 0, 2328







·







0, 3494 0, 4222 0, 2284

0, 345

0, 4234 0, 2316

0, 3434 0, 4238 0, 2328







=

0, 34617 0, 42307 0, 23076

0, 34615 0, 42308 0, 23077

0, 34614 0, 42308 0, 23078







Utilizando a equação de equação de Chapman–Kolmogorov temos que:

a(4) = a(0) · P4 = (1, 0, 0) ·







0, 34617 0, 42307 0, 23076

0, 34615 0, 42308 0, 23077

0, 34614 0, 42308 0, 23078







(cid:16)

=

0, 34617 0, 42307 0, 23076

(cid:17)

Após 8 estados de avaliação, o desempenho do aluno terá as seguintes probabilidades

possíveis, 34, 61% de chance de ser Excelente, 42, 3% de chance de ser Bom e 23, 07%

de chance de ser Ruim.

Observe que a medida que número de estados de transição aumenta as probabilidades
absolutas a4 e a8 independem de a0. Quando isso ocorre, dizemos as probabilidades

resultantes atingiram um estado de equilíbrio.

2.2 Classiﬁcação dos Estados de Uma Cadeia de Mar-

kov

2.2.1 Estado Transiente

Um estado é dito Transiente se o processo ao sair do estado que se encontra indo para

outro estado não é mais possível o seu retorno ao estado anterior. O estado i é transiente

se e somente se existe um estado j que é atingível a partir do estado i, entretanto o retorno

do estado j para o estado i não é mais possível.

Exemplo 2.4. Suponha uma cadeia de Markov com a seguinte matriz de transição:

35

P =










A B C

A 0, 1 0 0, 9

B 0, 6 0 0, 4

C 0, 7 0 0, 3










Observe que o estado B é Transiente pois ao sair do estado B o processo não retorna

mais ao estado B.

Diagrama de Flexas

B

0,6

0,3

C

0,9

0,7

0,4

A

0,1

2.2.2 Estado Recorrente

Dizemos que um estado é Recorrente quando é for possível o retorno ao estado de

origem. Em outras palavras dizemos que um estado j é Recorrente se a probabilidade de

voltar ao estado em que estava com base em outros estados for 1.

Exemplo 2.5. Suponha uma cadeia de Markov com a seguinte matriz de transição:

P =










A

B

C

A 0, 25 0, 75 0

B 0, 5

0, 5

C

0

0

0

1










Observe que os estados A e B são Recorrentes, pois quando o processo entra nesses

dois estado sempre retorna ao estado de origem.

(cid:10)
(cid:10)
(cid:34)
(cid:34)
(cid:115)
(cid:115)
(cid:124)
(cid:124)
(cid:84)
(cid:84)
(cid:98)
(cid:98)
Diagrama de Flexas

36

1,0

C

0,5

B

0,5

0,75

A

0,25

2.2.3 Estado Absorvente

Um estado é dito Absorvente quando uma vez o processo entrando nesse estado jamais

irá deixá–lo. Um estado j é absorvente se retornar para ele mesmo, com certeza, em uma

transição certa.

Exemplo 2.6. Suponha uma cadeia de Markov com a seguinte matriz de transição:

P =










A

B

C

A 0, 25 0, 75 0

B 0, 5

0, 5

C

0

0

0

1










Observe que o estado C é Absorvente pois, uma vez entrando nesse estado jamais o

processo retornara a outros estados.

1,0

C

Diagrama de Flexas

0,5

B

0,5

0,75

A

0,25

(cid:10)
(cid:10)
(cid:10)
(cid:10)
(cid:7)
(cid:7)
(cid:84)
(cid:84)
(cid:71)
(cid:71)
(cid:10)
(cid:10)
(cid:10)
(cid:10)
(cid:7)
(cid:7)
(cid:84)
(cid:84)
(cid:71)
(cid:71)
2.2.4 Estado Periódico

Dizemos que um estado j é periódico com t > 1 se seu retorno for possível em

2t, 4t, 6t, . . ., etapas.

Exemplo 2.7. Suponha uma cadeia de Markov com a seguinte matriz de transição:

37

P =










A B

C

A 0

0, 7 0, 3

B

0

1

C 0, 7 0, 3

0

0










Diagrama de Flexas

C

0,3

1,0

B

0,3

0,7

0,7

A

Observe que:


A

B

P2 =








A 0, 21 0, 79

B

C

0

0

1

C

0

0

0, 79 0, 21

0,21

C










Diagrama de Flexas

1,0

(cid:51) B

0,79

0,21

A

0,21

(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
(cid:10)
(cid:10)
(cid:51)
(cid:10)
(cid:10)
(cid:84)
(cid:84)
(cid:71)
(cid:71)
B

C

0, 937 0, 063

A

0

0

A

B

C 0, 147 0, 853

1

0

0

38










,

Diagrama de Flexas

C

0,853

1,0

B

0,063

0,147

0,937










P3 =










P4 =










P5 =

B

C

0

0

A

0

0

A

B

A

B

A 0, 0441

0, 9559

A






,




C

0

0

1

0, 00926 0, 0441

0,0441

C

Diagrama de Flexas

1,0

(cid:51) B

0,9559

0,9559

A

0,0441

B

C

0, 98677 0, 01323










,

C 0, 03087 0, 96913

1

0

0

(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
(cid:10)
(cid:10)
(cid:51)
(cid:10)
(cid:10)
(cid:84)
(cid:84)
(cid:71)
(cid:71)
39

Diagrama de Flexas

1,0

B

C

0,96913

0,01323

0,03087

0,98677

A










P6 =

A

B

A 0, 00926 0, 99074

B

C

0

0

1

0, 00926 0, 99074

C

0

0










0,99074

C

Diagrama de Flexas

1,0

(cid:51) B

0,99074

0,00926

A

0,00926

Calculado Pn foi possível observar que quando n é impar p11 e p33 são sempre iguais

a zero e quando n é par esses valores são positivos, logo p11 e p33 são periódicos.

2.3 Cadeias Ergódicas

Uma cadeia de Markov fechada é dita Ergódica quando todos os seus estados são

recorrentes e aperiódicos.

Exemplo 2.8. Suponha uma cadeia de Markov com a seguinte matriz de transição:










P =

A

A 0, 3

B 0, 1

B

0, 6

0, 6

C

0, 1

0, 3

C 0, 05 0, 4 0, 55










(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
(cid:10)
(cid:10)
(cid:51)
(cid:10)
(cid:10)
(cid:84)
(cid:84)
(cid:71)
(cid:71)
40

Diagrama de Flexas

0,55

C

0,3

0,4

0,6

B

0,1

0,1

0,05

0,6

A

0,3

Calculando: P2 =







0, 155

0, 58

0, 265

0, 105

0, 54

0, 355

0, 0825 0, 49 0, 4275



, P3 =











0, 11775

0, 547

0, 33525

0, 10325

0, 529

0, 36775

0, 09513 0, 5145 0, 39038




,









, P5 =

0, 10334 0, 52795 0, 36871

0, 10189 0, 52574 0, 37237

0, 10097 0, 52429 0, 37474




,















P4 =

P6 =

0, 10679 0, 53295 0, 36026

0, 10226 0, 52645 0, 37129

0, 09951 0, 52193 0, 37857

0, 10223 0, 52626 0, 37151

0, 10176 0, 52553 0, 37271

0, 10146 0, 52505 0, 37349













Observe que em todas as potencias de P acima os estados são recorrentes e aperiódicos,
logo temos uma Cadeia Ergódica. Note que a partir de P4 os valores tendem a estabilizar

e a matriz atinge o estado de equilíbrio.

2.4 Probabilidade de estado no Equilíbrio e tempo mé-

dio de retorno de Cadeias Ergódicas

Nos exemplos citados ao logo do texto, foi mostrado que uma matriz de transição Pn

tende a entrar em estado de equilíbrio á medida que n vai aumentando. Em uma cadeia

de Markov Ergódica as probabilidades de estado de equilíbrio é deﬁnida por:

πj = lim
n→∞

Pn
ij > 0.

(2.1)

(cid:10)
(cid:10)
(cid:51)
(cid:51)
(cid:34)
(cid:34)
(cid:10)
(cid:10)
(cid:115)
(cid:115)
(cid:9)
(cid:9)
(cid:84)
(cid:84)
(cid:98)
(cid:98)
(cid:74)
(cid:74)
Sendo que:

n(cid:88)

πj =

πj · Pij,

com j = 0, 1, 2, 3, . . . , n.

j

n(cid:88)

jπj = 1.

41

(2.2)

(2.3)

A equação (2.2) nos mostra que as probabilidades π permanecem inalteradas após

uma transição e por isso representam a distribuição de estado no equilíbrio.

Através da probabilidade de estado de equilíbrio é possível determinar o número de

transições antes de os sistemas retornarem a um estado j pela primeira vez. Esse processo

é conhecido como tempo médio do primeiro retorno ou tempo médio de recorrência e pode

ser calculado da seguinte forma:

µjj =

1
πj

,

j = 1, 2, 3, . . . , n.

Exemplo 2.9. Todo ano, no inicio da estação de plantio de mudas, um jardineiro usa

um teste químico para veriﬁcar a condição do solo. Dependendo do resultado do teste, a

produtividade para a nova estação cai em um dos três resultados: 1) bom; 2) razoável e 3)

ruim. Ao longo dos anos, o jardineiro observou que a condição do solo no ano anterior

causava um impacto sobre a produtividade no ano corrente e que a situação podia ser

descrita através da cadeia de Markov:







P =

0, 3

0, 1

0, 6

0, 6

0, 1

0, 3

0, 05 0, 4 0, 55







Com base nos dados acima, determine a distribuição de probabilidade de estado no

equilíbrio e os tempos médios do primeiro retorno.

Solução: Temos que: πj =

(π1, π2, π3) = (π1, π2, π3)·

(cid:80)







(cid:80)

πj · Pij e

πj = 1., daí implica

0, 3

0, 1

0, 6

0, 6

0, 1

0, 3

0, 05 0, 4 0, 55







⇒






0, 3π1 + 0, 1π2 + 0, 05π3 = π1
0, 6π1 + 0, 6π2 + 0, 4π3 = π2
0, 1π1 + 0, 3π2 + 0, 55π3 = π3
= 1

π1 + π2 + π3

Resolvendo o sistema temos que: π1 = 0, 1017, π2 = 0, 5254 e π3 = 0, 3729.

Esses resultados nos mostram que ao logo dos tempos a probabilidade do solo ser boa

é de 10, 17%, de ser um solo razoável é de 52, 54% e de ser ruim é de 37, 29%. Calculando

o tempo do primeiro retorno temos:

42

µ11 =

µ22 =

µ33 =

1
π1
1
π2
1
π3

=

=

=

1
0, 1017
1
0, 5254
1
0, 3729

= 9, 83.

= 1, 9.

= 2, 68.

Traduzindo os valores acima, temos que o solo levará aproximadamente 10 estações

para retornar ao estado bom, 2 estações para retornar ao estado razoável e 3 estações

para retornar ao estado ruim.

43

3 Aplicações utilizando Cadeias de

Markov

Todos nós educadores que vivemos em uma sociedade em constante revolução tecnoló-

gica, com novas tecnologias surgindo a cada momento. Diante desses desaﬁos tecnológicos,

o professor precisa cada vez mais manter–se atualizado e conectado com o mundo virtual.

O professor deve ter uma metodologia clara e precisa que lhe proporcione a melhor forma

possível de transmitir o conhecimento aos seus alunos. Se a intenção do professor for ape-

nas passar a informação, uma simples exposição oral é o suﬁciente, porém se pretende que

seus alunos entendam, assimilem o que está sendo ensinado terá que utilizar metodologias

e estratégias adequadas para cada conteúdo ministrado.

“Nada deve ser dado à criança, no campo da matemática, sem pri-

meiro apresentar-se a ela uma situação concreta que a leve a agir,

a pensar, a experimentar, a descobrir, e daí, a mergulhar na abs-

tração.” (AZEVEDO, 1979, p. 27).

Neste capítulo iremos trabalhar algumas aplicações do nosso dia–a–dia que envolvem

cadeias de Markov. Como nosso primeiro exemplo de aplicação prática, escolhemos o

futebol. O nosso estudo consistiu em analisar os passes certos durante uma partida de

futebol, pois como foi dito inicialmente um processo estocástico é uma cadeia de Markov

em que a probabilidade de ocorrências futuras depende exclusivamente do estado atual,

ou seja, o passe que saiu de um jogador A para um jogador B, não irá depender de passes

realizados anteriormente.

O nosso trabalho consistiu em analisarmos dois jogos da seleção brasileira durante

a copa do mundo de 2002, onde a nossa seleção se saiu vitoriosa. A nossa análise foi

feita em cima dos passes certos realizados durante todo o jogo, dividindo a nossa análise
em três momentos distintos. Fizemos uma matriz de transição para o 1◦ tempo de jogo,
uma matriz de transição para o 2◦ tempo de jogo e uma matriz contendo toda partida de

futebol.

44

O primeiro jogo analisado foi o jogo das quartas de ﬁnais, Brasil e Inglaterra realizado

no dia 21 de junho de 2002, jogo esse em que o Brasil saiu vitorioso pelo placar de 2 × 1.

Primeiramente ﬁzemos a coleta dos dados, ou seja, analisamos todos passes certos

feito por cada jogador durante o jogo. A nossa matriz é de ordem 11, em que cada linha

representa os jogadores que distribuem os passes e cada coluna representa os jogadores

que estão recebendo os passes.

Neste jogo o Brasil contou com os seguintes jogadores abaixo:

Número

1

2

3

4

5

6

7

8

9

10

11

Jogador

Marcos

Cafu

Lúcio

Roque Junior

Edmilson

Roberto Carlos

Kleberson

Gilberto Silva

Ronaldo

Rivaldo

Observações

Substituído aos 25 minutos do 2◦ tempo.

Ronaldinho Gaúcho

Expulso aos 12 minutos do 2◦ tempo.

O jogador Kleberson jogou com a camisa de número 15, mais para uma melhor orga-

nização e entendimento da matriz o colocamos com o número 7 na matriz.

Matriz de probabilidades de transição do 1◦ tempo do jogo Brasil × Inglaterra:

Obs: Os valores acima são aproximações.

45

Observações do 1◦ tempo de jogo:

• O jogador 1 tem a maior probabilidade de passar a bola aos jogadores 2, 3 e 4.
Entretanto não recebeu nenhum passe ao logo do 1◦ tempo, só lembrando que o

jogador é o goleiro e por isso tem menos posse de bola.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 7. O jogador

também distribuiu bola pra quase todos os outros jogadores.

• O jogador 3 tem a maior probabilidade de passar a bola ao jogador 2.

• O jogador 4 tem a maior probabilidade de passar a bola ao jogador 8.

• O jogador 5 tem a maior probabilidade de passar a bola ao jogador 2. O jogador

também distribuiu bola pra quase todos os outros jogadores.

• O jogador 6 tem a maior probabilidade de passar a bola ao jogador 8.

• O jogador 7 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 8 tem a maior probabilidade de passar a bola ao jogador 5, 6 e 10. O

jogador foi que mais recebeu e deu passes no 1◦ tempo.

• O jogador 9 tem a maior probabilidade de passar a bola ao jogador 10.

• O jogador 10 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 7.

• Durante o 1◦ tempo foram realizados 184 passes certos.

Matriz de probabilidades de transição do 2◦ tempo do jogo Brasil × Inglaterra:

46

Obs: Os valores acima são aproximações.

Observações do 2◦ tempo de jogo:

• O jogador 1 tem a maior probabilidade de passar a bola aos jogadores 5, 6 e 10.Re-

cebeu passe apenas dos jogadores 3 e 5, só lembrando que o jogador é o goleiro e

por isso tem menos posse de bola.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 9. O jogador 2

foi também que mais distribuiu bolas no 2◦ tempo de jogo.

47

• O jogador 3 tem a maior probabilidade de passar a bola aos jogadores 1, 2, 4, 7, 8

e 10.Entretanto foi o jogador de linha que menos distribuiu bolas.

• O jogador 4 tem a maior probabilidade de passar a bola aos jogadores 3 e 7.

• O jogador 5 tem a maior probabilidade de passar a bola aos jogadores 1, 2, 7 e 8.

• O jogador 6 tem a maior probabilidade de passar a bola ao jogador 8.

• O jogador 7 tem a maior probabilidade de passar a bola ao jogador 2. Foi o jogador

que mais recebeu passes durante o 2◦ tempo.

• O jogador 8 tem a maior probabilidade de passar a bola aos jogadores 7 e 9.

• O jogador 9 tem a maior probabilidade de passar a bola ao jogador 7. O jogador 10

tem a maior probabilidade de passar a bola aos jogadores 2 e 9.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 6. Só lembrando
que o jogador foi expulso aos 10 minutos do 2◦ tempo e por isso realizou poucos

passes.

• Durante o 2◦ tempo foram realizados apenas 121 passes certos, pois o Brasil teve

um jogador expulso e com uma menor posse de bola.

Matriz de probabilidades de transição do jogo Brasil × Inglaterra:

Obs: Os valores acima são aproximações.

48

Observações do jogo inteiro:

• O jogador 1 tem a mesma probabilidade de passar a bola aos jogadores 2, 3, 4, 5,

6 e 10.Recebeu passe apenas dos jogadores 3 e 5, só lembrando que o jogador é o

goleiro e por isso tem menos posse de bola.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 7. Foi o jogador

que mais passou a bola durante o jogo.

• O jogador 3 tem a maior probabilidade de passar a bola ao jogador 2.

• O jogador 4 tem a maior probabilidade de passar a bola aos jogadores 3 e 8.

• O jogador 5 tem a maior probabilidade de passar a bola ao jogador 2.

• O jogador 6 tem a maior probabilidade de passar a bola ao jogador 8.

• O jogador 7 tem a maior probabilidade de passar a bola ao jogador 2.Foi o jogador

que mais recebeu bolas durante o jogo.

• O jogador 8 tem a maior probabilidade de passar a bola ao jogador 7.

• O jogador 9 tem a maior probabilidade de passar a bola ao jogador 7.

• O jogador 10 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 7.

• Durante o jogo foram realizados 305 passes corretos.

49

O segundo jogo que iremos analisar é o jogo da ﬁnal da copa do mundo de 2002 entre

Brasil e Alemanha, realizado em 30 de junho de 2002 e que teve como vencedor o Brasil

pelo placar 2 × 0.

Neste jogo o Brasil contou com os seguintes jogadores abaixo:

Número

1

2

3

4

5

6

7

8

9

10

11

Jogador

Marcos

Cafu

Lúcio

Roque Junior

Edmilson

Roberto Carlos

Kleberson

Gilberto Silva

Ronaldo

Rivaldo

Observações

Substituído aos 40 minutos do 2◦ tempo.

Ronaldinho Gaúcho Substituído aos 40 minutos do 2◦ tempo.

O jogador Kleberson jogou com a camisa de número 15, mas para uma melhor orga-

nização e entendimento da matriz o colocamos com o número 7 na matriz.

Matriz de probabilidade de transição do 1◦ tempo de jogo Brasil × Alemanha:

Obs: Os valores acima são aproximações.

50

Observações do 1◦ tempo de jogo Brasil × Alemanha:

• O jogador 1 fez apenas um passe durante o jogo para o jogador 10, só lembrando

que o jogador é o goleiro e por isso tem menos posse de bola e jogou machucado.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 3 tem a maior probabilidade de passar a bola ao jogador 6.

• O jogador 4 tem a maior probabilidade de passar a bola aos jogadores 6 e 9.

• O jogador 5 tem a maior probabilidade de passar a bola aos jogadores 2 e 8.

• O jogador 6 tem a maior probabilidade de passar a bola aos jogadores 9 e 10.Foi

também o jogador que mais passou a bola no 1◦ tempo.

• O jogador 7 tem a maior probabilidade de passar a bola ao jogador 6.

• O jogador 8 tem a maior probabilidade de passar a bola ao jogador 7.

• O jogador 9 tem a maior probabilidade de passar a bola ao jogador 10.Foi também
um dos jogadores que mais recebeu a bola no 1◦ tempo junto com o jogador 11.

• O jogador 10 tem a maior probabilidade de passar a bola aos jogadores 7, 9 e 11.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 7.

• Durante o 1◦ tempo de jogo o Brasil teve pouca posse de bola. E realizou apenas

104 passes certos.

51

Matriz de probabilidade de transição do 2◦ tempo de jogo Brasil × Alemanha:

Obs: Os valores acima são aproximações.

Observações do 2◦ tempo de jogo Brasil × Alemanha:

• O jogador 1 não realizou e nem recebeu nenhum passe durante o jogo, pois o jogador

estava machucado.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 11.

52

• O jogador 3 tem a maior probabilidade de passar a bola ao jogador 7.

• O jogador 4 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 5 tem a maior probabilidade de passar a bola ao jogador 6.

• O jogador 6 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 7 tem a maior probabilidade de passar a bola aos jogadores 2 e 11.

• O jogador 8 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 9 tem a maior probabilidade de passar a bola aos jogadores 6 e 11.

• O jogador 10 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 10, foi também

o jogador que mais recebeu e deu passes no 2◦ tempo.

• No 2◦ tempo o Brasil realizou apenas 97 passes certos.

Obs: Os valores acima são aproximações.

53

Observações do jogo Brasil × Alemanha:

• O jogador 1 realizou apenas um passe durante o jogo, pois o jogador estava machu-

cado.

• O jogador 2 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 3 tem a maior probabilidade de passar a bola aos jogadores 6 e 7.

• O jogador 4 tem a maior probabilidade de passar a bola aos jogadores 8, 9 e 11.

• O jogador 5 tem a maior probabilidade de passar a bola ao jogador 8.

• O jogador 6 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 7 tem a maior probabilidade de passar a bola ao jogador 9.

• O jogador 8 tem a maior probabilidade de passar a bola ao jogador 7.

• O jogador 9 tem a maior probabilidade de passar a bola ao jogador 10.

• O jogador 10 tem a maior probabilidade de passar a bola ao jogador 11.

• O jogador 11 tem a maior probabilidade de passar a bola ao jogador 10.

• Durante o jogo o Brasil realizou 201 passes certos e teve uma menor posse de bola.

54

4 Considerações Finais

Procuramos mostrar por meio do trabalho temas como: probabilidade, matriz e ca-

deias de Markov. Apesar de não ser um conteúdo abordado no ensino médio, foi possível

mostrar que cadeia de Markov pode ser trabalhada através de exemplos práticos com

probabilidade e matrizes. O uso do jogo de futebol como aplicação é apenas uma das

inúmeras formas que podemos utilizar para trabalhar esse conteúdo.

Fizemos uma analise da quantidade de passes certos em uma partida de futebol,

essa quantidade de passes foram colocadas em uma matriz onde foi possível trabalhar a

probabilidade de passes que um jogador fez e recebeu durante o jogo. Por meio do uso

dos gráﬁcos procuramos mostrar de uma forma mais clara a probabilidade da ocorrência

dos passes.

É importante ressaltar que estamos diante de um tema riquíssimo em aplicações no

nosso cotidiano. Esperamos por meio desse trabalho contribuir com o ensino da ma-

temática, mostrando que é possível trabalhar temas bastante complexos com exemplos

práticos.

55

Referências

Almeida Nogueira, F. M. de. – Modelagem e Simulação: Cadeias de Markov. Notas de

aula da Disciplina EPD–042–Pesquisa Operacional II, UFJF, 2015.

Clarke, A. Bruce. – Probabilidade e processos estocásticos. Rio de Janeiro: livros técnicos

e cientíﬁcos, 1979.

Golmakani, Ali., Da Silva, Aryane Adelina., Freire, Emanoel M.S., Barbosa, Myrla kedynnna.,

Carvalho, Pedro H.G., Alves, Pedro I. – Cadeias de Markov. VII Bienal da Sociedade

Brasileira de Matemática, Maceió, 2014.

Hazzan, Samuel. – Fundamentos de Matemática Elementar – Vol. 5 – Combinatória,

Probabilidade. 7. ed. São Paulo: Atual, 2004.

Hoel, P.G., S. C. Port e C. J. Stone. – Introdução à Teoria da Probabilidade. Editora

Interciência, 4a ed., 1978.

Lipschutz, S. – Probabilidade. Editora McGraw–Hill do Brasil, 2 ed., 1978.

MEYER, P. L. – Probabilidade: aplicações à estatística. [sine loco]: Livro Técnico, 1970.

Souza, Fernando Luiz Junior. – Cadeias de Markov e o jogo Monopoly. 2016. 112 f.

Dissertação (Mestrado Proﬁssional em Ensino de Matemática) – Universidade Federal do

ABC, Santo André, 2016.

Taha, Hamdy A. – Pesquisa operacional: Um visão geral. 8. ed. São Paulo: Pearson

Prentice Hall, 2008.


Universidade Federal do Esprito Santo - UFES

Centro de Ciˆencias Exatas

Departamento de Matem´atica

Mestrado Proﬁssional em Matem´atica em Rede Nacional - PROFMAT

TEORIA B ´ASICA DAS CADEIAS DE MARKOV

Autor: Mateus Mendes Magela

Orientador: Dr. Florˆencio Ferreira Guimar˜aes Filho

13 de Outubro de 2015

Mateus Mendes Magela

TEORIA B ´ASICA DAS CADEIAS DE MARKOV

Disserta¸c˜ao

apresentada

ao Mestrado

Proﬁssional

em Matem´atica

em Rede

Nacional

da

Sociedade Brasileira

de

Matem´atica (PROFMAT) em parceria com

o Centro de Ciˆencias Exatas da Universidade

Federal do Esp´ırito Santo, como requisito

parcial para obten¸c˜ao do grau de Mestre

em Matem´atica, sob orienta¸c˜ao do Professor

Doutor Florˆencio Ferreira Guimar˜ares Filho.

13 de Outubro de 2015

Agradecimentos

Aos meus pais, pela bravura diante de todas as diﬁculdades, pela dedica¸c˜ao que

sempre tiveram na minha educa¸c˜ao, por todo carinho e amor dedicados ao

Henrique, pelos exemplos de dignidade, honestidade e sobretudo trabalho.

A minha irm˜a pela amizade e carinho.

A minha esposa Fl´avia, minha hero´ına, que sempre me apoiou e incentivou nas

horas dif´ıceis. Por estar sempre ao meu lado, pelo seu carinho, por sua aten¸c˜ao,

pelo seu amor. Te amo.

Ao meu ﬁlho Henrique, pelo seu amor incondicional.

A minha nova fam´ılia, Garcia, Inˆes e Amanda, pela conﬁan¸ca, por todo apoio

recebido e pelo carinho e amor dedicados ao Henrique.

Ao meu orientador Prof. Dr. Florˆencio Guimar˜aes Filho por tudo que me ensinou,

devo a ele a oportunidade que tive de chegar at´e aqui, sua dedica¸c˜ao e competˆencia

como professor s˜ao exemplos que levarei por toda minha vida.

A Escola S˜ao Domingos pela conﬁan¸ca e pelo carinho que sempre tiveram comigo,

por me proporcionar conhecimento n˜ao apenas proﬁssional, sobretudo a forma¸c˜ao

do meu car´ater. Pelos grandes amigos aqui a´ı encontrei. Muito obrigado por tudo.

Resumo

As cadeias de Markov desempenham papel cresecente e importante na resolu¸c˜ao

de problemas em diversas ´areas do conhecimento como exemplo: Administra¸c˜ao,

Biologia, Gen´etica, Sociologia, Metereologia, Teoria de Jogos. A ﬁnalidade desse

trabalho ´e apresentar a importˆancia das aplica¸c˜oes da distribui¸c˜ao estacion´aria das

cadeias de Markov. Uma revis˜ao sobre os pr´e-requisitos necess´arios para compreens˜ao

da teoria ´e apresentada nos primeiros cap´ıtulos. Em seguida, ´e apresentada a teoria

geral das cadeias de Markov introduzindo algumas de suas aplica¸c˜oes. O ´ultimo

cap´ıtulo trata com destaque o algoritmo Page Rank, uma importante aplica¸c˜ao das

cadeias de Markov utilizada pelo Google para apresentar no topo as p´aginas da web

mais interessantes sobre o assunto pesquisado.

Palavras chave: Probabilidade.Matriz Estoc´astica.Cadeias de Markov.Page Rank.

Abstract

Markov chains play a rising and important role in problems solving in several

knowledge areas such as: Administration, Biology, Genetics, Meteorology and

Game theory.

This paper aims show the use of Markov chains stationary

distribution. A review about prerequisites necessary for comprehending the theory

will be presented in the ﬁrst chapters. Then, we will introduce the general theory

of Markov chains focusing on some of their applications. The last chapter will

highlight the Page Rank algorithm, an important feature of Markov chain used by

Google to place on top the most interesting web pages related to the researched

topic.

Key-words: Probabilility.Stochastic Matrix.Markov chains.Page Rank.

Conte´udo

1 Introdu¸c˜ao

2 Teoria das Probabilidades

9

11

2.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

2.2 Antecedentes Hist´oricos

. . . . . . . . . . . . . . . . . . . . . . . . .

12

2.3 Conceitos B´asicos . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.3.1 Experimento Aleat´orio . . . . . . . . . . . . . . . . . . . . . .

12

2.3.2 Espa¸co Amostral

. . . . . . . . . . . . . . . . . . . . . . . . .

13

2.3.3 Evento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.3.4 Deﬁni¸c˜ao C´assica de Probabilidades . . . . . . . . . . . . . . .

14

2.4 Espa¸co Equiprov´avel e Probabilidade . . . . . . . . . . . . . . . . . .

15

2.5 Probabilidade Condicional

. . . . . . . . . . . . . . . . . . . . . . . .

17

2.6 Processos Estoc´asticos Finitos . . . . . . . . . . . . . . . . . . . . . .

21

2.6.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

21

2.6.2

Independˆencia . . . . . . . . . . . . . . . . . . . . . . . . . . .

23

2.6.3 Problema Motivador

. . . . . . . . . . . . . . . . . . . . . . .

24

3 Matrizes

27

3.1 Antecedentes Hist´oricos

. . . . . . . . . . . . . . . . . . . . . . . . .

27

3.2

Introdu¸c˜ao a Teoria das Matrizes

. . . . . . . . . . . . . . . . . . . .

30

3.3

´Algebra Matricial

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

35

3.3.1 Adi¸c˜ao de Matrizes . . . . . . . . . . . . . . . . . . . . . . . .

35

3.3.2 Propriedades da Adi¸c˜ao de Matrizes . . . . . . . . . . . . . . .

40

3.3.3 Multiplica¸c˜ao de Matrizes

. . . . . . . . . . . . . . . . . . . .

41

3.3.4 Associatividade do Produto de Matrizes

. . . . . . . . . . . .

45

3.3.5 Distributividade do Produto em rela¸c˜ao a Soma . . . . . . . .

46

3.3.6

´Algebra Num´erica versus ´Algebra Matricial . . . . . . . . . . .

47

4 Matrizes Estoc´asticas

48

4.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

48

4.2 Matriz Estoc´astica Regular . . . . . . . . . . . . . . . . . . . . . . . .

50

4.3 Ponto ﬁxo de uma Matriz Estoc´astica Regular . . . . . . . . . . . . .

53

5 Cadeias de Markov

63

5.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

63

5.2 Andrei Andreyevich Markov . . . . . . . . . . . . . . . . . . . . . . .

67

5.3 Conceitos B´asicos sobre Cadeias de Markov . . . . . . . . . . . . . .

69

5.3.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

69

7

5.3.2 Deﬁni¸c˜ao de uma cadeia de Markov . . . . . . . . . . . . . . .

70

5.4 Passeios Aleat´orios Simples

. . . . . . . . . . . . . . . . . . . . . . .

74

5.5 Probabilidades de Transi¸c˜ao Superiores . . . . . . . . . . . . . . . . .

77

5.6 Cadeias de Markov Regulares

. . . . . . . . . . . . . . . . . . . . . .

82

5.6.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

82

5.6.2 Distribui¸c˜ao Estacion´aria de uma cadeia de Markov Regular .

84

5.7 Cadeias de Markov Absorventes . . . . . . . . . . . . . . . . . . . . .

92

6 Como o Google googla?

95

6.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

95

6.2 A Origem do Google . . . . . . . . . . . . . . . . . . . . . . . . . . .

97

6.3 A Web e as cadeias de Markov . . . . . . . . . . . . . . . . . . . . . .

98

6.3.1

Introdu¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

98

6.3.2 Web Fortemente Conectada . . . . . . . . . . . . . . . . . . .

99

6.3.3 Web n˜ao Fortemente Conectada . . . . . . . . . . . . . . . . . 106

Bibliograﬁa

111

8

9

1 Introdu¸c˜ao

Esta disserta¸c˜ao, de car´ater elementar, pretende introduzir os principais elementos

te´oricos sobre as cadeias de Markov.

De maneira simples podemos descrever um sistema em cadeia de Markov discreto,

como sendo um processo estoc´astico discreto em que o estado do sistema no

instante futuro n˜ao se altera pelo seu hist´orico, mas apenas ´e afetado pelo seu

estado presente. Esta caracter´stica confere as cadeias de Markov o apelido de

processo desmemoriado.

A ﬁnalidade das cadeias de Markov ´e prever um estado futuro apenas com rela¸c˜ao

ao estado atual do sistema. Como exemplo: um matem´atico vai lan¸car uma moeda

honesta quatro vezes. Qual a probabilidade de que o resultado seja cara, cara, cara,

cara? A resposta ´e 6,25%. Agora, suponhamos que o jogador j´a tivesse jogado a

moeda uma vez, e o resultado tenha sido cara, como pode a partir da´ı prever o

futuro? Esse ´e um t´ıpico exemplo de uma cadeia de Markov.

Atrav´es das cadeias de Markov,

foi poss´ıvel compreender melhor fenˆomenos

cient´ıﬁcos e sociais em diversas ´areas do conhecimento.Como exemplos podemos

destacar o engenheiro da computa¸c˜ao, que necessita construir um algoritmo de

busca que classiﬁca p´aginas da internet levando em considera¸c˜ao sua relevˆancia na

web.

O soci´ologo, que necessita entender como memes, ou de que forma

caracter´ısticas culturais espalham-se pela sociedade. O genteticista, que necessita

construir o mapa gen´etico de uma esp´ecie. O meteorologista, que precisa prever

cen´arios clim´aticos para uma determinada regi˜ao. Ou at´e mesmo um bi´ologo, que

necessecita estudar o comportamento futuro da popula¸c˜ao de uma determinada

esp´ecie marinha submetida a pesca industrial.

Essas aplica¸c˜oes decorrem em virtude da existˆencia de uma distribui¸c˜ao de

probabilidades estacion´aria das cadeias de Markov regulares,

cujo valor ´e

determinado por meio de uma artm´etica elementar envolvendo matrizes, tornando

sua aplica¸c˜ao uma tarefa simples para os programas alg´ebricos de computa¸c˜ao j´a

existentes.

As cadeias de Markov s˜ao assim denominadas em homenagem ao matem´atico russo

Andrei A. Markov (1856 - 1922). Ele analisou a sequˆencia de vogais e consoantes

no poema Eugene Onegin (1883). Ele veriﬁcou empiricamente que uma vogal era

seguida de uma consoante em 87% das vezes e que um consoante era seguida por

uma vogal 66% das vezes. Este trabalho ﬁcou conhecido como cadeias de Markov.

Na ´epoca ele n˜ao imaginava que seu trabalho tivesse alguma outra aplica¸c˜ao.

Dentre os principais matem´aticos que contribu´ıram para o seu avan¸co dessa teoria

podemos destacar o matem´atico russo Andrei Kolmorogov.

10

11

2 Teoria das Probabilidades

2.1

Introdu¸c˜ao

Quando o assunto ´e condom´ınio, a garagem ´e sempre um ponto delicado, em

especial quando se trata de distribui¸c˜ao das vagas entre as unidades.

Para

minimizar as reclama¸c˜oes, um edif´ıcio decidiu fazer sorteio das vagas de garagem de

ano em ano. O edif´ıcio possui 48 vagas sendo 36 vagas presas (ruins),ou seja,

aquela que depende de seu vizinho de garagem para que se possa acess´a-la e 12

vagas soltas (boas), em outras palavras vagas isoladas, aquelas em que o morador

tem livre acesso. O sorteio acontece por ordem de chegada da seguinte forma: o

morador que chegar primeiro, ´e tamb´em o primeiro a sortear uma vaga, o morador

que chegar em segundo ´e o segundo a sortear e assim por diante. Entretanto, essa

medida n˜ao foi suﬁciente para amenizar as reclama¸c˜oes, pois alguns moradores

passaram a protestar que o morador que tinha condi¸c˜oes de ser o primeiro a chegar

levava grande vantagem sobre os demais

.

Sendo assim,

surgem alguns

questionamentos. O primiero morador a sortear a vaga tem maior probabilidade de

tirar uma vaga boa do que o segundo no sorteio?

Existe alguma posi¸c˜ao no sorteio que privilegia o resultado de uma vaga boa?

A Teoria das Probabilidades ´e o ramo da Matem´atica que se dedica no

desenvolvimento e na busca por modelos que podem ser usados para resolver esse e

demais problemas que envolvam experimentos aleat´orios.

2.2 Antecedentes Hist´oricos

O desenvolvimento dessa teoria come¸cou a ter destaque no s´eculo XVII atr´aves de

debates sobre problemas de jogos de azar entre Blaise Pascal, Pierre de Fermat e

Antonie Gombaud, tamb´em conhecido como Chevalier de M´er´e. Embora tenha

uma longa hist´oria de aplica¸c˜ao pr´atica, apenas a partir das d´ecadas de 20 e 30 do

s´eculo XX que a teoria das probabilidades

foi

sistematizada com s´olida

fundamenta¸c˜ao te´orica, passanod a assumir com grande destaque estudos em

diversas ´areas como: F´ısica, Qu´ımica, Biologia, Medicina, Psicologia, Sociologia,

Ciˆencias Pol´ıticas, Educa¸c˜ao, Economia, Engenharia dentre outras.

2.3 Conceitos B´asicos

2.3.1 Experimento Aleat´orio

Experimentos que submetidos as mesmas condi¸c˜oes,

implicam em resultados

arbitrariamente distintos, s˜ao chamados de experimentos aleat´orios. Podemos dizer

em outras palavras, ´e todo aquele experimento cujos resultados n˜ao podem ser

previstos com certeza antes de sua execu¸c˜ao como exemplo:

lan¸camento de um

dado, sorteio da Mega-Sena, lan¸camento de uma moeda, pesquisa de satisfa¸c˜ao,

risco econˆomico de cr´etido, temperatura m´axima no ver˜ao.

12

2.3.2 Espa¸co Amostral

O conjunto de todos os resultados poss´ıveis de um experimento ´e denominado

espa¸co amostral. Cada elemento do espa¸co amostral ´e chamado de ponto amostral

ou simplismente amostra.

Exemplo 2.3.2.1: O experimento aleat´orio dado pela obsevar¸c˜ao da face voltada

para cima no lan¸camento de um dado tem como espa¸co amostral o conjunto A

dado por:

2.3.3 Evento

A = {1, 2, 3, 4, 5, 6}

Um evento ´e um conjunto de resultados poss´ıveis de um experimento. Quando o

espa¸co amostral ´e um conjunto ﬁnito, ent˜ao todo subconjunto ´e um evento. O

mesmo n˜ao acontece quando o espa¸co amostral ´e um conjunto inﬁnito.

Exemplo 2.3.3.1: No lan¸camento de um dado, podemos considerar como evento

E a observa¸c˜ao de um n´umero par na face voltada para cima.

´E importante observarmos que podemos combinar eventos para obter novos eventos

E = {2, 4, 6}

usando as opera¸c˜oes elementares dos conjuntos.

Exemplos:

a) A ∪ B ´e o evento que ocorre se, e somente se, ocorre apenas A, ocorre apenas B

ou ocorre ambos;

b) A ∩ B ´e o evento que ocorre se, e somente se, ocorrem A e B simultˆaneamente.

13

Deﬁni¸c˜ao: Dois eventos A e B s˜ao chamados de mutuamente exclusivos se eles s˜ao

disjuntos, ou seja, se A ∩ B = (cid:11). Podemos dizer em outras palavras, A e B s˜ao

multuamente exclusivos se, e somente se, n˜ao podem ocorrer simultˆaneamente.

Exemplo 2.3.3.2: Seja A o evento em que o resultado no lan¸camento de um dado

seja um n´umero par e B o evento em que o resultado no lan¸camento de um dado

seja um n´umero ´ımpar. Ent˜ao temos:

A = {2, 4, 6} ; B = {1, 3, 5}

Os eventos A e B s˜ao multuamente exclusivos uma vez que n˜ao ´e poss´ıvel que um

n´umero seja par e ´ımpar simultˆaneamente.

2.3.4 Deﬁni¸c˜ao C´assica de Probabilidades

Consideremos o evento E = {2, 4, 6}. Se lan¸carmos um dado honesto um grande

n´umero de vezes,

´e

intuitivo esperar que um n´umero par ocorrer´a em

aproximadamente metade das observa¸c˜oes. Isso decorre dos seguintes fatos:

1) os eventos elementares equiprov´aveis

(elementos

favor´aveis)

s˜ao aqueles

igualmente prov´aveis;

2) o n´umero de elementos de E ´e justamente a metade dos elementos do espa¸co

amostral(todos os elementos poss´ıveis).

Estas condi¸c˜oes provocam a seguinte deﬁni¸c˜ao de probabilidade.

Probabilidade = n´umero de resultados favor´aveis
n´umero de resultados poss´ıveis

Dessa forma se um evento E ocorre de a maneiras dentre um total de b maneiras

igualmente prov´aveis, ent˜ao a probabilidade (chance) P(E) do evento E ocorrer ´e

14

dada por

P(E) = a
b

2.4 Espa¸co Equiprov´avel e Probabilidade

Seja S um espa¸co amostral ﬁnito tal que S = {s1, s2, · · · , sn}. Um espa¸co ﬁnito de

probabilidades ´e obtido associando-se a cada elemento sj ∈ S um n´umero real n˜ao

negativo pj, denominado a probabilidade de sj, tal que p1 + p2 + · · · + pn = 1:

Indicamos por P(E) a probabilidade de um evento E, deﬁnida como sendo a soma

das probabilidades dos elementos de E.

Exemplo 2.4.1.

Consideremos o lan¸camento simultˆaneo de 3 moedas e

observemos o n´umero de caras. O espa¸co amostral desse experimento aleat´orio ´e

dado pelo conjunto

Obtemos um espa¸co de probabilidades pela seguinte associa¸c˜ao:

A = {0, 1, 2, 3}

P (0) = 1

8, P (1) = 3

8, P (2) = 3

8, P (3) = 1

8

em que P(0) ´e a probabilidade de sair nenhuma cara, P(1) ´e a probabilidade de sair

1 cara, P(2) ´e a probabilidade de sair 2 caras e P(3) ´e a probabilidade de sair 3 caras.

Note que cada probabilidade ´e n˜ao negativa e a soma ´e 1.

Agora seja A o evento em que ocorre pelo menos 1 cara e seja B o evento em que

ocorrem apenas caras ou apenas coroas.

15

Ent˜ao pela deﬁni¸c˜ao,

P (A) = P (1) + P (2) + P (3) =

3
8

+

3
8

+

1
8

=

7
8

P (B) = P (0) + P (3) =

1
8

+

1
8

=

1
4

Deﬁni¸c˜ao: Um espa¸co ﬁnito de probabilidades S, em que cada ponto amostral

tem a mesma probabilidade, ´e denominado um espa¸co equiprov´avel. Em particular,

se S cont´em n elementos, ent˜ao a probabilidade de cada ponto amostral ´e 1

n . Al´em
disso, se um evento E cont´em m elementos, ent˜ao sua probabilidade ´e dada por

P(E) = m

n . Em outras palavras,

P(E) = n´umero de elemento de A
n´umero de elementos de S

´E importante ressaltar que, a equiprobabilidade ´e uma caracter´ıstica do modelo de

probabilidade e n˜ao do espa¸co amostral.

Exemplo 2.4.2: A Mega Sena ´e uma das loterias mais populares do Brasil.

Organizada pela Caixa Econˆomica Federal, ´e a loteria que mais premia no pa´ıs,

principalmente quando acumula o prˆemio por v´arias semanas. Qual ´e a chance real

de algu´em acertar os seis n´umeros?

Primeiro passo ´e veriﬁcar o total de agrupamentos poss´ıveis, 6 a 6, dos 60 n´umeros.

Eles podem ser calculados pelo princ´ıpio multiplicativo da contagem por meio do

produto 60 x 59 x 58 x 57 x 56 x 55 = 36.045.979.200.

Mas, um cart˜ao ´e contado 720 vezes, o total de possibilidades de trocas na ordem

desses 6 n´umeros e, portanto, para achar o n´umero de cart˜oes distintos ´e preciso

dividir o resultado por 720. Ao fazermos a conta encontramos 50.063.860. Logo, a

16

probabilidade de um apostador ganhar na Mega-Sena com apenas um cart˜ao de

seis n´umeros ´e

1
50.063.860

∼= 0, 000001997%

´E mais prov´avel jogar uma moeda 25 vezes seguidas e conseguir sempre o mesmo

resultado do que ganhar o prˆemio da loteria.

Total de combina¸c˜oes dos lan¸camentos = 2 · 2 · · · · · 2
(cid:125)

(cid:124)

(cid:123)(cid:122)
25vezes

= 225 = 33.554.432.

Logo, a probabilidade de que ocorre um mesmo resultado em todos os 25

lan¸camentos consecutivos de uma moeda ´e

1
33.554.432

∼= 0, 000002980%

2.5 Probabilidade Condicional

Seja E um evento arbitr´ario num espa¸co amostral S com P (E) > 0. A probabilidade

de que um evento A ocorra na certeza da ocorrˆencia de um evento E inidcada por

P (A|E) ´e deﬁnida por:

P(A|E) = P (A∩E)
P (E)

Note-se que P (A|E) somente est´a deﬁnida quando P (E) >0.

Se P (E) = 0 a probabilidade

condicional P (A|E) pode

ser deﬁnida

arbitrariamente. Convenientemente quando P (E) = 0 deﬁnimos P (A|E) = P (A).

Sendo assim, sempre que P (E) >0 podemos escrever

17

P(A∩E) = P (E) · P (A|E)

Podemos observar no diagrama a seguir que P (A |E) mede, num certo sentido, a

probabilidade relativa de A com rela¸c˜ao ao espa¸co reduzido E.

Figura 2.1: Diagrama

Exemplo 2.5.1: Um experimento foi conduzido com o objetivo de avaliar o poder

germinativo de duas culturas de cebola, conforme mostra a tabela abaixo.

Desejando-se fazer uma avalia¸c˜ao do poder germinativo de uma das culturas de

cebola, uma amostra foi retirada ao acaso. Sabendo-se que a amostra escolhida

germinou, qual a probabilidade de essa amostra pertencer `a Cultura A?

Figura 2.2: BUSSAB, W. O; MORETIN, L. G. Estat´ıstica para as ciˆencias agr´arias e biol´ogicas

(adaptado).

18

Queremos encontrar a probabilidade da amostra retirada pertencer a cultura A

considerando como espa¸co amostral reduzido somente as sementes que germinaram.

O experimento foi realizado com um total de 800 sementes dentre as quais 773

germinaram. Das 773 sementes que germinaram, 392 pertencem a cultura A. Sendo

assim, a probabilidade condicional de retirar uma semente da cultura A sabendo

que a semente germinou ´e dada por

392
773

∼= 50%

Fl´avia escreva a carta ´e de 8

Exemplo 2.5.2: Fl´avia quer enviar uma carta a Amanda. A probabilidade de
10. A probabilidade de que o correio n˜ao a perca ´e de 9
10.
10. Dado que Amanda n˜ao recebeu

A proabilidade de que o carteiro a entregue ´e de 9

a carta, qual a probabilidade condicional de que Fl´avia n˜ao tenha escrito a carta?

P (n˜ao escreve/n˜ao recebe) =

P (n˜ao escreve)
P (n˜ao recebe)

=

2/10
10 + 8

2

10 + 8

10. 1

10. 9

10. 1

10

=

25
44

.

Figura 2.3: Diagrama de ´arvore - problema da carta

19

Teorema da Probabilidade Composta: Sejam A e B dois conjuntos quaisquer

tais que A ∩ B ´e n˜ao vazio. Ent˜ao temos:

1) P (A ∩ B) = P (A)P (B|A) = P (B)P (A|B);

2) Se P (A1 ∩ A2 ∩ · · · ∩ An)

(cid:54)= 0,

ent˜ao P (A1 ∩ A2 ∩ · · · ∩ An) =

P (A1)P (A2|A1)P (A3|(A1 ∩ A2)) · · · P (An|A1 ∩ A2 ∩ · · · ∩ An−1).

Demonstra¸c˜ao: 1) Sabemos que

P (A|B) =

P (A ∩ B)
P (B)

P (B|A) =

P (B ∩ A)
P (A)

.

Da´ı segue que,

P (A ∩ B) = P (B)P (A|B);

P (B ∩ A) = P (A)P (B|A);

Como P (A ∩ A) = P (B ∩ A) temos que

P (B)P (A|B) = P (A)P (B|A)

Como quer´ıamos mostrar.

2)Para dois conjuntos A1 e A2 a f´ormula ´e verdadeira, pois j´a vimos que P (A ∩ B) =

P (A)P (B/A). Agora, vejamos a senten¸ca para trˆes conjuntos A1, A2 e A3.

P (A1 ∩ A2 ∩ A3) = P (A3|(A1 ∩ A2))P (A1 ∩ A2) = P (A3|(A1 ∩ A2))P (A2|A1)P (A1),

como quer´ıamos mostrar. No caso geral a demonstra¸c˜ao ´e an´aloga e segue o Princ´ıpio

da Indu¸c˜ao Completa.

Exemplo 2.5.3: Em um lote de 12 pe¸cas, das quais 4 s˜ao defeituosas, trˆes pe¸cas

s˜ao escolhidas ao acaso, uma ap´os a outra. Qual a probabilidade de que todas as

trˆes pe¸cas retiradas sejam n˜ao defeituosas.

Solu¸c˜ao: A probabilidade de que a primeira pe¸ca seja n˜ao defeituosa ´e 8

12, uma vez

20

que 8 das 12 pe¸cas s˜ao n˜ao defeituosas. Se a primeira pe¸ca ´e n˜ao defeituosa, ent˜ao a

probabilidade de que a segunda pe¸ca escolhida seja n˜ao defeituosa ´e 7

11, pois 7 das 11
pe¸cas restantes s˜ao n˜ao defeituosas. Se as duas primeiras pe¸cas escolhidas s˜ao n˜ao

defeituosas, ent˜ao a probabilidade da terceira pe¸ca escolhida ser n˜ao defeituosa ´e 6
10.
Assim, pelo teorema do produdo segue que a probabilidade de se retirar trˆes pe¸cas

n˜ao defeituosas ´e dada por

8
12

·

7
11

·

6
10

=

14
55

2.6 Processos Estoc´asticos Finitos

2.6.1 Introdu¸c˜ao

Uma sequˆencia ﬁnita de experimentos, na qual cada experimento tem um n´umero

ﬁnito de ocorrˆencias com probabilidades conhecidas, ´e chamado de um processo

estoc´astico ﬁnito. Um m´etodo conveniente para descrever um processo estoc´astico

ﬁnito e calcular a probabilidade de qualquer evento ´e atrav´es de um diagrama de

´arvore.

Exemplo 2.6.1.1:

Escolhemos aleatoriamente uma dentre duas moedas

dispon´ıveis A e B. Sabemos que a moeda A ´e honesta e que a moeda B possui cara

(C) em ambos os lados. A moeda escolhida ´e lan¸cada. Se o resultado for coroa (K),

joga-se um dado honesto, caso contr´ario joga-se a moeda novamente. A primeira

etapa do experimento ´e escolher uma moeda. A segunda etapa ´e lan¸car a moeda

escolhida e a terceira etapa ´e lan¸car uma moeda ou um dado, dependendo dos

resultados obtidos nas duas primeiras etapas.

Indicamos todos os poss´ıveis

resultados do experimento pela ´arvore de probabilidade abaixo:

21

Figura 2.4: Diagrama de ´arvore

Os poss´ıveis resultados para o experimento s˜ao:

(A, C, C) , (A, C, K) , (A, K, 1) ,

(A, K, 2) , (A, K, 3) , (A, K, 4) ,

(A, K, 5) , (A, K, 6) , (B, K, K) .

Cada resultado pode ser identiﬁcado como um caminho atrav´es da ´arvore. Cada

caminho ´e composto por segmentos chamados de ramos. Nesta ´arvore, h´a nove

caminhos com trˆes ramos cada. o processo descrito acima, pode ser realizado para

qualquer experiˆencia que ocorre em etapas. Exigimos apenas que haja num n´umero

ﬁnito de resultados em cada etapa e que saibamos as probabilidades para qualquer

resultado na en´esima etapa dado o conhecimento do resultado da (n−1)-´esima etapa.

Para cada n obtemos uma ´arvore Tn. A probabilidade de que um caminho particular

22

da ´arvore ocorra ´e dado pelo teorema da multiplica¸c˜ao como sendo o produto das

probabilidades de cada ramo do caminho. Por exemplo, a probabilidade de se escolher

a moeda A e a partir da´ı obter o n´umero 3 no lan¸camento de dado honesto ´e dado

pelo produto:

1
2

.

1
2

.

1
6

=

1
24

2.6.2

Independˆencia

Os eventos aleat´orios A e B s˜ao estocasticamente independentes se

P(A∩B) = P (A) · P (B)

Os eventos de probabilidade 0 ou 1 s˜ao independentes de qualquer outro.

Se P (A) = 0, ent˜ao P (A ∩ B) = 0 e A e B s˜ao independentes.

Se P (B) = 1, ent˜ao P (A ∩ B) = P (A) − P (A ∩ Bc) = 0 e P (A ∩ B) = P (A)P (B)

Logo A e B s˜ao independentes.

Exemplo 2.6.2.1: Uma moeda ´e lan¸cada duas vezes. Obtemos nesse caso o espa¸co

amostral equiprov´avel S dado por

S = {CC, CK, KC, KK}

em que C representa cara e K representa coroa.

Consideremos o evento A em que cara ocorra no primeiro lan¸camento e B o evento

em que cara ocorra no segundo lan¸camento.

P (A) =

2
4

=

1
2

P (B) =

2
4

=

1
2

Por outro lado, a probabilidade de que cara ocorre no primeiro e no segundo

lan¸camento ´e dada por

23

P (A ∩ B) =

1
4

Portanto, P(A∩B) = P (A) · P (B)

Consequentemente, A e B s˜ao eventos independentes.

2.6.3 Problema Motivador

Na introdu¸c˜ao deste cap´ıtulo iniciamos o texto com um problema motivador. O

problema em quest˜ao ´e denominado Problema das Garagens. Esse problema foi

vivenciado pelo professor Florˆencio Guimar˜ares Filho em um antigo pr´edio em que

morava, e desde que ele apresentou esse problema em uma aula do PIC (Programa

de Inicia¸c˜ao Cient´ıﬁca da OBMEP) na qual eu participava como seu monitor,

sempre o apresento em minhas aulas sobre probabilidade como um problema

motivador, aﬁm de despertar o interesse e a partici¸c˜ao dos alunos. Fato interessante

´e que, alguns alunos acabam se identiﬁcam com o problema, relatando que j´a

passaram por uma situa¸c˜ao semelhante. Segue a seguir uma solu¸c˜ao para esse

problema.

Solu¸c˜ao: A probabilidade de um morador retirar um vaga boa (B) sendo o

primeiro a sortear ´e de 12

48 = 1

4 = 25%.

Agora, sendo o segundo podem ocorrer dois casos: BB(boa,boa) ou RB(ruim,boa).

P (BB) =

12
48

·

11
47

P (RB) =

36
48

·

12
47

24

Sendo assim, a probabilidade do morador sortear uma vaga sendo o segundo na

ordem ´e de

P (BB) + P (RB) =

12
48

·

11
47

+

36
48

·

12
47

=

12
48

(cid:18) 11
47

+

36
47

(cid:19)

=

12
48

·

47
47

=

12
48

=

1
4

Portanto a probabilidade do morador sortear uma vaga boa sendo o primeiro ou

segundo da lista ´e a mesma.

Suponhamos agora que o morador seja o terceiro da lista, ent˜ao podem ocorrer quatro

casos favor´aveis: BBB,BRB,RRB,RBB.

Logo a probabilidade de uma vaga boa ser sorteada nessas condi¸c˜oes ´e dada por

P (BBB)+P (BRB)+P (RRB)+P (RBB) =

12
48

·

11
47

·

10
46

+

12
48

·

36
47

·

11
46

+

36
48

·

35
47

·

12
46

+

36
48

·

12
47

·

11
46

=

12
48

(cid:18) 11
47

=

12
48

·

·

·

+

+

10
46

11
46

35
46

36
47

36
46
(cid:18) 11.10 + 36.11 + 35.36 + 36.11
46.47

36
47

+

·

11
47
(cid:19)

(cid:19)

=

12
48

·

2162
2162

=

1
4

Ent˜ao, a probabilidade de uma vaga boa sair em primeiro, segundo, terceiro.

Agora supomos que em um determinado momento do sorteiro temos b vagas boas e

r vagas ruins. A probabilidade de um morador sortear uma vaga boa nessa situa¸c˜ao

´e dada por

b
b + r

.

E a probabilidade do pr´oximo morador sortear uma vaga boa ´e dada por

b
b + r

·

b − 1
b + r − 1

+

r
b + r

·

b
b + r − 1

=

b(b + r − 1)
(b + r)(b + r − 1)

=

b
b + r

25

Portanto, n˜ao existem motivos para que os protestos dos moradores quanto a

ordem do sorteio.

Uma outra forma de esclarecer esse problema ´e pensar no resultado do sorteio como

sendo uma lista em que cada sorteio resume-se a uma lista de vagas boas (B) ou

ruins (R). Dessa forma queremos saber se existe uma posi¸c˜ao mais privilegiada na

lista ﬁnal.

Note que, o total de listas distintas ´e dada por

48!
12! · 36!

Fixando uma vaga boa arbitrariamente em qualquer posi¸c˜ao na lista, o n´umero de

listas distintas dessa forma ´e dado por

47!
11! · 36!

Sendo assim, a probabilidade de que uma vaga boa aparecer em uma posi¸c˜ao

arbitraria na lista ´e

47!
11!·36!
48!
12!·36!

=

12
48

=

1
4

Portanto, a probabilidade de uma vaga boa aparecer em qualquer posi¸c˜ao na lista ´e

mesma, n˜ao havendo dessa forma uma posi¸c˜ao privilegiada na ordem do sorteio.

26

27

3 Matrizes

3.1 Antecedentes Hist´oricos

Por muitos s´eculos, matem´aticos trabalharam na elabora¸c˜ao e no entendimento de

problemas envolvendo blocos num´ericos como exemplo os quadrados m´agicos. No

quadrado m´agico mais simples, deve-se arranjar os n´umeros 1,2,3,4,5,6,7,8 e 9

usando-os uma ´unica vez, numa tabela 3 x 3, de modo que, os n´umeros em cada

linha, coluna ou diagonal somem 15.

Figura 3.1: Quadrado M´agico 3x3

Segundo uma lenda, o primerio quadrado m´agico surgiu h´a 4000 anos,

inscrito

sobre um casco de tartaruga que se arrastava saindo do rio Lo, na China. O rio

havia provocado uma grande enchente, e o imperador Yu ordenou que se ﬁzesse

sacrif´ıcios para agradar o deus do rio. Em contrapartida, o deus enviou uma

tartaruga, cujo padr˜ao num´erico inscrito no seu casco, destinava-se a ajudar o

imperador a controlar o rio.

Uma vez descoberto o arranjo num´erico, os

matem´aticos chineses come¸caram a construir quadrados maiores que funcionassem

da mesma forma. Esses quadrados eram reconhecidos como detentores de grandes

propriedades m´agicas. H´a evidˆencias de que os quadrados m´agicos foram levados
para ´India por mercadores chineses que lidavam n˜ao somente com especiarias, mas

tamb´em com ideias matem´aticas. Os quadrados m´agicos tamb´em foram populares

na cultura islˆamica medieval. Uma das primeiras exibi¸c˜oes de quadrados m´agicos

na Europa ´e o quadrado que aparece na gravura Melancholia, de Albrecht Durer.

Figura 3.2: Melancholia, de Albercht Durer

Nesse quadrado, os n´umeros de 1 a 16 est˜ao dispostos em linhas, colunas e

diagonais que somam 34. Durer ainda dispˆos os dois n´umeros centrais da ´ultima

linha para registrar o ano da gravura: 1514.

Quadrados m´agicos de diferentes tamanhos eram tradicionalmente associados a

planetas do sistema solar. O cl´assico 3 x 3 era associado a Saturno, o quadrado 4 x

28

Figura 3.3: Quadrado M´agico de Durer

4, a J´upter, enquanto o 9 x 9, era atribu´ıdo `a Lua. Uma explica¸c˜ao para o uso que

Durer fez do quadrado ´e que este reﬂetia a cren¸ca m´ıstica de que o esp´ırito alegre

de J´upter podia se contrapor ao senso de melancolia presente na gravura.

Entretanto, a ideia de tratar blocos num´ericos como um ´unico n´umero decolou

apenas h´a 150 anos com um pequeno grupo de matem´aticos que reconheceram seu

potencial. Doravante, o progresso de uma ´algebra unidimensional para uma ´algebra

de m´ultipla dimens˜oes demonstrou ser incrivelvente potente para aplica¸c˜oes

soﬁsticadas.

Augustin-Louis Cauchy (1789 - 1857), matem´atico francˆes, foi o primeiro a nomear

a essas conﬁgura¸c˜oes num´ericas de tableau, que em francˆes, signiﬁca tabela em

1826, mas o nome matriz surgiu em 1850 com James Joseph Sylvester. Entretanto,

foi Arthur Cayley em 1858, na sua publica¸c˜ao de Memoir on the Theory of

Matrices, quem formulou a primeira deﬁni¸c˜ao abstrata de matriz. Cayley tamb´em

forneceu uma ´algebra matricial, deﬁnindo adi¸c˜ao, multiplica¸c˜ao de matrizes,

multiplica¸c˜ao por escalar e matriz invert´ıvel. Foi a partir dos trabalhos de Cayley

que as matrizes passaram a ter relevˆancia e gradativamente foram superando os

determinantes em grau de importˆancia.

As matrizes est˜ao envolvidas em diversas ´areas do conhecimento e em diversas

atividades humanas, como por exemplo: nos jogos eletrˆonicos, os programas de

29

inform´atica, a aplica¸c˜ao de bancos de dados e internet, nos sistemas de rede el´etrica

e de transportes, s˜ao apenas alguns exemplos em que a aplica¸c˜ao de matrizes ´e

fundamental.

Neste cap´ıtulo apresentaremos as deﬁni¸c˜oes b´asicas da teoria de matrizes

necess´arias no desenvolvimento e na ´analise do estudos das cadeias de Markov.

3.2

Introdu¸c˜ao a Teoria das Matrizes

Frequentemente encontramos em revistas,

jornais ou documentos,

informa¸c˜oes

nu-m´ericas organizadas na forma de tabelas retangulares dispostas em linhas e

colunas. Estas tabelas de dados num´ericos s˜ao simpliﬁcadas, utilizando uma forma

denominada matriz. As matrizes est˜ao presentes em v´arias atividades cient´ıﬁcas

dentre as quais podemos destacar: an´alise de redes el´etricas, programa¸c˜ao linear

geom´etricas,

cadeias de Markov,

jogos de estrat´egia, modelos econˆomicos,

administra¸c˜ao de ﬂorestas, computa¸c˜ao gr´aﬁca, criptograﬁa dentre.

Exemplo 3.2.1. A tabela a seguir ´e parte da an´alise das condi¸c˜oes de vida da

popula¸c˜ao brasileira em 2014 realizada pelo IBGE.

Os dados s˜ao referentes ao n´umero de pessoas de 16 anos ou mais ocupadas em

alguma atividade economica nos estados de Alagoas e Esp´ırito Santo.

HOMENS MULHERES

AL

ES

757000

1076000

494000

783000

Tabela 3.1: IBGE, Pesquisa Nacional por Amostra de Domic´ılios 2013

30

Podemos representar a tabela acima na forma de uma matriz M dada por





M =

757000

494000

1076000 783000





Dessa forma deﬁmos matriz como sendo qualquer arranjo retangular de informa¸c˜oes

num´ericas organizadas em linhas e colunas.

As linhas s˜ao contadas de cima para baixo. A primeira e a segunda linha da matriz

M s˜ao respectivamente

(757000 494000)

;

(1076000 783000).

As colunas s˜ao contadas da esquerda para direita. A primeira e a segunda coluna

da matriz M s˜ao respectivamente





757000

1076000





 ;





 .

494000

783000

O elemento da matriz localizado na linha i e na coluna j ´e denotado por aij. Ent˜ao,

na matriz M temos: a11 = 757000, a12 = 494000, a21 = 1076000 e a22 = 783000.

Exemplo 3.2.2. Um grupo de alunos dos cursos A, B e C solicita transferˆencia

para outro curso, escolhido entre os mesmos A, B e C. A matriz abaixo, representa

o resultado obtido ap´os o processo de transferˆencia, admitindo que cada aluno pode

se matricular em apenas um curso








T =

137

7

8

12

14

115

13

15

119








em que a linha 1 representa a quantidade de alunos oriundos do curso A dentre os

31

quais 137 pernaneceram, 7 se transferiram para o curso B e 8 se transferiram para o

curso C. A linha 2 representa a quantidade de alunos oriundos do curso B dentre os

quais 12 alunos se transferiram para o curso A, 115 permaneceram no curso B e 13

se transferiram para o curso C. A linha 3 representa a quantidade de alunos

procedentes do curso C dentre os quais 14 se transferiram para o curso A, 15 se

transferiram para o curso B e 119 permaneceram matriculados no curso C.

Podemos dizer tamb´em por exemplo que a coluna 1 representa a quantidade de

alunos matriculados no curso A ap´os encerrado o per´ıodo de transferˆencias dentre

os quais, 137 j´a frequentavam o curso A, 12 estudavam no curso B e 14 estudavam

no curso C. A segunda coluna representa a quantidade de alunos matriculados no

curso B ap´os encerrado o per´ıodo de transferˆencias dentre os quais 7 estudavam no

curso A, 115 permaneceram no curso B e 15 s˜ao oriundos do curso C. A terceira

linha representa a quantidade de alunos matriculados no curso C ap´os encerrado o

per´ıodo de transferˆencias dentre os quais 8 estudavam no curso A, 13 estudavam no

curso B e 119 permaneceram matriculados no curso C.

Analisando a matriz T, qual a quantidade total do n´umero de alunos transferidos?

a12 + a13 + a21 + a23 + a31 + a32 = 69.

Portanto, 69 alunos transferiram de curso

Qual a quantidade de alunos que estavam matriculados no curso A antes do

processo de transferˆencia?

Para isso, basta somarmos o n´umero de alunos que permaneceram no curso A com

aqueles que se transferiram do curso A para o curso B ou C. Dessa forma fazemos,

32

a11 + a12 + a13 = 147.

Portando, haviam 147 estudantes matriculados no curso A.

Exemplo 3.2.3. Cada elemento aij da matriz M indica o tempo, em minuto, que

um sem´aforo ﬁca aberto num per´ıodo de 2 minutos, para que haja o ﬂuxo de

ve´ıculos da rua i para a rua j, considerando que cada rua tenha m˜ao dupla.

A =








0

1.5 0.5

1.5

0.5

0

1

1

0








Com base nos dados, e admitindo que ´e poss´ıvel at´e 20 carros passarem por minuto

cada vez que o sem´aforo se abre, em um per´ıodo de 2 horas, qual o n´umero m´aximo

de ve´ıculos podem passar da rua 3 para a rua 1?

Solu¸c˜ao: Segue da matriz M que o sem´aforo que permite aos ve´ıculos passarem da

rua 3 para a rua 1 ﬁca aberto por 0.5 minutos a cada 2 minutos, isto ´e, a cada uma

hora este sem´aforo ﬁca aberto por 30 x 0.5 = 15 minutos. Agora considerando o

ﬂuxo m´aximo de carros, temos 20 x 15 = 300 carros passando da rua 3 para a rua 1

em uma hora. Portanto, em duas horas, podem passar da rua 3 para a rua 1, 600

carros.

Deﬁni¸c˜ao: Uma matriz ´e uma tabela retangular com m linhas e n colunas cujos os

elementos aij representam elementos com dupla entrada, ou seja, com ´ındices

duplos em que 1 ≤ i≤ m e 1 ≤ j≤ n sendo m,n inteiros positivos.

Representamos uma matriz A = (aij) de ordem m x n, na qual o elemento aij

encontra-se na interse¸c˜ao da i-´esima linha com a j-´esima coluna da seguinte forma:

33

A =











a11

a12

· · ·

a1n

a21
a22
...
...
am1 am2

· · ·
. . .

a2n
...
· · · amn











Ent˜ao, podemos escrever que A = (aij)mxn

Exemplo 3.2.4: Considere a matriz A = (aij)mxn, tal que os elemntos aij s˜ao

dados por aij = 3i − 2j para resolver os itens abaixo:

a) represente a matriz A tal que m = 3 e n = 2;

b) determine a soma de todos os elemntos da segunda coluna da matriz A.

Solu¸c˜ao: a) Obedecendo a lei de forma¸c˜ao dos elementos de A temos que:

a11 = 3 · 1 − 2 · 1 = 3 − 2 = 1

a12 = 3 · 1 − 2 · 2 = 3 − 4 = −1

a21 = 3 · 2 − 2 · 1 = 6 − 2 = 4

a22 = 3 · 2 − 2 · 2 = 6 − 4 = 2

a31 = 3 · 3 − 2 · 1 = 9 − 2 = 7

a32 = 3 · 3 − 2 · 2 = 9 − 4 = 5

Logo, a matriz A ´e representada por:

A =















1 −1

4

7

2

5

Solu¸c˜ao: b) A soma dos elementos da segunda coluna ´e -1 + 2 + 5 = 6.

Exemplo 3.2.5. Uma f´abrica produz trˆes modelos de carros utilizando diferentes

pe¸cas para a montagem do motor. Considerando a matriz abaixo

34

A =








15 10 12

10 11 13

14 12 11








em que cada elemento aij representa a quantidade de pe¸cas do tipo j utilizada na

fabrica¸c˜ao de um carro do modelo i.

Quantas pe¸cas ser˜ao utilizadas para fabricar o modelo 2 de carro?

Solu¸c˜ao: Basta somarmos os elementos da segunda linha, 10 + 11 + 13 = 34. Logo,

ser˜ao utilizadas 34 pe¸cas.

3.3

´Algebra Matricial

3.3.1 Adi¸c˜ao de Matrizes

Uma vantagem fundamental da ´algebra de matricial ´e que podemos considerar uma

grande quantidade de informa¸c˜oes num´ericas, como sendo, apenas um objeto.

Exemplo 3.3.1.1: Observe a tabela abaixo:

produto 1 produto 2 produto 3 produto 4

f´abrica 1

f´abrica 2

f´abrica 3

7

0

3

5

4

2

0

3

0

1

7

2

Tabela 3.2: Tabela de produ¸c˜ao de Janeiro 2015

Suponhamos que essa tabela represente a produ¸c˜ao da empresa Alfa no mˆes de

35

janeiro de 2015, e que essa empresa, tenha trˆes f´abricas situadas em distintas parte

do pa´ıs e a produ¸c˜ao de cada um de seus quatro produtos, ´e medida em milh˜oes de

unidades. Assim, podemos representar sua produ¸c˜ao atrav´es de uma matriz A, de

modo que, cada elemento aij representa a produ¸c˜ao em milh˜oes de unidades da

f´abrica i e do produto j.

A =















7 5 0 1

0 4 3 7

3 2 0 2

Agora,

suponhamos que no mˆes

seguinte, a produ¸c˜ao dessa empresa seja

demonstrada pela tabela a seguir.

produto 1 produto 2 produto 3 produto 4

f´abrica1

f´abrica2

f´abrica3

9

0

4

4

5

1

1

1

1

0

8

0

Tabela 3.3: Tabela de produ¸c˜ao de Fevereiro 2015

Sendo assim, podemos representar os dados de produ¸c˜ao do mˆes de fevereiro de

2015 atrav´es da matriz B representada a seguir:

B =















9 4 1 0

0 5 1 8

4 1 1 0

Para apresentar os resultados da produ¸c˜ao total do primeiro bimestre de 2015 da

empresa Alfa, ´e necess´ario somar as produ¸c˜oes dos meses de janeiro e fevereiro de

36

2015, fazemos isso somando os elementos correspondentes nos dois quadros.

Essa situa¸c˜ao representa uma adi¸c˜ao de matrizes, conforme demonstrada a seguir:

A + B =








7 5 0 1

0 4 3 7

3 2 0 2















+

9 4 1 0

0 5 1 8

4 1 1 0















=

7 + 9 5 + 4 0 + 1 1 + 0

0 + 0 4 + 5 3 + 1 7 + 8

3 + 4 2 + 1 0 + 1 2 + 0








Portanto, a soma das matrizes A e B ´e dada por

A + B =








16 9 1

1

0

7

9 4 15

3 1

2








Exemplo 3.3.1.2. Uma editora pretende publicar uma cole¸c˜ao de livros de
´Algebra e Geometria em duas vers˜oes: volumes 1,2 e 3 e uma outra volume ´unico.

A tabela I mostra a quantidade de cada volume a ser lan¸cado no primeiro semestre

do ano e a tabela II mostra a quantidade de cada volume a ser lan¸cado no segundo

semestre do ano.

Volume

´Algebra Geometria

1

2

3
´Unico

200

220

260

300

250

230

240

310

Tabela 3.4: Tabela I: Quantidades de exemplares no primeiro semestre (em milhares

de unidades)

37

Volume

´Algebra Geometria

1

2

3
´Unico

170

120

120

350

150

140

140

410

Tabela 3.5: Tabela II: Quantidades de exemplares no segundo semestre (em milhares

de unidades)

Quantos livros de ´Algebra e Geometria de cada volume ser˜ao lan¸cados por essa

editora nesse ano?

Solu¸c˜ao: Para determinarmos o total de livros lan¸cados ´e preciso somar os

elementos correspondentes nas duas tabelas.

Volume

´Algebra Geometria

1

2

3
´Unico

370

340

380

650

400

370

380

720

Tabela 3.6: Tabela III: Quantidades de exemplares no ano (em milhares de unidades)

Esse problema pode ser resolvido atrav´es da soma de duas matrizes, conforme

mostrado a seguir:

38

A + B =











200 250

220 230

260 240

300 310





















+

170 150

120 140

120 140

350 410





















=

370 400

340 370

380 380

650 720











Note que a soma de matrizes segue uma soma alg´ebrica convencional entre os

elementos correspondentes (de mesmo ´ındice duplo). Portanto, podemos somar

duas matrizes somente quando elas forem de mesma ordem,

isto ´e, se ambas

tiverem o mesmo n´umero de linhas e colunas.

Deﬁni¸c˜ao: Deﬁnimos a soma de duas matrizes, como sendo a soma entre os seus

elementos correspondentes, isto ´e, de mesma posi¸c˜ao.

De modo geral, dadas as matrizes A = (aij) e B = (bij), deﬁnimos a soma

A + B = (cij) como sendo:











a11

a12

· · ·

a1n

a21
a22
...
...
am1 am2

· · ·
. . .

a2n
...
· · · amn





















+

b11

b12

b21
...
bm1

b22
...
bm2

· · ·

· · ·
. . .

· · ·











b1n

b2n
...
bmn











=

c11

c12

c21
...
cm1

c22
...
cm2

· · ·

· · ·
. . .

· · ·











c1n

c2n
...
cmn

tal que, cij = aij + bij, ∀ i, j

Sendo assim, `a adi¸c˜ao de matrizes segue as mesmas propriedades da adi¸c˜ao de

n´umeros reais:

comutativa, associativa, elemento neutro da adi¸c˜ao e elemento

oposto.

39

3.3.2 Propriedades da Adi¸c˜ao de Matrizes

Sejam A, B e C matrizes de mesma ordem, ent˜ao valem as seguintes propriedades:

(1) Comutativa: A + B = B + A

Demonstra¸c˜ao: Sejam X e Y matrizes tais que X = A + B e Y = B + A.
Observando que xij = aij + bij e que yij = bij + aij. Como aij e bij ∈ R, ent˜ao vale a

propriedade comutativa dos n´umeros reais, aij + bij = bij + aij

implicando que

xij = yij, logo X = Y. Portanto, A + B = B + A, como quer´ıamos mostrar.

(2) Associativa: A + (B + C) = (A + B) + C

Demonstra¸c˜ao: Sejam X e Y matrizes tais que X = A + (B + C) e Y = (A + B)

+ C. Observando que xij = aij + (bij + cij) e yij = (aij + bij) + cij. Como aij, bij e

cij s˜ao n´umeros reais, vale a propriedade associativa dos n´umeros reais, ent˜ao

xij = yij logo, X = Y . Portanto, A + (B + C) = (A + B) + C, como quer´ıamos

mostrar.

(3) Existˆencia do elemento sim´etrico: A + (-A) = 0

Demonstra¸c˜ao: Seja X uma matriz tal que X + A = 0, em que 0 representa uma

matriz nula (denotada por 0, uma matriz nula todos os elementos s˜ao iguais a

zero). Observamos que xij + aij = 0, ∀ i, j. Como aij ´e um n´umero real, segue que

xij + aij = 0 implica, xij + aij + (−aij) = 0 + (−aij). Logo, xij = (−aij) ∀ i, j.

Portanto, todo elemento da matriz X ´e o oposto do elemento correspondente em A.

Ent˜ao, existe uma matriz (- A) = -(aij) tal que A + (- A) = 0

(4) Existˆencia do elemento neutro: A + 0 = A

Demonstra¸c˜ao: Seja X uma matriz tal que A + X = A. Ent˜ao, aij + xij = aij, ∀

i, j,

isto ´e, xij = 0 ∀ i, j. Portanto, a ´unica matriz que satisfaz a equa¸c˜ao

aij + xij = aij ´e a matriz nula. Portanto, existe uma matriz 0 tal que A + 0 = A.

40

3.3.3 Multiplica¸c˜ao de Matrizes

Voltando ao exemplo da empresa Alfa, suponhamos que a dire¸c˜ao da empresa, aﬁm

de atender `a demanda de seus s´ocios, precisa apresentar a receita gerada no primeiro

bimestre do ano de 2015. Sabe-se que os pre¸cos de venda, em reais, de cada unidade,

de seus produtos 1,2,3 e 4 s˜ao respectivamente, 3,9,8,2.

Ent˜ao a receita total gerada nesse per´ıodo pela f´abrica 1 ´e dada por:

7 x 3 + 5 x 9 + 0 x 8 + 1 x 2 = 68 (milh˜oes de reais)

Entretanto, ao invˆes de calcularmos apenas a receita gerada por uma f´abrica,

podemos calcular simultˆaneamente com a mesma simplicidade a receita gerada por

todas as f´abricas. A resposta ser´a uma matriz de ordem 1 x 3, em que o elemento

da primeira linha corresponde `a receita gerada pela f´abrica 1, o elemento da

segunda linha corresponde `a f´abrica 2 e por ﬁm, o elemento da terceira linha

corresponde `a receita gerada pela f´abrica 3.

T =








7 5 0 1

0 4 3 7

3 2 0 2




























3

9

8

2








=

7 · 3 + 5 · 9 + 0 · 8 + 1 · 2

0 · 3 + 4 · 9 + 3 · 8 + 7 · 2

3 · 3 + 2 · 9 + 0 · 8 + 2 · 2








=















68

74

31

Podemos observar que, a multiplica¸c˜ao entre os elementos de uma linha pelos

elementos de uma coluna ´e uma a¸c˜ao fundamental para a multiplica¸c˜ao de matrizes.

Este exemplo sugere a deﬁni¸c˜ao geral para a multiplica¸c˜ao de matrizes.

Deﬁni¸c˜ao: Sejam A = (aij) e B = (bij) matrizes de ordem m x k e k x n

respectivamente. O produto AB ´e a matriz C = (cij), de ordem m x n, em que

41

cada elemento cij ´e dado por:

cij = ai1b1j + ai2b2j + · · · + aikbkj
























∗

∗

· · ·

∗

∗
∗
...
...
ai1 ai2
...
...
∗
∗

· · ·
∗
...
...
· · · aik
...
...
∗
· · ·















·















∗ · · ·

∗ · · ·
...
...
∗ · · ·
...
...
∗ · · ·

· · ·

∗

· · ·
...
· · ·
...
· · ·

∗

∗

∗















=















∗ · · ·

· · ·

· · ·

...
...
∗ · · ·
...
...
∗
∗

...
cij
...
· · ·

...
· · ·
...
· · ·

















∗

...
∗
...
∗

Exemplo 3.3.3.1 Dadas as matrizes

A =








1

4

2

5

3

6

1 −1 2

, B =















1

2 3

−1 0 3

2

4 1

b1j

b2j
...
bkj
...
bkj








Vamos determinar produto AB = C = (cij).

Note que o elemnto c22 ´e dado pela soma dos produtos entre os elementos

correspondentes da segunda linha da matriz A pelos da segunda coluna da matriz

B conforme segue demonstrado abaixo.

↓

−→








∗ ∗ ∗

4 5 6

∗ ∗ ∗















·

∗ 2 ∗

∗ 0 ∗

∗ 4 ∗








=








∗

∗

∗

42

↓

∗

4 . 2 + 5 . 0 + 6 . 4

∗








∗

∗

∗

Logo,

↓

↓

−→








∗ ∗ ∗

4 5 6

∗ ∗ ∗








·








∗ 2 ∗

∗ 0 ∗

∗ 4 ∗








=








∗

∗

∗

∗ 32 ∗

∗

∗

∗








Calculando cij ∀ i, i obtemos:

c11 = 1 · 1 + 2 · (−1) + 3 · 2 = 5

c12 = 1 · 2 + 2 · 0 + 3 · 2 = 14

c13 = 1 · 3 + 2 · 3 + 3 · 1 = 12

c21 = 4 · 1 + 5 · (−1) + 6 · 2 = 11

c22 = 4 · 2 + 5 · 0 + 6 · 0 = 32

c23 = 4 · 3 + 5 · 3 + 6 · 1 = 33

c31 = 1 · 1 + (−1) · (−1) + 2 · 2 = 6

c32 = 1 · 2 + (−1) · 0 + 2 · 4 = 10

c33 = 1 · 3 + (−1) · 3 + 2 · 1 = 2

Portanto, a matriz C = cij ´e dada por

C =








5

14 12

11 32 33

2

10

2








43

Exemplo 3.3.3.2: Dados os aeroportos de Londrina-PR (L) e Porto Alegre - RS

(P), e os a´eroportos de Esmeraladas - MG (E), Bras´ılia DF (B) e Trˆes Lagoas - MS

(T). A ﬁgura a seguir, mostra as poss´ıveis rotas de voos diretos entre essas cidades.

Figura 3.4: Rotas de voos diretos

A ﬁm de analizarmos as rotas de voo, primeiro codiﬁcamos a rede em uma matriz.

Se h´a um voo direto entre as cidades, colocamos 1, caso contr´ario 0.

Sendo assim o quadro que indica as rotas de voos pode ser representado por:

L P E B T

L 0

P 1

E 1

B 1

T 1

1

0

0

1

1

1

0

0

0

0

1

1

0

0

0

1

1

0

0

0

Tabela 3.7: Matriz de voos diretos

Dessa forma podemos observar que n˜ao existem voos diretos entre as cidades de

44

Esmeralda, Bras´ılia e Trˆes Lagoas.

Podemos interpretar a matriz AA = A2 como sendo a tabela das poss´ıveis rotas de

voos entre as cidades com exatamente uma escala.














0 1 1 1 1

1 0 0 1 1

1 0 0 0 0

1 1 0 0 0

1 1 0 0 0



























·

0 1 1 1 1

1 0 0 1 1

1 0 0 0 0

1 1 0 0 0

1 1 0 0 0



























=

4 2 0 1 1

2 3 1 1 1

0 1 1 1 1

1 1 0 2 2

1 1 1 2 2














Note que, h´a trˆes possibilidades de viagens de ida e volta a Porto Alegre passando

por outras cidades, mas n˜ao h´a rotas entre as cidades e Londrina e Esmeralda com

uma escala.

3.3.4 Associatividade do Produto de Matrizes

Uma propriedade importante do produto matricial, ´e a associatividade, isto ´e, dadas

as matrizes Amxn,Bnxp e Cpxq. Ent˜ao,

(AB)C = A(BC)

Demonstra¸c˜ao: Sejam X e Y matrizes tais que X = (AB)C e Y = A(BC), e

sejam xij e yij elementos quaisquer de X e Y respectivamente, queremos mostrar

que X = Y .

Tomando de X um elemento xij arbitr´ario temos que

45

xij = (cid:80)p
= (cid:80)p
= (cid:80)p
= (cid:80)n
= (cid:80)n
= (cid:80)n

i=1 (ab)ikckj
k=1 ((cid:80)n
k=1 ((cid:80)n
s=1 ((cid:80)p
s=1 ais ((cid:80)p
s=1 ais(bc)sj
= (a (bc))ij = yij

s=1 aisbsk)ckj
s=1 aisbskckj)
k=1 aisbskckj)
k=1 bskckj)

Portanto, X = Y , como quer´ıamos mostrar.

3.3.5 Distributividade do Produto em rela¸c˜ao a Soma

Outra propriedade importante ´e a distribuitividade do produto em rela¸c˜ao a soma,

isto ´e, das as matrizes A, B e C, compat´ıveis com as condi¸c˜oes de existˆencia da soma

e produto temos:

A(B + C) = AB + AC

Demonstra¸c˜ao: Sejam X e Y matrizes tais que X = A(B + C) e Y = AB + AC,

queremos mostrar que X = Y . Para isso, tomamos xij um elemento qualquer de X.

Logo, podemos escrever que xij = (a(b + c))ij. Ent˜ao xij = (a(b + c))ij =⇒xij =

aik(b + c)kj =⇒xij = aik(bkj + ckj) =⇒xij = aikbkj + aikckj =⇒xij = (ab)ij + (ac)ij

=⇒xij = (ab + ac)ij =⇒xij = yij.

Por outro lado, tomando yij um elemento qualquer de Y , podemos escrever que,

yij = (ab + ac)ij. Logo, sabemos que, yij = (ab)ij + (ac)ij =⇒yij = aikbkj + aikckj

=⇒yij = aik(bkj +ckj) =⇒yij = aik(b+c)kj =⇒yij = (a(b+c))ij. Portanto, yij = xij.

Ent˜ao, podemos concluir que X = Y , como quer´ıamos mostrar.

46

3.3.6

´Algebra Num´erica versus ´Algebra Matricial

Podemos estabelecer muitas semelhan¸cas entre a ´algebra n´umerica e a ´algebra

matricial, p´orem existem quatro diferen¸as fundamentais.

O produto AB n˜ao est´a deﬁnido para quaisquer matrizes A e B, pois o produto

apenas faz sentido quando o n´umero de linhas da matriz A ´e igual ao n´umero de

colunas da matriz B.

O produto AB n˜ao ´e comutativo. Mesmo que os produtos AB e BA estejam

deﬁnidos, n˜ao se tem necess´ariamente AB = BA. Por exemplo:

Enquanto que





0 1

1 0









0 0

0 1





 =







0 1

0 0





0 0

0 1









0 1

1 0





 =



0 0

1 0



 .

O produto de duas matrizes n˜ao nulas, pode gerar a matriz nula. Como exemplo:





0 1

0 0









0 1

0 0





 =



0 0

0 0



 .

Para todo x ∈ R diferente de zero, existe x−1 ∈ R, tal que, x.x−1 = 1.

Esse fato n˜ao ocorre na ´algebra matricial. Como exemplo:

Sejam A e B duas matrizes n˜ao nulas tais que AB = 0. Ent˜ao nem A nem B

possuem inversa. Pois,

A−1(AB) = (A−1A)B = B = 0

47

48

4 Matrizes Estoc´asticas

4.1

Introdu¸c˜ao

As matrizes estoc´asticas exercem papel

fundamental na teoria das cadeias de

Markov. Veja a seguir um exemplo t´ıpico de uma matriz estoc´astica.








A =

0, 1 0, 01 0, 3

0, 2 0, 99 0, 3

0, 7

0

0, 4








Toda matriz estoc´astica possui duas propriedades:

(1) todos os seus elementos s˜ao maiores ou iguais a zero;

(2) a soma dos elementos em cada coluna ´e igual a 1.

Para o desenvolvimento da teoria das cadeias de Markov, estaremos interessados nas

potˆencias dessas matrizes. As matrizes estoc´asticas est˜ao fortemente conectadas com

a teoria das Probabilidades.

Exemplo 4.1.1: Um homem ou dirige seu carro ou toma um ˆonibus para ir ao

trabalho todos os dias. Suponhamos que ele nunca tome o ˆonibus dois dias seguidos,

mas se ele dirige at´e o trabalho, ent˜ao no dia seguinte, a probabilidade dele dirigir

novamente ´e a mesma dele tomar um ˆonibus.

A matriz estoc´astica que representa as probabilidades de escolhas entre ir ao trabalho

de carro ou de ˆonibus ´e dada por:





A =





0, 5 1

0, 5 0

em que a primeira coluna corresponde a hip´otese de que no dia seguinte em que ele

dirigiu at´e o trabalho, ele dirige ou toma um ˆonibus no dia seguinte com igual

probabilidade. A segunda coluna corresponde a hip´otese de que ele nunca vai ao

trabalho de ˆonibus dois dias seguidos.

Deﬁni¸c˜ao: Uma matriz quadrada ´e denominada matriz estoc´astica quando todos

os seus elementos s˜ao n´umeros reais n˜ao negativos e a soma dos elementos em cada

coluna ´e sempre igual a 1.

Exemplo 4.1.2: A matriz P ´e estoc´astica.

P =











3/4 1/2

0

0

0

1/4 3/5 1/3

1/8 1/4 1/5 1/3

1/8

0

1/5 1/3











Pois, todos os seus elementos s˜ao maiores ou igual zero e a soma dos elementos de

cada coluna ´e igual a 1.

Teorema 4.1.1: Sejam A = (aij) e B = (bij) matrizes estoc´asticas de ordem m.

Ent˜ao o produto AB ´e uma matriz estoc´astica. Em particular, todas as potˆenicas

Ak com k inteiro positivo, s˜ao matrizes estoc´asticas.

Demonstra¸c˜ao: Considere as matrizes quadradas A = aij e B= bij de mesma

ordem. Sabemos que o produto AB ´e dado por AB= cij, em que

cij = ai1b1j + ai2b2j + · · · + aikbkj

49

Aﬁm de mostrar que o produto AB ´e estoc´astica, tomamos arbitrariamente uma

coluna k de AB. Somando seus elementos obtemos

c1k + c2k + · · · + cmk =

= (a11b1k + · · · + a1mbmk) + (a21b1k + · · · + a2mbmk) + · · · + (am1b1k + · · · + ammbmk)

= b1k (a11 + · · · + am1) + b2k (a12 + · · · + am2) + · · · + bmk(a1m + · · · + amm)

Como a matriz A=(aij) ´e uma matriz estoc´astica segue que

c1k + c2k + · · · + cmk = b1k.1 + b2k.1 + · · · + bmk.1 = b1k + · · · + bmk

Entretanto, como B=(bij) tamb´em ´e estoc´astica temos que b1k + · · · + bmk.

Logo, c1k + c2k + · · · + cmk = 1

Portanto, o produto entre duas matrizes estoc´asticas ´e uma matriz estoc´astica.

4.2 Matriz Estoc´astica Regular

Uma matriz estoc´astica P ´e dita uma matriz estoc´astica regular, se todos os

elementos de alguma potˆencia P n s˜ao estritamente positivos, sendo n um inteiro

positivo.

Exemplo 4.2.1. A migra¸c˜ao de animais ´e o deslocamento deles em grupos de um

lugar para outro. Muitos deles fazem esse movimento na procura de alimento ou na

busca de um local para se reproduzir, exemplo disso ´e a tartaruga-de-couro

(Dermochelys coriacea). Sua imigra¸c˜ao ´e uma das mais impressionantes. As fˆemeas

ﬁcam circulando entre a Am´erica e a Europa e escolhem o litoral brasileiro para

desovar [13].

50

Agora suponha que um bi´ologo especialista em comportamento migrat´orio, realizou

um estudo sobre a migra¸c˜ao da tartaruga-de-couro ap´os o per´ıodo da desova aﬁm

de estabelecer um padr˜ao migrat´orio para esp´ecie. Ele constatou empiricamente

que dentre as fˆemeas monitoradas que partiram dos EUA, 50% delas migraram

para o M´exico ap´os a desova e que 50% migraram para a Europa. Dentre as fˆemeas

que partiram do M´exico, 20% migraram para os EUA, 50% retornaram ao M´exico e

que 30% migraram para a Europa. Dentre as fˆemeas que partiram da Europa,

todas migraram para o M´exico ap´os o per´ıodo de desova.

Considere:








x = n´umero de fˆemeas que partiram dos EUA

y = n´umero de fˆemeas que partiram do M´exico

z = n´umero de fˆemeas que partiram da Europa

x’ = n´umero de fˆemeas que migraram para os EUA

y’ = n´umero de fˆemeas que migraram para o M´exico

z’ = n´umero de fˆemeas que migraram para Europa

Ent˜ao de acordo com os dados obtemos:

x’ = 20% de y




Dessa forma obtemos a seguinte equa¸c˜ao:

y’ = 50% de x + 50% de y + z

z’ = 50% de x + 30% de y








x(cid:48)

y(cid:48)

z(cid:48)















=

0

0, 2 0

0, 5 0, 5 1

0, 5 0, 3 0






















x

y

z

51

Indicando por M a matriz

M =








0

0, 2 0

0, 5 0, 5 1

0, 5 0, 3 0








e denotando

v =















x

y

z

v(cid:48) =








x(cid:48)

y(cid:48)

z(cid:48)








obtemos a seguinte equa¸c˜ao

v(cid:48) = M v

Vamos admitir que as taxas de migra¸c˜ao sejam mantidas a cada ano. Al´em disso

vamos supor que a popula¸c˜ao monitorada permanece constante.

Para o pr´oximo per´ıodo de desova a popula¸c˜ao de tartarugas-de-couro que migrou

para, EUA, M´exico e Europa ser´a dada por

Como o produto de matrizes ´e associativo, tem - se

v(cid:48) = M (M v)

Observe que

v(cid:48) = M 2v.

M 2 =








0

0, 2 0

0, 5 0, 5 1

0, 5 0, 3 0















0

0, 2 0

0, 5 0, 5 1

0, 5 0, 3 0















=

0, 1

0, 1

0, 2

0, 75 0, 65 0, 5

0, 15 0, 25 0, 3








52

Portanto, a cada ano a popula¸c˜ao que migra ´e obtida pela multiplica¸c˜ao da

popula¸c˜ao anterior matriz M . Da´ı se conclui que decorridos k anos, a popula¸c˜ao

que migra ´e dada por

M kv.

Por este motivo diz - se que o ﬂuxo migrat´orio das tartarugas-de-couro monitoradas

´e representada pela matriz M . Podemos observar atrav´es da matriz M , que ap´os a

desova, apenas migraram para os EUA, animais que partiram do M´exico. Mas no

segundo per´ıodo do ciclo migrat´orio de desova, todos os locais de observa¸c˜ao EUA,

M´exico e Europa receber˜ao animais vindo de todos os trˆes locais de partida. Isto

pode ser visto do fato de que todas as entradas de M 2 s˜ao positivas.

Observe que o produto de uma matriz com entradas positivas por uma matriz

estoc´astica resulta sempre numa matriz com entradas positivas.

4.3 Ponto ﬁxo de uma Matriz Estoc´astica Regular

Seja A uma matriz quadrada. Um vetor n˜ao nulo w ∈ R ´e chamado de autovetor da

matriz A, se existir λ ∈ R tal que

Aw = λw

O escalar λ ´e chamado de autovalor da matriz A associado ao autovetor w.

Quando o autovetor w est´a associado ao autovalor λ = 1, dizemos que w ´e um

ponto ﬁxo da matriz A. Assim um ponto ﬁxo de A ´e um vetor w, n˜ao nulo, w tal

que

53

Aw = w

Exemplo 4.3.1. Observe que o vetor

´e um autovetor da matriz

w =









1

2

A =









3

0

8 −1

associado ao autovalor λ = 3, pois Aw = 3w. Vejamos:





3

0

8 −1









1

2





 =



3

6





 = 3







1

2

Teorema 4.3.1. Seja A uma matriz quadrada e k um inteiro positivo. Se w ´e um

autovetor de A associado ao autovalor λ ent˜ao w ´e um autovetor de Ak associado ao

autovalor λk.

Demonstra¸c˜ao: Vamos mostrar por indu¸c˜ao que a senten¸ca

Akw = λkw

´e verdadeira para todo k ∈ N.

Observe que para k = 1 a senten¸ca ´e verdadeira, pois por hip´otese λ ´e um

autovetor da matriz A associado ao autovetor w, ou seja,

Aw = λw.

54

Agora segue da equa¸c˜ao acima que

A2w = A(Aw) = A(λw) = λ(Aw) = λ2w

Agora, supondo que a senten¸ca seja verdadeira para algum k = n com n ∈ N,

vamos mostrar que a ela ´e verdadeira para k = n + 1. De fato, suponha que

Anw = λnw, n ∈ N.

Multiplicando ambos os membros da igualdade pela matriz A, obtemos

A(Anw) = A(λnw).

Pela propriedade associativa do produto de matrizes segue que

(AAn)w = λn(Aw) = λn(λw)

An+1w = λn+1w.

Assim, mostramos que a senten¸ca ´e verdadeira para k = n + 1.

Portanto, pelo Princ´ıpio da Indu¸c˜ao Finita, Akw = λkw, ´e verdadeira para todo k

inteiro positivo, como quer´ıamos mostrar.

Em particular, quando λ = 1, obtemos o seguinte.

Corol´ario 4.3.1. Se w ´e um ponto ﬁxo de A ent˜ao w ´e ponto ﬁxo de Ak, ∀k ∈ N

com k ≥ 1.

Teorema 4.3.2. Toda matriz quadrada n˜ao nula A = (aij) tem pelo menos um

ponto ﬁxo se, somente se, o determinante da matriz A - I ´e nulo, em que I ´e a

matriz identidade.

Demonstra¸c˜ao: A matriz A = (aij) tem ponto ﬁxo se, somente se, existe um

55

vetor w, n˜ao nulo, dado por

tal que Aw = w, isto ´e,

w =











w1

w2
...
wm











Ent˜ao, segue que











a11

a12

· · ·

a1m

a21
a22
...
...
am1 am2

· · ·
. . .

a2m
...
· · · amm































w1

w2
...
wm

=











w1

w2
...
wm
















a11w1 + a12w2 + · · · + a1mwm = w1

a21w1 + a22w2 + · · · + a2mwm = w2
...
am1w1 + am2w2 + · · · + ammwm = wm

Em outras palavras, podemos dizer que w ´e um ponto ﬁxo de A = (aij), se existir

solu¸c˜ao n˜ao trivial para o sistema homogˆeneo abaixo.






(a11 − 1) w1 + a12w2 + · · · + a1mwm = 0

a21w1 + (a22 − 1) w2 + · · · + a2mwm = 0
...
am1w1 + am2w2 + · · · + (amm − 1) wm = 0

56

Como um sistema homogˆeneo possui solu¸c˜ao n˜ao trivial se,

somente se, o

determinante da matriz dos coeﬁcientes ´e nulo, conclu´ımos que

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(a11 − 1)

a12

a21
...
am1

(a22 − 1)
...
am2

· · ·

· · ·
. . .

· · ·

a1m

a2m
...
(amm − 1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= 0

Portanto podemos concluir que uma matriz quadrada possui ponto ﬁxo n˜ao nulo se,

e somente se, det(A - I) = 0.

Teorema 4.3.3. Toda matriz estoc´astica A tem pelo menos um ponto ﬁxo.

Demonstra¸c˜ao: Pelo fato da matriz A ser estoc´astica a soma dos elementos de

cada coluna da matriz A - I ´e zero. Logo a soma de todas as linhas da matriz A − I

´e a linha nula. O determinante de uma matriz n˜ao se altera quando se troca uma

linha pela soma dela com a soma das outras linhas. Substituindo a ´ultima linha da

matriz A - I pela soma de todas as linhas obtemos a linha nula. Logo det (A - I) =

0. Portanto, pelo teorema 4.3.2 toda matriz estoc´astica possui pelo menos um

ponto ﬁxo.

Exemplo 4.3.2. Consideremos a matriz

Ent˜ao, o vetor





A =





1/2 1/3

1/2 2/3

57

w =









2/5

3/5

´e um ponto ﬁxo de A. De fato, pois,





1/2 1/3

1/2 2/3











 =

2/5

3/5









1
2

.

2
5

+

1
3

.

3
5

1
2

.

2
5

+

2
3

.

3
5











=







2/5

3/5

Portanto,

Aw = w.

Teorema 4.3.4. Seja w um ponto ﬁxo da matriz A e seja x ∈ R com x (cid:54)= 0, ent˜ao

o vetor xw tamb´em ´e um ponto ﬁxo de A.

Demonstra¸c˜ao: Sabemos que w ´e um ponto ﬁxo de A ent˜ao podemos escrever

Aw = w ⇒ x(Aw) = xw ⇒ A(xw) = xw.

O que demonstra que o vetor xw tamb´em ´e um ponto ﬁxo de A.

Observa¸c˜ao: Vamos mostrar que todos os pontos ﬁxos da matriz A do exemplo

4.3.2 s˜ao colineares.

De fato seja (x, y) um ponto ﬁxo de A. Ent˜ao

A(x, y) = (x, y)

58









1
2

1
2









1
3

2
3









x

y






1
2

1
2

x +

x +

1
3

2
3

y = x

y = y

Logo

O que equivale a y =

3
2

x.

Ent˜ao

(cid:18)

(x, y) =

x,

(cid:19)

3
2

x

(cid:18)

= x

1,

(cid:19)

3
2

=

5
2

x

(cid:18) 2
5

,

3
5

(cid:19)

.

Deﬁni¸c˜ao: Se o vetor w ´e um ponto ﬁxo de A e al´em disso w1 + w2 + · · · + wm = 1

com wi ≥ 0 com i = 1, · · · , m. Dizemos que w ´e um vetor ﬁxo de probabilidade.

Teorema Fundamental da Matriz Estoc´astica Regular: Seja P uma matriz

estoc´astica regular. Ent˜ao, P possui um ´unico vetor de probabilidade ﬁxo w e

todas as coordenadas de w s˜ao positivas.

Demonstra¸c˜ao: Como P ´e uma matriz estoc´astica, pelo teorema 4.3.3 P possui

pelo menos um ponto ﬁxo w, logo

P w = w.

Pelo corol´ario 4.3.1, w ´e um ponto ﬁxo de P n, para todo n ≥ 1. Como P ´e uma

matriz estoc´astica, seja m ∈ N tal que todas as entradas de P m s˜ao positivas, logo

P mw = w.

59

Seja P m = (aij), aij > 0, 1 ≤ i, j ≤ n.

Ent˜ao,











a11 a12

· · ·

a1n

a21 a22
...
...
an1 an2

· · ·
. . .

a2n
...
· · · ann































w1

w2
...
wn











w1

w2
...
wn











.

=

Trocando w por −w, se necess´ario, podemos supor que w possui alguma coordenada

positiva. Vamos mostrar que todas as coordenadas de w s˜ao positivas.

Suponha

por

absurdo

que w possui

k

coordenadas

n˜ao

positivas

e

consequentemente w possui n − k coordenadas positivas.

Sem perda de

generalidade podemos supor que wj ≤ 0 com 1 ≤ j ≤ k e que wj > 0 com

k + 1 ≤ j ≤ n.

Ent˜ao podemos escrever o sistema






a11w1 + a12w2 + · · · + a1nwn = w1

a21w1 + a22w2 + · · · + a2nwn = w2
...
ak1w1 + ak2w2 + · · · + aknwn = wk
...
an1w1 + an2w2 + · · · + annwn = wn.

Considerando apenas as k primeiras equa¸c˜oes obtemos

60






a11w1 + a12w2 + · · · + a1kwk + a1k+1wk+1 + · · · + a1nwn = w1

a21w1 + a22w2 + · · · + a2kwk + a2k+1wk+1 + · · · + a2nwn = w2
...
ak1w1 + ak2w2 + · · · + akkwk + akk+1wk+1 + · · · + aknwn = wk

Isolando as (n − k) ´ultimas vari´aveis obtemos






a1k+1wk+1 · · · + a1nwn = w1 − (a11w1 + a12w2 + · · · + a1kwk)

a2k+1wk+1 · · · + a2nwn = w2 − (a21w1 + a22w2 + · · · + a2kwk)
...
akk+1wk+1 · · · + aknwn = wk − (ak1w1 + ak2w2 + · · · + akkwk) .

Somando as k equa¸c˜oes temos:

wk+1 (a1k+1 + · · · + akk+1)+· · ·+wn (a1n + · · · + akn) = w1

1 −

(cid:32)

k
(cid:88)

i=1

(cid:33)

(cid:32)

ai1

+· · ·+wk

1 −

(cid:33)

aik

k
(cid:88)

i=1

Lembrando que aij > 0, para todo 1 ≤ i, j ≤ n, logo

0 < wk+1
(cid:124) (cid:123)(cid:122) (cid:125)
>0

(a1k+1 + · · · + akk+1)
(cid:125)
(cid:123)(cid:122)
(cid:124)
>0

+ · · ·+ wn
(cid:124)(cid:123)(cid:122)(cid:125)
>0

(a1n + · · · + akn)
(cid:124)
(cid:125)
(cid:123)(cid:122)
>0

=

k
(cid:88)

j=1
(cid:124)

(cid:32)

wj

1 −

k
(cid:88)

i=1

(cid:33)

aij

≤ 0

(cid:123)(cid:122)
≤0

(cid:125)

Isto caracteriza um ﬂagrante absurdo. Portanto w n˜ao possui coordenadas menores

ou igual a zero.

Logo todas as coordenadas de w s˜ao positivas, isto ´e, w = (w1, · · · , wn) com wi > 0

∀ 1 ≤ i ≤ n.

61

Tomando w∗ =

1
w1 + · · · + wn

w, conclu´ımos que w ´e um vetor de probabilidade

ﬁxo, com todas as coordenadas positivas.

Agora vamos mostrar que o vetor de probabilidade de P ´e ´unico. Suponhamos que

existam dois vetores de probabilidade u e v, u (cid:54)= v, tais que u e v s˜ao pontos ﬁxos

de P . Ent˜ao

Al´em disso

P u = u e P v = v.

n
(cid:88)

i=1

(u − v)i =

n
(cid:88)

i=1

ui −

n
(cid:88)

i=1

vi = 1 − 1 = 0.

Como u − v (cid:54)= 0 ent˜ao o vetor u − v possui pelo menos uma coordenada maior que

zero e pelo menos uma coordenada menor que zero. Mas isso contraria ao que

demonstrado anteriormente.

Logo, P possui um ´unico vetor de probabilidade ﬁxo, como quer´ıamos demonstrar.

62

63

5 Cadeias de Markov

5.1

Introdu¸c˜ao

Observando a natureza, pode-se perceber uma equilibrada dicotomia. Pois n˜ao

existem duas coisas exatamente iguais, mas todas elas tendem a seguir algum

padr˜ao n˜ao manifestado claramente. Plat˜ao acreditava que a verdadeira forma do

universo estava oculta. Observando a natureza, apenas conseguir´ıamos atingir um

conhecimento aproximado sobre a verdade pura em outras palavras, a verdade

estava escondida em planos impercepit´ıveis aos nossos sentidos. Sendo assim, a

verdadeira forma pura das coisas, somente era acess´ıvel por meio do racioc´ınio

abstrato da ﬁlosoﬁa e da matem´atica, como exemplo um c´ırculo, cuja a distˆancia

da borda at´e o centro ´e sempre a mesma. Entretanto, n´os nunca encontraremos

uma manifesta¸c˜ao material de um c´ırculo perfeito ou de uma linha reta perfeita.

Embora

interessado, Plat˜ao

especulava

que,

passados

uma

quantidade

arbitrariamente grande de anos, o universo encontraria um estado ideal, retornando

a sua forma perfeita. Esse foco platˆonico em formas puramente abstratas, perdurou

at´e o s´eculo XVI, momento em que as pessoas passaram a interpretar o obscuro, as

varia¸c˜oes do mundo real e a aplicar a matem´atica como ferramenta para elucidar os

padr˜oes subjacentes da natureza.

Essa corrente de ideias foi amplamente extendida, notando que, n˜ao apenas as

coisas convergem para uma raz˜ao esperada, mas a probabilidade da varia¸c˜ao em

rela¸c˜ao as medidas, tamb´em seguem uma familiar forma subjacente ou uma

distribui¸c˜ao.

Um excelente exemplo dessa ideia, ´e a m´aquina de feij˜oes de Francis Galton.

Figura 5.1: M´aquina de feij˜oes de Francis Galton

Imagine cada colis˜ao como um evento independente, como uma virada em uma

moeda honesta. Ap´os 10 colis˜oes, o feij˜ao cai em um recipiente que representa a

raz˜ao entre a deﬂax˜ao entre esquerda e direita ou ainda como sendo cara ou coroa.

Essa curvatura ´e conhecida como distribui¸c˜ao binomial. Aparenta que a m´edia do

destino desses eventos ´e de alguma forma predeterminada, conhecida hoje como

Teorema Central do Limite.

Isso representou uma ideia ﬁlos´oﬁca perigosa para alguns. Parul Nekrasov, um

te´ologo por forma¸c˜ao que mais tarde acabou seguindo os passos da matem´atica, era

um inﬂuente proponente da doutrina religiosa do livre arb´ıtrio. Ele n˜ao admitia a

ideia de termos esse destino estat´ıstico predeterminado.

Ele aﬁrmava que a

independˆencia era uma condi¸c˜ao necess´aria para a lei dos grandes n´umeros desde

que a independˆencia descrevesse esses exemplos simples como os que utilizam

feij˜oes, dados ou moedas, os quais o resultado de um evento anterior n˜ao afeta a

probabilidade da ocorrˆencia do evento futuro. No entanto, como podemos observar,

64

a grande parte dos fenˆomenos da f´ısica, s˜ao claramente dependentes de um

resultado anterior.

Quando a probabilidade de algum evento depende ou ´e condicional a um evento

anterior, dizemos que eles s˜ao eventos dependentes.

Essa aﬁrma¸c˜ao irritou um matem´atico russo, Andrey A. Markov, o qual manteve

publicamente um desafeto com Nekrasov. Markov estendeu os trabalhos realizados

por Bernoulli sobre vari´aveis dependentes utilizando uma constru¸c˜ao engenhosa.

Imagine uma moeda a qual n˜ao seja independente, mas dependente apenas do

resultado anterior, ent˜ao esse processo teria uma mem´oria de curto prazo. Esse

processo pode ser visualizado utilizando uma m´aquina hipot´etica composta por

dois potes, os quais chamamos de estados. Em um estado temos uma mistura de 50

bolas pretas e 50 bolas brancas indistingu´ıveis. Enquanto no outro, temos uma

mistura com mais bolas pretas do que brancas. Um pote podemos chamar de

estado 0 (zero), ele representa a ocorrˆencia anterior a uma bola preta, e o outro,

podemos chamar de 1 (um), ele representa a bola branca tendo ocorrido

anteriormente.

Para iniciarmos o uso da m´aquina, simplismente come¸camos em um dos estados

retirando uma bola. A partir da´ı, iremos para o estado 0 ou 1, dependendo do

resultado daquele evento. Como esse processo possui dois estados, podemos

identiﬁcar 4 poss´ıveis transi¸c˜oes de estados. Se estamos no estado 0 e ocorre uma

bola preta, permanecemos no estado 0, e retiramos uma outra bola. Se uma bola

branca ´e retirada, o processo passa para o estado 1, o qual tamb´em pode

permanecer em si mesmo, ou passar para o estado 0 se uma bola preta for retirada.

A probabilidade de uma bola branca ser retirada em rela¸c˜ao uma bola preta ´e

claramente n˜ao independente

65

Figura 5.2: M´aquina de dois estados

Entretanto, Markov demonstrou que quando todos os estados da m´aquina s˜ao

acess´ıveis, ao ligar a m´aquina em uma sequˆencia, ela atingir´a o equil´ıbrio, ou seja,

n˜ao importa em que estado comece, uma vez que, iniciada a sequˆencia, o n´umero de

vezes que o processo visita cada estado, converge para um equil´ıbrio, isto ´e, para

uma distribui¸c˜ao de probabilidades.

Esse simples experimento, n˜ao dial´oga com a aﬁrma¸c˜ao de Nekrasov de que apenas

eventos independentes podem convergir para distribui¸c˜oes previs´ıveis. No entanto,

a pr´atica de modelar as sequˆencias de eventos aleat´orios utilizando estados e suas

transi¸c˜oes ﬁcou conhecido como cadeias de Markov.

As cadeias de Markov s˜ao assim denominadas em homenagem ao matem´atico russo

Andrei Andreyevich Markov (1856 -1922) que as utilizou para analisar altera¸c˜oes de

vogais e de consoantes no poema Eugene Onegin, de Pushkin. Ele n˜ao enxergava

outra aplica¸c˜ao para sua teoria na ´epoca, certamente ﬁcaria muito satisfeito se

soubesse do sucesso e da ampla utiliza¸c˜ao de sua descoberta. A cadeia de Markov ´e

um processo estoc´astico desmemoriado, isto ´e, um processo estoc´astico no qual o

estado futuro depende apenas do estado presente, mas n˜ao dos estados passados.

66

5.2 Andrei Andreyevich Markov

Andrei Andreyevich Markov nasceu em 14 de junho de 1856 em Ryazan, R´ussia,

e morreu em 20 de julho de 1922 em S˜ao Petersburgo foi o primeiro ﬁlho do casal

Andrei Grigorievich Markov e Nadezhda Petrovna.

Figura 5.3: Andrei Andreyevich Markov

Markov conviveu grande parte de sua infˆancia com uma sa´ude muito fr´agil,

apresentando diﬁculdades at´e mesmo para andar. Na adolescˆencia demonstrou seu

talento excepcional para a matem´atica, mas n˜ao teve o mesmo sucesso nas outras

disciplinas. Publicou seu primeiro artigo quando ainda cursava o equivalente ao

Ensino M´edio cujo tema abordado foi Equa¸c˜oes Diferenciais Lineares e, mesmo

apresentando resultados j´a conhecidos, o artigo despertou a aten¸c˜ao de dois

importantes professores da Universidade de S˜ao Petersburg, Aleksandr Korkin e

Yegor Ivanovich Zolotarev.

A partir da´ı, ﬁcou evidente que a Matem´atica era o caminho natural para Markov

e, em 1874, ingressou na Faculdade de F´ısica e Matem´atica de S˜ao Petersburgo. Por

l´a, matriculou-se no semin´ario dirigido pelos professores Korkin e Zolotarev, mas

tamb´em assistiu a muitas palestras do professor Pafnuty Chebyshev, na ´epoca chefe

do departamento de matem´atica.

67

Markov se formou em 1878 ganhando nesse ano o prˆemio de melhor artigo publicado

envolvendo o tema Integra¸c˜ao de Equa¸c˜oes Diferenciais por meio de Fun¸c˜oes

Cont´ınuas. Querendo tornar-se professor, trabalhou em seu mestrado ao longo de

dois anos obtendo o t´ıtulo em 1880 com um trabalho sobre Formas Quadr´aticas

Bin´arias com Determinantes Positivos.

Esse trabalho foi muito elogiado por

Chebyshev e representou uma dos melhores trabalhos realizados sobre Teorias dos

Nmeros de toda a Matem´atica Russa. Embora sua disserta¸c˜ao tenha sido publicada

simultaneamente em francˆes, ela n˜ao foi absorvida imediatamente por matem´aticos

da Europa Ocidental, dando a medida do quanto Markov havia se aprofundado no

assunto. Terminado o mestrado, Markov come¸cou a lecionar na Universidade de S˜ao

Petersburgo, enquanto trabalhava em seu doutoramento, concluindo-o em 1884 com

a tese sobre Aplica¸c˜oes de Fra¸c˜oes Cont´ınuas.

Agora professor, Markov havia ganhado notabilidade social suﬁciente para assumir

sua antiga paix˜ao por Maria Ivanova Valvatyeva, pedindo-a em casamento. Os

dois j´a se conheciam desde crian¸cas, pois ela era a ﬁlha do propriet´ario da fazenda

em que seu pai gerenciava. No entanto, a m˜ae de Ivanova n˜ao aceitava a ideia de

que sua ﬁlha casasse com o ﬁlho do gerente da fazenda. Entretanto, os esfor{ccos

para evitar a uni˜ao n˜ao foram suﬁcientes e, em 1883, a m˜ae de Ivanova concedeu a

anuncia e o casamento aconteceu naquele mesmo ano.

Markov construiu uma s´olida carreira como professor na Universidade de S˜ao

Petersburgo e, al´em disso, ingressou na Academia Russa de Ciˆencias indicado por

Chebyshev, em 1883. Aposentou-se formalmente em 1905, mas continuou a ensinar

por alguns anos.

Markov foi o porta-voz mais elegante das ideias e dire¸c˜oes de pesquisa em Teoria

de Probabilidades de Chebyshev. Ele ´e lembrado particularmente pelo estudo

desenvolvido sobre Sequˆencias de Vari´aveis Aleat´orias em que a pr´oxima vari´avel ´e

68

determinada no m´aximo pelo estado presente, mas ´e independente da forma pelo

qual o estado atual surgiu de seus antecessores. Markov analisou a sequˆencia de

vogais e consoantes no poema Eugene Onegin, escrito por Alexander Pushkin em

1883. Ele veriﬁcou empiricamente que uma vogal era seguida por uma consoante

em 87% das vezes e que uma consoante era seguida por uma vogal 66% das vezes.

Este trabalho ´e conhecido como Cadeias de Markov e representa um marco na

Teoria das Probabilidades. Em 1923, Nobert Winer tornou-se o primeiro a tratar

rigorosamente os Processos Cont´ınuos Markovianos. As bases de uma teoria geral

foi fornecida durante a d´ecada de 1930 por Andrei Kolmogorov.

Markov viveu um per´ıodo de grande atividade pol´ıtica na R´ussia e, por ter opini˜oes

ﬁrmes, tornou-se um militante pol´ıtico. Em 1913, a dinastia Romanov, que estava

no poder na R´ussia desde 1613, comemorou seus 300 anos de poder, mas Markov

fez quest˜ao de demonstrar toda sua desaprova¸c˜ao pela celebra¸c˜ao. Com o in´ıcio

da Revolu¸c˜ao Russa em 1917, Markov foi enviado para Zaraisk, uma pequena

cidade do interior da R´ussia, onde ensinou matem´atica na escola secund´aria sem

receber qualquer remunera¸c˜ao. Por ﬁm, retornou a S˜ao Petersburgo, apresentando

uma sa´ude debilitada, vindo a falecer em julho de 1922 depois de meses de sofrimento.

5.3 Conceitos B´asicos sobre Cadeias de Markov

5.3.1 Introdu¸c˜ao

Essa se¸c˜ao prop˜oem-se a apresentar os principais conceitos e deﬁni¸c˜oes sobre as

cadeias de Markov, ﬁxando as ideias por meio da apresenta¸c˜ao de alguns exemplos.

69

Em particular, os conceitos e ferramentas necess´arios para a an´alise da convergˆencia

de uma cadeia de Markov regular para sua distribui¸c˜ao estacion´aria.

Um conceito muito importante que ser´a apresentado ´e sobre a matriz de transi¸c˜ao

de uma cadeia de Markov, elemento esse fundamental na teoria. A partir da matriz

de transi¸c˜ao, podemos caracteriz´a - la e doravante estudarmos sua distribui¸c˜ao

de probabilidade estacion´aria utilizando opera¸c˜oes matriciais b´asicas facilmente

programadas. Isso ´e uma particularidade importante na aplica¸c˜ao da teoria.

5.3.2 Deﬁni¸c˜ao de uma cadeia de Markov

Considere um processo estoc´astico ﬁnito {Xn }n>0 em que cada vari´avel aleat´oria

Xi assume, com certa probabilidade, um estado si ∈ {s1, s2, · · · , sn } com

i = 1, 2, · · · , n.

Deﬁni¸c˜ao: Uma cadeia de Markov ﬁnita ´e um processo estoc´astico ﬁnito tal que:

P (Xn = sn|X1 = s1, X2 = s2, ..., Xn−1 = sn−1) = P (Xn = sn|Xn−1 = sn−1)

Podemos dizer outras palavras, que uma cadeia de Markov ´e um processo estoc´astico

desmemoriado, isto ´e, o resultado de qualquer tentativa depende apenas do resultado

da tentativa imediatamente anterior, n˜ao dependendo das demais tentativas.

A condi¸c˜ao acima ´e conhecida como propriedade de Markov.
Seja {Xn}∞

n=0 uma cadeia de Markov, se Xn = sj, dizemos que a cadeia de Markov,
est´a no estado sj no parˆametro n ou que a cadeia de Markov visita o estado sj no

parˆametro n.

A probabilidade do sistema passar do estado si para para o estado sj no tempo n ´e

70

denotada por:

pij(n) = P (Xn = si|Xn−1 = sj)

As probabilidades de transi¸c˜ao pij(n) n˜ao dependem de n. Sendo assim, denotamos

apenas por pij.

Se uma cadeia de Markov possui n estados poss´ıveis, ent˜ao as probabilidades de

transi¸c˜ao s˜ao convenientemente representadas em uma matriz quadrada de ordem

n, P = (pij) denotada matriz de transi¸c˜ao sendo representada por:

P =











p11 p12

p21 p22
...
...
pn1 pn2

· · ·

· · ·
. . .

· · ·











p1n

p2n
...
pnn

Assim, a cada estado sj correspondente a j-´esima coluna da matriz P . Ent˜ao o

vetor coluna representa a distribui¸c˜ao da probabilidade condicional de Xn dado que

Xn−1 = j, sendo portanto, um vetor de probabilidade.
(cid:111)
p(0)
j

O vetor de probabilidade inicial ´e o vetor w0 =

(cid:110)

= {P (X0 = sj)}.

Observe que P tem as seguintes propriedades:

pij ≥ 0

n
(cid:88)

j=1

pij = 1

71

Exemplo 5.3.2.1. O que ´e maior: a probabilidade de que neve depois de uma de

sol quente ou depois de um dia nublado e frio?

Situa¸c˜oes como essa podem serem estudadas e modeladas pelas cadeias de Markov

como segue na situa¸c˜ao a seguir.

Na terra de N´arnia nunca ocorrem dois dias ensolarados seguidos. Se em um dia

faz sol, ent˜ao para o dia seguinte ﬁca igualmente propenso a nevar ou chover. Se

chover, no dia seguinte a probabilidade de chover novamente ´e de 1

2 e ﬁca igualmente
propenso nevar ou fazer sol. Caso tenhamos um dia com precipta¸c˜ao de neve, para

o dia seguinte temos a probabilidade de nevar novamente de 1

2 e a de chover ou fazer

sol igualmente propensos. Dessa forma a matriz de transi¸c˜ao ´e dada por








P =

0, 5

0, 5 0, 25

0, 25

0

0, 25

0, 25 0, 5

0, 5








Ao usarmos uma cadeia de Markov para explicar um fenˆomeno da natureza, ´e

fundamental conhecermos alguns detalhes. Em fun¸c˜ao da independˆencia temporal,

que est´a presente no conceito das cadeias de Markov. Ent˜ao podemos ignorar o

tempo de 10 dias atr´as para prever o tempo amanh˜a. Entretanto, isso n˜ao signiﬁca

dizer que o futuro n˜ao dependa do passado, ou ainda, que o passado n˜ao inﬂuˆencia

no futuro. Ao contr´ario, uma s´erie de eventos cont´em mais informa¸c˜oes que dois

eventos isolados. Contudo, para prever o tempo amanh˜a, e em virtude das cadeias

de Markov, sabemos que podemos desprezar o tempo de 10 dias atr´as.

Na verdade, com a probabilidade, apenas medimos a chance de que algo venha

acontecer, isso n˜ao quer dizer que sabemos com certeza o que vai acontecer.

Exemplo 5.3.2.2. Um homem joga em duas m´aquinas distintas de ca¸ca n´ıquel. A

72

primeira paga o prˆemio com probabilidade c, e a segunda com probabilidade d. Se

ele perde, ele joga novamente na mesma m´aquina, se vence, ele muda para a outra

m´aquina. Seja si o estado em que ele ele joga na m´aquina i. Ent˜ao a matriz de

transi¸c˜ao ´e dada por





P =

c

1 − d

1 − c

d





Exemplo 5.3.2.3.

Um psic´ologo faz as

seguintes hip´oteses, quanto ao

comportamento de ratos sujeitos a um hor´ario especial de alimenta¸c˜ao. Para

qualquer tentativa particular, 80% dos ratos que foram para direita no experimento

anterior ir˜ao para a direita na pr´oxima tenativa, e 60% dos que foram para a

esquerda no experimento anterior ir˜ao para a direita na pr´oxima tentativa. Os

estados do sistema s˜ao D (direita) e E (esquerda). A matriz de tarnsi¸c˜ao ´e dada por





P =





0, 8 0, 6

0, 2 0, 4

Exemplo 5.3.2.4. Uma empresa de aluguel de autom´oveis tem trˆes lojas. Um

cliente pode alugar um carro em qualquer uma das lojas e devolvˆe-lo tamb´em em

qualquer uma das trˆes lojas. Por meio de um estudo realizado por essa empresa,

estima-se que os clientes devolvem os autom´oveis `as diferentes lojas, de acordo

com as seguintes probabilidades representadas na matriz de transi¸c˜ao a seguir, que

dependem apenas da loja onde o autom´ovel foi alugado

P =








0, 8 0, 3 0, 2

0, 1 0, 2 0, 6

0, 1 0, 5 0, 2








73

Nesta matriz o valor p23 = 0.6 corresponde `a probabilidade de um carro ser alugado

na loja 2 ser devolvido `a loja 3.

Exemplo 5.3.2.5. Em sociologia ´e conveniente classiﬁcar as pessoas por faixa de

renda: classe baixa, classe m´edia ou classe alta. Soci´ologos descubriram que o fator

predominante que inﬂuˆencia a classe de renda de uma pessoa, ´e a classe de renda

de seus pais. A matriz de transi¸c˜ao P mostra as probabilidades de um indiv´ıduo

mudar de classe social dependendo apenas da classe de renda de seus pais.

classe baixa

P =

classe m´edia

classe alta

classe baixa classe m´edia classe alta

0, 65

0, 28

0, 07

0, 15

0, 67

0, 18

0, 12

0, 36

0, 52

A matriz de transi¸c˜ao P mostra a probabilidade de mudan¸ca de classe de renda

de uma gera¸c˜ao para a pr´oxima. Agora desejamos investigar as probabilidades de

mudan¸cas de classe de renda para duas gera¸c˜oes. Por exemplo, para pais de classe

alta, qual a probabilidade de que tenham um neto de classe m´edia?

A probabilidade de que pais de classe alta tenham netos de classe m´edia ´e dada por

0.52 · 0.36 + 0.36 · 0.67 + 0.12 · 0.28 = 0.462 = 46, 2%

5.4 Passeios Aleat´orios Simples

Nesta se¸c˜ao iremos apresentar v´arios exemplos simples de cadeias de Markov. Esses

exemplos dizem a respeito ao que chamamos de passeio aleat´orio.

74

Sejam X1, X2, · · · , Xn, · · ·
aleat´orias
distribu´ıdas. Sejam, s0 = c e sn = s0 + (cid:80)n

vari´aveis

i=1 Xi, com n ≥ 1. O processo
estoc´astico {sn, n ≥ 0} ´e chamado de passeio aleat´orio simples. Em outras palavras,

independentes

e

igualmente

uma passeio aleat´orio simples consiste de uma part´ıcula inicialmente num ponto

x ∈ Z, que se move em Z e a cada instante pode pular d eum ponto x para um

dos pontos vizinhos, x + 1 ou x − 1, com probabilidade p de saltar para direita e

probabilidade q = 1 − p de saltar para esquerda. Se p = q = 1

2, ent˜ao dizemos que ´e
um passeio aleat´orio sim´etrico em que sn denota a posi¸c˜ao da part´ıcula no instante

n.

Imagine um homem que se move em linha reta em passos com comprimento 1, cada

passo corresponde a se deslocar uma unidade para a direita com probabilidade p ou

uma unidade para a esquerda, com probabilidade q. Move-se at´e atingir um dos

dois pontos extremos que s˜ao chamados de pontos de fronteira. As possibilidades

de seu comportamento nestes pontos determinam v´arios tipos diferentes de cadeias

de Markov. Os estados s˜ao as posi¸c˜oes poss´ıveis. Nos exemplos a seguir, estaremos

levando em considera¸c˜ao o caso com 5 estados. Os estados 0 e 4 s˜ao os estados de

fronteiras.

Exemplo 5.4.1. Um homem est´a num ponto de coordenada inteira sobre o eixo x

entre a origem e o ponto 4. Ele d´a um passo de uma unidade para a direita com

probabilidade p ou para a esquerda com probabilidade q = 1 − p, exceto quando ele

estiver na origem, caso em que d´a um passo para a direita chegando ao ponto 1, ou

quando estiver sobre o ponto 4, caso em que d´a um passo para esquerda chegando

ao ponto 3. Indiquemos por Xn a sua posi¸c˜ao, ap´os n passos. Esta ´e uma (C.M.),

cujo espa¸co de estados ´e S = {0, 1, 2, 3, 4}, em que cada estado si = i representa que

o homem est´a sobre o eixo x no ponto de abscissa i, com i = 0, 1, 2, 3, 4. A matriz

de transi¸c˜ao ´e dada por

75

P =














0 q 0 0 0

1 0 q 0 0

0 p 0 q 0

0 0 p 0 1

0 0 0 p 0














Cada coluna da matriz, exceto a primeira e a ´ultima, correspondem ao fato de que

o homem se move do estado si para o estado si+1, com probabilidade p ou para o

estado si−1 com probabilidade q = 1 − p. A primeira coluna corresponde ao fato

de que o homem passa do estado s0 sempre para o estado s1 e a ´ultima coluna

corresponde ao fato de que o homem sempre passa do estado s4 para o estado s3.

Exemplo 5.4.2. Supomos agora que sempre que o homem atinge um dos estados de

fronteira vai diretamente para o estado do centro s3. A matriz de transi¸c˜ao ´e dada por

P =














0 q 1 0 0

0 0 q 0 0

1 p 0 q 0

0 0 p 0 1

0 0 1 0 0














Exemplo 5.4.3. Suponha agora que quando o homem atinge um estado de fronteira

ele permanece nesse estado, com probabilidade 1

fronteira tamb´em com probabilidade 1

2 e se move para o outro estado de
2. Nesse caso a matriz de transi¸c˜ao ´e dada por

76

P =














0, 5 q 0 0 0, 5

0

0

0

0 q 0

p 0 q

0 p 0

0

0

p

0, 5 0 0 p 0, 5














Exemplo 5.4.4. A seguir, consideramos uma vers˜ao modiﬁcada do passeio

aleat´orio. Se o processo est´a em um dos trˆes estados interiores,ent˜ao tem igual

probabilidade de se deslocar para a direita, para a esquerda, ou permanecer em

seu estado atual. Se for na fronteira, n˜ao pode permanecer, entretanto tem igual

probabilidade de se deslocar para qualquer um dos outros quatro estados. A matriz

de transi¸c˜ao ´e dada por

P =














0

1/3

0

1/4 1/3 1/3

0

0

1/4

1/4

1/4 1/3 1/3 1/3 1/4

1/4

1/4

0

0

1/3 1/3 1/4

0

1/3

0














5.5 Probabilidades de Transi¸c˜ao Superiores

O elemento pij da matriz de transi¸c˜ao P de uma cadeia de Markov representa a

probabilidade de que o sistema passe do estado sj para o estado si em apenas um
est´agio: sj →si. Agora queremos determinar, a probabilidade p(n)

ij de que o sistema

mude do estado sj para o estado si em exatamente n est´agios.

77

sj→sk1→sk2→ · · · →sn−1→si

Teorema 5.5.1. Seja P a matriz de transi¸c˜ao de um processo em cadeia de Markov.

Se p = (pi) ´e a distribui¸c˜ao de probabilidades do sistema num instante arbitr´ario,

ent˜ao P pi ´e a distribui¸c˜ao de probabilidades do sistema ap´os um est´agio e P npi ´e

a distribui¸c˜ao de probabilidades do sistema ap´os n est´agios. Em particular, temos que

p(1) = P p(0); p(2) = P p(1); p(3) = P p(2); · · · ; p(n) = P p(n−1)

Logo, podemos escrever que p(n) = P p(0).

Demonstra¸c˜ao: Suponhamos que o espa¸co de estados seja S = {s1, s2, · · · , sn}.

A probabilidade de que o sistema esteja no estado sj no instante k e passe para o

estado si no instante k + 1 ´e o produto pijpi, isto ´e,

P (Xk+1 = si|Xk = sj) = pijpj

Dessa forma, a probabilidade de que o sistema esteja no estado si no instante k + 1

´e dada por

P (Xk+1 = si|Xk = s1) + P (Xk+1 = si|Xk = s2) + · · · + P (Xk+1 = si|Xk = sn) .

Ou seja,

pi1p1 + pi2p2 + · · · + pinpn

Logo, a distribui¸c˜ao de probabilidades no instante k + 1 ´e dada por:

78











p∗ =

p11p1 + p12p2 + · · · + p1npn

p21p1 + p22p2 + · · · + p2npn
...
pn1p1 + pn2p2 + · · · + pnnpn











Por outro lado,

isso mostra que o vetor p∗ ´e exatamente o produto da matriz

P = (pij) pelo vetor pi.

Portanto, p∗ = P p. Sendo assim tem - se

p(1) = P p(0); p(2) = P p(1); · · · ; p(n) = P p(n−1)

Agora note que

p(2) = P p(1) = P (P p(0)) = P 2p(0)

p(3) = P p(2) = P (P 2p(0)) = P 3p(0)
...
p(n) = P p(n−1) = P (P (n−1)p(0)) = P np(0)

como quer´ıamos demonstrar.

Teorema 5.5.2. Teorema das Potˆencias da Matriz de Transi¸c˜ao: Seja P

a matriz de transi¸c˜ao de um processo em cadeia de Markov. Ent˜ao, a matriz de

transi¸c˜ao para n est´agios ´e igual a en´esima potˆencia de P , em que p(n) = P n.

Demonstra¸c˜ao: Suponhamos que o sistema esteja no estado sj no instante k.

A distribui¸c˜ao de probabilidade do sistema no instante k, uma vez que o sistema

est´a no estado sj, ´e o vetor ej, tal que ej ´e o vetor coluna com valor 1 na j-´esima

coordenada e zeros nos demais ´ındices. Pelo teorema anterior a distribui¸c˜ao de

probabilidades no instante k + n ´e dada pelo vetor

79

p(n+k) = P npk = P nej.

Entretanto, P nej ´e a j-´esima coluna da matriz P n. Dessa forma, p(n)
ij ´e a i-´esima
componente da j-´esima coluna de P n. Portanto, p(n) = P n, como quer´ıamos

demonstrar.

Suponhamos agora, que em um instante arbitr´ario, a probabilidade de que o sistema

esteja no estado si seja pij. Indicamos estas probabilidades pelo vetor

p =





















p1

p2
...
pn

o qual determina a distribui¸c˜ao de probabilidades do sistema naquele instante. Em

particular, indicamos por

p(0) =











p(0)
1
p(0)
2
...
p(0)
n











como sendo a distribui¸c˜ao inicial de probabilidades,

isto ´e, a distribui¸c˜ao de

probabilidades que existe quando o processo se inicia, e indicamos por

80

p(n) =











p(n)
1
p(n)
2
...
p(n)
n











como sendo a distribui¸c˜ao de probabilidades ap´os n est´agios.

Exemplo 5.5.1. Um homem ou dirige ou toma um ˆonibus para ir trabalhar todos

os dias. Suponhamos que ele nunca tome o ˆonibus dois dias consecutivos, mas se ele

dirige at´e o trabalho, ent˜ao no dia seguinte, a probabilidade dele dirigir novamente

´e a mesma dele tomar o ˆonibus.

A matriz de transi¸c˜ao da cadeia de Markov associado a este processo ´e:









0 0, 5

1 0, 5

Nesse caso, o espa¸co de estados ´e deﬁnido tal que S = {s1 = ˆonibus, s2 = carro}

Ent˜ao, queremos conhecer, qual a probabilidade de que o sistema passe do estado s1

para o estado s2, em exatamente 4 est´agios.

Primeiramente, calculamos P 4





P 4 =









0 0, 5

1 0, 5

0 0, 5

1 0, 5









0 0, 5

1 0, 5









0 0, 5

1 0, 5





 =



0, 375 0, 3125

0, 625 0, 6875





Dessa forma, podemos dizer que a probabilidade do sistema passar do estado s1
para o estado s2, em exatamente 4 est´agios ´e dada por p(4)

12 = 0, 625.

Suponhamos agora que no primeiro dia o homem tenha lan¸cado um dado honesto

81

para decidir se iria ao trabalho de carro ou ˆonibus. Ele deﬁniu que iria dirindo

para o trabalho se, e somente se, o resultado do lan¸camento do dado fosse 6,

caso contr´ario iria de ˆonibus. Com isso podemos assumir que a distribui¸c˜ao

inicial de probabilidades do processo ´e, p(0) = (5/6, 1/6) ´e a distribui¸c˜ao inicial de

probabilidades do sistema.

Logo, a distribui¸c˜ao de probabilidades ap´os 4 dias ´e dada por:

p(4) = P 4p(0) =





0, 375 0, 3125

0, 625 0, 6875













 =







35/96

61/96

5/6

1/6

Portanto, a distribui¸c˜ao de probabilidades ap´os 4 dias ´e dada por:

p(4) =









35/96

61/96

Em outras palavras, ap´os espera-se que o homem tenha ido ao trabalho de ˆonibus

em 36,4% das vezes e tenha ido de carro em 63,6% das vezes.

5.6 Cadeias de Markov Regulares

5.6.1 Introdu¸c˜ao

Suponhamos que em uma determinada regi˜ao, observa-se que se chover bastante

durante o ano, a probabilidade de que chova bastante no ano seguinte ´e de 25%, e

que a probabilidade de que se tenha uma escassez de chuva ´e de 75%. Ainda sabemos

que, se houver uma escassez de chuvas em um ano, no ano seguinte a probabilidade

82

de haver bastante chuva ou uma seca, ser´a a mesma.

Suponhamos tamb´em,

para simpliﬁcar o modelo, que estas probabilidades permane¸cam inalteradas com

o decorrer dos anos, o que n˜ao ocorre na pr´atica, embora possamos usar essa

simpliﬁca¸c˜ao, como recurso para termos um indicador da situa¸c˜ao.

A longo prazo, o que podemos esperar com maior probabilidade. Que essa regi˜ao

sofra com per´ıodos de muita chuva? Ou com per´ıodos com escassez de chuvas?

As cadeias de Markov mostram-se eﬁcazes na resolu¸c˜ao desse tipo de problema.

Sendo assim, muito importantes na avalia¸c˜ao de propostas de interven¸c˜ao na

realidade utilizando conhecimentos alg´ebricos. Esse cap´ıtulo dedica-se na an´alise

do comportamento estacion´ario da distribui¸c˜ao de probabilidade de uma cadeia de

Markov regular, essencial na aplica¸c˜ao.

As cadeias de Markov regulares, exercem papel fundamental nas aplica¸c˜oes, em

virtude de sua distribui¸c˜ao estacion´aria de probabilidades, sobretudo, pois sua

convergˆencia para sua distribui¸c˜ao ´e obtida por meio de opera¸c˜oes matriciais

elementares aplicadas na matriz de transi¸c˜ao as quais s˜ao facilmente programadas

e esta ´e uma importante particularidade nas aplica¸c˜oes das cadeias regulares, o que

propcia apresentar o tema em turmas de Ensino M´edio. A contemporalidade do

tema e suas diversas aplica¸c˜oes corroboram para o desenvolvimento do pensamento

cr´ıtico e investigativo dos alunos, potencializando a aprendizagem de temas como

probabilidades e matrizes.

83

5.6.2 Distribui¸c˜ao Estacion´aria de uma cadeia de Markov

Regular

Deﬁni¸c˜ao: Uma cadeia de Markov ´e dita regular se, e somente se, a partir de um

estado inicial arbitr´ario ´e poss´ıvel acessar qualquer estado ap´os um certo n´umero de

passos, em outras palavras, se sua matriz de transi¸c˜ao P for uma matriz estoc´atica

regular.

Lema 5.6.2: Seja P uma matriz de transi¸c˜ao de ordem r com todas as entradas

s˜ao positivas. Seja (cid:15) a menor entrada da matriz P . Seja x um vetor coluna com r

coordenadas, sendo M0 sua maior coordenada e m0 sua menor coordenada, e sejam

M1 e m1 respectivamente a maior e a menor coordenada do vetor P x. Ent˜ao

M1 ≤ M0, m0 ≤ m1

M1 − m1 ≤ (1 − 2(cid:15))(M0 − m0).

Demonstra¸c˜ao: Seja x∗ um vetor obtido substituindo todas as componentes do

vetor x por M0 exceto a componente m0, ent˜ao, xi ≤ x∗

i . Cada componente de P x∗

´e da forma

P x∗

i = a · m0 + (1 − a) · M0 = M0 − a(M0 − m0)

em que a ≥ (cid:15). Assim, P x∗

i ≤ M0 − (cid:15)(M0 − m0). Entretanto, como xi ≤ x∗

i , temos

M1 ≤ M0 − (cid:15)(M0 − m0).

Se aplicarmos esse resultado no vetor −x, obtemos

−m1 ≤ −m0 − (cid:15)(−m0 + M0)

84

Segue dos resultados anteriores que

M1−m1 ≤ M0−m0−2(cid:15)(M0−m0) = (1−2(cid:15))(M0−m0) =⇒ M1−m1 ≤ (1−2(cid:15))(M0−m0)

Teorema Fundamental da Convergˆencia das Cadeias de Markov Regulares:

Seja P uma matriz de transi¸c˜ao regular. Ent˜ao, as potˆencias P n se aproximam da

matriz estoc´astica A, tal que todas as linhas s˜ao iguais ao ponto ﬁxo w da matriz P .

Al´em disso, cada coluna de A ´e o mesmo vetor de probabilidades w, isto ´e, A = wξ,

em que ξ ´e o vetor linha com todas as componentes iguais a 1.

Demonstra¸c˜ao: Primeiro vamos assumir que P n˜ao tem entrada zero e seja (cid:15) sua

menor entrada. Seja ρj um vetor coluna com 1 na j-´esima coordenada e 0 nas demais.

Sejam Mn e mn o maior e o menor valores dentre as coordenadas do vetor P nρj.

Desde que P nρj = P P n−1ρj segue do lema anterior. que M1 ≥ M2 ≥ M3 ≥ · · · e

m1 ≤ m2 ≤ m3 ≤ · · · ent˜ao

Mn − mn ≤ (1 − 2(cid:15))(Mn−1 − mn−1)

∀n ≥ 1.Se tomarmos dn = Mn − mn, isso nos diz que

dn ≤ (1 − 2(cid:15))nd0 = (1 − 2(cid:15))n

Assim, quando n tende ao inﬁnito dn tende a zero, Mn e mn aproximam de um

limite comum, e portanto P npj tende para o vetor com todas as componentes iguais.

Seja wj esse valor comum. Fica claro que, ∀n, mn ≤ wj ≤ Mn. Em particular, desde

que 0 < m1 e M1 < 1, temos que 0 < wj < 1. Agora P nρj ´e a j-´esima coluna de P n.

Assim, a j-´esima coluna de P n tende para o vetor com todas componentes iguais

ao valor wj, isto ´e, P n tende para a matriz A em que todas as linhas s˜ao iguais ao

vetor w = (w1, · · · , wr). Desde que as somas das componentes dos vetores linhas

85

da matriz P n sejam sempre iguais a 1, o mesmo deve ser verdade para o limite.

Isso completa a demonstra¸c˜ao para o caso me que todas as entradas da matriz s˜ao

positivas.

Consideramos agora que P seja regular. Seja N tal que, cada potˆencia P N n˜ao

tenha entradas zero. Tome (cid:15)∗ a menor das entradas de P N . Aplicando a primeira

parte da demonstra¸c˜ao para a matriz P N , temos

dkN ≤ (1 − 2(cid:15)∗)k

Portanto, a sequˆencia dn, que n˜ao ´e crescente, possui uma subsquˆencia tendendo a

zero. Assim dn tende a zero e o resto da prova ´e analoga a prova para a matriz com

todas as entradas positivas.

Portanto, a sequˆencia P , P 2, P 3,· · · ,Pn, · · · das potˆencias de P tende `a matriz

cujas as colunas s˜ao todas iguais ao vetor de probabilidade ﬁxo w, como quer´ıamos

demosntrar.

Esse teorema assegura a existˆencia de um m´etodo simples para determinar o vetor

de probabilidade ﬁxo de uma matriz de transi¸c˜ao de uma cadeia de Markov.

Para obtermos o vetor de probabilidade ﬁxo basta tomarmos uma potˆencia P n com

n suﬁcientemente grande.

O vetor de probabilidade ﬁxo w ser´a denominado vetor da distribui¸c˜ao estacion´aria

da cadeia de Markov regular determinada pela matriz de transi¸c˜ao P .

Suponhamos que uma cadeia de Markov seja regular, isto ´e, que sua matriz de

transi¸c˜ao P seja regular. Pelo teorema da convergˆencia, a sequˆencia das matrizes

de transi¸c˜ao para n est´agios, P n, tende a matriz T , cujas linhas s˜ao todas iguais
ao unico vetor de probabilidade ﬁxo w de P . Logo, a probabilidade w(n)

ij de que o

estado j ocorra, para n suﬁcientemente grande, ´e independente do estado inicial i e

86

tende a componente wi de w. Em outras palavras, a longo prazo, a probabilidade de

que qualquer estado j ocorra ´e aproximadamente igual a componente wi do ´unico

vetor de probabilidade ﬁxo w de P .

Dessa forma, observamos que a inﬂuˆencia do estado inicial ou da distribui¸c˜ao inicial

de probabilidades do processo diminui a medida em que o n´umero de est´agios do

processo aumenta. Al´em disso, toda sequˆencia de distribui¸c˜ao de probabilidades

tende ao vetor de probabilidade ﬁxo de P , o qual representa a distribui¸c˜ao

estacion´aria de uma cadeia de Markov.

Essa caracter´ıstica permite com que as cadeia de Markov Regulares, sejam um

´otimo modelo de modelagem matem´atica para a an´alise de previs˜oes a longo prazo.

Exemplo 5.6.1. Suponhamos que em uma determinada regi˜ao, observa-se que

se chover bastante durante o ano, a probabilidade de que chova bastante no ano

seguinte ´e de 1

´e de 3

4, e que a probabilidade de que se tenha uma escassez de chuva
4. Ainda sabemos que, se houver uma escassez de chuvas em um ano,
no ano seguinte a probabilidade de haver bastante chuva ou uma seca, ser´a a

mesma. Suponhamos tamb´em, para simpliﬁcar o modelo, que estas probabilidades

permane¸cam inalteradas com o decorrer dos anos, o que n˜ao ocorre na pr´atica,

embora possamos usar essa simpliﬁca¸c˜ao, como recurso para termos um indicador

da situa¸c˜ao. Sendo assim, a matriz de transi¸c˜ao desse processo em cadeia de Markov

´e dada por





M =





0, 25 0, 5

0, 75 0, 5

Note que M ´e uma matriz estoc´astica regular, uam vez que todos os seus elementos

s˜ao positivos.

Sendo assim, podemos concluir que, quaisquer que sejam as

87

probabilidades iniciais, a distribui¸c˜ao de probabilidades a longo prazo ´e dada pelo

vetor de probabilidades ﬁxo da matriz M .

M w = w





0, 25 0, 5

0, 75 0, 5









x

1 − x





 =



x

1 − x





 =







wchuva

wseca

Da equa¸c˜ao acima segue o sistema

Ent˜ao, devemos ter





0, 25x + 0, 5 − 0, 5x = x

0, 75x + 0, 5 − 0, 5x = 1 − x

0, 25x + 0, 5 − 0, 5x = x

x + 2 − 2x = 4x

Da equa¸c˜ao acima segue que, x = 2

5 = 0, 4 e 1 - x = 3

5 = 0, 6.





wchuva

wseca





 =







0, 4

0, 6

Portanto, a longo prazo, a probabilidade de termos nessa regi˜ao um ano ocm

bastante chuva ´e de 40%, enquanto que a probabilidade de termos um ano com

escassez de chuvas ´e de 60%, dentro das hip´oteses simpliﬁcadoras. Com base nesses

88

a dados podemos concluir, que a regi˜ao tender´a a uma ligeira aridez.

Exemplo 5.6.2 Suponhamos que em um munic´ıpio, a cada ano 3% da popula¸c˜ao

da zona rural, migra para a zona urbana, enquanto 1% da popula¸c˜ao da zona urbana

migra para a zona rural. Se todas essas porcentagens n˜ao mudarem, qual deve ser a

rela¸c˜ao entre as popula¸c˜oes urbana e rural desse munic´ıpio a longo prazo?

A Matriz de transi¸c˜ao desse processo markoviano regular ´e dada por









0.99 0.03

0.01 0.97

Como a a matriz ´e regular, ent˜ao, a longo prazo as probabilidades wrural = 1 − x e

wurbana = x, devem satisfazer a equa¸c˜ao





0, 99 0, 03

0, 01 0, 97









x

1 − x





 =







x

1 − x

Da equa¸c˜ao acima segue que

Da´ı segue que





0, 99x + 0, 03 − 0, 03x = x

0, 01x + 0, 97 − 0, 97x = 1 − x

0, 99x + 0, 03 − 0, 03x = x

0, 04x = 0, 03

Ent˜ao temos que x = 0,75. Logo, wrural = 25% e wurbana = 75%. Portanto, se

89

n˜ao houver modiﬁca¸c˜oes nas politicas p´ublicas de migra¸c˜ao daquela regi˜ao, teremos

a longo prazo, 25% da popula¸c˜ao vivendo na zona rural do munic´ıpio e 75% da

popula¸c˜ao vivendo na zona urbana.

Exemplo 5.6.3 Observa-se experiemntalmente que, em condi¸c˜oes naturais e sem ser

submetida `a pesca industrial, a quantidade de uma certa esp´ecie de peixe varia do

seguinte modo: se em um ano a popula¸c˜ao diminui, a probabilidade de que diminua

ainda mais no ano seguinte ´e de 60% e, se em um determinado ano a popula¸c˜ao

aumenta, a probabilidade de que diminua no ano seguinte ´e de 30%. Entretanto,

observa-se que, sendo essa mesma esp´ecie de peixe submetida `a pesca industrial,

quando a popula¸c˜ao de peixes aumenta num determinado ano, a probabilidade

de que dimiua no ano seguinte se altera para 50%, enquanto que se a popula¸c˜ao

diminua no ano seguinte continua sendo 60%. Deseja-se conhecer, como a longo

prazo, a pesca industrial estar´a afetando a popula¸c˜ao de peixes dessa espe´ecie.

Desse modo, seria poss´ıvel determinar, se a pesca industrial deve diminuir para

preservar a esp´ecie ou at´e mesmo para determinar que essa atividade comercial tem

potencial para expans˜ao. Os estado desse processo s˜ao: diminui¸c˜ao da popula¸c˜ao

de peixes (D) e aumento da popula¸c˜ao de peixes (A). Ent˜ao, vamos analisar as

probabilidades de evolu¸c˜ao populacional dessa esp´ecie de peixe, sem haver pesca

industrial, a matriz de probabilidades de transi¸c˜ao desse processo markoviano ´e

dada por





0, 7

0, 4

0, 3 0, 6





Como a matriz ´e regular, as probabilidades wD = 1 − x da popula¸c˜ao diminuir e

wA = x da popula¸c˜ao aumentar a longo prazo s˜ao tais que

90

Ent˜ao,

Da´ı segue que





0, 7 0, 4

0, 3 0, 6









x

1 − x





 =







x

1 − x






0, 7x + 0, 4 − 0, 4x = x

0, 3x − 0, 6 − 0, 6x = 1 − x

0, 7x + 0, 4 − 0, 4x = x

0, 7x = 0, 4

x = 4

7 =⇒ 1 − x = 3

7

Portanto, a probabilidade da popula¸c˜ao dessa esp´ecie de peixes aumentar ´e wA = 4
7
e a probabilidade da popula¸c˜ao de peixes diminuir ´e wD = 3
7. Podemos concluir que,

em condi¸c˜oes naturais, a esp´ecie tem a sobrevivˆencia razoavelmente garantida.

Exemplo 5.6.3. Agora vamos analisar como a longo prazo a pesca industrial efeta

a popula¸c˜ao de peixes. Com esse novo cen´ario, a matris de transi¸c˜ao se altera para





0, 5

0, 4

0, 5 0, 6





Como a matriz ´e regular, a longo prazo wA = x e wD = 1 - x, s˜ao tais que





0, 5 0, 4

0, 5 0, 6









x

1 − x





 =







x

1 − x

91

Da equa¸c˜ao acima segue que






0, 5x + 0, 4 − 0, 4x = x

0, 5x + 0, 6 − 0, 6x = 1 − x

Do sistema acima segue que

0, 5x + 0, 4 − 0, 4x = x

0, 9x = 0, 4

x = 4

9 =⇒ 1 − x = 5

9

Desse modo temos, wA = 4

9. Como a probabilidade da popula¸c˜ao diminuir
´e maior, se a esp´ecie for submetida `a pesca industrial, sua sobrevivˆencia ser´a

9 e wD = 5

amea¸cada e, portanto a pesca deve ser diminu´ıda ou at´e mesmo proibida.

Podemos observar que os processos markovianos, podem ser modelados e estudados,

aﬁm de estabelecermos cen´arios a longo prazo, os quais podem oferecer informa¸c˜oes

´uteis para tomadas de decis˜ao como por exemplo, na gest˜ao de recursos naturais e

na elabora¸c˜ao de pol´ıticas p´ublicas.

5.7 Cadeias de Markov Absorventes

Um estado i de uma cadeia de Markov ´e denominado absorvente se

pii = 1.

92

Uma cadeia de Markov ´e denominada absorvente se existe pelo menos um estado

absorvente e se for poss´ıvel, a partir de qualquer estado arbitr´ario, existir uma

sequˆencia de transi¸c˜oes at´e um estado absorvente. Um estado que n˜ao ´e absorvente

´e demoninado estado de transi¸c˜ao.

Exemplo 5.7.1.

Suponhamos uma cadeia de Markov em que sua matriz de

transi¸c˜ao ´e dada por

A B C D E














4

1

1
4

1
4

4 0 1
0 1 0 0 0
1
2 0 1
4 0
0 1 0 0 0

1

4

0 0 0 0 1














A

B

C

D

E

Note que os estados s2 = B e s5 = E s˜ao ambos absorventes, pois tanto a segunda

coluna como a quinta coluna possuem 1 na diagonal principal e 0 nas demais

posi¸c˜oes. Assim, um estado i ´e absorvente se, e somente se, a i-´esima linha da

matriz de transi¸c˜ao P possui a componente na diagonal principal igual a 1, e zeros

nas demais posi¸c˜oes.

Exemplo 5.7.2. Um homem lan¸ca uma moeda honesta at´e que ocorram 3 caras

consecutivas. Seja Xn = k se, na en´esima tentativa, a ´ultima coroa tenha ocorrido

na (n − k) ´esima tentativa, isto ´e, Xn indica a maior sequˆencia de caras que termina

na en´esima tentativa. Esse ´e um processo em cadeia de Markov, cujo espa¸co de

estados ´e S = {s0, s1, s2, s3 } , em que si signiﬁca que a sequˆencia de caras tem

comprimento i. A matriz de transi¸c˜ao ´e

93











A B C D

1

1
2

1
2 0 0
2 0 1
2 0
2 0 0 1
0 0 0 1

1

2











A

B

C

D

Qualquer coluna exceto a ´ultima, corresponde ao fato de que uma sequˆencia de

caras ´e interrompida, se ocorrer coroa ou ent˜ao, ´e ampliada se ocorrer cara. A

´ultima coluna corresponde ao fato de que o jogo termina se ocorrerem trˆes caras em

sequˆencia. Note que D ´e um estado absorvente.

Teorema 5.7.1. Se uma matriz estoc´astica de ordem n ≥ 2 tem 1 na diagonal

principal, ent˜ao P n˜ao ´e regular. Podemos dizer em outras palavras, que se uma

cadeia de Markov possui pelo menos um estado absorvente, ent˜ao a cadeia n˜ao ´e

regular.

Demonstra¸c˜ao: Seja sj um estado absorvente de uma cadeia de Markov com matriz
de transi¸c˜ao P . Ent˜ao para i, a probabilidade de transi¸c˜ao ap´os n est´agios ´e p(n)

ij = 0,

∀n. Portanto, qualquer potˆencia de P tem um elemento nulo. Logo, P n˜ao ´e regular.

94

95

6 Como o Google googla?

6.1

Introdu¸c˜ao

O Google tornou-se um dos principais buscadores utilizados pelos usu´arios de

internet em todo o mundo. Grande parte desse sucesso deve-se a matem´atica

aplicada em seu algoritmo de busca. O Google foi criado com a miss˜ao de organizar

a informa¸c˜ao mundial e torn´a-la universalmente acess´ıvel.

Neste cap´ıtulo vamos mostrar como um simples gesto de pesquisar um assunto no

Google tem por tr´as muita matem´atica, mais precisamente, cadeias de Markov.

Numa ´epoca em que a internet se transformou em um gigantesco acervo de

informa¸c˜oes e conhecimento, motores de busca como o Google se transformaram em

uma esp´ecie de sonar que leva o pescador a encontrar um bom cardume. Quando

pesquisamos um tema, o Google aplica um algoritmo que, em microssegundos,

apresenta uma excelente ordena¸c˜ao para encontrarmos o que procuramos.

Resumidamende, ao perquisarmos um assunto no Google, ele envia para cerca

de 1 milh˜ao de servidores ao redor do mundo e estes por sua vez processam mais de

1 bilh˜ao de pesquisas gerando aproximadamente 20 petabytes de dados o equivalente

a 22.517.998.136.852.500 bytes.

Suponhamos que uma pessoa deseja preparar uma deliciosa carne assada para o

jantar e vai a procura de uma receita. Nessa altura a pessoa percebe que existem

451000 p´aginas relacionadas com o tema. Certamente muitas dessas p´aginas

n˜ao s˜ao interessantes e mesmo assim seria imposs´ıvel ler todas antes do jantar,

mas como num passe de ”m´agica”normalmente encontramos o que queremos nas

primeiras sugest˜oes do Google. Mas como o Google sabe quais s˜ao as p´aginas mais

interessantes sobre carne assada a ponto de apresent´a - las em primeiro lugar?

M´agica ou Matem´atica?

Os primeiros buscadores desenvolvidos limitavam-se a contar o n´umero de vezes que

a express˜ao carne assada ocorria em cada p´agina apresentando a p´agina em que a

express˜ao ocorria com maior frenquˆencia em primeiro lugar. Entretanto este n˜ao ´e

o melhor crit´erio, pois um site que repete a express˜ao carne assada n˜ao signiﬁca que

tem a melhor receita at´e mesmo porque pode ser uma p´agina em que o autor repete

diversas vezes que destesta carne assada. Para se esquivar desse problema, no ﬁnal

da d´ecada de 90, o Google apresentou um novo m´etodo de classiﬁcar as p´aginas na

internet com base na intera¸c˜ao existente entre elas na Web.

Se existem muitos links para uma determinada p´agina que cont´em uma receita

para carne assada ent˜ao essa deve ser uma p´agina com uma receita saborosa.

Segundo o algoritmo utilizado pelo Google, a importˆancia de uma p´agina depende

essencialmente da importˆancia dos sites que possuem link para ela.

O algoritmo aplicado pelo Google utiliza a estrutura de links da Web para produzir

um ranking de importˆancia para as p´aginas da Web. Esse algoritmo ´e chamado de

PageRank, ele ajuda ao Google a qualiﬁcar a grande heterogeneidade das p´aginas

da internet.

Desenvolvedores de websites

se dedicam intensamente para conseguir uma

classiﬁca¸c˜ao no topo das pesquisas em motores de busca como o Google. Com o uso

da criptograﬁa como crit´erio para classiﬁca¸c˜ao das p´aginas, muitos sites tornar˜ao

suas p´aginas mais seguras para os usu´arios. Entretanto, a seguran¸ca de um site ter´a

um peso menor na classiﬁca¸c˜ao em rela¸c˜ao a outros fatores, mas sua importˆancia

poder´a aumentar com o tempo.

96

Atualmente, h´a outros fatores adicionais que inﬂuˆenciam na ordena¸c˜ao dos sites.

Entretanto, a essˆencia do ranqueamento para qualquer usu´ario da ferramenta de

busca ´e a mesma, o PageRank.

6.2 A Origem do Google

Em 1995, dois jovens estudantes de ciˆencias da computa¸c˜ao, Larry Page com 22 anos

e Sergey Brin com 21, criaram um mecanismo de pesquisa inicialmente chamado

de BackRub, que chegou a ser utlizado em servidores da universidade de Stanford

durante mais de um ano, e acabacou em desuso por usar uma largura de banda

excessiva para os padr˜oes que a universidade tinha dispon´ıvel naquela ´epoca.

A partir da´ı, eles decidiram que o mecanismo de busca por eles criado, precisava

de um outro nome. Ap´os diversas sugest˜oes, optaram por escolher Google, um

brincadeira com a palavra ”googol”, termo matem´atico para designar o n´umero

representado pelo d´ıgito 1 seguido de cem d´ıgitos 0.

10100

Andy Bechtolsheim, doou um cheque no valor 100 mil d´olares para uma entidade que

ainda inexistente: uma empresa chamada Google Inc. Improvisado em uma garagem

no endere¸co 232 Santa margarida, Menlo Park, o Google inicia seus trabalhos. A

formaliza¸c˜ao da cria¸c˜ao da empresa na Calif´ornia ocorreu em 4 de setembro de 1998.

Em seguida, Larry e Sergey abrem uma conta em um banco em nome da nova

empresa e depositam o cheque doado por Andy Bechtolsheim. Com o crescimento

da empresa foi necess´ario abandonar o pequeno escrit´orio na garagem, e transferir-se

97

para um novo endere¸co, mais amplo e que atendesse a nova demanda da empresa e

por isso em fevereiro do ano de 1999, o Google inaugura sua nova sede no endere¸co

165 University Avenue em Palo Alto, com apenas oito funcion´arios.

A partir da´ı, o Google teve uma ascens˜ao mete´orica e hoje ´e o site mais popular de

pesquisa na internet e uma das maiores empresas de todo o mundo.

Figura 6.1: Larry Page e Sergey Brin

6.3 A Web e as cadeias de Markov

6.3.1 Introdu¸c˜ao

Entender o mecanismo de funcionamento do algoritmo PageRank, ´e essencial para

qualquer desenvolvedor de sites que deseja ter sua p´agina acessada com frequˆencia,

uma vez que, aparecer listado no topo de uma pesquisa no Google provoca muitas

vizualiza¸c˜oes. Na verdade, em fun¸c˜ao da proeminˆencia do Google como um motor

de busca, o seu m´etodo de classiﬁca¸c˜ao provocou uma forte inﬂuˆencia sobre o

98

desenvolvimento e estrutura da internet, e principalmente, alterou o formato das

informa¸c˜oes e servi¸cos oferecidos via a rede mundial de computadores.

Ferramentas de pesquisa como o Google se propoem a realizar trˆes a¸c˜oes b´asicas:

1. rastrear a web e localizar todas as p´aginas com acesso p´ublico;

2. indexar os dados a partir da primeira a¸c˜ao, de modo a serem pesquisados de

forma eﬁciente por meio de palavra-chave ou experss˜oes relevantes;

3. calcular a taxa de importˆancia de cada p´agina do banco de dados, de modo

que, ao realizarmos uma busca dentro do subconjunto de p´aginas na base

de dados com a informa¸c˜ao desejada, as p´aginas mais importantes sejam

apresentadas no topo da lista,isto ´e, com maior prioridade.

O valor da importˆancia das p´aginas da web n˜ao ´e o ´unico fator levado em

considera¸c˜ao, mas ´e o crit´erio mais signiﬁcativo.

6.3.2 Web Fortemente Conectada

Deﬁni¸c˜ao: Uma rede ´e dita admiss´ıvel se, e somente se, todos os sites possuem

pelos menos uma link de sa´ıda.

Deﬁni¸c˜ao: Uma rede ´e dita fortemente conectada se ´e poss´ıvel passar de uma

p´agina para outra qualquer apenas clicando nos links.

Exemplo 6.3.2.1. A princ´ıpio consideremos um caso simples para ilustrar a

importˆancia dos sites de uma determinada rede da internet, representada pelo grafo

99

a seguir:

Figura 6.2: Web Admissivel

No exemplo acima, a rede ´e composta por 4 sites. Cada ﬂecha orientada representa

um link existente de um site para o outro. Trata-se de uma Web admiss´ıvel, isto ´e,

cada p´agina possui pelo menos um link de sa´ıda.

Considere que um usu´ario, estando no site 1 tem igual probabilidade de acessar os

demais sites com os quais ele possui link de sa´ıda, ou seja xi o ´ındice de importˆancia

do site i, com xi ≥ 0 para qualquer p´agina i.

Inicialmente poderiamos encontrar a importˆancia do site 4, somando as importˆancias

dos sites 1 e 2, ou seja, x4 = x1 + x2. Entretanto, podemos observar que o site 1

possui link de sa´ıda para os sites 2,3 e 4.

Desse modo, a importˆancia da p´agina 1 deve ser dividida igualmente em trˆes.

Da mesma forma, como a p´agina 2 possui link de sa´ıda para as p´aginas 3 e 4 sua

importˆancia deve ser dividida em duas partes iguais.

Portanto, x4 = 1

3x1 + 1

2x2.

As importˆancias dos demais sites seguem equa¸c˜oes an´alogas. Dessa forma, obtemos

a seguinte matriz de transi¸c˜ao.

100

P =











0

1/3

0

0

1 1/2

0

0

1/3 1/2 0 1/2

1/3 1/2 0

0











Observe que P n˜ao representa uma cadeia de Markov absorvente, e

P 2 =











1/2 3/4

0

1/2

0

0

1/3 1/6

1/3 1/4 1/3 1/6

1/6

0

1/3 1/6































P 16 =

P 32 =











P 1024 =

0, 3872645672

0, 3872851923

0, 3871504167

0, 3872007577

0, 1277596375

0, 1277831474

0, 1277928625

0, 1278153643

0, 28944822217 0, 28941951440 0, 28947241393 0, 28943110624

0, 19552757300 0, 19551214576 0, 19558430667 0, 19555277158

0, 3872216851

0, 3872216899

0, 3872216784

0, 3872216866

0, 12778315422 0, 12778315296 0, 12778315897 0, 12778315637

0, 2894482101

0, 2894482090

0, 2894482087

0, 2894482076

0, 19554695050 0, 19554694812 0, 19554695279 0, 19554694930

0, 3872216844

0, 3872216844

0, 3872216844

0, 3872216844

0, 12778315585 0, 12778315585 0, 12778315585 0, 12778315585

0, 2894482090

0, 2894482090

0, 2894482090

0, 2894482090

0, 19554695062 0, 19554695062 0, 19554695062 0, 19554695062

101































Sabemos que P ´e uma matriz de transi¸c˜ao de uma cadeia de Markov regular. Note

que as componentes dos vetores linhas de probabilidades da matriz P n para valores

de n suﬁcientemente grandes tornam-se constantes, ou seja, essa cadeia de Markov

possui uma distribui¸c˜ao estacion´aria.

Dessa forma podemos concluir que a probabilidade de que um usu´ario acesse a

p´agina 1 ap´os 1024 entradas ou s´aidas entre os links dessa rede ´e igual a 38,72%,

que ´e tamb´em a probabilidade de que se acesse o site 1 depois de 1024 cliques de

links saindo da p´agina 2,3 ou 4. Portanto, a probabilidade de um usu´ario acessar a

p´agina 1 ap´os 1024 entradas ou sa´ıdas entre esses links ´e 38,72%, enquanto que para

as p´aginas 2,3 e 4 as probabilidades s˜ao respectivamente 12,77%,28,94% e 19,55%,

isto ´e, o site 2 ´e o menos acessado nessa rede de links. Por outro lado, a p´agina 1

´e a mais popular, isto ´e, aquela que possui uma maior frequˆencia de vizuali¸c˜oes e

acessos.

Para an´alisar a convergˆencia de uma cadeia de Markov regular para uma distribui¸c˜ao

estacion´aria de modo pr´atico basta encontrar um autovetor da matriz de transi¸c˜ao

P associado ao autovalor 1 e nesse caso temos:

P w = w











0

1/3

0

0

1 1/2

0

0

1/3 1/2 0 1/2

1/3 1/2 0

0































w1

w2

w3

w4











w1

w2

w3

w4











=

102

Desse modo a equa¸c˜ao anterior envolvendo autovetor e autovalor, pode ser conduzida

a um problema de sistema linear homogˆeneo dado por:

w1 − w3 − w4

2 = 0

w1
3 − w2 = 0

3 + w2
w1

2 − w3 + w4

2 = 0

w1
3 + w2

2 − w4 = 0






Resolvendo o sistema, sua solu¸c˜ao ser´a

w = t





















12

4

9

6

tal que t ∈ R.

Sendo assim, o sistema possui

inﬁnitas solu¸c˜oes, mas o que ´e relevante ´e o

ranqueamento das importˆancias, isto ´e, sua ordena¸c˜ao. E para valores positivos

de t a ordena¸c˜ao ser´a sempre a mesma, por isso, tomamos t de modo que

w1 + w2 + w3 + w4 = 1. Nesse caso temos:

w1 = 12

31 w2 = 4

31 w3 = 9

31 w4 = 6

31

103

Portanto, o vetor de probabilidade

w =





















12
31

4
31

9
31

6
31

´e a distribui¸c˜ao estacion´aria de probabilidades da cadeia de Markov representada

pela matriz de transi¸c˜ao P e tamb´em um ponto ﬁxo de P .

Exemplo 6.3.2.2. Considere uma web com 3 sites, mas agora de forma que nesses

sites existam autolinks, isto ´e, links que mant´em o usu´ario no mesmo site, e em

alguns casos a probabilidade de permanecer no site ´e maior que a de sa´ıda. Dizemos

que essa rede ´e fortemente conectada, pois podemos passar de um site qualquer para

outro site arbit´ario apenas clicando nos links.

Figura 6.3: Web

Dessa forma a matriz de transi¸c˜ao P ´e dada por

104

P =














1
2

1
4

1
4














1
4

1
2

1
2

1
4

1
4

1
4

Desse modo para analisarmos a distribui¸c˜ao estacion´aria dessa cadeia de Markov

descrita pela matriz de transi¸c˜ao P devemos encontrar o w de P , isto ´e, devemos

resolver a equa¸c˜ao

P w = w








1
2

1
4

1
4

1
4

1
4

1
4






















x

y

z

1
4

1
2

1
2















x

y

z

=

w =















.

x

3
4x
5
4x

Portanto,

Entretanto devemos ter x1 = 1

3, da´ı segue que

w =








.








1
3

1
4

5
12

105

6.3.3 Web n˜ao Fortemente Conectada

Na internet muitas p´aginas s˜ao criadas a todo momento e algumas dessas p´aginas

podem conter apenas um autolink, isto ´e, um ´unico link para si mesmo. Essas

p´aginas trazem problemas para a aplica¸c˜ao do algoritmo PangRank, pois nesse caso,

a cadeia ´e absorvente e n˜ao regular. Sendo assim, o teorema da convergˆencia n˜ao se

aplica. Para esses casos ´e poss´ıvel fazer uma modiﬁca¸c˜ao na matriz original de links

P substituindo-a, por uma matriz M , em que M ´e uma soma aﬁm de P e A, tal que

M = (1 − m)P + mA

em que 0 < m < 1 e A = aij = 1

n ∀i, j, sendo A uma matriz quadrada de ordem
n. O valor utilizado pelo Google ´e m = 0, 15. Observe que, quanto menor o valor

de m, mais peso se atribui a matriz original de links P e menos peso ´e atribuido

a matriz A. Nesse sentido, dizemos que a matriz A ´e uma matriz neutra, pois ela

distribui sua importˆancia igualmente entre todos os links da web.

Exemplo 6.3.3.1. Considere uma processo em cadeia de Markov representado pela

seguinte matriz de transi¸c˜ao

106









































P =

0 1

2 0 0 0 0 0

0 0 1

3 0 1

2 0 0

1 0 0 0 0 1

3 0

0 0 1

3 1 0 0 0

0 1

2 0 0 0 1

3 0

0 0 1

3 0 1

2 0 0

0 0 0 0 0 1

3 1









































em que a primeira coluna representa as probabilidades de transi¸c˜ao do site A para

os demais, a segunda coluna representa as probabilidades de transi¸c˜ao do site B

para os demais sites, a terceira coluna representa as probabilidades de transi¸c˜ao do

site C para os demais sites e assim por diante at´e a s´etima coluna representando as

probabilidades de transi¸c˜ao do site G para os demais sites.

Note que P ´e absorvente, mas n˜ao ´e regular sendo assim, vamos aplicar a substitui¸c˜ao

M = (1 − m)P + mA

em que m = 0, 15 e

107

Ent˜ao temos:

A =






































1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7






































1
7

1
7

1
7

1
7

1
7

1
7

1
7

M = (1 − 0, 15)P + 0, 15A

108

M = 0, 85









































0 1

2 0 0 0 0 0

0 0 1

3 0 1

2 0 0

1 0 0 0 0 1

3 0

0 0 1

3 1 0 0 0

0 1

2 0 0 0 1

3 0

0 0 1

3 0 1

2 0 0

0 0 0 0 0 1

3 1









































+ 0, 15






































1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7

1
7






































1
7

1
7

1
7

1
7

1
7

1
7

1
7

Essa substitui¸c˜ao distribui igualmente a probabilidade de 1

7 para um site qualquer

passar para outro site arbitr´ario.

M =




















0, 021 0, 446 0, 021 0, 021 0, 021 0, 021 0, 021

0, 021 0, 021 0, 304 0, 021 0, 446 0, 021 0, 021

0, 871 0, 021 0, 021 0, 021 0, 021 0, 304 0, 021

0, 021 0, 021 0, 304 0, 871 0, 021 0, 021 0, 021

0, 021 0, 446 0, 021 0, 021 0, 021 0, 304 0, 021

0, 021 0, 021 0, 304 0, 021 0, 446 0, 021 0, 021

0, 021 0, 021 0, 021 0, 021 0, 021 0, 304 0, 871




















109

Calculando a potˆencia M 1000 temos:

P 1000 =




















0, 055 0, 055 0, 055 0, 055 0, 055 0, 055 0, 055

0, 080 0, 080 0, 080 0, 080 0, 080 0, 080 0, 080

0, 091 0, 091 0, 091 0, 091 0, 091 0, 091 0, 091

0, 316 0, 316 0, 316 0, 316 0, 316 0, 316 0, 316

0, 078 0, 078 0, 078 0, 078 0, 078 0, 078 0, 078

0, 080 0, 080 0, 080 0, 080 0, 080 0, 080 0, 080

0, 295 0, 295 0, 295 0, 295 0, 295 0, 295 0, 295




















Sendo assim, a distribui¸c˜ao estacion´aria da cadeia de Markov representada pela

matriz de transi¸c˜ao P ´e dada pelo vetor

w =







































0, 055

0, 080

0, 091

0, 316

0, 078

0, 080

0, 295

Portanto, o site acessado ´e o C com popularidade de 31,6% entre os usu´arios dessa

pequena web.

110

Bibliograﬁa

[1] KEMENY, G.J.; SNELL, L.J. Finite Markov Chains. New York: Springer -

Verlag, 1976.

[2] LISPCHUTZ, S. Matem´atica Finita. S˜ao Paulo: McGraw - Hill do Brasil,

1966.

[3] MORGADO, A.C.; CARVALHO, J.B.P.; CARVALHO, P.C.P.; FERNANDEZ,

P. An´alise Combinat´oria e Probabilidade. S´etima Edi¸c˜ao. Rio de Janeiro:

SBM, 1991.

[4] BOLDRINI, J. L.; COSTA, S.I.R.; RIBEIRO, V.L.F.F.; WELTZER, H.G.

´Algebra Linear. Segunda Edi¸c˜ao. S˜ao Paulo: Harbra, 1980.

[5] S ´A, C.C; ROCHA, J. Treze Viagens pelo Mundo da Matem´atica. Segunda

Edi¸c˜ao. Rio de Janeiro: SBM, 2012.

[6] CRILLY, T. 50 cosas que hay que saber sobre Matem´aticas. Quinta

Edi¸c˜ao. Buenos Aires: Ariel, 2011.

[7] BRYAN, K; lEISE, T. The $ 25,000,000,000 eigenvector:

the Linear

Algebra behind Google. SIAM Review, 2006. Vol. 48, n◦ 3,569. Dispon´ıvel

em: http:// www.rose-hulman.edu/bryan/googleFinalVersionFixed.pdf.

[8] RPM, Rio de Janeiro, n◦ 80, p. 42 - 45, 1◦ quadrimestre de 2013.

[9] NORRIS, J.R. Markov Chains. First Edition. New York: Cambridge

University Press, 1997.

[10] MELO, M.P. Ordena¸c˜ao das p´aginas do Google - Page Rank. 2009.

Disserta¸c˜ao. (Mestrado em Ciˆencias) - Instituto de Matem´atica e Estat´ıstica da

Universidade de S˜ao Paulo, S˜ao Paulo, 2009.

[11] ISTO ´e Matem´atica - Como ´e que o Google googla. Portugual: Sigma 8, 22 de

outubro de 2012. Dispon´ıvel em: clubes.obmep.org.br/blog/video-4/.

[12] CONNOR,

J.J.;

ROBERTSON,

E.F. MacTutor History

of

Mathematics. Scotland:

2006. Dispan´ıvel

em:http:www-history.mcs.st-

andrews.ac.uk/Biographies/Markov.html. Acesso em: 08 ago. 2015.

[13] Tartaruga

-

de

-

Couro

Gigante,

Dispon´ıvel

em

http:

www.tartarugas.avph.com.br. Acesso em 10 de outubro de 2015.

112

